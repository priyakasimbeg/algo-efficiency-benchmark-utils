python3 submission_runner.py --framework=jax --workload=criteo1tb --submission_path=baselines/adamw/jax/submission.py --tuning_search_space=baselines/adamw/tuning_search_space.json --data_dir=/data/criteo1tb --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_jax_upgrade_preliminary/adamw --overwrite=True --save_checkpoints=False --max_global_steps=800 2>&1 | tee -a /logs/criteo1tb_jax_08-08-2023-05-01-10.log
2023-08-08 05:01:15.675102: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0808 05:01:32.551974 139701833172800 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_jax_upgrade_preliminary/adamw/criteo1tb_jax.
I0808 05:01:34.201649 139701833172800 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter Host CUDA
I0808 05:01:34.202460 139701833172800 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0808 05:01:34.202628 139701833172800 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0808 05:01:34.208594 139701833172800 submission_runner.py:490] Using RNG seed 1357923893
I0808 05:01:39.605557 139701833172800 submission_runner.py:499] --- Tuning run 1/1 ---
I0808 05:01:39.605796 139701833172800 submission_runner.py:504] Creating tuning directory at /experiment_runs/timing_jax_upgrade_preliminary/adamw/criteo1tb_jax/trial_1.
I0808 05:01:39.606826 139701833172800 logger_utils.py:92] Saving hparams to /experiment_runs/timing_jax_upgrade_preliminary/adamw/criteo1tb_jax/trial_1/hparams.json.
I0808 05:01:39.790095 139701833172800 submission_runner.py:176] Initializing dataset.
I0808 05:01:39.790363 139701833172800 submission_runner.py:183] Initializing model.
I0808 05:01:45.687588 139701833172800 submission_runner.py:217] Initializing optimizer.
I0808 05:01:48.880645 139701833172800 submission_runner.py:224] Initializing metrics bundle.
I0808 05:01:48.880911 139701833172800 submission_runner.py:242] Initializing checkpoint and logger.
I0808 05:01:48.882324 139701833172800 checkpoints.py:915] Found no checkpoint files in /experiment_runs/timing_jax_upgrade_preliminary/adamw/criteo1tb_jax/trial_1 with prefix checkpoint_
I0808 05:01:48.882685 139701833172800 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0808 05:01:48.882784 139701833172800 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
I0808 05:01:49.746957 139701833172800 submission_runner.py:263] Saving meta data to /experiment_runs/timing_jax_upgrade_preliminary/adamw/criteo1tb_jax/trial_1/meta_data_0.json.
I0808 05:01:49.748082 139701833172800 submission_runner.py:266] Saving flags to /experiment_runs/timing_jax_upgrade_preliminary/adamw/criteo1tb_jax/trial_1/flags_0.json.
I0808 05:01:49.845801 139701833172800 submission_runner.py:276] Starting training loop.
I0808 05:02:17.157065 139537935226624 logging_writer.py:48] [0] global_step=0, grad_norm=7.500693321228027, loss=0.7977299094200134
I0808 05:02:17.168138 139701833172800 spec.py:320] Evaluating on the training split.
I0808 05:06:20.252878 139701833172800 spec.py:332] Evaluating on the validation split.
I0808 05:10:27.490315 139701833172800 spec.py:348] Evaluating on the test split.
I0808 05:14:34.760415 139701833172800 submission_runner.py:364] Time since start: 764.91s, 	Step: 1, 	{'train/loss': 0.7996889002182904, 'validation/loss': 0.8063452584269662, 'validation/num_examples': 89000000, 'test/loss': 0.8069765212262918, 'test/num_examples': 89274637, 'score': 27.322364568710327, 'total_duration': 764.9145796298981, 'accumulated_submission_time': 27.322364568710327, 'accumulated_eval_time': 737.5921928882599, 'accumulated_logging_time': 0}
I0808 05:14:34.780065 139515721127680 logging_writer.py:48] [1] accumulated_eval_time=737.592193, accumulated_logging_time=0, accumulated_submission_time=27.322365, global_step=1, preemption_count=0, score=27.322365, test/loss=0.806977, test/num_examples=89274637, total_duration=764.914580, train/loss=0.799689, validation/loss=0.806345, validation/num_examples=89000000
I0808 05:15:30.041760 139515503048448 logging_writer.py:48] [100] global_step=100, grad_norm=0.2461758852005005, loss=0.1295282542705536
I0808 05:16:34.904835 139701833172800 spec.py:320] Evaluating on the training split.
I0808 05:19:58.843516 139701833172800 spec.py:332] Evaluating on the validation split.
I0808 05:22:36.054184 139701833172800 spec.py:348] Evaluating on the test split.
I0808 05:25:12.405428 139701833172800 submission_runner.py:364] Time since start: 1402.56s, 	Step: 192, 	{'train/loss': 0.13030987907858455, 'validation/loss': 0.130526595505618, 'validation/num_examples': 89000000, 'test/loss': 0.13416434277968556, 'test/num_examples': 89274637, 'score': 147.43547773361206, 'total_duration': 1402.5595650672913, 'accumulated_submission_time': 147.43547773361206, 'accumulated_eval_time': 1255.092710018158, 'accumulated_logging_time': 0.028232097625732422}
I0808 05:25:12.418619 139515721127680 logging_writer.py:48] [192] accumulated_eval_time=1255.092710, accumulated_logging_time=0.028232, accumulated_submission_time=147.435478, global_step=192, preemption_count=0, score=147.435478, test/loss=0.134164, test/num_examples=89274637, total_duration=1402.559565, train/loss=0.130310, validation/loss=0.130527, validation/num_examples=89000000
I0808 05:25:13.307511 139515503048448 logging_writer.py:48] [200] global_step=200, grad_norm=0.02519885264337063, loss=0.13148540258407593
I0808 05:26:09.648958 139515721127680 logging_writer.py:48] [300] global_step=300, grad_norm=0.06632603704929352, loss=0.12624813616275787
I0808 05:27:12.741222 139701833172800 spec.py:320] Evaluating on the training split.
I0808 05:30:24.485212 139701833172800 spec.py:332] Evaluating on the validation split.
I0808 05:32:59.036735 139701833172800 spec.py:348] Evaluating on the test split.
I0808 05:35:37.380251 139701833172800 submission_runner.py:364] Time since start: 2027.53s, 	Step: 394, 	{'train/loss': 0.12675405390122357, 'validation/loss': 0.12772308988764045, 'validation/num_examples': 89000000, 'test/loss': 0.13097697613713064, 'test/num_examples': 89274637, 'score': 267.7472767829895, 'total_duration': 2027.5343923568726, 'accumulated_submission_time': 267.7472767829895, 'accumulated_eval_time': 1759.7316937446594, 'accumulated_logging_time': 0.049050331115722656}
I0808 05:35:37.397405 139515503048448 logging_writer.py:48] [394] accumulated_eval_time=1759.731694, accumulated_logging_time=0.049050, accumulated_submission_time=267.747277, global_step=394, preemption_count=0, score=267.747277, test/loss=0.130977, test/num_examples=89274637, total_duration=2027.534392, train/loss=0.126754, validation/loss=0.127723, validation/num_examples=89000000
I0808 05:35:38.093298 139515721127680 logging_writer.py:48] [400] global_step=400, grad_norm=0.093278668820858, loss=0.13373887538909912
I0808 05:36:38.568754 139515503048448 logging_writer.py:48] [500] global_step=500, grad_norm=0.11298548430204391, loss=0.12790638208389282
I0808 05:37:37.859783 139701833172800 spec.py:320] Evaluating on the training split.
I0808 05:40:51.641052 139701833172800 spec.py:332] Evaluating on the validation split.
I0808 05:43:22.819449 139701833172800 spec.py:348] Evaluating on the test split.
I0808 05:45:52.511186 139701833172800 submission_runner.py:364] Time since start: 2642.67s, 	Step: 588, 	{'train/loss': 0.1267589905682732, 'validation/loss': 0.12751584269662922, 'validation/num_examples': 89000000, 'test/loss': 0.13062511808365013, 'test/num_examples': 89274637, 'score': 388.1992325782776, 'total_duration': 2642.6653311252594, 'accumulated_submission_time': 388.1992325782776, 'accumulated_eval_time': 2254.3830287456512, 'accumulated_logging_time': 0.07369256019592285}
I0808 05:45:52.526812 139515721127680 logging_writer.py:48] [588] accumulated_eval_time=2254.383029, accumulated_logging_time=0.073693, accumulated_submission_time=388.199233, global_step=588, preemption_count=0, score=388.199233, test/loss=0.130625, test/num_examples=89274637, total_duration=2642.665331, train/loss=0.126759, validation/loss=0.127516, validation/num_examples=89000000
I0808 05:45:53.803416 139515503048448 logging_writer.py:48] [600] global_step=600, grad_norm=0.04801710322499275, loss=0.12527009844779968
I0808 05:46:59.822267 139515721127680 logging_writer.py:48] [700] global_step=700, grad_norm=0.041849344968795776, loss=0.1272481083869934
I0808 05:47:52.988980 139701833172800 spec.py:320] Evaluating on the training split.
I0808 05:50:52.979856 139701833172800 spec.py:332] Evaluating on the validation split.
I0808 05:53:17.153096 139701833172800 spec.py:348] Evaluating on the test split.
I0808 05:55:38.763478 139701833172800 submission_runner.py:364] Time since start: 3228.92s, 	Step: 782, 	{'train/loss': 0.1229856154497932, 'validation/loss': 0.12617901123595507, 'validation/num_examples': 89000000, 'test/loss': 0.12937978118017998, 'test/num_examples': 89274637, 'score': 508.64723539352417, 'total_duration': 3228.917628288269, 'accumulated_submission_time': 508.64723539352417, 'accumulated_eval_time': 2720.157458305359, 'accumulated_logging_time': 0.10049295425415039}
I0808 05:55:38.781138 139515503048448 logging_writer.py:48] [782] accumulated_eval_time=2720.157458, accumulated_logging_time=0.100493, accumulated_submission_time=508.647235, global_step=782, preemption_count=0, score=508.647235, test/loss=0.129380, test/num_examples=89274637, total_duration=3228.917628, train/loss=0.122986, validation/loss=0.126179, validation/num_examples=89000000
I0808 05:55:40.437966 139701833172800 spec.py:320] Evaluating on the training split.
I0808 05:58:19.664353 139701833172800 spec.py:332] Evaluating on the validation split.
I0808 06:00:28.531445 139701833172800 spec.py:348] Evaluating on the test split.
I0808 06:02:36.175527 139701833172800 submission_runner.py:364] Time since start: 3646.33s, 	Step: 800, 	{'train/loss': 0.12498531341552735, 'validation/loss': 0.12630567415730337, 'validation/num_examples': 89000000, 'test/loss': 0.12956448089506092, 'test/num_examples': 89274637, 'score': 510.29617285728455, 'total_duration': 3646.3296854496, 'accumulated_submission_time': 510.29617285728455, 'accumulated_eval_time': 3135.8949489593506, 'accumulated_logging_time': 0.12549948692321777}
I0808 06:02:36.188348 139515721127680 logging_writer.py:48] [800] accumulated_eval_time=3135.894949, accumulated_logging_time=0.125499, accumulated_submission_time=510.296173, global_step=800, preemption_count=0, score=510.296173, test/loss=0.129564, test/num_examples=89274637, total_duration=3646.329685, train/loss=0.124985, validation/loss=0.126306, validation/num_examples=89000000
I0808 06:02:36.200298 139515503048448 logging_writer.py:48] [800] global_step=800, preemption_count=0, score=510.296173
I0808 06:02:39.834450 139701833172800 checkpoints.py:490] Saving checkpoint at step: 800
I0808 06:03:12.582879 139701833172800 checkpoints.py:422] Saved checkpoint at /experiment_runs/timing_jax_upgrade_preliminary/adamw/criteo1tb_jax/trial_1/checkpoint_800
I0808 06:03:12.808652 139701833172800 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_jax_upgrade_preliminary/adamw/criteo1tb_jax/trial_1/checkpoint_800.
I0808 06:03:12.919171 139701833172800 submission_runner.py:530] Tuning trial 1/1
I0808 06:03:12.919430 139701833172800 submission_runner.py:531] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0808 06:03:12.920774 139701833172800 submission_runner.py:532] Metrics: {'eval_results': [(1, {'train/loss': 0.7996889002182904, 'validation/loss': 0.8063452584269662, 'validation/num_examples': 89000000, 'test/loss': 0.8069765212262918, 'test/num_examples': 89274637, 'score': 27.322364568710327, 'total_duration': 764.9145796298981, 'accumulated_submission_time': 27.322364568710327, 'accumulated_eval_time': 737.5921928882599, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (192, {'train/loss': 0.13030987907858455, 'validation/loss': 0.130526595505618, 'validation/num_examples': 89000000, 'test/loss': 0.13416434277968556, 'test/num_examples': 89274637, 'score': 147.43547773361206, 'total_duration': 1402.5595650672913, 'accumulated_submission_time': 147.43547773361206, 'accumulated_eval_time': 1255.092710018158, 'accumulated_logging_time': 0.028232097625732422, 'global_step': 192, 'preemption_count': 0}), (394, {'train/loss': 0.12675405390122357, 'validation/loss': 0.12772308988764045, 'validation/num_examples': 89000000, 'test/loss': 0.13097697613713064, 'test/num_examples': 89274637, 'score': 267.7472767829895, 'total_duration': 2027.5343923568726, 'accumulated_submission_time': 267.7472767829895, 'accumulated_eval_time': 1759.7316937446594, 'accumulated_logging_time': 0.049050331115722656, 'global_step': 394, 'preemption_count': 0}), (588, {'train/loss': 0.1267589905682732, 'validation/loss': 0.12751584269662922, 'validation/num_examples': 89000000, 'test/loss': 0.13062511808365013, 'test/num_examples': 89274637, 'score': 388.1992325782776, 'total_duration': 2642.6653311252594, 'accumulated_submission_time': 388.1992325782776, 'accumulated_eval_time': 2254.3830287456512, 'accumulated_logging_time': 0.07369256019592285, 'global_step': 588, 'preemption_count': 0}), (782, {'train/loss': 0.1229856154497932, 'validation/loss': 0.12617901123595507, 'validation/num_examples': 89000000, 'test/loss': 0.12937978118017998, 'test/num_examples': 89274637, 'score': 508.64723539352417, 'total_duration': 3228.917628288269, 'accumulated_submission_time': 508.64723539352417, 'accumulated_eval_time': 2720.157458305359, 'accumulated_logging_time': 0.10049295425415039, 'global_step': 782, 'preemption_count': 0}), (800, {'train/loss': 0.12498531341552735, 'validation/loss': 0.12630567415730337, 'validation/num_examples': 89000000, 'test/loss': 0.12956448089506092, 'test/num_examples': 89274637, 'score': 510.29617285728455, 'total_duration': 3646.3296854496, 'accumulated_submission_time': 510.29617285728455, 'accumulated_eval_time': 3135.8949489593506, 'accumulated_logging_time': 0.12549948692321777, 'global_step': 800, 'preemption_count': 0})], 'global_step': 800}
I0808 06:03:12.920914 139701833172800 submission_runner.py:533] Timing: 510.29617285728455
I0808 06:03:12.921023 139701833172800 submission_runner.py:535] Total number of evals: 6
I0808 06:03:12.921107 139701833172800 submission_runner.py:536] ====================
I0808 06:03:12.921305 139701833172800 submission_runner.py:604] Final criteo1tb score: 510.29617285728455
