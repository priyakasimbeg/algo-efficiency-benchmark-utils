torchrun --redirects 1:0,2:0,3:0,4:0,5:0,6:0,7:0 --standalone --nnodes=1 --nproc_per_node=8 submission_runner.py --framework=pytorch --workload=wmt --submission_path=baselines/adamw/pytorch/submission.py --tuning_search_space=baselines/adamw/tuning_search_space.json --data_dir=/data/wmt --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=test_today/adamw --overwrite=True --save_checkpoints=False --max_global_steps=10 2>&1 | tee -a /logs/wmt_pytorch_06-29-2023-21-27-41.log
master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-06-29 21:27:45.954032: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 21:27:45.954029: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 21:27:45.954029: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 21:27:45.961261: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 21:27:45.961961: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 21:27:45.981082: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 21:27:45.981160: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 21:27:45.999527: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0629 21:27:58.706424 140142181488448 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 6
I0629 21:27:58.706500 139648717702976 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 5
I0629 21:27:59.669019 140135220025152 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
I0629 21:27:59.669516 140198359578432 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 7
I0629 21:27:59.680848 139702015969088 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 4
I0629 21:27:59.681087 140406466914112 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
I0629 21:27:59.682017 140093220095808 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
I0629 21:27:59.682610 140683775735616 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
I0629 21:27:59.682969 140683775735616 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 21:27:59.690067 140135220025152 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 21:27:59.690329 140198359578432 distributed_c10d.py:476] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 21:27:59.691481 139702015969088 distributed_c10d.py:476] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 21:27:59.691456 140142181488448 distributed_c10d.py:476] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 21:27:59.691660 140406466914112 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 21:27:59.691629 139648717702976 distributed_c10d.py:476] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 21:27:59.692668 140093220095808 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 21:28:03.492698 140683775735616 logger_utils.py:61] Removing existing experiment directory /experiment_runs/test_today/adamw/wmt_pytorch because --overwrite was set.
I0629 21:28:03.505421 140683775735616 logger_utils.py:76] Creating experiment directory at /experiment_runs/test_today/adamw/wmt_pytorch.
W0629 21:28:03.518787 139702015969088 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0629 21:28:03.519923 140135220025152 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0629 21:28:03.520845 140406466914112 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0629 21:28:03.522016 140093220095808 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0629 21:28:03.522167 140198359578432 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0629 21:28:03.524725 140142181488448 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0629 21:28:03.531902 140683775735616 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0629 21:28:03.536558 140683775735616 submission_runner.py:547] Using RNG seed 2868289206
I0629 21:28:03.537915 140683775735616 submission_runner.py:556] --- Tuning run 1/1 ---
I0629 21:28:03.538034 140683775735616 submission_runner.py:561] Creating tuning directory at /experiment_runs/test_today/adamw/wmt_pytorch/trial_1.
I0629 21:28:03.538352 140683775735616 logger_utils.py:92] Saving hparams to /experiment_runs/test_today/adamw/wmt_pytorch/trial_1/hparams.json.
I0629 21:28:03.539192 140683775735616 submission_runner.py:249] Initializing dataset.
I0629 21:28:03.539309 140683775735616 submission_runner.py:256] Initializing model.
W0629 21:28:03.665427 139648717702976 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0629 21:28:06.984770 140683775735616 submission_runner.py:268] Initializing optimizer.
I0629 21:28:06.986005 140683775735616 submission_runner.py:275] Initializing metrics bundle.
I0629 21:28:06.986113 140683775735616 submission_runner.py:292] Initializing checkpoint and logger.
I0629 21:28:06.986811 140683775735616 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0629 21:28:06.986911 140683775735616 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0629 21:28:07.553819 140683775735616 submission_runner.py:313] Saving meta data to /experiment_runs/test_today/adamw/wmt_pytorch/trial_1/meta_data_0.json.
I0629 21:28:07.554747 140683775735616 submission_runner.py:316] Saving flags to /experiment_runs/test_today/adamw/wmt_pytorch/trial_1/flags_0.json.
I0629 21:28:07.598992 140683775735616 submission_runner.py:328] Starting training loop.
I0629 21:28:07.612508 140683775735616 dataset_info.py:578] Load dataset info from /data/wmt/wmt17_translate/de-en/1.0.0
I0629 21:28:07.616627 140683775735616 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0629 21:28:07.674261 140683775735616 logging_logger.py:49] Constructing tf.data.Dataset wmt17_translate for split train, from /data/wmt/wmt17_translate/de-en/1.0.0
I0629 21:28:11.436076 140636950882048 logging_writer.py:48] [0] global_step=0, grad_norm=5.532185, loss=11.124224
I0629 21:28:11.445611 140683775735616 submission.py:119] 0) loss = 11.124, grad_norm = 5.532
I0629 21:28:11.446878 140683775735616 spec.py:298] Evaluating on the training split.
I0629 21:28:11.449219 140683775735616 dataset_info.py:578] Load dataset info from /data/wmt/wmt17_translate/de-en/1.0.0
I0629 21:28:11.452287 140683775735616 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0629 21:28:11.487692 140683775735616 logging_logger.py:49] Constructing tf.data.Dataset wmt17_translate for split train, from /data/wmt/wmt17_translate/de-en/1.0.0
I0629 21:28:15.666134 140683775735616 workload.py:131] Translating evaluation dataset.
I0629 21:32:57.981309 140683775735616 spec.py:310] Evaluating on the validation split.
I0629 21:32:57.984060 140683775735616 dataset_info.py:578] Load dataset info from /data/wmt/wmt14_translate/de-en/1.0.0
I0629 21:32:57.987798 140683775735616 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0629 21:32:58.022285 140683775735616 logging_logger.py:49] Constructing tf.data.Dataset wmt14_translate for split validation, from /data/wmt/wmt14_translate/de-en/1.0.0
I0629 21:33:01.857350 140683775735616 workload.py:131] Translating evaluation dataset.
I0629 21:37:38.369565 140683775735616 spec.py:326] Evaluating on the test split.
I0629 21:37:38.372269 140683775735616 dataset_info.py:578] Load dataset info from /data/wmt/wmt14_translate/de-en/1.0.0
I0629 21:37:38.376227 140683775735616 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0629 21:37:38.410382 140683775735616 logging_logger.py:49] Constructing tf.data.Dataset wmt14_translate for split test, from /data/wmt/wmt14_translate/de-en/1.0.0
I0629 21:37:42.332346 140683775735616 workload.py:131] Translating evaluation dataset.
I0629 21:42:24.476458 140683775735616 submission_runner.py:424] Time since start: 856.88s, 	Step: 1, 	{'train/accuracy': 0.0006308352258390108, 'train/loss': 11.125226527194734, 'train/bleu': 0.0, 'validation/accuracy': 0.00048356498989473163, 'validation/loss': 11.138046180456534, 'validation/bleu': 0.0, 'validation/num_examples': 3000, 'test/accuracy': 0.0007088489919237697, 'test/loss': 11.145620533379816, 'test/bleu': 0.0, 'test/num_examples': 3003, 'score': 3.8471384048461914, 'total_duration': 856.8780343532562, 'accumulated_submission_time': 3.8471384048461914, 'accumulated_eval_time': 853.0294759273529, 'accumulated_logging_time': 0}
I0629 21:42:24.484775 140625893525248 logging_writer.py:48] [1] accumulated_eval_time=853.029476, accumulated_logging_time=0, accumulated_submission_time=3.847138, global_step=1, preemption_count=0, score=3.847138, test/accuracy=0.000709, test/bleu=0.000000, test/loss=11.145621, test/num_examples=3003, total_duration=856.878034, train/accuracy=0.000631, train/bleu=0.000000, train/loss=11.125227, validation/accuracy=0.000484, validation/bleu=0.000000, validation/loss=11.138046, validation/num_examples=3000
I0629 21:42:24.502908 140683775735616 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 21:42:24.502918 140135220025152 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 21:42:24.502933 140406466914112 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 21:42:24.502971 140142181488448 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 21:42:24.503010 140093220095808 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 21:42:24.503253 139702015969088 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 21:42:24.503267 140198359578432 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 21:42:24.503305 139648717702976 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 21:42:24.928614 140625885132544 logging_writer.py:48] [1] global_step=1, grad_norm=5.457439, loss=11.115674
I0629 21:42:24.932863 140683775735616 submission.py:119] 1) loss = 11.116, grad_norm = 5.457
I0629 21:42:25.363810 140625893525248 logging_writer.py:48] [2] global_step=2, grad_norm=5.477408, loss=11.113034
I0629 21:42:25.367598 140683775735616 submission.py:119] 2) loss = 11.113, grad_norm = 5.477
I0629 21:42:25.799788 140625885132544 logging_writer.py:48] [3] global_step=3, grad_norm=5.445150, loss=11.101536
I0629 21:42:25.803566 140683775735616 submission.py:119] 3) loss = 11.102, grad_norm = 5.445
I0629 21:42:26.235624 140625893525248 logging_writer.py:48] [4] global_step=4, grad_norm=5.392638, loss=11.072922
I0629 21:42:26.239324 140683775735616 submission.py:119] 4) loss = 11.073, grad_norm = 5.393
I0629 21:42:26.672072 140625885132544 logging_writer.py:48] [5] global_step=5, grad_norm=5.307706, loss=11.026723
I0629 21:42:26.675862 140683775735616 submission.py:119] 5) loss = 11.027, grad_norm = 5.308
I0629 21:42:27.108369 140625893525248 logging_writer.py:48] [6] global_step=6, grad_norm=5.292266, loss=11.007998
I0629 21:42:27.112026 140683775735616 submission.py:119] 6) loss = 11.008, grad_norm = 5.292
I0629 21:42:27.548657 140625885132544 logging_writer.py:48] [7] global_step=7, grad_norm=5.122378, loss=10.962667
I0629 21:42:27.552415 140683775735616 submission.py:119] 7) loss = 10.963, grad_norm = 5.122
I0629 21:42:27.987381 140625893525248 logging_writer.py:48] [8] global_step=8, grad_norm=5.093190, loss=10.907427
I0629 21:42:27.990957 140683775735616 submission.py:119] 8) loss = 10.907, grad_norm = 5.093
I0629 21:42:28.424457 140625885132544 logging_writer.py:48] [9] global_step=9, grad_norm=4.927769, loss=10.849863
I0629 21:42:28.428043 140683775735616 submission.py:119] 9) loss = 10.850, grad_norm = 4.928
I0629 21:42:28.429464 140683775735616 spec.py:298] Evaluating on the training split.
I0629 21:42:32.236141 140683775735616 workload.py:131] Translating evaluation dataset.
I0629 21:47:14.282180 140683775735616 spec.py:310] Evaluating on the validation split.
I0629 21:47:18.023408 140683775735616 workload.py:131] Translating evaluation dataset.
I0629 21:51:54.264081 140683775735616 spec.py:326] Evaluating on the test split.
I0629 21:51:58.075292 140683775735616 workload.py:131] Translating evaluation dataset.
I0629 21:56:40.689071 140683775735616 submission_runner.py:424] Time since start: 1713.09s, 	Step: 10, 	{'train/accuracy': 0.0005826374053214216, 'train/loss': 10.756387590965693, 'train/bleu': 0.0, 'validation/accuracy': 0.00048356498989473163, 'validation/loss': 10.77986788756494, 'validation/bleu': 0.0, 'validation/num_examples': 3000, 'test/accuracy': 0.0007088489919237697, 'test/loss': 10.80077566672477, 'test/bleu': 0.0, 'test/num_examples': 3003, 'score': 7.7774553298950195, 'total_duration': 1713.0906653404236, 'accumulated_submission_time': 7.7774553298950195, 'accumulated_eval_time': 1705.2890164852142, 'accumulated_logging_time': 0.019092798233032227}
I0629 21:56:40.696765 140625893525248 logging_writer.py:48] [10] accumulated_eval_time=1705.289016, accumulated_logging_time=0.019093, accumulated_submission_time=7.777455, global_step=10, preemption_count=0, score=7.777455, test/accuracy=0.000709, test/bleu=0.000000, test/loss=10.800776, test/num_examples=3003, total_duration=1713.090665, train/accuracy=0.000583, train/bleu=0.000000, train/loss=10.756388, validation/accuracy=0.000484, validation/bleu=0.000000, validation/loss=10.779868, validation/num_examples=3000
I0629 21:56:40.714531 140625885132544 logging_writer.py:48] [10] global_step=10, preemption_count=0, score=7.777455
I0629 21:56:43.009969 140683775735616 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/test_today/adamw/wmt_pytorch/trial_1/checkpoint_10.
I0629 21:56:43.031306 140683775735616 submission_runner.py:587] Tuning trial 1/1
I0629 21:56:43.031502 140683775735616 submission_runner.py:588] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0629 21:56:43.031944 140683775735616 submission_runner.py:589] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0006308352258390108, 'train/loss': 11.125226527194734, 'train/bleu': 0.0, 'validation/accuracy': 0.00048356498989473163, 'validation/loss': 11.138046180456534, 'validation/bleu': 0.0, 'validation/num_examples': 3000, 'test/accuracy': 0.0007088489919237697, 'test/loss': 11.145620533379816, 'test/bleu': 0.0, 'test/num_examples': 3003, 'score': 3.8471384048461914, 'total_duration': 856.8780343532562, 'accumulated_submission_time': 3.8471384048461914, 'accumulated_eval_time': 853.0294759273529, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (10, {'train/accuracy': 0.0005826374053214216, 'train/loss': 10.756387590965693, 'train/bleu': 0.0, 'validation/accuracy': 0.00048356498989473163, 'validation/loss': 10.77986788756494, 'validation/bleu': 0.0, 'validation/num_examples': 3000, 'test/accuracy': 0.0007088489919237697, 'test/loss': 10.80077566672477, 'test/bleu': 0.0, 'test/num_examples': 3003, 'score': 7.7774553298950195, 'total_duration': 1713.0906653404236, 'accumulated_submission_time': 7.7774553298950195, 'accumulated_eval_time': 1705.2890164852142, 'accumulated_logging_time': 0.019092798233032227, 'global_step': 10, 'preemption_count': 0})], 'global_step': 10}
I0629 21:56:43.032095 140683775735616 submission_runner.py:590] Timing: 7.7774553298950195
I0629 21:56:43.032155 140683775735616 submission_runner.py:591] ====================
I0629 21:56:43.032259 140683775735616 submission_runner.py:659] Final wmt score: 7.7774553298950195
