torchrun --redirects 1:0,2:0,3:0,4:0,5:0,6:0,7:0 --standalone --nnodes=1 --nproc_per_node=8 submission_runner.py --framework=pytorch --workload=librispeech_deepspeech --submission_path=baselines/adamw/pytorch/submission.py --tuning_search_space=baselines/adamw/tuning_search_space.json --data_dir=/data/librispeech --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=test_today/adamw --overwrite=True --save_checkpoints=False --max_global_steps=10 --librispeech_tokenizer_vocab_path=/data/librispeech/spm_model.vocab 2>&1 | tee -a /logs/librispeech_deepspeech_pytorch_06-29-2023-20-39-54.log
master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-06-29 20:39:59.352509: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 20:39:59.352508: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 20:39:59.352509: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 20:39:59.352508: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 20:39:59.352508: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 20:39:59.352510: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 20:39:59.352508: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 20:39:59.352509: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0629 20:40:12.270689 140444228691776 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
I0629 20:40:12.270711 139813895567168 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 5
I0629 20:40:12.271642 139700014761792 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 6
I0629 20:40:12.271735 139895918839616 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
I0629 20:40:12.271787 139647207237440 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 4
I0629 20:40:12.271963 139706846455616 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 7
I0629 20:40:12.272135 140322078975808 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
I0629 20:40:12.282192 139700014761792 distributed_c10d.py:476] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 20:40:12.282165 140053555898176 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
I0629 20:40:12.282284 139647207237440 distributed_c10d.py:476] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 20:40:12.282309 139895918839616 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 20:40:12.282453 140053555898176 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 20:40:12.282495 139706846455616 distributed_c10d.py:476] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 20:40:12.282646 140322078975808 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 20:40:12.291670 140444228691776 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 20:40:12.291727 139813895567168 distributed_c10d.py:476] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 20:40:12.621455 140053555898176 logger_utils.py:61] Removing existing experiment directory /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch because --overwrite was set.
W0629 20:40:12.623952 139813895567168 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0629 20:40:12.624880 139647207237440 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0629 20:40:12.624979 140322078975808 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0629 20:40:12.625117 139700014761792 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0629 20:40:12.625539 140444228691776 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0629 20:40:12.625880 139895918839616 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0629 20:40:12.625801 139706846455616 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0629 20:40:12.631712 140053555898176 logger_utils.py:76] Creating experiment directory at /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch.
W0629 20:40:12.661960 140053555898176 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0629 20:40:12.667356 140053555898176 submission_runner.py:547] Using RNG seed 3987838435
I0629 20:40:12.669017 140053555898176 submission_runner.py:556] --- Tuning run 1/1 ---
I0629 20:40:12.669169 140053555898176 submission_runner.py:561] Creating tuning directory at /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch/trial_1.
I0629 20:40:12.669578 140053555898176 logger_utils.py:92] Saving hparams to /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch/trial_1/hparams.json.
I0629 20:40:12.670510 140053555898176 submission_runner.py:249] Initializing dataset.
I0629 20:40:12.670652 140053555898176 input_pipeline.py:20] Loading split = train-clean-100
I0629 20:40:12.705819 140053555898176 input_pipeline.py:20] Loading split = train-clean-360
I0629 20:40:13.149511 140053555898176 input_pipeline.py:20] Loading split = train-other-500
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
I0629 20:40:13.699544 140053555898176 submission_runner.py:256] Initializing model.
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
I0629 20:40:21.251205 140053555898176 submission_runner.py:268] Initializing optimizer.
I0629 20:40:21.252351 140053555898176 submission_runner.py:275] Initializing metrics bundle.
I0629 20:40:21.252519 140053555898176 submission_runner.py:292] Initializing checkpoint and logger.
I0629 20:40:21.253489 140053555898176 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0629 20:40:21.253672 140053555898176 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0629 20:40:22.063672 140053555898176 submission_runner.py:313] Saving meta data to /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch/trial_1/meta_data_0.json.
I0629 20:40:22.064803 140053555898176 submission_runner.py:316] Saving flags to /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch/trial_1/flags_0.json.
I0629 20:40:22.073045 140053555898176 submission_runner.py:328] Starting training loop.
I0629 20:40:52.598845 140028130875136 logging_writer.py:48] [0] global_step=0, grad_norm=24.075642, loss=33.392735
I0629 20:40:52.617459 140053555898176 submission.py:119] 0) loss = 33.393, grad_norm = 24.076
I0629 20:40:52.619463 140053555898176 spec.py:298] Evaluating on the training split.
I0629 20:40:52.620754 140053555898176 input_pipeline.py:20] Loading split = train-clean-100
I0629 20:40:52.660320 140053555898176 input_pipeline.py:20] Loading split = train-clean-360
I0629 20:40:53.147890 140053555898176 input_pipeline.py:20] Loading split = train-other-500
I0629 20:41:10.056374 140053555898176 spec.py:310] Evaluating on the validation split.
I0629 20:41:10.057698 140053555898176 input_pipeline.py:20] Loading split = dev-clean
I0629 20:41:10.061103 140053555898176 input_pipeline.py:20] Loading split = dev-other
I0629 20:41:23.236824 140053555898176 spec.py:326] Evaluating on the test split.
I0629 20:41:23.238177 140053555898176 input_pipeline.py:20] Loading split = test-clean
I0629 20:41:31.139699 140053555898176 submission_runner.py:424] Time since start: 69.07s, 	Step: 1, 	{'train/ctc_loss': 31.424796323733204, 'train/wer': 2.0980049711476343, 'validation/ctc_loss': 30.144338959212376, 'validation/wer': 1.9123159368512528, 'validation/num_examples': 5348, 'test/ctc_loss': 30.152758242467257, 'test/wer': 2.0945504031848556, 'test/num_examples': 2472, 'score': 30.544936656951904, 'total_duration': 69.06652879714966, 'accumulated_submission_time': 30.544936656951904, 'accumulated_eval_time': 38.51952624320984, 'accumulated_logging_time': 0}
I0629 20:41:31.152242 140025110959872 logging_writer.py:48] [1] accumulated_eval_time=38.519526, accumulated_logging_time=0, accumulated_submission_time=30.544937, global_step=1, preemption_count=0, score=30.544937, test/ctc_loss=30.152758, test/num_examples=2472, test/wer=2.094550, total_duration=69.066529, train/ctc_loss=31.424796, train/wer=2.098005, validation/ctc_loss=30.144339, validation/num_examples=5348, validation/wer=1.912316
I0629 20:41:31.193550 140053555898176 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 20:41:31.194101 140444228691776 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 20:41:31.194194 139895918839616 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 20:41:31.195159 139700014761792 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 20:41:31.195264 139813895567168 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 20:41:31.196255 139647207237440 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 20:41:31.196988 139706846455616 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 20:41:31.197694 140322078975808 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 20:41:32.361512 140025027098368 logging_writer.py:48] [1] global_step=1, grad_norm=22.622040, loss=32.765327
I0629 20:41:32.364980 140053555898176 submission.py:119] 1) loss = 32.765, grad_norm = 22.622
I0629 20:41:33.636453 140025110959872 logging_writer.py:48] [2] global_step=2, grad_norm=23.010323, loss=33.297340
I0629 20:41:33.640224 140053555898176 submission.py:119] 2) loss = 33.297, grad_norm = 23.010
I0629 20:41:34.639810 140025027098368 logging_writer.py:48] [3] global_step=3, grad_norm=24.156305, loss=33.384922
I0629 20:41:34.643271 140053555898176 submission.py:119] 3) loss = 33.385, grad_norm = 24.156
I0629 20:41:35.544894 140025110959872 logging_writer.py:48] [4] global_step=4, grad_norm=24.352406, loss=32.854393
I0629 20:41:35.548011 140053555898176 submission.py:119] 4) loss = 32.854, grad_norm = 24.352
I0629 20:41:36.453482 140025027098368 logging_writer.py:48] [5] global_step=5, grad_norm=26.470955, loss=33.167889
I0629 20:41:36.456792 140053555898176 submission.py:119] 5) loss = 33.168, grad_norm = 26.471
I0629 20:41:37.363814 140025110959872 logging_writer.py:48] [6] global_step=6, grad_norm=26.911572, loss=33.281620
I0629 20:41:37.367173 140053555898176 submission.py:119] 6) loss = 33.282, grad_norm = 26.912
I0629 20:41:38.268465 140025027098368 logging_writer.py:48] [7] global_step=7, grad_norm=27.391644, loss=32.251537
I0629 20:41:38.271991 140053555898176 submission.py:119] 7) loss = 32.252, grad_norm = 27.392
I0629 20:41:39.173843 140025110959872 logging_writer.py:48] [8] global_step=8, grad_norm=31.122305, loss=32.654709
I0629 20:41:39.177254 140053555898176 submission.py:119] 8) loss = 32.655, grad_norm = 31.122
I0629 20:41:40.086248 140025027098368 logging_writer.py:48] [9] global_step=9, grad_norm=30.481562, loss=32.229839
I0629 20:41:40.089623 140053555898176 submission.py:119] 9) loss = 32.230, grad_norm = 30.482
I0629 20:41:40.091059 140053555898176 spec.py:298] Evaluating on the training split.
I0629 20:41:55.503158 140053555898176 spec.py:310] Evaluating on the validation split.
I0629 20:42:07.102621 140053555898176 spec.py:326] Evaluating on the test split.
I0629 20:42:13.169282 140053555898176 submission_runner.py:424] Time since start: 111.10s, 	Step: 10, 	{'train/ctc_loss': 31.236107071612608, 'train/wer': 2.3504275843945384, 'validation/ctc_loss': 29.929048623668876, 'validation/wer': 2.1388210302708446, 'validation/num_examples': 5348, 'test/ctc_loss': 29.904451900122588, 'test/wer': 2.313712347409258, 'test/num_examples': 2472, 'score': 39.47049164772034, 'total_duration': 111.09661078453064, 'accumulated_submission_time': 39.47049164772034, 'accumulated_eval_time': 71.59738969802856, 'accumulated_logging_time': 0.02163553237915039}
I0629 20:42:13.182825 140025110959872 logging_writer.py:48] [10] accumulated_eval_time=71.597390, accumulated_logging_time=0.021636, accumulated_submission_time=39.470492, global_step=10, preemption_count=0, score=39.470492, test/ctc_loss=29.904452, test/num_examples=2472, test/wer=2.313712, total_duration=111.096611, train/ctc_loss=31.236107, train/wer=2.350428, validation/ctc_loss=29.929049, validation/num_examples=5348, validation/wer=2.138821
I0629 20:42:13.199224 140025027098368 logging_writer.py:48] [10] global_step=10, preemption_count=0, score=39.470492
I0629 20:42:13.586368 140053555898176 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch/trial_1/checkpoint_10.
I0629 20:42:13.704267 140053555898176 submission_runner.py:587] Tuning trial 1/1
I0629 20:42:13.704472 140053555898176 submission_runner.py:588] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0629 20:42:13.704880 140053555898176 submission_runner.py:589] Metrics: {'eval_results': [(1, {'train/ctc_loss': 31.424796323733204, 'train/wer': 2.0980049711476343, 'validation/ctc_loss': 30.144338959212376, 'validation/wer': 1.9123159368512528, 'validation/num_examples': 5348, 'test/ctc_loss': 30.152758242467257, 'test/wer': 2.0945504031848556, 'test/num_examples': 2472, 'score': 30.544936656951904, 'total_duration': 69.06652879714966, 'accumulated_submission_time': 30.544936656951904, 'accumulated_eval_time': 38.51952624320984, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (10, {'train/ctc_loss': 31.236107071612608, 'train/wer': 2.3504275843945384, 'validation/ctc_loss': 29.929048623668876, 'validation/wer': 2.1388210302708446, 'validation/num_examples': 5348, 'test/ctc_loss': 29.904451900122588, 'test/wer': 2.313712347409258, 'test/num_examples': 2472, 'score': 39.47049164772034, 'total_duration': 111.09661078453064, 'accumulated_submission_time': 39.47049164772034, 'accumulated_eval_time': 71.59738969802856, 'accumulated_logging_time': 0.02163553237915039, 'global_step': 10, 'preemption_count': 0})], 'global_step': 10}
I0629 20:42:13.704963 140053555898176 submission_runner.py:590] Timing: 39.47049164772034
I0629 20:42:13.705019 140053555898176 submission_runner.py:591] ====================
I0629 20:42:13.705170 140053555898176 submission_runner.py:659] Final librispeech_deepspeech score: 39.47049164772034
