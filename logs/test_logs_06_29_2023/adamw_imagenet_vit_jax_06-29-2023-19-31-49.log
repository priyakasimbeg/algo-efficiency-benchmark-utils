python3 submission_runner.py --framework=jax --workload=imagenet_vit --submission_path=baselines/adamw/jax/submission.py --tuning_search_space=baselines/adamw/tuning_search_space.json --data_dir=/data/imagenet/jax --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=test_today/adamw --overwrite=True --save_checkpoints=False --max_global_steps=10 --imagenet_v2_data_dir=/data/imagenet/jax 2>&1 | tee -a /logs/imagenet_vit_jax_06-29-2023-19-31-49.log
2023-06-29 19:31:51.665427: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
I0629 19:32:05.744894 140623450134336 logger_utils.py:61] Removing existing experiment directory /experiment_runs/test_today/adamw/imagenet_vit_jax because --overwrite was set.
I0629 19:32:05.745710 140623450134336 logger_utils.py:76] Creating experiment directory at /experiment_runs/test_today/adamw/imagenet_vit_jax.
I0629 19:32:06.581553 140623450134336 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0629 19:32:06.582348 140623450134336 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0629 19:32:06.582484 140623450134336 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0629 19:32:06.587197 140623450134336 submission_runner.py:547] Using RNG seed 2546692652
I0629 19:32:08.787272 140623450134336 submission_runner.py:556] --- Tuning run 1/1 ---
I0629 19:32:08.787463 140623450134336 submission_runner.py:561] Creating tuning directory at /experiment_runs/test_today/adamw/imagenet_vit_jax/trial_1.
I0629 19:32:08.787702 140623450134336 logger_utils.py:92] Saving hparams to /experiment_runs/test_today/adamw/imagenet_vit_jax/trial_1/hparams.json.
I0629 19:32:08.968576 140623450134336 submission_runner.py:249] Initializing dataset.
I0629 19:32:08.984596 140623450134336 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0629 19:32:08.995193 140623450134336 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0629 19:32:09.307410 140623450134336 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0629 19:32:17.155540 140623450134336 submission_runner.py:256] Initializing model.
I0629 19:32:25.822810 140623450134336 submission_runner.py:268] Initializing optimizer.
I0629 19:32:26.787843 140623450134336 submission_runner.py:275] Initializing metrics bundle.
I0629 19:32:26.788053 140623450134336 submission_runner.py:292] Initializing checkpoint and logger.
I0629 19:32:26.789129 140623450134336 checkpoints.py:915] Found no checkpoint files in /experiment_runs/test_today/adamw/imagenet_vit_jax/trial_1 with prefix checkpoint_
I0629 19:32:27.895514 140623450134336 submission_runner.py:313] Saving meta data to /experiment_runs/test_today/adamw/imagenet_vit_jax/trial_1/meta_data_0.json.
I0629 19:32:27.897577 140623450134336 submission_runner.py:316] Saving flags to /experiment_runs/test_today/adamw/imagenet_vit_jax/trial_1/flags_0.json.
I0629 19:32:27.904449 140623450134336 submission_runner.py:328] Starting training loop.
2023-06-29 19:33:14.304300: E external/xla/xla/service/rendezvous.cc:31] This thread has been waiting for 10 seconds and may be stuck:
2023-06-29 19:33:16.671825: E external/xla/xla/service/rendezvous.cc:36] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.
I0629 19:33:18.210442 140459145946880 logging_writer.py:48] [0] global_step=0, grad_norm=0.32575300335884094, loss=6.907756805419922
I0629 19:33:18.225633 140623450134336 spec.py:298] Evaluating on the training split.
I0629 19:33:18.234280 140623450134336 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0629 19:33:18.243686 140623450134336 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0629 19:33:18.328153 140623450134336 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0629 19:33:36.184324 140623450134336 spec.py:310] Evaluating on the validation split.
I0629 19:33:36.192959 140623450134336 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0629 19:33:36.208725 140623450134336 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0629 19:33:36.285796 140623450134336 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0629 19:33:54.076637 140623450134336 spec.py:326] Evaluating on the test split.
I0629 19:33:54.082933 140623450134336 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0629 19:33:54.089298 140623450134336 dataset_builder.py:528] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0629 19:33:54.134634 140623450134336 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0629 19:34:03.400827 140623450134336 submission_runner.py:424] Time since start: 95.50s, 	Step: 1, 	{'train/accuracy': 0.001015624962747097, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 50.32102918624878, 'total_duration': 95.49631834030151, 'accumulated_submission_time': 50.32102918624878, 'accumulated_eval_time': 45.17514777183533, 'accumulated_logging_time': 0}
I0629 19:34:03.408339 140416213042944 logging_writer.py:48] [1] accumulated_eval_time=45.175148, accumulated_logging_time=0, accumulated_submission_time=50.321029, global_step=1, preemption_count=0, score=50.321029, test/accuracy=0.001000, test/loss=6.907757, test/num_examples=10000, total_duration=95.496318, train/accuracy=0.001016, train/loss=6.907756, validation/accuracy=0.001000, validation/loss=6.907756, validation/num_examples=50000
I0629 19:34:27.878791 140623450134336 spec.py:298] Evaluating on the training split.
I0629 19:34:35.334677 140623450134336 spec.py:310] Evaluating on the validation split.
I0629 19:34:45.111040 140623450134336 spec.py:326] Evaluating on the test split.
I0629 19:34:46.701317 140623450134336 submission_runner.py:424] Time since start: 138.80s, 	Step: 10, 	{'train/accuracy': 0.0016406249487772584, 'train/loss': 6.907711029052734, 'validation/accuracy': 0.0011999999405816197, 'validation/loss': 6.907718181610107, 'validation/num_examples': 50000, 'test/accuracy': 0.0014000000664964318, 'test/loss': 6.9077277183532715, 'test/num_examples': 10000, 'score': 74.78117108345032, 'total_duration': 138.79678535461426, 'accumulated_submission_time': 74.78117108345032, 'accumulated_eval_time': 63.997660636901855, 'accumulated_logging_time': 0.017348766326904297}
I0629 19:34:46.710144 140416322082560 logging_writer.py:48] [10] accumulated_eval_time=63.997661, accumulated_logging_time=0.017349, accumulated_submission_time=74.781171, global_step=10, preemption_count=0, score=74.781171, test/accuracy=0.001400, test/loss=6.907728, test/num_examples=10000, total_duration=138.796785, train/accuracy=0.001641, train/loss=6.907711, validation/accuracy=0.001200, validation/loss=6.907718, validation/num_examples=50000
I0629 19:34:46.727218 140416330475264 logging_writer.py:48] [10] global_step=10, preemption_count=0, score=74.781171
I0629 19:34:47.396019 140623450134336 checkpoints.py:490] Saving checkpoint at step: 10
I0629 19:34:48.349467 140623450134336 checkpoints.py:422] Saved checkpoint at /experiment_runs/test_today/adamw/imagenet_vit_jax/trial_1/checkpoint_10
I0629 19:34:48.369065 140623450134336 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/test_today/adamw/imagenet_vit_jax/trial_1/checkpoint_10.
I0629 19:34:48.636446 140623450134336 submission_runner.py:587] Tuning trial 1/1
I0629 19:34:48.636680 140623450134336 submission_runner.py:588] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0629 19:34:48.638988 140623450134336 submission_runner.py:589] Metrics: {'eval_results': [(1, {'train/accuracy': 0.001015624962747097, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 50.32102918624878, 'total_duration': 95.49631834030151, 'accumulated_submission_time': 50.32102918624878, 'accumulated_eval_time': 45.17514777183533, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (10, {'train/accuracy': 0.0016406249487772584, 'train/loss': 6.907711029052734, 'validation/accuracy': 0.0011999999405816197, 'validation/loss': 6.907718181610107, 'validation/num_examples': 50000, 'test/accuracy': 0.0014000000664964318, 'test/loss': 6.9077277183532715, 'test/num_examples': 10000, 'score': 74.78117108345032, 'total_duration': 138.79678535461426, 'accumulated_submission_time': 74.78117108345032, 'accumulated_eval_time': 63.997660636901855, 'accumulated_logging_time': 0.017348766326904297, 'global_step': 10, 'preemption_count': 0})], 'global_step': 10}
I0629 19:34:48.639179 140623450134336 submission_runner.py:590] Timing: 74.78117108345032
I0629 19:34:48.639250 140623450134336 submission_runner.py:591] ====================
I0629 19:34:48.639383 140623450134336 submission_runner.py:659] Final imagenet_vit score: 74.78117108345032
