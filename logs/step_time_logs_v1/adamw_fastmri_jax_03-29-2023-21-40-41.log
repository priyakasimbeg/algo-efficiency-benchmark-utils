I0329 21:41:00.413076 140691803780928 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_adamw/fastmri_jax.
I0329 21:41:00.788249 140691803780928 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0329 21:41:01.607363 140691803780928 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0329 21:41:01.608448 140691803780928 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0329 21:41:01.614879 140691803780928 submission_runner.py:504] Using RNG seed 2832731959
I0329 21:41:04.318181 140691803780928 submission_runner.py:513] --- Tuning run 1/1 ---
I0329 21:41:04.318376 140691803780928 submission_runner.py:518] Creating tuning directory at /experiment_runs/timing_adamw/fastmri_jax/trial_1.
I0329 21:41:04.318542 140691803780928 logger_utils.py:84] Saving hparams to /experiment_runs/timing_adamw/fastmri_jax/trial_1/hparams.json.
I0329 21:41:04.456623 140691803780928 submission_runner.py:230] Starting train once: RAM USED (GB) 4.591251456
I0329 21:41:04.456797 140691803780928 submission_runner.py:231] Initializing dataset.
I0329 21:41:09.412944 140691803780928 submission_runner.py:239] After Initializing dataset: RAM USED (GB) 4.67156992
I0329 21:41:09.413147 140691803780928 submission_runner.py:240] Initializing model.
I0329 21:41:16.663338 140691803780928 submission_runner.py:251] After Initializing model: RAM USED (GB) 8.605323264
I0329 21:41:16.663541 140691803780928 submission_runner.py:252] Initializing optimizer.
I0329 21:41:17.161060 140691803780928 submission_runner.py:260] After Initializing metrics bundle: RAM USED (GB) 8.60614656
I0329 21:41:17.161232 140691803780928 submission_runner.py:261] Initializing metrics bundle.
I0329 21:41:17.161286 140691803780928 submission_runner.py:275] Initializing checkpoint and logger.
I0329 21:41:17.162212 140691803780928 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_adamw/fastmri_jax/trial_1 with prefix checkpoint_
I0329 21:41:17.162469 140691803780928 logger_utils.py:231] Unable to record workload.train_mean information. Continuing without it.
I0329 21:41:17.162542 140691803780928 logger_utils.py:231] Unable to record workload.train_stddev information. Continuing without it.
I0329 21:41:18.002407 140691803780928 submission_runner.py:296] Saving meta data to /experiment_runs/timing_adamw/fastmri_jax/trial_1/meta_data_0.json.
I0329 21:41:18.003318 140691803780928 submission_runner.py:299] Saving flags to /experiment_runs/timing_adamw/fastmri_jax/trial_1/flags_0.json.
I0329 21:41:18.008144 140691803780928 submission_runner.py:304] After checkpoint and logger metrics bundle: RAM USED (GB) 8.603942912
I0329 21:41:18.008352 140691803780928 submission_runner.py:311] Before starting training loop and logger metrics bundle: RAM USED (GB) 8.603942912
I0329 21:41:18.008418 140691803780928 submission_runner.py:312] Starting training loop.
I0329 21:41:39.193976 140691803780928 submission_runner.py:333] After dataselection batch at step 0: RAM USED (GB) 17.901760512
I0329 21:42:05.517534 140515517392640 logging_writer.py:48] [0] global_step=0, grad_norm=5.443048000335693, loss=1.1712502241134644
I0329 21:42:05.525971 140691803780928 submission_runner.py:350] After update parameters step 0: RAM USED (GB) 23.490961408
I0329 21:42:05.526232 140691803780928 submission_runner.py:371] Before eval at step 1: RAM USED (GB) 23.490961408
I0329 21:42:05.526320 140691803780928 spec.py:298] Evaluating on the training split.
I0329 21:43:21.246951 140691803780928 spec.py:310] Evaluating on the validation split.
I0329 21:44:05.932479 140691803780928 spec.py:326] Evaluating on the test split.
I0329 21:44:47.009208 140691803780928 submission_runner.py:380] Time since start: 47.52s, 	Step: 1, 	{'train/ssim': 0.18695909636361258, 'train/loss': 1.1376170430864607, 'validation/ssim': 0.18305492669461346, 'validation/loss': 1.134646920723129, 'validation/num_examples': 3554, 'test/ssim': 0.20604732442055293, 'test/loss': 1.1313989250994834, 'test/num_examples': 3581}
I0329 21:44:47.009936 140691803780928 submission_runner.py:390] After eval at step 1: RAM USED (GB) 62.532214784
I0329 21:44:47.019302 140485192562432 logging_writer.py:48] [1] global_step=1, preemption_count=0, score=47.379359, test/loss=1.131399, test/num_examples=3581, test/ssim=0.206047, total_duration=47.517841, train/loss=1.137617, train/ssim=0.186959, validation/loss=1.134647, validation/num_examples=3554, validation/ssim=0.183055
I0329 21:44:47.058024 140691803780928 checkpoints.py:356] Saving checkpoint at step: 1
I0329 21:44:47.332900 140691803780928 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_1
I0329 21:44:47.333631 140691803780928 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_1.
I0329 21:44:47.334297 140691803780928 submission_runner.py:409] After logging and checkpointing eval at step 1: RAM USED (GB) 62.559555584
I0329 21:44:47.336506 140691803780928 submission_runner.py:333] After dataselection batch at step 1: RAM USED (GB) 62.559555584
I0329 21:44:47.352159 140691803780928 submission_runner.py:350] After update parameters step 1: RAM USED (GB) 62.610907136
I0329 21:45:09.349956 140485184169728 logging_writer.py:48] [100] global_step=100, grad_norm=0.2966567277908325, loss=0.25781673192977905
I0329 21:45:33.949406 140485075130112 logging_writer.py:48] [200] global_step=200, grad_norm=0.18935981392860413, loss=0.36452484130859375
I0329 21:45:58.739743 140485184169728 logging_writer.py:48] [300] global_step=300, grad_norm=0.11315018683671951, loss=0.3247791826725006
I0329 21:46:07.345566 140691803780928 submission_runner.py:371] Before eval at step 336: RAM USED (GB) 88.297787392
I0329 21:46:07.345835 140691803780928 spec.py:298] Evaluating on the training split.
I0329 21:46:09.212059 140691803780928 spec.py:310] Evaluating on the validation split.
I0329 21:46:16.124503 140691803780928 spec.py:326] Evaluating on the test split.
I0329 21:46:17.493984 140691803780928 submission_runner.py:380] Time since start: 289.34s, 	Step: 336, 	{'train/ssim': 0.6983460698808942, 'train/loss': 0.30655159269060406, 'validation/ssim': 0.678035257368458, 'validation/loss': 0.32860325183771805, 'validation/num_examples': 3554, 'test/ssim': 0.6963444901258378, 'test/loss': 0.33013975670203854, 'test/num_examples': 3581}
I0329 21:46:17.494542 140691803780928 submission_runner.py:390] After eval at step 336: RAM USED (GB) 89.37125888
I0329 21:46:17.502218 140485075130112 logging_writer.py:48] [336] global_step=336, preemption_count=0, score=126.911072, test/loss=0.330140, test/num_examples=3581, test/ssim=0.696344, total_duration=289.336718, train/loss=0.306552, train/ssim=0.698346, validation/loss=0.328603, validation/num_examples=3554, validation/ssim=0.678035
I0329 21:46:17.576064 140691803780928 checkpoints.py:356] Saving checkpoint at step: 336
I0329 21:46:17.863497 140691803780928 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_336
I0329 21:46:17.867993 140691803780928 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_336.
I0329 21:46:17.871005 140691803780928 submission_runner.py:409] After logging and checkpointing eval at step 336: RAM USED (GB) 89.417416704
I0329 21:46:31.493056 140485184169728 logging_writer.py:48] [400] global_step=400, grad_norm=0.37335383892059326, loss=0.3207673728466034
I0329 21:47:01.036825 140484957697792 logging_writer.py:48] [500] global_step=500, grad_norm=0.3632623553276062, loss=0.2040538787841797
I0329 21:47:34.356263 140485184169728 logging_writer.py:48] [600] global_step=600, grad_norm=0.2536156177520752, loss=0.3236437141895294
I0329 21:47:38.141727 140691803780928 submission_runner.py:371] Before eval at step 613: RAM USED (GB) 108.425662464
I0329 21:47:38.141985 140691803780928 spec.py:298] Evaluating on the training split.
I0329 21:47:39.562299 140691803780928 spec.py:310] Evaluating on the validation split.
I0329 21:47:44.056150 140691803780928 spec.py:326] Evaluating on the test split.
I0329 21:47:45.425056 140691803780928 submission_runner.py:380] Time since start: 380.13s, 	Step: 613, 	{'train/ssim': 0.7204161371503558, 'train/loss': 0.28668063027518137, 'validation/ssim': 0.7012174882175014, 'validation/loss': 0.3071809080657358, 'validation/num_examples': 3554, 'test/ssim': 0.7186241458827841, 'test/loss': 0.30937992917262985, 'test/num_examples': 3581}
I0329 21:47:45.426290 140691803780928 submission_runner.py:390] After eval at step 613: RAM USED (GB) 109.413445632
I0329 21:47:45.439961 140484957697792 logging_writer.py:48] [613] global_step=613, preemption_count=0, score=206.767033, test/loss=0.309380, test/num_examples=3581, test/ssim=0.718624, total_duration=380.132910, train/loss=0.286681, train/ssim=0.720416, validation/loss=0.307181, validation/num_examples=3554, validation/ssim=0.701217
I0329 21:47:45.526807 140691803780928 checkpoints.py:356] Saving checkpoint at step: 613
I0329 21:47:45.810835 140691803780928 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_613
I0329 21:47:45.814714 140691803780928 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_613.
I0329 21:47:45.816024 140691803780928 submission_runner.py:409] After logging and checkpointing eval at step 613: RAM USED (GB) 109.567348736
I0329 21:48:13.064454 140485184169728 logging_writer.py:48] [700] global_step=700, grad_norm=0.6841720342636108, loss=0.3033337891101837
I0329 21:48:48.381236 140482842564352 logging_writer.py:48] [800] global_step=800, grad_norm=0.2773264944553375, loss=0.3140742778778076
I0329 21:49:06.019483 140691803780928 submission_runner.py:371] Before eval at step 850: RAM USED (GB) 127.960887296
I0329 21:49:06.019690 140691803780928 spec.py:298] Evaluating on the training split.
I0329 21:49:07.440016 140691803780928 spec.py:310] Evaluating on the validation split.
I0329 21:49:09.861181 140691803780928 spec.py:326] Evaluating on the test split.
I0329 21:49:12.086593 140691803780928 submission_runner.py:380] Time since start: 468.01s, 	Step: 850, 	{'train/ssim': 0.7138806751796177, 'train/loss': 0.291689395904541, 'validation/ssim': 0.6957287206097004, 'validation/loss': 0.3116245559580754, 'validation/num_examples': 3554, 'test/ssim': 0.7130280009730173, 'test/loss': 0.31380626483524154, 'test/num_examples': 3581}
I0329 21:49:12.087015 140691803780928 submission_runner.py:390] After eval at step 850: RAM USED (GB) 128.815202304
I0329 21:49:12.097326 140485184169728 logging_writer.py:48] [850] global_step=850, preemption_count=0, score=286.637527, test/loss=0.313806, test/num_examples=3581, test/ssim=0.713028, total_duration=468.010819, train/loss=0.291689, train/ssim=0.713881, validation/loss=0.311625, validation/num_examples=3554, validation/ssim=0.695729
I0329 21:49:12.190239 140691803780928 checkpoints.py:356] Saving checkpoint at step: 850
I0329 21:49:12.497582 140691803780928 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_850
I0329 21:49:12.501280 140691803780928 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_850.
I0329 21:49:12.502207 140691803780928 submission_runner.py:409] After logging and checkpointing eval at step 850: RAM USED (GB) 128.971563008
I0329 21:49:27.451876 140482842564352 logging_writer.py:48] [900] global_step=900, grad_norm=0.10301914066076279, loss=0.3135797083377838
I0329 21:50:00.165045 140462151526144 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.2767176926136017, loss=0.2562682032585144
I0329 21:50:24.306011 140482842564352 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.1498851776123047, loss=0.2565072476863861
I0329 21:50:32.620644 140691803780928 submission_runner.py:371] Before eval at step 1136: RAM USED (GB) 140.22268928
I0329 21:50:32.620911 140691803780928 spec.py:298] Evaluating on the training split.
I0329 21:50:34.039209 140691803780928 spec.py:310] Evaluating on the validation split.
I0329 21:50:39.230436 140691803780928 spec.py:326] Evaluating on the test split.
I0329 21:50:40.601084 140691803780928 submission_runner.py:380] Time since start: 554.61s, 	Step: 1136, 	{'train/ssim': 0.7261298043387276, 'train/loss': 0.28099279744284494, 'validation/ssim': 0.7060704185644696, 'validation/loss': 0.3015038141992297, 'validation/num_examples': 3554, 'test/ssim': 0.723302428398143, 'test/loss': 0.3033138084464884, 'test/num_examples': 3581}
I0329 21:50:40.601827 140691803780928 submission_runner.py:390] After eval at step 1136: RAM USED (GB) 140.392235008
I0329 21:50:40.609719 140462151526144 logging_writer.py:48] [1136] global_step=1136, preemption_count=0, score=366.388057, test/loss=0.303314, test/num_examples=3581, test/ssim=0.723302, total_duration=554.611808, train/loss=0.280993, train/ssim=0.726130, validation/loss=0.301504, validation/num_examples=3554, validation/ssim=0.706070
I0329 21:50:40.677221 140691803780928 checkpoints.py:356] Saving checkpoint at step: 1136
I0329 21:50:40.968669 140691803780928 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_1136
I0329 21:50:40.973858 140691803780928 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_1136.
I0329 21:50:40.974602 140691803780928 submission_runner.py:409] After logging and checkpointing eval at step 1136: RAM USED (GB) 140.517388288
I0329 21:50:54.268052 140482842564352 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.48528048396110535, loss=0.2530251145362854
I0329 21:51:18.637569 140446996993792 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.22712840139865875, loss=0.3233839273452759
I0329 21:51:42.813538 140482842564352 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.6472266912460327, loss=0.3196885883808136
I0329 21:52:01.040613 140691803780928 submission_runner.py:371] Before eval at step 1477: RAM USED (GB) 140.473974784
I0329 21:52:01.040803 140691803780928 spec.py:298] Evaluating on the training split.
I0329 21:52:02.464366 140691803780928 spec.py:310] Evaluating on the validation split.
I0329 21:52:05.122932 140691803780928 spec.py:326] Evaluating on the test split.
I0329 21:52:06.492469 140691803780928 submission_runner.py:380] Time since start: 643.03s, 	Step: 1477, 	{'train/ssim': 0.7321757589067731, 'train/loss': 0.2760016747883388, 'validation/ssim': 0.7129165228659609, 'validation/loss': 0.2960274803148741, 'validation/num_examples': 3554, 'test/ssim': 0.7301089817570162, 'test/loss': 0.297689302045518, 'test/num_examples': 3581}
I0329 21:52:06.493151 140691803780928 submission_runner.py:390] After eval at step 1477: RAM USED (GB) 140.601696256
I0329 21:52:06.500985 140446996993792 logging_writer.py:48] [1477] global_step=1477, preemption_count=0, score=446.071416, test/loss=0.297689, test/num_examples=3581, test/ssim=0.730109, total_duration=643.031949, train/loss=0.276002, train/ssim=0.732176, validation/loss=0.296027, validation/num_examples=3554, validation/ssim=0.712917
I0329 21:52:06.537549 140691803780928 checkpoints.py:356] Saving checkpoint at step: 1477
I0329 21:52:06.790567 140691803780928 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_1477
I0329 21:52:06.791087 140691803780928 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_1477.
I0329 21:52:06.791924 140691803780928 submission_runner.py:409] After logging and checkpointing eval at step 1477: RAM USED (GB) 140.605059072
I0329 21:52:10.316251 140482842564352 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.15899443626403809, loss=0.32741910219192505
I0329 21:52:34.621646 140446495926016 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.3504030406475067, loss=0.2525688111782074
I0329 21:52:58.780963 140482842564352 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.09470076858997345, loss=0.33938223123550415
I0329 21:53:23.060818 140446495926016 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.2467617690563202, loss=0.2530761659145355
I0329 21:53:26.995572 140691803780928 submission_runner.py:371] Before eval at step 1818: RAM USED (GB) 140.509605888
I0329 21:53:26.995822 140691803780928 spec.py:298] Evaluating on the training split.
I0329 21:53:28.414370 140691803780928 spec.py:310] Evaluating on the validation split.
I0329 21:53:29.781876 140691803780928 spec.py:326] Evaluating on the test split.
I0329 21:53:31.151292 140691803780928 submission_runner.py:380] Time since start: 728.99s, 	Step: 1818, 	{'train/ssim': 0.7344479560852051, 'train/loss': 0.2738993338176182, 'validation/ssim': 0.7149881460590181, 'validation/loss': 0.2940633985254291, 'validation/num_examples': 3554, 'test/ssim': 0.7321814840913851, 'test/loss': 0.29572768905115543, 'test/num_examples': 3581}
I0329 21:53:31.152013 140691803780928 submission_runner.py:390] After eval at step 1818: RAM USED (GB) 140.652146688
I0329 21:53:31.159919 140482842564352 logging_writer.py:48] [1818] global_step=1818, preemption_count=0, score=525.904396, test/loss=0.295728, test/num_examples=3581, test/ssim=0.732181, total_duration=728.986827, train/loss=0.273899, train/ssim=0.734448, validation/loss=0.294063, validation/num_examples=3554, validation/ssim=0.714988
I0329 21:53:31.197081 140691803780928 checkpoints.py:356] Saving checkpoint at step: 1818
I0329 21:53:31.445175 140691803780928 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_1818
I0329 21:53:31.445706 140691803780928 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_1818.
I0329 21:53:31.446463 140691803780928 submission_runner.py:409] After logging and checkpointing eval at step 1818: RAM USED (GB) 140.650295296
I0329 21:53:49.041631 140446495926016 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.20333771407604218, loss=0.2706879675388336
I0329 21:54:13.239988 140446793520896 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.1913684755563736, loss=0.2988758385181427
I0329 21:54:37.835760 140446495926016 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.19508786499500275, loss=0.35466066002845764
I0329 21:54:51.517712 140691803780928 submission_runner.py:371] Before eval at step 2157: RAM USED (GB) 140.553211904
I0329 21:54:51.517916 140691803780928 spec.py:298] Evaluating on the training split.
I0329 21:54:52.941904 140691803780928 spec.py:310] Evaluating on the validation split.
I0329 21:54:54.310718 140691803780928 spec.py:326] Evaluating on the test split.
I0329 21:54:55.682021 140691803780928 submission_runner.py:380] Time since start: 813.51s, 	Step: 2157, 	{'train/ssim': 0.732762268611363, 'train/loss': 0.2767561844417027, 'validation/ssim': 0.7136551959499859, 'validation/loss': 0.29658050622977633, 'validation/num_examples': 3554, 'test/ssim': 0.7305990356002164, 'test/loss': 0.2984462675186749, 'test/num_examples': 3581}
I0329 21:54:55.682740 140691803780928 submission_runner.py:390] After eval at step 2157: RAM USED (GB) 140.688510976
I0329 21:54:55.690902 140446793520896 logging_writer.py:48] [2157] global_step=2157, preemption_count=0, score=605.613765, test/loss=0.298446, test/num_examples=3581, test/ssim=0.730599, total_duration=813.509063, train/loss=0.276756, train/ssim=0.732762, validation/loss=0.296581, validation/num_examples=3554, validation/ssim=0.713655
I0329 21:54:55.727560 140691803780928 checkpoints.py:356] Saving checkpoint at step: 2157
I0329 21:54:55.978218 140691803780928 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_2157
I0329 21:54:55.978748 140691803780928 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_2157.
I0329 21:54:55.979578 140691803780928 submission_runner.py:409] After logging and checkpointing eval at step 2157: RAM USED (GB) 140.690878464
I0329 21:55:04.626845 140446495926016 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.16094814240932465, loss=0.2869367301464081
I0329 21:55:28.831499 140446630143744 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.13464570045471191, loss=0.28144344687461853
I0329 21:55:53.100818 140446495926016 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.1255205273628235, loss=0.2932842969894409
I0329 21:56:15.983405 140691803780928 submission_runner.py:371] Before eval at step 2496: RAM USED (GB) 140.585066496
I0329 21:56:15.983623 140691803780928 spec.py:298] Evaluating on the training split.
I0329 21:56:17.404053 140691803780928 spec.py:310] Evaluating on the validation split.
I0329 21:56:18.782506 140691803780928 spec.py:326] Evaluating on the test split.
I0329 21:56:20.150580 140691803780928 submission_runner.py:380] Time since start: 897.97s, 	Step: 2496, 	{'train/ssim': 0.7356818062918526, 'train/loss': 0.2737163986478533, 'validation/ssim': 0.715958457349993, 'validation/loss': 0.2941348409142867, 'validation/num_examples': 3554, 'test/ssim': 0.7330272837545379, 'test/loss': 0.2957261550762706, 'test/num_examples': 3581}
I0329 21:56:20.151228 140691803780928 submission_runner.py:390] After eval at step 2496: RAM USED (GB) 140.72797184
I0329 21:56:20.159145 140446630143744 logging_writer.py:48] [2496] global_step=2496, preemption_count=0, score=685.249092, test/loss=0.295726, test/num_examples=3581, test/ssim=0.733027, total_duration=897.974700, train/loss=0.273716, train/ssim=0.735682, validation/loss=0.294135, validation/num_examples=3554, validation/ssim=0.715958
I0329 21:56:20.196517 140691803780928 checkpoints.py:356] Saving checkpoint at step: 2496
I0329 21:56:20.445941 140691803780928 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_2496
I0329 21:56:20.446490 140691803780928 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_2496.
I0329 21:56:20.447324 140691803780928 submission_runner.py:409] After logging and checkpointing eval at step 2496: RAM USED (GB) 140.725886976
I0329 21:56:20.820086 140446495926016 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.27732065320014954, loss=0.3792853355407715
I0329 21:56:43.320811 140446621751040 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.07440006732940674, loss=0.3126216530799866
I0329 21:57:07.475612 140446495926016 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.20451045036315918, loss=0.2884259819984436
I0329 21:57:10.584075 140691803780928 submission_runner.py:371] Before eval at step 2714: RAM USED (GB) 140.579868672
I0329 21:57:10.584280 140691803780928 spec.py:298] Evaluating on the training split.
I0329 21:57:12.013101 140691803780928 spec.py:310] Evaluating on the validation split.
I0329 21:57:13.383666 140691803780928 spec.py:326] Evaluating on the test split.
I0329 21:57:14.751239 140691803780928 submission_runner.py:380] Time since start: 952.58s, 	Step: 2714, 	{'train/ssim': 0.7346575600760323, 'train/loss': 0.273105263710022, 'validation/ssim': 0.7143169997713844, 'validation/loss': 0.29363440071926, 'validation/num_examples': 3554, 'test/ssim': 0.7315682350207693, 'test/loss': 0.2951889570716106, 'test/num_examples': 3581}
I0329 21:57:14.751919 140691803780928 submission_runner.py:390] After eval at step 2714: RAM USED (GB) 140.725485568
I0329 21:57:14.759852 140446621751040 logging_writer.py:48] [2714] global_step=2714, preemption_count=0, score=735.151974, test/loss=0.295189, test/num_examples=3581, test/ssim=0.731568, total_duration=952.575418, train/loss=0.273105, train/ssim=0.734658, validation/loss=0.293634, validation/num_examples=3554, validation/ssim=0.714317
I0329 21:57:14.795671 140691803780928 checkpoints.py:356] Saving checkpoint at step: 2714
I0329 21:57:15.052796 140691803780928 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_2714
I0329 21:57:15.053316 140691803780928 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_2714.
I0329 21:57:15.054118 140691803780928 submission_runner.py:409] After logging and checkpointing eval at step 2714: RAM USED (GB) 140.727820288
I0329 21:57:15.060931 140446495926016 logging_writer.py:48] [2714] global_step=2714, preemption_count=0, score=735.151974
I0329 21:57:15.092557 140691803780928 checkpoints.py:356] Saving checkpoint at step: 2714
I0329 21:57:15.436105 140691803780928 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_2714
I0329 21:57:15.436644 140691803780928 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw/fastmri_jax/trial_1/checkpoint_2714.
I0329 21:57:16.402167 140691803780928 submission_runner.py:543] Tuning trial 1/1
I0329 21:57:16.402393 140691803780928 submission_runner.py:544] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0329 21:57:16.407901 140691803780928 submission_runner.py:545] Metrics: {'eval_results': [(1, {'train/ssim': 0.18695909636361258, 'train/loss': 1.1376170430864607, 'validation/ssim': 0.18305492669461346, 'validation/loss': 1.134646920723129, 'validation/num_examples': 3554, 'test/ssim': 0.20604732442055293, 'test/loss': 1.1313989250994834, 'test/num_examples': 3581, 'score': 47.37935924530029, 'total_duration': 47.51784086227417, 'global_step': 1, 'preemption_count': 0}), (336, {'train/ssim': 0.6983460698808942, 'train/loss': 0.30655159269060406, 'validation/ssim': 0.678035257368458, 'validation/loss': 0.32860325183771805, 'validation/num_examples': 3554, 'test/ssim': 0.6963444901258378, 'test/loss': 0.33013975670203854, 'test/num_examples': 3581, 'score': 126.91107201576233, 'total_duration': 289.336718082428, 'global_step': 336, 'preemption_count': 0}), (613, {'train/ssim': 0.7204161371503558, 'train/loss': 0.28668063027518137, 'validation/ssim': 0.7012174882175014, 'validation/loss': 0.3071809080657358, 'validation/num_examples': 3554, 'test/ssim': 0.7186241458827841, 'test/loss': 0.30937992917262985, 'test/num_examples': 3581, 'score': 206.76703333854675, 'total_duration': 380.13291025161743, 'global_step': 613, 'preemption_count': 0}), (850, {'train/ssim': 0.7138806751796177, 'train/loss': 0.291689395904541, 'validation/ssim': 0.6957287206097004, 'validation/loss': 0.3116245559580754, 'validation/num_examples': 3554, 'test/ssim': 0.7130280009730173, 'test/loss': 0.31380626483524154, 'test/num_examples': 3581, 'score': 286.6375274658203, 'total_duration': 468.01081943511963, 'global_step': 850, 'preemption_count': 0}), (1136, {'train/ssim': 0.7261298043387276, 'train/loss': 0.28099279744284494, 'validation/ssim': 0.7060704185644696, 'validation/loss': 0.3015038141992297, 'validation/num_examples': 3554, 'test/ssim': 0.723302428398143, 'test/loss': 0.3033138084464884, 'test/num_examples': 3581, 'score': 366.3880572319031, 'total_duration': 554.6118078231812, 'global_step': 1136, 'preemption_count': 0}), (1477, {'train/ssim': 0.7321757589067731, 'train/loss': 0.2760016747883388, 'validation/ssim': 0.7129165228659609, 'validation/loss': 0.2960274803148741, 'validation/num_examples': 3554, 'test/ssim': 0.7301089817570162, 'test/loss': 0.297689302045518, 'test/num_examples': 3581, 'score': 446.0714156627655, 'total_duration': 643.0319485664368, 'global_step': 1477, 'preemption_count': 0}), (1818, {'train/ssim': 0.7344479560852051, 'train/loss': 0.2738993338176182, 'validation/ssim': 0.7149881460590181, 'validation/loss': 0.2940633985254291, 'validation/num_examples': 3554, 'test/ssim': 0.7321814840913851, 'test/loss': 0.29572768905115543, 'test/num_examples': 3581, 'score': 525.9043958187103, 'total_duration': 728.9868273735046, 'global_step': 1818, 'preemption_count': 0}), (2157, {'train/ssim': 0.732762268611363, 'train/loss': 0.2767561844417027, 'validation/ssim': 0.7136551959499859, 'validation/loss': 0.29658050622977633, 'validation/num_examples': 3554, 'test/ssim': 0.7305990356002164, 'test/loss': 0.2984462675186749, 'test/num_examples': 3581, 'score': 605.6137647628784, 'total_duration': 813.5090625286102, 'global_step': 2157, 'preemption_count': 0}), (2496, {'train/ssim': 0.7356818062918526, 'train/loss': 0.2737163986478533, 'validation/ssim': 0.715958457349993, 'validation/loss': 0.2941348409142867, 'validation/num_examples': 3554, 'test/ssim': 0.7330272837545379, 'test/loss': 0.2957261550762706, 'test/num_examples': 3581, 'score': 685.2490923404694, 'total_duration': 897.9747004508972, 'global_step': 2496, 'preemption_count': 0}), (2714, {'train/ssim': 0.7346575600760323, 'train/loss': 0.273105263710022, 'validation/ssim': 0.7143169997713844, 'validation/loss': 0.29363440071926, 'validation/num_examples': 3554, 'test/ssim': 0.7315682350207693, 'test/loss': 0.2951889570716106, 'test/num_examples': 3581, 'score': 735.1519742012024, 'total_duration': 952.5754182338715, 'global_step': 2714, 'preemption_count': 0})], 'global_step': 2714}
I0329 21:57:16.408043 140691803780928 submission_runner.py:546] Timing: 735.1519742012024
I0329 21:57:16.408092 140691803780928 submission_runner.py:547] ====================
I0329 21:57:16.408206 140691803780928 submission_runner.py:606] Final fastmri score: 735.1519742012024
