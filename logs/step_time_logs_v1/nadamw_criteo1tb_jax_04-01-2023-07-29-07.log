I0401 07:29:27.744285 140717235074880 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_nadamw/criteo1tb_jax.
I0401 07:29:28.100986 140717235074880 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0401 07:29:34.179817 140717235074880 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0401 07:29:34.180557 140717235074880 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0401 07:29:34.185524 140717235074880 submission_runner.py:511] Using RNG seed 3430206599
I0401 07:29:37.329740 140717235074880 submission_runner.py:520] --- Tuning run 1/1 ---
I0401 07:29:37.331484 140717235074880 submission_runner.py:525] Creating tuning directory at /experiment_runs/timing_nadamw/criteo1tb_jax/trial_1.
I0401 07:29:37.331737 140717235074880 logger_utils.py:84] Saving hparams to /experiment_runs/timing_nadamw/criteo1tb_jax/trial_1/hparams.json.
I0401 07:29:37.460332 140717235074880 submission_runner.py:230] Starting train once: RAM USED (GB) 4.522438656
I0401 07:29:37.460473 140717235074880 submission_runner.py:231] Initializing dataset.
I0401 07:29:37.460630 140717235074880 submission_runner.py:239] After Initializing dataset: RAM USED (GB) 4.522438656
I0401 07:29:37.460678 140717235074880 submission_runner.py:240] Initializing model.
I0401 07:29:45.236344 140717235074880 submission_runner.py:251] After Initializing model: RAM USED (GB) 8.216444928
I0401 07:29:45.236576 140717235074880 submission_runner.py:252] Initializing optimizer.
I0401 07:29:48.454808 140717235074880 submission_runner.py:260] After Initializing metrics bundle: RAM USED (GB) 8.21686272
I0401 07:29:48.454995 140717235074880 submission_runner.py:261] Initializing metrics bundle.
I0401 07:29:48.455044 140717235074880 submission_runner.py:276] Initializing checkpoint and logger.
I0401 07:29:48.457142 140717235074880 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_nadamw/criteo1tb_jax/trial_1 with prefix checkpoint_
I0401 07:29:48.457434 140717235074880 logger_utils.py:231] Unable to record workload.train_mean information. Continuing without it.
I0401 07:29:48.457499 140717235074880 logger_utils.py:231] Unable to record workload.train_stddev information. Continuing without it.
I0401 07:29:50.539290 140717235074880 submission_runner.py:297] Saving meta data to /experiment_runs/timing_nadamw/criteo1tb_jax/trial_1/meta_data_0.json.
I0401 07:29:50.541127 140717235074880 submission_runner.py:300] Saving flags to /experiment_runs/timing_nadamw/criteo1tb_jax/trial_1/flags_0.json.
I0401 07:29:50.587833 140717235074880 submission_runner.py:305] After checkpoint and logger metrics bundle: RAM USED (GB) 8.236797952
I0401 07:29:50.588119 140717235074880 submission_runner.py:312] Before starting training loop and logger metrics bundle: RAM USED (GB) 8.236797952
I0401 07:29:50.588188 140717235074880 submission_runner.py:313] Starting training loop.
I0401 07:32:23.123738 140717235074880 submission_runner.py:335] After dataselection batch at step 0: RAM USED (GB) 46.360293376
I0401 07:32:45.220490 140511767688960 logging_writer.py:48] [0] global_step=0, grad_norm=7.392955303192139, loss=0.9822285771369934
I0401 07:32:45.229829 140717235074880 submission_runner.py:352] After update parameters step 0: RAM USED (GB) 54.241026048
I0401 07:32:45.230105 140717235074880 submission_runner.py:373] Before eval at step 1: RAM USED (GB) 54.241284096
I0401 07:32:45.230187 140717235074880 spec.py:298] Evaluating on the training split.
I0401 07:42:57.816562 140717235074880 spec.py:310] Evaluating on the validation split.
I0401 07:47:19.415688 140717235074880 spec.py:326] Evaluating on the test split.
I0401 07:51:56.288515 140717235074880 submission_runner.py:382] Time since start: 174.64s, 	Step: 1, 	{'train/loss': 0.9822292931383371, 'validation/loss': 0.9824702022471911, 'validation/num_examples': 89000000, 'test/loss': 0.9825530178296888, 'test/num_examples': 89274637}
I0401 07:51:56.289063 140717235074880 submission_runner.py:396] After eval at step 1: RAM USED (GB) 95.987290112
I0401 07:51:56.311382 140458256729856 logging_writer.py:48] [1] global_step=1, preemption_count=0, score=174.443049, test/loss=0.982553, test/num_examples=89274637, total_duration=174.641967, train/loss=0.982229, validation/loss=0.982470, validation/num_examples=89000000
I0401 07:52:02.757452 140717235074880 checkpoints.py:356] Saving checkpoint at step: 1
I0401 07:52:40.336629 140717235074880 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nadamw/criteo1tb_jax/trial_1/checkpoint_1
I0401 07:52:40.859067 140717235074880 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/criteo1tb_jax/trial_1/checkpoint_1.
I0401 07:52:41.391197 140717235074880 submission_runner.py:416] After logging and checkpointing eval at step 1: RAM USED (GB) 96.066113536
I0401 07:52:41.400019 140717235074880 submission_runner.py:335] After dataselection batch at step 1: RAM USED (GB) 96.024825856
I0401 07:52:41.433408 140717235074880 submission_runner.py:352] After update parameters step 1: RAM USED (GB) 96.024444928
I0401 07:54:08.126175 140458248337152 logging_writer.py:48] [100] global_step=100, grad_norm=0.015364913269877434, loss=0.1318444162607193
I0401 07:56:33.951469 140458214766336 logging_writer.py:48] [200] global_step=200, grad_norm=0.05755944550037384, loss=0.13072846829891205
I0401 07:58:38.315121 140458248337152 logging_writer.py:48] [300] global_step=300, grad_norm=0.09667349606752396, loss=0.12643928825855255
I0401 08:00:52.304655 140458214766336 logging_writer.py:48] [400] global_step=400, grad_norm=0.05121418088674545, loss=0.12661238014698029
I0401 08:01:41.952702 140717235074880 submission_runner.py:373] Before eval at step 441: RAM USED (GB) 102.629896192
I0401 08:01:41.952889 140717235074880 spec.py:298] Evaluating on the training split.
I0401 08:12:33.922013 140717235074880 spec.py:310] Evaluating on the validation split.
I0401 08:16:24.993158 140717235074880 spec.py:326] Evaluating on the test split.
I0401 08:21:35.272539 140717235074880 submission_runner.py:382] Time since start: 1911.36s, 	Step: 441, 	{'train/loss': 0.12622071435295368, 'validation/loss': 0.1272385168539326, 'validation/num_examples': 89000000, 'test/loss': 0.12952586970474045, 'test/num_examples': 89274637}
I0401 08:21:35.273344 140717235074880 submission_runner.py:396] After eval at step 441: RAM USED (GB) 107.169947648
I0401 08:21:35.283032 140454758708992 logging_writer.py:48] [441] global_step=441, preemption_count=0, score=713.028555, test/loss=0.129526, test/num_examples=89274637, total_duration=1911.364315, train/loss=0.126221, validation/loss=0.127239, validation/num_examples=89000000
I0401 08:21:41.651894 140717235074880 checkpoints.py:356] Saving checkpoint at step: 441
I0401 08:22:18.543919 140717235074880 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nadamw/criteo1tb_jax/trial_1/checkpoint_441
I0401 08:22:19.071850 140717235074880 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/criteo1tb_jax/trial_1/checkpoint_441.
I0401 08:22:19.592128 140717235074880 submission_runner.py:416] After logging and checkpointing eval at step 441: RAM USED (GB) 107.134242816
I0401 08:23:04.062044 140454750316288 logging_writer.py:48] [500] global_step=500, grad_norm=0.08757393062114716, loss=0.1244783028960228
I0401 08:25:11.114232 140454708352768 logging_writer.py:48] [600] global_step=600, grad_norm=0.05572750046849251, loss=0.12513713538646698
I0401 08:27:17.010063 140454750316288 logging_writer.py:48] [700] global_step=700, grad_norm=0.06309276074171066, loss=0.12535184621810913
I0401 08:29:16.946689 140717235074880 submission_runner.py:373] Before eval at step 800: RAM USED (GB) 107.957702656
I0401 08:29:16.946877 140717235074880 spec.py:298] Evaluating on the training split.
I0401 08:39:47.474324 140717235074880 spec.py:310] Evaluating on the validation split.
I0401 08:43:49.112913 140717235074880 spec.py:326] Evaluating on the test split.
I0401 08:48:25.973727 140717235074880 submission_runner.py:382] Time since start: 3566.36s, 	Step: 800, 	{'train/loss': 0.12460622443619504, 'validation/loss': 0.12593804494382022, 'validation/num_examples': 89000000, 'test/loss': 0.12829210383683778, 'test/num_examples': 89274637}
I0401 08:48:25.974685 140717235074880 submission_runner.py:396] After eval at step 800: RAM USED (GB) 112.327077888
I0401 08:48:25.984106 140454708352768 logging_writer.py:48] [800] global_step=800, preemption_count=0, score=1128.044245, test/loss=0.128292, test/num_examples=89274637, total_duration=3566.358324, train/loss=0.124606, validation/loss=0.125938, validation/num_examples=89000000
I0401 08:48:32.001972 140717235074880 checkpoints.py:356] Saving checkpoint at step: 800
I0401 08:49:07.650266 140717235074880 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nadamw/criteo1tb_jax/trial_1/checkpoint_800
I0401 08:49:08.123188 140717235074880 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/criteo1tb_jax/trial_1/checkpoint_800.
I0401 08:49:08.578924 140717235074880 submission_runner.py:416] After logging and checkpointing eval at step 800: RAM USED (GB) 112.363405312
I0401 08:49:08.584933 140454750316288 logging_writer.py:48] [800] global_step=800, preemption_count=0, score=1128.044245
I0401 08:49:14.557379 140717235074880 checkpoints.py:356] Saving checkpoint at step: 800
I0401 08:49:56.929344 140717235074880 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nadamw/criteo1tb_jax/trial_1/checkpoint_800
I0401 08:49:57.439656 140717235074880 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/criteo1tb_jax/trial_1/checkpoint_800.
I0401 08:51:29.631946 140717235074880 submission_runner.py:550] Tuning trial 1/1
I0401 08:51:29.633238 140717235074880 submission_runner.py:551] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.045677535963609565, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0401 08:51:29.634791 140717235074880 submission_runner.py:552] Metrics: {'eval_results': [(1, {'train/loss': 0.9822292931383371, 'validation/loss': 0.9824702022471911, 'validation/num_examples': 89000000, 'test/loss': 0.9825530178296888, 'test/num_examples': 89274637, 'score': 174.4430491924286, 'total_duration': 174.64196729660034, 'global_step': 1, 'preemption_count': 0}), (441, {'train/loss': 0.12622071435295368, 'validation/loss': 0.1272385168539326, 'validation/num_examples': 89000000, 'test/loss': 0.12952586970474045, 'test/num_examples': 89274637, 'score': 713.028555393219, 'total_duration': 1911.3643145561218, 'global_step': 441, 'preemption_count': 0}), (800, {'train/loss': 0.12460622443619504, 'validation/loss': 0.12593804494382022, 'validation/num_examples': 89000000, 'test/loss': 0.12829210383683778, 'test/num_examples': 89274637, 'score': 1128.044245004654, 'total_duration': 3566.3583238124847, 'global_step': 800, 'preemption_count': 0})], 'global_step': 800}
I0401 08:51:29.635077 140717235074880 submission_runner.py:553] Timing: 1128.044245004654
I0401 08:51:29.635158 140717235074880 submission_runner.py:554] ====================
I0401 08:51:29.635323 140717235074880 submission_runner.py:613] Final criteo1tb score: 1128.044245004654
