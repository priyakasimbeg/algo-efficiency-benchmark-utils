I0331 21:19:03.556391 139985821210432 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_nadamw/fastmri_jax.
I0331 21:19:03.919009 139985821210432 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0331 21:19:04.888073 139985821210432 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Host Interpreter
I0331 21:19:04.888767 139985821210432 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0331 21:19:04.893557 139985821210432 submission_runner.py:511] Using RNG seed 1574217218
I0331 21:19:07.554864 139985821210432 submission_runner.py:520] --- Tuning run 1/1 ---
I0331 21:19:07.555053 139985821210432 submission_runner.py:525] Creating tuning directory at /experiment_runs/timing_nadamw/fastmri_jax/trial_1.
I0331 21:19:07.555221 139985821210432 logger_utils.py:84] Saving hparams to /experiment_runs/timing_nadamw/fastmri_jax/trial_1/hparams.json.
I0331 21:19:07.683629 139985821210432 submission_runner.py:230] Starting train once: RAM USED (GB) 4.18654208
I0331 21:19:07.683799 139985821210432 submission_runner.py:231] Initializing dataset.
I0331 21:19:11.399445 139985821210432 submission_runner.py:239] After Initializing dataset: RAM USED (GB) 4.27061248
I0331 21:19:11.399637 139985821210432 submission_runner.py:240] Initializing model.
I0331 21:19:18.418870 139985821210432 submission_runner.py:251] After Initializing model: RAM USED (GB) 8.218083328
I0331 21:19:18.419081 139985821210432 submission_runner.py:252] Initializing optimizer.
I0331 21:19:18.875394 139985821210432 submission_runner.py:260] After Initializing metrics bundle: RAM USED (GB) 8.219107328
I0331 21:19:18.875561 139985821210432 submission_runner.py:261] Initializing metrics bundle.
I0331 21:19:18.875609 139985821210432 submission_runner.py:276] Initializing checkpoint and logger.
I0331 21:19:18.876461 139985821210432 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_nadamw/fastmri_jax/trial_1 with prefix checkpoint_
I0331 21:19:18.876681 139985821210432 logger_utils.py:231] Unable to record workload.train_mean information. Continuing without it.
I0331 21:19:18.876739 139985821210432 logger_utils.py:231] Unable to record workload.train_stddev information. Continuing without it.
I0331 21:19:19.816306 139985821210432 submission_runner.py:297] Saving meta data to /experiment_runs/timing_nadamw/fastmri_jax/trial_1/meta_data_0.json.
I0331 21:19:19.817234 139985821210432 submission_runner.py:300] Saving flags to /experiment_runs/timing_nadamw/fastmri_jax/trial_1/flags_0.json.
I0331 21:19:19.822079 139985821210432 submission_runner.py:305] After checkpoint and logger metrics bundle: RAM USED (GB) 8.2173952
I0331 21:19:19.822280 139985821210432 submission_runner.py:312] Before starting training loop and logger metrics bundle: RAM USED (GB) 8.2173952
I0331 21:19:19.822341 139985821210432 submission_runner.py:313] Starting training loop.
I0331 21:19:58.817443 139985821210432 submission_runner.py:335] After dataselection batch at step 0: RAM USED (GB) 16.774483968
I0331 21:20:25.135359 139809456641792 logging_writer.py:48] [0] global_step=0, grad_norm=5.4024200439453125, loss=0.908011794090271
I0331 21:20:25.145614 139985821210432 submission_runner.py:352] After update parameters step 0: RAM USED (GB) 23.084494848
I0331 21:20:25.145925 139985821210432 submission_runner.py:373] Before eval at step 1: RAM USED (GB) 23.084494848
I0331 21:20:25.146008 139985821210432 spec.py:298] Evaluating on the training split.
I0331 21:21:52.621184 139985821210432 spec.py:310] Evaluating on the validation split.
I0331 21:22:54.195646 139985821210432 spec.py:326] Evaluating on the test split.
I0331 21:23:52.562943 139985821210432 submission_runner.py:382] Time since start: 65.32s, 	Step: 1, 	{'train/ssim': 0.24337003912244523, 'train/loss': 0.9297927447727748, 'validation/ssim': 0.23459009998087543, 'validation/loss': 0.9309125308850943, 'validation/num_examples': 3554, 'test/ssim': 0.2571022184958374, 'test/loss': 0.930454691972389, 'test/num_examples': 3581}
I0331 21:23:52.563946 139985821210432 submission_runner.py:396] After eval at step 1: RAM USED (GB) 58.650292224
I0331 21:23:52.573212 139780507559680 logging_writer.py:48] [1] global_step=1, preemption_count=0, score=65.194469, test/loss=0.930455, test/num_examples=3581, test/ssim=0.257102, total_duration=65.323580, train/loss=0.929793, train/ssim=0.243370, validation/loss=0.930913, validation/num_examples=3554, validation/ssim=0.234590
I0331 21:23:52.609575 139985821210432 checkpoints.py:356] Saving checkpoint at step: 1
I0331 21:23:52.854271 139985821210432 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_1
I0331 21:23:52.855016 139985821210432 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_1.
I0331 21:23:52.857097 139985821210432 submission_runner.py:416] After logging and checkpointing eval at step 1: RAM USED (GB) 58.637725696
I0331 21:23:52.859352 139985821210432 submission_runner.py:335] After dataselection batch at step 1: RAM USED (GB) 58.637725696
I0331 21:23:52.878095 139985821210432 submission_runner.py:352] After update parameters step 1: RAM USED (GB) 58.657079296
I0331 21:24:15.054042 139780499166976 logging_writer.py:48] [100] global_step=100, grad_norm=0.2175731509923935, loss=0.2524978816509247
I0331 21:24:39.604641 139780465596160 logging_writer.py:48] [200] global_step=200, grad_norm=0.0694613978266716, loss=0.2947212755680084
I0331 21:25:03.866333 139780499166976 logging_writer.py:48] [300] global_step=300, grad_norm=0.1585640162229538, loss=0.3093244433403015
I0331 21:25:13.021093 139985821210432 submission_runner.py:373] Before eval at step 335: RAM USED (GB) 81.672720384
I0331 21:25:13.021301 139985821210432 spec.py:298] Evaluating on the training split.
I0331 21:25:14.790899 139985821210432 spec.py:310] Evaluating on the validation split.
I0331 21:25:16.139335 139985821210432 spec.py:326] Evaluating on the test split.
I0331 21:25:17.486810 139985821210432 submission_runner.py:382] Time since start: 353.20s, 	Step: 335, 	{'train/ssim': 0.7016626085553851, 'train/loss': 0.31071243967328754, 'validation/ssim': 0.6823441264464336, 'validation/loss': 0.3246239451256507, 'validation/num_examples': 3554, 'test/ssim': 0.7004122506370427, 'test/loss': 0.3265276208199525, 'test/num_examples': 3581}
I0331 21:25:17.488080 139985821210432 submission_runner.py:396] After eval at step 335: RAM USED (GB) 82.722398208
I0331 21:25:17.497888 139780465596160 logging_writer.py:48] [335] global_step=335, preemption_count=0, score=144.907555, test/loss=0.326528, test/num_examples=3581, test/ssim=0.700412, total_duration=353.198145, train/loss=0.310712, train/ssim=0.701663, validation/loss=0.324624, validation/num_examples=3554, validation/ssim=0.682344
I0331 21:25:17.578804 139985821210432 checkpoints.py:356] Saving checkpoint at step: 335
I0331 21:25:17.825565 139985821210432 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_335
I0331 21:25:17.826302 139985821210432 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_335.
I0331 21:25:17.827126 139985821210432 submission_runner.py:416] After logging and checkpointing eval at step 335: RAM USED (GB) 82.890612736
I0331 21:25:37.705936 139780499166976 logging_writer.py:48] [400] global_step=400, grad_norm=0.1543329358100891, loss=0.26560327410697937
I0331 21:26:12.146656 139780213958400 logging_writer.py:48] [500] global_step=500, grad_norm=0.4355114698410034, loss=0.29043957591056824
I0331 21:26:38.069997 139985821210432 submission_runner.py:373] Before eval at step 575: RAM USED (GB) 101.584605184
I0331 21:26:38.070272 139985821210432 spec.py:298] Evaluating on the training split.
I0331 21:26:39.471241 139985821210432 spec.py:310] Evaluating on the validation split.
I0331 21:26:40.821717 139985821210432 spec.py:326] Evaluating on the test split.
I0331 21:26:42.172127 139985821210432 submission_runner.py:382] Time since start: 438.25s, 	Step: 575, 	{'train/ssim': 0.717813423701695, 'train/loss': 0.29434926169259207, 'validation/ssim': 0.6993926160444218, 'validation/loss': 0.3077871722992579, 'validation/num_examples': 3554, 'test/ssim': 0.7167785354780438, 'test/loss': 0.3098904019259634, 'test/num_examples': 3581}
I0331 21:26:42.172788 139985821210432 submission_runner.py:396] After eval at step 575: RAM USED (GB) 102.651035648
I0331 21:26:42.182183 139780499166976 logging_writer.py:48] [575] global_step=575, preemption_count=0, score=224.802632, test/loss=0.309890, test/num_examples=3581, test/ssim=0.716779, total_duration=438.246443, train/loss=0.294349, train/ssim=0.717813, validation/loss=0.307787, validation/num_examples=3554, validation/ssim=0.699393
I0331 21:26:42.267199 139985821210432 checkpoints.py:356] Saving checkpoint at step: 575
I0331 21:26:42.501953 139985821210432 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_575
I0331 21:26:42.502604 139985821210432 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_575.
I0331 21:26:42.503405 139985821210432 submission_runner.py:416] After logging and checkpointing eval at step 575: RAM USED (GB) 102.808498176
I0331 21:26:48.640263 139780213958400 logging_writer.py:48] [600] global_step=600, grad_norm=0.13626864552497864, loss=0.28330543637275696
I0331 21:27:23.693311 139762023261952 logging_writer.py:48] [700] global_step=700, grad_norm=0.4299101233482361, loss=0.29147374629974365
I0331 21:27:58.647497 139780213958400 logging_writer.py:48] [800] global_step=800, grad_norm=0.16098371148109436, loss=0.25058218836784363
I0331 21:28:02.789863 139985821210432 submission_runner.py:373] Before eval at step 813: RAM USED (GB) 121.198997504
I0331 21:28:02.790064 139985821210432 spec.py:298] Evaluating on the training split.
I0331 21:28:04.193099 139985821210432 spec.py:310] Evaluating on the validation split.
I0331 21:28:08.547452 139985821210432 spec.py:326] Evaluating on the test split.
I0331 21:28:09.902800 139985821210432 submission_runner.py:382] Time since start: 522.97s, 	Step: 813, 	{'train/ssim': 0.7203812599182129, 'train/loss': 0.2894338539668492, 'validation/ssim': 0.7029068259355655, 'validation/loss': 0.3024852883634637, 'validation/num_examples': 3554, 'test/ssim': 0.7200081321121893, 'test/loss': 0.3045262621954412, 'test/num_examples': 3581}
I0331 21:28:09.903427 139985821210432 submission_runner.py:396] After eval at step 813: RAM USED (GB) 122.214690816
I0331 21:28:09.914057 139762023261952 logging_writer.py:48] [813] global_step=813, preemption_count=0, score=304.746866, test/loss=0.304526, test/num_examples=3581, test/ssim=0.720008, total_duration=522.967283, train/loss=0.289434, train/ssim=0.720381, validation/loss=0.302485, validation/num_examples=3554, validation/ssim=0.702907
I0331 21:28:10.005727 139985821210432 checkpoints.py:356] Saving checkpoint at step: 813
I0331 21:28:10.286744 139985821210432 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_813
I0331 21:28:10.287366 139985821210432 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_813.
I0331 21:28:10.289094 139985821210432 submission_runner.py:416] After logging and checkpointing eval at step 813: RAM USED (GB) 122.415468544
I0331 21:28:38.730370 139780213958400 logging_writer.py:48] [900] global_step=900, grad_norm=0.2365323305130005, loss=0.26797130703926086
I0331 21:29:09.981153 139731020916480 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.1549629271030426, loss=0.24532082676887512
I0331 21:29:30.401079 139985821210432 submission_runner.py:373] Before eval at step 1086: RAM USED (GB) 136.594378752
I0331 21:29:30.401277 139985821210432 spec.py:298] Evaluating on the training split.
I0331 21:29:31.805297 139985821210432 spec.py:310] Evaluating on the validation split.
I0331 21:29:33.680805 139985821210432 spec.py:326] Evaluating on the test split.
I0331 21:29:35.033823 139985821210432 submission_runner.py:382] Time since start: 610.58s, 	Step: 1086, 	{'train/ssim': 0.7280577932085309, 'train/loss': 0.28509203025272917, 'validation/ssim': 0.7095622340144907, 'validation/loss': 0.2984691956905951, 'validation/num_examples': 3554, 'test/ssim': 0.7266414485740715, 'test/loss': 0.3005181562630899, 'test/num_examples': 3581}
I0331 21:29:35.034559 139985821210432 submission_runner.py:396] After eval at step 1086: RAM USED (GB) 136.853274624
I0331 21:29:35.042206 139780213958400 logging_writer.py:48] [1086] global_step=1086, preemption_count=0, score=384.506589, test/loss=0.300518, test/num_examples=3581, test/ssim=0.726641, total_duration=610.578441, train/loss=0.285092, train/ssim=0.728058, validation/loss=0.298469, validation/num_examples=3554, validation/ssim=0.709562
I0331 21:29:35.111984 139985821210432 checkpoints.py:356] Saving checkpoint at step: 1086
I0331 21:29:35.347946 139985821210432 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_1086
I0331 21:29:35.348544 139985821210432 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_1086.
I0331 21:29:35.349400 139985821210432 submission_runner.py:416] After logging and checkpointing eval at step 1086: RAM USED (GB) 136.976101376
I0331 21:29:36.625892 139731020916480 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.23741765320301056, loss=0.43514931201934814
I0331 21:30:00.311440 139709028226816 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.14012376964092255, loss=0.2931782603263855
I0331 21:30:24.255141 139731020916480 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.30970361828804016, loss=0.24893589317798615
I0331 21:30:48.091731 139709028226816 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.21324671804904938, loss=0.24866443872451782
I0331 21:30:55.399887 139985821210432 submission_runner.py:373] Before eval at step 1432: RAM USED (GB) 136.839299072
I0331 21:30:55.400120 139985821210432 spec.py:298] Evaluating on the training split.
I0331 21:30:56.807306 139985821210432 spec.py:310] Evaluating on the validation split.
I0331 21:30:58.160954 139985821210432 spec.py:326] Evaluating on the test split.
I0331 21:30:59.518243 139985821210432 submission_runner.py:382] Time since start: 695.58s, 	Step: 1432, 	{'train/ssim': 0.7335294314793178, 'train/loss': 0.2808783565248762, 'validation/ssim': 0.7140534872678672, 'validation/loss': 0.29485400473058526, 'validation/num_examples': 3554, 'test/ssim': 0.7311093379118961, 'test/loss': 0.2967274316160814, 'test/num_examples': 3581}
I0331 21:30:59.518951 139985821210432 submission_runner.py:396] After eval at step 1432: RAM USED (GB) 137.04507392
I0331 21:30:59.526497 139731020916480 logging_writer.py:48] [1432] global_step=1432, preemption_count=0, score=464.198487, test/loss=0.296727, test/num_examples=3581, test/ssim=0.731109, total_duration=695.577292, train/loss=0.280878, train/ssim=0.733529, validation/loss=0.294854, validation/num_examples=3554, validation/ssim=0.714053
I0331 21:30:59.561312 139985821210432 checkpoints.py:356] Saving checkpoint at step: 1432
I0331 21:30:59.781659 139985821210432 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_1432
I0331 21:30:59.782238 139985821210432 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_1432.
I0331 21:30:59.783140 139985821210432 submission_runner.py:416] After logging and checkpointing eval at step 1432: RAM USED (GB) 137.057148928
I0331 21:31:14.035470 139709028226816 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.3694796562194824, loss=0.37110722064971924
I0331 21:31:37.876127 139708868830976 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.3074183166027069, loss=0.28433361649513245
I0331 21:32:01.805943 139709028226816 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.1092807799577713, loss=0.33077892661094666
I0331 21:32:19.851209 139985821210432 submission_runner.py:373] Before eval at step 1777: RAM USED (GB) 136.87097344
I0331 21:32:19.851468 139985821210432 spec.py:298] Evaluating on the training split.
I0331 21:32:21.258099 139985821210432 spec.py:310] Evaluating on the validation split.
I0331 21:32:22.608212 139985821210432 spec.py:326] Evaluating on the test split.
I0331 21:32:23.959976 139985821210432 submission_runner.py:382] Time since start: 780.03s, 	Step: 1777, 	{'train/ssim': 0.7339840616498675, 'train/loss': 0.2825146062033517, 'validation/ssim': 0.7144467638796075, 'validation/loss': 0.2962989613925331, 'validation/num_examples': 3554, 'test/ssim': 0.7315916877923415, 'test/loss': 0.2981079749240785, 'test/num_examples': 3581}
I0331 21:32:23.960701 139985821210432 submission_runner.py:396] After eval at step 1777: RAM USED (GB) 137.078878208
I0331 21:32:23.968076 139708868830976 logging_writer.py:48] [1777] global_step=1777, preemption_count=0, score=543.910080, test/loss=0.298108, test/num_examples=3581, test/ssim=0.731592, total_duration=780.028655, train/loss=0.282515, train/ssim=0.733984, validation/loss=0.296299, validation/num_examples=3554, validation/ssim=0.714447
I0331 21:32:24.004917 139985821210432 checkpoints.py:356] Saving checkpoint at step: 1777
I0331 21:32:24.221371 139985821210432 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_1777
I0331 21:32:24.221937 139985821210432 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_1777.
I0331 21:32:24.222828 139985821210432 submission_runner.py:416] After logging and checkpointing eval at step 1777: RAM USED (GB) 137.081536512
I0331 21:32:27.668297 139709028226816 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.23622044920921326, loss=0.2504684627056122
I0331 21:32:51.422839 139708692682496 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.09589289873838425, loss=0.31602489948272705
I0331 21:33:15.634905 139709028226816 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.06461330503225327, loss=0.3307276666164398
I0331 21:33:39.525766 139708692682496 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.11454106867313385, loss=0.2798028588294983
I0331 21:33:44.226654 139985821210432 submission_runner.py:373] Before eval at step 2121: RAM USED (GB) 136.934539264
I0331 21:33:44.226859 139985821210432 spec.py:298] Evaluating on the training split.
I0331 21:33:45.631741 139985821210432 spec.py:310] Evaluating on the validation split.
I0331 21:33:46.981118 139985821210432 spec.py:326] Evaluating on the test split.
I0331 21:33:48.334278 139985821210432 submission_runner.py:382] Time since start: 864.40s, 	Step: 2121, 	{'train/ssim': 0.7358603477478027, 'train/loss': 0.2785645382744925, 'validation/ssim': 0.7173596212014631, 'validation/loss': 0.29272931495541993, 'validation/num_examples': 3554, 'test/ssim': 0.7343029372687447, 'test/loss': 0.29446481866098856, 'test/num_examples': 3581}
I0331 21:33:48.334958 139985821210432 submission_runner.py:396] After eval at step 2121: RAM USED (GB) 137.138049024
I0331 21:33:48.342960 139709028226816 logging_writer.py:48] [2121] global_step=2121, preemption_count=0, score=623.557366, test/loss=0.294465, test/num_examples=3581, test/ssim=0.734303, total_duration=864.404051, train/loss=0.278565, train/ssim=0.735860, validation/loss=0.292729, validation/num_examples=3554, validation/ssim=0.717360
I0331 21:33:48.378711 139985821210432 checkpoints.py:356] Saving checkpoint at step: 2121
I0331 21:33:48.590118 139985821210432 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_2121
I0331 21:33:48.590687 139985821210432 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_2121.
I0331 21:33:48.591522 139985821210432 submission_runner.py:416] After logging and checkpointing eval at step 2121: RAM USED (GB) 137.136480256
I0331 21:34:05.622749 139708692682496 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.2657206356525421, loss=0.21903757750988007
I0331 21:34:29.623672 139708667504384 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.0891614481806755, loss=0.2603573501110077
I0331 21:34:53.338038 139708692682496 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.07289416342973709, loss=0.2524561285972595
I0331 21:35:08.804080 139985821210432 submission_runner.py:373] Before eval at step 2466: RAM USED (GB) 137.171214336
I0331 21:35:08.804325 139985821210432 spec.py:298] Evaluating on the training split.
I0331 21:35:10.210391 139985821210432 spec.py:310] Evaluating on the validation split.
I0331 21:35:11.561082 139985821210432 spec.py:326] Evaluating on the test split.
I0331 21:35:12.911343 139985821210432 submission_runner.py:382] Time since start: 948.98s, 	Step: 2466, 	{'train/ssim': 0.7388007300240653, 'train/loss': 0.27636386666979107, 'validation/ssim': 0.7189413831686128, 'validation/loss': 0.2908437510991137, 'validation/num_examples': 3554, 'test/ssim': 0.7360017633211743, 'test/loss': 0.2925107732760577, 'test/num_examples': 3581}
I0331 21:35:12.912096 139985821210432 submission_runner.py:396] After eval at step 2466: RAM USED (GB) 137.179430912
I0331 21:35:12.919634 139708667504384 logging_writer.py:48] [2466] global_step=2466, preemption_count=0, score=703.413920, test/loss=0.292511, test/num_examples=3581, test/ssim=0.736002, total_duration=948.981447, train/loss=0.276364, train/ssim=0.738801, validation/loss=0.290844, validation/num_examples=3554, validation/ssim=0.718941
I0331 21:35:12.956224 139985821210432 checkpoints.py:356] Saving checkpoint at step: 2466
I0331 21:35:13.173545 139985821210432 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_2466
I0331 21:35:13.174143 139985821210432 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_2466.
I0331 21:35:13.175003 139985821210432 submission_runner.py:416] After logging and checkpointing eval at step 2466: RAM USED (GB) 137.182273536
I0331 21:35:19.254855 139708692682496 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.14277692139148712, loss=0.2898591160774231
I0331 21:35:43.025671 139708659111680 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.14350058138370514, loss=0.28706496953964233
I0331 21:36:06.888403 139708692682496 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.08146057277917862, loss=0.2750568687915802
I0331 21:36:09.958631 139985821210432 submission_runner.py:373] Before eval at step 2714: RAM USED (GB) 137.122603008
I0331 21:36:09.958875 139985821210432 spec.py:298] Evaluating on the training split.
I0331 21:36:11.360195 139985821210432 spec.py:310] Evaluating on the validation split.
I0331 21:36:12.712882 139985821210432 spec.py:326] Evaluating on the test split.
I0331 21:36:14.067730 139985821210432 submission_runner.py:382] Time since start: 1010.14s, 	Step: 2714, 	{'train/ssim': 0.7378334317888532, 'train/loss': 0.27656681197030203, 'validation/ssim': 0.7181664393333216, 'validation/loss': 0.290893760771314, 'validation/num_examples': 3554, 'test/ssim': 0.7352719321593131, 'test/loss': 0.29253293069106046, 'test/num_examples': 3581}
I0331 21:36:14.068619 139985821210432 submission_runner.py:396] After eval at step 2714: RAM USED (GB) 137.17979136
I0331 21:36:14.076916 139708659111680 logging_writer.py:48] [2714] global_step=2714, preemption_count=0, score=759.936723, test/loss=0.292533, test/num_examples=3581, test/ssim=0.735272, total_duration=1010.135932, train/loss=0.276567, train/ssim=0.737833, validation/loss=0.290894, validation/num_examples=3554, validation/ssim=0.718166
I0331 21:36:14.110692 139985821210432 checkpoints.py:356] Saving checkpoint at step: 2714
I0331 21:36:14.347543 139985821210432 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_2714
I0331 21:36:14.348116 139985821210432 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_2714.
I0331 21:36:14.349080 139985821210432 submission_runner.py:416] After logging and checkpointing eval at step 2714: RAM USED (GB) 137.180602368
I0331 21:36:14.356171 139708692682496 logging_writer.py:48] [2714] global_step=2714, preemption_count=0, score=759.936723
I0331 21:36:14.383574 139985821210432 checkpoints.py:356] Saving checkpoint at step: 2714
I0331 21:36:14.740925 139985821210432 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_2714
I0331 21:36:14.741563 139985821210432 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/fastmri_jax/trial_1/checkpoint_2714.
I0331 21:36:15.428917 139985821210432 submission_runner.py:550] Tuning trial 1/1
I0331 21:36:15.429186 139985821210432 submission_runner.py:551] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.045677535963609565, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0331 21:36:15.438521 139985821210432 submission_runner.py:552] Metrics: {'eval_results': [(1, {'train/ssim': 0.24337003912244523, 'train/loss': 0.9297927447727748, 'validation/ssim': 0.23459009998087543, 'validation/loss': 0.9309125308850943, 'validation/num_examples': 3554, 'test/ssim': 0.2571022184958374, 'test/loss': 0.930454691972389, 'test/num_examples': 3581, 'score': 65.19446873664856, 'total_duration': 65.32357954978943, 'global_step': 1, 'preemption_count': 0}), (335, {'train/ssim': 0.7016626085553851, 'train/loss': 0.31071243967328754, 'validation/ssim': 0.6823441264464336, 'validation/loss': 0.3246239451256507, 'validation/num_examples': 3554, 'test/ssim': 0.7004122506370427, 'test/loss': 0.3265276208199525, 'test/num_examples': 3581, 'score': 144.90755462646484, 'total_duration': 353.1981449127197, 'global_step': 335, 'preemption_count': 0}), (575, {'train/ssim': 0.717813423701695, 'train/loss': 0.29434926169259207, 'validation/ssim': 0.6993926160444218, 'validation/loss': 0.3077871722992579, 'validation/num_examples': 3554, 'test/ssim': 0.7167785354780438, 'test/loss': 0.3098904019259634, 'test/num_examples': 3581, 'score': 224.8026316165924, 'total_duration': 438.2464425563812, 'global_step': 575, 'preemption_count': 0}), (813, {'train/ssim': 0.7203812599182129, 'train/loss': 0.2894338539668492, 'validation/ssim': 0.7029068259355655, 'validation/loss': 0.3024852883634637, 'validation/num_examples': 3554, 'test/ssim': 0.7200081321121893, 'test/loss': 0.3045262621954412, 'test/num_examples': 3581, 'score': 304.74686646461487, 'total_duration': 522.9672827720642, 'global_step': 813, 'preemption_count': 0}), (1086, {'train/ssim': 0.7280577932085309, 'train/loss': 0.28509203025272917, 'validation/ssim': 0.7095622340144907, 'validation/loss': 0.2984691956905951, 'validation/num_examples': 3554, 'test/ssim': 0.7266414485740715, 'test/loss': 0.3005181562630899, 'test/num_examples': 3581, 'score': 384.50658917427063, 'total_duration': 610.5784409046173, 'global_step': 1086, 'preemption_count': 0}), (1432, {'train/ssim': 0.7335294314793178, 'train/loss': 0.2808783565248762, 'validation/ssim': 0.7140534872678672, 'validation/loss': 0.29485400473058526, 'validation/num_examples': 3554, 'test/ssim': 0.7311093379118961, 'test/loss': 0.2967274316160814, 'test/num_examples': 3581, 'score': 464.1984872817993, 'total_duration': 695.577291727066, 'global_step': 1432, 'preemption_count': 0}), (1777, {'train/ssim': 0.7339840616498675, 'train/loss': 0.2825146062033517, 'validation/ssim': 0.7144467638796075, 'validation/loss': 0.2962989613925331, 'validation/num_examples': 3554, 'test/ssim': 0.7315916877923415, 'test/loss': 0.2981079749240785, 'test/num_examples': 3581, 'score': 543.9100804328918, 'total_duration': 780.0286550521851, 'global_step': 1777, 'preemption_count': 0}), (2121, {'train/ssim': 0.7358603477478027, 'train/loss': 0.2785645382744925, 'validation/ssim': 0.7173596212014631, 'validation/loss': 0.29272931495541993, 'validation/num_examples': 3554, 'test/ssim': 0.7343029372687447, 'test/loss': 0.29446481866098856, 'test/num_examples': 3581, 'score': 623.5573661327362, 'total_duration': 864.4040508270264, 'global_step': 2121, 'preemption_count': 0}), (2466, {'train/ssim': 0.7388007300240653, 'train/loss': 0.27636386666979107, 'validation/ssim': 0.7189413831686128, 'validation/loss': 0.2908437510991137, 'validation/num_examples': 3554, 'test/ssim': 0.7360017633211743, 'test/loss': 0.2925107732760577, 'test/num_examples': 3581, 'score': 703.4139199256897, 'total_duration': 948.98144698143, 'global_step': 2466, 'preemption_count': 0}), (2714, {'train/ssim': 0.7378334317888532, 'train/loss': 0.27656681197030203, 'validation/ssim': 0.7181664393333216, 'validation/loss': 0.290893760771314, 'validation/num_examples': 3554, 'test/ssim': 0.7352719321593131, 'test/loss': 0.29253293069106046, 'test/num_examples': 3581, 'score': 759.9367234706879, 'total_duration': 1010.1359317302704, 'global_step': 2714, 'preemption_count': 0})], 'global_step': 2714}
I0331 21:36:15.438684 139985821210432 submission_runner.py:553] Timing: 759.9367234706879
I0331 21:36:15.438732 139985821210432 submission_runner.py:554] ====================
I0331 21:36:15.438847 139985821210432 submission_runner.py:613] Final fastmri score: 759.9367234706879
