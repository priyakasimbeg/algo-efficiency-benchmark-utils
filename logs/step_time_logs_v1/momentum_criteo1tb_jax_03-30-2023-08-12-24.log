I0330 08:12:44.750179 140675314521920 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_momentum/criteo1tb_jax.
I0330 08:12:45.102640 140675314521920 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0330 08:12:51.310781 140675314521920 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0330 08:12:51.311552 140675314521920 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0330 08:12:51.318902 140675314521920 submission_runner.py:504] Using RNG seed 3605034319
I0330 08:12:54.411910 140675314521920 submission_runner.py:513] --- Tuning run 1/1 ---
I0330 08:12:54.412108 140675314521920 submission_runner.py:518] Creating tuning directory at /experiment_runs/timing_momentum/criteo1tb_jax/trial_1.
I0330 08:12:54.412293 140675314521920 logger_utils.py:84] Saving hparams to /experiment_runs/timing_momentum/criteo1tb_jax/trial_1/hparams.json.
I0330 08:12:54.554317 140675314521920 submission_runner.py:230] Starting train once: RAM USED (GB) 4.56032256
I0330 08:12:54.554489 140675314521920 submission_runner.py:231] Initializing dataset.
I0330 08:12:54.554669 140675314521920 submission_runner.py:239] After Initializing dataset: RAM USED (GB) 4.56032256
I0330 08:12:54.554732 140675314521920 submission_runner.py:240] Initializing model.
I0330 08:13:01.859715 140675314521920 submission_runner.py:251] After Initializing model: RAM USED (GB) 8.352780288
I0330 08:13:01.859971 140675314521920 submission_runner.py:252] Initializing optimizer.
I0330 08:13:03.715810 140675314521920 submission_runner.py:260] After Initializing metrics bundle: RAM USED (GB) 8.355688448
I0330 08:13:03.716010 140675314521920 submission_runner.py:261] Initializing metrics bundle.
I0330 08:13:03.716063 140675314521920 submission_runner.py:275] Initializing checkpoint and logger.
I0330 08:13:03.720158 140675314521920 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_momentum/criteo1tb_jax/trial_1 with prefix checkpoint_
I0330 08:13:03.720507 140675314521920 logger_utils.py:231] Unable to record workload.train_mean information. Continuing without it.
I0330 08:13:03.720733 140675314521920 logger_utils.py:231] Unable to record workload.train_stddev information. Continuing without it.
I0330 08:13:05.436566 140675314521920 submission_runner.py:296] Saving meta data to /experiment_runs/timing_momentum/criteo1tb_jax/trial_1/meta_data_0.json.
I0330 08:13:05.437608 140675314521920 submission_runner.py:299] Saving flags to /experiment_runs/timing_momentum/criteo1tb_jax/trial_1/flags_0.json.
I0330 08:13:05.480320 140675314521920 submission_runner.py:304] After checkpoint and logger metrics bundle: RAM USED (GB) 8.354091008
I0330 08:13:05.480572 140675314521920 submission_runner.py:311] Before starting training loop and logger metrics bundle: RAM USED (GB) 8.354091008
I0330 08:13:05.480649 140675314521920 submission_runner.py:312] Starting training loop.
I0330 08:15:32.665060 140675314521920 submission_runner.py:333] After dataselection batch at step 0: RAM USED (GB) 46.47483392
I0330 08:15:56.004898 140469606536960 logging_writer.py:48] [0] global_step=0, grad_norm=2.662496566772461, loss=0.45711833238601685
I0330 08:15:56.031728 140675314521920 submission_runner.py:350] After update parameters step 0: RAM USED (GB) 54.385594368
I0330 08:15:56.031980 140675314521920 submission_runner.py:371] Before eval at step 1: RAM USED (GB) 54.386110464
I0330 08:15:56.032107 140675314521920 spec.py:298] Evaluating on the training split.
I0330 08:26:04.308215 140675314521920 spec.py:310] Evaluating on the validation split.
I0330 08:30:27.619657 140675314521920 spec.py:326] Evaluating on the test split.
I0330 08:35:52.271116 140675314521920 submission_runner.py:380] Time since start: 170.55s, 	Step: 1, 	{'train/loss': 0.45697807441133187, 'validation/loss': 0.45916260674157305, 'validation/num_examples': 89000000, 'test/loss': 0.45875340831685485, 'test/num_examples': 89274637}
I0330 08:35:52.271683 140675314521920 submission_runner.py:390] After eval at step 1: RAM USED (GB) 95.890440192
I0330 08:35:52.291774 140415567132416 logging_writer.py:48] [1] global_step=1, preemption_count=0, score=170.335019, test/loss=0.458753, test/num_examples=89274637, total_duration=170.551409, train/loss=0.456978, validation/loss=0.459163, validation/num_examples=89000000
I0330 08:35:56.235570 140675314521920 checkpoints.py:356] Saving checkpoint at step: 1
I0330 08:36:18.877683 140675314521920 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_momentum/criteo1tb_jax/trial_1/checkpoint_1
I0330 08:36:19.159579 140675314521920 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/criteo1tb_jax/trial_1/checkpoint_1.
I0330 08:36:19.444214 140675314521920 submission_runner.py:409] After logging and checkpointing eval at step 1: RAM USED (GB) 95.962394624
I0330 08:36:19.450133 140675314521920 submission_runner.py:333] After dataselection batch at step 1: RAM USED (GB) 95.922622464
I0330 08:36:19.498953 140675314521920 submission_runner.py:350] After update parameters step 1: RAM USED (GB) 95.920914432
I0330 08:37:51.343452 140415558739712 logging_writer.py:48] [100] global_step=100, grad_norm=0.02708820253610611, loss=0.1390434205532074
I0330 08:39:54.936342 140415525168896 logging_writer.py:48] [200] global_step=200, grad_norm=0.008491519838571548, loss=0.13938331604003906
I0330 08:42:00.063038 140415558739712 logging_writer.py:48] [300] global_step=300, grad_norm=0.009787637740373611, loss=0.1380569040775299
I0330 08:44:05.797690 140415525168896 logging_writer.py:48] [400] global_step=400, grad_norm=0.008901388384401798, loss=0.13499628007411957
I0330 08:45:19.518678 140675314521920 submission_runner.py:371] Before eval at step 457: RAM USED (GB) 103.137521664
I0330 08:45:19.519410 140675314521920 spec.py:298] Evaluating on the training split.
I0330 08:56:08.794066 140675314521920 spec.py:310] Evaluating on the validation split.
I0330 08:59:55.476649 140675314521920 spec.py:326] Evaluating on the test split.
I0330 09:03:54.715908 140675314521920 submission_runner.py:380] Time since start: 1934.04s, 	Step: 457, 	{'train/loss': 0.1365845198136555, 'validation/loss': 0.13647526966292134, 'validation/num_examples': 89000000, 'test/loss': 0.13981768416487653, 'test/num_examples': 89274637}
I0330 09:03:54.716812 140675314521920 submission_runner.py:390] After eval at step 457: RAM USED (GB) 109.643370496
I0330 09:03:54.728185 140416045254400 logging_writer.py:48] [457] global_step=457, preemption_count=0, score=708.556725, test/loss=0.139818, test/num_examples=89274637, total_duration=1934.036970, train/loss=0.136585, validation/loss=0.136475, validation/num_examples=89000000
I0330 09:03:58.660031 140675314521920 checkpoints.py:356] Saving checkpoint at step: 457
I0330 09:04:20.980495 140675314521920 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_momentum/criteo1tb_jax/trial_1/checkpoint_457
I0330 09:04:21.264768 140675314521920 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/criteo1tb_jax/trial_1/checkpoint_457.
I0330 09:04:21.505517 140675314521920 submission_runner.py:409] After logging and checkpointing eval at step 457: RAM USED (GB) 109.782573056
I0330 09:04:47.674423 140416036861696 logging_writer.py:48] [500] global_step=500, grad_norm=0.028669780120253563, loss=0.13622401654720306
I0330 09:06:50.237937 140415994898176 logging_writer.py:48] [600] global_step=600, grad_norm=0.008777834475040436, loss=0.133816197514534
I0330 09:08:54.139310 140416036861696 logging_writer.py:48] [700] global_step=700, grad_norm=0.062068529427051544, loss=0.13353843986988068
I0330 09:11:04.668113 140675314521920 submission_runner.py:371] Before eval at step 800: RAM USED (GB) 110.416412672
I0330 09:11:04.668321 140675314521920 spec.py:298] Evaluating on the training split.
I0330 09:21:59.708933 140675314521920 spec.py:310] Evaluating on the validation split.
I0330 09:26:05.148696 140675314521920 spec.py:326] Evaluating on the test split.
I0330 09:30:56.349523 140675314521920 submission_runner.py:380] Time since start: 3479.19s, 	Step: 800, 	{'train/loss': 0.13333458861855568, 'validation/loss': 0.13360524719101124, 'validation/num_examples': 89000000, 'test/loss': 0.1363836853237499, 'test/num_examples': 89274637}
I0330 09:30:56.350114 140675314521920 submission_runner.py:390] After eval at step 800: RAM USED (GB) 114.050359296
I0330 09:30:56.358253 140407027521280 logging_writer.py:48] [800] global_step=800, preemption_count=0, score=1109.546932, test/loss=0.136384, test/num_examples=89274637, total_duration=3479.187283, train/loss=0.133335, validation/loss=0.133605, validation/num_examples=89000000
I0330 09:31:00.923635 140675314521920 checkpoints.py:356] Saving checkpoint at step: 800
I0330 09:31:27.934433 140675314521920 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_momentum/criteo1tb_jax/trial_1/checkpoint_800
I0330 09:31:28.269683 140675314521920 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/criteo1tb_jax/trial_1/checkpoint_800.
I0330 09:31:28.587035 140675314521920 submission_runner.py:409] After logging and checkpointing eval at step 800: RAM USED (GB) 114.095464448
I0330 09:31:28.594093 140407019128576 logging_writer.py:48] [800] global_step=800, preemption_count=0, score=1109.546932
I0330 09:31:33.007447 140675314521920 checkpoints.py:356] Saving checkpoint at step: 800
I0330 09:32:06.541530 140675314521920 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_momentum/criteo1tb_jax/trial_1/checkpoint_800
I0330 09:32:06.812715 140675314521920 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/criteo1tb_jax/trial_1/checkpoint_800.
I0330 09:33:43.111746 140675314521920 submission_runner.py:543] Tuning trial 1/1
I0330 09:33:43.113374 140675314521920 submission_runner.py:544] Hyperparameters: Hyperparameters(learning_rate=0.4394877561366806, one_minus_beta1=0.07113602458522507, warmup_factor=0.05, weight_decay=9.611851572925426e-07, label_smoothing=0.2, dropout_rate=0.0, decay_steps_factor=0.9, end_factor=0.001)
I0330 09:33:43.114753 140675314521920 submission_runner.py:545] Metrics: {'eval_results': [(1, {'train/loss': 0.45697807441133187, 'validation/loss': 0.45916260674157305, 'validation/num_examples': 89000000, 'test/loss': 0.45875340831685485, 'test/num_examples': 89274637, 'score': 170.33501887321472, 'total_duration': 170.55140852928162, 'global_step': 1, 'preemption_count': 0}), (457, {'train/loss': 0.1365845198136555, 'validation/loss': 0.13647526966292134, 'validation/num_examples': 89000000, 'test/loss': 0.13981768416487653, 'test/num_examples': 89274637, 'score': 708.5567247867584, 'total_duration': 1934.0369701385498, 'global_step': 457, 'preemption_count': 0}), (800, {'train/loss': 0.13333458861855568, 'validation/loss': 0.13360524719101124, 'validation/num_examples': 89000000, 'test/loss': 0.1363836853237499, 'test/num_examples': 89274637, 'score': 1109.5469319820404, 'total_duration': 3479.187282562256, 'global_step': 800, 'preemption_count': 0})], 'global_step': 800}
I0330 09:33:43.114889 140675314521920 submission_runner.py:546] Timing: 1109.5469319820404
I0330 09:33:43.114944 140675314521920 submission_runner.py:547] ====================
I0330 09:33:43.115076 140675314521920 submission_runner.py:606] Final criteo1tb score: 1109.5469319820404
