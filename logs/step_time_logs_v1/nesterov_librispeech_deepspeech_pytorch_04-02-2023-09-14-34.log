WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
I0402 09:14:49.624014 140033103284032 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 2
I0402 09:14:49.624044 140534331713344 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 7
I0402 09:14:49.624805 139891649652544 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 6
I0402 09:14:49.624857 139931352536896 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 5
I0402 09:14:49.624883 140345059444544 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 1
I0402 09:14:49.624904 140649644136256 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 4
I0402 09:14:49.625491 140005836134208 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 3
I0402 09:14:49.635556 140537578567488 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 0
I0402 09:14:49.635940 140537578567488 distributed_c10d.py:353] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0402 09:14:49.636024 140005836134208 distributed_c10d.py:353] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0402 09:14:49.645012 140033103284032 distributed_c10d.py:353] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0402 09:14:49.645037 140534331713344 distributed_c10d.py:353] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0402 09:14:49.645653 139931352536896 distributed_c10d.py:353] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0402 09:14:49.645636 139891649652544 distributed_c10d.py:353] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0402 09:14:49.645678 140345059444544 distributed_c10d.py:353] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0402 09:14:49.645709 140649644136256 distributed_c10d.py:353] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0402 09:14:50.022038 140537578567488 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_nesterov/librispeech_deepspeech_pytorch.
W0402 09:14:50.069821 140649644136256 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0402 09:14:50.070394 140534331713344 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0402 09:14:50.070980 140345059444544 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0402 09:14:50.071639 140005836134208 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0402 09:14:50.072353 139891649652544 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0402 09:14:50.073207 139931352536896 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0402 09:14:50.073820 140033103284032 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0402 09:14:50.094102 140537578567488 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0402 09:14:50.097908 140537578567488 submission_runner.py:511] Using RNG seed 437424242
I0402 09:14:50.099053 140537578567488 submission_runner.py:520] --- Tuning run 1/1 ---
I0402 09:14:50.099179 140537578567488 submission_runner.py:525] Creating tuning directory at /experiment_runs/timing_nesterov/librispeech_deepspeech_pytorch/trial_1.
I0402 09:14:50.099466 140537578567488 logger_utils.py:84] Saving hparams to /experiment_runs/timing_nesterov/librispeech_deepspeech_pytorch/trial_1/hparams.json.
I0402 09:14:50.100463 140537578567488 submission_runner.py:230] Starting train once: RAM USED (GB) 5.76239616
I0402 09:14:50.100584 140537578567488 submission_runner.py:231] Initializing dataset.
I0402 09:14:50.100677 140537578567488 input_pipeline.py:20] Loading split = train-clean-100
I0402 09:14:50.128040 140537578567488 input_pipeline.py:20] Loading split = train-clean-360
I0402 09:14:50.446661 140537578567488 input_pipeline.py:20] Loading split = train-other-500
I0402 09:14:50.862152 140537578567488 submission_runner.py:239] After Initializing dataset: RAM USED (GB) 5.978902528
I0402 09:14:50.862323 140537578567488 submission_runner.py:240] Initializing model.
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
I0402 09:14:57.899030 140537578567488 submission_runner.py:251] After Initializing model: RAM USED (GB) 21.68799232
I0402 09:14:57.899273 140537578567488 submission_runner.py:252] Initializing optimizer.
I0402 09:14:58.077865 140537578567488 submission_runner.py:260] After Initializing metrics bundle: RAM USED (GB) 21.345140736
I0402 09:14:58.078043 140537578567488 submission_runner.py:261] Initializing metrics bundle.
I0402 09:14:58.078093 140537578567488 submission_runner.py:276] Initializing checkpoint and logger.
I0402 09:14:58.079718 140537578567488 logger_utils.py:231] Unable to record workload.train_mean information. Continuing without it.
I0402 09:14:58.079852 140537578567488 logger_utils.py:231] Unable to record workload.train_stddev information. Continuing without it.
I0402 09:14:58.904582 140537578567488 submission_runner.py:297] Saving meta data to /experiment_runs/timing_nesterov/librispeech_deepspeech_pytorch/trial_1/meta_data_0.json.
I0402 09:14:58.905595 140537578567488 submission_runner.py:300] Saving flags to /experiment_runs/timing_nesterov/librispeech_deepspeech_pytorch/trial_1/flags_0.json.
I0402 09:14:58.908928 140537578567488 submission_runner.py:305] After checkpoint and logger metrics bundle: RAM USED (GB) 21.352251392
I0402 09:14:58.910012 140537578567488 submission_runner.py:312] Before starting training loop and logger metrics bundle: RAM USED (GB) 21.352251392
I0402 09:14:58.910110 140537578567488 submission_runner.py:313] Starting training loop.
I0402 09:15:01.339346 140537578567488 submission_runner.py:335] After dataselection batch at step 0: RAM USED (GB) 25.810870272
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
I0402 09:15:07.724534 140511324591872 logging_writer.py:48] [0] global_step=0, grad_norm=40.502945, loss=33.587543
I0402 09:15:07.734220 140537578567488 submission.py:139] 0) loss = 33.588, grad_norm = 40.503
I0402 09:15:07.734896 140537578567488 submission_runner.py:352] After update parameters step 0: RAM USED (GB) 31.581863936
I0402 09:15:07.735455 140537578567488 submission_runner.py:373] Before eval at step 1: RAM USED (GB) 31.581863936
I0402 09:15:07.735569 140537578567488 spec.py:298] Evaluating on the training split.
I0402 09:15:07.736327 140537578567488 input_pipeline.py:20] Loading split = train-clean-100
I0402 09:15:07.764649 140537578567488 input_pipeline.py:20] Loading split = train-clean-360
I0402 09:15:08.175134 140537578567488 input_pipeline.py:20] Loading split = train-other-500
I0402 09:15:25.054924 140537578567488 spec.py:310] Evaluating on the validation split.
I0402 09:15:25.056078 140537578567488 input_pipeline.py:20] Loading split = dev-clean
I0402 09:15:25.060211 140537578567488 input_pipeline.py:20] Loading split = dev-other
I0402 09:15:36.586930 140537578567488 spec.py:326] Evaluating on the test split.
I0402 09:15:36.588122 140537578567488 input_pipeline.py:20] Loading split = test-clean
I0402 09:15:43.591884 140537578567488 submission_runner.py:382] Time since start: 8.83s, 	Step: 1, 	{'train/ctc_loss': 31.137516905599135, 'train/wer': 4.544677422843177, 'validation/ctc_loss': 30.265232569821176, 'validation/wer': 4.218790131801284, 'validation/num_examples': 5348, 'test/ctc_loss': 30.369614168656042, 'test/wer': 4.463429000873398, 'test/num_examples': 2472}
I0402 09:15:43.592628 140537578567488 submission_runner.py:396] After eval at step 1: RAM USED (GB) 45.574488064
I0402 09:15:43.605391 140509276268288 logging_writer.py:48] [1] global_step=1, preemption_count=0, score=8.823963, test/ctc_loss=30.369614, test/num_examples=2472, test/wer=4.463429, total_duration=8.825969, train/ctc_loss=31.137517, train/wer=4.544677, validation/ctc_loss=30.265233, validation/num_examples=5348, validation/wer=4.218790
I0402 09:15:43.796205 140537578567488 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nesterov/librispeech_deepspeech_pytorch/trial_1/checkpoint_1.
I0402 09:15:43.796695 140537578567488 submission_runner.py:416] After logging and checkpointing eval at step 1: RAM USED (GB) 45.604777984
I0402 09:15:43.800111 140537578567488 submission_runner.py:335] After dataselection batch at step 1: RAM USED (GB) 45.61235968
I0402 09:15:43.839904 140345059444544 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0402 09:15:43.840638 140537578567488 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0402 09:15:43.841494 139931352536896 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0402 09:15:43.841504 139891649652544 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0402 09:15:43.842259 140649644136256 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0402 09:15:43.842299 140033103284032 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0402 09:15:43.842300 140005836134208 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0402 09:15:43.842272 140534331713344 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0402 09:15:44.883465 140509267875584 logging_writer.py:48] [1] global_step=1, grad_norm=42.501823, loss=32.947117
I0402 09:15:44.886529 140537578567488 submission.py:139] 1) loss = 32.947, grad_norm = 42.502
I0402 09:15:44.887216 140537578567488 submission_runner.py:352] After update parameters step 1: RAM USED (GB) 45.79837952
I0402 09:15:45.852881 140509276268288 logging_writer.py:48] [2] global_step=2, grad_norm=54.106670, loss=33.210766
I0402 09:15:45.855893 140537578567488 submission.py:139] 2) loss = 33.211, grad_norm = 54.107
I0402 09:15:46.679839 140509267875584 logging_writer.py:48] [3] global_step=3, grad_norm=58.500683, loss=32.110287
I0402 09:15:46.682801 140537578567488 submission.py:139] 3) loss = 32.110, grad_norm = 58.501
I0402 09:15:47.493386 140509276268288 logging_writer.py:48] [4] global_step=4, grad_norm=52.289482, loss=29.848692
I0402 09:15:47.496455 140537578567488 submission.py:139] 4) loss = 29.849, grad_norm = 52.289
I0402 09:15:48.309277 140509267875584 logging_writer.py:48] [5] global_step=5, grad_norm=32.639446, loss=28.458033
I0402 09:15:48.312598 140537578567488 submission.py:139] 5) loss = 28.458, grad_norm = 32.639
I0402 09:15:49.139067 140509276268288 logging_writer.py:48] [6] global_step=6, grad_norm=24.472525, loss=27.497293
I0402 09:15:49.142908 140537578567488 submission.py:139] 6) loss = 27.497, grad_norm = 24.473
I0402 09:15:49.968089 140509267875584 logging_writer.py:48] [7] global_step=7, grad_norm=22.458403, loss=25.697058
I0402 09:15:49.971369 140537578567488 submission.py:139] 7) loss = 25.697, grad_norm = 22.458
I0402 09:15:50.787944 140509276268288 logging_writer.py:48] [8] global_step=8, grad_norm=22.479815, loss=25.145277
I0402 09:15:50.791577 140537578567488 submission.py:139] 8) loss = 25.145, grad_norm = 22.480
I0402 09:15:51.603011 140509267875584 logging_writer.py:48] [9] global_step=9, grad_norm=21.508039, loss=23.921854
I0402 09:15:51.606178 140537578567488 submission.py:139] 9) loss = 23.922, grad_norm = 21.508
I0402 09:15:52.423698 140509276268288 logging_writer.py:48] [10] global_step=10, grad_norm=21.106693, loss=22.678080
I0402 09:15:52.426905 140537578567488 submission.py:139] 10) loss = 22.678, grad_norm = 21.107
I0402 09:15:53.231707 140509267875584 logging_writer.py:48] [11] global_step=11, grad_norm=21.364807, loss=21.689775
I0402 09:15:53.234618 140537578567488 submission.py:139] 11) loss = 21.690, grad_norm = 21.365
I0402 09:15:54.050726 140509276268288 logging_writer.py:48] [12] global_step=12, grad_norm=23.155993, loss=20.192883
I0402 09:15:54.053687 140537578567488 submission.py:139] 12) loss = 20.193, grad_norm = 23.156
I0402 09:15:54.864403 140509267875584 logging_writer.py:48] [13] global_step=13, grad_norm=20.669060, loss=18.440201
I0402 09:15:54.867488 140537578567488 submission.py:139] 13) loss = 18.440, grad_norm = 20.669
I0402 09:15:55.681254 140509276268288 logging_writer.py:48] [14] global_step=14, grad_norm=19.818983, loss=16.789282
I0402 09:15:55.684361 140537578567488 submission.py:139] 14) loss = 16.789, grad_norm = 19.819
I0402 09:15:56.490075 140509267875584 logging_writer.py:48] [15] global_step=15, grad_norm=19.301502, loss=15.127424
I0402 09:15:56.493340 140537578567488 submission.py:139] 15) loss = 15.127, grad_norm = 19.302
I0402 09:15:57.301649 140509276268288 logging_writer.py:48] [16] global_step=16, grad_norm=16.084797, loss=13.660585
I0402 09:15:57.304981 140537578567488 submission.py:139] 16) loss = 13.661, grad_norm = 16.085
I0402 09:15:58.110734 140509267875584 logging_writer.py:48] [17] global_step=17, grad_norm=15.222923, loss=12.214297
I0402 09:15:58.114447 140537578567488 submission.py:139] 17) loss = 12.214, grad_norm = 15.223
I0402 09:15:58.926178 140509276268288 logging_writer.py:48] [18] global_step=18, grad_norm=11.992000, loss=10.869390
I0402 09:15:58.929408 140537578567488 submission.py:139] 18) loss = 10.869, grad_norm = 11.992
I0402 09:15:59.736854 140509267875584 logging_writer.py:48] [19] global_step=19, grad_norm=7.524808, loss=10.520450
I0402 09:15:59.739852 140537578567488 submission.py:139] 19) loss = 10.520, grad_norm = 7.525
I0402 09:16:00.551835 140509276268288 logging_writer.py:48] [20] global_step=20, grad_norm=7.168898, loss=10.091428
I0402 09:16:00.554795 140537578567488 submission.py:139] 20) loss = 10.091, grad_norm = 7.169
I0402 09:16:01.364657 140509267875584 logging_writer.py:48] [21] global_step=21, grad_norm=8.147484, loss=9.901535
I0402 09:16:01.367603 140537578567488 submission.py:139] 21) loss = 9.902, grad_norm = 8.147
I0402 09:16:02.174243 140509276268288 logging_writer.py:48] [22] global_step=22, grad_norm=8.945024, loss=9.780844
I0402 09:16:02.178091 140537578567488 submission.py:139] 22) loss = 9.781, grad_norm = 8.945
I0402 09:16:02.985850 140509267875584 logging_writer.py:48] [23] global_step=23, grad_norm=8.757363, loss=9.517066
I0402 09:16:02.988967 140537578567488 submission.py:139] 23) loss = 9.517, grad_norm = 8.757
I0402 09:16:03.802600 140509276268288 logging_writer.py:48] [24] global_step=24, grad_norm=8.189117, loss=9.461378
I0402 09:16:03.805948 140537578567488 submission.py:139] 24) loss = 9.461, grad_norm = 8.189
I0402 09:16:04.615735 140509267875584 logging_writer.py:48] [25] global_step=25, grad_norm=12.926675, loss=9.340908
I0402 09:16:04.618901 140537578567488 submission.py:139] 25) loss = 9.341, grad_norm = 12.927
I0402 09:16:05.434767 140509276268288 logging_writer.py:48] [26] global_step=26, grad_norm=8.672099, loss=8.923364
I0402 09:16:05.437740 140537578567488 submission.py:139] 26) loss = 8.923, grad_norm = 8.672
I0402 09:16:06.254486 140509267875584 logging_writer.py:48] [27] global_step=27, grad_norm=10.217488, loss=8.968354
I0402 09:16:06.257750 140537578567488 submission.py:139] 27) loss = 8.968, grad_norm = 10.217
I0402 09:16:07.082670 140509276268288 logging_writer.py:48] [28] global_step=28, grad_norm=17.207598, loss=8.620506
I0402 09:16:07.086653 140537578567488 submission.py:139] 28) loss = 8.621, grad_norm = 17.208
I0402 09:16:07.900182 140509267875584 logging_writer.py:48] [29] global_step=29, grad_norm=11.966259, loss=8.695718
I0402 09:16:07.903878 140537578567488 submission.py:139] 29) loss = 8.696, grad_norm = 11.966
I0402 09:16:08.717325 140509276268288 logging_writer.py:48] [30] global_step=30, grad_norm=10.397767, loss=8.126503
I0402 09:16:08.721205 140537578567488 submission.py:139] 30) loss = 8.127, grad_norm = 10.398
I0402 09:16:09.551869 140509267875584 logging_writer.py:48] [31] global_step=31, grad_norm=30.629190, loss=8.139607
I0402 09:16:09.554992 140537578567488 submission.py:139] 31) loss = 8.140, grad_norm = 30.629
I0402 09:16:10.364779 140509276268288 logging_writer.py:48] [32] global_step=32, grad_norm=9.847054, loss=8.175089
I0402 09:16:10.368732 140537578567488 submission.py:139] 32) loss = 8.175, grad_norm = 9.847
I0402 09:16:11.185995 140509267875584 logging_writer.py:48] [33] global_step=33, grad_norm=5.991156, loss=8.155941
I0402 09:16:11.189371 140537578567488 submission.py:139] 33) loss = 8.156, grad_norm = 5.991
I0402 09:16:12.005882 140509276268288 logging_writer.py:48] [34] global_step=34, grad_norm=8.204387, loss=8.195774
I0402 09:16:12.008897 140537578567488 submission.py:139] 34) loss = 8.196, grad_norm = 8.204
I0402 09:16:12.831947 140509267875584 logging_writer.py:48] [35] global_step=35, grad_norm=4.901880, loss=7.999581
I0402 09:16:12.835110 140537578567488 submission.py:139] 35) loss = 8.000, grad_norm = 4.902
I0402 09:16:13.654748 140509276268288 logging_writer.py:48] [36] global_step=36, grad_norm=4.299469, loss=7.829454
I0402 09:16:13.658631 140537578567488 submission.py:139] 36) loss = 7.829, grad_norm = 4.299
I0402 09:16:14.470183 140509267875584 logging_writer.py:48] [37] global_step=37, grad_norm=3.595408, loss=7.523653
I0402 09:16:14.473647 140537578567488 submission.py:139] 37) loss = 7.524, grad_norm = 3.595
I0402 09:16:15.296207 140509276268288 logging_writer.py:48] [38] global_step=38, grad_norm=5.347249, loss=7.704041
I0402 09:16:15.300205 140537578567488 submission.py:139] 38) loss = 7.704, grad_norm = 5.347
I0402 09:16:16.115700 140509267875584 logging_writer.py:48] [39] global_step=39, grad_norm=4.754379, loss=7.459793
I0402 09:16:16.119494 140537578567488 submission.py:139] 39) loss = 7.460, grad_norm = 4.754
I0402 09:16:16.946728 140509276268288 logging_writer.py:48] [40] global_step=40, grad_norm=4.294031, loss=7.298482
I0402 09:16:16.949994 140537578567488 submission.py:139] 40) loss = 7.298, grad_norm = 4.294
I0402 09:16:17.763358 140509267875584 logging_writer.py:48] [41] global_step=41, grad_norm=2.890620, loss=7.173264
I0402 09:16:17.766540 140537578567488 submission.py:139] 41) loss = 7.173, grad_norm = 2.891
I0402 09:16:18.584397 140509276268288 logging_writer.py:48] [42] global_step=42, grad_norm=13.723100, loss=7.136708
I0402 09:16:18.587372 140537578567488 submission.py:139] 42) loss = 7.137, grad_norm = 13.723
I0402 09:16:19.394376 140509267875584 logging_writer.py:48] [43] global_step=43, grad_norm=15.267488, loss=7.634483
I0402 09:16:19.398075 140537578567488 submission.py:139] 43) loss = 7.634, grad_norm = 15.267
I0402 09:16:20.214114 140509276268288 logging_writer.py:48] [44] global_step=44, grad_norm=4.640283, loss=7.001131
I0402 09:16:20.217629 140537578567488 submission.py:139] 44) loss = 7.001, grad_norm = 4.640
I0402 09:16:21.030722 140509267875584 logging_writer.py:48] [45] global_step=45, grad_norm=3.831591, loss=6.953573
I0402 09:16:21.034012 140537578567488 submission.py:139] 45) loss = 6.954, grad_norm = 3.832
I0402 09:16:21.845767 140509276268288 logging_writer.py:48] [46] global_step=46, grad_norm=9.876790, loss=6.957489
I0402 09:16:21.848907 140537578567488 submission.py:139] 46) loss = 6.957, grad_norm = 9.877
I0402 09:16:22.661370 140509267875584 logging_writer.py:48] [47] global_step=47, grad_norm=11.271112, loss=7.050863
I0402 09:16:22.664685 140537578567488 submission.py:139] 47) loss = 7.051, grad_norm = 11.271
I0402 09:16:23.474059 140509276268288 logging_writer.py:48] [48] global_step=48, grad_norm=10.155218, loss=6.966236
I0402 09:16:23.477439 140537578567488 submission.py:139] 48) loss = 6.966, grad_norm = 10.155
I0402 09:16:24.285009 140509267875584 logging_writer.py:48] [49] global_step=49, grad_norm=9.691640, loss=6.981205
I0402 09:16:24.288387 140537578567488 submission.py:139] 49) loss = 6.981, grad_norm = 9.692
I0402 09:16:25.095019 140509276268288 logging_writer.py:48] [50] global_step=50, grad_norm=7.202585, loss=6.729143
I0402 09:16:25.097934 140537578567488 submission.py:139] 50) loss = 6.729, grad_norm = 7.203
I0402 09:16:25.908495 140509267875584 logging_writer.py:48] [51] global_step=51, grad_norm=7.336274, loss=6.735724
I0402 09:16:25.911824 140537578567488 submission.py:139] 51) loss = 6.736, grad_norm = 7.336
I0402 09:16:26.717469 140509276268288 logging_writer.py:48] [52] global_step=52, grad_norm=11.966963, loss=6.717729
I0402 09:16:26.721323 140537578567488 submission.py:139] 52) loss = 6.718, grad_norm = 11.967
I0402 09:16:27.530858 140509267875584 logging_writer.py:48] [53] global_step=53, grad_norm=8.520175, loss=6.831228
I0402 09:16:27.534802 140537578567488 submission.py:139] 53) loss = 6.831, grad_norm = 8.520
I0402 09:16:28.347852 140509276268288 logging_writer.py:48] [54] global_step=54, grad_norm=4.503717, loss=6.608173
I0402 09:16:28.351730 140537578567488 submission.py:139] 54) loss = 6.608, grad_norm = 4.504
I0402 09:16:29.160813 140509267875584 logging_writer.py:48] [55] global_step=55, grad_norm=4.646183, loss=6.545658
I0402 09:16:29.164006 140537578567488 submission.py:139] 55) loss = 6.546, grad_norm = 4.646
I0402 09:16:29.988990 140509276268288 logging_writer.py:48] [56] global_step=56, grad_norm=3.996489, loss=6.459289
I0402 09:16:29.993152 140537578567488 submission.py:139] 56) loss = 6.459, grad_norm = 3.996
I0402 09:16:30.801238 140509267875584 logging_writer.py:48] [57] global_step=57, grad_norm=4.868906, loss=6.491530
I0402 09:16:30.804595 140537578567488 submission.py:139] 57) loss = 6.492, grad_norm = 4.869
I0402 09:16:31.611971 140509276268288 logging_writer.py:48] [58] global_step=58, grad_norm=5.680350, loss=6.504106
I0402 09:16:31.615779 140537578567488 submission.py:139] 58) loss = 6.504, grad_norm = 5.680
I0402 09:16:32.423115 140509267875584 logging_writer.py:48] [59] global_step=59, grad_norm=6.076845, loss=6.493145
I0402 09:16:32.426953 140537578567488 submission.py:139] 59) loss = 6.493, grad_norm = 6.077
I0402 09:16:33.234900 140509276268288 logging_writer.py:48] [60] global_step=60, grad_norm=5.383866, loss=6.395311
I0402 09:16:33.238636 140537578567488 submission.py:139] 60) loss = 6.395, grad_norm = 5.384
I0402 09:16:34.053308 140509267875584 logging_writer.py:48] [61] global_step=61, grad_norm=7.342167, loss=6.390764
I0402 09:16:34.056715 140537578567488 submission.py:139] 61) loss = 6.391, grad_norm = 7.342
I0402 09:16:34.867836 140509276268288 logging_writer.py:48] [62] global_step=62, grad_norm=8.449551, loss=6.439125
I0402 09:16:34.871527 140537578567488 submission.py:139] 62) loss = 6.439, grad_norm = 8.450
I0402 09:16:35.679881 140509267875584 logging_writer.py:48] [63] global_step=63, grad_norm=9.393739, loss=6.435898
I0402 09:16:35.683519 140537578567488 submission.py:139] 63) loss = 6.436, grad_norm = 9.394
I0402 09:16:36.493165 140509276268288 logging_writer.py:48] [64] global_step=64, grad_norm=10.502565, loss=6.462157
I0402 09:16:36.496937 140537578567488 submission.py:139] 64) loss = 6.462, grad_norm = 10.503
I0402 09:16:37.310569 140509267875584 logging_writer.py:48] [65] global_step=65, grad_norm=15.509775, loss=6.519484
I0402 09:16:37.314083 140537578567488 submission.py:139] 65) loss = 6.519, grad_norm = 15.510
I0402 09:16:38.128241 140509276268288 logging_writer.py:48] [66] global_step=66, grad_norm=15.051435, loss=6.768486
I0402 09:16:38.131304 140537578567488 submission.py:139] 66) loss = 6.768, grad_norm = 15.051
I0402 09:16:38.941635 140509267875584 logging_writer.py:48] [67] global_step=67, grad_norm=13.175078, loss=6.746325
I0402 09:16:38.944749 140537578567488 submission.py:139] 67) loss = 6.746, grad_norm = 13.175
I0402 09:16:39.755089 140509276268288 logging_writer.py:48] [68] global_step=68, grad_norm=8.186122, loss=6.403595
I0402 09:16:39.758257 140537578567488 submission.py:139] 68) loss = 6.404, grad_norm = 8.186
I0402 09:16:40.580050 140509267875584 logging_writer.py:48] [69] global_step=69, grad_norm=9.582539, loss=6.400972
I0402 09:16:40.582992 140537578567488 submission.py:139] 69) loss = 6.401, grad_norm = 9.583
I0402 09:16:41.392953 140509276268288 logging_writer.py:48] [70] global_step=70, grad_norm=9.811301, loss=6.344574
I0402 09:16:41.396175 140537578567488 submission.py:139] 70) loss = 6.345, grad_norm = 9.811
I0402 09:16:42.203175 140509267875584 logging_writer.py:48] [71] global_step=71, grad_norm=37.301537, loss=7.055266
I0402 09:16:42.206797 140537578567488 submission.py:139] 71) loss = 7.055, grad_norm = 37.302
I0402 09:16:43.018176 140509276268288 logging_writer.py:48] [72] global_step=72, grad_norm=27.730433, loss=8.229527
I0402 09:16:43.021437 140537578567488 submission.py:139] 72) loss = 8.230, grad_norm = 27.730
I0402 09:16:43.830015 140509267875584 logging_writer.py:48] [73] global_step=73, grad_norm=15.661822, loss=7.762355
I0402 09:16:43.833208 140537578567488 submission.py:139] 73) loss = 7.762, grad_norm = 15.662
I0402 09:16:44.650012 140509276268288 logging_writer.py:48] [74] global_step=74, grad_norm=9.043645, loss=6.773018
I0402 09:16:44.653327 140537578567488 submission.py:139] 74) loss = 6.773, grad_norm = 9.044
I0402 09:16:45.471385 140509267875584 logging_writer.py:48] [75] global_step=75, grad_norm=13.478264, loss=6.955745
I0402 09:16:45.474570 140537578567488 submission.py:139] 75) loss = 6.956, grad_norm = 13.478
I0402 09:16:46.290940 140509276268288 logging_writer.py:48] [76] global_step=76, grad_norm=11.621243, loss=7.016208
I0402 09:16:46.293961 140537578567488 submission.py:139] 76) loss = 7.016, grad_norm = 11.621
I0402 09:16:47.110260 140509267875584 logging_writer.py:48] [77] global_step=77, grad_norm=10.081502, loss=6.951933
I0402 09:16:47.114026 140537578567488 submission.py:139] 77) loss = 6.952, grad_norm = 10.082
I0402 09:16:47.930922 140509276268288 logging_writer.py:48] [78] global_step=78, grad_norm=9.446807, loss=6.918657
I0402 09:16:47.934647 140537578567488 submission.py:139] 78) loss = 6.919, grad_norm = 9.447
I0402 09:16:48.747275 140509267875584 logging_writer.py:48] [79] global_step=79, grad_norm=10.713833, loss=6.738648
I0402 09:16:48.750744 140537578567488 submission.py:139] 79) loss = 6.739, grad_norm = 10.714
I0402 09:16:49.575568 140509276268288 logging_writer.py:48] [80] global_step=80, grad_norm=11.781215, loss=7.036211
I0402 09:16:49.578640 140537578567488 submission.py:139] 80) loss = 7.036, grad_norm = 11.781
I0402 09:16:50.426233 140509267875584 logging_writer.py:48] [81] global_step=81, grad_norm=11.631373, loss=6.832246
I0402 09:16:50.429548 140537578567488 submission.py:139] 81) loss = 6.832, grad_norm = 11.631
I0402 09:16:51.239639 140509276268288 logging_writer.py:48] [82] global_step=82, grad_norm=10.917840, loss=6.849286
I0402 09:16:51.242792 140537578567488 submission.py:139] 82) loss = 6.849, grad_norm = 10.918
I0402 09:16:52.055732 140509267875584 logging_writer.py:48] [83] global_step=83, grad_norm=11.491461, loss=6.744359
I0402 09:16:52.059559 140537578567488 submission.py:139] 83) loss = 6.744, grad_norm = 11.491
I0402 09:16:52.876675 140509276268288 logging_writer.py:48] [84] global_step=84, grad_norm=12.759422, loss=6.756699
I0402 09:16:52.880455 140537578567488 submission.py:139] 84) loss = 6.757, grad_norm = 12.759
I0402 09:16:53.692171 140509267875584 logging_writer.py:48] [85] global_step=85, grad_norm=11.638423, loss=6.788548
I0402 09:16:53.695449 140537578567488 submission.py:139] 85) loss = 6.789, grad_norm = 11.638
I0402 09:16:54.507603 140509276268288 logging_writer.py:48] [86] global_step=86, grad_norm=8.959454, loss=6.560024
I0402 09:16:54.511024 140537578567488 submission.py:139] 86) loss = 6.560, grad_norm = 8.959
I0402 09:16:55.319895 140509267875584 logging_writer.py:48] [87] global_step=87, grad_norm=7.372626, loss=6.649190
I0402 09:16:55.322895 140537578567488 submission.py:139] 87) loss = 6.649, grad_norm = 7.373
I0402 09:16:56.133523 140509276268288 logging_writer.py:48] [88] global_step=88, grad_norm=7.112632, loss=6.395422
I0402 09:16:56.136708 140537578567488 submission.py:139] 88) loss = 6.395, grad_norm = 7.113
I0402 09:16:56.962343 140509267875584 logging_writer.py:48] [89] global_step=89, grad_norm=6.209799, loss=6.338760
I0402 09:16:56.965460 140537578567488 submission.py:139] 89) loss = 6.339, grad_norm = 6.210
I0402 09:16:57.781960 140509276268288 logging_writer.py:48] [90] global_step=90, grad_norm=4.712806, loss=6.294488
I0402 09:16:57.784940 140537578567488 submission.py:139] 90) loss = 6.294, grad_norm = 4.713
I0402 09:16:58.606262 140509267875584 logging_writer.py:48] [91] global_step=91, grad_norm=2.591531, loss=6.271523
I0402 09:16:58.609498 140537578567488 submission.py:139] 91) loss = 6.272, grad_norm = 2.592
I0402 09:16:59.430145 140509276268288 logging_writer.py:48] [92] global_step=92, grad_norm=2.246319, loss=6.257390
I0402 09:16:59.433497 140537578567488 submission.py:139] 92) loss = 6.257, grad_norm = 2.246
I0402 09:17:00.253891 140509267875584 logging_writer.py:48] [93] global_step=93, grad_norm=2.703698, loss=6.325864
I0402 09:17:00.257877 140537578567488 submission.py:139] 93) loss = 6.326, grad_norm = 2.704
I0402 09:17:01.079985 140509276268288 logging_writer.py:48] [94] global_step=94, grad_norm=2.553541, loss=6.224276
I0402 09:17:01.083260 140537578567488 submission.py:139] 94) loss = 6.224, grad_norm = 2.554
I0402 09:17:01.912137 140509267875584 logging_writer.py:48] [95] global_step=95, grad_norm=2.094884, loss=6.204294
I0402 09:17:01.915599 140537578567488 submission.py:139] 95) loss = 6.204, grad_norm = 2.095
I0402 09:17:02.761001 140509276268288 logging_writer.py:48] [96] global_step=96, grad_norm=3.116396, loss=6.243673
I0402 09:17:02.764017 140537578567488 submission.py:139] 96) loss = 6.244, grad_norm = 3.116
I0402 09:17:03.583760 140509267875584 logging_writer.py:48] [97] global_step=97, grad_norm=4.288807, loss=6.145355
I0402 09:17:03.587003 140537578567488 submission.py:139] 97) loss = 6.145, grad_norm = 4.289
I0402 09:17:04.406957 140509276268288 logging_writer.py:48] [98] global_step=98, grad_norm=6.486951, loss=6.226402
I0402 09:17:04.410772 140537578567488 submission.py:139] 98) loss = 6.226, grad_norm = 6.487
I0402 09:17:05.222683 140509267875584 logging_writer.py:48] [99] global_step=99, grad_norm=7.255412, loss=6.236018
I0402 09:17:05.225972 140537578567488 submission.py:139] 99) loss = 6.236, grad_norm = 7.255
I0402 09:17:06.050257 140509276268288 logging_writer.py:48] [100] global_step=100, grad_norm=6.950500, loss=6.196502
I0402 09:17:06.053486 140537578567488 submission.py:139] 100) loss = 6.197, grad_norm = 6.951
I0402 09:22:29.263150 140509267875584 logging_writer.py:48] [500] global_step=500, grad_norm=0.583780, loss=5.775786
I0402 09:22:29.268092 140537578567488 submission.py:139] 500) loss = 5.776, grad_norm = 0.584
I0402 09:29:13.488847 140509276268288 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.036649, loss=4.435672
I0402 09:29:13.493174 140537578567488 submission.py:139] 1000) loss = 4.436, grad_norm = 1.037
I0402 09:35:58.676311 140509276268288 logging_writer.py:48] [1500] global_step=1500, grad_norm=1.875065, loss=3.564779
I0402 09:35:58.683973 140537578567488 submission.py:139] 1500) loss = 3.565, grad_norm = 1.875
I0402 09:42:42.260525 140509267875584 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.941173, loss=2.976169
I0402 09:42:42.265679 140537578567488 submission.py:139] 2000) loss = 2.976, grad_norm = 0.941
I0402 09:49:26.653488 140509267875584 logging_writer.py:48] [2500] global_step=2500, grad_norm=1.045918, loss=2.823075
I0402 09:49:26.660369 140537578567488 submission.py:139] 2500) loss = 2.823, grad_norm = 1.046
I0402 09:55:44.364998 140537578567488 submission_runner.py:373] Before eval at step 2969: RAM USED (GB) 43.676188672
I0402 09:55:44.371364 140537578567488 spec.py:298] Evaluating on the training split.
I0402 09:55:54.857402 140537578567488 spec.py:310] Evaluating on the validation split.
I0402 09:56:04.078769 140537578567488 spec.py:326] Evaluating on the test split.
I0402 09:56:09.218793 140537578567488 submission_runner.py:382] Time since start: 2445.14s, 	Step: 2969, 	{'train/ctc_loss': 2.3222000101433595, 'train/wer': 0.6059486990937993, 'validation/ctc_loss': 2.5587522917922443, 'validation/wer': 0.6162120407473567, 'validation/num_examples': 5348, 'test/ctc_loss': 2.050158679592232, 'test/wer': 0.5463611805090082, 'test/num_examples': 2472}
I0402 09:56:09.219526 140537578567488 submission_runner.py:396] After eval at step 2969: RAM USED (GB) 42.155450368
I0402 09:56:09.238058 140509267875584 logging_writer.py:48] [2969] global_step=2969, preemption_count=0, score=1470.955144, test/ctc_loss=2.050159, test/num_examples=2472, test/wer=0.546361, total_duration=2445.137491, train/ctc_loss=2.322200, train/wer=0.605949, validation/ctc_loss=2.558752, validation/num_examples=5348, validation/wer=0.616212
I0402 09:56:09.442047 140537578567488 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nesterov/librispeech_deepspeech_pytorch/trial_1/checkpoint_2969.
I0402 09:56:09.442563 140537578567488 submission_runner.py:416] After logging and checkpointing eval at step 2969: RAM USED (GB) 42.160119808
I0402 09:56:35.381158 140508613572352 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.959284, loss=2.713706
I0402 09:56:35.384560 140537578567488 submission.py:139] 3000) loss = 2.714, grad_norm = 0.959
I0402 10:03:21.318868 140508613572352 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.892681, loss=2.538643
I0402 10:03:21.325570 140537578567488 submission.py:139] 3500) loss = 2.539, grad_norm = 0.893
I0402 10:10:04.991276 140508605179648 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.979138, loss=2.497541
I0402 10:10:04.996423 140537578567488 submission.py:139] 4000) loss = 2.498, grad_norm = 0.979
I0402 10:16:49.687533 140508613572352 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.871574, loss=2.348408
I0402 10:16:49.693880 140537578567488 submission.py:139] 4500) loss = 2.348, grad_norm = 0.872
I0402 10:23:28.866157 140508605179648 logging_writer.py:48] [5000] global_step=5000, grad_norm=nan, loss=nan
I0402 10:23:28.870189 140537578567488 submission.py:139] 5000) loss = nan, grad_norm = nan
I0402 10:29:59.944494 140508605179648 logging_writer.py:48] [5500] global_step=5500, grad_norm=nan, loss=nan
I0402 10:29:59.951048 140537578567488 submission.py:139] 5500) loss = nan, grad_norm = nan
I0402 10:36:09.746300 140537578567488 submission_runner.py:373] Before eval at step 5975: RAM USED (GB) 42.170413056
I0402 10:36:09.746532 140537578567488 spec.py:298] Evaluating on the training split.
I0402 10:36:19.429148 140537578567488 spec.py:310] Evaluating on the validation split.
I0402 10:36:28.246548 140537578567488 spec.py:326] Evaluating on the test split.
I0402 10:36:33.215940 140537578567488 submission_runner.py:382] Time since start: 4870.54s, 	Step: 5975, 	{'train/ctc_loss': nan, 'train/wer': 0.9418647403594523, 'validation/ctc_loss': nan, 'validation/wer': 0.8967218654950997, 'validation/num_examples': 5348, 'test/ctc_loss': nan, 'test/wer': 0.899579550301627, 'test/num_examples': 2472}
I0402 10:36:33.216721 140537578567488 submission_runner.py:396] After eval at step 5975: RAM USED (GB) 41.925931008
I0402 10:36:33.233473 140508605179648 logging_writer.py:48] [5975] global_step=5975, preemption_count=0, score=2913.459598, test/ctc_loss=nan, test/num_examples=2472, test/wer=0.899580, total_duration=4870.542291, train/ctc_loss=nan, train/wer=0.941865, validation/ctc_loss=nan, validation/num_examples=5348, validation/wer=0.896722
I0402 10:36:33.437876 140537578567488 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nesterov/librispeech_deepspeech_pytorch/trial_1/checkpoint_5975.
I0402 10:36:33.438375 140537578567488 submission_runner.py:416] After logging and checkpointing eval at step 5975: RAM USED (GB) 41.930878976
I0402 10:36:53.696849 140508596786944 logging_writer.py:48] [6000] global_step=6000, grad_norm=nan, loss=nan
I0402 10:36:53.700659 140537578567488 submission.py:139] 6000) loss = nan, grad_norm = nan
I0402 10:43:26.072698 140508596786944 logging_writer.py:48] [6500] global_step=6500, grad_norm=nan, loss=nan
I0402 10:43:26.080189 140537578567488 submission.py:139] 6500) loss = nan, grad_norm = nan
I0402 10:49:57.402267 140508378691328 logging_writer.py:48] [7000] global_step=7000, grad_norm=nan, loss=nan
I0402 10:49:57.406731 140537578567488 submission.py:139] 7000) loss = nan, grad_norm = nan
I0402 10:56:29.328304 140508596786944 logging_writer.py:48] [7500] global_step=7500, grad_norm=nan, loss=nan
I0402 10:56:29.335189 140537578567488 submission.py:139] 7500) loss = nan, grad_norm = nan
I0402 11:03:00.695626 140537578567488 submission_runner.py:373] Before eval at step 8000: RAM USED (GB) 42.045038592
I0402 11:03:00.695898 140537578567488 spec.py:298] Evaluating on the training split.
I0402 11:03:10.497024 140537578567488 spec.py:310] Evaluating on the validation split.
I0402 11:03:19.256675 140537578567488 spec.py:326] Evaluating on the test split.
I0402 11:03:24.565678 140537578567488 submission_runner.py:382] Time since start: 6481.47s, 	Step: 8000, 	{'train/ctc_loss': nan, 'train/wer': 0.9418647403594523, 'validation/ctc_loss': nan, 'validation/wer': 0.8967218654950997, 'validation/num_examples': 5348, 'test/ctc_loss': nan, 'test/wer': 0.899579550301627, 'test/num_examples': 2472}
I0402 11:03:24.566449 140537578567488 submission_runner.py:396] After eval at step 8000: RAM USED (GB) 41.8219008
I0402 11:03:24.582936 140508596786944 logging_writer.py:48] [8000] global_step=8000, preemption_count=0, score=3879.819692, test/ctc_loss=nan, test/num_examples=2472, test/wer=0.899580, total_duration=6481.474635, train/ctc_loss=nan, train/wer=0.941865, validation/ctc_loss=nan, validation/num_examples=5348, validation/wer=0.896722
I0402 11:03:24.786007 140537578567488 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nesterov/librispeech_deepspeech_pytorch/trial_1/checkpoint_8000.
I0402 11:03:24.786537 140537578567488 submission_runner.py:416] After logging and checkpointing eval at step 8000: RAM USED (GB) 41.827495936
I0402 11:03:24.797148 140508378691328 logging_writer.py:48] [8000] global_step=8000, preemption_count=0, score=3879.819692
I0402 11:03:25.134428 140537578567488 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nesterov/librispeech_deepspeech_pytorch/trial_1/checkpoint_8000.
I0402 11:03:25.295834 140537578567488 submission_runner.py:550] Tuning trial 1/1
I0402 11:03:25.296078 140537578567488 submission_runner.py:551] Hyperparameters: Hyperparameters(learning_rate=0.4394877561366806, one_minus_beta1=0.07113602458522507, warmup_factor=0.05, weight_decay=9.611851572925426e-07, label_smoothing=0.2, dropout_rate=0.0, decay_steps_factor=0.9, end_factor=0.001)
I0402 11:03:25.296461 140537578567488 submission_runner.py:552] Metrics: {'eval_results': [(1, {'train/ctc_loss': 31.137516905599135, 'train/wer': 4.544677422843177, 'validation/ctc_loss': 30.265232569821176, 'validation/wer': 4.218790131801284, 'validation/num_examples': 5348, 'test/ctc_loss': 30.369614168656042, 'test/wer': 4.463429000873398, 'test/num_examples': 2472, 'score': 8.823963165283203, 'total_duration': 8.825969457626343, 'global_step': 1, 'preemption_count': 0}), (2969, {'train/ctc_loss': 2.3222000101433595, 'train/wer': 0.6059486990937993, 'validation/ctc_loss': 2.5587522917922443, 'validation/wer': 0.6162120407473567, 'validation/num_examples': 5348, 'test/ctc_loss': 2.050158679592232, 'test/wer': 0.5463611805090082, 'test/num_examples': 2472, 'score': 1470.9551441669464, 'total_duration': 2445.1374905109406, 'global_step': 2969, 'preemption_count': 0}), (5975, {'train/ctc_loss': nan, 'train/wer': 0.9418647403594523, 'validation/ctc_loss': nan, 'validation/wer': 0.8967218654950997, 'validation/num_examples': 5348, 'test/ctc_loss': nan, 'test/wer': 0.899579550301627, 'test/num_examples': 2472, 'score': 2913.4595975875854, 'total_duration': 4870.542291402817, 'global_step': 5975, 'preemption_count': 0}), (8000, {'train/ctc_loss': nan, 'train/wer': 0.9418647403594523, 'validation/ctc_loss': nan, 'validation/wer': 0.8967218654950997, 'validation/num_examples': 5348, 'test/ctc_loss': nan, 'test/wer': 0.899579550301627, 'test/num_examples': 2472, 'score': 3879.819692134857, 'total_duration': 6481.474634885788, 'global_step': 8000, 'preemption_count': 0})], 'global_step': 8000}
I0402 11:03:25.296542 140537578567488 submission_runner.py:553] Timing: 3879.819692134857
I0402 11:03:25.296590 140537578567488 submission_runner.py:554] ====================
I0402 11:03:25.296757 140537578567488 submission_runner.py:613] Final librispeech_deepspeech score: 3879.819692134857
