torchrun --redirects 1:0,2:0,3:0,4:0,5:0,6:0,7:0 --standalone --nnodes=1 --nproc_per_node=8 submission_runner.py --framework=pytorch --workload=fastmri --submission_path=baselines/momentum/pytorch/submission.py --tuning_search_space=baselines/momentum/tuning_search_space.json --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_v4_b_pytorch/momentum --overwrite=True --save_checkpoints=False --max_global_steps=5428 2>&1 | tee -a /logs/fastmri_pytorch_06-09-2023-01-51-10.log
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
I0609 01:51:33.752111 140639648765760 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 5
I0609 01:51:33.752142 140458711607104 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 7
I0609 01:51:33.752158 140387160844096 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 4
I0609 01:51:33.752184 140619402774336 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 1
I0609 01:51:33.753159 139718278391616 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 2
I0609 01:51:33.753269 140119435134784 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 3
I0609 01:51:34.737919 139721048889152 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 6
I0609 01:51:34.743586 139698849601344 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 0
I0609 01:51:34.743945 139698849601344 distributed_c10d.py:353] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0609 01:51:34.748583 139721048889152 distributed_c10d.py:353] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0609 01:51:34.751845 140619402774336 distributed_c10d.py:353] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0609 01:51:34.751773 140639648765760 distributed_c10d.py:353] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0609 01:51:34.751873 140119435134784 distributed_c10d.py:353] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0609 01:51:34.751945 140458711607104 distributed_c10d.py:353] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0609 01:51:34.751995 140387160844096 distributed_c10d.py:353] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0609 01:51:34.752089 139718278391616 distributed_c10d.py:353] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0609 01:51:35.315490 139698849601344 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_v4_b_pytorch/momentum/fastmri_pytorch.
W0609 01:51:35.445183 140387160844096 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0609 01:51:35.445525 139721048889152 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0609 01:51:35.446087 140639648765760 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0609 01:51:35.446268 140458711607104 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0609 01:51:35.446410 140619402774336 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0609 01:51:35.446806 139718278391616 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0609 01:51:35.447901 139698849601344 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0609 01:51:35.447988 140119435134784 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0609 01:51:35.453515 139698849601344 submission_runner.py:541] Using RNG seed 1725383016
I0609 01:51:35.454903 139698849601344 submission_runner.py:550] --- Tuning run 1/1 ---
I0609 01:51:35.455007 139698849601344 submission_runner.py:555] Creating tuning directory at /experiment_runs/timing_v4_b_pytorch/momentum/fastmri_pytorch/trial_1.
I0609 01:51:35.455239 139698849601344 logger_utils.py:92] Saving hparams to /experiment_runs/timing_v4_b_pytorch/momentum/fastmri_pytorch/trial_1/hparams.json.
I0609 01:51:35.456181 139698849601344 submission_runner.py:255] Initializing dataset.
I0609 01:51:35.456295 139698849601344 submission_runner.py:262] Initializing model.
I0609 01:51:39.561932 139698849601344 submission_runner.py:272] Initializing optimizer.
I0609 01:51:40.040638 139698849601344 submission_runner.py:279] Initializing metrics bundle.
I0609 01:51:40.040842 139698849601344 submission_runner.py:297] Initializing checkpoint and logger.
I0609 01:51:40.044181 139698849601344 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0609 01:51:40.044308 139698849601344 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0609 01:51:40.511031 139698849601344 submission_runner.py:318] Saving meta data to /experiment_runs/timing_v4_b_pytorch/momentum/fastmri_pytorch/trial_1/meta_data_0.json.
I0609 01:51:40.512058 139698849601344 submission_runner.py:321] Saving flags to /experiment_runs/timing_v4_b_pytorch/momentum/fastmri_pytorch/trial_1/flags_0.json.
I0609 01:51:40.566466 139698849601344 submission_runner.py:332] Starting training loop.
I0609 01:52:25.244204 139656381323008 logging_writer.py:48] [0] global_step=0, grad_norm=6.027957, loss=0.832427
I0609 01:52:25.256495 139698849601344 spec.py:298] Evaluating on the training split.
I0609 01:53:57.190584 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 01:54:57.872555 139698849601344 spec.py:326] Evaluating on the test split.
I0609 01:55:56.420437 139698849601344 submission_runner.py:419] Time since start: 255.85s, 	Step: 1, 	{'train/ssim': 0.23183165277753556, 'train/loss': 0.9142254420689174, 'validation/ssim': 0.2223073672765282, 'validation/loss': 0.9188996305878939, 'validation/num_examples': 3554, 'test/ssim': 0.24476831047869835, 'test/loss': 0.917520352097005, 'test/num_examples': 3581, 'score': 44.68880796432495, 'total_duration': 255.85440182685852, 'accumulated_submission_time': 44.68880796432495, 'accumulated_eval_time': 211.16485118865967, 'accumulated_logging_time': 0}
I0609 01:55:56.436179 139631483918080 logging_writer.py:48] [1] accumulated_eval_time=211.164851, accumulated_logging_time=0, accumulated_submission_time=44.688808, global_step=1, preemption_count=0, score=44.688808, test/loss=0.917520, test/num_examples=3581, test/ssim=0.244768, total_duration=255.854402, train/loss=0.914225, train/ssim=0.231832, validation/loss=0.918900, validation/num_examples=3554, validation/ssim=0.222307
I0609 01:55:56.461904 139721048889152 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0609 01:55:56.461902 139718278391616 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0609 01:55:56.461902 140387160844096 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0609 01:55:56.461908 140639648765760 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0609 01:55:56.461913 140458711607104 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0609 01:55:56.461923 140119435134784 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0609 01:55:56.461930 140619402774336 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0609 01:55:56.462022 139698849601344 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0609 01:55:56.533397 139631400056576 logging_writer.py:48] [1] global_step=1, grad_norm=5.607430, loss=0.881681
I0609 01:55:56.615674 139631483918080 logging_writer.py:48] [2] global_step=2, grad_norm=4.946262, loss=0.937442
I0609 01:55:56.693188 139631400056576 logging_writer.py:48] [3] global_step=3, grad_norm=4.840205, loss=0.847386
I0609 01:55:56.762592 139631483918080 logging_writer.py:48] [4] global_step=4, grad_norm=3.182870, loss=0.828014
I0609 01:55:56.839201 139631400056576 logging_writer.py:48] [5] global_step=5, grad_norm=2.767113, loss=0.671088
I0609 01:55:56.919754 139631483918080 logging_writer.py:48] [6] global_step=6, grad_norm=1.686232, loss=0.647306
I0609 01:55:56.997967 139631400056576 logging_writer.py:48] [7] global_step=7, grad_norm=1.949272, loss=0.600020
I0609 01:55:57.070311 139631483918080 logging_writer.py:48] [8] global_step=8, grad_norm=2.659439, loss=0.666856
I0609 01:55:57.150855 139631400056576 logging_writer.py:48] [9] global_step=9, grad_norm=2.903288, loss=0.713735
I0609 01:55:57.233052 139631483918080 logging_writer.py:48] [10] global_step=10, grad_norm=3.119743, loss=0.590993
I0609 01:55:57.309826 139631400056576 logging_writer.py:48] [11] global_step=11, grad_norm=2.762695, loss=0.665306
I0609 01:55:57.386379 139631483918080 logging_writer.py:48] [12] global_step=12, grad_norm=2.172800, loss=0.649117
I0609 01:55:57.473016 139631400056576 logging_writer.py:48] [13] global_step=13, grad_norm=1.474521, loss=0.645453
I0609 01:55:57.582828 139631483918080 logging_writer.py:48] [14] global_step=14, grad_norm=1.086939, loss=0.432501
I0609 01:55:57.858925 139631400056576 logging_writer.py:48] [15] global_step=15, grad_norm=0.820265, loss=0.501106
I0609 01:55:58.108168 139631483918080 logging_writer.py:48] [16] global_step=16, grad_norm=0.907241, loss=0.492527
I0609 01:55:58.434121 139631400056576 logging_writer.py:48] [17] global_step=17, grad_norm=1.018526, loss=0.447680
I0609 01:55:58.643715 139631483918080 logging_writer.py:48] [18] global_step=18, grad_norm=1.422722, loss=0.421523
I0609 01:55:58.887989 139631400056576 logging_writer.py:48] [19] global_step=19, grad_norm=1.361572, loss=0.391409
I0609 01:55:59.142601 139631483918080 logging_writer.py:48] [20] global_step=20, grad_norm=0.816038, loss=0.448657
I0609 01:55:59.451819 139631400056576 logging_writer.py:48] [21] global_step=21, grad_norm=0.644906, loss=0.422336
I0609 01:55:59.728177 139631483918080 logging_writer.py:48] [22] global_step=22, grad_norm=0.657762, loss=0.424104
I0609 01:55:59.963842 139631400056576 logging_writer.py:48] [23] global_step=23, grad_norm=0.671451, loss=0.477496
I0609 01:56:00.226622 139631483918080 logging_writer.py:48] [24] global_step=24, grad_norm=0.819330, loss=0.490985
I0609 01:56:00.470246 139631400056576 logging_writer.py:48] [25] global_step=25, grad_norm=0.957016, loss=0.370537
I0609 01:56:00.775011 139631483918080 logging_writer.py:48] [26] global_step=26, grad_norm=0.947067, loss=0.378122
I0609 01:56:01.085465 139631400056576 logging_writer.py:48] [27] global_step=27, grad_norm=0.874255, loss=0.383209
I0609 01:56:01.357794 139631483918080 logging_writer.py:48] [28] global_step=28, grad_norm=0.809381, loss=0.362348
I0609 01:56:01.706163 139631400056576 logging_writer.py:48] [29] global_step=29, grad_norm=0.583657, loss=0.346549
I0609 01:56:01.962865 139631483918080 logging_writer.py:48] [30] global_step=30, grad_norm=0.467727, loss=0.356275
I0609 01:56:02.198519 139631400056576 logging_writer.py:48] [31] global_step=31, grad_norm=0.347999, loss=0.422161
I0609 01:56:02.515672 139631483918080 logging_writer.py:48] [32] global_step=32, grad_norm=0.502487, loss=0.374859
I0609 01:56:02.802266 139631400056576 logging_writer.py:48] [33] global_step=33, grad_norm=0.660550, loss=0.336789
I0609 01:56:03.065697 139631483918080 logging_writer.py:48] [34] global_step=34, grad_norm=0.750848, loss=0.335077
I0609 01:56:03.370742 139631400056576 logging_writer.py:48] [35] global_step=35, grad_norm=0.690798, loss=0.516473
I0609 01:56:03.618846 139631483918080 logging_writer.py:48] [36] global_step=36, grad_norm=0.627650, loss=0.340573
I0609 01:56:03.898766 139631400056576 logging_writer.py:48] [37] global_step=37, grad_norm=0.460601, loss=0.346497
I0609 01:56:04.178862 139631483918080 logging_writer.py:48] [38] global_step=38, grad_norm=0.263977, loss=0.258383
I0609 01:56:04.462631 139631400056576 logging_writer.py:48] [39] global_step=39, grad_norm=0.475626, loss=0.389379
I0609 01:56:04.688142 139631483918080 logging_writer.py:48] [40] global_step=40, grad_norm=0.480982, loss=0.312362
I0609 01:56:04.985263 139631400056576 logging_writer.py:48] [41] global_step=41, grad_norm=0.529120, loss=0.410958
I0609 01:56:05.236146 139631483918080 logging_writer.py:48] [42] global_step=42, grad_norm=0.513815, loss=0.339095
I0609 01:56:05.496209 139631400056576 logging_writer.py:48] [43] global_step=43, grad_norm=0.613865, loss=0.263797
I0609 01:56:05.818085 139631483918080 logging_writer.py:48] [44] global_step=44, grad_norm=0.343931, loss=0.378921
I0609 01:56:06.111512 139631400056576 logging_writer.py:48] [45] global_step=45, grad_norm=0.316359, loss=0.436515
I0609 01:56:06.407588 139631483918080 logging_writer.py:48] [46] global_step=46, grad_norm=0.393400, loss=0.380088
I0609 01:56:06.646234 139631400056576 logging_writer.py:48] [47] global_step=47, grad_norm=0.425190, loss=0.361301
I0609 01:56:06.873369 139631483918080 logging_writer.py:48] [48] global_step=48, grad_norm=0.488007, loss=0.402677
I0609 01:56:07.194698 139631400056576 logging_writer.py:48] [49] global_step=49, grad_norm=0.398243, loss=0.381790
I0609 01:56:07.481603 139631483918080 logging_writer.py:48] [50] global_step=50, grad_norm=0.194987, loss=0.385942
I0609 01:56:07.729239 139631400056576 logging_writer.py:48] [51] global_step=51, grad_norm=0.190538, loss=0.400451
I0609 01:56:08.027018 139631483918080 logging_writer.py:48] [52] global_step=52, grad_norm=0.229201, loss=0.349661
I0609 01:56:08.230834 139631400056576 logging_writer.py:48] [53] global_step=53, grad_norm=0.352936, loss=0.376472
I0609 01:56:08.520073 139631483918080 logging_writer.py:48] [54] global_step=54, grad_norm=0.367746, loss=0.467368
I0609 01:56:08.799956 139631400056576 logging_writer.py:48] [55] global_step=55, grad_norm=0.255066, loss=0.442506
I0609 01:56:09.039818 139631483918080 logging_writer.py:48] [56] global_step=56, grad_norm=0.192345, loss=0.371309
I0609 01:56:09.307967 139631400056576 logging_writer.py:48] [57] global_step=57, grad_norm=0.121469, loss=0.451109
I0609 01:56:09.568357 139631483918080 logging_writer.py:48] [58] global_step=58, grad_norm=0.421682, loss=0.289694
I0609 01:56:09.828698 139631400056576 logging_writer.py:48] [59] global_step=59, grad_norm=0.292955, loss=0.318568
I0609 01:56:10.108739 139631483918080 logging_writer.py:48] [60] global_step=60, grad_norm=0.203309, loss=0.319270
I0609 01:56:10.333554 139631400056576 logging_writer.py:48] [61] global_step=61, grad_norm=0.153915, loss=0.369276
I0609 01:56:10.600096 139631483918080 logging_writer.py:48] [62] global_step=62, grad_norm=0.150747, loss=0.329987
I0609 01:56:10.879406 139631400056576 logging_writer.py:48] [63] global_step=63, grad_norm=0.298513, loss=0.432521
I0609 01:56:11.183889 139631483918080 logging_writer.py:48] [64] global_step=64, grad_norm=0.266566, loss=0.299962
I0609 01:56:11.427971 139631400056576 logging_writer.py:48] [65] global_step=65, grad_norm=0.109658, loss=0.252583
I0609 01:56:11.712471 139631483918080 logging_writer.py:48] [66] global_step=66, grad_norm=0.109979, loss=0.369473
I0609 01:56:11.990762 139631400056576 logging_writer.py:48] [67] global_step=67, grad_norm=0.250967, loss=0.369293
I0609 01:56:12.236998 139631483918080 logging_writer.py:48] [68] global_step=68, grad_norm=0.156712, loss=0.345485
I0609 01:56:12.521325 139631400056576 logging_writer.py:48] [69] global_step=69, grad_norm=0.185285, loss=0.348387
I0609 01:56:12.736408 139631483918080 logging_writer.py:48] [70] global_step=70, grad_norm=0.076446, loss=0.320549
I0609 01:56:12.998981 139631400056576 logging_writer.py:48] [71] global_step=71, grad_norm=0.082798, loss=0.314302
I0609 01:56:13.275045 139631483918080 logging_writer.py:48] [72] global_step=72, grad_norm=0.179412, loss=0.469363
I0609 01:56:13.551714 139631400056576 logging_writer.py:48] [73] global_step=73, grad_norm=0.217125, loss=0.276394
I0609 01:56:13.798013 139631483918080 logging_writer.py:48] [74] global_step=74, grad_norm=0.199077, loss=0.304513
I0609 01:56:14.057415 139631400056576 logging_writer.py:48] [75] global_step=75, grad_norm=0.132945, loss=0.348585
I0609 01:56:14.311411 139631483918080 logging_writer.py:48] [76] global_step=76, grad_norm=0.194820, loss=0.270733
I0609 01:56:14.621091 139631400056576 logging_writer.py:48] [77] global_step=77, grad_norm=0.195177, loss=0.234264
I0609 01:56:14.892745 139631483918080 logging_writer.py:48] [78] global_step=78, grad_norm=0.216921, loss=0.301459
I0609 01:56:15.140144 139631400056576 logging_writer.py:48] [79] global_step=79, grad_norm=0.266342, loss=0.277321
I0609 01:56:15.402867 139631483918080 logging_writer.py:48] [80] global_step=80, grad_norm=0.214455, loss=0.276147
I0609 01:56:15.644105 139631400056576 logging_writer.py:48] [81] global_step=81, grad_norm=0.126041, loss=0.378531
I0609 01:56:15.943758 139631483918080 logging_writer.py:48] [82] global_step=82, grad_norm=0.146852, loss=0.238535
I0609 01:56:16.226918 139631400056576 logging_writer.py:48] [83] global_step=83, grad_norm=0.119234, loss=0.315941
I0609 01:56:16.521992 139631483918080 logging_writer.py:48] [84] global_step=84, grad_norm=0.223556, loss=0.288186
I0609 01:56:16.773984 139631400056576 logging_writer.py:48] [85] global_step=85, grad_norm=0.197727, loss=0.351179
I0609 01:56:17.024538 139631483918080 logging_writer.py:48] [86] global_step=86, grad_norm=0.210620, loss=0.307425
I0609 01:56:17.336204 139631400056576 logging_writer.py:48] [87] global_step=87, grad_norm=0.124005, loss=0.259239
I0609 01:56:17.609083 139631483918080 logging_writer.py:48] [88] global_step=88, grad_norm=0.127615, loss=0.320581
I0609 01:56:17.885792 139631400056576 logging_writer.py:48] [89] global_step=89, grad_norm=0.211459, loss=0.294190
I0609 01:56:18.168049 139631483918080 logging_writer.py:48] [90] global_step=90, grad_norm=0.335447, loss=0.256781
I0609 01:56:18.420108 139631400056576 logging_writer.py:48] [91] global_step=91, grad_norm=0.143117, loss=0.279864
I0609 01:56:18.642034 139631483918080 logging_writer.py:48] [92] global_step=92, grad_norm=0.245115, loss=0.247011
I0609 01:56:18.936195 139631400056576 logging_writer.py:48] [93] global_step=93, grad_norm=0.375330, loss=0.259611
I0609 01:56:19.215077 139631483918080 logging_writer.py:48] [94] global_step=94, grad_norm=0.246281, loss=0.246423
I0609 01:56:19.514216 139631400056576 logging_writer.py:48] [95] global_step=95, grad_norm=0.072180, loss=0.357762
I0609 01:56:19.773415 139631483918080 logging_writer.py:48] [96] global_step=96, grad_norm=0.333236, loss=0.323699
I0609 01:56:20.048480 139631400056576 logging_writer.py:48] [97] global_step=97, grad_norm=0.387742, loss=0.302097
I0609 01:56:20.314185 139631483918080 logging_writer.py:48] [98] global_step=98, grad_norm=0.100716, loss=0.288156
I0609 01:56:20.572811 139631400056576 logging_writer.py:48] [99] global_step=99, grad_norm=0.236842, loss=0.392545
I0609 01:56:20.892550 139631483918080 logging_writer.py:48] [100] global_step=100, grad_norm=0.356391, loss=0.312715
I0609 01:57:16.434840 139698849601344 spec.py:298] Evaluating on the training split.
I0609 01:57:18.681074 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 01:57:20.954150 139698849601344 spec.py:326] Evaluating on the test split.
I0609 01:57:23.148502 139698849601344 submission_runner.py:419] Time since start: 342.58s, 	Step: 304, 	{'train/ssim': 0.7050538744245257, 'train/loss': 0.310117312840053, 'validation/ssim': 0.6811622357730726, 'validation/loss': 0.3283568099434616, 'validation/num_examples': 3554, 'test/ssim': 0.6994467327562134, 'test/loss': 0.33001737959456157, 'test/num_examples': 3581, 'score': 124.44338369369507, 'total_duration': 342.58250308036804, 'accumulated_submission_time': 124.44338369369507, 'accumulated_eval_time': 217.87850165367126, 'accumulated_logging_time': 0.02450847625732422}
I0609 01:57:23.166804 139631400056576 logging_writer.py:48] [304] accumulated_eval_time=217.878502, accumulated_logging_time=0.024508, accumulated_submission_time=124.443384, global_step=304, preemption_count=0, score=124.443384, test/loss=0.330017, test/num_examples=3581, test/ssim=0.699447, total_duration=342.582503, train/loss=0.310117, train/ssim=0.705054, validation/loss=0.328357, validation/num_examples=3554, validation/ssim=0.681162
I0609 01:58:25.199277 139631483918080 logging_writer.py:48] [500] global_step=500, grad_norm=0.172327, loss=0.270925
I0609 01:58:43.251986 139698849601344 spec.py:298] Evaluating on the training split.
I0609 01:58:45.452797 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 01:58:47.730592 139698849601344 spec.py:326] Evaluating on the test split.
I0609 01:58:49.917431 139698849601344 submission_runner.py:419] Time since start: 429.35s, 	Step: 552, 	{'train/ssim': 0.7185888290405273, 'train/loss': 0.2947260652269636, 'validation/ssim': 0.6948181736247889, 'validation/loss': 0.3128112896010657, 'validation/num_examples': 3554, 'test/ssim': 0.7127871328277716, 'test/loss': 0.3145155748219771, 'test/num_examples': 3581, 'score': 204.28152060508728, 'total_duration': 429.3508520126343, 'accumulated_submission_time': 204.28152060508728, 'accumulated_eval_time': 224.5434112548828, 'accumulated_logging_time': 0.05267524719238281}
I0609 01:58:49.930781 139631400056576 logging_writer.py:48] [552] accumulated_eval_time=224.543411, accumulated_logging_time=0.052675, accumulated_submission_time=204.281521, global_step=552, preemption_count=0, score=204.281521, test/loss=0.314516, test/num_examples=3581, test/ssim=0.712787, total_duration=429.350852, train/loss=0.294726, train/ssim=0.718589, validation/loss=0.312811, validation/num_examples=3554, validation/ssim=0.694818
I0609 02:00:10.007775 139698849601344 spec.py:298] Evaluating on the training split.
I0609 02:00:12.205687 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 02:00:14.450508 139698849601344 spec.py:326] Evaluating on the test split.
I0609 02:00:16.634958 139698849601344 submission_runner.py:419] Time since start: 516.07s, 	Step: 789, 	{'train/ssim': 0.6877471378871373, 'train/loss': 0.30157457079206196, 'validation/ssim': 0.6752608196750141, 'validation/loss': 0.3173056684589547, 'validation/num_examples': 3554, 'test/ssim': 0.6900995761047891, 'test/loss': 0.3193698213007889, 'test/num_examples': 3581, 'score': 284.1235613822937, 'total_duration': 516.0689830780029, 'accumulated_submission_time': 284.1235613822937, 'accumulated_eval_time': 231.17079710960388, 'accumulated_logging_time': 0.07995152473449707}
I0609 02:00:16.646938 139631483918080 logging_writer.py:48] [789] accumulated_eval_time=231.170797, accumulated_logging_time=0.079952, accumulated_submission_time=284.123561, global_step=789, preemption_count=0, score=284.123561, test/loss=0.319370, test/num_examples=3581, test/ssim=0.690100, total_duration=516.068983, train/loss=0.301575, train/ssim=0.687747, validation/loss=0.317306, validation/num_examples=3554, validation/ssim=0.675261
I0609 02:01:25.549393 139631400056576 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.261982, loss=0.300490
I0609 02:01:36.865638 139698849601344 spec.py:298] Evaluating on the training split.
I0609 02:01:38.972373 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 02:01:41.128629 139698849601344 spec.py:326] Evaluating on the test split.
I0609 02:01:43.193627 139698849601344 submission_runner.py:419] Time since start: 602.63s, 	Step: 1043, 	{'train/ssim': 0.7162162235804966, 'train/loss': 0.2913170542035784, 'validation/ssim': 0.6968592277187676, 'validation/loss': 0.3078993505886853, 'validation/num_examples': 3554, 'test/ssim': 0.7134541051076864, 'test/loss': 0.30957941408431655, 'test/num_examples': 3581, 'score': 364.1111071109772, 'total_duration': 602.627667427063, 'accumulated_submission_time': 364.1111071109772, 'accumulated_eval_time': 237.49877047538757, 'accumulated_logging_time': 0.11373090744018555}
I0609 02:01:43.204293 139631483918080 logging_writer.py:48] [1043] accumulated_eval_time=237.498770, accumulated_logging_time=0.113731, accumulated_submission_time=364.111107, global_step=1043, preemption_count=0, score=364.111107, test/loss=0.309579, test/num_examples=3581, test/ssim=0.713454, total_duration=602.627667, train/loss=0.291317, train/ssim=0.716216, validation/loss=0.307899, validation/num_examples=3554, validation/ssim=0.696859
I0609 02:03:03.440928 139698849601344 spec.py:298] Evaluating on the training split.
I0609 02:03:05.562653 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 02:03:07.711565 139698849601344 spec.py:326] Evaluating on the test split.
I0609 02:03:09.772309 139698849601344 submission_runner.py:419] Time since start: 689.21s, 	Step: 1352, 	{'train/ssim': 0.7277191025870187, 'train/loss': 0.28359835488455637, 'validation/ssim': 0.7060472684826955, 'validation/loss': 0.30131260276712857, 'validation/num_examples': 3554, 'test/ssim': 0.7230621738428512, 'test/loss': 0.30292455379738553, 'test/num_examples': 3581, 'score': 444.21102690696716, 'total_duration': 689.2063443660736, 'accumulated_submission_time': 444.21102690696716, 'accumulated_eval_time': 243.8302230834961, 'accumulated_logging_time': 0.13417935371398926}
I0609 02:03:09.782640 139631400056576 logging_writer.py:48] [1352] accumulated_eval_time=243.830223, accumulated_logging_time=0.134179, accumulated_submission_time=444.211027, global_step=1352, preemption_count=0, score=444.211027, test/loss=0.302925, test/num_examples=3581, test/ssim=0.723062, total_duration=689.206344, train/loss=0.283598, train/ssim=0.727719, validation/loss=0.301313, validation/num_examples=3554, validation/ssim=0.706047
I0609 02:03:47.016401 139631483918080 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.126995, loss=0.315703
I0609 02:04:29.811731 139698849601344 spec.py:298] Evaluating on the training split.
I0609 02:04:31.932394 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 02:04:34.066397 139698849601344 spec.py:326] Evaluating on the test split.
I0609 02:04:36.129599 139698849601344 submission_runner.py:419] Time since start: 775.56s, 	Step: 1661, 	{'train/ssim': 0.730959279196603, 'train/loss': 0.28135928085872103, 'validation/ssim': 0.7064434302678321, 'validation/loss': 0.2997164836276027, 'validation/num_examples': 3554, 'test/ssim': 0.7237950047778204, 'test/loss': 0.3013873405211533, 'test/num_examples': 3581, 'score': 524.1040704250336, 'total_duration': 775.5636084079742, 'accumulated_submission_time': 524.1040704250336, 'accumulated_eval_time': 250.14811897277832, 'accumulated_logging_time': 0.15277791023254395}
I0609 02:04:36.140441 139631400056576 logging_writer.py:48] [1661] accumulated_eval_time=250.148119, accumulated_logging_time=0.152778, accumulated_submission_time=524.104070, global_step=1661, preemption_count=0, score=524.104070, test/loss=0.301387, test/num_examples=3581, test/ssim=0.723795, total_duration=775.563608, train/loss=0.281359, train/ssim=0.730959, validation/loss=0.299716, validation/num_examples=3554, validation/ssim=0.706443
I0609 02:05:56.147144 139698849601344 spec.py:298] Evaluating on the training split.
I0609 02:05:58.246220 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 02:06:00.395376 139698849601344 spec.py:326] Evaluating on the test split.
I0609 02:06:02.474229 139698849601344 submission_runner.py:419] Time since start: 861.91s, 	Step: 1970, 	{'train/ssim': 0.7295582635062081, 'train/loss': 0.2842108692441668, 'validation/ssim': 0.705371519656549, 'validation/loss': 0.30257012620023216, 'validation/num_examples': 3554, 'test/ssim': 0.7220486595922927, 'test/loss': 0.30437484183014524, 'test/num_examples': 3581, 'score': 603.9766030311584, 'total_duration': 861.908212184906, 'accumulated_submission_time': 603.9766030311584, 'accumulated_eval_time': 256.47515749931335, 'accumulated_logging_time': 0.17180967330932617}
I0609 02:06:02.484936 139631483918080 logging_writer.py:48] [1970] accumulated_eval_time=256.475157, accumulated_logging_time=0.171810, accumulated_submission_time=603.976603, global_step=1970, preemption_count=0, score=603.976603, test/loss=0.304375, test/num_examples=3581, test/ssim=0.722049, total_duration=861.908212, train/loss=0.284211, train/ssim=0.729558, validation/loss=0.302570, validation/num_examples=3554, validation/ssim=0.705372
I0609 02:06:08.302526 139631400056576 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.135452, loss=0.334838
I0609 02:07:22.549129 139698849601344 spec.py:298] Evaluating on the training split.
I0609 02:07:24.661165 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 02:07:26.833591 139698849601344 spec.py:326] Evaluating on the test split.
I0609 02:07:28.915793 139698849601344 submission_runner.py:419] Time since start: 948.35s, 	Step: 2278, 	{'train/ssim': 0.7351153237479073, 'train/loss': 0.28016362871442524, 'validation/ssim': 0.7100888468538971, 'validation/loss': 0.2996104535052933, 'validation/num_examples': 3554, 'test/ssim': 0.7265384336384739, 'test/loss': 0.3017491881523143, 'test/num_examples': 3581, 'score': 683.9067974090576, 'total_duration': 948.3497834205627, 'accumulated_submission_time': 683.9067974090576, 'accumulated_eval_time': 262.841774225235, 'accumulated_logging_time': 0.19095230102539062}
I0609 02:07:28.926496 139631483918080 logging_writer.py:48] [2278] accumulated_eval_time=262.841774, accumulated_logging_time=0.190952, accumulated_submission_time=683.906797, global_step=2278, preemption_count=0, score=683.906797, test/loss=0.301749, test/num_examples=3581, test/ssim=0.726538, total_duration=948.349783, train/loss=0.280164, train/ssim=0.735115, validation/loss=0.299610, validation/num_examples=3554, validation/ssim=0.710089
I0609 02:08:26.134518 139631400056576 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.180690, loss=0.307954
I0609 02:08:48.938661 139698849601344 spec.py:298] Evaluating on the training split.
I0609 02:08:51.047536 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 02:08:53.209589 139698849601344 spec.py:326] Evaluating on the test split.
I0609 02:08:55.286261 139698849601344 submission_runner.py:419] Time since start: 1034.72s, 	Step: 2586, 	{'train/ssim': 0.7363369805472237, 'train/loss': 0.27739381790161133, 'validation/ssim': 0.7112446335774831, 'validation/loss': 0.29642031041168404, 'validation/num_examples': 3554, 'test/ssim': 0.7284122010044332, 'test/loss': 0.29813991569001325, 'test/num_examples': 3581, 'score': 763.7818076610565, 'total_duration': 1034.7202756404877, 'accumulated_submission_time': 763.7818076610565, 'accumulated_eval_time': 269.18935322761536, 'accumulated_logging_time': 0.21051359176635742}
I0609 02:08:55.296773 139631483918080 logging_writer.py:48] [2586] accumulated_eval_time=269.189353, accumulated_logging_time=0.210514, accumulated_submission_time=763.781808, global_step=2586, preemption_count=0, score=763.781808, test/loss=0.298140, test/num_examples=3581, test/ssim=0.728412, total_duration=1034.720276, train/loss=0.277394, train/ssim=0.736337, validation/loss=0.296420, validation/num_examples=3554, validation/ssim=0.711245
I0609 02:10:15.338700 139698849601344 spec.py:298] Evaluating on the training split.
I0609 02:10:17.452892 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 02:10:19.592785 139698849601344 spec.py:326] Evaluating on the test split.
I0609 02:10:21.673369 139698849601344 submission_runner.py:419] Time since start: 1121.11s, 	Step: 2896, 	{'train/ssim': 0.7351399830409459, 'train/loss': 0.2755656582968576, 'validation/ssim': 0.7111969595218416, 'validation/loss': 0.29399604346554936, 'validation/num_examples': 3554, 'test/ssim': 0.7283603867416574, 'test/loss': 0.2955347150106465, 'test/num_examples': 3581, 'score': 843.6882035732269, 'total_duration': 1121.107403755188, 'accumulated_submission_time': 843.6882035732269, 'accumulated_eval_time': 275.52403807640076, 'accumulated_logging_time': 0.22920966148376465}
I0609 02:10:21.683758 139631400056576 logging_writer.py:48] [2896] accumulated_eval_time=275.524038, accumulated_logging_time=0.229210, accumulated_submission_time=843.688204, global_step=2896, preemption_count=0, score=843.688204, test/loss=0.295535, test/num_examples=3581, test/ssim=0.728360, total_duration=1121.107404, train/loss=0.275566, train/ssim=0.735140, validation/loss=0.293996, validation/num_examples=3554, validation/ssim=0.711197
I0609 02:10:47.271627 139631483918080 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.080591, loss=0.274500
I0609 02:11:41.952446 139698849601344 spec.py:298] Evaluating on the training split.
I0609 02:11:44.104016 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 02:11:46.260771 139698849601344 spec.py:326] Evaluating on the test split.
I0609 02:11:48.328675 139698849601344 submission_runner.py:419] Time since start: 1207.76s, 	Step: 3202, 	{'train/ssim': 0.7391038622174945, 'train/loss': 0.27508429118565153, 'validation/ssim': 0.7151049268869584, 'validation/loss': 0.29366445460880347, 'validation/num_examples': 3554, 'test/ssim': 0.7322707955180118, 'test/loss': 0.2951925363463418, 'test/num_examples': 3581, 'score': 923.8249976634979, 'total_duration': 1207.7627158164978, 'accumulated_submission_time': 923.8249976634979, 'accumulated_eval_time': 281.9002809524536, 'accumulated_logging_time': 0.24816226959228516}
I0609 02:11:48.339453 139631400056576 logging_writer.py:48] [3202] accumulated_eval_time=281.900281, accumulated_logging_time=0.248162, accumulated_submission_time=923.824998, global_step=3202, preemption_count=0, score=923.824998, test/loss=0.295193, test/num_examples=3581, test/ssim=0.732271, total_duration=1207.762716, train/loss=0.275084, train/ssim=0.739104, validation/loss=0.293664, validation/num_examples=3554, validation/ssim=0.715105
I0609 02:13:06.123813 139631483918080 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.132562, loss=0.295107
I0609 02:13:08.494343 139698849601344 spec.py:298] Evaluating on the training split.
I0609 02:13:10.594547 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 02:13:12.745290 139698849601344 spec.py:326] Evaluating on the test split.
I0609 02:13:14.816359 139698849601344 submission_runner.py:419] Time since start: 1294.25s, 	Step: 3510, 	{'train/ssim': 0.7394296101161412, 'train/loss': 0.2743322678974697, 'validation/ssim': 0.7139424767867192, 'validation/loss': 0.29380057296795864, 'validation/num_examples': 3554, 'test/ssim': 0.7309024217441008, 'test/loss': 0.2955651218016965, 'test/num_examples': 3581, 'score': 1003.8415973186493, 'total_duration': 1294.2503917217255, 'accumulated_submission_time': 1003.8415973186493, 'accumulated_eval_time': 288.22241711616516, 'accumulated_logging_time': 0.26803040504455566}
I0609 02:13:14.826820 139631400056576 logging_writer.py:48] [3510] accumulated_eval_time=288.222417, accumulated_logging_time=0.268030, accumulated_submission_time=1003.841597, global_step=3510, preemption_count=0, score=1003.841597, test/loss=0.295565, test/num_examples=3581, test/ssim=0.730902, total_duration=1294.250392, train/loss=0.274332, train/ssim=0.739430, validation/loss=0.293801, validation/num_examples=3554, validation/ssim=0.713942
I0609 02:14:34.992650 139698849601344 spec.py:298] Evaluating on the training split.
I0609 02:14:37.095997 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 02:14:39.240547 139698849601344 spec.py:326] Evaluating on the test split.
I0609 02:14:41.313458 139698849601344 submission_runner.py:419] Time since start: 1380.75s, 	Step: 3819, 	{'train/ssim': 0.739415032523019, 'train/loss': 0.2737868172781808, 'validation/ssim': 0.7138551659441826, 'validation/loss': 0.293063067692213, 'validation/num_examples': 3554, 'test/ssim': 0.7309314650019199, 'test/loss': 0.29477713594753563, 'test/num_examples': 3581, 'score': 1083.8714389801025, 'total_duration': 1380.7474570274353, 'accumulated_submission_time': 1083.8714389801025, 'accumulated_eval_time': 294.543194770813, 'accumulated_logging_time': 0.2865629196166992}
I0609 02:14:41.323792 139631483918080 logging_writer.py:48] [3819] accumulated_eval_time=294.543195, accumulated_logging_time=0.286563, accumulated_submission_time=1083.871439, global_step=3819, preemption_count=0, score=1083.871439, test/loss=0.294777, test/num_examples=3581, test/ssim=0.730931, total_duration=1380.747457, train/loss=0.273787, train/ssim=0.739415, validation/loss=0.293063, validation/num_examples=3554, validation/ssim=0.713855
I0609 02:15:27.571009 139631400056576 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.185731, loss=0.262859
I0609 02:16:01.418007 139698849601344 spec.py:298] Evaluating on the training split.
I0609 02:16:03.526689 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 02:16:05.674770 139698849601344 spec.py:326] Evaluating on the test split.
I0609 02:16:07.746347 139698849601344 submission_runner.py:419] Time since start: 1467.18s, 	Step: 4126, 	{'train/ssim': 0.7419346400669643, 'train/loss': 0.2728550945009504, 'validation/ssim': 0.7166384652416291, 'validation/loss': 0.2918993467417874, 'validation/num_examples': 3554, 'test/ssim': 0.7336673262531416, 'test/loss': 0.29359144153824, 'test/num_examples': 3581, 'score': 1163.829433441162, 'total_duration': 1467.180385351181, 'accumulated_submission_time': 1163.829433441162, 'accumulated_eval_time': 300.8715772628784, 'accumulated_logging_time': 0.3061511516571045}
I0609 02:16:07.756875 139631483918080 logging_writer.py:48] [4126] accumulated_eval_time=300.871577, accumulated_logging_time=0.306151, accumulated_submission_time=1163.829433, global_step=4126, preemption_count=0, score=1163.829433, test/loss=0.293591, test/num_examples=3581, test/ssim=0.733667, total_duration=1467.180385, train/loss=0.272855, train/ssim=0.741935, validation/loss=0.291899, validation/num_examples=3554, validation/ssim=0.716638
I0609 02:17:28.019174 139698849601344 spec.py:298] Evaluating on the training split.
I0609 02:17:30.117291 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 02:17:32.260382 139698849601344 spec.py:326] Evaluating on the test split.
I0609 02:17:34.317701 139698849601344 submission_runner.py:419] Time since start: 1553.75s, 	Step: 4435, 	{'train/ssim': 0.7421386582510812, 'train/loss': 0.27287677356175016, 'validation/ssim': 0.7164057279210045, 'validation/loss': 0.2922272260898811, 'validation/num_examples': 3554, 'test/ssim': 0.7335655384974519, 'test/loss': 0.2938301962069778, 'test/num_examples': 3581, 'score': 1243.9568388462067, 'total_duration': 1553.7517426013947, 'accumulated_submission_time': 1243.9568388462067, 'accumulated_eval_time': 307.1701798439026, 'accumulated_logging_time': 0.3248918056488037}
I0609 02:17:34.328400 139631400056576 logging_writer.py:48] [4435] accumulated_eval_time=307.170180, accumulated_logging_time=0.324892, accumulated_submission_time=1243.956839, global_step=4435, preemption_count=0, score=1243.956839, test/loss=0.293830, test/num_examples=3581, test/ssim=0.733566, total_duration=1553.751743, train/loss=0.272877, train/ssim=0.742139, validation/loss=0.292227, validation/num_examples=3554, validation/ssim=0.716406
I0609 02:17:49.276815 139631483918080 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.081043, loss=0.256571
I0609 02:18:54.424938 139698849601344 spec.py:298] Evaluating on the training split.
I0609 02:18:56.541386 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 02:18:58.698696 139698849601344 spec.py:326] Evaluating on the test split.
I0609 02:19:00.779998 139698849601344 submission_runner.py:419] Time since start: 1640.21s, 	Step: 4745, 	{'train/ssim': 0.7391296114240374, 'train/loss': 0.27629237515585764, 'validation/ssim': 0.7140845372291784, 'validation/loss': 0.29572130846185635, 'validation/num_examples': 3554, 'test/ssim': 0.7308304271895071, 'test/loss': 0.2975607890385018, 'test/num_examples': 3581, 'score': 1323.9176995754242, 'total_duration': 1640.2140362262726, 'accumulated_submission_time': 1323.9176995754242, 'accumulated_eval_time': 313.5252287387848, 'accumulated_logging_time': 0.3438711166381836}
I0609 02:19:00.790476 139631400056576 logging_writer.py:48] [4745] accumulated_eval_time=313.525229, accumulated_logging_time=0.343871, accumulated_submission_time=1323.917700, global_step=4745, preemption_count=0, score=1323.917700, test/loss=0.297561, test/num_examples=3581, test/ssim=0.730830, total_duration=1640.214036, train/loss=0.276292, train/ssim=0.739130, validation/loss=0.295721, validation/num_examples=3554, validation/ssim=0.714085
I0609 02:20:06.827763 139631483918080 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.068002, loss=0.310131
I0609 02:20:20.927233 139698849601344 spec.py:298] Evaluating on the training split.
I0609 02:20:23.058175 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 02:20:25.200161 139698849601344 spec.py:326] Evaluating on the test split.
I0609 02:20:27.260676 139698849601344 submission_runner.py:419] Time since start: 1726.69s, 	Step: 5053, 	{'train/ssim': 0.7430697849818638, 'train/loss': 0.27367242744990755, 'validation/ssim': 0.7176744485746693, 'validation/loss': 0.2930424249635094, 'validation/num_examples': 3554, 'test/ssim': 0.7346668642880829, 'test/loss': 0.2946501569154042, 'test/num_examples': 3581, 'score': 1403.917526960373, 'total_duration': 1726.6947212219238, 'accumulated_submission_time': 1403.917526960373, 'accumulated_eval_time': 319.8586685657501, 'accumulated_logging_time': 0.36264491081237793}
I0609 02:20:27.271007 139631400056576 logging_writer.py:48] [5053] accumulated_eval_time=319.858669, accumulated_logging_time=0.362645, accumulated_submission_time=1403.917527, global_step=5053, preemption_count=0, score=1403.917527, test/loss=0.294650, test/num_examples=3581, test/ssim=0.734667, total_duration=1726.694721, train/loss=0.273672, train/ssim=0.743070, validation/loss=0.293042, validation/num_examples=3554, validation/ssim=0.717674
I0609 02:21:47.274738 139698849601344 spec.py:298] Evaluating on the training split.
I0609 02:21:49.433265 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 02:21:51.582323 139698849601344 spec.py:326] Evaluating on the test split.
I0609 02:21:53.642277 139698849601344 submission_runner.py:419] Time since start: 1813.08s, 	Step: 5361, 	{'train/ssim': 0.7422918592180524, 'train/loss': 0.2721843719482422, 'validation/ssim': 0.7172118591068163, 'validation/loss': 0.2911019741180712, 'validation/num_examples': 3554, 'test/ssim': 0.7344104518640044, 'test/loss': 0.2926350252417272, 'test/num_examples': 3581, 'score': 1483.7862079143524, 'total_duration': 1813.0762825012207, 'accumulated_submission_time': 1483.7862079143524, 'accumulated_eval_time': 326.22618556022644, 'accumulated_logging_time': 0.3809328079223633}
I0609 02:21:53.653808 139631483918080 logging_writer.py:48] [5361] accumulated_eval_time=326.226186, accumulated_logging_time=0.380933, accumulated_submission_time=1483.786208, global_step=5361, preemption_count=0, score=1483.786208, test/loss=0.292635, test/num_examples=3581, test/ssim=0.734410, total_duration=1813.076283, train/loss=0.272184, train/ssim=0.742292, validation/loss=0.291102, validation/num_examples=3554, validation/ssim=0.717212
I0609 02:22:09.323680 139698849601344 spec.py:298] Evaluating on the training split.
I0609 02:22:11.359189 139698849601344 spec.py:310] Evaluating on the validation split.
I0609 02:22:13.423014 139698849601344 spec.py:326] Evaluating on the test split.
I0609 02:22:15.455326 139698849601344 submission_runner.py:419] Time since start: 1834.89s, 	Step: 5428, 	{'train/ssim': 0.7409764017377581, 'train/loss': 0.2751833030155727, 'validation/ssim': 0.7158035510164603, 'validation/loss': 0.2949632978466165, 'validation/num_examples': 3554, 'test/ssim': 0.7324937332012706, 'test/loss': 0.29680430080197573, 'test/num_examples': 3581, 'score': 1499.419847726822, 'total_duration': 1834.8893656730652, 'accumulated_submission_time': 1499.419847726822, 'accumulated_eval_time': 332.3578906059265, 'accumulated_logging_time': 0.401289701461792}
I0609 02:22:15.467399 139631400056576 logging_writer.py:48] [5428] accumulated_eval_time=332.357891, accumulated_logging_time=0.401290, accumulated_submission_time=1499.419848, global_step=5428, preemption_count=0, score=1499.419848, test/loss=0.296804, test/num_examples=3581, test/ssim=0.732494, total_duration=1834.889366, train/loss=0.275183, train/ssim=0.740976, validation/loss=0.294963, validation/num_examples=3554, validation/ssim=0.715804
I0609 02:22:15.484013 139631483918080 logging_writer.py:48] [5428] global_step=5428, preemption_count=0, score=1499.419848
I0609 02:22:15.585868 139698849601344 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v4_b_pytorch/momentum/fastmri_pytorch/trial_1/checkpoint_5428.
I0609 02:22:16.249138 139698849601344 submission_runner.py:581] Tuning trial 1/1
I0609 02:22:16.249386 139698849601344 submission_runner.py:582] Hyperparameters: Hyperparameters(learning_rate=0.4394877561366806, one_minus_beta1=0.07113602458522507, warmup_factor=0.05, weight_decay=9.611851572925426e-07, label_smoothing=0.2, dropout_rate=0.0, decay_steps_factor=0.9, end_factor=0.001)
I0609 02:22:16.256612 139698849601344 submission_runner.py:583] Metrics: {'eval_results': [(1, {'train/ssim': 0.23183165277753556, 'train/loss': 0.9142254420689174, 'validation/ssim': 0.2223073672765282, 'validation/loss': 0.9188996305878939, 'validation/num_examples': 3554, 'test/ssim': 0.24476831047869835, 'test/loss': 0.917520352097005, 'test/num_examples': 3581, 'score': 44.68880796432495, 'total_duration': 255.85440182685852, 'accumulated_submission_time': 44.68880796432495, 'accumulated_eval_time': 211.16485118865967, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (304, {'train/ssim': 0.7050538744245257, 'train/loss': 0.310117312840053, 'validation/ssim': 0.6811622357730726, 'validation/loss': 0.3283568099434616, 'validation/num_examples': 3554, 'test/ssim': 0.6994467327562134, 'test/loss': 0.33001737959456157, 'test/num_examples': 3581, 'score': 124.44338369369507, 'total_duration': 342.58250308036804, 'accumulated_submission_time': 124.44338369369507, 'accumulated_eval_time': 217.87850165367126, 'accumulated_logging_time': 0.02450847625732422, 'global_step': 304, 'preemption_count': 0}), (552, {'train/ssim': 0.7185888290405273, 'train/loss': 0.2947260652269636, 'validation/ssim': 0.6948181736247889, 'validation/loss': 0.3128112896010657, 'validation/num_examples': 3554, 'test/ssim': 0.7127871328277716, 'test/loss': 0.3145155748219771, 'test/num_examples': 3581, 'score': 204.28152060508728, 'total_duration': 429.3508520126343, 'accumulated_submission_time': 204.28152060508728, 'accumulated_eval_time': 224.5434112548828, 'accumulated_logging_time': 0.05267524719238281, 'global_step': 552, 'preemption_count': 0}), (789, {'train/ssim': 0.6877471378871373, 'train/loss': 0.30157457079206196, 'validation/ssim': 0.6752608196750141, 'validation/loss': 0.3173056684589547, 'validation/num_examples': 3554, 'test/ssim': 0.6900995761047891, 'test/loss': 0.3193698213007889, 'test/num_examples': 3581, 'score': 284.1235613822937, 'total_duration': 516.0689830780029, 'accumulated_submission_time': 284.1235613822937, 'accumulated_eval_time': 231.17079710960388, 'accumulated_logging_time': 0.07995152473449707, 'global_step': 789, 'preemption_count': 0}), (1043, {'train/ssim': 0.7162162235804966, 'train/loss': 0.2913170542035784, 'validation/ssim': 0.6968592277187676, 'validation/loss': 0.3078993505886853, 'validation/num_examples': 3554, 'test/ssim': 0.7134541051076864, 'test/loss': 0.30957941408431655, 'test/num_examples': 3581, 'score': 364.1111071109772, 'total_duration': 602.627667427063, 'accumulated_submission_time': 364.1111071109772, 'accumulated_eval_time': 237.49877047538757, 'accumulated_logging_time': 0.11373090744018555, 'global_step': 1043, 'preemption_count': 0}), (1352, {'train/ssim': 0.7277191025870187, 'train/loss': 0.28359835488455637, 'validation/ssim': 0.7060472684826955, 'validation/loss': 0.30131260276712857, 'validation/num_examples': 3554, 'test/ssim': 0.7230621738428512, 'test/loss': 0.30292455379738553, 'test/num_examples': 3581, 'score': 444.21102690696716, 'total_duration': 689.2063443660736, 'accumulated_submission_time': 444.21102690696716, 'accumulated_eval_time': 243.8302230834961, 'accumulated_logging_time': 0.13417935371398926, 'global_step': 1352, 'preemption_count': 0}), (1661, {'train/ssim': 0.730959279196603, 'train/loss': 0.28135928085872103, 'validation/ssim': 0.7064434302678321, 'validation/loss': 0.2997164836276027, 'validation/num_examples': 3554, 'test/ssim': 0.7237950047778204, 'test/loss': 0.3013873405211533, 'test/num_examples': 3581, 'score': 524.1040704250336, 'total_duration': 775.5636084079742, 'accumulated_submission_time': 524.1040704250336, 'accumulated_eval_time': 250.14811897277832, 'accumulated_logging_time': 0.15277791023254395, 'global_step': 1661, 'preemption_count': 0}), (1970, {'train/ssim': 0.7295582635062081, 'train/loss': 0.2842108692441668, 'validation/ssim': 0.705371519656549, 'validation/loss': 0.30257012620023216, 'validation/num_examples': 3554, 'test/ssim': 0.7220486595922927, 'test/loss': 0.30437484183014524, 'test/num_examples': 3581, 'score': 603.9766030311584, 'total_duration': 861.908212184906, 'accumulated_submission_time': 603.9766030311584, 'accumulated_eval_time': 256.47515749931335, 'accumulated_logging_time': 0.17180967330932617, 'global_step': 1970, 'preemption_count': 0}), (2278, {'train/ssim': 0.7351153237479073, 'train/loss': 0.28016362871442524, 'validation/ssim': 0.7100888468538971, 'validation/loss': 0.2996104535052933, 'validation/num_examples': 3554, 'test/ssim': 0.7265384336384739, 'test/loss': 0.3017491881523143, 'test/num_examples': 3581, 'score': 683.9067974090576, 'total_duration': 948.3497834205627, 'accumulated_submission_time': 683.9067974090576, 'accumulated_eval_time': 262.841774225235, 'accumulated_logging_time': 0.19095230102539062, 'global_step': 2278, 'preemption_count': 0}), (2586, {'train/ssim': 0.7363369805472237, 'train/loss': 0.27739381790161133, 'validation/ssim': 0.7112446335774831, 'validation/loss': 0.29642031041168404, 'validation/num_examples': 3554, 'test/ssim': 0.7284122010044332, 'test/loss': 0.29813991569001325, 'test/num_examples': 3581, 'score': 763.7818076610565, 'total_duration': 1034.7202756404877, 'accumulated_submission_time': 763.7818076610565, 'accumulated_eval_time': 269.18935322761536, 'accumulated_logging_time': 0.21051359176635742, 'global_step': 2586, 'preemption_count': 0}), (2896, {'train/ssim': 0.7351399830409459, 'train/loss': 0.2755656582968576, 'validation/ssim': 0.7111969595218416, 'validation/loss': 0.29399604346554936, 'validation/num_examples': 3554, 'test/ssim': 0.7283603867416574, 'test/loss': 0.2955347150106465, 'test/num_examples': 3581, 'score': 843.6882035732269, 'total_duration': 1121.107403755188, 'accumulated_submission_time': 843.6882035732269, 'accumulated_eval_time': 275.52403807640076, 'accumulated_logging_time': 0.22920966148376465, 'global_step': 2896, 'preemption_count': 0}), (3202, {'train/ssim': 0.7391038622174945, 'train/loss': 0.27508429118565153, 'validation/ssim': 0.7151049268869584, 'validation/loss': 0.29366445460880347, 'validation/num_examples': 3554, 'test/ssim': 0.7322707955180118, 'test/loss': 0.2951925363463418, 'test/num_examples': 3581, 'score': 923.8249976634979, 'total_duration': 1207.7627158164978, 'accumulated_submission_time': 923.8249976634979, 'accumulated_eval_time': 281.9002809524536, 'accumulated_logging_time': 0.24816226959228516, 'global_step': 3202, 'preemption_count': 0}), (3510, {'train/ssim': 0.7394296101161412, 'train/loss': 0.2743322678974697, 'validation/ssim': 0.7139424767867192, 'validation/loss': 0.29380057296795864, 'validation/num_examples': 3554, 'test/ssim': 0.7309024217441008, 'test/loss': 0.2955651218016965, 'test/num_examples': 3581, 'score': 1003.8415973186493, 'total_duration': 1294.2503917217255, 'accumulated_submission_time': 1003.8415973186493, 'accumulated_eval_time': 288.22241711616516, 'accumulated_logging_time': 0.26803040504455566, 'global_step': 3510, 'preemption_count': 0}), (3819, {'train/ssim': 0.739415032523019, 'train/loss': 0.2737868172781808, 'validation/ssim': 0.7138551659441826, 'validation/loss': 0.293063067692213, 'validation/num_examples': 3554, 'test/ssim': 0.7309314650019199, 'test/loss': 0.29477713594753563, 'test/num_examples': 3581, 'score': 1083.8714389801025, 'total_duration': 1380.7474570274353, 'accumulated_submission_time': 1083.8714389801025, 'accumulated_eval_time': 294.543194770813, 'accumulated_logging_time': 0.2865629196166992, 'global_step': 3819, 'preemption_count': 0}), (4126, {'train/ssim': 0.7419346400669643, 'train/loss': 0.2728550945009504, 'validation/ssim': 0.7166384652416291, 'validation/loss': 0.2918993467417874, 'validation/num_examples': 3554, 'test/ssim': 0.7336673262531416, 'test/loss': 0.29359144153824, 'test/num_examples': 3581, 'score': 1163.829433441162, 'total_duration': 1467.180385351181, 'accumulated_submission_time': 1163.829433441162, 'accumulated_eval_time': 300.8715772628784, 'accumulated_logging_time': 0.3061511516571045, 'global_step': 4126, 'preemption_count': 0}), (4435, {'train/ssim': 0.7421386582510812, 'train/loss': 0.27287677356175016, 'validation/ssim': 0.7164057279210045, 'validation/loss': 0.2922272260898811, 'validation/num_examples': 3554, 'test/ssim': 0.7335655384974519, 'test/loss': 0.2938301962069778, 'test/num_examples': 3581, 'score': 1243.9568388462067, 'total_duration': 1553.7517426013947, 'accumulated_submission_time': 1243.9568388462067, 'accumulated_eval_time': 307.1701798439026, 'accumulated_logging_time': 0.3248918056488037, 'global_step': 4435, 'preemption_count': 0}), (4745, {'train/ssim': 0.7391296114240374, 'train/loss': 0.27629237515585764, 'validation/ssim': 0.7140845372291784, 'validation/loss': 0.29572130846185635, 'validation/num_examples': 3554, 'test/ssim': 0.7308304271895071, 'test/loss': 0.2975607890385018, 'test/num_examples': 3581, 'score': 1323.9176995754242, 'total_duration': 1640.2140362262726, 'accumulated_submission_time': 1323.9176995754242, 'accumulated_eval_time': 313.5252287387848, 'accumulated_logging_time': 0.3438711166381836, 'global_step': 4745, 'preemption_count': 0}), (5053, {'train/ssim': 0.7430697849818638, 'train/loss': 0.27367242744990755, 'validation/ssim': 0.7176744485746693, 'validation/loss': 0.2930424249635094, 'validation/num_examples': 3554, 'test/ssim': 0.7346668642880829, 'test/loss': 0.2946501569154042, 'test/num_examples': 3581, 'score': 1403.917526960373, 'total_duration': 1726.6947212219238, 'accumulated_submission_time': 1403.917526960373, 'accumulated_eval_time': 319.8586685657501, 'accumulated_logging_time': 0.36264491081237793, 'global_step': 5053, 'preemption_count': 0}), (5361, {'train/ssim': 0.7422918592180524, 'train/loss': 0.2721843719482422, 'validation/ssim': 0.7172118591068163, 'validation/loss': 0.2911019741180712, 'validation/num_examples': 3554, 'test/ssim': 0.7344104518640044, 'test/loss': 0.2926350252417272, 'test/num_examples': 3581, 'score': 1483.7862079143524, 'total_duration': 1813.0762825012207, 'accumulated_submission_time': 1483.7862079143524, 'accumulated_eval_time': 326.22618556022644, 'accumulated_logging_time': 0.3809328079223633, 'global_step': 5361, 'preemption_count': 0}), (5428, {'train/ssim': 0.7409764017377581, 'train/loss': 0.2751833030155727, 'validation/ssim': 0.7158035510164603, 'validation/loss': 0.2949632978466165, 'validation/num_examples': 3554, 'test/ssim': 0.7324937332012706, 'test/loss': 0.29680430080197573, 'test/num_examples': 3581, 'score': 1499.419847726822, 'total_duration': 1834.8893656730652, 'accumulated_submission_time': 1499.419847726822, 'accumulated_eval_time': 332.3578906059265, 'accumulated_logging_time': 0.401289701461792, 'global_step': 5428, 'preemption_count': 0})], 'global_step': 5428}
I0609 02:22:16.256775 139698849601344 submission_runner.py:584] Timing: 1499.419847726822
I0609 02:22:16.256825 139698849601344 submission_runner.py:586] Total number of evals: 20
I0609 02:22:16.256867 139698849601344 submission_runner.py:587] ====================
I0609 02:22:16.256973 139698849601344 submission_runner.py:655] Final fastmri score: 1499.419847726822
