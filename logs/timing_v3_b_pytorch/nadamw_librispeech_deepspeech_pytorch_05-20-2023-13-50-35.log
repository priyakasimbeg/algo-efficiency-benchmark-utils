torchrun --redirects 1:0,2:0,3:0,4:0,5:0,6:0,7:0 --standalone --nnodes=1 --nproc_per_node=8 submission_runner.py --framework=pytorch --workload=librispeech_deepspeech --submission_path=baselines/nadamw/pytorch/submission.py --tuning_search_space=baselines/nadamw/tuning_search_space.json --data_dir=/data/librispeech --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_v3_b_pytorch/timing_nadamw --overwrite=True --save_checkpoints=False --max_global_steps=16000 --librispeech_tokenizer_vocab_path=/data/librispeech/spm_model.vocab 2>&1 | tee -a /logs/librispeech_deepspeech_pytorch_05-20-2023-13-50-35.log
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
I0520 13:50:58.382470 140020588312384 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 1
I0520 13:50:58.382476 140174810892096 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 4
I0520 13:50:58.382492 140168352900928 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 6
I0520 13:50:58.382518 140136865224512 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 5
I0520 13:50:58.383237 140280073070400 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 3
I0520 13:50:58.383532 140280073070400 distributed_c10d.py:353] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0520 13:50:58.383361 140641177446208 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 7
I0520 13:50:58.383399 140109822056256 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 0
I0520 13:50:58.383415 140399762216768 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 2
I0520 13:50:58.383716 140399762216768 distributed_c10d.py:353] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0520 13:50:58.383709 140641177446208 distributed_c10d.py:353] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0520 13:50:58.383745 140109822056256 distributed_c10d.py:353] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0520 13:50:58.393115 140020588312384 distributed_c10d.py:353] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0520 13:50:58.393141 140174810892096 distributed_c10d.py:353] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0520 13:50:58.393169 140168352900928 distributed_c10d.py:353] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0520 13:50:58.393199 140136865224512 distributed_c10d.py:353] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0520 13:50:58.768031 140109822056256 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_v3_b_pytorch/timing_nadamw/librispeech_deepspeech_pytorch.
W0520 13:50:58.794507 140136865224512 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0520 13:50:58.796180 140020588312384 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0520 13:50:58.796516 140174810892096 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0520 13:50:58.796595 140399762216768 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0520 13:50:58.796679 140168352900928 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0520 13:50:58.797762 140280073070400 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0520 13:50:58.798477 140641177446208 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0520 13:50:58.803283 140109822056256 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0520 13:50:58.808209 140109822056256 submission_runner.py:544] Using RNG seed 4264816815
I0520 13:50:58.809908 140109822056256 submission_runner.py:553] --- Tuning run 1/1 ---
I0520 13:50:58.810052 140109822056256 submission_runner.py:558] Creating tuning directory at /experiment_runs/timing_v3_b_pytorch/timing_nadamw/librispeech_deepspeech_pytorch/trial_1.
I0520 13:50:58.810396 140109822056256 logger_utils.py:92] Saving hparams to /experiment_runs/timing_v3_b_pytorch/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/hparams.json.
I0520 13:50:58.811362 140109822056256 submission_runner.py:241] Initializing dataset.
I0520 13:50:58.811490 140109822056256 input_pipeline.py:20] Loading split = train-clean-100
I0520 13:50:59.066532 140109822056256 input_pipeline.py:20] Loading split = train-clean-360
I0520 13:50:59.418137 140109822056256 input_pipeline.py:20] Loading split = train-other-500
I0520 13:50:59.884847 140109822056256 submission_runner.py:248] Initializing model.
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
I0520 13:51:07.625118 140109822056256 submission_runner.py:258] Initializing optimizer.
I0520 13:51:07.626101 140109822056256 submission_runner.py:265] Initializing metrics bundle.
I0520 13:51:07.626221 140109822056256 submission_runner.py:283] Initializing checkpoint and logger.
I0520 13:51:07.628402 140109822056256 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0520 13:51:07.628521 140109822056256 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0520 13:51:08.245269 140109822056256 submission_runner.py:304] Saving meta data to /experiment_runs/timing_v3_b_pytorch/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/meta_data_0.json.
I0520 13:51:08.246335 140109822056256 submission_runner.py:307] Saving flags to /experiment_runs/timing_v3_b_pytorch/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/flags_0.json.
I0520 13:51:08.253289 140109822056256 submission_runner.py:319] Starting training loop.
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
I0520 13:51:17.466217 140083629905664 logging_writer.py:48] [0] global_step=0, grad_norm=23.926554, loss=33.403690
I0520 13:51:17.486673 140109822056256 submission.py:296] 0) loss = 33.404, grad_norm = 23.927
I0520 13:51:17.488011 140109822056256 spec.py:298] Evaluating on the training split.
I0520 13:51:17.489318 140109822056256 input_pipeline.py:20] Loading split = train-clean-100
I0520 13:51:17.526154 140109822056256 input_pipeline.py:20] Loading split = train-clean-360
I0520 13:51:17.657631 140109822056256 input_pipeline.py:20] Loading split = train-other-500
I0520 13:51:37.688763 140109822056256 spec.py:310] Evaluating on the validation split.
I0520 13:51:37.690135 140109822056256 input_pipeline.py:20] Loading split = dev-clean
I0520 13:51:37.693976 140109822056256 input_pipeline.py:20] Loading split = dev-other
I0520 13:51:50.192445 140109822056256 spec.py:326] Evaluating on the test split.
I0520 13:51:50.193812 140109822056256 input_pipeline.py:20] Loading split = test-clean
I0520 13:51:57.547192 140109822056256 submission_runner.py:421] Time since start: 49.29s, 	Step: 1, 	{'train/ctc_loss': 32.27484960012529, 'train/wer': 3.7131858498630614, 'validation/ctc_loss': 30.86392091119148, 'validation/wer': 3.3501762178342105, 'validation/num_examples': 5348, 'test/ctc_loss': 30.888170204529324, 'test/wer': 3.5340726748319216, 'test/num_examples': 2472, 'score': 9.233933210372925, 'total_duration': 49.29368805885315, 'accumulated_submission_time': 9.233933210372925, 'accumulated_eval_time': 40.058419704437256, 'accumulated_logging_time': 0}
I0520 13:51:57.574957 140082416879360 logging_writer.py:48] [1] accumulated_eval_time=40.058420, accumulated_logging_time=0, accumulated_submission_time=9.233933, global_step=1, preemption_count=0, score=9.233933, test/ctc_loss=30.888170, test/num_examples=2472, test/wer=3.534073, total_duration=49.293688, train/ctc_loss=32.274850, train/wer=3.713186, validation/ctc_loss=30.863921, validation/num_examples=5348, validation/wer=3.350176
I0520 13:51:57.618169 140109822056256 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0520 13:51:57.618211 140020588312384 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0520 13:51:57.618359 140399762216768 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0520 13:51:57.618518 140641177446208 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0520 13:51:57.618553 140136865224512 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0520 13:51:57.618502 140174810892096 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0520 13:51:57.618607 140168352900928 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0520 13:51:57.618897 140280073070400 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0520 13:51:58.757191 140081718351616 logging_writer.py:48] [1] global_step=1, grad_norm=20.703199, loss=32.815598
I0520 13:51:58.761018 140109822056256 submission.py:296] 1) loss = 32.816, grad_norm = 20.703
I0520 13:51:59.731085 140082416879360 logging_writer.py:48] [2] global_step=2, grad_norm=22.168421, loss=33.261696
I0520 13:51:59.735392 140109822056256 submission.py:296] 2) loss = 33.262, grad_norm = 22.168
I0520 13:52:00.545933 140081718351616 logging_writer.py:48] [3] global_step=3, grad_norm=23.643963, loss=33.372925
I0520 13:52:00.549458 140109822056256 submission.py:296] 3) loss = 33.373, grad_norm = 23.644
I0520 13:52:01.357579 140082416879360 logging_writer.py:48] [4] global_step=4, grad_norm=23.473433, loss=32.840603
I0520 13:52:01.361196 140109822056256 submission.py:296] 4) loss = 32.841, grad_norm = 23.473
I0520 13:52:02.204315 140081718351616 logging_writer.py:48] [5] global_step=5, grad_norm=26.335686, loss=33.121948
I0520 13:52:02.208319 140109822056256 submission.py:296] 5) loss = 33.122, grad_norm = 26.336
I0520 13:52:03.020988 140082416879360 logging_writer.py:48] [6] global_step=6, grad_norm=37.814449, loss=33.204498
I0520 13:52:03.024655 140109822056256 submission.py:296] 6) loss = 33.204, grad_norm = 37.814
I0520 13:52:03.836277 140081718351616 logging_writer.py:48] [7] global_step=7, grad_norm=44.012321, loss=32.149063
I0520 13:52:03.839998 140109822056256 submission.py:296] 7) loss = 32.149, grad_norm = 44.012
I0520 13:52:04.656783 140082416879360 logging_writer.py:48] [8] global_step=8, grad_norm=50.961056, loss=32.535839
I0520 13:52:04.660084 140109822056256 submission.py:296] 8) loss = 32.536, grad_norm = 50.961
I0520 13:52:05.462670 140081718351616 logging_writer.py:48] [9] global_step=9, grad_norm=58.860733, loss=32.060863
I0520 13:52:05.466064 140109822056256 submission.py:296] 9) loss = 32.061, grad_norm = 58.861
I0520 13:52:06.274209 140082416879360 logging_writer.py:48] [10] global_step=10, grad_norm=63.695999, loss=31.855659
I0520 13:52:06.278255 140109822056256 submission.py:296] 10) loss = 31.856, grad_norm = 63.696
I0520 13:52:07.087591 140081718351616 logging_writer.py:48] [11] global_step=11, grad_norm=66.140198, loss=31.774508
I0520 13:52:07.091642 140109822056256 submission.py:296] 11) loss = 31.775, grad_norm = 66.140
I0520 13:52:07.907636 140082416879360 logging_writer.py:48] [12] global_step=12, grad_norm=68.386726, loss=31.749287
I0520 13:52:07.911383 140109822056256 submission.py:296] 12) loss = 31.749, grad_norm = 68.387
I0520 13:52:08.727824 140081718351616 logging_writer.py:48] [13] global_step=13, grad_norm=66.557999, loss=30.975204
I0520 13:52:08.731990 140109822056256 submission.py:296] 13) loss = 30.975, grad_norm = 66.558
I0520 13:52:09.532271 140082416879360 logging_writer.py:48] [14] global_step=14, grad_norm=59.977436, loss=30.776800
I0520 13:52:09.536128 140109822056256 submission.py:296] 14) loss = 30.777, grad_norm = 59.977
I0520 13:52:10.340737 140081718351616 logging_writer.py:48] [15] global_step=15, grad_norm=55.008583, loss=29.663734
I0520 13:52:10.344213 140109822056256 submission.py:296] 15) loss = 29.664, grad_norm = 55.009
I0520 13:52:11.149575 140082416879360 logging_writer.py:48] [16] global_step=16, grad_norm=54.040295, loss=30.040016
I0520 13:52:11.152827 140109822056256 submission.py:296] 16) loss = 30.040, grad_norm = 54.040
I0520 13:52:11.952335 140081718351616 logging_writer.py:48] [17] global_step=17, grad_norm=49.239021, loss=29.632130
I0520 13:52:11.955737 140109822056256 submission.py:296] 17) loss = 29.632, grad_norm = 49.239
I0520 13:52:12.768149 140082416879360 logging_writer.py:48] [18] global_step=18, grad_norm=44.557644, loss=29.361826
I0520 13:52:12.771706 140109822056256 submission.py:296] 18) loss = 29.362, grad_norm = 44.558
I0520 13:52:13.592107 140081718351616 logging_writer.py:48] [19] global_step=19, grad_norm=41.179905, loss=28.764259
I0520 13:52:13.595170 140109822056256 submission.py:296] 19) loss = 28.764, grad_norm = 41.180
I0520 13:52:14.411627 140082416879360 logging_writer.py:48] [20] global_step=20, grad_norm=39.183861, loss=28.052179
I0520 13:52:14.415699 140109822056256 submission.py:296] 20) loss = 28.052, grad_norm = 39.184
I0520 13:52:15.223824 140081718351616 logging_writer.py:48] [21] global_step=21, grad_norm=37.276390, loss=28.122702
I0520 13:52:15.227780 140109822056256 submission.py:296] 21) loss = 28.123, grad_norm = 37.276
I0520 13:52:16.047397 140082416879360 logging_writer.py:48] [22] global_step=22, grad_norm=35.998535, loss=28.445049
I0520 13:52:16.051517 140109822056256 submission.py:296] 22) loss = 28.445, grad_norm = 35.999
I0520 13:52:16.865755 140081718351616 logging_writer.py:48] [23] global_step=23, grad_norm=32.209351, loss=27.521179
I0520 13:52:16.869803 140109822056256 submission.py:296] 23) loss = 27.521, grad_norm = 32.209
I0520 13:52:17.684746 140082416879360 logging_writer.py:48] [24] global_step=24, grad_norm=31.020321, loss=27.773926
I0520 13:52:17.688484 140109822056256 submission.py:296] 24) loss = 27.774, grad_norm = 31.020
I0520 13:52:18.495456 140081718351616 logging_writer.py:48] [25] global_step=25, grad_norm=29.943016, loss=27.679209
I0520 13:52:18.499114 140109822056256 submission.py:296] 25) loss = 27.679, grad_norm = 29.943
I0520 13:52:19.321087 140082416879360 logging_writer.py:48] [26] global_step=26, grad_norm=29.649179, loss=27.279066
I0520 13:52:19.324693 140109822056256 submission.py:296] 26) loss = 27.279, grad_norm = 29.649
I0520 13:52:20.151399 140081718351616 logging_writer.py:48] [27] global_step=27, grad_norm=29.554729, loss=27.306791
I0520 13:52:20.155467 140109822056256 submission.py:296] 27) loss = 27.307, grad_norm = 29.555
I0520 13:52:20.969269 140082416879360 logging_writer.py:48] [28] global_step=28, grad_norm=28.154009, loss=26.945845
I0520 13:52:20.972768 140109822056256 submission.py:296] 28) loss = 26.946, grad_norm = 28.154
I0520 13:52:21.775716 140081718351616 logging_writer.py:48] [29] global_step=29, grad_norm=29.336422, loss=26.308546
I0520 13:52:21.779284 140109822056256 submission.py:296] 29) loss = 26.309, grad_norm = 29.336
I0520 13:52:22.593396 140082416879360 logging_writer.py:48] [30] global_step=30, grad_norm=29.206909, loss=26.065063
I0520 13:52:22.597489 140109822056256 submission.py:296] 30) loss = 26.065, grad_norm = 29.207
I0520 13:52:23.407979 140081718351616 logging_writer.py:48] [31] global_step=31, grad_norm=29.423367, loss=26.075081
I0520 13:52:23.412097 140109822056256 submission.py:296] 31) loss = 26.075, grad_norm = 29.423
I0520 13:52:24.214442 140082416879360 logging_writer.py:48] [32] global_step=32, grad_norm=28.958956, loss=25.851252
I0520 13:52:24.217772 140109822056256 submission.py:296] 32) loss = 25.851, grad_norm = 28.959
I0520 13:52:25.021047 140081718351616 logging_writer.py:48] [33] global_step=33, grad_norm=29.741716, loss=25.868967
I0520 13:52:25.024551 140109822056256 submission.py:296] 33) loss = 25.869, grad_norm = 29.742
I0520 13:52:25.828444 140082416879360 logging_writer.py:48] [34] global_step=34, grad_norm=29.628441, loss=25.665966
I0520 13:52:25.831638 140109822056256 submission.py:296] 34) loss = 25.666, grad_norm = 29.628
I0520 13:52:26.641334 140081718351616 logging_writer.py:48] [35] global_step=35, grad_norm=29.449764, loss=25.449511
I0520 13:52:26.644762 140109822056256 submission.py:296] 35) loss = 25.450, grad_norm = 29.450
I0520 13:52:27.443198 140082416879360 logging_writer.py:48] [36] global_step=36, grad_norm=29.971245, loss=24.944073
I0520 13:52:27.446713 140109822056256 submission.py:296] 36) loss = 24.944, grad_norm = 29.971
I0520 13:52:28.246031 140081718351616 logging_writer.py:48] [37] global_step=37, grad_norm=30.112885, loss=24.228079
I0520 13:52:28.249224 140109822056256 submission.py:296] 37) loss = 24.228, grad_norm = 30.113
I0520 13:52:29.050686 140082416879360 logging_writer.py:48] [38] global_step=38, grad_norm=29.951481, loss=24.305710
I0520 13:52:29.053969 140109822056256 submission.py:296] 38) loss = 24.306, grad_norm = 29.951
I0520 13:52:29.858112 140081718351616 logging_writer.py:48] [39] global_step=39, grad_norm=31.236776, loss=24.142076
I0520 13:52:29.861501 140109822056256 submission.py:296] 39) loss = 24.142, grad_norm = 31.237
I0520 13:52:30.665850 140082416879360 logging_writer.py:48] [40] global_step=40, grad_norm=30.883362, loss=23.558115
I0520 13:52:30.669604 140109822056256 submission.py:296] 40) loss = 23.558, grad_norm = 30.883
I0520 13:52:31.470335 140081718351616 logging_writer.py:48] [41] global_step=41, grad_norm=29.668539, loss=23.104570
I0520 13:52:31.474105 140109822056256 submission.py:296] 41) loss = 23.105, grad_norm = 29.669
I0520 13:52:32.281009 140082416879360 logging_writer.py:48] [42] global_step=42, grad_norm=29.588440, loss=22.848009
I0520 13:52:32.284428 140109822056256 submission.py:296] 42) loss = 22.848, grad_norm = 29.588
I0520 13:52:33.089126 140081718351616 logging_writer.py:48] [43] global_step=43, grad_norm=29.852158, loss=22.325893
I0520 13:52:33.092805 140109822056256 submission.py:296] 43) loss = 22.326, grad_norm = 29.852
I0520 13:52:33.897682 140082416879360 logging_writer.py:48] [44] global_step=44, grad_norm=30.106239, loss=22.082869
I0520 13:52:33.901123 140109822056256 submission.py:296] 44) loss = 22.083, grad_norm = 30.106
I0520 13:52:34.704461 140081718351616 logging_writer.py:48] [45] global_step=45, grad_norm=29.375317, loss=21.406498
I0520 13:52:34.708000 140109822056256 submission.py:296] 45) loss = 21.406, grad_norm = 29.375
I0520 13:52:35.514205 140082416879360 logging_writer.py:48] [46] global_step=46, grad_norm=28.045990, loss=20.773296
I0520 13:52:35.517412 140109822056256 submission.py:296] 46) loss = 20.773, grad_norm = 28.046
I0520 13:52:36.330161 140081718351616 logging_writer.py:48] [47] global_step=47, grad_norm=27.465313, loss=20.581797
I0520 13:52:36.334125 140109822056256 submission.py:296] 47) loss = 20.582, grad_norm = 27.465
I0520 13:52:37.139590 140082416879360 logging_writer.py:48] [48] global_step=48, grad_norm=26.711731, loss=20.763334
I0520 13:52:37.143111 140109822056256 submission.py:296] 48) loss = 20.763, grad_norm = 26.712
I0520 13:52:37.946146 140081718351616 logging_writer.py:48] [49] global_step=49, grad_norm=26.019873, loss=20.398445
I0520 13:52:37.949921 140109822056256 submission.py:296] 49) loss = 20.398, grad_norm = 26.020
I0520 13:52:38.764837 140082416879360 logging_writer.py:48] [50] global_step=50, grad_norm=24.958271, loss=19.559595
I0520 13:52:38.768756 140109822056256 submission.py:296] 50) loss = 19.560, grad_norm = 24.958
I0520 13:52:39.575665 140081718351616 logging_writer.py:48] [51] global_step=51, grad_norm=23.353346, loss=19.146017
I0520 13:52:39.579190 140109822056256 submission.py:296] 51) loss = 19.146, grad_norm = 23.353
I0520 13:52:40.385985 140082416879360 logging_writer.py:48] [52] global_step=52, grad_norm=21.842787, loss=18.748343
I0520 13:52:40.389297 140109822056256 submission.py:296] 52) loss = 18.748, grad_norm = 21.843
I0520 13:52:41.196182 140081718351616 logging_writer.py:48] [53] global_step=53, grad_norm=21.634346, loss=18.406332
I0520 13:52:41.199655 140109822056256 submission.py:296] 53) loss = 18.406, grad_norm = 21.634
I0520 13:52:42.005701 140082416879360 logging_writer.py:48] [54] global_step=54, grad_norm=21.246950, loss=18.581917
I0520 13:52:42.010001 140109822056256 submission.py:296] 54) loss = 18.582, grad_norm = 21.247
I0520 13:52:42.812119 140081718351616 logging_writer.py:48] [55] global_step=55, grad_norm=21.201693, loss=18.301350
I0520 13:52:42.816277 140109822056256 submission.py:296] 55) loss = 18.301, grad_norm = 21.202
I0520 13:52:43.640251 140082416879360 logging_writer.py:48] [56] global_step=56, grad_norm=20.123863, loss=17.718424
I0520 13:52:43.643838 140109822056256 submission.py:296] 56) loss = 17.718, grad_norm = 20.124
I0520 13:52:44.448463 140081718351616 logging_writer.py:48] [57] global_step=57, grad_norm=19.116468, loss=17.614328
I0520 13:52:44.451681 140109822056256 submission.py:296] 57) loss = 17.614, grad_norm = 19.116
I0520 13:52:45.256771 140082416879360 logging_writer.py:48] [58] global_step=58, grad_norm=19.073650, loss=17.006592
I0520 13:52:45.260105 140109822056256 submission.py:296] 58) loss = 17.007, grad_norm = 19.074
I0520 13:52:46.063170 140081718351616 logging_writer.py:48] [59] global_step=59, grad_norm=18.465330, loss=16.995943
I0520 13:52:46.066896 140109822056256 submission.py:296] 59) loss = 16.996, grad_norm = 18.465
I0520 13:52:46.870480 140082416879360 logging_writer.py:48] [60] global_step=60, grad_norm=18.261171, loss=16.565542
I0520 13:52:46.874282 140109822056256 submission.py:296] 60) loss = 16.566, grad_norm = 18.261
I0520 13:52:47.681921 140081718351616 logging_writer.py:48] [61] global_step=61, grad_norm=17.043234, loss=16.472120
I0520 13:52:47.686111 140109822056256 submission.py:296] 61) loss = 16.472, grad_norm = 17.043
I0520 13:52:48.507534 140082416879360 logging_writer.py:48] [62] global_step=62, grad_norm=17.563349, loss=16.242891
I0520 13:52:48.511321 140109822056256 submission.py:296] 62) loss = 16.243, grad_norm = 17.563
I0520 13:52:49.320914 140081718351616 logging_writer.py:48] [63] global_step=63, grad_norm=18.082052, loss=15.899817
I0520 13:52:49.324147 140109822056256 submission.py:296] 63) loss = 15.900, grad_norm = 18.082
I0520 13:52:50.132856 140082416879360 logging_writer.py:48] [64] global_step=64, grad_norm=17.475290, loss=15.547528
I0520 13:52:50.136234 140109822056256 submission.py:296] 64) loss = 15.548, grad_norm = 17.475
I0520 13:52:50.941894 140081718351616 logging_writer.py:48] [65] global_step=65, grad_norm=16.186651, loss=15.605754
I0520 13:52:50.945399 140109822056256 submission.py:296] 65) loss = 15.606, grad_norm = 16.187
I0520 13:52:51.768436 140082416879360 logging_writer.py:48] [66] global_step=66, grad_norm=15.732021, loss=14.996341
I0520 13:52:51.772535 140109822056256 submission.py:296] 66) loss = 14.996, grad_norm = 15.732
I0520 13:52:52.573583 140081718351616 logging_writer.py:48] [67] global_step=67, grad_norm=15.859512, loss=14.681341
I0520 13:52:52.577347 140109822056256 submission.py:296] 67) loss = 14.681, grad_norm = 15.860
I0520 13:52:53.381836 140082416879360 logging_writer.py:48] [68] global_step=68, grad_norm=15.074056, loss=14.467034
I0520 13:52:53.386048 140109822056256 submission.py:296] 68) loss = 14.467, grad_norm = 15.074
I0520 13:52:54.189402 140081718351616 logging_writer.py:48] [69] global_step=69, grad_norm=15.506482, loss=14.598104
I0520 13:52:54.192869 140109822056256 submission.py:296] 69) loss = 14.598, grad_norm = 15.506
I0520 13:52:55.001763 140082416879360 logging_writer.py:48] [70] global_step=70, grad_norm=15.570997, loss=13.915805
I0520 13:52:55.005248 140109822056256 submission.py:296] 70) loss = 13.916, grad_norm = 15.571
I0520 13:52:55.810339 140081718351616 logging_writer.py:48] [71] global_step=71, grad_norm=14.286454, loss=14.255552
I0520 13:52:55.814250 140109822056256 submission.py:296] 71) loss = 14.256, grad_norm = 14.286
I0520 13:52:56.618900 140082416879360 logging_writer.py:48] [72] global_step=72, grad_norm=13.739781, loss=13.672636
I0520 13:52:56.622606 140109822056256 submission.py:296] 72) loss = 13.673, grad_norm = 13.740
I0520 13:52:57.424164 140081718351616 logging_writer.py:48] [73] global_step=73, grad_norm=13.352114, loss=13.691708
I0520 13:52:57.428087 140109822056256 submission.py:296] 73) loss = 13.692, grad_norm = 13.352
I0520 13:52:58.234011 140082416879360 logging_writer.py:48] [74] global_step=74, grad_norm=12.931488, loss=13.546185
I0520 13:52:58.238008 140109822056256 submission.py:296] 74) loss = 13.546, grad_norm = 12.931
I0520 13:52:59.059498 140081718351616 logging_writer.py:48] [75] global_step=75, grad_norm=13.109772, loss=13.277159
I0520 13:52:59.063224 140109822056256 submission.py:296] 75) loss = 13.277, grad_norm = 13.110
I0520 13:52:59.893708 140082416879360 logging_writer.py:48] [76] global_step=76, grad_norm=12.573799, loss=12.804291
I0520 13:52:59.897905 140109822056256 submission.py:296] 76) loss = 12.804, grad_norm = 12.574
I0520 13:53:00.704662 140081718351616 logging_writer.py:48] [77] global_step=77, grad_norm=11.342838, loss=12.919258
I0520 13:53:00.708583 140109822056256 submission.py:296] 77) loss = 12.919, grad_norm = 11.343
I0520 13:53:01.511453 140082416879360 logging_writer.py:48] [78] global_step=78, grad_norm=11.501217, loss=12.464204
I0520 13:53:01.515091 140109822056256 submission.py:296] 78) loss = 12.464, grad_norm = 11.501
I0520 13:53:02.319366 140081718351616 logging_writer.py:48] [79] global_step=79, grad_norm=10.736858, loss=12.456160
I0520 13:53:02.322838 140109822056256 submission.py:296] 79) loss = 12.456, grad_norm = 10.737
I0520 13:53:03.132022 140082416879360 logging_writer.py:48] [80] global_step=80, grad_norm=10.414288, loss=12.233236
I0520 13:53:03.135509 140109822056256 submission.py:296] 80) loss = 12.233, grad_norm = 10.414
I0520 13:53:03.939154 140081718351616 logging_writer.py:48] [81] global_step=81, grad_norm=9.557123, loss=12.033684
I0520 13:53:03.942394 140109822056256 submission.py:296] 81) loss = 12.034, grad_norm = 9.557
I0520 13:53:04.748980 140082416879360 logging_writer.py:48] [82] global_step=82, grad_norm=10.133137, loss=11.966186
I0520 13:53:04.752589 140109822056256 submission.py:296] 82) loss = 11.966, grad_norm = 10.133
I0520 13:53:05.555721 140081718351616 logging_writer.py:48] [83] global_step=83, grad_norm=10.179463, loss=12.012013
I0520 13:53:05.559096 140109822056256 submission.py:296] 83) loss = 12.012, grad_norm = 10.179
I0520 13:53:06.365045 140082416879360 logging_writer.py:48] [84] global_step=84, grad_norm=8.626583, loss=11.451635
I0520 13:53:06.368640 140109822056256 submission.py:296] 84) loss = 11.452, grad_norm = 8.627
I0520 13:53:07.174069 140081718351616 logging_writer.py:48] [85] global_step=85, grad_norm=8.696473, loss=11.474666
I0520 13:53:07.177556 140109822056256 submission.py:296] 85) loss = 11.475, grad_norm = 8.696
I0520 13:53:07.989218 140082416879360 logging_writer.py:48] [86] global_step=86, grad_norm=8.723422, loss=11.290813
I0520 13:53:07.992662 140109822056256 submission.py:296] 86) loss = 11.291, grad_norm = 8.723
I0520 13:53:08.791857 140081718351616 logging_writer.py:48] [87] global_step=87, grad_norm=8.454959, loss=11.221189
I0520 13:53:08.795457 140109822056256 submission.py:296] 87) loss = 11.221, grad_norm = 8.455
I0520 13:53:09.596451 140082416879360 logging_writer.py:48] [88] global_step=88, grad_norm=8.643545, loss=11.301538
I0520 13:53:09.599838 140109822056256 submission.py:296] 88) loss = 11.302, grad_norm = 8.644
I0520 13:53:10.403813 140081718351616 logging_writer.py:48] [89] global_step=89, grad_norm=9.402981, loss=11.369516
I0520 13:53:10.407234 140109822056256 submission.py:296] 89) loss = 11.370, grad_norm = 9.403
I0520 13:53:11.212536 140082416879360 logging_writer.py:48] [90] global_step=90, grad_norm=7.832765, loss=10.838891
I0520 13:53:11.215741 140109822056256 submission.py:296] 90) loss = 10.839, grad_norm = 7.833
I0520 13:53:12.020898 140081718351616 logging_writer.py:48] [91] global_step=91, grad_norm=8.165478, loss=10.769048
I0520 13:53:12.024152 140109822056256 submission.py:296] 91) loss = 10.769, grad_norm = 8.165
I0520 13:53:12.832274 140082416879360 logging_writer.py:48] [92] global_step=92, grad_norm=8.152390, loss=10.566314
I0520 13:53:12.835561 140109822056256 submission.py:296] 92) loss = 10.566, grad_norm = 8.152
I0520 13:53:13.644213 140081718351616 logging_writer.py:48] [93] global_step=93, grad_norm=8.351096, loss=10.766942
I0520 13:53:13.647535 140109822056256 submission.py:296] 93) loss = 10.767, grad_norm = 8.351
I0520 13:53:14.453453 140082416879360 logging_writer.py:48] [94] global_step=94, grad_norm=7.813229, loss=10.214792
I0520 13:53:14.456778 140109822056256 submission.py:296] 94) loss = 10.215, grad_norm = 7.813
I0520 13:53:15.264374 140081718351616 logging_writer.py:48] [95] global_step=95, grad_norm=7.948597, loss=10.504868
I0520 13:53:15.267771 140109822056256 submission.py:296] 95) loss = 10.505, grad_norm = 7.949
I0520 13:53:16.099614 140082416879360 logging_writer.py:48] [96] global_step=96, grad_norm=9.043874, loss=10.606936
I0520 13:53:16.103212 140109822056256 submission.py:296] 96) loss = 10.607, grad_norm = 9.044
I0520 13:53:16.908747 140081718351616 logging_writer.py:48] [97] global_step=97, grad_norm=7.972972, loss=10.304939
I0520 13:53:16.912315 140109822056256 submission.py:296] 97) loss = 10.305, grad_norm = 7.973
I0520 13:53:17.720493 140082416879360 logging_writer.py:48] [98] global_step=98, grad_norm=7.038514, loss=9.998799
I0520 13:53:17.723812 140109822056256 submission.py:296] 98) loss = 9.999, grad_norm = 7.039
I0520 13:53:18.529299 140081718351616 logging_writer.py:48] [99] global_step=99, grad_norm=7.183805, loss=10.026567
I0520 13:53:18.532829 140109822056256 submission.py:296] 99) loss = 10.027, grad_norm = 7.184
I0520 13:53:19.341208 140082416879360 logging_writer.py:48] [100] global_step=100, grad_norm=7.745939, loss=10.144212
I0520 13:53:19.344483 140109822056256 submission.py:296] 100) loss = 10.144, grad_norm = 7.746
I0520 13:58:40.331502 140081718351616 logging_writer.py:48] [500] global_step=500, grad_norm=0.504724, loss=5.782168
I0520 13:58:40.335801 140109822056256 submission.py:296] 500) loss = 5.782, grad_norm = 0.505
I0520 14:05:22.351200 140082416879360 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.055028, loss=4.823012
I0520 14:05:22.357164 140109822056256 submission.py:296] 1000) loss = 4.823, grad_norm = 1.055
I0520 14:12:05.479491 140082416879360 logging_writer.py:48] [1500] global_step=1500, grad_norm=3.089149, loss=3.601115
I0520 14:12:05.486816 140109822056256 submission.py:296] 1500) loss = 3.601, grad_norm = 3.089
I0520 14:18:46.017728 140081718351616 logging_writer.py:48] [2000] global_step=2000, grad_norm=2.370984, loss=3.055185
I0520 14:18:46.022858 140109822056256 submission.py:296] 2000) loss = 3.055, grad_norm = 2.371
I0520 14:25:27.493737 140081718351616 logging_writer.py:48] [2500] global_step=2500, grad_norm=2.445300, loss=2.691873
I0520 14:25:27.501194 140109822056256 submission.py:296] 2500) loss = 2.692, grad_norm = 2.445
I0520 14:31:58.372946 140109822056256 spec.py:298] Evaluating on the training split.
I0520 14:32:08.458628 140109822056256 spec.py:310] Evaluating on the validation split.
I0520 14:32:17.363677 140109822056256 spec.py:326] Evaluating on the test split.
I0520 14:32:22.267751 140109822056256 submission_runner.py:421] Time since start: 2474.01s, 	Step: 2988, 	{'train/ctc_loss': 5.067832301160641, 'train/wer': 0.911199560054231, 'validation/ctc_loss': 5.0046247896574245, 'validation/wer': 0.8741370154009559, 'validation/num_examples': 5348, 'test/ctc_loss': 4.801908187625008, 'test/wer': 0.8691121808543051, 'test/num_examples': 2472, 'score': 1502.1992180347443, 'total_duration': 2474.0146083831787, 'accumulated_submission_time': 1502.1992180347443, 'accumulated_eval_time': 63.952823877334595, 'accumulated_logging_time': 0.037455081939697266}
I0520 14:32:22.288777 140081718351616 logging_writer.py:48] [2988] accumulated_eval_time=63.952824, accumulated_logging_time=0.037455, accumulated_submission_time=1502.199218, global_step=2988, preemption_count=0, score=1502.199218, test/ctc_loss=4.801908, test/num_examples=2472, test/wer=0.869112, total_duration=2474.014608, train/ctc_loss=5.067832, train/wer=0.911200, validation/ctc_loss=5.004625, validation/num_examples=5348, validation/wer=0.874137
I0520 14:32:32.835747 140081709958912 logging_writer.py:48] [3000] global_step=3000, grad_norm=3.218810, loss=2.483889
I0520 14:32:32.839495 140109822056256 submission.py:296] 3000) loss = 2.484, grad_norm = 3.219
I0520 14:39:15.286305 140081718351616 logging_writer.py:48] [3500] global_step=3500, grad_norm=4.187269, loss=2.351324
I0520 14:39:15.296358 140109822056256 submission.py:296] 3500) loss = 2.351, grad_norm = 4.187
I0520 14:45:55.314593 140081709958912 logging_writer.py:48] [4000] global_step=4000, grad_norm=4.248316, loss=2.232481
I0520 14:45:55.319626 140109822056256 submission.py:296] 4000) loss = 2.232, grad_norm = 4.248
I0520 14:52:37.531455 140081718351616 logging_writer.py:48] [4500] global_step=4500, grad_norm=4.302562, loss=2.105106
I0520 14:52:37.538341 140109822056256 submission.py:296] 4500) loss = 2.105, grad_norm = 4.303
I0520 14:59:18.099011 140081709958912 logging_writer.py:48] [5000] global_step=5000, grad_norm=3.561270, loss=2.048629
I0520 14:59:18.104177 140109822056256 submission.py:296] 5000) loss = 2.049, grad_norm = 3.561
I0520 15:05:59.525278 140081718351616 logging_writer.py:48] [5500] global_step=5500, grad_norm=3.187746, loss=2.001603
I0520 15:05:59.532020 140109822056256 submission.py:296] 5500) loss = 2.002, grad_norm = 3.188
I0520 15:12:23.397725 140109822056256 spec.py:298] Evaluating on the training split.
I0520 15:12:35.121220 140109822056256 spec.py:310] Evaluating on the validation split.
I0520 15:12:44.784491 140109822056256 spec.py:326] Evaluating on the test split.
I0520 15:12:50.088637 140109822056256 submission_runner.py:421] Time since start: 4901.84s, 	Step: 5979, 	{'train/ctc_loss': 0.9208451502636892, 'train/wer': 0.29059289226229046, 'validation/ctc_loss': 1.2025914911718907, 'validation/wer': 0.3284507314247091, 'validation/num_examples': 5348, 'test/ctc_loss': 0.8170213602490484, 'test/wer': 0.25937887189486725, 'test/num_examples': 2472, 'score': 2969.1707084178925, 'total_duration': 4901.835519313812, 'accumulated_submission_time': 2969.1707084178925, 'accumulated_eval_time': 90.64335584640503, 'accumulated_logging_time': 0.06834626197814941}
I0520 15:12:50.110540 140081718351616 logging_writer.py:48] [5979] accumulated_eval_time=90.643356, accumulated_logging_time=0.068346, accumulated_submission_time=2969.170708, global_step=5979, preemption_count=0, score=2969.170708, test/ctc_loss=0.817021, test/num_examples=2472, test/wer=0.259379, total_duration=4901.835519, train/ctc_loss=0.920845, train/wer=0.290593, validation/ctc_loss=1.202591, validation/num_examples=5348, validation/wer=0.328451
I0520 15:13:07.740471 140081709958912 logging_writer.py:48] [6000] global_step=6000, grad_norm=3.152628, loss=2.116417
I0520 15:13:07.744525 140109822056256 submission.py:296] 6000) loss = 2.116, grad_norm = 3.153
I0520 15:19:48.504366 140081718351616 logging_writer.py:48] [6500] global_step=6500, grad_norm=2.123719, loss=1.857227
I0520 15:19:48.512440 140109822056256 submission.py:296] 6500) loss = 1.857, grad_norm = 2.124
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
I0520 15:26:27.142646 140081709958912 logging_writer.py:48] [7000] global_step=7000, grad_norm=3.261491, loss=1.838539
I0520 15:26:27.148378 140109822056256 submission.py:296] 7000) loss = 1.839, grad_norm = 3.261
I0520 15:33:08.181143 140081709958912 logging_writer.py:48] [7500] global_step=7500, grad_norm=4.666394, loss=1.843139
I0520 15:33:08.188848 140109822056256 submission.py:296] 7500) loss = 1.843, grad_norm = 4.666
I0520 15:39:48.990701 140081666979584 logging_writer.py:48] [8000] global_step=8000, grad_norm=3.275461, loss=1.728473
I0520 15:39:48.996778 140109822056256 submission.py:296] 8000) loss = 1.728, grad_norm = 3.275
I0520 15:46:30.927039 140081666979584 logging_writer.py:48] [8500] global_step=8500, grad_norm=2.963238, loss=1.716728
I0520 15:46:30.934006 140109822056256 submission.py:296] 8500) loss = 1.717, grad_norm = 2.963
I0520 15:52:50.840124 140109822056256 spec.py:298] Evaluating on the training split.
I0520 15:53:03.023093 140109822056256 spec.py:310] Evaluating on the validation split.
I0520 15:53:12.947702 140109822056256 spec.py:326] Evaluating on the test split.
I0520 15:53:18.162634 140109822056256 submission_runner.py:421] Time since start: 7329.91s, 	Step: 8976, 	{'train/ctc_loss': 0.6027445742840898, 'train/wer': 0.20133508295264593, 'validation/ctc_loss': 0.8633008715089411, 'validation/wer': 0.24752570849225125, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5424711876572682, 'test/wer': 0.1794528060447261, 'test/num_examples': 2472, 'score': 4435.118803024292, 'total_duration': 7329.909523963928, 'accumulated_submission_time': 4435.118803024292, 'accumulated_eval_time': 117.96551489830017, 'accumulated_logging_time': 0.10106897354125977}
I0520 15:53:18.187174 140081666979584 logging_writer.py:48] [8976] accumulated_eval_time=117.965515, accumulated_logging_time=0.101069, accumulated_submission_time=4435.118803, global_step=8976, preemption_count=0, score=4435.118803, test/ctc_loss=0.542471, test/num_examples=2472, test/wer=0.179453, total_duration=7329.909524, train/ctc_loss=0.602745, train/wer=0.201335, validation/ctc_loss=0.863301, validation/num_examples=5348, validation/wer=0.247526
I0520 15:53:38.073152 140081658586880 logging_writer.py:48] [9000] global_step=9000, grad_norm=3.011566, loss=1.735723
I0520 15:53:38.077214 140109822056256 submission.py:296] 9000) loss = 1.736, grad_norm = 3.012
I0520 16:00:19.402893 140081666979584 logging_writer.py:48] [9500] global_step=9500, grad_norm=3.452910, loss=1.768450
I0520 16:00:19.410158 140109822056256 submission.py:296] 9500) loss = 1.768, grad_norm = 3.453
I0520 16:06:58.655868 140081658586880 logging_writer.py:48] [10000] global_step=10000, grad_norm=3.726221, loss=1.763037
I0520 16:06:58.661220 140109822056256 submission.py:296] 10000) loss = 1.763, grad_norm = 3.726
I0520 16:13:40.389912 140081666979584 logging_writer.py:48] [10500] global_step=10500, grad_norm=3.124222, loss=1.642180
I0520 16:13:40.397765 140109822056256 submission.py:296] 10500) loss = 1.642, grad_norm = 3.124
I0520 16:20:19.913747 140081658586880 logging_writer.py:48] [11000] global_step=11000, grad_norm=3.166697, loss=1.685375
I0520 16:20:19.921512 140109822056256 submission.py:296] 11000) loss = 1.685, grad_norm = 3.167
I0520 16:27:01.878554 140081666979584 logging_writer.py:48] [11500] global_step=11500, grad_norm=4.156950, loss=1.625317
I0520 16:27:01.885640 140109822056256 submission.py:296] 11500) loss = 1.625, grad_norm = 4.157
I0520 16:33:19.199477 140109822056256 spec.py:298] Evaluating on the training split.
I0520 16:33:31.102879 140109822056256 spec.py:310] Evaluating on the validation split.
I0520 16:33:41.099354 140109822056256 spec.py:326] Evaluating on the test split.
I0520 16:33:46.395197 140109822056256 submission_runner.py:421] Time since start: 9758.14s, 	Step: 11973, 	{'train/ctc_loss': 0.5013778675561851, 'train/wer': 0.16929200311446757, 'validation/ctc_loss': 0.7549302965516376, 'validation/wer': 0.21706174866026168, 'validation/num_examples': 5348, 'test/ctc_loss': 0.45754539607394024, 'test/wer': 0.15071192086608576, 'test/num_examples': 2472, 'score': 5902.453907966614, 'total_duration': 9758.142038822174, 'accumulated_submission_time': 5902.453907966614, 'accumulated_eval_time': 145.16085171699524, 'accumulated_logging_time': 0.13692736625671387}
I0520 16:33:46.419889 140081666979584 logging_writer.py:48] [11973] accumulated_eval_time=145.160852, accumulated_logging_time=0.136927, accumulated_submission_time=5902.453908, global_step=11973, preemption_count=0, score=5902.453908, test/ctc_loss=0.457545, test/num_examples=2472, test/wer=0.150712, total_duration=9758.142039, train/ctc_loss=0.501378, train/wer=0.169292, validation/ctc_loss=0.754930, validation/num_examples=5348, validation/wer=0.217062
I0520 16:34:08.798171 140081658586880 logging_writer.py:48] [12000] global_step=12000, grad_norm=4.021627, loss=1.665797
I0520 16:34:08.802449 140109822056256 submission.py:296] 12000) loss = 1.666, grad_norm = 4.022
I0520 16:40:50.918901 140081666979584 logging_writer.py:48] [12500] global_step=12500, grad_norm=4.192229, loss=1.578852
I0520 16:40:50.926910 140109822056256 submission.py:296] 12500) loss = 1.579, grad_norm = 4.192
I0520 16:47:30.320794 140081658586880 logging_writer.py:48] [13000] global_step=13000, grad_norm=7.773447, loss=1.635831
I0520 16:47:30.326376 140109822056256 submission.py:296] 13000) loss = 1.636, grad_norm = 7.773
I0520 16:54:11.629684 140081666979584 logging_writer.py:48] [13500] global_step=13500, grad_norm=4.248243, loss=1.576176
I0520 16:54:11.636997 140109822056256 submission.py:296] 13500) loss = 1.576, grad_norm = 4.248
I0520 17:00:50.802674 140081658586880 logging_writer.py:48] [14000] global_step=14000, grad_norm=2.781837, loss=1.558573
I0520 17:00:50.835680 140109822056256 submission.py:296] 14000) loss = 1.559, grad_norm = 2.782
I0520 17:07:32.150349 140081666979584 logging_writer.py:48] [14500] global_step=14500, grad_norm=3.202396, loss=1.517184
I0520 17:07:32.157737 140109822056256 submission.py:296] 14500) loss = 1.517, grad_norm = 3.202
I0520 17:13:47.076803 140109822056256 spec.py:298] Evaluating on the training split.
I0520 17:13:59.063724 140109822056256 spec.py:310] Evaluating on the validation split.
I0520 17:14:09.375520 140109822056256 spec.py:326] Evaluating on the test split.
I0520 17:14:16.004806 140109822056256 submission_runner.py:421] Time since start: 12187.75s, 	Step: 14969, 	{'train/ctc_loss': 0.4433026731513668, 'train/wer': 0.14996270261735065, 'validation/ctc_loss': 0.7021375475625377, 'validation/wer': 0.203785062521122, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4155541284921608, 'test/wer': 0.13659537302215993, 'test/num_examples': 2472, 'score': 7369.800501585007, 'total_duration': 12187.750467777252, 'accumulated_submission_time': 7369.800501585007, 'accumulated_eval_time': 174.08727073669434, 'accumulated_logging_time': 0.1738431453704834}
I0520 17:14:16.032501 140081666979584 logging_writer.py:48] [14969] accumulated_eval_time=174.087271, accumulated_logging_time=0.173843, accumulated_submission_time=7369.800502, global_step=14969, preemption_count=0, score=7369.800502, test/ctc_loss=0.415554, test/num_examples=2472, test/wer=0.136595, total_duration=12187.750468, train/ctc_loss=0.443303, train/wer=0.149963, validation/ctc_loss=0.702138, validation/num_examples=5348, validation/wer=0.203785
I0520 17:14:41.584472 140081658586880 logging_writer.py:48] [15000] global_step=15000, grad_norm=3.461813, loss=1.590307
I0520 17:14:41.588969 140109822056256 submission.py:296] 15000) loss = 1.590, grad_norm = 3.462
I0520 17:21:24.433189 140081666979584 logging_writer.py:48] [15500] global_step=15500, grad_norm=4.050647, loss=1.492573
I0520 17:21:24.440596 140109822056256 submission.py:296] 15500) loss = 1.493, grad_norm = 4.051
I0520 17:28:03.103524 140109822056256 spec.py:298] Evaluating on the training split.
I0520 17:28:15.066878 140109822056256 spec.py:310] Evaluating on the validation split.
I0520 17:28:24.819118 140109822056256 spec.py:326] Evaluating on the test split.
I0520 17:28:30.010707 140109822056256 submission_runner.py:421] Time since start: 13041.76s, 	Step: 16000, 	{'train/ctc_loss': 0.43364124203740334, 'train/wer': 0.1456775872677081, 'validation/ctc_loss': 0.6949765307131555, 'validation/wer': 0.19728672814174672, 'validation/num_examples': 5348, 'test/ctc_loss': 0.40487390315504224, 'test/wer': 0.13287835394958666, 'test/num_examples': 2472, 'score': 7875.616693973541, 'total_duration': 13041.756875038147, 'accumulated_submission_time': 7875.616693973541, 'accumulated_eval_time': 200.99336123466492, 'accumulated_logging_time': 0.21853232383728027}
I0520 17:28:30.038011 140081666979584 logging_writer.py:48] [16000] accumulated_eval_time=200.993361, accumulated_logging_time=0.218532, accumulated_submission_time=7875.616694, global_step=16000, preemption_count=0, score=7875.616694, test/ctc_loss=0.404874, test/num_examples=2472, test/wer=0.132878, total_duration=13041.756875, train/ctc_loss=0.433641, train/wer=0.145678, validation/ctc_loss=0.694977, validation/num_examples=5348, validation/wer=0.197287
I0520 17:28:30.069683 140081658586880 logging_writer.py:48] [16000] global_step=16000, preemption_count=0, score=7875.616694
I0520 17:28:30.427589 140109822056256 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b_pytorch/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/checkpoint_16000.
I0520 17:28:30.551092 140109822056256 submission_runner.py:584] Tuning trial 1/1
I0520 17:28:30.551379 140109822056256 submission_runner.py:585] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.045677535963609565, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0520 17:28:30.551908 140109822056256 submission_runner.py:586] Metrics: {'eval_results': [(1, {'train/ctc_loss': 32.27484960012529, 'train/wer': 3.7131858498630614, 'validation/ctc_loss': 30.86392091119148, 'validation/wer': 3.3501762178342105, 'validation/num_examples': 5348, 'test/ctc_loss': 30.888170204529324, 'test/wer': 3.5340726748319216, 'test/num_examples': 2472, 'score': 9.233933210372925, 'total_duration': 49.29368805885315, 'accumulated_submission_time': 9.233933210372925, 'accumulated_eval_time': 40.058419704437256, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (2988, {'train/ctc_loss': 5.067832301160641, 'train/wer': 0.911199560054231, 'validation/ctc_loss': 5.0046247896574245, 'validation/wer': 0.8741370154009559, 'validation/num_examples': 5348, 'test/ctc_loss': 4.801908187625008, 'test/wer': 0.8691121808543051, 'test/num_examples': 2472, 'score': 1502.1992180347443, 'total_duration': 2474.0146083831787, 'accumulated_submission_time': 1502.1992180347443, 'accumulated_eval_time': 63.952823877334595, 'accumulated_logging_time': 0.037455081939697266, 'global_step': 2988, 'preemption_count': 0}), (5979, {'train/ctc_loss': 0.9208451502636892, 'train/wer': 0.29059289226229046, 'validation/ctc_loss': 1.2025914911718907, 'validation/wer': 0.3284507314247091, 'validation/num_examples': 5348, 'test/ctc_loss': 0.8170213602490484, 'test/wer': 0.25937887189486725, 'test/num_examples': 2472, 'score': 2969.1707084178925, 'total_duration': 4901.835519313812, 'accumulated_submission_time': 2969.1707084178925, 'accumulated_eval_time': 90.64335584640503, 'accumulated_logging_time': 0.06834626197814941, 'global_step': 5979, 'preemption_count': 0}), (8976, {'train/ctc_loss': 0.6027445742840898, 'train/wer': 0.20133508295264593, 'validation/ctc_loss': 0.8633008715089411, 'validation/wer': 0.24752570849225125, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5424711876572682, 'test/wer': 0.1794528060447261, 'test/num_examples': 2472, 'score': 4435.118803024292, 'total_duration': 7329.909523963928, 'accumulated_submission_time': 4435.118803024292, 'accumulated_eval_time': 117.96551489830017, 'accumulated_logging_time': 0.10106897354125977, 'global_step': 8976, 'preemption_count': 0}), (11973, {'train/ctc_loss': 0.5013778675561851, 'train/wer': 0.16929200311446757, 'validation/ctc_loss': 0.7549302965516376, 'validation/wer': 0.21706174866026168, 'validation/num_examples': 5348, 'test/ctc_loss': 0.45754539607394024, 'test/wer': 0.15071192086608576, 'test/num_examples': 2472, 'score': 5902.453907966614, 'total_duration': 9758.142038822174, 'accumulated_submission_time': 5902.453907966614, 'accumulated_eval_time': 145.16085171699524, 'accumulated_logging_time': 0.13692736625671387, 'global_step': 11973, 'preemption_count': 0}), (14969, {'train/ctc_loss': 0.4433026731513668, 'train/wer': 0.14996270261735065, 'validation/ctc_loss': 0.7021375475625377, 'validation/wer': 0.203785062521122, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4155541284921608, 'test/wer': 0.13659537302215993, 'test/num_examples': 2472, 'score': 7369.800501585007, 'total_duration': 12187.750467777252, 'accumulated_submission_time': 7369.800501585007, 'accumulated_eval_time': 174.08727073669434, 'accumulated_logging_time': 0.1738431453704834, 'global_step': 14969, 'preemption_count': 0}), (16000, {'train/ctc_loss': 0.43364124203740334, 'train/wer': 0.1456775872677081, 'validation/ctc_loss': 0.6949765307131555, 'validation/wer': 0.19728672814174672, 'validation/num_examples': 5348, 'test/ctc_loss': 0.40487390315504224, 'test/wer': 0.13287835394958666, 'test/num_examples': 2472, 'score': 7875.616693973541, 'total_duration': 13041.756875038147, 'accumulated_submission_time': 7875.616693973541, 'accumulated_eval_time': 200.99336123466492, 'accumulated_logging_time': 0.21853232383728027, 'global_step': 16000, 'preemption_count': 0})], 'global_step': 16000}
I0520 17:28:30.552006 140109822056256 submission_runner.py:587] Timing: 7875.616693973541
I0520 17:28:30.552060 140109822056256 submission_runner.py:588] ====================
I0520 17:28:30.552299 140109822056256 submission_runner.py:651] Final librispeech_deepspeech score: 7875.616693973541
