python3 submission_runner.py --framework=jax --workload=fastmri --submission_path=baselines/sam/jax/submission.py --tuning_search_space=baselines/sam/tuning_search_space.json --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_fancy_verify/timing_sam --overwrite=True --save_checkpoints=False --max_global_steps=5428 2>&1 | tee -a /logs/fastmri_jax_05-09-2023-20-00-42.log
I0509 20:01:02.497945 140632881538880 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_fancy_verify/timing_sam/fastmri_jax.
I0509 20:01:02.652547 140632881538880 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0509 20:01:03.487375 140632881538880 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter Host
I0509 20:01:03.488099 140632881538880 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0509 20:01:03.493846 140632881538880 submission_runner.py:547] Using RNG seed 2814092149
I0509 20:01:06.336033 140632881538880 submission_runner.py:556] --- Tuning run 1/1 ---
I0509 20:01:06.336283 140632881538880 submission_runner.py:561] Creating tuning directory at /experiment_runs/timing_fancy_verify/timing_sam/fastmri_jax/trial_1.
I0509 20:01:06.336471 140632881538880 logger_utils.py:92] Saving hparams to /experiment_runs/timing_fancy_verify/timing_sam/fastmri_jax/trial_1/hparams.json.
I0509 20:01:06.478519 140632881538880 submission_runner.py:241] Initializing dataset.
I0509 20:01:11.660849 140632881538880 submission_runner.py:248] Initializing model.
I0509 20:01:19.319897 140632881538880 submission_runner.py:258] Initializing optimizer.
I0509 20:01:19.817284 140632881538880 submission_runner.py:265] Initializing metrics bundle.
I0509 20:01:19.817508 140632881538880 submission_runner.py:283] Initializing checkpoint and logger.
I0509 20:01:19.819932 140632881538880 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_fancy_verify/timing_sam/fastmri_jax/trial_1 with prefix checkpoint_
I0509 20:01:19.820224 140632881538880 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0509 20:01:19.820300 140632881538880 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0509 20:01:20.582620 140632881538880 submission_runner.py:304] Saving meta data to /experiment_runs/timing_fancy_verify/timing_sam/fastmri_jax/trial_1/meta_data_0.json.
I0509 20:01:20.583842 140632881538880 submission_runner.py:307] Saving flags to /experiment_runs/timing_fancy_verify/timing_sam/fastmri_jax/trial_1/flags_0.json.
I0509 20:01:20.590340 140632881538880 submission_runner.py:319] Starting training loop.
I0509 20:02:29.381885 140456402876160 logging_writer.py:48] [0] global_step=0, grad_norm=4.187687873840332, loss=0.7402933239936829
I0509 20:02:29.391976 140632881538880 spec.py:298] Evaluating on the training split.
I0509 20:03:57.121938 140632881538880 spec.py:310] Evaluating on the validation split.
I0509 20:05:00.148174 140632881538880 spec.py:326] Evaluating on the test split.
I0509 20:05:59.839122 140632881538880 submission_runner.py:424] Time since start: 279.25s, 	Step: 1, 	{'train/ssim': 0.28299944741385324, 'train/loss': 0.7835339818681989, 'validation/ssim': 0.2700521440135675, 'validation/loss': 0.796358347878271, 'validation/num_examples': 3554, 'test/ssim': 0.2929518080996056, 'test/loss': 0.7950659322858489, 'test/num_examples': 3581, 'score': 68.8014543056488, 'total_duration': 279.24869084358215, 'accumulated_submission_time': 68.8014543056488, 'accumulated_data_selection_time': 36.585532665252686, 'accumulated_eval_time': 210.4470784664154, 'accumulated_logging_time': 0}
I0509 20:05:59.856156 140427848054528 logging_writer.py:48] [1] accumulated_data_selection_time=36.585533, accumulated_eval_time=210.447078, accumulated_logging_time=0, accumulated_submission_time=68.801454, global_step=1, preemption_count=0, score=68.801454, test/loss=0.795066, test/num_examples=3581, test/ssim=0.292952, total_duration=279.248691, train/loss=0.783534, train/ssim=0.282999, validation/loss=0.796358, validation/num_examples=3554, validation/ssim=0.270052
I0509 20:06:22.618723 140427839661824 logging_writer.py:48] [100] global_step=100, grad_norm=0.3027621805667877, loss=0.23792773485183716
I0509 20:06:47.755134 140427848054528 logging_writer.py:48] [200] global_step=200, grad_norm=0.30430614948272705, loss=0.40537595748901367
I0509 20:07:12.522085 140427839661824 logging_writer.py:48] [300] global_step=300, grad_norm=0.3810046315193176, loss=0.38652217388153076
I0509 20:07:20.184561 140632881538880 spec.py:298] Evaluating on the training split.
I0509 20:07:22.025894 140632881538880 spec.py:310] Evaluating on the validation split.
I0509 20:07:23.384797 140632881538880 spec.py:326] Evaluating on the test split.
I0509 20:07:24.743128 140632881538880 submission_runner.py:424] Time since start: 364.15s, 	Step: 329, 	{'train/ssim': 0.6979986599513462, 'train/loss': 0.3100654057094029, 'validation/ssim': 0.6738602053803813, 'validation/loss': 0.3305638988969295, 'validation/num_examples': 3554, 'test/ssim': 0.6921687377827422, 'test/loss': 0.33243475357136626, 'test/num_examples': 3581, 'score': 149.11688494682312, 'total_duration': 364.1526873111725, 'accumulated_submission_time': 149.11688494682312, 'accumulated_data_selection_time': 108.53375005722046, 'accumulated_eval_time': 215.00557613372803, 'accumulated_logging_time': 0.025673627853393555}
I0509 20:07:24.753778 140427848054528 logging_writer.py:48] [329] accumulated_data_selection_time=108.533750, accumulated_eval_time=215.005576, accumulated_logging_time=0.025674, accumulated_submission_time=149.116885, global_step=329, preemption_count=0, score=149.116885, test/loss=0.332435, test/num_examples=3581, test/ssim=0.692169, total_duration=364.152687, train/loss=0.310065, train/ssim=0.697999, validation/loss=0.330564, validation/num_examples=3554, validation/ssim=0.673860
I0509 20:07:46.818126 140427839661824 logging_writer.py:48] [400] global_step=400, grad_norm=0.1593487411737442, loss=0.3370335102081299
I0509 20:08:23.643914 140427848054528 logging_writer.py:48] [500] global_step=500, grad_norm=0.22098736464977264, loss=0.2558790147304535
I0509 20:08:44.880875 140632881538880 spec.py:298] Evaluating on the training split.
I0509 20:08:46.357630 140632881538880 spec.py:310] Evaluating on the validation split.
I0509 20:08:47.709614 140632881538880 spec.py:326] Evaluating on the test split.
I0509 20:08:49.068418 140632881538880 submission_runner.py:424] Time since start: 448.48s, 	Step: 564, 	{'train/ssim': 0.7168310710362026, 'train/loss': 0.2952800818852016, 'validation/ssim': 0.6938103550796637, 'validation/loss': 0.3145582277451463, 'validation/num_examples': 3554, 'test/ssim': 0.7114650510070512, 'test/loss': 0.316770654255969, 'test/num_examples': 3581, 'score': 229.22612524032593, 'total_duration': 448.4779884815216, 'accumulated_submission_time': 229.22612524032593, 'accumulated_data_selection_time': 182.84632420539856, 'accumulated_eval_time': 219.1930603981018, 'accumulated_logging_time': 0.051164865493774414}
I0509 20:08:49.078964 140427839661824 logging_writer.py:48] [564] accumulated_data_selection_time=182.846324, accumulated_eval_time=219.193060, accumulated_logging_time=0.051165, accumulated_submission_time=229.226125, global_step=564, preemption_count=0, score=229.226125, test/loss=0.316771, test/num_examples=3581, test/ssim=0.711465, total_duration=448.477988, train/loss=0.295280, train/ssim=0.716831, validation/loss=0.314558, validation/num_examples=3554, validation/ssim=0.693810
I0509 20:08:58.258396 140427848054528 logging_writer.py:48] [600] global_step=600, grad_norm=0.15932297706604004, loss=0.2921059727668762
I0509 20:09:33.715842 140427839661824 logging_writer.py:48] [700] global_step=700, grad_norm=0.36301425099372864, loss=0.2923769950866699
I0509 20:10:08.916593 140427848054528 logging_writer.py:48] [800] global_step=800, grad_norm=0.22189338505268097, loss=0.35179403424263
I0509 20:10:09.352061 140632881538880 spec.py:298] Evaluating on the training split.
I0509 20:10:10.826515 140632881538880 spec.py:310] Evaluating on the validation split.
I0509 20:10:12.181611 140632881538880 spec.py:326] Evaluating on the test split.
I0509 20:10:13.538040 140632881538880 submission_runner.py:424] Time since start: 532.95s, 	Step: 803, 	{'train/ssim': 0.7190600122724261, 'train/loss': 0.2901318073272705, 'validation/ssim': 0.697025674745885, 'validation/loss': 0.30888535859682753, 'validation/num_examples': 3554, 'test/ssim': 0.7142208880201061, 'test/loss': 0.31112647888814227, 'test/num_examples': 3581, 'score': 309.4813714027405, 'total_duration': 532.9476251602173, 'accumulated_submission_time': 309.4813714027405, 'accumulated_data_selection_time': 256.4764401912689, 'accumulated_eval_time': 223.37900757789612, 'accumulated_logging_time': 0.07646489143371582}
I0509 20:10:13.549417 140427839661824 logging_writer.py:48] [803] accumulated_data_selection_time=256.476440, accumulated_eval_time=223.379008, accumulated_logging_time=0.076465, accumulated_submission_time=309.481371, global_step=803, preemption_count=0, score=309.481371, test/loss=0.311126, test/num_examples=3581, test/ssim=0.714221, total_duration=532.947625, train/loss=0.290132, train/ssim=0.719060, validation/loss=0.308885, validation/num_examples=3554, validation/ssim=0.697026
I0509 20:10:44.902474 140427848054528 logging_writer.py:48] [900] global_step=900, grad_norm=0.16478809714317322, loss=0.31017646193504333
I0509 20:11:16.362237 140427839661824 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.20984740555286407, loss=0.27734342217445374
I0509 20:11:33.851419 140632881538880 spec.py:298] Evaluating on the training split.
I0509 20:11:35.334574 140632881538880 spec.py:310] Evaluating on the validation split.
I0509 20:11:36.692454 140632881538880 spec.py:326] Evaluating on the test split.
I0509 20:11:38.050913 140632881538880 submission_runner.py:424] Time since start: 617.46s, 	Step: 1072, 	{'train/ssim': 0.7267129080636161, 'train/loss': 0.28590801783970426, 'validation/ssim': 0.7035884824977139, 'validation/loss': 0.30551338088465463, 'validation/num_examples': 3554, 'test/ssim': 0.7206905804942754, 'test/loss': 0.30778425440912105, 'test/num_examples': 3581, 'score': 389.76232743263245, 'total_duration': 617.4604759216309, 'accumulated_submission_time': 389.76232743263245, 'accumulated_data_selection_time': 330.12352538108826, 'accumulated_eval_time': 227.57844257354736, 'accumulated_logging_time': 0.10543036460876465}
I0509 20:11:38.059759 140427848054528 logging_writer.py:48] [1072] accumulated_data_selection_time=330.123525, accumulated_eval_time=227.578443, accumulated_logging_time=0.105430, accumulated_submission_time=389.762327, global_step=1072, preemption_count=0, score=389.762327, test/loss=0.307784, test/num_examples=3581, test/ssim=0.720691, total_duration=617.460476, train/loss=0.285908, train/ssim=0.726713, validation/loss=0.305513, validation/num_examples=3554, validation/ssim=0.703588
I0509 20:11:43.191376 140427839661824 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.23685720562934875, loss=0.21487957239151
I0509 20:12:07.881221 140427848054528 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.12072525173425674, loss=0.2290651947259903
I0509 20:12:32.502718 140427839661824 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.1334616094827652, loss=0.24894264340400696
I0509 20:12:57.069045 140427848054528 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.12642192840576172, loss=0.2359081655740738
I0509 20:12:58.198635 140632881538880 spec.py:298] Evaluating on the training split.
I0509 20:12:59.681352 140632881538880 spec.py:310] Evaluating on the validation split.
I0509 20:13:01.040678 140632881538880 spec.py:326] Evaluating on the test split.
I0509 20:13:02.399575 140632881538880 submission_runner.py:424] Time since start: 701.81s, 	Step: 1406, 	{'train/ssim': 0.7315048490251813, 'train/loss': 0.28089054993220736, 'validation/ssim': 0.7085193812209833, 'validation/loss': 0.30010107037185213, 'validation/num_examples': 3554, 'test/ssim': 0.7257609469901913, 'test/loss': 0.3019316970752758, 'test/num_examples': 3581, 'score': 469.88837790489197, 'total_duration': 701.8091356754303, 'accumulated_submission_time': 469.88837790489197, 'accumulated_data_selection_time': 402.2046568393707, 'accumulated_eval_time': 231.77931666374207, 'accumulated_logging_time': 0.12238931655883789}
I0509 20:13:02.408361 140427839661824 logging_writer.py:48] [1406] accumulated_data_selection_time=402.204657, accumulated_eval_time=231.779317, accumulated_logging_time=0.122389, accumulated_submission_time=469.888378, global_step=1406, preemption_count=0, score=469.888378, test/loss=0.301932, test/num_examples=3581, test/ssim=0.725761, total_duration=701.809136, train/loss=0.280891, train/ssim=0.731505, validation/loss=0.300101, validation/num_examples=3554, validation/ssim=0.708519
I0509 20:13:23.662091 140427848054528 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.2039455771446228, loss=0.3604617118835449
I0509 20:13:48.488857 140427839661824 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.22632041573524475, loss=0.3054737448692322
I0509 20:14:13.071808 140427848054528 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.1649133563041687, loss=0.3155324459075928
I0509 20:14:22.484246 140632881538880 spec.py:298] Evaluating on the training split.
I0509 20:14:23.967279 140632881538880 spec.py:310] Evaluating on the validation split.
I0509 20:14:25.325804 140632881538880 spec.py:326] Evaluating on the test split.
I0509 20:14:26.687473 140632881538880 submission_runner.py:424] Time since start: 786.10s, 	Step: 1740, 	{'train/ssim': 0.7353490420750209, 'train/loss': 0.2779268366949899, 'validation/ssim': 0.7119984194745357, 'validation/loss': 0.29757499802159537, 'validation/num_examples': 3554, 'test/ssim': 0.7293137691767314, 'test/loss': 0.2992658873437936, 'test/num_examples': 3581, 'score': 549.9516477584839, 'total_duration': 786.0970232486725, 'accumulated_submission_time': 549.9516477584839, 'accumulated_data_selection_time': 474.41468334198, 'accumulated_eval_time': 235.98246550559998, 'accumulated_logging_time': 0.13925576210021973}
I0509 20:14:26.696595 140427839661824 logging_writer.py:48] [1740] accumulated_data_selection_time=474.414683, accumulated_eval_time=235.982466, accumulated_logging_time=0.139256, accumulated_submission_time=549.951648, global_step=1740, preemption_count=0, score=549.951648, test/loss=0.299266, test/num_examples=3581, test/ssim=0.729314, total_duration=786.097023, train/loss=0.277927, train/ssim=0.735349, validation/loss=0.297575, validation/num_examples=3554, validation/ssim=0.711998
I0509 20:14:39.697174 140427848054528 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.13316145539283752, loss=0.26376259326934814
I0509 20:15:04.371249 140427839661824 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.14210867881774902, loss=0.35522133111953735
I0509 20:15:28.924745 140427848054528 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.161762535572052, loss=0.2636021375656128
I0509 20:15:46.753252 140632881538880 spec.py:298] Evaluating on the training split.
I0509 20:15:48.232529 140632881538880 spec.py:310] Evaluating on the validation split.
I0509 20:15:49.595968 140632881538880 spec.py:326] Evaluating on the test split.
I0509 20:15:50.956352 140632881538880 submission_runner.py:424] Time since start: 870.37s, 	Step: 2071, 	{'train/ssim': 0.7300763811383929, 'train/loss': 0.27880355290004183, 'validation/ssim': 0.708418262762908, 'validation/loss': 0.2976870732691158, 'validation/num_examples': 3554, 'test/ssim': 0.7254709234719702, 'test/loss': 0.2994087174497347, 'test/num_examples': 3581, 'score': 629.9959139823914, 'total_duration': 870.3659014701843, 'accumulated_submission_time': 629.9959139823914, 'accumulated_data_selection_time': 546.6877727508545, 'accumulated_eval_time': 240.18550276756287, 'accumulated_logging_time': 0.1561717987060547}
I0509 20:15:50.965717 140427839661824 logging_writer.py:48] [2071] accumulated_data_selection_time=546.687773, accumulated_eval_time=240.185503, accumulated_logging_time=0.156172, accumulated_submission_time=629.995914, global_step=2071, preemption_count=0, score=629.995914, test/loss=0.299409, test/num_examples=3581, test/ssim=0.725471, total_duration=870.365901, train/loss=0.278804, train/ssim=0.730076, validation/loss=0.297687, validation/num_examples=3554, validation/ssim=0.708418
I0509 20:15:56.419868 140427848054528 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.24661950767040253, loss=0.3098990023136139
I0509 20:16:21.250245 140427839661824 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.08864998072385788, loss=0.2773438096046448
I0509 20:16:46.027147 140427848054528 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.11487752944231033, loss=0.26602810621261597
I0509 20:17:10.602436 140427839661824 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.07112819701433182, loss=0.2537079453468323
I0509 20:17:11.202763 140632881538880 spec.py:298] Evaluating on the training split.
I0509 20:17:12.689158 140632881538880 spec.py:310] Evaluating on the validation split.
I0509 20:17:14.053873 140632881538880 spec.py:326] Evaluating on the test split.
I0509 20:17:15.414107 140632881538880 submission_runner.py:424] Time since start: 954.82s, 	Step: 2404, 	{'train/ssim': 0.7378464426313128, 'train/loss': 0.2745086465563093, 'validation/ssim': 0.7142825150798396, 'validation/loss': 0.2941751646472285, 'validation/num_examples': 3554, 'test/ssim': 0.7315639398910919, 'test/loss': 0.2958637696676033, 'test/num_examples': 3581, 'score': 710.2199323177338, 'total_duration': 954.8236472606659, 'accumulated_submission_time': 710.2199323177338, 'accumulated_data_selection_time': 618.8994538784027, 'accumulated_eval_time': 244.3967580795288, 'accumulated_logging_time': 0.17400360107421875}
I0509 20:17:15.423615 140427848054528 logging_writer.py:48] [2404] accumulated_data_selection_time=618.899454, accumulated_eval_time=244.396758, accumulated_logging_time=0.174004, accumulated_submission_time=710.219932, global_step=2404, preemption_count=0, score=710.219932, test/loss=0.295864, test/num_examples=3581, test/ssim=0.731564, total_duration=954.823647, train/loss=0.274509, train/ssim=0.737846, validation/loss=0.294175, validation/num_examples=3554, validation/ssim=0.714283
I0509 20:17:37.357585 140427839661824 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.09603051096200943, loss=0.2511957585811615
I0509 20:18:01.886061 140427848054528 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.14589664340019226, loss=0.3214389681816101
I0509 20:18:26.466770 140427839661824 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.17168548703193665, loss=0.27863678336143494
I0509 20:18:35.557722 140632881538880 spec.py:298] Evaluating on the training split.
I0509 20:18:37.040786 140632881538880 spec.py:310] Evaluating on the validation split.
I0509 20:18:38.404565 140632881538880 spec.py:326] Evaluating on the test split.
I0509 20:18:39.766520 140632881538880 submission_runner.py:424] Time since start: 1039.18s, 	Step: 2738, 	{'train/ssim': 0.7383364949907575, 'train/loss': 0.27326370988573345, 'validation/ssim': 0.7144975291924592, 'validation/loss': 0.29304572230453363, 'validation/num_examples': 3554, 'test/ssim': 0.7319140952247976, 'test/loss': 0.29462367028239317, 'test/num_examples': 3581, 'score': 790.3411655426025, 'total_duration': 1039.1760907173157, 'accumulated_submission_time': 790.3411655426025, 'accumulated_data_selection_time': 691.1961417198181, 'accumulated_eval_time': 248.6055202484131, 'accumulated_logging_time': 0.19178199768066406}
I0509 20:18:39.775944 140427848054528 logging_writer.py:48] [2738] accumulated_data_selection_time=691.196142, accumulated_eval_time=248.605520, accumulated_logging_time=0.191782, accumulated_submission_time=790.341166, global_step=2738, preemption_count=0, score=790.341166, test/loss=0.294624, test/num_examples=3581, test/ssim=0.731914, total_duration=1039.176091, train/loss=0.273264, train/ssim=0.738336, validation/loss=0.293046, validation/num_examples=3554, validation/ssim=0.714498
I0509 20:18:53.417935 140427839661824 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.13981151580810547, loss=0.2702767550945282
I0509 20:19:18.444189 140427848054528 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.13130202889442444, loss=0.3009687662124634
I0509 20:19:43.168906 140427839661824 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.11153775453567505, loss=0.2904355823993683
I0509 20:19:59.897379 140632881538880 spec.py:298] Evaluating on the training split.
I0509 20:20:01.377600 140632881538880 spec.py:310] Evaluating on the validation split.
I0509 20:20:02.735909 140632881538880 spec.py:326] Evaluating on the test split.
I0509 20:20:04.095950 140632881538880 submission_runner.py:424] Time since start: 1123.51s, 	Step: 3069, 	{'train/ssim': 0.7403180258614677, 'train/loss': 0.27238929271698, 'validation/ssim': 0.7168069044122819, 'validation/loss': 0.2921149447585467, 'validation/num_examples': 3554, 'test/ssim': 0.7340977936941496, 'test/loss': 0.2936894454892139, 'test/num_examples': 3581, 'score': 870.4499657154083, 'total_duration': 1123.5055058002472, 'accumulated_submission_time': 870.4499657154083, 'accumulated_data_selection_time': 763.5309662818909, 'accumulated_eval_time': 252.80404019355774, 'accumulated_logging_time': 0.20926380157470703}
I0509 20:20:04.106514 140427848054528 logging_writer.py:48] [3069] accumulated_data_selection_time=763.530966, accumulated_eval_time=252.804040, accumulated_logging_time=0.209264, accumulated_submission_time=870.449966, global_step=3069, preemption_count=0, score=870.449966, test/loss=0.293689, test/num_examples=3581, test/ssim=0.734098, total_duration=1123.505506, train/loss=0.272389, train/ssim=0.740318, validation/loss=0.292115, validation/num_examples=3554, validation/ssim=0.716807
I0509 20:20:09.961214 140427839661824 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.13487863540649414, loss=0.27902573347091675
I0509 20:20:34.712041 140427848054528 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.10093720257282257, loss=0.24235951900482178
I0509 20:20:59.463858 140427839661824 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.10524817556142807, loss=0.29790788888931274
I0509 20:21:24.090662 140427848054528 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.22281086444854736, loss=0.29396840929985046
I0509 20:21:24.208068 140632881538880 spec.py:298] Evaluating on the training split.
I0509 20:21:25.690320 140632881538880 spec.py:310] Evaluating on the validation split.
I0509 20:21:27.052657 140632881538880 spec.py:326] Evaluating on the test split.
I0509 20:21:28.414433 140632881538880 submission_runner.py:424] Time since start: 1207.82s, 	Step: 3402, 	{'train/ssim': 0.7391842433384487, 'train/loss': 0.27540366990225656, 'validation/ssim': 0.7153553187209833, 'validation/loss': 0.2954151366088386, 'validation/num_examples': 3554, 'test/ssim': 0.7322537513526249, 'test/loss': 0.29722004208408964, 'test/num_examples': 3581, 'score': 950.5378625392914, 'total_duration': 1207.8239648342133, 'accumulated_submission_time': 950.5378625392914, 'accumulated_data_selection_time': 835.6826694011688, 'accumulated_eval_time': 257.0103192329407, 'accumulated_logging_time': 0.2289891242980957}
I0509 20:21:28.424377 140427839661824 logging_writer.py:48] [3402] accumulated_data_selection_time=835.682669, accumulated_eval_time=257.010319, accumulated_logging_time=0.228989, accumulated_submission_time=950.537863, global_step=3402, preemption_count=0, score=950.537863, test/loss=0.297220, test/num_examples=3581, test/ssim=0.732254, total_duration=1207.823965, train/loss=0.275404, train/ssim=0.739184, validation/loss=0.295415, validation/num_examples=3554, validation/ssim=0.715355
I0509 20:21:50.597707 140427848054528 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.16705794632434845, loss=0.2969856858253479
I0509 20:22:15.426874 140427839661824 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.06589612364768982, loss=0.3926391005516052
I0509 20:22:40.094843 140427848054528 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.06831274181604385, loss=0.31605884432792664
I0509 20:22:48.458099 140632881538880 spec.py:298] Evaluating on the training split.
I0509 20:22:49.935276 140632881538880 spec.py:310] Evaluating on the validation split.
I0509 20:22:51.297805 140632881538880 spec.py:326] Evaluating on the test split.
I0509 20:22:52.663687 140632881538880 submission_runner.py:424] Time since start: 1292.07s, 	Step: 3735, 	{'train/ssim': 0.7388229370117188, 'train/loss': 0.2734854221343994, 'validation/ssim': 0.7145432111045653, 'validation/loss': 0.2935755294430571, 'validation/num_examples': 3554, 'test/ssim': 0.7319141634014591, 'test/loss': 0.2950208334242356, 'test/num_examples': 3581, 'score': 1030.5587422847748, 'total_duration': 1292.0732610225677, 'accumulated_submission_time': 1030.5587422847748, 'accumulated_data_selection_time': 907.8232474327087, 'accumulated_eval_time': 261.2158601284027, 'accumulated_logging_time': 0.2471940517425537}
I0509 20:22:52.674043 140427839661824 logging_writer.py:48] [3735] accumulated_data_selection_time=907.823247, accumulated_eval_time=261.215860, accumulated_logging_time=0.247194, accumulated_submission_time=1030.558742, global_step=3735, preemption_count=0, score=1030.558742, test/loss=0.295021, test/num_examples=3581, test/ssim=0.731914, total_duration=1292.073261, train/loss=0.273485, train/ssim=0.738823, validation/loss=0.293576, validation/num_examples=3554, validation/ssim=0.714543
I0509 20:23:06.946207 140427848054528 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.1356758177280426, loss=0.2982577383518219
I0509 20:23:31.622880 140427839661824 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.0520145483314991, loss=0.3374759554862976
I0509 20:23:56.361064 140427848054528 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.08250459283590317, loss=0.3230576813220978
I0509 20:24:12.906659 140632881538880 spec.py:298] Evaluating on the training split.
I0509 20:24:14.392018 140632881538880 spec.py:310] Evaluating on the validation split.
I0509 20:24:15.754721 140632881538880 spec.py:326] Evaluating on the test split.
I0509 20:24:17.115021 140632881538880 submission_runner.py:424] Time since start: 1376.52s, 	Step: 4069, 	{'train/ssim': 0.7420073236737933, 'train/loss': 0.2716865198952811, 'validation/ssim': 0.7179249777979038, 'validation/loss': 0.2917944500804551, 'validation/num_examples': 3554, 'test/ssim': 0.7351594406677604, 'test/loss': 0.2933768214076899, 'test/num_examples': 3581, 'score': 1110.7785708904266, 'total_duration': 1376.5245842933655, 'accumulated_submission_time': 1110.7785708904266, 'accumulated_data_selection_time': 980.2070775032043, 'accumulated_eval_time': 265.4241621494293, 'accumulated_logging_time': 0.26541924476623535}
I0509 20:24:17.124939 140427839661824 logging_writer.py:48] [4069] accumulated_data_selection_time=980.207078, accumulated_eval_time=265.424162, accumulated_logging_time=0.265419, accumulated_submission_time=1110.778571, global_step=4069, preemption_count=0, score=1110.778571, test/loss=0.293377, test/num_examples=3581, test/ssim=0.735159, total_duration=1376.524584, train/loss=0.271687, train/ssim=0.742007, validation/loss=0.291794, validation/num_examples=3554, validation/ssim=0.717925
I0509 20:24:22.967363 140427848054528 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.06692926585674286, loss=0.2134438008069992
I0509 20:24:48.522901 140427839661824 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.09633306413888931, loss=0.2537024915218353
I0509 20:25:13.074195 140427848054528 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.0883532464504242, loss=0.3034762740135193
I0509 20:25:37.275687 140632881538880 spec.py:298] Evaluating on the training split.
I0509 20:25:38.755932 140632881538880 spec.py:310] Evaluating on the validation split.
I0509 20:25:40.118298 140632881538880 spec.py:326] Evaluating on the test split.
I0509 20:25:41.477760 140632881538880 submission_runner.py:424] Time since start: 1460.89s, 	Step: 4399, 	{'train/ssim': 0.7425810950142997, 'train/loss': 0.27122626985822407, 'validation/ssim': 0.718173446182998, 'validation/loss': 0.29143514295072454, 'validation/num_examples': 3554, 'test/ssim': 0.735324769072012, 'test/loss': 0.29305223232206434, 'test/num_examples': 3581, 'score': 1190.9166474342346, 'total_duration': 1460.8873200416565, 'accumulated_submission_time': 1190.9166474342346, 'accumulated_data_selection_time': 1052.53577542305, 'accumulated_eval_time': 269.62617444992065, 'accumulated_logging_time': 0.28348350524902344}
I0509 20:25:41.488331 140427839661824 logging_writer.py:48] [4399] accumulated_data_selection_time=1052.535775, accumulated_eval_time=269.626174, accumulated_logging_time=0.283484, accumulated_submission_time=1190.916647, global_step=4399, preemption_count=0, score=1190.916647, test/loss=0.293052, test/num_examples=3581, test/ssim=0.735325, total_duration=1460.887320, train/loss=0.271226, train/ssim=0.742581, validation/loss=0.291435, validation/num_examples=3554, validation/ssim=0.718173
I0509 20:25:41.793467 140427848054528 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.08650848269462585, loss=0.3038145899772644
I0509 20:26:04.785232 140427839661824 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.1904699206352234, loss=0.21537281572818756
I0509 20:26:29.458402 140427848054528 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.06324495375156403, loss=0.28980696201324463
I0509 20:26:53.928189 140427839661824 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.12663127481937408, loss=0.31377771496772766
I0509 20:27:01.599272 140632881538880 spec.py:298] Evaluating on the training split.
I0509 20:27:03.083178 140632881538880 spec.py:310] Evaluating on the validation split.
I0509 20:27:04.442801 140632881538880 spec.py:326] Evaluating on the test split.
I0509 20:27:05.801579 140632881538880 submission_runner.py:424] Time since start: 1545.21s, 	Step: 4733, 	{'train/ssim': 0.7425328663417271, 'train/loss': 0.27130896704537527, 'validation/ssim': 0.718843699440771, 'validation/loss': 0.29106594379792133, 'validation/num_examples': 3554, 'test/ssim': 0.7362559940920832, 'test/loss': 0.2925256357882749, 'test/num_examples': 3581, 'score': 1271.0145478248596, 'total_duration': 1545.2111489772797, 'accumulated_submission_time': 1271.0145478248596, 'accumulated_data_selection_time': 1124.7997071743011, 'accumulated_eval_time': 273.82842683792114, 'accumulated_logging_time': 0.3025491237640381}
I0509 20:27:05.811786 140427848054528 logging_writer.py:48] [4733] accumulated_data_selection_time=1124.799707, accumulated_eval_time=273.828427, accumulated_logging_time=0.302549, accumulated_submission_time=1271.014548, global_step=4733, preemption_count=0, score=1271.014548, test/loss=0.292526, test/num_examples=3581, test/ssim=0.736256, total_duration=1545.211149, train/loss=0.271309, train/ssim=0.742533, validation/loss=0.291066, validation/num_examples=3554, validation/ssim=0.718844
I0509 20:27:20.738161 140427839661824 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.06751322001218796, loss=0.2686348855495453
I0509 20:27:45.388666 140427848054528 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.05551305413246155, loss=0.45179691910743713
I0509 20:28:09.947277 140427839661824 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.051164790987968445, loss=0.3081132769584656
I0509 20:28:25.838716 140632881538880 spec.py:298] Evaluating on the training split.
I0509 20:28:27.321653 140632881538880 spec.py:310] Evaluating on the validation split.
I0509 20:28:28.684592 140632881538880 spec.py:326] Evaluating on the test split.
I0509 20:28:30.047928 140632881538880 submission_runner.py:424] Time since start: 1629.46s, 	Step: 5067, 	{'train/ssim': 0.7401718412126813, 'train/loss': 0.2714803048542568, 'validation/ssim': 0.7165876312341728, 'validation/loss': 0.29126642900165306, 'validation/num_examples': 3554, 'test/ssim': 0.7339321925832519, 'test/loss': 0.2928518270254468, 'test/num_examples': 3581, 'score': 1351.0281014442444, 'total_duration': 1629.457494020462, 'accumulated_submission_time': 1351.0281014442444, 'accumulated_data_selection_time': 1196.9784896373749, 'accumulated_eval_time': 278.0375828742981, 'accumulated_logging_time': 0.32154083251953125}
I0509 20:28:30.059391 140427848054528 logging_writer.py:48] [5067] accumulated_data_selection_time=1196.978490, accumulated_eval_time=278.037583, accumulated_logging_time=0.321541, accumulated_submission_time=1351.028101, global_step=5067, preemption_count=0, score=1351.028101, test/loss=0.292852, test/num_examples=3581, test/ssim=0.733932, total_duration=1629.457494, train/loss=0.271480, train/ssim=0.740172, validation/loss=0.291266, validation/num_examples=3554, validation/ssim=0.716588
I0509 20:28:36.350775 140427839661824 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.10099354386329651, loss=0.2680627703666687
I0509 20:29:00.922100 140427848054528 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.09562806785106659, loss=0.2314680516719818
I0509 20:29:25.966725 140427839661824 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.10985352098941803, loss=0.2345026731491089
I0509 20:29:50.267199 140632881538880 spec.py:298] Evaluating on the training split.
I0509 20:29:51.751408 140632881538880 spec.py:310] Evaluating on the validation split.
I0509 20:29:53.114558 140632881538880 spec.py:326] Evaluating on the test split.
I0509 20:29:54.474131 140632881538880 submission_runner.py:424] Time since start: 1713.88s, 	Step: 5400, 	{'train/ssim': 0.7385042054312569, 'train/loss': 0.27409631865365164, 'validation/ssim': 0.7154964174389772, 'validation/loss': 0.29337878809527995, 'validation/num_examples': 3554, 'test/ssim': 0.7325570011431862, 'test/loss': 0.2951720833478777, 'test/num_examples': 3581, 'score': 1431.22345495224, 'total_duration': 1713.883698940277, 'accumulated_submission_time': 1431.22345495224, 'accumulated_data_selection_time': 1269.3581669330597, 'accumulated_eval_time': 282.2444689273834, 'accumulated_logging_time': 0.34078431129455566}
I0509 20:29:54.484011 140427848054528 logging_writer.py:48] [5400] accumulated_data_selection_time=1269.358167, accumulated_eval_time=282.244469, accumulated_logging_time=0.340784, accumulated_submission_time=1431.223455, global_step=5400, preemption_count=0, score=1431.223455, test/loss=0.295172, test/num_examples=3581, test/ssim=0.732557, total_duration=1713.883699, train/loss=0.274096, train/ssim=0.738504, validation/loss=0.293379, validation/num_examples=3554, validation/ssim=0.715496
I0509 20:29:54.646198 140427839661824 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.06198800727725029, loss=0.2652699649333954
I0509 20:29:59.373512 140632881538880 spec.py:298] Evaluating on the training split.
I0509 20:30:00.852646 140632881538880 spec.py:310] Evaluating on the validation split.
I0509 20:30:02.217425 140632881538880 spec.py:326] Evaluating on the test split.
I0509 20:30:03.580488 140632881538880 submission_runner.py:424] Time since start: 1722.99s, 	Step: 5428, 	{'train/ssim': 0.7388428960527692, 'train/loss': 0.27183851173945833, 'validation/ssim': 0.7151187345024972, 'validation/loss': 0.2914464432131929, 'validation/num_examples': 3554, 'test/ssim': 0.7325273442954133, 'test/loss': 0.2930025997124581, 'test/num_examples': 3581, 'score': 1436.103980064392, 'total_duration': 1722.990051984787, 'accumulated_submission_time': 1436.103980064392, 'accumulated_data_selection_time': 1271.8306708335876, 'accumulated_eval_time': 286.4513990879059, 'accumulated_logging_time': 0.35891032218933105}
I0509 20:30:03.590399 140427848054528 logging_writer.py:48] [5428] accumulated_data_selection_time=1271.830671, accumulated_eval_time=286.451399, accumulated_logging_time=0.358910, accumulated_submission_time=1436.103980, global_step=5428, preemption_count=0, score=1436.103980, test/loss=0.293003, test/num_examples=3581, test/ssim=0.732527, total_duration=1722.990052, train/loss=0.271839, train/ssim=0.738843, validation/loss=0.291446, validation/num_examples=3554, validation/ssim=0.715119
I0509 20:30:03.604828 140427839661824 logging_writer.py:48] [5428] global_step=5428, preemption_count=0, score=1436.103980
I0509 20:30:03.639302 140632881538880 checkpoints.py:356] Saving checkpoint at step: 5428
I0509 20:30:03.866600 140632881538880 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_fancy_verify/timing_sam/fastmri_jax/trial_1/checkpoint_5428
I0509 20:30:03.867274 140632881538880 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_fancy_verify/timing_sam/fastmri_jax/trial_1/checkpoint_5428.
I0509 20:30:04.617488 140632881538880 submission_runner.py:587] Tuning trial 1/1
I0509 20:30:04.617716 140632881538880 submission_runner.py:588] Hyperparameters: Hyperparameters(learning_rate=0.0013159053452895648, one_minus_beta1=0.2018302260773442, beta2=0.999, warmup_factor=0.05, weight_decay=0.07935861128365443, label_smoothing=0.1, dropout_rate=0.0, rho=0.01)
I0509 20:30:04.620815 140632881538880 submission_runner.py:589] Metrics: {'eval_results': [(1, {'train/ssim': 0.28299944741385324, 'train/loss': 0.7835339818681989, 'validation/ssim': 0.2700521440135675, 'validation/loss': 0.796358347878271, 'validation/num_examples': 3554, 'test/ssim': 0.2929518080996056, 'test/loss': 0.7950659322858489, 'test/num_examples': 3581, 'score': 68.8014543056488, 'total_duration': 279.24869084358215, 'accumulated_submission_time': 68.8014543056488, 'accumulated_data_selection_time': 36.585532665252686, 'accumulated_eval_time': 210.4470784664154, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (329, {'train/ssim': 0.6979986599513462, 'train/loss': 0.3100654057094029, 'validation/ssim': 0.6738602053803813, 'validation/loss': 0.3305638988969295, 'validation/num_examples': 3554, 'test/ssim': 0.6921687377827422, 'test/loss': 0.33243475357136626, 'test/num_examples': 3581, 'score': 149.11688494682312, 'total_duration': 364.1526873111725, 'accumulated_submission_time': 149.11688494682312, 'accumulated_data_selection_time': 108.53375005722046, 'accumulated_eval_time': 215.00557613372803, 'accumulated_logging_time': 0.025673627853393555, 'global_step': 329, 'preemption_count': 0}), (564, {'train/ssim': 0.7168310710362026, 'train/loss': 0.2952800818852016, 'validation/ssim': 0.6938103550796637, 'validation/loss': 0.3145582277451463, 'validation/num_examples': 3554, 'test/ssim': 0.7114650510070512, 'test/loss': 0.316770654255969, 'test/num_examples': 3581, 'score': 229.22612524032593, 'total_duration': 448.4779884815216, 'accumulated_submission_time': 229.22612524032593, 'accumulated_data_selection_time': 182.84632420539856, 'accumulated_eval_time': 219.1930603981018, 'accumulated_logging_time': 0.051164865493774414, 'global_step': 564, 'preemption_count': 0}), (803, {'train/ssim': 0.7190600122724261, 'train/loss': 0.2901318073272705, 'validation/ssim': 0.697025674745885, 'validation/loss': 0.30888535859682753, 'validation/num_examples': 3554, 'test/ssim': 0.7142208880201061, 'test/loss': 0.31112647888814227, 'test/num_examples': 3581, 'score': 309.4813714027405, 'total_duration': 532.9476251602173, 'accumulated_submission_time': 309.4813714027405, 'accumulated_data_selection_time': 256.4764401912689, 'accumulated_eval_time': 223.37900757789612, 'accumulated_logging_time': 0.07646489143371582, 'global_step': 803, 'preemption_count': 0}), (1072, {'train/ssim': 0.7267129080636161, 'train/loss': 0.28590801783970426, 'validation/ssim': 0.7035884824977139, 'validation/loss': 0.30551338088465463, 'validation/num_examples': 3554, 'test/ssim': 0.7206905804942754, 'test/loss': 0.30778425440912105, 'test/num_examples': 3581, 'score': 389.76232743263245, 'total_duration': 617.4604759216309, 'accumulated_submission_time': 389.76232743263245, 'accumulated_data_selection_time': 330.12352538108826, 'accumulated_eval_time': 227.57844257354736, 'accumulated_logging_time': 0.10543036460876465, 'global_step': 1072, 'preemption_count': 0}), (1406, {'train/ssim': 0.7315048490251813, 'train/loss': 0.28089054993220736, 'validation/ssim': 0.7085193812209833, 'validation/loss': 0.30010107037185213, 'validation/num_examples': 3554, 'test/ssim': 0.7257609469901913, 'test/loss': 0.3019316970752758, 'test/num_examples': 3581, 'score': 469.88837790489197, 'total_duration': 701.8091356754303, 'accumulated_submission_time': 469.88837790489197, 'accumulated_data_selection_time': 402.2046568393707, 'accumulated_eval_time': 231.77931666374207, 'accumulated_logging_time': 0.12238931655883789, 'global_step': 1406, 'preemption_count': 0}), (1740, {'train/ssim': 0.7353490420750209, 'train/loss': 0.2779268366949899, 'validation/ssim': 0.7119984194745357, 'validation/loss': 0.29757499802159537, 'validation/num_examples': 3554, 'test/ssim': 0.7293137691767314, 'test/loss': 0.2992658873437936, 'test/num_examples': 3581, 'score': 549.9516477584839, 'total_duration': 786.0970232486725, 'accumulated_submission_time': 549.9516477584839, 'accumulated_data_selection_time': 474.41468334198, 'accumulated_eval_time': 235.98246550559998, 'accumulated_logging_time': 0.13925576210021973, 'global_step': 1740, 'preemption_count': 0}), (2071, {'train/ssim': 0.7300763811383929, 'train/loss': 0.27880355290004183, 'validation/ssim': 0.708418262762908, 'validation/loss': 0.2976870732691158, 'validation/num_examples': 3554, 'test/ssim': 0.7254709234719702, 'test/loss': 0.2994087174497347, 'test/num_examples': 3581, 'score': 629.9959139823914, 'total_duration': 870.3659014701843, 'accumulated_submission_time': 629.9959139823914, 'accumulated_data_selection_time': 546.6877727508545, 'accumulated_eval_time': 240.18550276756287, 'accumulated_logging_time': 0.1561717987060547, 'global_step': 2071, 'preemption_count': 0}), (2404, {'train/ssim': 0.7378464426313128, 'train/loss': 0.2745086465563093, 'validation/ssim': 0.7142825150798396, 'validation/loss': 0.2941751646472285, 'validation/num_examples': 3554, 'test/ssim': 0.7315639398910919, 'test/loss': 0.2958637696676033, 'test/num_examples': 3581, 'score': 710.2199323177338, 'total_duration': 954.8236472606659, 'accumulated_submission_time': 710.2199323177338, 'accumulated_data_selection_time': 618.8994538784027, 'accumulated_eval_time': 244.3967580795288, 'accumulated_logging_time': 0.17400360107421875, 'global_step': 2404, 'preemption_count': 0}), (2738, {'train/ssim': 0.7383364949907575, 'train/loss': 0.27326370988573345, 'validation/ssim': 0.7144975291924592, 'validation/loss': 0.29304572230453363, 'validation/num_examples': 3554, 'test/ssim': 0.7319140952247976, 'test/loss': 0.29462367028239317, 'test/num_examples': 3581, 'score': 790.3411655426025, 'total_duration': 1039.1760907173157, 'accumulated_submission_time': 790.3411655426025, 'accumulated_data_selection_time': 691.1961417198181, 'accumulated_eval_time': 248.6055202484131, 'accumulated_logging_time': 0.19178199768066406, 'global_step': 2738, 'preemption_count': 0}), (3069, {'train/ssim': 0.7403180258614677, 'train/loss': 0.27238929271698, 'validation/ssim': 0.7168069044122819, 'validation/loss': 0.2921149447585467, 'validation/num_examples': 3554, 'test/ssim': 0.7340977936941496, 'test/loss': 0.2936894454892139, 'test/num_examples': 3581, 'score': 870.4499657154083, 'total_duration': 1123.5055058002472, 'accumulated_submission_time': 870.4499657154083, 'accumulated_data_selection_time': 763.5309662818909, 'accumulated_eval_time': 252.80404019355774, 'accumulated_logging_time': 0.20926380157470703, 'global_step': 3069, 'preemption_count': 0}), (3402, {'train/ssim': 0.7391842433384487, 'train/loss': 0.27540366990225656, 'validation/ssim': 0.7153553187209833, 'validation/loss': 0.2954151366088386, 'validation/num_examples': 3554, 'test/ssim': 0.7322537513526249, 'test/loss': 0.29722004208408964, 'test/num_examples': 3581, 'score': 950.5378625392914, 'total_duration': 1207.8239648342133, 'accumulated_submission_time': 950.5378625392914, 'accumulated_data_selection_time': 835.6826694011688, 'accumulated_eval_time': 257.0103192329407, 'accumulated_logging_time': 0.2289891242980957, 'global_step': 3402, 'preemption_count': 0}), (3735, {'train/ssim': 0.7388229370117188, 'train/loss': 0.2734854221343994, 'validation/ssim': 0.7145432111045653, 'validation/loss': 0.2935755294430571, 'validation/num_examples': 3554, 'test/ssim': 0.7319141634014591, 'test/loss': 0.2950208334242356, 'test/num_examples': 3581, 'score': 1030.5587422847748, 'total_duration': 1292.0732610225677, 'accumulated_submission_time': 1030.5587422847748, 'accumulated_data_selection_time': 907.8232474327087, 'accumulated_eval_time': 261.2158601284027, 'accumulated_logging_time': 0.2471940517425537, 'global_step': 3735, 'preemption_count': 0}), (4069, {'train/ssim': 0.7420073236737933, 'train/loss': 0.2716865198952811, 'validation/ssim': 0.7179249777979038, 'validation/loss': 0.2917944500804551, 'validation/num_examples': 3554, 'test/ssim': 0.7351594406677604, 'test/loss': 0.2933768214076899, 'test/num_examples': 3581, 'score': 1110.7785708904266, 'total_duration': 1376.5245842933655, 'accumulated_submission_time': 1110.7785708904266, 'accumulated_data_selection_time': 980.2070775032043, 'accumulated_eval_time': 265.4241621494293, 'accumulated_logging_time': 0.26541924476623535, 'global_step': 4069, 'preemption_count': 0}), (4399, {'train/ssim': 0.7425810950142997, 'train/loss': 0.27122626985822407, 'validation/ssim': 0.718173446182998, 'validation/loss': 0.29143514295072454, 'validation/num_examples': 3554, 'test/ssim': 0.735324769072012, 'test/loss': 0.29305223232206434, 'test/num_examples': 3581, 'score': 1190.9166474342346, 'total_duration': 1460.8873200416565, 'accumulated_submission_time': 1190.9166474342346, 'accumulated_data_selection_time': 1052.53577542305, 'accumulated_eval_time': 269.62617444992065, 'accumulated_logging_time': 0.28348350524902344, 'global_step': 4399, 'preemption_count': 0}), (4733, {'train/ssim': 0.7425328663417271, 'train/loss': 0.27130896704537527, 'validation/ssim': 0.718843699440771, 'validation/loss': 0.29106594379792133, 'validation/num_examples': 3554, 'test/ssim': 0.7362559940920832, 'test/loss': 0.2925256357882749, 'test/num_examples': 3581, 'score': 1271.0145478248596, 'total_duration': 1545.2111489772797, 'accumulated_submission_time': 1271.0145478248596, 'accumulated_data_selection_time': 1124.7997071743011, 'accumulated_eval_time': 273.82842683792114, 'accumulated_logging_time': 0.3025491237640381, 'global_step': 4733, 'preemption_count': 0}), (5067, {'train/ssim': 0.7401718412126813, 'train/loss': 0.2714803048542568, 'validation/ssim': 0.7165876312341728, 'validation/loss': 0.29126642900165306, 'validation/num_examples': 3554, 'test/ssim': 0.7339321925832519, 'test/loss': 0.2928518270254468, 'test/num_examples': 3581, 'score': 1351.0281014442444, 'total_duration': 1629.457494020462, 'accumulated_submission_time': 1351.0281014442444, 'accumulated_data_selection_time': 1196.9784896373749, 'accumulated_eval_time': 278.0375828742981, 'accumulated_logging_time': 0.32154083251953125, 'global_step': 5067, 'preemption_count': 0}), (5400, {'train/ssim': 0.7385042054312569, 'train/loss': 0.27409631865365164, 'validation/ssim': 0.7154964174389772, 'validation/loss': 0.29337878809527995, 'validation/num_examples': 3554, 'test/ssim': 0.7325570011431862, 'test/loss': 0.2951720833478777, 'test/num_examples': 3581, 'score': 1431.22345495224, 'total_duration': 1713.883698940277, 'accumulated_submission_time': 1431.22345495224, 'accumulated_data_selection_time': 1269.3581669330597, 'accumulated_eval_time': 282.2444689273834, 'accumulated_logging_time': 0.34078431129455566, 'global_step': 5400, 'preemption_count': 0}), (5428, {'train/ssim': 0.7388428960527692, 'train/loss': 0.27183851173945833, 'validation/ssim': 0.7151187345024972, 'validation/loss': 0.2914464432131929, 'validation/num_examples': 3554, 'test/ssim': 0.7325273442954133, 'test/loss': 0.2930025997124581, 'test/num_examples': 3581, 'score': 1436.103980064392, 'total_duration': 1722.990051984787, 'accumulated_submission_time': 1436.103980064392, 'accumulated_data_selection_time': 1271.8306708335876, 'accumulated_eval_time': 286.4513990879059, 'accumulated_logging_time': 0.35891032218933105, 'global_step': 5428, 'preemption_count': 0})], 'global_step': 5428}
I0509 20:30:04.620978 140632881538880 submission_runner.py:590] Timing: 1436.103980064392
I0509 20:30:04.621029 140632881538880 submission_runner.py:591] ====================
I0509 20:30:04.621154 140632881538880 submission_runner.py:654] Final fastmri score: 1436.103980064392
