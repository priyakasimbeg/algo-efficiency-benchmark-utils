torchrun --redirects 1:0,2:0,3:0,4:0,5:0,6:0,7:0 --standalone --nnodes=1 --nproc_per_node=8 submission_runner.py --framework=pytorch --workload=imagenet_resnet --submission_path=baselines/adamw/pytorch/submission.py --tuning_search_space=baselines/adamw/tuning_search_space.json --data_dir=/data/imagenet/pytorch --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=test_today/adamw --overwrite=True --save_checkpoints=False --max_global_steps=10 --imagenet_v2_data_dir=/data/imagenet/pytorch 2>&1 | tee -a /logs/imagenet_resnet_pytorch_06-27-2023-21-40-15.log
master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-06-27 21:40:20.407086: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 21:40:20.407090: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 21:40:20.407090: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 21:40:20.407086: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 21:40:20.407086: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 21:40:20.407086: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 21:40:20.407086: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 21:40:20.407086: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0627 21:40:33.337480 140719058421568 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 6
I0627 21:40:33.337478 140166013343552 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
I0627 21:40:34.276538 140016329647936 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 7
I0627 21:40:34.276559 140553263818560 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 5
I0627 21:40:34.289672 140514955667264 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
I0627 21:40:34.294829 140654708516672 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 4
I0627 21:40:34.295819 139748006541120 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
I0627 21:40:34.304415 139909407442752 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
I0627 21:40:34.304752 139909407442752 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 21:40:34.305464 140654708516672 distributed_c10d.py:476] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 21:40:34.306393 139748006541120 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 21:40:34.308000 140016329647936 distributed_c10d.py:476] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 21:40:34.308098 140553263818560 distributed_c10d.py:476] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 21:40:34.310873 140514955667264 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 21:40:34.313795 140719058421568 distributed_c10d.py:476] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 21:40:34.313822 140166013343552 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
I0627 21:40:35.467434 139909407442752 logger_utils.py:61] Removing existing experiment directory /experiment_runs/test_today/adamw/imagenet_resnet_pytorch because --overwrite was set.
I0627 21:40:35.469928 139909407442752 logger_utils.py:76] Creating experiment directory at /experiment_runs/test_today/adamw/imagenet_resnet_pytorch.
W0627 21:40:35.496001 140016329647936 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 21:40:35.496315 140654708516672 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 21:40:35.498167 140719058421568 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 21:40:35.499149 139748006541120 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 21:40:35.499918 140553263818560 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 21:40:35.500704 140166013343552 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 21:40:35.500934 139909407442752 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 21:40:35.502141 140514955667264 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0627 21:40:35.505919 139909407442752 submission_runner.py:547] Using RNG seed 1814805618
I0627 21:40:35.507340 139909407442752 submission_runner.py:556] --- Tuning run 1/1 ---
I0627 21:40:35.507461 139909407442752 submission_runner.py:561] Creating tuning directory at /experiment_runs/test_today/adamw/imagenet_resnet_pytorch/trial_1.
I0627 21:40:35.507820 139909407442752 logger_utils.py:92] Saving hparams to /experiment_runs/test_today/adamw/imagenet_resnet_pytorch/trial_1/hparams.json.
I0627 21:40:35.509024 139909407442752 submission_runner.py:249] Initializing dataset.
I0627 21:40:42.096589 139909407442752 submission_runner.py:256] Initializing model.
I0627 21:40:46.711978 139909407442752 submission_runner.py:268] Initializing optimizer.
I0627 21:40:46.713479 139909407442752 submission_runner.py:275] Initializing metrics bundle.
I0627 21:40:46.713614 139909407442752 submission_runner.py:292] Initializing checkpoint and logger.
I0627 21:40:47.405840 139909407442752 submission_runner.py:313] Saving meta data to /experiment_runs/test_today/adamw/imagenet_resnet_pytorch/trial_1/meta_data_0.json.
I0627 21:40:47.409190 139909407442752 submission_runner.py:316] Saving flags to /experiment_runs/test_today/adamw/imagenet_resnet_pytorch/trial_1/flags_0.json.
I0627 21:40:47.457939 139909407442752 submission_runner.py:328] Starting training loop.
I0627 21:41:00.752354 139881506400000 logging_writer.py:48] [0] global_step=0, grad_norm=0.585077, loss=6.922867
I0627 21:41:01.250402 139909407442752 submission.py:119] 0) loss = 6.923, grad_norm = 0.585
I0627 21:41:01.252134 139909407442752 spec.py:298] Evaluating on the training split.
I0627 21:42:03.239663 139909407442752 spec.py:310] Evaluating on the validation split.
I0627 21:42:49.822807 139909407442752 spec.py:326] Evaluating on the test split.
I0627 21:42:49.840160 139909407442752 dataset_info.py:578] Load dataset info from /data/imagenet/pytorch/imagenet_v2/matched-frequency/3.0.0
I0627 21:42:49.845946 139909407442752 dataset_builder.py:528] Reusing dataset imagenet_v2 (/data/imagenet/pytorch/imagenet_v2/matched-frequency/3.0.0)
I0627 21:42:49.910375 139909407442752 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/pytorch/imagenet_v2/matched-frequency/3.0.0
I0627 21:43:05.808542 139909407442752 submission_runner.py:424] Time since start: 138.35s, 	Step: 1, 	{'train/accuracy': 0.0009964923469387755, 'train/loss': 6.920298673668686, 'validation/accuracy': 0.00098, 'validation/loss': 6.9211075, 'validation/num_examples': 50000, 'test/accuracy': 0.0009, 'test/loss': 6.9225953125, 'test/num_examples': 10000, 'score': 13.792945146560669, 'total_duration': 138.35104250907898, 'accumulated_submission_time': 13.792945146560669, 'accumulated_eval_time': 124.556405544281, 'accumulated_logging_time': 0}
I0627 21:43:05.818475 139866128815872 logging_writer.py:48] [1] accumulated_eval_time=124.556406, accumulated_logging_time=0, accumulated_submission_time=13.792945, global_step=1, preemption_count=0, score=13.792945, test/accuracy=0.000900, test/loss=6.922595, test/num_examples=10000, total_duration=138.351043, train/accuracy=0.000996, train/loss=6.920299, validation/accuracy=0.000980, validation/loss=6.921107, validation/num_examples=50000
I0627 21:43:05.867212 139909407442752 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 21:43:05.867414 139748006541120 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 21:43:05.867442 140514955667264 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 21:43:05.867527 140166013343552 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 21:43:05.867616 140016329647936 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 21:43:05.867664 140719058421568 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 21:43:05.869534 140553263818560 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 21:43:05.869942 140654708516672 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [512, 2048, 1, 1], strides() = [2048, 1, 1, 1]
bucket_view.sizes() = [512, 2048, 1, 1], strides() = [2048, 1, 2048, 2048] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [512, 2048, 1, 1], strides() = [2048, 1, 1, 1]
bucket_view.sizes() = [512, 2048, 1, 1], strides() = [2048, 1, 2048, 2048] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [512, 2048, 1, 1], strides() = [2048, 1, 1, 1]
bucket_view.sizes() = [512, 2048, 1, 1], strides() = [2048, 1, 2048, 2048] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [512, 2048, 1, 1], strides() = [2048, 1, 1, 1]
bucket_view.sizes() = [512, 2048, 1, 1], strides() = [2048, 1, 2048, 2048] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [512, 2048, 1, 1], strides() = [2048, 1, 1, 1]
bucket_view.sizes() = [512, 2048, 1, 1], strides() = [2048, 1, 2048, 2048] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [512, 2048, 1, 1], strides() = [2048, 1, 1, 1]
bucket_view.sizes() = [512, 2048, 1, 1], strides() = [2048, 1, 2048, 2048] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [512, 2048, 1, 1], strides() = [2048, 1, 1, 1]
bucket_view.sizes() = [512, 2048, 1, 1], strides() = [2048, 1, 2048, 2048] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [512, 2048, 1, 1], strides() = [2048, 1, 1, 1]
bucket_view.sizes() = [512, 2048, 1, 1], strides() = [2048, 1, 2048, 2048] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
I0627 21:43:06.357843 139866120423168 logging_writer.py:48] [1] global_step=1, grad_norm=0.615997, loss=6.930437
I0627 21:43:06.362064 139909407442752 submission.py:119] 1) loss = 6.930, grad_norm = 0.616
I0627 21:43:06.735206 139866128815872 logging_writer.py:48] [2] global_step=2, grad_norm=0.605642, loss=6.926683
I0627 21:43:06.739687 139909407442752 submission.py:119] 2) loss = 6.927, grad_norm = 0.606
I0627 21:43:07.121221 139866120423168 logging_writer.py:48] [3] global_step=3, grad_norm=0.612646, loss=6.934949
I0627 21:43:07.126075 139909407442752 submission.py:119] 3) loss = 6.935, grad_norm = 0.613
I0627 21:43:07.502412 139866128815872 logging_writer.py:48] [4] global_step=4, grad_norm=0.603477, loss=6.926802
I0627 21:43:07.507897 139909407442752 submission.py:119] 4) loss = 6.927, grad_norm = 0.603
I0627 21:43:07.886603 139866120423168 logging_writer.py:48] [5] global_step=5, grad_norm=0.592067, loss=6.922902
I0627 21:43:07.891676 139909407442752 submission.py:119] 5) loss = 6.923, grad_norm = 0.592
I0627 21:43:08.273064 139866128815872 logging_writer.py:48] [6] global_step=6, grad_norm=0.610190, loss=6.919312
I0627 21:43:08.277527 139909407442752 submission.py:119] 6) loss = 6.919, grad_norm = 0.610
I0627 21:43:08.655668 139866120423168 logging_writer.py:48] [7] global_step=7, grad_norm=0.622461, loss=6.939243
I0627 21:43:08.660689 139909407442752 submission.py:119] 7) loss = 6.939, grad_norm = 0.622
I0627 21:43:09.044737 139866128815872 logging_writer.py:48] [8] global_step=8, grad_norm=0.609026, loss=6.929287
I0627 21:43:09.049936 139909407442752 submission.py:119] 8) loss = 6.929, grad_norm = 0.609
I0627 21:43:09.423882 139866120423168 logging_writer.py:48] [9] global_step=9, grad_norm=0.622274, loss=6.919619
I0627 21:43:09.428035 139909407442752 submission.py:119] 9) loss = 6.920, grad_norm = 0.622
I0627 21:43:09.430009 139909407442752 spec.py:298] Evaluating on the training split.
I0627 21:43:53.526248 139909407442752 spec.py:310] Evaluating on the validation split.
I0627 21:44:39.088242 139909407442752 spec.py:326] Evaluating on the test split.
I0627 21:44:40.429836 139909407442752 submission_runner.py:424] Time since start: 232.97s, 	Step: 10, 	{'train/accuracy': 0.0007374043367346938, 'train/loss': 6.914121043925383, 'validation/accuracy': 0.00104, 'validation/loss': 6.914496875, 'validation/num_examples': 50000, 'test/accuracy': 0.0013, 'test/loss': 6.9152546875, 'test/num_examples': 10000, 'score': 17.386699199676514, 'total_duration': 232.97246170043945, 'accumulated_submission_time': 17.386699199676514, 'accumulated_eval_time': 215.55659818649292, 'accumulated_logging_time': 0.02028656005859375}
I0627 21:44:40.438162 139866137208576 logging_writer.py:48] [10] accumulated_eval_time=215.556598, accumulated_logging_time=0.020287, accumulated_submission_time=17.386699, global_step=10, preemption_count=0, score=17.386699, test/accuracy=0.001300, test/loss=6.915255, test/num_examples=10000, total_duration=232.972462, train/accuracy=0.000737, train/loss=6.914121, validation/accuracy=0.001040, validation/loss=6.914497, validation/num_examples=50000
I0627 21:44:40.456413 139866901829376 logging_writer.py:48] [10] global_step=10, preemption_count=0, score=17.386699
I0627 21:44:41.073678 139909407442752 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/test_today/adamw/imagenet_resnet_pytorch/trial_1/checkpoint_10.
I0627 21:44:41.437584 139909407442752 submission_runner.py:587] Tuning trial 1/1
I0627 21:44:41.437866 139909407442752 submission_runner.py:588] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0627 21:44:41.438562 139909407442752 submission_runner.py:589] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0009964923469387755, 'train/loss': 6.920298673668686, 'validation/accuracy': 0.00098, 'validation/loss': 6.9211075, 'validation/num_examples': 50000, 'test/accuracy': 0.0009, 'test/loss': 6.9225953125, 'test/num_examples': 10000, 'score': 13.792945146560669, 'total_duration': 138.35104250907898, 'accumulated_submission_time': 13.792945146560669, 'accumulated_eval_time': 124.556405544281, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (10, {'train/accuracy': 0.0007374043367346938, 'train/loss': 6.914121043925383, 'validation/accuracy': 0.00104, 'validation/loss': 6.914496875, 'validation/num_examples': 50000, 'test/accuracy': 0.0013, 'test/loss': 6.9152546875, 'test/num_examples': 10000, 'score': 17.386699199676514, 'total_duration': 232.97246170043945, 'accumulated_submission_time': 17.386699199676514, 'accumulated_eval_time': 215.55659818649292, 'accumulated_logging_time': 0.02028656005859375, 'global_step': 10, 'preemption_count': 0})], 'global_step': 10}
I0627 21:44:41.438700 139909407442752 submission_runner.py:590] Timing: 17.386699199676514
I0627 21:44:41.438763 139909407442752 submission_runner.py:591] ====================
I0627 21:44:41.438880 139909407442752 submission_runner.py:659] Final imagenet_resnet score: 17.386699199676514
