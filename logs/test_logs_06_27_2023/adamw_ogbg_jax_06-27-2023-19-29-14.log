python3 submission_runner.py --framework=jax --workload=ogbg --submission_path=baselines/adamw/jax/submission.py --tuning_search_space=baselines/adamw/tuning_search_space.json --data_dir=/data/ogbg --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=test_today/adamw --overwrite=True --save_checkpoints=False --max_global_steps=10 2>&1 | tee -a /logs/ogbg_jax_06-27-2023-19-29-14.log
2023-06-27 19:29:17.232756: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0627 19:29:33.436773 140050963105600 logger_utils.py:61] Removing existing experiment directory /experiment_runs/test_today/adamw/ogbg_jax because --overwrite was set.
I0627 19:29:33.437541 140050963105600 logger_utils.py:76] Creating experiment directory at /experiment_runs/test_today/adamw/ogbg_jax.
I0627 19:29:34.384479 140050963105600 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Host Interpreter CUDA
I0627 19:29:34.385332 140050963105600 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0627 19:29:34.385638 140050963105600 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0627 19:29:34.391371 140050963105600 submission_runner.py:547] Using RNG seed 1075674020
I0627 19:29:36.728333 140050963105600 submission_runner.py:556] --- Tuning run 1/1 ---
I0627 19:29:36.728556 140050963105600 submission_runner.py:561] Creating tuning directory at /experiment_runs/test_today/adamw/ogbg_jax/trial_1.
I0627 19:29:36.728840 140050963105600 logger_utils.py:92] Saving hparams to /experiment_runs/test_today/adamw/ogbg_jax/trial_1/hparams.json.
I0627 19:29:36.916115 140050963105600 submission_runner.py:249] Initializing dataset.
I0627 19:29:37.031460 140050963105600 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0627 19:29:37.037203 140050963105600 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/reader.py:101: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
W0627 19:29:37.214260 140050963105600 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/reader.py:101: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
I0627 19:29:37.273828 140050963105600 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split train, from /data/ogbg/ogbg_molpcba/0.1.3
I0627 19:29:37.312141 140050963105600 submission_runner.py:256] Initializing model.
I0627 19:29:41.894695 140050963105600 submission_runner.py:268] Initializing optimizer.
I0627 19:29:42.567948 140050963105600 submission_runner.py:275] Initializing metrics bundle.
I0627 19:29:42.568167 140050963105600 submission_runner.py:292] Initializing checkpoint and logger.
I0627 19:29:42.569225 140050963105600 checkpoints.py:915] Found no checkpoint files in /experiment_runs/test_today/adamw/ogbg_jax/trial_1 with prefix checkpoint_
I0627 19:29:42.569491 140050963105600 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0627 19:29:42.569561 140050963105600 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0627 19:29:43.638740 140050963105600 submission_runner.py:313] Saving meta data to /experiment_runs/test_today/adamw/ogbg_jax/trial_1/meta_data_0.json.
I0627 19:29:43.639737 140050963105600 submission_runner.py:316] Saving flags to /experiment_runs/test_today/adamw/ogbg_jax/trial_1/flags_0.json.
I0627 19:29:43.647193 140050963105600 submission_runner.py:328] Starting training loop.
I0627 19:30:08.944294 139886900270848 logging_writer.py:48] [0] global_step=0, grad_norm=3.236935615539551, loss=0.7187861800193787
I0627 19:30:08.960237 140050963105600 spec.py:298] Evaluating on the training split.
I0627 19:30:08.966176 140050963105600 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0627 19:30:08.970309 140050963105600 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
I0627 19:30:09.039395 140050963105600 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split train, from /data/ogbg/ogbg_molpcba/0.1.3
I0627 19:32:04.825649 140050963105600 spec.py:310] Evaluating on the validation split.
I0627 19:32:04.829334 140050963105600 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0627 19:32:04.833423 140050963105600 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
I0627 19:32:04.900348 140050963105600 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split validation, from /data/ogbg/ogbg_molpcba/0.1.3
I0627 19:33:39.162994 140050963105600 spec.py:326] Evaluating on the test split.
I0627 19:33:39.166406 140050963105600 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0627 19:33:39.170366 140050963105600 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
I0627 19:33:39.233687 140050963105600 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split test, from /data/ogbg/ogbg_molpcba/0.1.3
I0627 19:35:15.504966 140050963105600 submission_runner.py:424] Time since start: 331.86s, 	Step: 1, 	{'train/accuracy': 0.4931411147117615, 'train/loss': 0.7172741889953613, 'train/mean_average_precision': 0.020078916859859203, 'validation/accuracy': 0.5006040334701538, 'validation/loss': 0.7176740765571594, 'validation/mean_average_precision': 0.024608516681823997, 'validation/num_examples': 43793, 'test/accuracy': 0.5033842921257019, 'test/loss': 0.7172349095344543, 'test/mean_average_precision': 0.02684759342455033, 'test/num_examples': 43793, 'score': 25.312844038009644, 'total_duration': 331.8576934337616, 'accumulated_submission_time': 25.312844038009644, 'accumulated_eval_time': 306.5446536540985, 'accumulated_logging_time': 0}
I0627 19:35:15.512319 139876708116224 logging_writer.py:48] [1] accumulated_eval_time=306.544654, accumulated_logging_time=0, accumulated_submission_time=25.312844, global_step=1, preemption_count=0, score=25.312844, test/accuracy=0.503384, test/loss=0.717235, test/mean_average_precision=0.026848, test/num_examples=43793, total_duration=331.857693, train/accuracy=0.493141, train/loss=0.717274, train/mean_average_precision=0.020079, validation/accuracy=0.500604, validation/loss=0.717674, validation/mean_average_precision=0.024609, validation/num_examples=43793
I0627 19:35:18.181775 140050963105600 spec.py:298] Evaluating on the training split.
I0627 19:37:06.892316 140050963105600 spec.py:310] Evaluating on the validation split.
I0627 19:37:09.843460 140050963105600 spec.py:326] Evaluating on the test split.
I0627 19:37:12.712058 140050963105600 submission_runner.py:424] Time since start: 449.06s, 	Step: 10, 	{'train/accuracy': 0.5619224309921265, 'train/loss': 0.6754629611968994, 'train/mean_average_precision': 0.022134941453599975, 'validation/accuracy': 0.5584326982498169, 'validation/loss': 0.6766252517700195, 'validation/mean_average_precision': 0.02399833043052636, 'validation/num_examples': 43793, 'test/accuracy': 0.5591300129890442, 'test/loss': 0.6765934228897095, 'test/mean_average_precision': 0.026193556186835554, 'test/num_examples': 43793, 'score': 27.97204566001892, 'total_duration': 449.06476163864136, 'accumulated_submission_time': 27.97204566001892, 'accumulated_eval_time': 421.0748562812805, 'accumulated_logging_time': 0.01723766326904297}
I0627 19:37:12.719209 139876691330816 logging_writer.py:48] [10] accumulated_eval_time=421.074856, accumulated_logging_time=0.017238, accumulated_submission_time=27.972046, global_step=10, preemption_count=0, score=27.972046, test/accuracy=0.559130, test/loss=0.676593, test/mean_average_precision=0.026194, test/num_examples=43793, total_duration=449.064762, train/accuracy=0.561922, train/loss=0.675463, train/mean_average_precision=0.022135, validation/accuracy=0.558433, validation/loss=0.676625, validation/mean_average_precision=0.023998, validation/num_examples=43793
I0627 19:37:12.735497 139876766570240 logging_writer.py:48] [10] global_step=10, preemption_count=0, score=27.972046
I0627 19:37:12.783850 140050963105600 checkpoints.py:490] Saving checkpoint at step: 10
I0627 19:37:12.909075 140050963105600 checkpoints.py:422] Saved checkpoint at /experiment_runs/test_today/adamw/ogbg_jax/trial_1/checkpoint_10
I0627 19:37:12.910351 140050963105600 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/test_today/adamw/ogbg_jax/trial_1/checkpoint_10.
I0627 19:37:13.029212 140050963105600 submission_runner.py:587] Tuning trial 1/1
I0627 19:37:13.029419 140050963105600 submission_runner.py:588] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0627 19:37:13.030295 140050963105600 submission_runner.py:589] Metrics: {'eval_results': [(1, {'train/accuracy': 0.4931411147117615, 'train/loss': 0.7172741889953613, 'train/mean_average_precision': 0.020078916859859203, 'validation/accuracy': 0.5006040334701538, 'validation/loss': 0.7176740765571594, 'validation/mean_average_precision': 0.024608516681823997, 'validation/num_examples': 43793, 'test/accuracy': 0.5033842921257019, 'test/loss': 0.7172349095344543, 'test/mean_average_precision': 0.02684759342455033, 'test/num_examples': 43793, 'score': 25.312844038009644, 'total_duration': 331.8576934337616, 'accumulated_submission_time': 25.312844038009644, 'accumulated_eval_time': 306.5446536540985, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (10, {'train/accuracy': 0.5619224309921265, 'train/loss': 0.6754629611968994, 'train/mean_average_precision': 0.022134941453599975, 'validation/accuracy': 0.5584326982498169, 'validation/loss': 0.6766252517700195, 'validation/mean_average_precision': 0.02399833043052636, 'validation/num_examples': 43793, 'test/accuracy': 0.5591300129890442, 'test/loss': 0.6765934228897095, 'test/mean_average_precision': 0.026193556186835554, 'test/num_examples': 43793, 'score': 27.97204566001892, 'total_duration': 449.06476163864136, 'accumulated_submission_time': 27.97204566001892, 'accumulated_eval_time': 421.0748562812805, 'accumulated_logging_time': 0.01723766326904297, 'global_step': 10, 'preemption_count': 0})], 'global_step': 10}
I0627 19:37:13.030401 140050963105600 submission_runner.py:590] Timing: 27.97204566001892
I0627 19:37:13.030452 140050963105600 submission_runner.py:591] ====================
I0627 19:37:13.030565 140050963105600 submission_runner.py:659] Final ogbg score: 27.97204566001892
