python3 submission_runner.py --framework=jax --workload=ogbg --submission_path=baselines/adamw/jax/submission.py --tuning_search_space=baselines/adamw/tuning_search_space.json --data_dir=/data/ogbg --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=test_today/adamw --overwrite=True --save_checkpoints=False --max_global_steps=10 2>&1 | tee -a /logs/ogbg_jax_06-27-2023-22-13-52.log
2023-06-27 22:13:55.382608: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0627 22:14:10.000690 139649845016384 logger_utils.py:61] Removing existing experiment directory /experiment_runs/test_today/adamw/ogbg_jax because --overwrite was set.
I0627 22:14:10.004325 139649845016384 logger_utils.py:76] Creating experiment directory at /experiment_runs/test_today/adamw/ogbg_jax.
I0627 22:14:11.057809 139649845016384 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Host CUDA Interpreter
I0627 22:14:11.058455 139649845016384 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0627 22:14:11.058665 139649845016384 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0627 22:14:11.063017 139649845016384 submission_runner.py:547] Using RNG seed 110737098
I0627 22:14:13.406971 139649845016384 submission_runner.py:556] --- Tuning run 1/1 ---
I0627 22:14:13.407180 139649845016384 submission_runner.py:561] Creating tuning directory at /experiment_runs/test_today/adamw/ogbg_jax/trial_1.
I0627 22:14:13.407419 139649845016384 logger_utils.py:92] Saving hparams to /experiment_runs/test_today/adamw/ogbg_jax/trial_1/hparams.json.
I0627 22:14:13.592560 139649845016384 submission_runner.py:249] Initializing dataset.
I0627 22:14:13.707463 139649845016384 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0627 22:14:13.712976 139649845016384 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/reader.py:101: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
W0627 22:14:13.884820 139649845016384 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/reader.py:101: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
I0627 22:14:13.942319 139649845016384 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split train, from /data/ogbg/ogbg_molpcba/0.1.3
I0627 22:14:13.975733 139649845016384 submission_runner.py:256] Initializing model.
I0627 22:14:18.680545 139649845016384 submission_runner.py:268] Initializing optimizer.
I0627 22:14:19.399511 139649845016384 submission_runner.py:275] Initializing metrics bundle.
I0627 22:14:19.399723 139649845016384 submission_runner.py:292] Initializing checkpoint and logger.
I0627 22:14:19.400718 139649845016384 checkpoints.py:915] Found no checkpoint files in /experiment_runs/test_today/adamw/ogbg_jax/trial_1 with prefix checkpoint_
I0627 22:14:19.401032 139649845016384 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0627 22:14:19.401119 139649845016384 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0627 22:14:20.485456 139649845016384 submission_runner.py:313] Saving meta data to /experiment_runs/test_today/adamw/ogbg_jax/trial_1/meta_data_0.json.
I0627 22:14:20.486462 139649845016384 submission_runner.py:316] Saving flags to /experiment_runs/test_today/adamw/ogbg_jax/trial_1/flags_0.json.
I0627 22:14:20.493549 139649845016384 submission_runner.py:328] Starting training loop.
I0627 22:14:45.586751 139485723481856 logging_writer.py:48] [0] global_step=0, grad_norm=3.0426769256591797, loss=0.7703936100006104
I0627 22:14:45.602452 139649845016384 spec.py:298] Evaluating on the training split.
I0627 22:14:45.608574 139649845016384 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0627 22:14:45.612680 139649845016384 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
I0627 22:14:45.681298 139649845016384 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split train, from /data/ogbg/ogbg_molpcba/0.1.3
I0627 22:16:40.732262 139649845016384 spec.py:310] Evaluating on the validation split.
I0627 22:16:40.735865 139649845016384 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0627 22:16:40.740039 139649845016384 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
I0627 22:16:40.804807 139649845016384 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split validation, from /data/ogbg/ogbg_molpcba/0.1.3
I0627 22:18:15.712225 139649845016384 spec.py:326] Evaluating on the test split.
I0627 22:18:15.716004 139649845016384 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0627 22:18:15.720242 139649845016384 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
I0627 22:18:15.787178 139649845016384 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split test, from /data/ogbg/ogbg_molpcba/0.1.3
I0627 22:19:53.187866 139649845016384 submission_runner.py:424] Time since start: 332.69s, 	Step: 1, 	{'train/accuracy': 0.46069401502609253, 'train/loss': 0.7710090279579163, 'train/mean_average_precision': 0.023224708512981612, 'validation/accuracy': 0.45674923062324524, 'validation/loss': 0.7755216360092163, 'validation/mean_average_precision': 0.025572195006994602, 'validation/num_examples': 43793, 'test/accuracy': 0.4579346477985382, 'test/loss': 0.7748171091079712, 'test/mean_average_precision': 0.026997408470458895, 'test/num_examples': 43793, 'score': 25.108734607696533, 'total_duration': 332.6942448616028, 'accumulated_submission_time': 25.108734607696533, 'accumulated_eval_time': 307.5853545665741, 'accumulated_logging_time': 0}
I0627 22:19:53.210605 139474457093888 logging_writer.py:48] [1] accumulated_eval_time=307.585355, accumulated_logging_time=0, accumulated_submission_time=25.108735, global_step=1, preemption_count=0, score=25.108735, test/accuracy=0.457935, test/loss=0.774817, test/mean_average_precision=0.026997, test/num_examples=43793, total_duration=332.694245, train/accuracy=0.460694, train/loss=0.771009, train/mean_average_precision=0.023225, validation/accuracy=0.456749, validation/loss=0.775522, validation/mean_average_precision=0.025572, validation/num_examples=43793
I0627 22:19:55.972123 139649845016384 spec.py:298] Evaluating on the training split.
I0627 22:21:47.722903 139649845016384 spec.py:310] Evaluating on the validation split.
I0627 22:21:50.677547 139649845016384 spec.py:326] Evaluating on the test split.
I0627 22:21:53.507189 139649845016384 submission_runner.py:424] Time since start: 453.01s, 	Step: 10, 	{'train/accuracy': 0.5203611254692078, 'train/loss': 0.731665849685669, 'train/mean_average_precision': 0.025346181566949004, 'validation/accuracy': 0.5115934610366821, 'validation/loss': 0.7365832328796387, 'validation/mean_average_precision': 0.02584702214080754, 'validation/num_examples': 43793, 'test/accuracy': 0.5113037824630737, 'test/loss': 0.7363401055335999, 'test/mean_average_precision': 0.027388074707455738, 'test/num_examples': 43793, 'score': 27.858304977416992, 'total_duration': 453.01357340812683, 'accumulated_submission_time': 27.858304977416992, 'accumulated_eval_time': 425.1203806400299, 'accumulated_logging_time': 0.03432035446166992}
I0627 22:21:53.514328 139475573274368 logging_writer.py:48] [10] accumulated_eval_time=425.120381, accumulated_logging_time=0.034320, accumulated_submission_time=27.858305, global_step=10, preemption_count=0, score=27.858305, test/accuracy=0.511304, test/loss=0.736340, test/mean_average_precision=0.027388, test/num_examples=43793, total_duration=453.013573, train/accuracy=0.520361, train/loss=0.731666, train/mean_average_precision=0.025346, validation/accuracy=0.511593, validation/loss=0.736583, validation/mean_average_precision=0.025847, validation/num_examples=43793
I0627 22:21:53.530987 139475665364736 logging_writer.py:48] [10] global_step=10, preemption_count=0, score=27.858305
I0627 22:21:53.578143 139649845016384 checkpoints.py:490] Saving checkpoint at step: 10
I0627 22:21:53.684642 139649845016384 checkpoints.py:422] Saved checkpoint at /experiment_runs/test_today/adamw/ogbg_jax/trial_1/checkpoint_10
I0627 22:21:53.685559 139649845016384 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/test_today/adamw/ogbg_jax/trial_1/checkpoint_10.
I0627 22:21:53.798331 139649845016384 submission_runner.py:587] Tuning trial 1/1
I0627 22:21:53.798528 139649845016384 submission_runner.py:588] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0627 22:21:53.799472 139649845016384 submission_runner.py:589] Metrics: {'eval_results': [(1, {'train/accuracy': 0.46069401502609253, 'train/loss': 0.7710090279579163, 'train/mean_average_precision': 0.023224708512981612, 'validation/accuracy': 0.45674923062324524, 'validation/loss': 0.7755216360092163, 'validation/mean_average_precision': 0.025572195006994602, 'validation/num_examples': 43793, 'test/accuracy': 0.4579346477985382, 'test/loss': 0.7748171091079712, 'test/mean_average_precision': 0.026997408470458895, 'test/num_examples': 43793, 'score': 25.108734607696533, 'total_duration': 332.6942448616028, 'accumulated_submission_time': 25.108734607696533, 'accumulated_eval_time': 307.5853545665741, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (10, {'train/accuracy': 0.5203611254692078, 'train/loss': 0.731665849685669, 'train/mean_average_precision': 0.025346181566949004, 'validation/accuracy': 0.5115934610366821, 'validation/loss': 0.7365832328796387, 'validation/mean_average_precision': 0.02584702214080754, 'validation/num_examples': 43793, 'test/accuracy': 0.5113037824630737, 'test/loss': 0.7363401055335999, 'test/mean_average_precision': 0.027388074707455738, 'test/num_examples': 43793, 'score': 27.858304977416992, 'total_duration': 453.01357340812683, 'accumulated_submission_time': 27.858304977416992, 'accumulated_eval_time': 425.1203806400299, 'accumulated_logging_time': 0.03432035446166992, 'global_step': 10, 'preemption_count': 0})], 'global_step': 10}
I0627 22:21:53.799590 139649845016384 submission_runner.py:590] Timing: 27.858304977416992
I0627 22:21:53.799643 139649845016384 submission_runner.py:591] ====================
I0627 22:21:53.799754 139649845016384 submission_runner.py:659] Final ogbg score: 27.858304977416992
