torchrun --redirects 1:0,2:0,3:0,4:0,5:0,6:0,7:0 --standalone --nnodes=1 --nproc_per_node=8 submission_runner.py --framework=pytorch --workload=imagenet_vit --submission_path=reference_algorithms/target_setting_algorithms/pytorch_nadamw.py --tuning_search_space=reference_algorithms/target_setting_algorithms/imagenet_vit/tuning_search_space.json --data_dir=/data/imagenet/pytorch --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=targets_check_pytorch/nadamw_run_0 --overwrite=true --save_checkpoints=false --max_global_steps=140000 --imagenet_v2_data_dir=/data/imagenet/pytorch --torch_compile=true 2>&1 | tee -a /logs/imagenet_vit_pytorch_09-15-2023-00-02-49.log
master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-09-15 00:02:59.028603: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-15 00:02:59.028607: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-15 00:02:59.028602: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-15 00:02:59.028611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-15 00:02:59.028603: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-15 00:02:59.028607: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-15 00:02:59.028612: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-15 00:02:59.028631: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0915 00:03:12.874644 139637226022720 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 5
I0915 00:03:12.874681 140101857412928 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
I0915 00:03:12.874684 139751877015360 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 7
I0915 00:03:12.875766 140585831905088 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
I0915 00:03:12.875905 140079640172352 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
I0915 00:03:12.876012 140072611149632 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 4
I0915 00:03:12.876402 140115095766848 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 6
I0915 00:03:12.885999 139684108298048 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
I0915 00:03:12.886511 140585831905088 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0915 00:03:12.886518 139684108298048 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0915 00:03:12.886681 140079640172352 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0915 00:03:12.886801 140072611149632 distributed_c10d.py:476] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0915 00:03:12.887195 140115095766848 distributed_c10d.py:476] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0915 00:03:12.895896 139751877015360 distributed_c10d.py:476] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0915 00:03:12.895923 139637226022720 distributed_c10d.py:476] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0915 00:03:12.895942 140101857412928 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
I0915 00:03:14.118339 139684108298048 logger_utils.py:76] Creating experiment directory at /experiment_runs/targets_check_pytorch/nadamw_run_0/imagenet_vit_pytorch.
W0915 00:03:15.111936 139637226022720 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0915 00:03:15.111936 139751877015360 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0915 00:03:15.111936 140585831905088 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0915 00:03:15.112142 140079640172352 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0915 00:03:15.112198 139684108298048 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0915 00:03:15.112396 140072611149632 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0915 00:03:15.112510 140101857412928 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0915 00:03:15.113282 140115095766848 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0915 00:03:15.117672 139684108298048 submission_runner.py:500] Using RNG seed 4247892447
I0915 00:03:15.119518 139684108298048 submission_runner.py:509] --- Tuning run 1/1 ---
I0915 00:03:15.119688 139684108298048 submission_runner.py:514] Creating tuning directory at /experiment_runs/targets_check_pytorch/nadamw_run_0/imagenet_vit_pytorch/trial_1.
I0915 00:03:15.119981 139684108298048 logger_utils.py:92] Saving hparams to /experiment_runs/targets_check_pytorch/nadamw_run_0/imagenet_vit_pytorch/trial_1/hparams.json.
I0915 00:03:15.121005 139684108298048 submission_runner.py:185] Initializing dataset.
I0915 00:03:21.461836 139684108298048 submission_runner.py:192] Initializing model.
I0915 00:03:26.169151 139684108298048 submission_runner.py:223] Performing `torch.compile`.
I0915 00:03:26.440112 139684108298048 submission_runner.py:226] Initializing optimizer.
I0915 00:03:26.441826 139684108298048 submission_runner.py:233] Initializing metrics bundle.
I0915 00:03:26.441946 139684108298048 submission_runner.py:251] Initializing checkpoint and logger.
I0915 00:03:26.892940 139684108298048 submission_runner.py:272] Saving meta data to /experiment_runs/targets_check_pytorch/nadamw_run_0/imagenet_vit_pytorch/trial_1/meta_data_0.json.
I0915 00:03:26.893807 139684108298048 submission_runner.py:275] Saving flags to /experiment_runs/targets_check_pytorch/nadamw_run_0/imagenet_vit_pytorch/trial_1/flags_0.json.
I0915 00:03:26.975516 139684108298048 submission_runner.py:285] Starting training loop.
[2023-09-15 00:03:29,369] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:03:29,494] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:03:29,501] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:03:29,535] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:03:29,583] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:03:29,586] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:03:29,624] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:03:29,660] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:03:31,664] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:03:31,720] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:03:31,725] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:03:31,730] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:03:31,731] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:03:31,783] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:03:31,787] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:03:31,788] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:03:31,804] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:03:31,862] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:03:31,866] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:03:31,867] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:03:31,924] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:03:31,937] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:03:31,945] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:03:31,981] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:03:31,981] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:03:31,985] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:03:31,986] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:03:32,002] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:03:32,006] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:03:32,007] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:03:32,027] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:03:32,035] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:03:32,039] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:03:32,039] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:03:32,044] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:03:32,048] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:03:32,054] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:03:32,120] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:03:32,124] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:03:32,132] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:03:37,352] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-15 00:03:37,352] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-15 00:03:37,352] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-15 00:03:37,352] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-15 00:03:37,353] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-15 00:03:37,352] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-15 00:03:37,353] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-15 00:03:37,354] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-15 00:03:43,588] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-15 00:03:43,595] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-15 00:03:43,595] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-15 00:03:43,595] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-15 00:03:43,595] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-15 00:03:43,670] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-15 00:03:43,678] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-15 00:03:43,767] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-15 00:03:47,251] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-15 00:03:47,252] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-15 00:03:47,280] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-15 00:03:47,290] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-15 00:03:47,338] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-15 00:03:47,366] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-15 00:03:47,400] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-15 00:03:47,403] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-15 00:03:54,153] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-15 00:03:54,193] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-15 00:03:54,244] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-15 00:03:54,266] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-15 00:03:54,286] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-15 00:03:54,298] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-15 00:03:54,305] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-15 00:03:54,374] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-15 00:03:57,510] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-15 00:03:57,552] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-15 00:03:57,620] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-15 00:03:57,670] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-15 00:03:57,696] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-15 00:03:57,702] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-15 00:03:57,704] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-15 00:03:57,718] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-15 00:03:58,724] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-15 00:03:58,768] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-15 00:03:58,840] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-15 00:03:58,893] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-15 00:03:58,919] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-15 00:03:58,923] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-15 00:03:58,924] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-15 00:03:58,941] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-15 00:04:02,075] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-15 00:04:02,085] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-15 00:04:02,188] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-15 00:04:02,247] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-15 00:04:02,266] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-15 00:04:02,267] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-15 00:04:02,298] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-15 00:04:02,299] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-15 00:04:05,754] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-15 00:04:05,769] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-15 00:04:05,953] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-15 00:04:05,990] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-15 00:04:06,006] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-15 00:04:06,012] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-15 00:04:06,013] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-15 00:04:06,018] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-15 00:04:06,020] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:04:06,026] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:04:06,033] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-15 00:04:06,040] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-15 00:04:06,044] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-15 00:04:06,162] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-15 00:04:06,194] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-15 00:04:06,199] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-15 00:04:06,207] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:04:06,225] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-15 00:04:06,231] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-15 00:04:06,238] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:04:06,275] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-15 00:04:06,276] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-15 00:04:06,281] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-15 00:04:06,281] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-15 00:04:06,282] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-15 00:04:06,287] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-15 00:04:06,288] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:04:06,288] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:04:06,295] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:04:06,399] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-15 00:04:06,405] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-15 00:04:06,412] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:04:15,171] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-15 00:04:15,289] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-15 00:04:15,290] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-15 00:04:15,297] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-15 00:04:15,308] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-15 00:04:15,309] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-15 00:04:15,311] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-15 00:04:15,312] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-15 00:04:15,676] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-15 00:04:15,708] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-15 00:04:15,792] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-15 00:04:15,793] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-15 00:04:15,816] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-15 00:04:15,817] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-15 00:04:15,817] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-15 00:04:15,818] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-15 00:04:15,818] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-15 00:04:15,842] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-15 00:04:15,842] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-15 00:04:15,843] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-15 00:04:15,853] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-15 00:04:15,858] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-15 00:04:15,877] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-15 00:04:15,883] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-15 00:04:20,628] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-15 00:04:20,629] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-15 00:04:20,686] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-15 00:04:20,730] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-15 00:04:20,764] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-15 00:04:20,795] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-15 00:04:20,804] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-15 00:04:20,814] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-15 00:04:22,622] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-15 00:04:22,643] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-15 00:04:22,700] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-15 00:04:22,726] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-15 00:04:22,757] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-15 00:04:22,769] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-15 00:04:22,789] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-15 00:04:22,825] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-15 00:04:27,763] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-15 00:04:27,874] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-15 00:04:27,893] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-15 00:04:27,902] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-15 00:04:27,927] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-15 00:04:27,982] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-15 00:04:27,996] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-15 00:04:28,053] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-15 00:04:28,974] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-15 00:04:29,088] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-15 00:04:29,106] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-15 00:04:29,114] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-15 00:04:29,138] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-15 00:04:29,191] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-15 00:04:29,208] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-15 00:04:29,265] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-15 00:04:31,233] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-15 00:04:31,248] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-15 00:04:31,356] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-15 00:04:31,371] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-15 00:04:31,395] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-15 00:04:31,404] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-15 00:04:31,410] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-15 00:04:31,415] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-15 00:04:31,419] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-15 00:04:31,430] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-15 00:04:31,461] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-15 00:04:31,469] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-15 00:04:31,476] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-15 00:04:31,484] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-15 00:04:31,521] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-15 00:04:31,536] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-15 00:04:31,788] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-15 00:04:31,919] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-15 00:04:31,962] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-15 00:04:31,973] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-15 00:04:31,996] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-15 00:04:32,039] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-15 00:04:32,039] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-15 00:04:32,092] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
I0915 00:04:32.659519 139656817530624 logging_writer.py:48] [0] global_step=0, grad_norm=0.367421, loss=6.907756
I0915 00:04:32.684078 139684108298048 pytorch_submission_base.py:86] 0) loss = 6.908, grad_norm = 0.367
I0915 00:04:33.131070 139684108298048 spec.py:320] Evaluating on the training split.
[2023-09-15 00:04:44,787] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:04:44,796] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:04:44,818] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:04:44,857] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:04:44,876] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:04:44,951] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:04:44,993] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:04:45,094] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:04:46,464] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:04:46,474] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:04:46,493] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:04:46,507] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:04:46,511] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:04:46,511] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:04:46,516] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:04:46,520] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:04:46,521] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:04:46,524] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:04:46,537] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:04:46,540] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:04:46,541] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:04:46,560] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:04:46,567] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:04:46,571] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:04:46,572] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:04:46,603] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:04:46,607] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:04:46,608] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:04:46,645] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:04:46,645] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:04:46,688] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:04:46,688] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:04:46,691] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:04:46,692] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:04:46,692] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:04:46,692] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:04:46,732] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:04:46,774] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:04:46,778] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:04:46,779] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:04:47,007] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-15 00:04:47,010] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-15 00:04:47,043] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-15 00:04:47,068] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-15 00:04:47,100] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-15 00:04:47,188] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-15 00:04:47,191] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-15 00:04:47,270] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-15 00:04:49,480] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-15 00:04:49,541] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-15 00:04:49,579] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-15 00:04:49,602] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-15 00:04:49,607] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-15 00:04:49,673] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-15 00:04:49,788] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-15 00:04:49,801] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-15 00:04:51,000] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-15 00:04:51,025] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-15 00:04:51,081] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-15 00:04:51,098] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-15 00:04:51,101] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-15 00:04:51,192] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-15 00:04:51,305] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-15 00:04:51,349] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-15 00:04:54,795] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-15 00:04:54,795] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-15 00:04:54,812] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-15 00:04:54,844] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-15 00:04:54,876] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-15 00:04:54,877] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-15 00:04:55,113] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-15 00:04:55,140] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-15 00:04:56,428] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-15 00:04:56,451] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-15 00:04:56,464] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-15 00:04:56,515] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-15 00:04:56,551] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-15 00:04:56,562] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-15 00:04:56,751] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-15 00:04:56,816] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-15 00:04:57,432] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-15 00:04:57,464] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-15 00:04:57,467] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-15 00:04:57,512] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-15 00:04:57,557] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-15 00:04:57,573] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-15 00:04:57,773] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-15 00:04:57,812] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-15 00:04:58,831] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-15 00:04:58,852] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-15 00:04:58,861] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-15 00:04:58,904] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-15 00:04:58,965] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-15 00:04:58,980] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-15 00:04:59,174] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-15 00:04:59,277] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-15 00:05:02,613] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-15 00:05:02,616] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-15 00:05:02,632] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-15 00:05:02,635] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-15 00:05:02,675] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-15 00:05:02,733] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-15 00:05:02,812] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-15 00:05:02,817] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-15 00:05:02,822] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:05:02,825] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-15 00:05:02,829] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-15 00:05:02,835] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:05:02,837] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-15 00:05:02,842] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-15 00:05:02,843] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-15 00:05:02,847] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:05:02,848] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-15 00:05:02,853] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:05:02,872] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-15 00:05:02,877] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-15 00:05:02,882] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:05:02,936] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-15 00:05:02,941] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-15 00:05:02,947] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:05:02,978] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-15 00:05:03,093] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-15 00:05:03,174] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-15 00:05:03,179] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-15 00:05:03,184] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:05:03,301] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-15 00:05:03,306] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-15 00:05:03,313] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0915 00:05:52.297366 139684108298048 spec.py:332] Evaluating on the validation split.
[2023-09-15 00:06:42,989] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:06:43,110] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:06:43,347] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:06:43,522] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:06:43,566] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:06:43,911] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:06:44,378] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:06:44,586] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:06:44,893] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:06:44,935] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:06:44,939] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:06:44,940] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:06:44,967] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:06:45,010] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:06:45,014] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:06:45,014] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:06:45,208] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:06:45,249] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:06:45,253] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:06:45,254] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:06:45,398] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:06:45,440] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:06:45,444] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:06:45,445] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:06:45,445] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-15 00:06:45,451] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:06:45,492] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:06:45,496] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:06:45,496] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:06:45,501] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-15 00:06:45,743] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-15 00:06:45,781] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:06:45,822] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:06:45,826] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:06:45,827] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:06:45,932] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-15 00:06:46,003] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-15 00:06:46,276] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:06:46,323] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:06:46,327] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:06:46,328] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:06:46,361] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-15 00:06:46,537] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:06:46,589] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:06:46,594] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:06:46,595] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:06:46,891] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-15 00:06:47,236] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-15 00:06:47,807] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-15 00:06:47,910] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-15 00:06:48,183] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-15 00:06:48,348] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-15 00:06:48,386] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-15 00:06:48,735] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-15 00:06:49,213] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-15 00:06:49,400] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-15 00:06:49,438] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-15 00:06:49,529] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-15 00:06:49,689] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-15 00:06:49,884] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-15 00:06:49,887] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-15 00:06:50,222] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-15 00:06:50,785] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-15 00:06:51,137] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-15 00:06:52,814] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-15 00:06:52,984] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-15 00:06:53,290] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-15 00:06:53,531] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-15 00:06:53,642] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-15 00:06:53,867] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-15 00:06:54,422] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-15 00:06:54,684] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-15 00:06:55,189] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-15 00:06:55,258] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-15 00:06:55,559] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-15 00:06:55,763] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-15 00:06:55,842] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-15 00:06:56,038] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-15 00:06:56,199] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-15 00:06:56,274] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-15 00:06:56,571] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-15 00:06:56,625] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-15 00:06:56,767] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-15 00:06:56,839] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-15 00:06:56,857] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-15 00:06:57,044] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-15 00:06:57,627] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-15 00:06:57,640] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-15 00:06:57,670] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-15 00:06:57,852] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-15 00:06:57,978] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-15 00:06:58,170] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-15 00:06:58,268] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-15 00:06:58,450] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-15 00:06:59,177] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-15 00:06:59,297] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-15 00:07:00,436] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-15 00:07:00,441] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-15 00:07:00,651] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-15 00:07:00,653] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-15 00:07:00,656] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-15 00:07:00,658] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-15 00:07:00,662] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:00,664] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:00,777] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-15 00:07:00,922] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-15 00:07:00,979] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-15 00:07:00,984] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-15 00:07:00,989] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:01,061] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-15 00:07:01,126] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-15 00:07:01,131] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-15 00:07:01,136] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:01,250] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-15 00:07:01,264] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-15 00:07:01,269] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-15 00:07:01,275] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:01,447] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-15 00:07:01,452] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-15 00:07:01,457] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:01,893] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-15 00:07:02,052] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-15 00:07:02,116] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-15 00:07:02,122] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-15 00:07:02,128] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:02,269] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-15 00:07:02,274] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-15 00:07:02,279] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0915 00:07:05.347251 139684108298048 spec.py:348] Evaluating on the test split.
I0915 00:07:05.362875 139684108298048 dataset_info.py:578] Load dataset info from /data/imagenet/pytorch/imagenet_v2/matched-frequency/3.0.0
I0915 00:07:05.369236 139684108298048 dataset_builder.py:528] Reusing dataset imagenet_v2 (/data/imagenet/pytorch/imagenet_v2/matched-frequency/3.0.0)
I0915 00:07:05.441886 139684108298048 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/pytorch/imagenet_v2/matched-frequency/3.0.0
[2023-09-15 00:07:08,479] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:07:08,549] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:07:08,644] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:07:08,672] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:07:08,753] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:07:08,800] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:07:09,167] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:07:09,346] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:07:13,840] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:07:13,880] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:07:13,884] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:07:13,884] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:07:13,891] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:07:13,931] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:07:13,935] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:07:13,936] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:07:13,952] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:07:13,959] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:07:13,969] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:07:13,993] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:07:13,998] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:07:13,998] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:07:14,000] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:07:14,004] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:07:14,005] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:07:14,010] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:07:14,015] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:07:14,015] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:07:14,052] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:07:14,092] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:07:14,096] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:07:14,096] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:07:14,136] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:07:14,161] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:07:14,177] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:07:14,180] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:07:14,181] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:07:14,201] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:07:14,206] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:07:14,206] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:07:14,370] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-15 00:07:14,425] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-15 00:07:14,491] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-15 00:07:14,493] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-15 00:07:14,508] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-15 00:07:14,575] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-15 00:07:14,662] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-15 00:07:14,695] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-15 00:07:15,167] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-15 00:07:15,262] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-15 00:07:15,279] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-15 00:07:15,310] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-15 00:07:15,321] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-15 00:07:15,417] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-15 00:07:15,493] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-15 00:07:15,527] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-15 00:07:16,637] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-15 00:07:16,737] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-15 00:07:16,798] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-15 00:07:16,804] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-15 00:07:16,829] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-15 00:07:16,879] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-15 00:07:16,935] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-15 00:07:17,013] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-15 00:07:17,970] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-15 00:07:18,095] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-15 00:07:18,149] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-15 00:07:18,157] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-15 00:07:18,187] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-15 00:07:18,228] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-15 00:07:18,306] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-15 00:07:18,380] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-15 00:07:19,576] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-15 00:07:19,686] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-15 00:07:19,750] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-15 00:07:19,795] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-15 00:07:19,804] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-15 00:07:19,809] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-15 00:07:19,886] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-15 00:07:20,011] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-15 00:07:20,519] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-15 00:07:20,634] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-15 00:07:20,693] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-15 00:07:20,752] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-15 00:07:20,754] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-15 00:07:20,754] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-15 00:07:20,839] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-15 00:07:20,965] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-15 00:07:21,887] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-15 00:07:22,008] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-15 00:07:22,090] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-15 00:07:22,126] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-15 00:07:22,163] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-15 00:07:22,171] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-15 00:07:22,231] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-15 00:07:22,380] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-15 00:07:22,746] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-15 00:07:22,876] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-15 00:07:22,943] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-15 00:07:22,947] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-15 00:07:22,953] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:22,964] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-15 00:07:22,998] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-15 00:07:23,041] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-15 00:07:23,047] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-15 00:07:23,079] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-15 00:07:23,083] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-15 00:07:23,091] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:23,104] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-15 00:07:23,190] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-15 00:07:23,196] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-15 00:07:23,204] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:23,217] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-15 00:07:23,221] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-15 00:07:23,227] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:23,262] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-15 00:07:23,266] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-15 00:07:23,273] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:23,278] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-15 00:07:23,282] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-15 00:07:23,289] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:23,291] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-15 00:07:23,334] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-15 00:07:23,338] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-15 00:07:23,345] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:23,655] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-15 00:07:23,662] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-15 00:07:23,672] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:27,578] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:07:27,675] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:07:27,727] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:07:27,743] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:07:27,832] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:07:27,875] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:07:28,018] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:07:28,144] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-15 00:07:29,285] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:07:29,328] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:07:29,331] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:07:29,332] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:07:29,381] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:07:29,394] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:07:29,412] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:07:29,422] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:07:29,426] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:07:29,426] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:07:29,435] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:07:29,439] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:07:29,440] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:07:29,455] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:07:29,458] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:07:29,459] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:07:29,512] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:07:29,522] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:07:29,554] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:07:29,558] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:07:29,558] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:07:29,563] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:07:29,567] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:07:29,568] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:07:29,679] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:07:29,721] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:07:29,725] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:07:29,725] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:07:29,796] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-15 00:07:29,826] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-15 00:07:29,838] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-15 00:07:29,841] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-15 00:07:29,842] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-15 00:07:29,904] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-15 00:07:29,922] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-15 00:07:29,944] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-15 00:07:30,049] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-15 00:07:30,053] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-15 00:07:30,212] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-15 00:07:30,343] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-15 00:07:31,359] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-15 00:07:31,432] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-15 00:07:31,450] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-15 00:07:31,511] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-15 00:07:31,619] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-15 00:07:31,626] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-15 00:07:31,802] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-15 00:07:31,935] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-15 00:07:32,883] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-15 00:07:32,923] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-15 00:07:32,982] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-15 00:07:33,017] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-15 00:07:33,092] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-15 00:07:33,154] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-15 00:07:33,289] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-15 00:07:33,439] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-15 00:07:34,397] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-15 00:07:34,443] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-15 00:07:34,544] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-15 00:07:34,629] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-15 00:07:34,715] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-15 00:07:34,718] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-15 00:07:34,885] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-15 00:07:34,989] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-15 00:07:36,054] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-15 00:07:36,143] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-15 00:07:36,181] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-15 00:07:36,261] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-15 00:07:36,353] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-15 00:07:36,364] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-15 00:07:36,480] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-15 00:07:36,637] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-15 00:07:37,013] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-15 00:07:37,103] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-15 00:07:37,130] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-15 00:07:37,219] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-15 00:07:37,310] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-15 00:07:37,316] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-15 00:07:37,437] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-15 00:07:37,594] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-15 00:07:38,410] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-15 00:07:38,506] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-15 00:07:38,508] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-15 00:07:38,610] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-15 00:07:38,691] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-15 00:07:38,758] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-15 00:07:38,821] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-15 00:07:38,999] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-15 00:07:41,113] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-15 00:07:41,210] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-15 00:07:41,226] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-15 00:07:41,346] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-15 00:07:41,374] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-15 00:07:41,379] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-15 00:07:41,384] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:41,395] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-15 00:07:41,429] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-15 00:07:41,433] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-15 00:07:41,439] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:41,446] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-15 00:07:41,451] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-15 00:07:41,456] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:41,471] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-15 00:07:41,545] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-15 00:07:41,550] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-15 00:07:41,554] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-15 00:07:41,555] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:41,625] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-15 00:07:41,631] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-15 00:07:41,636] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:41,672] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-15 00:07:41,676] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-15 00:07:41,682] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:41,690] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-15 00:07:41,769] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-15 00:07:41,774] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-15 00:07:41,779] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-15 00:07:41,889] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-15 00:07:41,894] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-15 00:07:41,899] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0915 00:07:42.683649 139684108298048 submission_runner.py:376] Time since start: 255.71s, 	Step: 1, 	{'train/accuracy': 0.0026171875, 'train/loss': 6.90775634765625, 'validation/accuracy': 0.0024, 'validation/loss': 6.907755625, 'validation/num_examples': 50000, 'test/accuracy': 0.002, 'test/loss': 6.90775546875, 'test/num_examples': 10000, 'score': 65.70964407920837, 'total_duration': 255.70850658416748, 'accumulated_submission_time': 65.70964407920837, 'accumulated_eval_time': 189.55266499519348, 'accumulated_logging_time': 0}
I0915 00:07:42.703745 139649854994176 logging_writer.py:48] [1] accumulated_eval_time=189.552665, accumulated_logging_time=0, accumulated_submission_time=65.709644, global_step=1, preemption_count=0, score=65.709644, test/accuracy=0.002000, test/loss=6.907755, test/num_examples=10000, total_duration=255.708507, train/accuracy=0.002617, train/loss=6.907756, validation/accuracy=0.002400, validation/loss=6.907756, validation/num_examples=50000
I0915 00:07:43.396368 139751877015360 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0915 00:07:43.396355 140079640172352 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0915 00:07:43.396399 140585831905088 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0915 00:07:43.396375 139684108298048 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0915 00:07:43.396415 139637226022720 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0915 00:07:43.396373 140072611149632 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0915 00:07:43.396445 140101857412928 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0915 00:07:43.396437 140115095766848 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0915 00:07:44.038416 139649846601472 logging_writer.py:48] [1] global_step=1, grad_norm=0.372968, loss=6.907756
I0915 00:07:44.042185 139684108298048 pytorch_submission_base.py:86] 1) loss = 6.908, grad_norm = 0.373
I0915 00:07:44.506477 139649854994176 logging_writer.py:48] [2] global_step=2, grad_norm=0.384498, loss=6.907755
I0915 00:07:44.510671 139684108298048 pytorch_submission_base.py:86] 2) loss = 6.908, grad_norm = 0.384
I0915 00:07:44.909533 139649846601472 logging_writer.py:48] [3] global_step=3, grad_norm=0.376419, loss=6.907752
I0915 00:07:44.913573 139684108298048 pytorch_submission_base.py:86] 3) loss = 6.908, grad_norm = 0.376
I0915 00:07:45.311026 139649854994176 logging_writer.py:48] [4] global_step=4, grad_norm=0.370554, loss=6.907752
I0915 00:07:45.316214 139684108298048 pytorch_submission_base.py:86] 4) loss = 6.908, grad_norm = 0.371
I0915 00:07:45.728142 139649846601472 logging_writer.py:48] [5] global_step=5, grad_norm=0.380121, loss=6.907754
I0915 00:07:45.732227 139684108298048 pytorch_submission_base.py:86] 5) loss = 6.908, grad_norm = 0.380
I0915 00:07:46.140306 139649854994176 logging_writer.py:48] [6] global_step=6, grad_norm=0.379347, loss=6.907744
I0915 00:07:46.144927 139684108298048 pytorch_submission_base.py:86] 6) loss = 6.908, grad_norm = 0.379
I0915 00:07:46.552293 139649846601472 logging_writer.py:48] [7] global_step=7, grad_norm=0.374206, loss=6.907746
I0915 00:07:46.556265 139684108298048 pytorch_submission_base.py:86] 7) loss = 6.908, grad_norm = 0.374
I0915 00:07:46.986021 139649854994176 logging_writer.py:48] [8] global_step=8, grad_norm=0.387228, loss=6.907737
I0915 00:07:46.996412 139684108298048 pytorch_submission_base.py:86] 8) loss = 6.908, grad_norm = 0.387
I0915 00:07:47.413713 139649846601472 logging_writer.py:48] [9] global_step=9, grad_norm=0.383799, loss=6.907742
I0915 00:07:47.418579 139684108298048 pytorch_submission_base.py:86] 9) loss = 6.908, grad_norm = 0.384
I0915 00:07:47.825800 139649854994176 logging_writer.py:48] [10] global_step=10, grad_norm=0.381910, loss=6.907738
I0915 00:07:47.831215 139684108298048 pytorch_submission_base.py:86] 10) loss = 6.908, grad_norm = 0.382
I0915 00:07:48.252644 139649846601472 logging_writer.py:48] [11] global_step=11, grad_norm=0.382524, loss=6.907727
I0915 00:07:48.256760 139684108298048 pytorch_submission_base.py:86] 11) loss = 6.908, grad_norm = 0.383
I0915 00:07:48.660438 139649854994176 logging_writer.py:48] [12] global_step=12, grad_norm=0.374163, loss=6.907727
I0915 00:07:48.665066 139684108298048 pytorch_submission_base.py:86] 12) loss = 6.908, grad_norm = 0.374
I0915 00:07:49.069873 139649846601472 logging_writer.py:48] [13] global_step=13, grad_norm=0.380325, loss=6.907717
I0915 00:07:49.073903 139684108298048 pytorch_submission_base.py:86] 13) loss = 6.908, grad_norm = 0.380
I0915 00:07:49.492720 139649854994176 logging_writer.py:48] [14] global_step=14, grad_norm=0.386015, loss=6.907723
I0915 00:07:49.497803 139684108298048 pytorch_submission_base.py:86] 14) loss = 6.908, grad_norm = 0.386
I0915 00:07:49.919425 139649846601472 logging_writer.py:48] [15] global_step=15, grad_norm=0.367708, loss=6.907715
I0915 00:07:49.923678 139684108298048 pytorch_submission_base.py:86] 15) loss = 6.908, grad_norm = 0.368
I0915 00:07:50.386992 139649854994176 logging_writer.py:48] [16] global_step=16, grad_norm=0.372752, loss=6.907706
I0915 00:07:50.392123 139684108298048 pytorch_submission_base.py:86] 16) loss = 6.908, grad_norm = 0.373
I0915 00:07:50.795629 139649846601472 logging_writer.py:48] [17] global_step=17, grad_norm=0.376724, loss=6.907695
I0915 00:07:50.800308 139684108298048 pytorch_submission_base.py:86] 17) loss = 6.908, grad_norm = 0.377
I0915 00:07:51.206392 139649854994176 logging_writer.py:48] [18] global_step=18, grad_norm=0.383420, loss=6.907671
I0915 00:07:51.210728 139684108298048 pytorch_submission_base.py:86] 18) loss = 6.908, grad_norm = 0.383
I0915 00:07:51.645410 139649846601472 logging_writer.py:48] [19] global_step=19, grad_norm=0.374610, loss=6.907667
I0915 00:07:51.651051 139684108298048 pytorch_submission_base.py:86] 19) loss = 6.908, grad_norm = 0.375
I0915 00:07:52.055143 139649854994176 logging_writer.py:48] [20] global_step=20, grad_norm=0.386401, loss=6.907640
I0915 00:07:52.060840 139684108298048 pytorch_submission_base.py:86] 20) loss = 6.908, grad_norm = 0.386
I0915 00:07:52.463694 139649846601472 logging_writer.py:48] [21] global_step=21, grad_norm=0.374365, loss=6.907633
I0915 00:07:52.467819 139684108298048 pytorch_submission_base.py:86] 21) loss = 6.908, grad_norm = 0.374
I0915 00:07:52.873100 139649854994176 logging_writer.py:48] [22] global_step=22, grad_norm=0.392207, loss=6.907593
I0915 00:07:52.877051 139684108298048 pytorch_submission_base.py:86] 22) loss = 6.908, grad_norm = 0.392
I0915 00:07:53.287339 139649846601472 logging_writer.py:48] [23] global_step=23, grad_norm=0.378741, loss=6.907605
I0915 00:07:53.291430 139684108298048 pytorch_submission_base.py:86] 23) loss = 6.908, grad_norm = 0.379
I0915 00:07:53.704493 139649854994176 logging_writer.py:48] [24] global_step=24, grad_norm=0.377570, loss=6.907564
I0915 00:07:53.709873 139684108298048 pytorch_submission_base.py:86] 24) loss = 6.908, grad_norm = 0.378
I0915 00:07:54.113238 139649846601472 logging_writer.py:48] [25] global_step=25, grad_norm=0.366479, loss=6.907584
I0915 00:07:54.121902 139684108298048 pytorch_submission_base.py:86] 25) loss = 6.908, grad_norm = 0.366
I0915 00:07:54.527828 139649854994176 logging_writer.py:48] [26] global_step=26, grad_norm=0.384663, loss=6.907560
I0915 00:07:54.533333 139684108298048 pytorch_submission_base.py:86] 26) loss = 6.908, grad_norm = 0.385
I0915 00:07:54.944489 139649846601472 logging_writer.py:48] [27] global_step=27, grad_norm=0.364019, loss=6.907556
I0915 00:07:54.949667 139684108298048 pytorch_submission_base.py:86] 27) loss = 6.908, grad_norm = 0.364
I0915 00:07:55.355810 139649854994176 logging_writer.py:48] [28] global_step=28, grad_norm=0.391099, loss=6.907491
I0915 00:07:55.361096 139684108298048 pytorch_submission_base.py:86] 28) loss = 6.907, grad_norm = 0.391
I0915 00:07:55.797566 139649846601472 logging_writer.py:48] [29] global_step=29, grad_norm=0.386253, loss=6.907578
I0915 00:07:55.802885 139684108298048 pytorch_submission_base.py:86] 29) loss = 6.908, grad_norm = 0.386
I0915 00:07:56.204747 139649854994176 logging_writer.py:48] [30] global_step=30, grad_norm=0.387968, loss=6.907388
I0915 00:07:56.209463 139684108298048 pytorch_submission_base.py:86] 30) loss = 6.907, grad_norm = 0.388
I0915 00:07:56.615687 139649846601472 logging_writer.py:48] [31] global_step=31, grad_norm=0.382851, loss=6.907490
I0915 00:07:56.622182 139684108298048 pytorch_submission_base.py:86] 31) loss = 6.907, grad_norm = 0.383
I0915 00:07:57.031098 139649854994176 logging_writer.py:48] [32] global_step=32, grad_norm=0.367406, loss=6.907578
I0915 00:07:57.038901 139684108298048 pytorch_submission_base.py:86] 32) loss = 6.908, grad_norm = 0.367
I0915 00:07:57.449636 139649846601472 logging_writer.py:48] [33] global_step=33, grad_norm=0.396923, loss=6.907330
I0915 00:07:57.454728 139684108298048 pytorch_submission_base.py:86] 33) loss = 6.907, grad_norm = 0.397
I0915 00:07:57.875560 139649854994176 logging_writer.py:48] [34] global_step=34, grad_norm=0.398467, loss=6.907326
I0915 00:07:57.880673 139684108298048 pytorch_submission_base.py:86] 34) loss = 6.907, grad_norm = 0.398
I0915 00:07:58.283828 139649846601472 logging_writer.py:48] [35] global_step=35, grad_norm=0.382403, loss=6.907421
I0915 00:07:58.293334 139684108298048 pytorch_submission_base.py:86] 35) loss = 6.907, grad_norm = 0.382
I0915 00:07:58.712509 139649854994176 logging_writer.py:48] [36] global_step=36, grad_norm=0.400974, loss=6.907163
I0915 00:07:58.717559 139684108298048 pytorch_submission_base.py:86] 36) loss = 6.907, grad_norm = 0.401
I0915 00:07:59.123652 139649846601472 logging_writer.py:48] [37] global_step=37, grad_norm=0.389348, loss=6.907322
I0915 00:07:59.128983 139684108298048 pytorch_submission_base.py:86] 37) loss = 6.907, grad_norm = 0.389
I0915 00:07:59.536136 139649854994176 logging_writer.py:48] [38] global_step=38, grad_norm=0.394842, loss=6.907218
I0915 00:07:59.544009 139684108298048 pytorch_submission_base.py:86] 38) loss = 6.907, grad_norm = 0.395
I0915 00:07:59.947526 139649846601472 logging_writer.py:48] [39] global_step=39, grad_norm=0.387871, loss=6.907250
I0915 00:07:59.953032 139684108298048 pytorch_submission_base.py:86] 39) loss = 6.907, grad_norm = 0.388
I0915 00:08:00.354484 139649854994176 logging_writer.py:48] [40] global_step=40, grad_norm=0.413236, loss=6.907101
I0915 00:08:00.359666 139684108298048 pytorch_submission_base.py:86] 40) loss = 6.907, grad_norm = 0.413
I0915 00:08:00.765176 139649846601472 logging_writer.py:48] [41] global_step=41, grad_norm=0.397259, loss=6.907070
I0915 00:08:00.769925 139684108298048 pytorch_submission_base.py:86] 41) loss = 6.907, grad_norm = 0.397
I0915 00:08:01.178359 139649854994176 logging_writer.py:48] [42] global_step=42, grad_norm=0.383130, loss=6.907121
I0915 00:08:01.185080 139684108298048 pytorch_submission_base.py:86] 42) loss = 6.907, grad_norm = 0.383
I0915 00:08:01.591765 139649846601472 logging_writer.py:48] [43] global_step=43, grad_norm=0.410269, loss=6.907159
I0915 00:08:01.596387 139684108298048 pytorch_submission_base.py:86] 43) loss = 6.907, grad_norm = 0.410
I0915 00:08:02.004272 139649854994176 logging_writer.py:48] [44] global_step=44, grad_norm=0.402800, loss=6.906926
I0915 00:08:02.008522 139684108298048 pytorch_submission_base.py:86] 44) loss = 6.907, grad_norm = 0.403
I0915 00:08:02.427889 139649846601472 logging_writer.py:48] [45] global_step=45, grad_norm=0.395548, loss=6.906912
I0915 00:08:02.432204 139684108298048 pytorch_submission_base.py:86] 45) loss = 6.907, grad_norm = 0.396
I0915 00:08:02.856037 139649854994176 logging_writer.py:48] [46] global_step=46, grad_norm=0.396530, loss=6.906810
I0915 00:08:02.860825 139684108298048 pytorch_submission_base.py:86] 46) loss = 6.907, grad_norm = 0.397
I0915 00:08:03.277058 139649846601472 logging_writer.py:48] [47] global_step=47, grad_norm=0.398120, loss=6.906731
I0915 00:08:03.282200 139684108298048 pytorch_submission_base.py:86] 47) loss = 6.907, grad_norm = 0.398
I0915 00:08:03.686899 139649854994176 logging_writer.py:48] [48] global_step=48, grad_norm=0.412825, loss=6.906471
I0915 00:08:03.691863 139684108298048 pytorch_submission_base.py:86] 48) loss = 6.906, grad_norm = 0.413
I0915 00:08:04.094039 139649846601472 logging_writer.py:48] [49] global_step=49, grad_norm=0.409432, loss=6.906780
I0915 00:08:04.099473 139684108298048 pytorch_submission_base.py:86] 49) loss = 6.907, grad_norm = 0.409
I0915 00:08:04.512122 139649854994176 logging_writer.py:48] [50] global_step=50, grad_norm=0.413627, loss=6.906655
I0915 00:08:04.517220 139684108298048 pytorch_submission_base.py:86] 50) loss = 6.907, grad_norm = 0.414
I0915 00:08:04.920977 139649846601472 logging_writer.py:48] [51] global_step=51, grad_norm=0.406921, loss=6.906555
I0915 00:08:04.925416 139684108298048 pytorch_submission_base.py:86] 51) loss = 6.907, grad_norm = 0.407
I0915 00:08:05.343772 139649854994176 logging_writer.py:48] [52] global_step=52, grad_norm=0.399201, loss=6.906285
I0915 00:08:05.348432 139684108298048 pytorch_submission_base.py:86] 52) loss = 6.906, grad_norm = 0.399
I0915 00:08:05.752746 139649846601472 logging_writer.py:48] [53] global_step=53, grad_norm=0.409458, loss=6.906120
I0915 00:08:05.757908 139684108298048 pytorch_submission_base.py:86] 53) loss = 6.906, grad_norm = 0.409
I0915 00:08:06.179054 139649854994176 logging_writer.py:48] [54] global_step=54, grad_norm=0.431199, loss=6.906256
I0915 00:08:06.184174 139684108298048 pytorch_submission_base.py:86] 54) loss = 6.906, grad_norm = 0.431
I0915 00:08:06.604336 139649846601472 logging_writer.py:48] [55] global_step=55, grad_norm=0.421385, loss=6.906102
I0915 00:08:06.608575 139684108298048 pytorch_submission_base.py:86] 55) loss = 6.906, grad_norm = 0.421
I0915 00:08:07.011285 139649854994176 logging_writer.py:48] [56] global_step=56, grad_norm=0.412517, loss=6.906093
I0915 00:08:07.019529 139684108298048 pytorch_submission_base.py:86] 56) loss = 6.906, grad_norm = 0.413
I0915 00:08:07.439359 139649846601472 logging_writer.py:48] [57] global_step=57, grad_norm=0.413697, loss=6.905994
I0915 00:08:07.443655 139684108298048 pytorch_submission_base.py:86] 57) loss = 6.906, grad_norm = 0.414
I0915 00:08:07.870609 139649854994176 logging_writer.py:48] [58] global_step=58, grad_norm=0.416829, loss=6.905948
I0915 00:08:07.876080 139684108298048 pytorch_submission_base.py:86] 58) loss = 6.906, grad_norm = 0.417
I0915 00:08:08.293112 139649846601472 logging_writer.py:48] [59] global_step=59, grad_norm=0.433683, loss=6.905708
I0915 00:08:08.299060 139684108298048 pytorch_submission_base.py:86] 59) loss = 6.906, grad_norm = 0.434
I0915 00:08:08.725687 139649854994176 logging_writer.py:48] [60] global_step=60, grad_norm=0.429424, loss=6.905665
I0915 00:08:08.729909 139684108298048 pytorch_submission_base.py:86] 60) loss = 6.906, grad_norm = 0.429
I0915 00:08:09.137240 139649846601472 logging_writer.py:48] [61] global_step=61, grad_norm=0.427852, loss=6.905634
I0915 00:08:09.142612 139684108298048 pytorch_submission_base.py:86] 61) loss = 6.906, grad_norm = 0.428
I0915 00:08:09.547961 139649854994176 logging_writer.py:48] [62] global_step=62, grad_norm=0.429050, loss=6.905372
I0915 00:08:09.553055 139684108298048 pytorch_submission_base.py:86] 62) loss = 6.905, grad_norm = 0.429
I0915 00:08:09.964476 139649846601472 logging_writer.py:48] [63] global_step=63, grad_norm=0.429442, loss=6.904984
I0915 00:08:09.970120 139684108298048 pytorch_submission_base.py:86] 63) loss = 6.905, grad_norm = 0.429
I0915 00:08:10.377032 139649854994176 logging_writer.py:48] [64] global_step=64, grad_norm=0.433901, loss=6.905063
I0915 00:08:10.382752 139684108298048 pytorch_submission_base.py:86] 64) loss = 6.905, grad_norm = 0.434
I0915 00:08:10.789085 139649846601472 logging_writer.py:48] [65] global_step=65, grad_norm=0.446675, loss=6.905067
I0915 00:08:10.794777 139684108298048 pytorch_submission_base.py:86] 65) loss = 6.905, grad_norm = 0.447
I0915 00:08:11.209325 139649854994176 logging_writer.py:48] [66] global_step=66, grad_norm=0.430462, loss=6.904789
I0915 00:08:11.214618 139684108298048 pytorch_submission_base.py:86] 66) loss = 6.905, grad_norm = 0.430
I0915 00:08:11.637404 139649846601472 logging_writer.py:48] [67] global_step=67, grad_norm=0.445575, loss=6.904283
I0915 00:08:11.641812 139684108298048 pytorch_submission_base.py:86] 67) loss = 6.904, grad_norm = 0.446
I0915 00:08:12.074361 139649854994176 logging_writer.py:48] [68] global_step=68, grad_norm=0.442447, loss=6.904696
I0915 00:08:12.079434 139684108298048 pytorch_submission_base.py:86] 68) loss = 6.905, grad_norm = 0.442
I0915 00:08:12.506718 139649846601472 logging_writer.py:48] [69] global_step=69, grad_norm=0.427312, loss=6.904677
I0915 00:08:12.514064 139684108298048 pytorch_submission_base.py:86] 69) loss = 6.905, grad_norm = 0.427
I0915 00:08:12.921534 139649854994176 logging_writer.py:48] [70] global_step=70, grad_norm=0.448246, loss=6.903946
I0915 00:08:12.926815 139684108298048 pytorch_submission_base.py:86] 70) loss = 6.904, grad_norm = 0.448
I0915 00:08:13.347489 139649846601472 logging_writer.py:48] [71] global_step=71, grad_norm=0.452448, loss=6.904062
I0915 00:08:13.352652 139684108298048 pytorch_submission_base.py:86] 71) loss = 6.904, grad_norm = 0.452
I0915 00:08:13.762588 139649854994176 logging_writer.py:48] [72] global_step=72, grad_norm=0.446513, loss=6.904388
I0915 00:08:13.766816 139684108298048 pytorch_submission_base.py:86] 72) loss = 6.904, grad_norm = 0.447
I0915 00:08:14.184071 139649846601472 logging_writer.py:48] [73] global_step=73, grad_norm=0.459363, loss=6.903309
I0915 00:08:14.190518 139684108298048 pytorch_submission_base.py:86] 73) loss = 6.903, grad_norm = 0.459
I0915 00:08:14.595433 139649854994176 logging_writer.py:48] [74] global_step=74, grad_norm=0.468873, loss=6.903288
I0915 00:08:14.599748 139684108298048 pytorch_submission_base.py:86] 74) loss = 6.903, grad_norm = 0.469
I0915 00:08:15.025807 139649846601472 logging_writer.py:48] [75] global_step=75, grad_norm=0.458420, loss=6.902567
I0915 00:08:15.035004 139684108298048 pytorch_submission_base.py:86] 75) loss = 6.903, grad_norm = 0.458
I0915 00:08:15.457412 139649854994176 logging_writer.py:48] [76] global_step=76, grad_norm=0.475126, loss=6.903104
I0915 00:08:15.462915 139684108298048 pytorch_submission_base.py:86] 76) loss = 6.903, grad_norm = 0.475
I0915 00:08:15.864396 139649846601472 logging_writer.py:48] [77] global_step=77, grad_norm=0.444886, loss=6.903771
I0915 00:08:15.869111 139684108298048 pytorch_submission_base.py:86] 77) loss = 6.904, grad_norm = 0.445
I0915 00:08:16.272587 139649854994176 logging_writer.py:48] [78] global_step=78, grad_norm=0.451532, loss=6.903320
I0915 00:08:16.278924 139684108298048 pytorch_submission_base.py:86] 78) loss = 6.903, grad_norm = 0.452
I0915 00:08:16.691058 139649846601472 logging_writer.py:48] [79] global_step=79, grad_norm=0.443696, loss=6.904297
I0915 00:08:16.694929 139684108298048 pytorch_submission_base.py:86] 79) loss = 6.904, grad_norm = 0.444
I0915 00:08:17.109508 139649854994176 logging_writer.py:48] [80] global_step=80, grad_norm=0.444794, loss=6.903865
I0915 00:08:17.113818 139684108298048 pytorch_submission_base.py:86] 80) loss = 6.904, grad_norm = 0.445
I0915 00:08:17.540237 139649846601472 logging_writer.py:48] [81] global_step=81, grad_norm=0.455337, loss=6.903108
I0915 00:08:17.544305 139684108298048 pytorch_submission_base.py:86] 81) loss = 6.903, grad_norm = 0.455
I0915 00:08:17.950874 139649854994176 logging_writer.py:48] [82] global_step=82, grad_norm=0.455915, loss=6.902470
I0915 00:08:17.956277 139684108298048 pytorch_submission_base.py:86] 82) loss = 6.902, grad_norm = 0.456
I0915 00:08:18.364972 139649846601472 logging_writer.py:48] [83] global_step=83, grad_norm=0.486245, loss=6.901887
I0915 00:08:18.370819 139684108298048 pytorch_submission_base.py:86] 83) loss = 6.902, grad_norm = 0.486
I0915 00:08:18.777353 139649854994176 logging_writer.py:48] [84] global_step=84, grad_norm=0.504798, loss=6.901399
I0915 00:08:18.782794 139684108298048 pytorch_submission_base.py:86] 84) loss = 6.901, grad_norm = 0.505
I0915 00:08:19.187281 139649846601472 logging_writer.py:48] [85] global_step=85, grad_norm=0.479974, loss=6.901856
I0915 00:08:19.192322 139684108298048 pytorch_submission_base.py:86] 85) loss = 6.902, grad_norm = 0.480
I0915 00:08:19.610816 139649854994176 logging_writer.py:48] [86] global_step=86, grad_norm=0.481204, loss=6.900541
I0915 00:08:19.616205 139684108298048 pytorch_submission_base.py:86] 86) loss = 6.901, grad_norm = 0.481
I0915 00:08:20.020711 139649846601472 logging_writer.py:48] [87] global_step=87, grad_norm=0.494677, loss=6.900591
I0915 00:08:20.025559 139684108298048 pytorch_submission_base.py:86] 87) loss = 6.901, grad_norm = 0.495
I0915 00:08:20.429360 139649854994176 logging_writer.py:48] [88] global_step=88, grad_norm=0.506846, loss=6.900652
I0915 00:08:20.434076 139684108298048 pytorch_submission_base.py:86] 88) loss = 6.901, grad_norm = 0.507
I0915 00:08:20.839918 139649846601472 logging_writer.py:48] [89] global_step=89, grad_norm=0.504958, loss=6.900287
I0915 00:08:20.845804 139684108298048 pytorch_submission_base.py:86] 89) loss = 6.900, grad_norm = 0.505
I0915 00:08:21.265942 139649854994176 logging_writer.py:48] [90] global_step=90, grad_norm=0.493681, loss=6.899678
I0915 00:08:21.270669 139684108298048 pytorch_submission_base.py:86] 90) loss = 6.900, grad_norm = 0.494
I0915 00:08:21.687537 139649846601472 logging_writer.py:48] [91] global_step=91, grad_norm=0.448483, loss=6.900510
I0915 00:08:21.692216 139684108298048 pytorch_submission_base.py:86] 91) loss = 6.901, grad_norm = 0.448
I0915 00:08:22.111531 139649854994176 logging_writer.py:48] [92] global_step=92, grad_norm=0.477673, loss=6.899993
I0915 00:08:22.116545 139684108298048 pytorch_submission_base.py:86] 92) loss = 6.900, grad_norm = 0.478
I0915 00:08:22.539087 139649846601472 logging_writer.py:48] [93] global_step=93, grad_norm=0.483954, loss=6.900304
I0915 00:08:22.544030 139684108298048 pytorch_submission_base.py:86] 93) loss = 6.900, grad_norm = 0.484
I0915 00:08:22.950909 139649854994176 logging_writer.py:48] [94] global_step=94, grad_norm=0.469989, loss=6.900093
I0915 00:08:22.954810 139684108298048 pytorch_submission_base.py:86] 94) loss = 6.900, grad_norm = 0.470
I0915 00:08:23.358283 139649846601472 logging_writer.py:48] [95] global_step=95, grad_norm=0.472292, loss=6.899351
I0915 00:08:23.363620 139684108298048 pytorch_submission_base.py:86] 95) loss = 6.899, grad_norm = 0.472
I0915 00:08:23.764581 139649854994176 logging_writer.py:48] [96] global_step=96, grad_norm=0.465902, loss=6.899244
I0915 00:08:23.770033 139684108298048 pytorch_submission_base.py:86] 96) loss = 6.899, grad_norm = 0.466
I0915 00:08:24.188851 139649846601472 logging_writer.py:48] [97] global_step=97, grad_norm=0.493620, loss=6.899084
I0915 00:08:24.194767 139684108298048 pytorch_submission_base.py:86] 97) loss = 6.899, grad_norm = 0.494
I0915 00:08:24.598066 139649854994176 logging_writer.py:48] [98] global_step=98, grad_norm=0.499885, loss=6.897119
I0915 00:08:24.602563 139684108298048 pytorch_submission_base.py:86] 98) loss = 6.897, grad_norm = 0.500
I0915 00:08:25.028448 139649846601472 logging_writer.py:48] [99] global_step=99, grad_norm=0.502592, loss=6.897727
I0915 00:08:25.033781 139684108298048 pytorch_submission_base.py:86] 99) loss = 6.898, grad_norm = 0.503
I0915 00:08:25.453588 139649854994176 logging_writer.py:48] [100] global_step=100, grad_norm=0.490556, loss=6.898773
I0915 00:08:25.459417 139684108298048 pytorch_submission_base.py:86] 100) loss = 6.899, grad_norm = 0.491
I0915 00:11:07.826279 139649846601472 logging_writer.py:48] [500] global_step=500, grad_norm=0.666285, loss=6.709565
I0915 00:11:07.831313 139684108298048 pytorch_submission_base.py:86] 500) loss = 6.710, grad_norm = 0.666
I0915 00:14:30.131477 139649854994176 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.620148, loss=6.388030
I0915 00:14:30.136541 139684108298048 pytorch_submission_base.py:86] 1000) loss = 6.388, grad_norm = 1.620
I0915 00:14:44.163099 139684108298048 spec.py:320] Evaluating on the training split.
I0915 00:15:29.081623 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 00:16:23.001531 139684108298048 spec.py:348] Evaluating on the test split.
I0915 00:16:24.430366 139684108298048 submission_runner.py:376] Time since start: 777.46s, 	Step: 1033, 	{'train/accuracy': 0.02626953125, 'train/loss': 6.08369873046875, 'validation/accuracy': 0.02534, 'validation/loss': 6.108815625, 'validation/num_examples': 50000, 'test/accuracy': 0.0176, 'test/loss': 6.18779921875, 'test/num_examples': 10000, 'score': 484.74924492836, 'total_duration': 777.4552552700043, 'accumulated_submission_time': 484.74924492836, 'accumulated_eval_time': 289.82026290893555, 'accumulated_logging_time': 0.030212879180908203}
I0915 00:16:24.450469 139639855773440 logging_writer.py:48] [1033] accumulated_eval_time=289.820263, accumulated_logging_time=0.030213, accumulated_submission_time=484.749245, global_step=1033, preemption_count=0, score=484.749245, test/accuracy=0.017600, test/loss=6.187799, test/num_examples=10000, total_duration=777.455255, train/accuracy=0.026270, train/loss=6.083699, validation/accuracy=0.025340, validation/loss=6.108816, validation/num_examples=50000
I0915 00:19:37.770361 139640336475904 logging_writer.py:48] [1500] global_step=1500, grad_norm=1.701588, loss=6.147460
I0915 00:19:37.776952 139684108298048 pytorch_submission_base.py:86] 1500) loss = 6.147, grad_norm = 1.702
I0915 00:23:00.641221 139639855773440 logging_writer.py:48] [2000] global_step=2000, grad_norm=1.537005, loss=5.906508
I0915 00:23:00.646789 139684108298048 pytorch_submission_base.py:86] 2000) loss = 5.907, grad_norm = 1.537
I0915 00:23:25.550656 139684108298048 spec.py:320] Evaluating on the training split.
I0915 00:24:07.742137 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 00:24:51.250006 139684108298048 spec.py:348] Evaluating on the test split.
I0915 00:24:52.643237 139684108298048 submission_runner.py:376] Time since start: 1285.67s, 	Step: 2060, 	{'train/accuracy': 0.0691796875, 'train/loss': 5.352781372070313, 'validation/accuracy': 0.06678, 'validation/loss': 5.3990025, 'validation/num_examples': 50000, 'test/accuracy': 0.0514, 'test/loss': 5.591217578125, 'test/num_examples': 10000, 'score': 903.558568239212, 'total_duration': 1285.668110370636, 'accumulated_submission_time': 903.558568239212, 'accumulated_eval_time': 376.9129524230957, 'accumulated_logging_time': 0.06643295288085938}
I0915 00:24:52.659615 139640336475904 logging_writer.py:48] [2060] accumulated_eval_time=376.912952, accumulated_logging_time=0.066433, accumulated_submission_time=903.558568, global_step=2060, preemption_count=0, score=903.558568, test/accuracy=0.051400, test/loss=5.591218, test/num_examples=10000, total_duration=1285.668110, train/accuracy=0.069180, train/loss=5.352781, validation/accuracy=0.066780, validation/loss=5.399002, validation/num_examples=50000
I0915 00:27:51.938079 139639855773440 logging_writer.py:48] [2500] global_step=2500, grad_norm=1.362836, loss=5.923986
I0915 00:27:51.942519 139684108298048 pytorch_submission_base.py:86] 2500) loss = 5.924, grad_norm = 1.363
I0915 00:31:17.061523 139640336475904 logging_writer.py:48] [3000] global_step=3000, grad_norm=1.378988, loss=5.703026
I0915 00:31:17.067721 139684108298048 pytorch_submission_base.py:86] 3000) loss = 5.703, grad_norm = 1.379
I0915 00:31:53.685191 139684108298048 spec.py:320] Evaluating on the training split.
I0915 00:32:36.780431 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 00:33:20.701318 139684108298048 spec.py:348] Evaluating on the test split.
I0915 00:33:22.095123 139684108298048 submission_runner.py:376] Time since start: 1795.12s, 	Step: 3089, 	{'train/accuracy': 0.1134765625, 'train/loss': 4.862177429199218, 'validation/accuracy': 0.10374, 'validation/loss': 4.9325371875, 'validation/num_examples': 50000, 'test/accuracy': 0.077, 'test/loss': 5.242923046875, 'test/num_examples': 10000, 'score': 1322.326075553894, 'total_duration': 1795.1200304031372, 'accumulated_submission_time': 1322.326075553894, 'accumulated_eval_time': 465.32336616516113, 'accumulated_logging_time': 0.09168696403503418}
I0915 00:33:22.116023 139639855773440 logging_writer.py:48] [3089] accumulated_eval_time=465.323366, accumulated_logging_time=0.091687, accumulated_submission_time=1322.326076, global_step=3089, preemption_count=0, score=1322.326076, test/accuracy=0.077000, test/loss=5.242923, test/num_examples=10000, total_duration=1795.120030, train/accuracy=0.113477, train/loss=4.862177, validation/accuracy=0.103740, validation/loss=4.932537, validation/num_examples=50000
I0915 00:36:09.488218 139640336475904 logging_writer.py:48] [3500] global_step=3500, grad_norm=1.534282, loss=5.689037
I0915 00:36:09.493659 139684108298048 pytorch_submission_base.py:86] 3500) loss = 5.689, grad_norm = 1.534
I0915 00:39:34.889908 139639855773440 logging_writer.py:48] [4000] global_step=4000, grad_norm=1.303202, loss=5.587643
I0915 00:39:34.896529 139684108298048 pytorch_submission_base.py:86] 4000) loss = 5.588, grad_norm = 1.303
I0915 00:40:23.461784 139684108298048 spec.py:320] Evaluating on the training split.
I0915 00:41:07.044685 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 00:41:51.534599 139684108298048 spec.py:348] Evaluating on the test split.
I0915 00:41:52.924006 139684108298048 submission_runner.py:376] Time since start: 2305.95s, 	Step: 4118, 	{'train/accuracy': 0.1684765625, 'train/loss': 4.366781616210938, 'validation/accuracy': 0.16056, 'validation/loss': 4.446858125, 'validation/num_examples': 50000, 'test/accuracy': 0.125, 'test/loss': 4.763651171875, 'test/num_examples': 10000, 'score': 1741.4536910057068, 'total_duration': 2305.948929786682, 'accumulated_submission_time': 1741.4536910057068, 'accumulated_eval_time': 554.7858331203461, 'accumulated_logging_time': 0.12237405776977539}
I0915 00:41:52.940222 139640336475904 logging_writer.py:48] [4118] accumulated_eval_time=554.785833, accumulated_logging_time=0.122374, accumulated_submission_time=1741.453691, global_step=4118, preemption_count=0, score=1741.453691, test/accuracy=0.125000, test/loss=4.763651, test/num_examples=10000, total_duration=2305.948930, train/accuracy=0.168477, train/loss=4.366782, validation/accuracy=0.160560, validation/loss=4.446858, validation/num_examples=50000
I0915 00:44:28.997930 139639855773440 logging_writer.py:48] [4500] global_step=4500, grad_norm=1.444276, loss=5.228545
I0915 00:44:29.004242 139684108298048 pytorch_submission_base.py:86] 4500) loss = 5.229, grad_norm = 1.444
I0915 00:47:51.716546 139640336475904 logging_writer.py:48] [5000] global_step=5000, grad_norm=1.293635, loss=5.220033
I0915 00:47:51.721131 139684108298048 pytorch_submission_base.py:86] 5000) loss = 5.220, grad_norm = 1.294
I0915 00:48:54.204411 139684108298048 spec.py:320] Evaluating on the training split.
I0915 00:49:38.638691 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 00:50:24.228087 139684108298048 spec.py:348] Evaluating on the test split.
I0915 00:50:25.618822 139684108298048 submission_runner.py:376] Time since start: 2818.64s, 	Step: 5147, 	{'train/accuracy': 0.22849609375, 'train/loss': 3.8848251342773437, 'validation/accuracy': 0.2131, 'validation/loss': 3.992564375, 'validation/num_examples': 50000, 'test/accuracy': 0.1575, 'test/loss': 4.410009375, 'test/num_examples': 10000, 'score': 2160.4416978359222, 'total_duration': 2818.6436960697174, 'accumulated_submission_time': 2160.4416978359222, 'accumulated_eval_time': 646.2004444599152, 'accumulated_logging_time': 0.1485135555267334}
I0915 00:50:25.635954 139639855773440 logging_writer.py:48] [5147] accumulated_eval_time=646.200444, accumulated_logging_time=0.148514, accumulated_submission_time=2160.441698, global_step=5147, preemption_count=0, score=2160.441698, test/accuracy=0.157500, test/loss=4.410009, test/num_examples=10000, total_duration=2818.643696, train/accuracy=0.228496, train/loss=3.884825, validation/accuracy=0.213100, validation/loss=3.992564, validation/num_examples=50000
I0915 00:52:50.087491 139640336475904 logging_writer.py:48] [5500] global_step=5500, grad_norm=1.112519, loss=5.260155
I0915 00:52:50.093269 139684108298048 pytorch_submission_base.py:86] 5500) loss = 5.260, grad_norm = 1.113
I0915 00:56:12.862464 139639855773440 logging_writer.py:48] [6000] global_step=6000, grad_norm=1.258932, loss=4.985785
I0915 00:56:12.868637 139684108298048 pytorch_submission_base.py:86] 6000) loss = 4.986, grad_norm = 1.259
I0915 00:57:27.005360 139684108298048 spec.py:320] Evaluating on the training split.
I0915 00:58:12.159024 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 00:59:05.389971 139684108298048 spec.py:348] Evaluating on the test split.
I0915 00:59:06.780372 139684108298048 submission_runner.py:376] Time since start: 3339.81s, 	Step: 6181, 	{'train/accuracy': 0.2867578125, 'train/loss': 3.4843060302734377, 'validation/accuracy': 0.26574, 'validation/loss': 3.6052284375, 'validation/num_examples': 50000, 'test/accuracy': 0.2008, 'test/loss': 4.079585546875, 'test/num_examples': 10000, 'score': 2579.516234397888, 'total_duration': 3339.805244207382, 'accumulated_submission_time': 2579.516234397888, 'accumulated_eval_time': 745.97585272789, 'accumulated_logging_time': 0.1744997501373291}
I0915 00:59:06.796714 139640336475904 logging_writer.py:48] [6181] accumulated_eval_time=745.975853, accumulated_logging_time=0.174500, accumulated_submission_time=2579.516234, global_step=6181, preemption_count=0, score=2579.516234, test/accuracy=0.200800, test/loss=4.079586, test/num_examples=10000, total_duration=3339.805244, train/accuracy=0.286758, train/loss=3.484306, validation/accuracy=0.265740, validation/loss=3.605228, validation/num_examples=50000
I0915 01:01:19.264141 139639855773440 logging_writer.py:48] [6500] global_step=6500, grad_norm=1.258659, loss=4.815808
I0915 01:01:19.269225 139684108298048 pytorch_submission_base.py:86] 6500) loss = 4.816, grad_norm = 1.259
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
I0915 01:04:42.255597 139640336475904 logging_writer.py:48] [7000] global_step=7000, grad_norm=1.082073, loss=5.180638
I0915 01:04:42.262839 139684108298048 pytorch_submission_base.py:86] 7000) loss = 5.181, grad_norm = 1.082
I0915 01:06:08.004214 139684108298048 spec.py:320] Evaluating on the training split.
I0915 01:06:51.603719 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 01:07:36.918224 139684108298048 spec.py:348] Evaluating on the test split.
I0915 01:07:38.311584 139684108298048 submission_runner.py:376] Time since start: 3851.34s, 	Step: 7210, 	{'train/accuracy': 0.3319140625, 'train/loss': 3.201805419921875, 'validation/accuracy': 0.3065, 'validation/loss': 3.3465034375, 'validation/num_examples': 50000, 'test/accuracy': 0.2317, 'test/loss': 3.844699609375, 'test/num_examples': 10000, 'score': 2998.426082611084, 'total_duration': 3851.3365049362183, 'accumulated_submission_time': 2998.426082611084, 'accumulated_eval_time': 836.2835268974304, 'accumulated_logging_time': 0.19990110397338867}
I0915 01:07:38.329934 139639855773440 logging_writer.py:48] [7210] accumulated_eval_time=836.283527, accumulated_logging_time=0.199901, accumulated_submission_time=2998.426083, global_step=7210, preemption_count=0, score=2998.426083, test/accuracy=0.231700, test/loss=3.844700, test/num_examples=10000, total_duration=3851.336505, train/accuracy=0.331914, train/loss=3.201805, validation/accuracy=0.306500, validation/loss=3.346503, validation/num_examples=50000
I0915 01:09:37.820108 139640336475904 logging_writer.py:48] [7500] global_step=7500, grad_norm=1.198245, loss=4.452987
I0915 01:09:37.823974 139684108298048 pytorch_submission_base.py:86] 7500) loss = 4.453, grad_norm = 1.198
I0915 01:13:03.304542 139639855773440 logging_writer.py:48] [8000] global_step=8000, grad_norm=1.237252, loss=4.357260
I0915 01:13:03.315271 139684108298048 pytorch_submission_base.py:86] 8000) loss = 4.357, grad_norm = 1.237
I0915 01:14:39.661539 139684108298048 spec.py:320] Evaluating on the training split.
I0915 01:15:24.965771 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 01:16:09.958469 139684108298048 spec.py:348] Evaluating on the test split.
I0915 01:16:11.350338 139684108298048 submission_runner.py:376] Time since start: 4364.38s, 	Step: 8236, 	{'train/accuracy': 0.3818359375, 'train/loss': 2.876129455566406, 'validation/accuracy': 0.3551, 'validation/loss': 3.021036875, 'validation/num_examples': 50000, 'test/accuracy': 0.275, 'test/loss': 3.566540625, 'test/num_examples': 10000, 'score': 3417.463707447052, 'total_duration': 4364.375236272812, 'accumulated_submission_time': 3417.463707447052, 'accumulated_eval_time': 927.9725637435913, 'accumulated_logging_time': 0.22741484642028809}
I0915 01:16:11.369648 139640336475904 logging_writer.py:48] [8236] accumulated_eval_time=927.972564, accumulated_logging_time=0.227415, accumulated_submission_time=3417.463707, global_step=8236, preemption_count=0, score=3417.463707, test/accuracy=0.275000, test/loss=3.566541, test/num_examples=10000, total_duration=4364.375236, train/accuracy=0.381836, train/loss=2.876129, validation/accuracy=0.355100, validation/loss=3.021037, validation/num_examples=50000
I0915 01:17:59.520560 139639855773440 logging_writer.py:48] [8500] global_step=8500, grad_norm=1.289251, loss=3.988185
I0915 01:17:59.526095 139684108298048 pytorch_submission_base.py:86] 8500) loss = 3.988, grad_norm = 1.289
I0915 01:21:24.886402 139640336475904 logging_writer.py:48] [9000] global_step=9000, grad_norm=1.040438, loss=4.346162
I0915 01:21:24.892161 139684108298048 pytorch_submission_base.py:86] 9000) loss = 4.346, grad_norm = 1.040
I0915 01:23:12.475524 139684108298048 spec.py:320] Evaluating on the training split.
I0915 01:23:55.967179 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 01:24:41.075284 139684108298048 spec.py:348] Evaluating on the test split.
I0915 01:24:42.463844 139684108298048 submission_runner.py:376] Time since start: 4875.49s, 	Step: 9263, 	{'train/accuracy': 0.4187109375, 'train/loss': 2.6722613525390626, 'validation/accuracy': 0.38584, 'validation/loss': 2.8444759375, 'validation/num_examples': 50000, 'test/accuracy': 0.2937, 'test/loss': 3.424807421875, 'test/num_examples': 10000, 'score': 3836.348623752594, 'total_duration': 4875.488702297211, 'accumulated_submission_time': 3836.348623752594, 'accumulated_eval_time': 1017.961156129837, 'accumulated_logging_time': 0.25620222091674805}
I0915 01:24:42.480760 139639855773440 logging_writer.py:48] [9263] accumulated_eval_time=1017.961156, accumulated_logging_time=0.256202, accumulated_submission_time=3836.348624, global_step=9263, preemption_count=0, score=3836.348624, test/accuracy=0.293700, test/loss=3.424807, test/num_examples=10000, total_duration=4875.488702, train/accuracy=0.418711, train/loss=2.672261, validation/accuracy=0.385840, validation/loss=2.844476, validation/num_examples=50000
I0915 01:26:19.727609 139640336475904 logging_writer.py:48] [9500] global_step=9500, grad_norm=1.198659, loss=3.944915
I0915 01:26:19.732358 139684108298048 pytorch_submission_base.py:86] 9500) loss = 3.945, grad_norm = 1.199
I0915 01:29:42.930924 139639855773440 logging_writer.py:48] [10000] global_step=10000, grad_norm=1.004041, loss=4.311045
I0915 01:29:42.937715 139684108298048 pytorch_submission_base.py:86] 10000) loss = 4.311, grad_norm = 1.004
I0915 01:31:43.701675 139684108298048 spec.py:320] Evaluating on the training split.
I0915 01:32:27.621524 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 01:33:13.071708 139684108298048 spec.py:348] Evaluating on the test split.
I0915 01:33:14.464152 139684108298048 submission_runner.py:376] Time since start: 5387.49s, 	Step: 10291, 	{'train/accuracy': 0.4486328125, 'train/loss': 2.4993214416503906, 'validation/accuracy': 0.4168, 'validation/loss': 2.6679325, 'validation/num_examples': 50000, 'test/accuracy': 0.3239, 'test/loss': 3.2349083984375, 'test/num_examples': 10000, 'score': 4255.360187530518, 'total_duration': 5387.489059209824, 'accumulated_submission_time': 4255.360187530518, 'accumulated_eval_time': 1108.723829984665, 'accumulated_logging_time': 0.2835521697998047}
I0915 01:33:14.480576 139640336475904 logging_writer.py:48] [10291] accumulated_eval_time=1108.723830, accumulated_logging_time=0.283552, accumulated_submission_time=4255.360188, global_step=10291, preemption_count=0, score=4255.360188, test/accuracy=0.323900, test/loss=3.234908, test/num_examples=10000, total_duration=5387.489059, train/accuracy=0.448633, train/loss=2.499321, validation/accuracy=0.416800, validation/loss=2.667933, validation/num_examples=50000
I0915 01:34:40.441315 139639855773440 logging_writer.py:48] [10500] global_step=10500, grad_norm=1.165652, loss=3.959016
I0915 01:34:40.447697 139684108298048 pytorch_submission_base.py:86] 10500) loss = 3.959, grad_norm = 1.166
I0915 01:38:02.938084 139640336475904 logging_writer.py:48] [11000] global_step=11000, grad_norm=1.075562, loss=4.010961
I0915 01:38:02.945586 139684108298048 pytorch_submission_base.py:86] 11000) loss = 4.011, grad_norm = 1.076
I0915 01:40:15.694836 139684108298048 spec.py:320] Evaluating on the training split.
I0915 01:41:01.992457 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 01:41:46.868842 139684108298048 spec.py:348] Evaluating on the test split.
I0915 01:41:48.256470 139684108298048 submission_runner.py:376] Time since start: 5901.28s, 	Step: 11320, 	{'train/accuracy': 0.47462890625, 'train/loss': 2.3745030212402343, 'validation/accuracy': 0.43826, 'validation/loss': 2.5582146875, 'validation/num_examples': 50000, 'test/accuracy': 0.3468, 'test/loss': 3.12915546875, 'test/num_examples': 10000, 'score': 4674.373912572861, 'total_duration': 5901.281381845474, 'accumulated_submission_time': 4674.373912572861, 'accumulated_eval_time': 1201.2859156131744, 'accumulated_logging_time': 0.30875205993652344}
I0915 01:41:48.276837 139639855773440 logging_writer.py:48] [11320] accumulated_eval_time=1201.285916, accumulated_logging_time=0.308752, accumulated_submission_time=4674.373913, global_step=11320, preemption_count=0, score=4674.373913, test/accuracy=0.346800, test/loss=3.129155, test/num_examples=10000, total_duration=5901.281382, train/accuracy=0.474629, train/loss=2.374503, validation/accuracy=0.438260, validation/loss=2.558215, validation/num_examples=50000
I0915 01:43:02.327253 139640336475904 logging_writer.py:48] [11500] global_step=11500, grad_norm=1.137854, loss=4.081642
I0915 01:43:02.333672 139684108298048 pytorch_submission_base.py:86] 11500) loss = 4.082, grad_norm = 1.138
I0915 01:46:25.179469 139639855773440 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.992396, loss=4.201370
I0915 01:46:25.184554 139684108298048 pytorch_submission_base.py:86] 12000) loss = 4.201, grad_norm = 0.992
I0915 01:48:49.507674 139684108298048 spec.py:320] Evaluating on the training split.
I0915 01:49:33.683487 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 01:50:28.391437 139684108298048 spec.py:348] Evaluating on the test split.
I0915 01:50:29.784259 139684108298048 submission_runner.py:376] Time since start: 6422.81s, 	Step: 12354, 	{'train/accuracy': 0.50400390625, 'train/loss': 2.20080810546875, 'validation/accuracy': 0.46488, 'validation/loss': 2.38894390625, 'validation/num_examples': 50000, 'test/accuracy': 0.3626, 'test/loss': 2.99171875, 'test/num_examples': 10000, 'score': 5093.282171964645, 'total_duration': 6422.80912733078, 'accumulated_submission_time': 5093.282171964645, 'accumulated_eval_time': 1301.562652349472, 'accumulated_logging_time': 0.3387117385864258}
I0915 01:50:29.801110 139640336475904 logging_writer.py:48] [12354] accumulated_eval_time=1301.562652, accumulated_logging_time=0.338712, accumulated_submission_time=5093.282172, global_step=12354, preemption_count=0, score=5093.282172, test/accuracy=0.362600, test/loss=2.991719, test/num_examples=10000, total_duration=6422.809127, train/accuracy=0.504004, train/loss=2.200808, validation/accuracy=0.464880, validation/loss=2.388944, validation/num_examples=50000
I0915 01:51:30.470544 139639855773440 logging_writer.py:48] [12500] global_step=12500, grad_norm=1.037202, loss=3.966503
I0915 01:51:30.475204 139684108298048 pytorch_submission_base.py:86] 12500) loss = 3.967, grad_norm = 1.037
I0915 01:54:56.043698 139640336475904 logging_writer.py:48] [13000] global_step=13000, grad_norm=1.071171, loss=4.293289
I0915 01:54:56.048953 139684108298048 pytorch_submission_base.py:86] 13000) loss = 4.293, grad_norm = 1.071
I0915 01:57:31.094804 139684108298048 spec.py:320] Evaluating on the training split.
I0915 01:58:15.099027 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 01:59:00.457683 139684108298048 spec.py:348] Evaluating on the test split.
I0915 01:59:01.849565 139684108298048 submission_runner.py:376] Time since start: 6934.87s, 	Step: 13381, 	{'train/accuracy': 0.52501953125, 'train/loss': 2.06103759765625, 'validation/accuracy': 0.4867, 'validation/loss': 2.2611503125, 'validation/num_examples': 50000, 'test/accuracy': 0.3789, 'test/loss': 2.883974609375, 'test/num_examples': 10000, 'score': 5512.209890365601, 'total_duration': 6934.87442111969, 'accumulated_submission_time': 5512.209890365601, 'accumulated_eval_time': 1392.3178429603577, 'accumulated_logging_time': 0.364915132522583}
I0915 01:59:01.869465 139639855773440 logging_writer.py:48] [13381] accumulated_eval_time=1392.317843, accumulated_logging_time=0.364915, accumulated_submission_time=5512.209890, global_step=13381, preemption_count=0, score=5512.209890, test/accuracy=0.378900, test/loss=2.883975, test/num_examples=10000, total_duration=6934.874421, train/accuracy=0.525020, train/loss=2.061038, validation/accuracy=0.486700, validation/loss=2.261150, validation/num_examples=50000
I0915 01:59:51.044531 139640336475904 logging_writer.py:48] [13500] global_step=13500, grad_norm=1.143239, loss=3.720469
I0915 01:59:51.050144 139684108298048 pytorch_submission_base.py:86] 13500) loss = 3.720, grad_norm = 1.143
I0915 02:03:17.209774 139639855773440 logging_writer.py:48] [14000] global_step=14000, grad_norm=1.108868, loss=3.793718
I0915 02:03:17.216295 139684108298048 pytorch_submission_base.py:86] 14000) loss = 3.794, grad_norm = 1.109
I0915 02:06:03.299598 139684108298048 spec.py:320] Evaluating on the training split.
I0915 02:06:47.239452 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 02:07:32.500017 139684108298048 spec.py:348] Evaluating on the test split.
I0915 02:07:33.889476 139684108298048 submission_runner.py:376] Time since start: 7446.91s, 	Step: 14407, 	{'train/accuracy': 0.542890625, 'train/loss': 1.9765310668945313, 'validation/accuracy': 0.5012, 'validation/loss': 2.1831240625, 'validation/num_examples': 50000, 'test/accuracy': 0.3947, 'test/loss': 2.80878984375, 'test/num_examples': 10000, 'score': 5931.344927072525, 'total_duration': 7446.914384126663, 'accumulated_submission_time': 5931.344927072525, 'accumulated_eval_time': 1482.9080996513367, 'accumulated_logging_time': 0.3952047824859619}
I0915 02:07:33.910053 139640336475904 logging_writer.py:48] [14407] accumulated_eval_time=1482.908100, accumulated_logging_time=0.395205, accumulated_submission_time=5931.344927, global_step=14407, preemption_count=0, score=5931.344927, test/accuracy=0.394700, test/loss=2.808790, test/num_examples=10000, total_duration=7446.914384, train/accuracy=0.542891, train/loss=1.976531, validation/accuracy=0.501200, validation/loss=2.183124, validation/num_examples=50000
I0915 02:08:12.843064 139639855773440 logging_writer.py:48] [14500] global_step=14500, grad_norm=1.185296, loss=3.538455
I0915 02:08:12.848082 139684108298048 pytorch_submission_base.py:86] 14500) loss = 3.538, grad_norm = 1.185
I0915 02:11:35.666909 139640336475904 logging_writer.py:48] [15000] global_step=15000, grad_norm=1.234209, loss=3.093834
I0915 02:11:35.677491 139684108298048 pytorch_submission_base.py:86] 15000) loss = 3.094, grad_norm = 1.234
I0915 02:14:34.998813 139684108298048 spec.py:320] Evaluating on the training split.
I0915 02:15:18.955858 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 02:16:04.110476 139684108298048 spec.py:348] Evaluating on the test split.
I0915 02:16:05.501295 139684108298048 submission_runner.py:376] Time since start: 7958.53s, 	Step: 15435, 	{'train/accuracy': 0.55765625, 'train/loss': 1.9126416015625, 'validation/accuracy': 0.517, 'validation/loss': 2.12261234375, 'validation/num_examples': 50000, 'test/accuracy': 0.4091, 'test/loss': 2.727919921875, 'test/num_examples': 10000, 'score': 6350.162551641464, 'total_duration': 7958.526209115982, 'accumulated_submission_time': 6350.162551641464, 'accumulated_eval_time': 1573.4109802246094, 'accumulated_logging_time': 0.425351619720459}
I0915 02:16:05.519288 139639855773440 logging_writer.py:48] [15435] accumulated_eval_time=1573.410980, accumulated_logging_time=0.425352, accumulated_submission_time=6350.162552, global_step=15435, preemption_count=0, score=6350.162552, test/accuracy=0.409100, test/loss=2.727920, test/num_examples=10000, total_duration=7958.526209, train/accuracy=0.557656, train/loss=1.912642, validation/accuracy=0.517000, validation/loss=2.122612, validation/num_examples=50000
I0915 02:16:33.219968 139640336475904 logging_writer.py:48] [15500] global_step=15500, grad_norm=1.121636, loss=3.447990
I0915 02:16:33.224905 139684108298048 pytorch_submission_base.py:86] 15500) loss = 3.448, grad_norm = 1.122
I0915 02:19:56.015966 139639855773440 logging_writer.py:48] [16000] global_step=16000, grad_norm=1.073250, loss=3.668366
I0915 02:19:56.023041 139684108298048 pytorch_submission_base.py:86] 16000) loss = 3.668, grad_norm = 1.073
I0915 02:23:06.535643 139684108298048 spec.py:320] Evaluating on the training split.
I0915 02:23:52.591079 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 02:24:38.920744 139684108298048 spec.py:348] Evaluating on the test split.
I0915 02:24:40.314090 139684108298048 submission_runner.py:376] Time since start: 8473.34s, 	Step: 16461, 	{'train/accuracy': 0.57162109375, 'train/loss': 1.82017822265625, 'validation/accuracy': 0.52508, 'validation/loss': 2.03893109375, 'validation/num_examples': 50000, 'test/accuracy': 0.413, 'test/loss': 2.680346875, 'test/num_examples': 10000, 'score': 6768.91895699501, 'total_duration': 8473.338947534561, 'accumulated_submission_time': 6768.91895699501, 'accumulated_eval_time': 1667.1897485256195, 'accumulated_logging_time': 0.4525120258331299}
I0915 02:24:40.333711 139640336475904 logging_writer.py:48] [16461] accumulated_eval_time=1667.189749, accumulated_logging_time=0.452512, accumulated_submission_time=6768.918957, global_step=16461, preemption_count=0, score=6768.918957, test/accuracy=0.413000, test/loss=2.680347, test/num_examples=10000, total_duration=8473.338948, train/accuracy=0.571621, train/loss=1.820178, validation/accuracy=0.525080, validation/loss=2.038931, validation/num_examples=50000
I0915 02:24:57.374889 139639855773440 logging_writer.py:48] [16500] global_step=16500, grad_norm=1.163888, loss=3.131193
I0915 02:24:57.378989 139684108298048 pytorch_submission_base.py:86] 16500) loss = 3.131, grad_norm = 1.164
I0915 02:28:20.163763 139640336475904 logging_writer.py:48] [17000] global_step=17000, grad_norm=1.099143, loss=3.876169
I0915 02:28:20.172484 139684108298048 pytorch_submission_base.py:86] 17000) loss = 3.876, grad_norm = 1.099
I0915 02:31:41.471200 139684108298048 spec.py:320] Evaluating on the training split.
I0915 02:32:26.753655 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 02:33:12.113357 139684108298048 spec.py:348] Evaluating on the test split.
I0915 02:33:13.507951 139684108298048 submission_runner.py:376] Time since start: 8986.53s, 	Step: 17492, 	{'train/accuracy': 0.59095703125, 'train/loss': 1.7585520935058594, 'validation/accuracy': 0.54238, 'validation/loss': 1.982668125, 'validation/num_examples': 50000, 'test/accuracy': 0.4277, 'test/loss': 2.6225697265625, 'test/num_examples': 10000, 'score': 7187.769836425781, 'total_duration': 8986.532859563828, 'accumulated_submission_time': 7187.769836425781, 'accumulated_eval_time': 1759.226996421814, 'accumulated_logging_time': 0.48085522651672363}
I0915 02:33:13.526461 139639855773440 logging_writer.py:48] [17492] accumulated_eval_time=1759.226996, accumulated_logging_time=0.480855, accumulated_submission_time=7187.769836, global_step=17492, preemption_count=0, score=7187.769836, test/accuracy=0.427700, test/loss=2.622570, test/num_examples=10000, total_duration=8986.532860, train/accuracy=0.590957, train/loss=1.758552, validation/accuracy=0.542380, validation/loss=1.982668, validation/num_examples=50000
I0915 02:33:17.971887 139640336475904 logging_writer.py:48] [17500] global_step=17500, grad_norm=1.122005, loss=3.494752
I0915 02:33:17.977217 139684108298048 pytorch_submission_base.py:86] 17500) loss = 3.495, grad_norm = 1.122
I0915 02:36:43.176576 139639855773440 logging_writer.py:48] [18000] global_step=18000, grad_norm=1.159365, loss=3.405874
I0915 02:36:43.181766 139684108298048 pytorch_submission_base.py:86] 18000) loss = 3.406, grad_norm = 1.159
I0915 02:40:06.075204 139640336475904 logging_writer.py:48] [18500] global_step=18500, grad_norm=1.107991, loss=3.741378
I0915 02:40:06.085258 139684108298048 pytorch_submission_base.py:86] 18500) loss = 3.741, grad_norm = 1.108
I0915 02:40:14.933263 139684108298048 spec.py:320] Evaluating on the training split.
I0915 02:40:59.019455 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 02:41:51.783446 139684108298048 spec.py:348] Evaluating on the test split.
I0915 02:41:53.175571 139684108298048 submission_runner.py:376] Time since start: 9506.20s, 	Step: 18520, 	{'train/accuracy': 0.60359375, 'train/loss': 1.67911376953125, 'validation/accuracy': 0.55544, 'validation/loss': 1.9092615625, 'validation/num_examples': 50000, 'test/accuracy': 0.4379, 'test/loss': 2.5372498046875, 'test/num_examples': 10000, 'score': 7606.83567404747, 'total_duration': 9506.200477838516, 'accumulated_submission_time': 7606.83567404747, 'accumulated_eval_time': 1857.4695353507996, 'accumulated_logging_time': 0.5122838020324707}
I0915 02:41:53.194066 139639855773440 logging_writer.py:48] [18520] accumulated_eval_time=1857.469535, accumulated_logging_time=0.512284, accumulated_submission_time=7606.835674, global_step=18520, preemption_count=0, score=7606.835674, test/accuracy=0.437900, test/loss=2.537250, test/num_examples=10000, total_duration=9506.200478, train/accuracy=0.603594, train/loss=1.679114, validation/accuracy=0.555440, validation/loss=1.909262, validation/num_examples=50000
I0915 02:45:11.544028 139640336475904 logging_writer.py:48] [19000] global_step=19000, grad_norm=1.210737, loss=3.270695
I0915 02:45:11.549057 139684108298048 pytorch_submission_base.py:86] 19000) loss = 3.271, grad_norm = 1.211
I0915 02:48:34.827670 139639855773440 logging_writer.py:48] [19500] global_step=19500, grad_norm=1.089725, loss=3.330371
I0915 02:48:34.833862 139684108298048 pytorch_submission_base.py:86] 19500) loss = 3.330, grad_norm = 1.090
I0915 02:48:54.595858 139684108298048 spec.py:320] Evaluating on the training split.
I0915 02:49:39.763709 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 02:50:26.039146 139684108298048 spec.py:348] Evaluating on the test split.
I0915 02:50:27.430837 139684108298048 submission_runner.py:376] Time since start: 10020.46s, 	Step: 19547, 	{'train/accuracy': 0.6109765625, 'train/loss': 1.6482713317871094, 'validation/accuracy': 0.56214, 'validation/loss': 1.881830625, 'validation/num_examples': 50000, 'test/accuracy': 0.4477, 'test/loss': 2.5102265625, 'test/num_examples': 10000, 'score': 8025.950723171234, 'total_duration': 10020.455704689026, 'accumulated_submission_time': 8025.950723171234, 'accumulated_eval_time': 1950.304919242859, 'accumulated_logging_time': 0.5400962829589844}
I0915 02:50:27.450063 139640336475904 logging_writer.py:48] [19547] accumulated_eval_time=1950.304919, accumulated_logging_time=0.540096, accumulated_submission_time=8025.950723, global_step=19547, preemption_count=0, score=8025.950723, test/accuracy=0.447700, test/loss=2.510227, test/num_examples=10000, total_duration=10020.455705, train/accuracy=0.610977, train/loss=1.648271, validation/accuracy=0.562140, validation/loss=1.881831, validation/num_examples=50000
I0915 02:53:33.191560 139639855773440 logging_writer.py:48] [20000] global_step=20000, grad_norm=1.165811, loss=3.110499
I0915 02:53:33.196386 139684108298048 pytorch_submission_base.py:86] 20000) loss = 3.110, grad_norm = 1.166
I0915 02:56:58.670640 139640336475904 logging_writer.py:48] [20500] global_step=20500, grad_norm=1.245356, loss=3.097207
I0915 02:56:58.677220 139684108298048 pytorch_submission_base.py:86] 20500) loss = 3.097, grad_norm = 1.245
I0915 02:57:28.492810 139684108298048 spec.py:320] Evaluating on the training split.
I0915 02:58:12.527468 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 02:58:57.911978 139684108298048 spec.py:348] Evaluating on the test split.
I0915 02:58:59.305316 139684108298048 submission_runner.py:376] Time since start: 10532.33s, 	Step: 20572, 	{'train/accuracy': 0.61626953125, 'train/loss': 1.6307284545898437, 'validation/accuracy': 0.56518, 'validation/loss': 1.87129125, 'validation/num_examples': 50000, 'test/accuracy': 0.4521, 'test/loss': 2.48384140625, 'test/num_examples': 10000, 'score': 8444.716110944748, 'total_duration': 10532.33020234108, 'accumulated_submission_time': 8444.716110944748, 'accumulated_eval_time': 2041.1175422668457, 'accumulated_logging_time': 0.5693168640136719}
I0915 02:58:59.322856 139639855773440 logging_writer.py:48] [20572] accumulated_eval_time=2041.117542, accumulated_logging_time=0.569317, accumulated_submission_time=8444.716111, global_step=20572, preemption_count=0, score=8444.716111, test/accuracy=0.452100, test/loss=2.483841, test/num_examples=10000, total_duration=10532.330202, train/accuracy=0.616270, train/loss=1.630728, validation/accuracy=0.565180, validation/loss=1.871291, validation/num_examples=50000
I0915 03:01:53.990904 139640336475904 logging_writer.py:48] [21000] global_step=21000, grad_norm=1.085170, loss=3.301740
I0915 03:01:53.997889 139684108298048 pytorch_submission_base.py:86] 21000) loss = 3.302, grad_norm = 1.085
I0915 03:05:20.502160 139639855773440 logging_writer.py:48] [21500] global_step=21500, grad_norm=1.164234, loss=3.401654
I0915 03:05:20.508271 139684108298048 pytorch_submission_base.py:86] 21500) loss = 3.402, grad_norm = 1.164
I0915 03:06:00.599975 139684108298048 spec.py:320] Evaluating on the training split.
I0915 03:06:44.835278 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 03:07:29.775128 139684108298048 spec.py:348] Evaluating on the test split.
I0915 03:07:31.167413 139684108298048 submission_runner.py:376] Time since start: 11044.19s, 	Step: 21597, 	{'train/accuracy': 0.6278125, 'train/loss': 1.5581813049316406, 'validation/accuracy': 0.57692, 'validation/loss': 1.7992946875, 'validation/num_examples': 50000, 'test/accuracy': 0.4597, 'test/loss': 2.4328720703125, 'test/num_examples': 10000, 'score': 8863.765577316284, 'total_duration': 11044.192291259766, 'accumulated_submission_time': 8863.765577316284, 'accumulated_eval_time': 2131.685292005539, 'accumulated_logging_time': 0.5963025093078613}
I0915 03:07:31.188408 139640336475904 logging_writer.py:48] [21597] accumulated_eval_time=2131.685292, accumulated_logging_time=0.596303, accumulated_submission_time=8863.765577, global_step=21597, preemption_count=0, score=8863.765577, test/accuracy=0.459700, test/loss=2.432872, test/num_examples=10000, total_duration=11044.192291, train/accuracy=0.627812, train/loss=1.558181, validation/accuracy=0.576920, validation/loss=1.799295, validation/num_examples=50000
I0915 03:10:15.898465 139639855773440 logging_writer.py:48] [22000] global_step=22000, grad_norm=1.165714, loss=3.309144
I0915 03:10:15.902966 139684108298048 pytorch_submission_base.py:86] 22000) loss = 3.309, grad_norm = 1.166
I0915 03:13:38.614001 139640336475904 logging_writer.py:48] [22500] global_step=22500, grad_norm=1.274728, loss=3.363339
I0915 03:13:38.619656 139684108298048 pytorch_submission_base.py:86] 22500) loss = 3.363, grad_norm = 1.275
I0915 03:14:32.568079 139684108298048 spec.py:320] Evaluating on the training split.
I0915 03:15:18.597204 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 03:16:08.332450 139684108298048 spec.py:348] Evaluating on the test split.
I0915 03:16:09.721271 139684108298048 submission_runner.py:376] Time since start: 11562.75s, 	Step: 22626, 	{'train/accuracy': 0.631953125, 'train/loss': 1.5348011779785156, 'validation/accuracy': 0.58222, 'validation/loss': 1.7792, 'validation/num_examples': 50000, 'test/accuracy': 0.4675, 'test/loss': 2.41618671875, 'test/num_examples': 10000, 'score': 9282.886711597443, 'total_duration': 11562.746190071106, 'accumulated_submission_time': 9282.886711597443, 'accumulated_eval_time': 2228.8388845920563, 'accumulated_logging_time': 0.6277039051055908}
I0915 03:16:09.739440 139639855773440 logging_writer.py:48] [22626] accumulated_eval_time=2228.838885, accumulated_logging_time=0.627704, accumulated_submission_time=9282.886712, global_step=22626, preemption_count=0, score=9282.886712, test/accuracy=0.467500, test/loss=2.416187, test/num_examples=10000, total_duration=11562.746190, train/accuracy=0.631953, train/loss=1.534801, validation/accuracy=0.582220, validation/loss=1.779200, validation/num_examples=50000
I0915 03:18:42.827571 139640336475904 logging_writer.py:48] [23000] global_step=23000, grad_norm=1.121168, loss=3.009407
I0915 03:18:42.832165 139684108298048 pytorch_submission_base.py:86] 23000) loss = 3.009, grad_norm = 1.121
I0915 03:22:05.653647 139639855773440 logging_writer.py:48] [23500] global_step=23500, grad_norm=1.111800, loss=3.205717
I0915 03:22:05.659667 139684108298048 pytorch_submission_base.py:86] 23500) loss = 3.206, grad_norm = 1.112
I0915 03:23:10.862167 139684108298048 spec.py:320] Evaluating on the training split.
I0915 03:23:56.207321 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 03:24:42.743401 139684108298048 spec.py:348] Evaluating on the test split.
I0915 03:24:44.131802 139684108298048 submission_runner.py:376] Time since start: 12077.16s, 	Step: 23659, 	{'train/accuracy': 0.6465625, 'train/loss': 1.463553924560547, 'validation/accuracy': 0.59056, 'validation/loss': 1.713401875, 'validation/num_examples': 50000, 'test/accuracy': 0.4776, 'test/loss': 2.3525095703125, 'test/num_examples': 10000, 'score': 9701.763073205948, 'total_duration': 12077.156704187393, 'accumulated_submission_time': 9701.763073205948, 'accumulated_eval_time': 2322.108835697174, 'accumulated_logging_time': 0.6549313068389893}
I0915 03:24:44.150410 139640336475904 logging_writer.py:48] [23659] accumulated_eval_time=2322.108836, accumulated_logging_time=0.654931, accumulated_submission_time=9701.763073, global_step=23659, preemption_count=0, score=9701.763073, test/accuracy=0.477600, test/loss=2.352510, test/num_examples=10000, total_duration=12077.156704, train/accuracy=0.646563, train/loss=1.463554, validation/accuracy=0.590560, validation/loss=1.713402, validation/num_examples=50000
I0915 03:27:06.281385 139639855773440 logging_writer.py:48] [24000] global_step=24000, grad_norm=1.240547, loss=3.550387
I0915 03:27:06.285935 139684108298048 pytorch_submission_base.py:86] 24000) loss = 3.550, grad_norm = 1.241
I0915 03:30:29.499443 139640336475904 logging_writer.py:48] [24500] global_step=24500, grad_norm=1.292354, loss=3.008275
I0915 03:30:29.504814 139684108298048 pytorch_submission_base.py:86] 24500) loss = 3.008, grad_norm = 1.292
I0915 03:31:45.492583 139684108298048 spec.py:320] Evaluating on the training split.
I0915 03:32:29.459890 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 03:33:18.761696 139684108298048 spec.py:348] Evaluating on the test split.
I0915 03:33:20.153812 139684108298048 submission_runner.py:376] Time since start: 12593.18s, 	Step: 24686, 	{'train/accuracy': 0.652421875, 'train/loss': 1.4400218200683594, 'validation/accuracy': 0.59774, 'validation/loss': 1.68804703125, 'validation/num_examples': 50000, 'test/accuracy': 0.4759, 'test/loss': 2.3373685546875, 'test/num_examples': 10000, 'score': 10120.81158041954, 'total_duration': 12593.178675174713, 'accumulated_submission_time': 10120.81158041954, 'accumulated_eval_time': 2416.770309448242, 'accumulated_logging_time': 0.682269811630249}
I0915 03:33:20.172304 139639855773440 logging_writer.py:48] [24686] accumulated_eval_time=2416.770309, accumulated_logging_time=0.682270, accumulated_submission_time=10120.811580, global_step=24686, preemption_count=0, score=10120.811580, test/accuracy=0.475900, test/loss=2.337369, test/num_examples=10000, total_duration=12593.178675, train/accuracy=0.652422, train/loss=1.440022, validation/accuracy=0.597740, validation/loss=1.688047, validation/num_examples=50000
I0915 03:35:29.101156 139640336475904 logging_writer.py:48] [25000] global_step=25000, grad_norm=1.100844, loss=3.758377
I0915 03:35:29.106888 139684108298048 pytorch_submission_base.py:86] 25000) loss = 3.758, grad_norm = 1.101
I0915 03:38:54.778983 139639855773440 logging_writer.py:48] [25500] global_step=25500, grad_norm=1.163874, loss=3.041850
I0915 03:38:54.784957 139684108298048 pytorch_submission_base.py:86] 25500) loss = 3.042, grad_norm = 1.164
I0915 03:40:21.581669 139684108298048 spec.py:320] Evaluating on the training split.
I0915 03:41:06.954276 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 03:41:51.899685 139684108298048 spec.py:348] Evaluating on the test split.
I0915 03:41:53.293798 139684108298048 submission_runner.py:376] Time since start: 13106.32s, 	Step: 25712, 	{'train/accuracy': 0.65755859375, 'train/loss': 1.4183949279785155, 'validation/accuracy': 0.6043, 'validation/loss': 1.6652515625, 'validation/num_examples': 50000, 'test/accuracy': 0.4851, 'test/loss': 2.316401171875, 'test/num_examples': 10000, 'score': 10539.973780155182, 'total_duration': 13106.318683624268, 'accumulated_submission_time': 10539.973780155182, 'accumulated_eval_time': 2508.482878923416, 'accumulated_logging_time': 0.709888219833374}
I0915 03:41:53.311560 139640336475904 logging_writer.py:48] [25712] accumulated_eval_time=2508.482879, accumulated_logging_time=0.709888, accumulated_submission_time=10539.973780, global_step=25712, preemption_count=0, score=10539.973780, test/accuracy=0.485100, test/loss=2.316401, test/num_examples=10000, total_duration=13106.318684, train/accuracy=0.657559, train/loss=1.418395, validation/accuracy=0.604300, validation/loss=1.665252, validation/num_examples=50000
I0915 03:43:51.553884 139639855773440 logging_writer.py:48] [26000] global_step=26000, grad_norm=1.285188, loss=2.663409
I0915 03:43:51.559907 139684108298048 pytorch_submission_base.py:86] 26000) loss = 2.663, grad_norm = 1.285
I0915 03:47:17.517969 139640336475904 logging_writer.py:48] [26500] global_step=26500, grad_norm=1.212733, loss=3.189762
I0915 03:47:17.528693 139684108298048 pytorch_submission_base.py:86] 26500) loss = 3.190, grad_norm = 1.213
I0915 03:48:54.550443 139684108298048 spec.py:320] Evaluating on the training split.
I0915 03:49:38.498226 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 03:50:23.819649 139684108298048 spec.py:348] Evaluating on the test split.
I0915 03:50:25.210755 139684108298048 submission_runner.py:376] Time since start: 13618.24s, 	Step: 26737, 	{'train/accuracy': 0.65951171875, 'train/loss': 1.3987852478027343, 'validation/accuracy': 0.60434, 'validation/loss': 1.64842859375, 'validation/num_examples': 50000, 'test/accuracy': 0.4824, 'test/loss': 2.2939185546875, 'test/num_examples': 10000, 'score': 10958.973457813263, 'total_duration': 13618.23564505577, 'accumulated_submission_time': 10958.973457813263, 'accumulated_eval_time': 2599.1434013843536, 'accumulated_logging_time': 0.7385730743408203}
I0915 03:50:25.229582 139639855773440 logging_writer.py:48] [26737] accumulated_eval_time=2599.143401, accumulated_logging_time=0.738573, accumulated_submission_time=10958.973458, global_step=26737, preemption_count=0, score=10958.973458, test/accuracy=0.482400, test/loss=2.293919, test/num_examples=10000, total_duration=13618.235645, train/accuracy=0.659512, train/loss=1.398785, validation/accuracy=0.604340, validation/loss=1.648429, validation/num_examples=50000
I0915 03:52:12.954269 139640336475904 logging_writer.py:48] [27000] global_step=27000, grad_norm=1.323578, loss=3.216933
I0915 03:52:12.960973 139684108298048 pytorch_submission_base.py:86] 27000) loss = 3.217, grad_norm = 1.324
I0915 03:55:36.416281 139639855773440 logging_writer.py:48] [27500] global_step=27500, grad_norm=1.146730, loss=2.717105
I0915 03:55:36.422902 139684108298048 pytorch_submission_base.py:86] 27500) loss = 2.717, grad_norm = 1.147
I0915 03:57:26.475754 139684108298048 spec.py:320] Evaluating on the training split.
I0915 03:58:10.937395 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 03:58:55.872131 139684108298048 spec.py:348] Evaluating on the test split.
I0915 03:58:57.262871 139684108298048 submission_runner.py:376] Time since start: 14130.29s, 	Step: 27764, 	{'train/accuracy': 0.6642578125, 'train/loss': 1.391507110595703, 'validation/accuracy': 0.609, 'validation/loss': 1.64691, 'validation/num_examples': 50000, 'test/accuracy': 0.4861, 'test/loss': 2.2992857421875, 'test/num_examples': 10000, 'score': 11377.977722406387, 'total_duration': 14130.287772655487, 'accumulated_submission_time': 11377.977722406387, 'accumulated_eval_time': 2689.9310009479523, 'accumulated_logging_time': 0.7662363052368164}
I0915 03:58:57.283154 139640336475904 logging_writer.py:48] [27764] accumulated_eval_time=2689.931001, accumulated_logging_time=0.766236, accumulated_submission_time=11377.977722, global_step=27764, preemption_count=0, score=11377.977722, test/accuracy=0.486100, test/loss=2.299286, test/num_examples=10000, total_duration=14130.287773, train/accuracy=0.664258, train/loss=1.391507, validation/accuracy=0.609000, validation/loss=1.646910, validation/num_examples=50000
I0915 04:00:34.307307 139639855773440 logging_writer.py:48] [28000] global_step=28000, grad_norm=1.221648, loss=2.832425
I0915 04:00:34.313033 139684108298048 pytorch_submission_base.py:86] 28000) loss = 2.832, grad_norm = 1.222
I0915 04:03:57.443205 139640336475904 logging_writer.py:48] [28500] global_step=28500, grad_norm=1.241109, loss=3.015490
I0915 04:03:57.450527 139684108298048 pytorch_submission_base.py:86] 28500) loss = 3.015, grad_norm = 1.241
I0915 04:05:58.424365 139684108298048 spec.py:320] Evaluating on the training split.
I0915 04:06:43.876830 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 04:07:32.404063 139684108298048 spec.py:348] Evaluating on the test split.
I0915 04:07:33.795137 139684108298048 submission_runner.py:376] Time since start: 14646.82s, 	Step: 28790, 	{'train/accuracy': 0.6741015625, 'train/loss': 1.3380560302734374, 'validation/accuracy': 0.61936, 'validation/loss': 1.5933046875, 'validation/num_examples': 50000, 'test/accuracy': 0.4959, 'test/loss': 2.231582421875, 'test/num_examples': 10000, 'score': 11796.862185955048, 'total_duration': 14646.820058584213, 'accumulated_submission_time': 11796.862185955048, 'accumulated_eval_time': 2785.302080631256, 'accumulated_logging_time': 0.7985968589782715}
I0915 04:07:33.813870 139639855773440 logging_writer.py:48] [28790] accumulated_eval_time=2785.302081, accumulated_logging_time=0.798597, accumulated_submission_time=11796.862186, global_step=28790, preemption_count=0, score=11796.862186, test/accuracy=0.495900, test/loss=2.231582, test/num_examples=10000, total_duration=14646.820059, train/accuracy=0.674102, train/loss=1.338056, validation/accuracy=0.619360, validation/loss=1.593305, validation/num_examples=50000
I0915 04:09:00.343459 139640336475904 logging_writer.py:48] [29000] global_step=29000, grad_norm=1.332026, loss=2.767322
I0915 04:09:00.349571 139684108298048 pytorch_submission_base.py:86] 29000) loss = 2.767, grad_norm = 1.332
I0915 04:12:23.297700 139639855773440 logging_writer.py:48] [29500] global_step=29500, grad_norm=1.242676, loss=2.829043
I0915 04:12:23.302937 139684108298048 pytorch_submission_base.py:86] 29500) loss = 2.829, grad_norm = 1.243
I0915 04:14:35.168361 139684108298048 spec.py:320] Evaluating on the training split.
I0915 04:15:19.431280 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 04:16:10.436709 139684108298048 spec.py:348] Evaluating on the test split.
I0915 04:16:11.830848 139684108298048 submission_runner.py:376] Time since start: 15164.86s, 	Step: 29822, 	{'train/accuracy': 0.67931640625, 'train/loss': 1.3232623291015626, 'validation/accuracy': 0.62336, 'validation/loss': 1.5767871875, 'validation/num_examples': 50000, 'test/accuracy': 0.5012, 'test/loss': 2.210870703125, 'test/num_examples': 10000, 'score': 12215.971857786179, 'total_duration': 15164.855756521225, 'accumulated_submission_time': 12215.971857786179, 'accumulated_eval_time': 2881.9648518562317, 'accumulated_logging_time': 0.8288023471832275}
I0915 04:16:11.850376 139640336475904 logging_writer.py:48] [29822] accumulated_eval_time=2881.964852, accumulated_logging_time=0.828802, accumulated_submission_time=12215.971858, global_step=29822, preemption_count=0, score=12215.971858, test/accuracy=0.501200, test/loss=2.210871, test/num_examples=10000, total_duration=15164.855757, train/accuracy=0.679316, train/loss=1.323262, validation/accuracy=0.623360, validation/loss=1.576787, validation/num_examples=50000
I0915 04:17:25.802270 139639855773440 logging_writer.py:48] [30000] global_step=30000, grad_norm=1.315105, loss=2.475006
I0915 04:17:25.806870 139684108298048 pytorch_submission_base.py:86] 30000) loss = 2.475, grad_norm = 1.315
I0915 04:20:51.338627 139640336475904 logging_writer.py:48] [30500] global_step=30500, grad_norm=1.179760, loss=2.721152
I0915 04:20:51.343770 139684108298048 pytorch_submission_base.py:86] 30500) loss = 2.721, grad_norm = 1.180
I0915 04:23:13.136146 139684108298048 spec.py:320] Evaluating on the training split.
I0915 04:23:57.189938 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 04:24:42.459029 139684108298048 spec.py:348] Evaluating on the test split.
I0915 04:24:43.851314 139684108298048 submission_runner.py:376] Time since start: 15676.88s, 	Step: 30848, 	{'train/accuracy': 0.68216796875, 'train/loss': 1.3191340637207032, 'validation/accuracy': 0.62474, 'validation/loss': 1.57301953125, 'validation/num_examples': 50000, 'test/accuracy': 0.505, 'test/loss': 2.195338671875, 'test/num_examples': 10000, 'score': 12635.018734931946, 'total_duration': 15676.876236438751, 'accumulated_submission_time': 12635.018734931946, 'accumulated_eval_time': 2972.6803107261658, 'accumulated_logging_time': 0.8579301834106445}
I0915 04:24:43.871622 139639855773440 logging_writer.py:48] [30848] accumulated_eval_time=2972.680311, accumulated_logging_time=0.857930, accumulated_submission_time=12635.018735, global_step=30848, preemption_count=0, score=12635.018735, test/accuracy=0.505000, test/loss=2.195339, test/num_examples=10000, total_duration=15676.876236, train/accuracy=0.682168, train/loss=1.319134, validation/accuracy=0.624740, validation/loss=1.573020, validation/num_examples=50000
I0915 04:25:46.610854 139640336475904 logging_writer.py:48] [31000] global_step=31000, grad_norm=1.268364, loss=2.672430
I0915 04:25:46.616383 139684108298048 pytorch_submission_base.py:86] 31000) loss = 2.672, grad_norm = 1.268
I0915 04:29:12.327772 139639855773440 logging_writer.py:48] [31500] global_step=31500, grad_norm=1.257114, loss=2.798436
I0915 04:29:12.336640 139684108298048 pytorch_submission_base.py:86] 31500) loss = 2.798, grad_norm = 1.257
I0915 04:31:45.022983 139684108298048 spec.py:320] Evaluating on the training split.
I0915 04:32:29.098364 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 04:33:14.138640 139684108298048 spec.py:348] Evaluating on the test split.
I0915 04:33:15.529939 139684108298048 submission_runner.py:376] Time since start: 16188.55s, 	Step: 31874, 	{'train/accuracy': 0.67888671875, 'train/loss': 1.3131819152832032, 'validation/accuracy': 0.62318, 'validation/loss': 1.5704321875, 'validation/num_examples': 50000, 'test/accuracy': 0.5102, 'test/loss': 2.213048046875, 'test/num_examples': 10000, 'score': 13053.914733409882, 'total_duration': 16188.55485868454, 'accumulated_submission_time': 13053.914733409882, 'accumulated_eval_time': 3063.1874573230743, 'accumulated_logging_time': 0.8888599872589111}
I0915 04:33:15.549916 139640336475904 logging_writer.py:48] [31874] accumulated_eval_time=3063.187457, accumulated_logging_time=0.888860, accumulated_submission_time=13053.914733, global_step=31874, preemption_count=0, score=13053.914733, test/accuracy=0.510200, test/loss=2.213048, test/num_examples=10000, total_duration=16188.554859, train/accuracy=0.678887, train/loss=1.313182, validation/accuracy=0.623180, validation/loss=1.570432, validation/num_examples=50000
I0915 04:34:07.810348 139639855773440 logging_writer.py:48] [32000] global_step=32000, grad_norm=1.232121, loss=2.449018
I0915 04:34:07.816043 139684108298048 pytorch_submission_base.py:86] 32000) loss = 2.449, grad_norm = 1.232
I0915 04:37:30.798106 139640336475904 logging_writer.py:48] [32500] global_step=32500, grad_norm=1.209906, loss=3.169011
I0915 04:37:30.804898 139684108298048 pytorch_submission_base.py:86] 32500) loss = 3.169, grad_norm = 1.210
I0915 04:40:16.791754 139684108298048 spec.py:320] Evaluating on the training split.
I0915 04:41:00.760035 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 04:41:46.444224 139684108298048 spec.py:348] Evaluating on the test split.
I0915 04:41:47.835968 139684108298048 submission_runner.py:376] Time since start: 16700.86s, 	Step: 32902, 	{'train/accuracy': 0.69193359375, 'train/loss': 1.2588944244384765, 'validation/accuracy': 0.63584, 'validation/loss': 1.5135659375, 'validation/num_examples': 50000, 'test/accuracy': 0.5122, 'test/loss': 2.15730703125, 'test/num_examples': 10000, 'score': 13472.851302623749, 'total_duration': 16700.860886096954, 'accumulated_submission_time': 13472.851302623749, 'accumulated_eval_time': 3154.231927871704, 'accumulated_logging_time': 0.9182641506195068}
I0915 04:41:47.856555 139639855773440 logging_writer.py:48] [32902] accumulated_eval_time=3154.231928, accumulated_logging_time=0.918264, accumulated_submission_time=13472.851303, global_step=32902, preemption_count=0, score=13472.851303, test/accuracy=0.512200, test/loss=2.157307, test/num_examples=10000, total_duration=16700.860886, train/accuracy=0.691934, train/loss=1.258894, validation/accuracy=0.635840, validation/loss=1.513566, validation/num_examples=50000
I0915 04:42:28.773965 139640336475904 logging_writer.py:48] [33000] global_step=33000, grad_norm=1.388463, loss=2.464131
I0915 04:42:28.780581 139684108298048 pytorch_submission_base.py:86] 33000) loss = 2.464, grad_norm = 1.388
I0915 04:45:51.851096 139639855773440 logging_writer.py:48] [33500] global_step=33500, grad_norm=1.244090, loss=3.275652
I0915 04:45:51.857215 139684108298048 pytorch_submission_base.py:86] 33500) loss = 3.276, grad_norm = 1.244
I0915 04:48:49.075887 139684108298048 spec.py:320] Evaluating on the training split.
I0915 04:49:35.802155 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 04:50:23.460692 139684108298048 spec.py:348] Evaluating on the test split.
I0915 04:50:24.851978 139684108298048 submission_runner.py:376] Time since start: 17217.88s, 	Step: 33927, 	{'train/accuracy': 0.697734375, 'train/loss': 1.2217210388183595, 'validation/accuracy': 0.63848, 'validation/loss': 1.49125875, 'validation/num_examples': 50000, 'test/accuracy': 0.517, 'test/loss': 2.128406640625, 'test/num_examples': 10000, 'score': 13891.836766242981, 'total_duration': 17217.87688279152, 'accumulated_submission_time': 13891.836766242981, 'accumulated_eval_time': 3250.008403778076, 'accumulated_logging_time': 0.9483447074890137}
I0915 04:50:24.871535 139640336475904 logging_writer.py:48] [33927] accumulated_eval_time=3250.008404, accumulated_logging_time=0.948345, accumulated_submission_time=13891.836766, global_step=33927, preemption_count=0, score=13891.836766, test/accuracy=0.517000, test/loss=2.128407, test/num_examples=10000, total_duration=17217.876883, train/accuracy=0.697734, train/loss=1.221721, validation/accuracy=0.638480, validation/loss=1.491259, validation/num_examples=50000
I0915 04:50:55.888501 139639855773440 logging_writer.py:48] [34000] global_step=34000, grad_norm=1.150241, loss=2.661322
I0915 04:50:55.893865 139684108298048 pytorch_submission_base.py:86] 34000) loss = 2.661, grad_norm = 1.150
I0915 04:54:19.055328 139640336475904 logging_writer.py:48] [34500] global_step=34500, grad_norm=1.283905, loss=2.995543
I0915 04:54:19.060826 139684108298048 pytorch_submission_base.py:86] 34500) loss = 2.996, grad_norm = 1.284
I0915 04:57:26.277823 139684108298048 spec.py:320] Evaluating on the training split.
I0915 04:58:11.580767 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 04:58:57.117761 139684108298048 spec.py:348] Evaluating on the test split.
I0915 04:58:58.508162 139684108298048 submission_runner.py:376] Time since start: 17731.53s, 	Step: 34960, 	{'train/accuracy': 0.69525390625, 'train/loss': 1.240261993408203, 'validation/accuracy': 0.63798, 'validation/loss': 1.4990771875, 'validation/num_examples': 50000, 'test/accuracy': 0.5162, 'test/loss': 2.145701171875, 'test/num_examples': 10000, 'score': 14310.932742118835, 'total_duration': 17731.532814741135, 'accumulated_submission_time': 14310.932742118835, 'accumulated_eval_time': 3342.239068031311, 'accumulated_logging_time': 0.9771223068237305}
I0915 04:58:58.527430 139639855773440 logging_writer.py:48] [34960] accumulated_eval_time=3342.239068, accumulated_logging_time=0.977122, accumulated_submission_time=14310.932742, global_step=34960, preemption_count=0, score=14310.932742, test/accuracy=0.516200, test/loss=2.145701, test/num_examples=10000, total_duration=17731.532815, train/accuracy=0.695254, train/loss=1.240262, validation/accuracy=0.637980, validation/loss=1.499077, validation/num_examples=50000
I0915 04:59:15.910551 139640336475904 logging_writer.py:48] [35000] global_step=35000, grad_norm=1.234710, loss=2.680747
I0915 04:59:15.914628 139684108298048 pytorch_submission_base.py:86] 35000) loss = 2.681, grad_norm = 1.235
I0915 05:02:41.599025 139639855773440 logging_writer.py:48] [35500] global_step=35500, grad_norm=1.183864, loss=2.731748
I0915 05:02:41.603887 139684108298048 pytorch_submission_base.py:86] 35500) loss = 2.732, grad_norm = 1.184
I0915 05:05:59.764750 139684108298048 spec.py:320] Evaluating on the training split.
I0915 05:06:43.815866 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 05:07:35.430960 139684108298048 spec.py:348] Evaluating on the test split.
I0915 05:07:36.822983 139684108298048 submission_runner.py:376] Time since start: 18249.85s, 	Step: 35987, 	{'train/accuracy': 0.70171875, 'train/loss': 1.2196855926513672, 'validation/accuracy': 0.64092, 'validation/loss': 1.485736875, 'validation/num_examples': 50000, 'test/accuracy': 0.5168, 'test/loss': 2.136860546875, 'test/num_examples': 10000, 'score': 14729.872365951538, 'total_duration': 18249.847893238068, 'accumulated_submission_time': 14729.872365951538, 'accumulated_eval_time': 3439.2978398799896, 'accumulated_logging_time': 1.00677490234375}
I0915 05:07:36.843983 139640336475904 logging_writer.py:48] [35987] accumulated_eval_time=3439.297840, accumulated_logging_time=1.006775, accumulated_submission_time=14729.872366, global_step=35987, preemption_count=0, score=14729.872366, test/accuracy=0.516800, test/loss=2.136861, test/num_examples=10000, total_duration=18249.847893, train/accuracy=0.701719, train/loss=1.219686, validation/accuracy=0.640920, validation/loss=1.485737, validation/num_examples=50000
I0915 05:07:43.330767 139639855773440 logging_writer.py:48] [36000] global_step=36000, grad_norm=1.231831, loss=3.045807
I0915 05:07:43.336119 139684108298048 pytorch_submission_base.py:86] 36000) loss = 3.046, grad_norm = 1.232
I0915 05:11:08.555607 139640336475904 logging_writer.py:48] [36500] global_step=36500, grad_norm=1.216331, loss=2.744107
I0915 05:11:08.560836 139684108298048 pytorch_submission_base.py:86] 36500) loss = 2.744, grad_norm = 1.216
I0915 05:14:31.923530 139639855773440 logging_writer.py:48] [37000] global_step=37000, grad_norm=1.244743, loss=3.013435
I0915 05:14:31.928518 139684108298048 pytorch_submission_base.py:86] 37000) loss = 3.013, grad_norm = 1.245
I0915 05:14:38.233391 139684108298048 spec.py:320] Evaluating on the training split.
I0915 05:15:24.238412 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 05:16:10.022050 139684108298048 spec.py:348] Evaluating on the test split.
I0915 05:16:11.411574 139684108298048 submission_runner.py:376] Time since start: 18764.44s, 	Step: 37014, 	{'train/accuracy': 0.69978515625, 'train/loss': 1.2184580230712891, 'validation/accuracy': 0.64356, 'validation/loss': 1.4832809375, 'validation/num_examples': 50000, 'test/accuracy': 0.521, 'test/loss': 2.12569375, 'test/num_examples': 10000, 'score': 15148.976285934448, 'total_duration': 18764.436487436295, 'accumulated_submission_time': 15148.976285934448, 'accumulated_eval_time': 3532.476112127304, 'accumulated_logging_time': 1.0384349822998047}
I0915 05:16:11.431320 139640336475904 logging_writer.py:48] [37014] accumulated_eval_time=3532.476112, accumulated_logging_time=1.038435, accumulated_submission_time=15148.976286, global_step=37014, preemption_count=0, score=15148.976286, test/accuracy=0.521000, test/loss=2.125694, test/num_examples=10000, total_duration=18764.436487, train/accuracy=0.699785, train/loss=1.218458, validation/accuracy=0.643560, validation/loss=1.483281, validation/num_examples=50000
I0915 05:19:30.360684 139639855773440 logging_writer.py:48] [37500] global_step=37500, grad_norm=1.382320, loss=3.040204
I0915 05:19:30.368167 139684108298048 pytorch_submission_base.py:86] 37500) loss = 3.040, grad_norm = 1.382
I0915 05:22:56.007451 139640336475904 logging_writer.py:48] [38000] global_step=38000, grad_norm=1.297207, loss=2.526822
I0915 05:22:56.013022 139684108298048 pytorch_submission_base.py:86] 38000) loss = 2.527, grad_norm = 1.297
I0915 05:23:12.446992 139684108298048 spec.py:320] Evaluating on the training split.
I0915 05:23:56.391892 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 05:24:41.624636 139684108298048 spec.py:348] Evaluating on the test split.
I0915 05:24:43.014406 139684108298048 submission_runner.py:376] Time since start: 19276.04s, 	Step: 38039, 	{'train/accuracy': 0.71169921875, 'train/loss': 1.1861380004882813, 'validation/accuracy': 0.65042, 'validation/loss': 1.455365625, 'validation/num_examples': 50000, 'test/accuracy': 0.5259, 'test/loss': 2.084976171875, 'test/num_examples': 10000, 'score': 15567.745805978775, 'total_duration': 19276.039237976074, 'accumulated_submission_time': 15567.745805978775, 'accumulated_eval_time': 3623.043833255768, 'accumulated_logging_time': 1.0669054985046387}
I0915 05:24:43.035058 139639855773440 logging_writer.py:48] [38039] accumulated_eval_time=3623.043833, accumulated_logging_time=1.066905, accumulated_submission_time=15567.745806, global_step=38039, preemption_count=0, score=15567.745806, test/accuracy=0.525900, test/loss=2.084976, test/num_examples=10000, total_duration=19276.039238, train/accuracy=0.711699, train/loss=1.186138, validation/accuracy=0.650420, validation/loss=1.455366, validation/num_examples=50000
I0915 05:27:51.333939 139640336475904 logging_writer.py:48] [38500] global_step=38500, grad_norm=1.370857, loss=2.585582
I0915 05:27:51.340047 139684108298048 pytorch_submission_base.py:86] 38500) loss = 2.586, grad_norm = 1.371
I0915 05:31:16.370085 139639855773440 logging_writer.py:48] [39000] global_step=39000, grad_norm=1.196560, loss=2.896049
I0915 05:31:16.379006 139684108298048 pytorch_submission_base.py:86] 39000) loss = 2.896, grad_norm = 1.197
I0915 05:31:44.326347 139684108298048 spec.py:320] Evaluating on the training split.
I0915 05:32:28.919712 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 05:33:14.160331 139684108298048 spec.py:348] Evaluating on the test split.
I0915 05:33:15.551948 139684108298048 submission_runner.py:376] Time since start: 19788.58s, 	Step: 39067, 	{'train/accuracy': 0.71400390625, 'train/loss': 1.1646676635742188, 'validation/accuracy': 0.65348, 'validation/loss': 1.436515625, 'validation/num_examples': 50000, 'test/accuracy': 0.5294, 'test/loss': 2.0696662109375, 'test/num_examples': 10000, 'score': 15986.764743804932, 'total_duration': 19788.57683157921, 'accumulated_submission_time': 15986.764743804932, 'accumulated_eval_time': 3714.2696459293365, 'accumulated_logging_time': 1.0964574813842773}
I0915 05:33:15.573651 139640336475904 logging_writer.py:48] [39067] accumulated_eval_time=3714.269646, accumulated_logging_time=1.096457, accumulated_submission_time=15986.764744, global_step=39067, preemption_count=0, score=15986.764744, test/accuracy=0.529400, test/loss=2.069666, test/num_examples=10000, total_duration=19788.576832, train/accuracy=0.714004, train/loss=1.164668, validation/accuracy=0.653480, validation/loss=1.436516, validation/num_examples=50000
I0915 05:36:12.750829 139639855773440 logging_writer.py:48] [39500] global_step=39500, grad_norm=1.389237, loss=2.416629
I0915 05:36:12.756850 139684108298048 pytorch_submission_base.py:86] 39500) loss = 2.417, grad_norm = 1.389
I0915 05:39:37.053322 139640336475904 logging_writer.py:48] [40000] global_step=40000, grad_norm=1.332859, loss=2.605034
I0915 05:39:37.060583 139684108298048 pytorch_submission_base.py:86] 40000) loss = 2.605, grad_norm = 1.333
I0915 05:40:16.717893 139684108298048 spec.py:320] Evaluating on the training split.
I0915 05:41:02.482853 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 05:41:54.975886 139684108298048 spec.py:348] Evaluating on the test split.
I0915 05:41:56.365476 139684108298048 submission_runner.py:376] Time since start: 20309.39s, 	Step: 40092, 	{'train/accuracy': 0.71607421875, 'train/loss': 1.146628646850586, 'validation/accuracy': 0.65274, 'validation/loss': 1.41732640625, 'validation/num_examples': 50000, 'test/accuracy': 0.5329, 'test/loss': 2.047136328125, 'test/num_examples': 10000, 'score': 16405.679308891296, 'total_duration': 20309.39036488533, 'accumulated_submission_time': 16405.679308891296, 'accumulated_eval_time': 3813.917498588562, 'accumulated_logging_time': 1.1280629634857178}
I0915 05:41:56.388919 139639855773440 logging_writer.py:48] [40092] accumulated_eval_time=3813.917499, accumulated_logging_time=1.128063, accumulated_submission_time=16405.679309, global_step=40092, preemption_count=0, score=16405.679309, test/accuracy=0.532900, test/loss=2.047136, test/num_examples=10000, total_duration=20309.390365, train/accuracy=0.716074, train/loss=1.146629, validation/accuracy=0.652740, validation/loss=1.417326, validation/num_examples=50000
I0915 05:44:43.766027 139640336475904 logging_writer.py:48] [40500] global_step=40500, grad_norm=1.269129, loss=2.890418
I0915 05:44:43.772521 139684108298048 pytorch_submission_base.py:86] 40500) loss = 2.890, grad_norm = 1.269
I0915 05:48:06.223708 139639855773440 logging_writer.py:48] [41000] global_step=41000, grad_norm=1.259784, loss=2.606044
I0915 05:48:06.232173 139684108298048 pytorch_submission_base.py:86] 41000) loss = 2.606, grad_norm = 1.260
I0915 05:48:57.776009 139684108298048 spec.py:320] Evaluating on the training split.
I0915 05:49:42.603864 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 05:50:30.806824 139684108298048 spec.py:348] Evaluating on the test split.
I0915 05:50:32.200407 139684108298048 submission_runner.py:376] Time since start: 20825.23s, 	Step: 41125, 	{'train/accuracy': 0.71478515625, 'train/loss': 1.1488006591796875, 'validation/accuracy': 0.65094, 'validation/loss': 1.43545109375, 'validation/num_examples': 50000, 'test/accuracy': 0.5312, 'test/loss': 2.077178515625, 'test/num_examples': 10000, 'score': 16824.81717801094, 'total_duration': 20825.225256681442, 'accumulated_submission_time': 16824.81717801094, 'accumulated_eval_time': 3908.342100381851, 'accumulated_logging_time': 1.1604938507080078}
I0915 05:50:32.220074 139640336475904 logging_writer.py:48] [41125] accumulated_eval_time=3908.342100, accumulated_logging_time=1.160494, accumulated_submission_time=16824.817178, global_step=41125, preemption_count=0, score=16824.817178, test/accuracy=0.531200, test/loss=2.077179, test/num_examples=10000, total_duration=20825.225257, train/accuracy=0.714785, train/loss=1.148801, validation/accuracy=0.650940, validation/loss=1.435451, validation/num_examples=50000
I0915 05:53:08.532275 139639855773440 logging_writer.py:48] [41500] global_step=41500, grad_norm=1.256308, loss=2.535700
I0915 05:53:08.537509 139684108298048 pytorch_submission_base.py:86] 41500) loss = 2.536, grad_norm = 1.256
I0915 05:56:31.858766 139640336475904 logging_writer.py:48] [42000] global_step=42000, grad_norm=1.266034, loss=2.991709
I0915 05:56:31.864798 139684108298048 pytorch_submission_base.py:86] 42000) loss = 2.992, grad_norm = 1.266
I0915 05:57:33.276012 139684108298048 spec.py:320] Evaluating on the training split.
I0915 05:58:17.012401 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 05:59:02.353545 139684108298048 spec.py:348] Evaluating on the test split.
I0915 05:59:03.746064 139684108298048 submission_runner.py:376] Time since start: 21336.77s, 	Step: 42150, 	{'train/accuracy': 0.71998046875, 'train/loss': 1.1204037475585937, 'validation/accuracy': 0.65894, 'validation/loss': 1.3971328125, 'validation/num_examples': 50000, 'test/accuracy': 0.5354, 'test/loss': 2.039900390625, 'test/num_examples': 10000, 'score': 17243.604677677155, 'total_duration': 21336.77097415924, 'accumulated_submission_time': 17243.604677677155, 'accumulated_eval_time': 3998.8128588199615, 'accumulated_logging_time': 1.190061330795288}
I0915 05:59:03.765947 139639855773440 logging_writer.py:48] [42150] accumulated_eval_time=3998.812859, accumulated_logging_time=1.190061, accumulated_submission_time=17243.604678, global_step=42150, preemption_count=0, score=17243.604678, test/accuracy=0.535400, test/loss=2.039900, test/num_examples=10000, total_duration=21336.770974, train/accuracy=0.719980, train/loss=1.120404, validation/accuracy=0.658940, validation/loss=1.397133, validation/num_examples=50000
I0915 06:01:27.905001 139640336475904 logging_writer.py:48] [42500] global_step=42500, grad_norm=1.342304, loss=2.699201
I0915 06:01:27.910409 139684108298048 pytorch_submission_base.py:86] 42500) loss = 2.699, grad_norm = 1.342
I0915 06:04:53.031332 139639855773440 logging_writer.py:48] [43000] global_step=43000, grad_norm=1.323143, loss=2.800681
I0915 06:04:53.038579 139684108298048 pytorch_submission_base.py:86] 43000) loss = 2.801, grad_norm = 1.323
I0915 06:06:04.976775 139684108298048 spec.py:320] Evaluating on the training split.
I0915 06:06:48.997606 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 06:07:34.444522 139684108298048 spec.py:348] Evaluating on the test split.
I0915 06:07:35.837371 139684108298048 submission_runner.py:376] Time since start: 21848.86s, 	Step: 43176, 	{'train/accuracy': 0.71935546875, 'train/loss': 1.1192827606201172, 'validation/accuracy': 0.65862, 'validation/loss': 1.3972553125, 'validation/num_examples': 50000, 'test/accuracy': 0.5384, 'test/loss': 2.025319921875, 'test/num_examples': 10000, 'score': 17662.550467967987, 'total_duration': 21848.862194299698, 'accumulated_submission_time': 17662.550467967987, 'accumulated_eval_time': 4089.6736998558044, 'accumulated_logging_time': 1.219120740890503}
I0915 06:07:35.857153 139640336475904 logging_writer.py:48] [43176] accumulated_eval_time=4089.673700, accumulated_logging_time=1.219121, accumulated_submission_time=17662.550468, global_step=43176, preemption_count=0, score=17662.550468, test/accuracy=0.538400, test/loss=2.025320, test/num_examples=10000, total_duration=21848.862194, train/accuracy=0.719355, train/loss=1.119283, validation/accuracy=0.658620, validation/loss=1.397255, validation/num_examples=50000
I0915 06:09:48.153783 139639855773440 logging_writer.py:48] [43500] global_step=43500, grad_norm=1.259624, loss=2.369948
I0915 06:09:48.162898 139684108298048 pytorch_submission_base.py:86] 43500) loss = 2.370, grad_norm = 1.260
I0915 06:13:13.684941 139640336475904 logging_writer.py:48] [44000] global_step=44000, grad_norm=1.380178, loss=2.934932
I0915 06:13:13.690054 139684108298048 pytorch_submission_base.py:86] 44000) loss = 2.935, grad_norm = 1.380
I0915 06:14:37.084401 139684108298048 spec.py:320] Evaluating on the training split.
I0915 06:15:21.088757 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 06:16:06.109214 139684108298048 spec.py:348] Evaluating on the test split.
I0915 06:16:07.502628 139684108298048 submission_runner.py:376] Time since start: 22360.53s, 	Step: 44203, 	{'train/accuracy': 0.7238671875, 'train/loss': 1.1068960571289062, 'validation/accuracy': 0.66084, 'validation/loss': 1.379905, 'validation/num_examples': 50000, 'test/accuracy': 0.5398, 'test/loss': 2.0197302734375, 'test/num_examples': 10000, 'score': 18081.493983745575, 'total_duration': 22360.52747821808, 'accumulated_submission_time': 18081.493983745575, 'accumulated_eval_time': 4180.092182397842, 'accumulated_logging_time': 1.2488369941711426}
I0915 06:16:07.523859 139639855773440 logging_writer.py:48] [44203] accumulated_eval_time=4180.092182, accumulated_logging_time=1.248837, accumulated_submission_time=18081.493984, global_step=44203, preemption_count=0, score=18081.493984, test/accuracy=0.539800, test/loss=2.019730, test/num_examples=10000, total_duration=22360.527478, train/accuracy=0.723867, train/loss=1.106896, validation/accuracy=0.660840, validation/loss=1.379905, validation/num_examples=50000
I0915 06:18:09.394294 139640336475904 logging_writer.py:48] [44500] global_step=44500, grad_norm=1.422786, loss=2.710586
I0915 06:18:09.400504 139684108298048 pytorch_submission_base.py:86] 44500) loss = 2.711, grad_norm = 1.423
I0915 06:21:32.269566 139639855773440 logging_writer.py:48] [45000] global_step=45000, grad_norm=1.390947, loss=2.456741
I0915 06:21:32.278353 139684108298048 pytorch_submission_base.py:86] 45000) loss = 2.457, grad_norm = 1.391
I0915 06:23:08.541562 139684108298048 spec.py:320] Evaluating on the training split.
I0915 06:23:53.992846 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 06:24:40.317972 139684108298048 spec.py:348] Evaluating on the test split.
I0915 06:24:41.709152 139684108298048 submission_runner.py:376] Time since start: 22874.73s, 	Step: 45231, 	{'train/accuracy': 0.7253515625, 'train/loss': 1.1061186218261718, 'validation/accuracy': 0.66368, 'validation/loss': 1.38838234375, 'validation/num_examples': 50000, 'test/accuracy': 0.5412, 'test/loss': 2.0248123046875, 'test/num_examples': 10000, 'score': 18500.272318840027, 'total_duration': 22874.73406767845, 'accumulated_submission_time': 18500.272318840027, 'accumulated_eval_time': 4273.259990692139, 'accumulated_logging_time': 1.2786579132080078}
I0915 06:24:41.729590 139640336475904 logging_writer.py:48] [45231] accumulated_eval_time=4273.259991, accumulated_logging_time=1.278658, accumulated_submission_time=18500.272319, global_step=45231, preemption_count=0, score=18500.272319, test/accuracy=0.541200, test/loss=2.024812, test/num_examples=10000, total_duration=22874.734068, train/accuracy=0.725352, train/loss=1.106119, validation/accuracy=0.663680, validation/loss=1.388382, validation/num_examples=50000
I0915 06:26:32.229323 139639855773440 logging_writer.py:48] [45500] global_step=45500, grad_norm=1.410290, loss=2.321114
I0915 06:26:32.239575 139684108298048 pytorch_submission_base.py:86] 45500) loss = 2.321, grad_norm = 1.410
I0915 06:29:55.521370 139640336475904 logging_writer.py:48] [46000] global_step=46000, grad_norm=1.309596, loss=3.130568
I0915 06:29:55.531826 139684108298048 pytorch_submission_base.py:86] 46000) loss = 3.131, grad_norm = 1.310
I0915 06:31:42.865258 139684108298048 spec.py:320] Evaluating on the training split.
I0915 06:32:28.367610 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 06:33:14.114019 139684108298048 spec.py:348] Evaluating on the test split.
I0915 06:33:15.506783 139684108298048 submission_runner.py:376] Time since start: 23388.53s, 	Step: 46261, 	{'train/accuracy': 0.73146484375, 'train/loss': 1.072737274169922, 'validation/accuracy': 0.6682, 'validation/loss': 1.357775625, 'validation/num_examples': 50000, 'test/accuracy': 0.5449, 'test/loss': 1.9881630859375, 'test/num_examples': 10000, 'score': 18919.114461183548, 'total_duration': 23388.53168988228, 'accumulated_submission_time': 18919.114461183548, 'accumulated_eval_time': 4365.901824235916, 'accumulated_logging_time': 1.3087048530578613}
I0915 06:33:15.529181 139639855773440 logging_writer.py:48] [46261] accumulated_eval_time=4365.901824, accumulated_logging_time=1.308705, accumulated_submission_time=18919.114461, global_step=46261, preemption_count=0, score=18919.114461, test/accuracy=0.544900, test/loss=1.988163, test/num_examples=10000, total_duration=23388.531690, train/accuracy=0.731465, train/loss=1.072737, validation/accuracy=0.668200, validation/loss=1.357776, validation/num_examples=50000
I0915 06:34:56.260881 139640336475904 logging_writer.py:48] [46500] global_step=46500, grad_norm=1.367846, loss=2.742578
I0915 06:34:56.265574 139684108298048 pytorch_submission_base.py:86] 46500) loss = 2.743, grad_norm = 1.368
I0915 06:38:19.640843 139639855773440 logging_writer.py:48] [47000] global_step=47000, grad_norm=1.333315, loss=2.557791
I0915 06:38:19.649614 139684108298048 pytorch_submission_base.py:86] 47000) loss = 2.558, grad_norm = 1.333
I0915 06:40:16.700062 139684108298048 spec.py:320] Evaluating on the training split.
I0915 06:41:00.562628 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 06:41:54.641901 139684108298048 spec.py:348] Evaluating on the test split.
I0915 06:41:56.031056 139684108298048 submission_runner.py:376] Time since start: 23909.06s, 	Step: 47287, 	{'train/accuracy': 0.733203125, 'train/loss': 1.0674948120117187, 'validation/accuracy': 0.67018, 'validation/loss': 1.35777953125, 'validation/num_examples': 50000, 'test/accuracy': 0.5505, 'test/loss': 1.9850087890625, 'test/num_examples': 10000, 'score': 19337.941229581833, 'total_duration': 23909.055931806564, 'accumulated_submission_time': 19337.941229581833, 'accumulated_eval_time': 4465.233575105667, 'accumulated_logging_time': 1.3402297496795654}
I0915 06:41:56.051450 139640336475904 logging_writer.py:48] [47287] accumulated_eval_time=4465.233575, accumulated_logging_time=1.340230, accumulated_submission_time=19337.941230, global_step=47287, preemption_count=0, score=19337.941230, test/accuracy=0.550500, test/loss=1.985009, test/num_examples=10000, total_duration=23909.055932, train/accuracy=0.733203, train/loss=1.067495, validation/accuracy=0.670180, validation/loss=1.357780, validation/num_examples=50000
I0915 06:43:24.416637 139639855773440 logging_writer.py:48] [47500] global_step=47500, grad_norm=1.346981, loss=2.762757
I0915 06:43:24.422465 139684108298048 pytorch_submission_base.py:86] 47500) loss = 2.763, grad_norm = 1.347
I0915 06:46:50.031578 139640336475904 logging_writer.py:48] [48000] global_step=48000, grad_norm=1.285942, loss=2.764624
I0915 06:46:50.036882 139684108298048 pytorch_submission_base.py:86] 48000) loss = 2.765, grad_norm = 1.286
I0915 06:48:57.466458 139684108298048 spec.py:320] Evaluating on the training split.
I0915 06:49:42.948122 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 06:50:29.732623 139684108298048 spec.py:348] Evaluating on the test split.
I0915 06:50:31.123431 139684108298048 submission_runner.py:376] Time since start: 24424.15s, 	Step: 48312, 	{'train/accuracy': 0.73505859375, 'train/loss': 1.0556340789794922, 'validation/accuracy': 0.66984, 'validation/loss': 1.3533246875, 'validation/num_examples': 50000, 'test/accuracy': 0.5462, 'test/loss': 1.9885140625, 'test/num_examples': 10000, 'score': 19757.0280752182, 'total_duration': 24424.148333072662, 'accumulated_submission_time': 19757.0280752182, 'accumulated_eval_time': 4558.890681266785, 'accumulated_logging_time': 1.370004653930664}
I0915 06:50:31.143762 139639855773440 logging_writer.py:48] [48312] accumulated_eval_time=4558.890681, accumulated_logging_time=1.370005, accumulated_submission_time=19757.028075, global_step=48312, preemption_count=0, score=19757.028075, test/accuracy=0.546200, test/loss=1.988514, test/num_examples=10000, total_duration=24424.148333, train/accuracy=0.735059, train/loss=1.055634, validation/accuracy=0.669840, validation/loss=1.353325, validation/num_examples=50000
I0915 06:51:48.224259 139640336475904 logging_writer.py:48] [48500] global_step=48500, grad_norm=1.336532, loss=2.642688
I0915 06:51:48.228768 139684108298048 pytorch_submission_base.py:86] 48500) loss = 2.643, grad_norm = 1.337
I0915 06:55:14.585479 139639855773440 logging_writer.py:48] [49000] global_step=49000, grad_norm=1.330439, loss=2.874429
I0915 06:55:14.590258 139684108298048 pytorch_submission_base.py:86] 49000) loss = 2.874, grad_norm = 1.330
I0915 06:57:32.170445 139684108298048 spec.py:320] Evaluating on the training split.
I0915 06:58:16.246390 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 06:59:01.559728 139684108298048 spec.py:348] Evaluating on the test split.
I0915 06:59:02.952981 139684108298048 submission_runner.py:376] Time since start: 24935.98s, 	Step: 49337, 	{'train/accuracy': 0.7382421875, 'train/loss': 1.0397127532958985, 'validation/accuracy': 0.67116, 'validation/loss': 1.34067359375, 'validation/num_examples': 50000, 'test/accuracy': 0.5468, 'test/loss': 1.9801173828125, 'test/num_examples': 10000, 'score': 20175.821433782578, 'total_duration': 24935.97784304619, 'accumulated_submission_time': 20175.821433782578, 'accumulated_eval_time': 4649.673602819443, 'accumulated_logging_time': 1.3998687267303467}
I0915 06:59:02.972187 139640336475904 logging_writer.py:48] [49337] accumulated_eval_time=4649.673603, accumulated_logging_time=1.399869, accumulated_submission_time=20175.821434, global_step=49337, preemption_count=0, score=20175.821434, test/accuracy=0.546800, test/loss=1.980117, test/num_examples=10000, total_duration=24935.977843, train/accuracy=0.738242, train/loss=1.039713, validation/accuracy=0.671160, validation/loss=1.340674, validation/num_examples=50000
I0915 07:00:10.282652 139639855773440 logging_writer.py:48] [49500] global_step=49500, grad_norm=1.365219, loss=2.600000
I0915 07:00:10.294175 139684108298048 pytorch_submission_base.py:86] 49500) loss = 2.600, grad_norm = 1.365
I0915 07:03:33.713561 139640336475904 logging_writer.py:48] [50000] global_step=50000, grad_norm=1.514188, loss=2.392285
I0915 07:03:33.720053 139684108298048 pytorch_submission_base.py:86] 50000) loss = 2.392, grad_norm = 1.514
I0915 07:06:04.382788 139684108298048 spec.py:320] Evaluating on the training split.
I0915 07:06:48.697848 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 07:07:34.074999 139684108298048 spec.py:348] Evaluating on the test split.
I0915 07:07:35.468103 139684108298048 submission_runner.py:376] Time since start: 25448.49s, 	Step: 50363, 	{'train/accuracy': 0.742265625, 'train/loss': 1.0322038269042968, 'validation/accuracy': 0.6756, 'validation/loss': 1.32815984375, 'validation/num_examples': 50000, 'test/accuracy': 0.5564, 'test/loss': 1.9555203125, 'test/num_examples': 10000, 'score': 20594.957370758057, 'total_duration': 25448.493005752563, 'accumulated_submission_time': 20594.957370758057, 'accumulated_eval_time': 4740.759184360504, 'accumulated_logging_time': 1.4278614521026611}
I0915 07:07:35.488575 139639855773440 logging_writer.py:48] [50363] accumulated_eval_time=4740.759184, accumulated_logging_time=1.427861, accumulated_submission_time=20594.957371, global_step=50363, preemption_count=0, score=20594.957371, test/accuracy=0.556400, test/loss=1.955520, test/num_examples=10000, total_duration=25448.493006, train/accuracy=0.742266, train/loss=1.032204, validation/accuracy=0.675600, validation/loss=1.328160, validation/num_examples=50000
I0915 07:08:32.361774 139640336475904 logging_writer.py:48] [50500] global_step=50500, grad_norm=1.350954, loss=2.969251
I0915 07:08:32.367672 139684108298048 pytorch_submission_base.py:86] 50500) loss = 2.969, grad_norm = 1.351
I0915 07:11:55.201713 139639855773440 logging_writer.py:48] [51000] global_step=51000, grad_norm=1.407969, loss=2.467488
I0915 07:11:55.209097 139684108298048 pytorch_submission_base.py:86] 51000) loss = 2.467, grad_norm = 1.408
I0915 07:14:36.774161 139684108298048 spec.py:320] Evaluating on the training split.
I0915 07:15:22.438246 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 07:16:13.399144 139684108298048 spec.py:348] Evaluating on the test split.
I0915 07:16:14.789965 139684108298048 submission_runner.py:376] Time since start: 25967.81s, 	Step: 51389, 	{'train/accuracy': 0.74587890625, 'train/loss': 1.0296810150146485, 'validation/accuracy': 0.67772, 'validation/loss': 1.322539375, 'validation/num_examples': 50000, 'test/accuracy': 0.5565, 'test/loss': 1.9421529296875, 'test/num_examples': 10000, 'score': 21013.991913557053, 'total_duration': 25967.81488609314, 'accumulated_submission_time': 21013.991913557053, 'accumulated_eval_time': 4838.775243282318, 'accumulated_logging_time': 1.4578449726104736}
I0915 07:16:14.810556 139640336475904 logging_writer.py:48] [51389] accumulated_eval_time=4838.775243, accumulated_logging_time=1.457845, accumulated_submission_time=21013.991914, global_step=51389, preemption_count=0, score=21013.991914, test/accuracy=0.556500, test/loss=1.942153, test/num_examples=10000, total_duration=25967.814886, train/accuracy=0.745879, train/loss=1.029681, validation/accuracy=0.677720, validation/loss=1.322539, validation/num_examples=50000
I0915 07:17:01.165886 139639855773440 logging_writer.py:48] [51500] global_step=51500, grad_norm=1.346511, loss=2.732423
I0915 07:17:01.175249 139684108298048 pytorch_submission_base.py:86] 51500) loss = 2.732, grad_norm = 1.347
I0915 07:20:24.358705 139640336475904 logging_writer.py:48] [52000] global_step=52000, grad_norm=1.393231, loss=2.283426
I0915 07:20:24.364858 139684108298048 pytorch_submission_base.py:86] 52000) loss = 2.283, grad_norm = 1.393
I0915 07:23:15.943531 139684108298048 spec.py:320] Evaluating on the training split.
I0915 07:24:00.965970 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 07:24:47.599241 139684108298048 spec.py:348] Evaluating on the test split.
I0915 07:24:48.991611 139684108298048 submission_runner.py:376] Time since start: 26482.02s, 	Step: 52419, 	{'train/accuracy': 0.745, 'train/loss': 1.021488037109375, 'validation/accuracy': 0.6793, 'validation/loss': 1.307887578125, 'validation/num_examples': 50000, 'test/accuracy': 0.5567, 'test/loss': 1.9352248046875, 'test/num_examples': 10000, 'score': 21432.790216207504, 'total_duration': 26482.016530275345, 'accumulated_submission_time': 21432.790216207504, 'accumulated_eval_time': 4931.823822975159, 'accumulated_logging_time': 1.4883503913879395}
I0915 07:24:49.014474 139639855773440 logging_writer.py:48] [52419] accumulated_eval_time=4931.823823, accumulated_logging_time=1.488350, accumulated_submission_time=21432.790216, global_step=52419, preemption_count=0, score=21432.790216, test/accuracy=0.556700, test/loss=1.935225, test/num_examples=10000, total_duration=26482.016530, train/accuracy=0.745000, train/loss=1.021488, validation/accuracy=0.679300, validation/loss=1.307888, validation/num_examples=50000
I0915 07:25:23.067088 139640336475904 logging_writer.py:48] [52500] global_step=52500, grad_norm=1.318881, loss=2.568240
I0915 07:25:23.072371 139684108298048 pytorch_submission_base.py:86] 52500) loss = 2.568, grad_norm = 1.319
I0915 07:28:48.448618 139639855773440 logging_writer.py:48] [53000] global_step=53000, grad_norm=1.365673, loss=2.717906
I0915 07:28:48.453026 139684108298048 pytorch_submission_base.py:86] 53000) loss = 2.718, grad_norm = 1.366
I0915 07:31:50.368789 139684108298048 spec.py:320] Evaluating on the training split.
I0915 07:32:34.638071 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 07:33:23.363590 139684108298048 spec.py:348] Evaluating on the test split.
I0915 07:33:24.757308 139684108298048 submission_runner.py:376] Time since start: 26997.78s, 	Step: 53447, 	{'train/accuracy': 0.74888671875, 'train/loss': 1.0007962799072265, 'validation/accuracy': 0.68382, 'validation/loss': 1.294533984375, 'validation/num_examples': 50000, 'test/accuracy': 0.5576, 'test/loss': 1.924509375, 'test/num_examples': 10000, 'score': 21851.882763385773, 'total_duration': 26997.782219409943, 'accumulated_submission_time': 21851.882763385773, 'accumulated_eval_time': 5026.212872266769, 'accumulated_logging_time': 1.5215964317321777}
I0915 07:33:24.781232 139640336475904 logging_writer.py:48] [53447] accumulated_eval_time=5026.212872, accumulated_logging_time=1.521596, accumulated_submission_time=21851.882763, global_step=53447, preemption_count=0, score=21851.882763, test/accuracy=0.557600, test/loss=1.924509, test/num_examples=10000, total_duration=26997.782219, train/accuracy=0.748887, train/loss=1.000796, validation/accuracy=0.683820, validation/loss=1.294534, validation/num_examples=50000
I0915 07:33:47.439081 139639855773440 logging_writer.py:48] [53500] global_step=53500, grad_norm=1.544963, loss=2.755050
I0915 07:33:47.444093 139684108298048 pytorch_submission_base.py:86] 53500) loss = 2.755, grad_norm = 1.545
I0915 07:37:15.003045 139640336475904 logging_writer.py:48] [54000] global_step=54000, grad_norm=1.474204, loss=2.860590
I0915 07:37:15.007539 139684108298048 pytorch_submission_base.py:86] 54000) loss = 2.861, grad_norm = 1.474
I0915 07:40:26.067750 139684108298048 spec.py:320] Evaluating on the training split.
I0915 07:41:11.416505 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 07:41:56.705352 139684108298048 spec.py:348] Evaluating on the test split.
I0915 07:41:58.099460 139684108298048 submission_runner.py:376] Time since start: 27511.12s, 	Step: 54461, 	{'train/accuracy': 0.75017578125, 'train/loss': 0.9845518493652343, 'validation/accuracy': 0.6819, 'validation/loss': 1.284678828125, 'validation/num_examples': 50000, 'test/accuracy': 0.5577, 'test/loss': 1.923010546875, 'test/num_examples': 10000, 'score': 22270.88813996315, 'total_duration': 27511.12437748909, 'accumulated_submission_time': 22270.88813996315, 'accumulated_eval_time': 5118.245020389557, 'accumulated_logging_time': 1.5569963455200195}
I0915 07:41:58.123142 139639855773440 logging_writer.py:48] [54461] accumulated_eval_time=5118.245020, accumulated_logging_time=1.556996, accumulated_submission_time=22270.888140, global_step=54461, preemption_count=0, score=22270.888140, test/accuracy=0.557700, test/loss=1.923011, test/num_examples=10000, total_duration=27511.124377, train/accuracy=0.750176, train/loss=0.984552, validation/accuracy=0.681900, validation/loss=1.284679, validation/num_examples=50000
I0915 07:42:15.270879 139640336475904 logging_writer.py:48] [54500] global_step=54500, grad_norm=1.384033, loss=2.463905
I0915 07:42:15.275580 139684108298048 pytorch_submission_base.py:86] 54500) loss = 2.464, grad_norm = 1.384
I0915 07:45:47.753158 139639855773440 logging_writer.py:48] [55000] global_step=55000, grad_norm=1.492551, loss=2.441046
I0915 07:45:47.759103 139684108298048 pytorch_submission_base.py:86] 55000) loss = 2.441, grad_norm = 1.493
I0915 07:48:59.421162 139684108298048 spec.py:320] Evaluating on the training split.
I0915 07:49:43.496205 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 07:50:28.896170 139684108298048 spec.py:348] Evaluating on the test split.
I0915 07:50:30.287784 139684108298048 submission_runner.py:376] Time since start: 28023.31s, 	Step: 55462, 	{'train/accuracy': 0.752890625, 'train/loss': 0.979212646484375, 'validation/accuracy': 0.6861, 'validation/loss': 1.2788175, 'validation/num_examples': 50000, 'test/accuracy': 0.5579, 'test/loss': 1.9023837890625, 'test/num_examples': 10000, 'score': 22689.95379137993, 'total_duration': 28023.31267142296, 'accumulated_submission_time': 22689.95379137993, 'accumulated_eval_time': 5209.111755371094, 'accumulated_logging_time': 1.5931775569915771}
I0915 07:50:30.308914 139640336475904 logging_writer.py:48] [55462] accumulated_eval_time=5209.111755, accumulated_logging_time=1.593178, accumulated_submission_time=22689.953791, global_step=55462, preemption_count=0, score=22689.953791, test/accuracy=0.557900, test/loss=1.902384, test/num_examples=10000, total_duration=28023.312671, train/accuracy=0.752891, train/loss=0.979213, validation/accuracy=0.686100, validation/loss=1.278817, validation/num_examples=50000
I0915 07:50:47.060672 139639855773440 logging_writer.py:48] [55500] global_step=55500, grad_norm=1.433661, loss=1.933169
I0915 07:50:47.065651 139684108298048 pytorch_submission_base.py:86] 55500) loss = 1.933, grad_norm = 1.434
I0915 07:54:10.142423 139640336475904 logging_writer.py:48] [56000] global_step=56000, grad_norm=1.380639, loss=3.048578
I0915 07:54:10.153561 139684108298048 pytorch_submission_base.py:86] 56000) loss = 3.049, grad_norm = 1.381
I0915 07:57:31.629805 139684108298048 spec.py:320] Evaluating on the training split.
I0915 07:58:16.300437 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 07:59:01.548269 139684108298048 spec.py:348] Evaluating on the test split.
I0915 07:59:02.943566 139684108298048 submission_runner.py:376] Time since start: 28535.97s, 	Step: 56486, 	{'train/accuracy': 0.7530078125, 'train/loss': 0.9812405395507813, 'validation/accuracy': 0.68612, 'validation/loss': 1.282058984375, 'validation/num_examples': 50000, 'test/accuracy': 0.5611, 'test/loss': 1.9186826171875, 'test/num_examples': 10000, 'score': 23109.04629802704, 'total_duration': 28535.968436717987, 'accumulated_submission_time': 23109.04629802704, 'accumulated_eval_time': 5300.425964355469, 'accumulated_logging_time': 1.6234455108642578}
I0915 07:59:02.964090 139639855773440 logging_writer.py:48] [56486] accumulated_eval_time=5300.425964, accumulated_logging_time=1.623446, accumulated_submission_time=23109.046298, global_step=56486, preemption_count=0, score=23109.046298, test/accuracy=0.561100, test/loss=1.918683, test/num_examples=10000, total_duration=28535.968437, train/accuracy=0.753008, train/loss=0.981241, validation/accuracy=0.686120, validation/loss=1.282059, validation/num_examples=50000
I0915 07:59:09.808019 139640336475904 logging_writer.py:48] [56500] global_step=56500, grad_norm=1.371870, loss=2.583848
I0915 07:59:09.812406 139684108298048 pytorch_submission_base.py:86] 56500) loss = 2.584, grad_norm = 1.372
I0915 08:02:33.374436 139639855773440 logging_writer.py:48] [57000] global_step=57000, grad_norm=1.413498, loss=2.281735
I0915 08:02:33.380709 139684108298048 pytorch_submission_base.py:86] 57000) loss = 2.282, grad_norm = 1.413
I0915 08:05:56.761176 139640336475904 logging_writer.py:48] [57500] global_step=57500, grad_norm=1.496253, loss=3.125196
I0915 08:05:56.767456 139684108298048 pytorch_submission_base.py:86] 57500) loss = 3.125, grad_norm = 1.496
I0915 08:06:04.405413 139684108298048 spec.py:320] Evaluating on the training split.
I0915 08:06:50.021393 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 08:07:38.890297 139684108298048 spec.py:348] Evaluating on the test split.
I0915 08:07:40.281602 139684108298048 submission_runner.py:376] Time since start: 29053.31s, 	Step: 57517, 	{'train/accuracy': 0.7569140625, 'train/loss': 0.9662100982666015, 'validation/accuracy': 0.69078, 'validation/loss': 1.263790390625, 'validation/num_examples': 50000, 'test/accuracy': 0.5638, 'test/loss': 1.88946796875, 'test/num_examples': 10000, 'score': 23528.19397497177, 'total_duration': 29053.30651664734, 'accumulated_submission_time': 23528.19397497177, 'accumulated_eval_time': 5396.302827358246, 'accumulated_logging_time': 1.653935194015503}
I0915 08:07:40.302585 139639855773440 logging_writer.py:48] [57517] accumulated_eval_time=5396.302827, accumulated_logging_time=1.653935, accumulated_submission_time=23528.193975, global_step=57517, preemption_count=0, score=23528.193975, test/accuracy=0.563800, test/loss=1.889468, test/num_examples=10000, total_duration=29053.306517, train/accuracy=0.756914, train/loss=0.966210, validation/accuracy=0.690780, validation/loss=1.263790, validation/num_examples=50000
I0915 08:10:59.763088 139640336475904 logging_writer.py:48] [58000] global_step=58000, grad_norm=1.631811, loss=3.006115
I0915 08:10:59.768761 139684108298048 pytorch_submission_base.py:86] 58000) loss = 3.006, grad_norm = 1.632
I0915 08:14:22.661744 139639855773440 logging_writer.py:48] [58500] global_step=58500, grad_norm=1.646925, loss=2.560807
I0915 08:14:22.667319 139684108298048 pytorch_submission_base.py:86] 58500) loss = 2.561, grad_norm = 1.647
I0915 08:14:41.600214 139684108298048 spec.py:320] Evaluating on the training split.
I0915 08:15:25.999052 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 08:16:18.025031 139684108298048 spec.py:348] Evaluating on the test split.
I0915 08:16:19.415922 139684108298048 submission_runner.py:376] Time since start: 29572.44s, 	Step: 58545, 	{'train/accuracy': 0.75435546875, 'train/loss': 0.9642987060546875, 'validation/accuracy': 0.68598, 'validation/loss': 1.27245078125, 'validation/num_examples': 50000, 'test/accuracy': 0.567, 'test/loss': 1.8873513671875, 'test/num_examples': 10000, 'score': 23947.1761302948, 'total_duration': 29572.44074511528, 'accumulated_submission_time': 23947.1761302948, 'accumulated_eval_time': 5494.11896109581, 'accumulated_logging_time': 1.6849124431610107}
I0915 08:16:19.439614 139640336475904 logging_writer.py:48] [58545] accumulated_eval_time=5494.118961, accumulated_logging_time=1.684912, accumulated_submission_time=23947.176130, global_step=58545, preemption_count=0, score=23947.176130, test/accuracy=0.567000, test/loss=1.887351, test/num_examples=10000, total_duration=29572.440745, train/accuracy=0.754355, train/loss=0.964299, validation/accuracy=0.685980, validation/loss=1.272451, validation/num_examples=50000
I0915 08:19:28.143574 139639855773440 logging_writer.py:48] [59000] global_step=59000, grad_norm=1.404711, loss=2.343516
I0915 08:19:28.148665 139684108298048 pytorch_submission_base.py:86] 59000) loss = 2.344, grad_norm = 1.405
I0915 08:22:51.635460 139640336475904 logging_writer.py:48] [59500] global_step=59500, grad_norm=1.571516, loss=2.804850
I0915 08:22:51.641146 139684108298048 pytorch_submission_base.py:86] 59500) loss = 2.805, grad_norm = 1.572
I0915 08:23:20.653652 139684108298048 spec.py:320] Evaluating on the training split.
I0915 08:24:05.815382 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 08:24:54.632910 139684108298048 spec.py:348] Evaluating on the test split.
I0915 08:24:56.023131 139684108298048 submission_runner.py:376] Time since start: 30089.05s, 	Step: 59570, 	{'train/accuracy': 0.7605078125, 'train/loss': 0.957832260131836, 'validation/accuracy': 0.69118, 'validation/loss': 1.261976640625, 'validation/num_examples': 50000, 'test/accuracy': 0.5661, 'test/loss': 1.8909234375, 'test/num_examples': 10000, 'score': 24366.14768886566, 'total_duration': 30089.04805111885, 'accumulated_submission_time': 24366.14768886566, 'accumulated_eval_time': 5589.488629817963, 'accumulated_logging_time': 1.7184011936187744}
I0915 08:24:56.044062 139639855773440 logging_writer.py:48] [59570] accumulated_eval_time=5589.488630, accumulated_logging_time=1.718401, accumulated_submission_time=24366.147689, global_step=59570, preemption_count=0, score=24366.147689, test/accuracy=0.566100, test/loss=1.890923, test/num_examples=10000, total_duration=30089.048051, train/accuracy=0.760508, train/loss=0.957832, validation/accuracy=0.691180, validation/loss=1.261977, validation/num_examples=50000
I0915 08:27:53.727965 139640336475904 logging_writer.py:48] [60000] global_step=60000, grad_norm=1.543110, loss=2.337650
I0915 08:27:53.734103 139684108298048 pytorch_submission_base.py:86] 60000) loss = 2.338, grad_norm = 1.543
I0915 08:31:18.992532 139639855773440 logging_writer.py:48] [60500] global_step=60500, grad_norm=1.477063, loss=2.479232
I0915 08:31:18.999086 139684108298048 pytorch_submission_base.py:86] 60500) loss = 2.479, grad_norm = 1.477
I0915 08:31:57.413446 139684108298048 spec.py:320] Evaluating on the training split.
I0915 08:32:41.836471 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 08:33:27.018533 139684108298048 spec.py:348] Evaluating on the test split.
I0915 08:33:28.411617 139684108298048 submission_runner.py:376] Time since start: 30601.44s, 	Step: 60593, 	{'train/accuracy': 0.76001953125, 'train/loss': 0.9597245788574219, 'validation/accuracy': 0.69134, 'validation/loss': 1.264243046875, 'validation/num_examples': 50000, 'test/accuracy': 0.5748, 'test/loss': 1.90301171875, 'test/num_examples': 10000, 'score': 24785.3037545681, 'total_duration': 30601.43651509285, 'accumulated_submission_time': 24785.3037545681, 'accumulated_eval_time': 5680.48707151413, 'accumulated_logging_time': 1.7484703063964844}
I0915 08:33:28.431422 139640336475904 logging_writer.py:48] [60593] accumulated_eval_time=5680.487072, accumulated_logging_time=1.748470, accumulated_submission_time=24785.303755, global_step=60593, preemption_count=0, score=24785.303755, test/accuracy=0.574800, test/loss=1.903012, test/num_examples=10000, total_duration=30601.436515, train/accuracy=0.760020, train/loss=0.959725, validation/accuracy=0.691340, validation/loss=1.264243, validation/num_examples=50000
I0915 08:36:14.708800 139639855773440 logging_writer.py:48] [61000] global_step=61000, grad_norm=1.478369, loss=2.533449
I0915 08:36:14.715821 139684108298048 pytorch_submission_base.py:86] 61000) loss = 2.533, grad_norm = 1.478
I0915 08:39:41.145147 139640336475904 logging_writer.py:48] [61500] global_step=61500, grad_norm=1.440778, loss=2.237738
I0915 08:39:41.150670 139684108298048 pytorch_submission_base.py:86] 61500) loss = 2.238, grad_norm = 1.441
I0915 08:40:29.759779 139684108298048 spec.py:320] Evaluating on the training split.
I0915 08:41:14.107426 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 08:41:59.376224 139684108298048 spec.py:348] Evaluating on the test split.
I0915 08:42:00.767926 139684108298048 submission_runner.py:376] Time since start: 31113.79s, 	Step: 61618, 	{'train/accuracy': 0.762109375, 'train/loss': 0.9413234710693359, 'validation/accuracy': 0.692, 'validation/loss': 1.25130953125, 'validation/num_examples': 50000, 'test/accuracy': 0.5685, 'test/loss': 1.862825390625, 'test/num_examples': 10000, 'score': 25204.41980266571, 'total_duration': 31113.792841911316, 'accumulated_submission_time': 25204.41980266571, 'accumulated_eval_time': 5771.495392084122, 'accumulated_logging_time': 1.7780542373657227}
I0915 08:42:00.792830 139639855773440 logging_writer.py:48] [61618] accumulated_eval_time=5771.495392, accumulated_logging_time=1.778054, accumulated_submission_time=25204.419803, global_step=61618, preemption_count=0, score=25204.419803, test/accuracy=0.568500, test/loss=1.862825, test/num_examples=10000, total_duration=31113.792842, train/accuracy=0.762109, train/loss=0.941323, validation/accuracy=0.692000, validation/loss=1.251310, validation/num_examples=50000
I0915 08:44:36.969859 139640336475904 logging_writer.py:48] [62000] global_step=62000, grad_norm=1.548434, loss=2.814046
I0915 08:44:36.975903 139684108298048 pytorch_submission_base.py:86] 62000) loss = 2.814, grad_norm = 1.548
I0915 08:47:59.932895 139639855773440 logging_writer.py:48] [62500] global_step=62500, grad_norm=1.595978, loss=2.528652
I0915 08:47:59.944381 139684108298048 pytorch_submission_base.py:86] 62500) loss = 2.529, grad_norm = 1.596
I0915 08:49:02.050367 139684108298048 spec.py:320] Evaluating on the training split.
I0915 08:49:47.944943 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 08:50:36.098428 139684108298048 spec.py:348] Evaluating on the test split.
I0915 08:50:37.489089 139684108298048 submission_runner.py:376] Time since start: 31630.51s, 	Step: 62646, 	{'train/accuracy': 0.76513671875, 'train/loss': 0.923326644897461, 'validation/accuracy': 0.6933, 'validation/loss': 1.23762875, 'validation/num_examples': 50000, 'test/accuracy': 0.575, 'test/loss': 1.8524271484375, 'test/num_examples': 10000, 'score': 25623.434438943863, 'total_duration': 31630.51397585869, 'accumulated_submission_time': 25623.434438943863, 'accumulated_eval_time': 5866.934550285339, 'accumulated_logging_time': 1.8117358684539795}
I0915 08:50:37.512864 139640336475904 logging_writer.py:48] [62646] accumulated_eval_time=5866.934550, accumulated_logging_time=1.811736, accumulated_submission_time=25623.434439, global_step=62646, preemption_count=0, score=25623.434439, test/accuracy=0.575000, test/loss=1.852427, test/num_examples=10000, total_duration=31630.513976, train/accuracy=0.765137, train/loss=0.923327, validation/accuracy=0.693300, validation/loss=1.237629, validation/num_examples=50000
I0915 08:53:02.543447 139639855773440 logging_writer.py:48] [63000] global_step=63000, grad_norm=1.434379, loss=2.324774
I0915 08:53:02.549520 139684108298048 pytorch_submission_base.py:86] 63000) loss = 2.325, grad_norm = 1.434
I0915 08:56:25.663346 139640336475904 logging_writer.py:48] [63500] global_step=63500, grad_norm=1.550427, loss=2.417400
I0915 08:56:25.668368 139684108298048 pytorch_submission_base.py:86] 63500) loss = 2.417, grad_norm = 1.550
I0915 08:57:38.608234 139684108298048 spec.py:320] Evaluating on the training split.
I0915 08:58:23.702045 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 08:59:12.740042 139684108298048 spec.py:348] Evaluating on the test split.
I0915 08:59:14.131509 139684108298048 submission_runner.py:376] Time since start: 32147.16s, 	Step: 63678, 	{'train/accuracy': 0.76783203125, 'train/loss': 0.9318679809570313, 'validation/accuracy': 0.6958, 'validation/loss': 1.23982125, 'validation/num_examples': 50000, 'test/accuracy': 0.5728, 'test/loss': 1.8615568359375, 'test/num_examples': 10000, 'score': 26042.256200551987, 'total_duration': 32147.156406402588, 'accumulated_submission_time': 26042.256200551987, 'accumulated_eval_time': 5962.458073854446, 'accumulated_logging_time': 1.8441426753997803}
I0915 08:59:14.156514 139639855773440 logging_writer.py:48] [63678] accumulated_eval_time=5962.458074, accumulated_logging_time=1.844143, accumulated_submission_time=26042.256201, global_step=63678, preemption_count=0, score=26042.256201, test/accuracy=0.572800, test/loss=1.861557, test/num_examples=10000, total_duration=32147.156406, train/accuracy=0.767832, train/loss=0.931868, validation/accuracy=0.695800, validation/loss=1.239821, validation/num_examples=50000
I0915 09:01:28.233100 139640336475904 logging_writer.py:48] [64000] global_step=64000, grad_norm=1.395748, loss=2.474624
I0915 09:01:28.238024 139684108298048 pytorch_submission_base.py:86] 64000) loss = 2.475, grad_norm = 1.396
I0915 09:04:51.578397 139639855773440 logging_writer.py:48] [64500] global_step=64500, grad_norm=1.566035, loss=2.280623
I0915 09:04:51.584943 139684108298048 pytorch_submission_base.py:86] 64500) loss = 2.281, grad_norm = 1.566
I0915 09:06:15.365592 139684108298048 spec.py:320] Evaluating on the training split.
I0915 09:06:59.366060 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 09:07:47.530038 139684108298048 spec.py:348] Evaluating on the test split.
I0915 09:07:48.919756 139684108298048 submission_runner.py:376] Time since start: 32661.94s, 	Step: 64705, 	{'train/accuracy': 0.77521484375, 'train/loss': 0.8806224060058594, 'validation/accuracy': 0.70328, 'validation/loss': 1.195711328125, 'validation/num_examples': 50000, 'test/accuracy': 0.5759, 'test/loss': 1.837216796875, 'test/num_examples': 10000, 'score': 26461.22221827507, 'total_duration': 32661.944671869278, 'accumulated_submission_time': 26461.22221827507, 'accumulated_eval_time': 6056.012538909912, 'accumulated_logging_time': 1.878692865371704}
I0915 09:07:48.940987 139640336475904 logging_writer.py:48] [64705] accumulated_eval_time=6056.012539, accumulated_logging_time=1.878693, accumulated_submission_time=26461.222218, global_step=64705, preemption_count=0, score=26461.222218, test/accuracy=0.575900, test/loss=1.837217, test/num_examples=10000, total_duration=32661.944672, train/accuracy=0.775215, train/loss=0.880622, validation/accuracy=0.703280, validation/loss=1.195711, validation/num_examples=50000
I0915 09:09:50.395437 139639855773440 logging_writer.py:48] [65000] global_step=65000, grad_norm=1.576485, loss=2.311377
I0915 09:09:50.401211 139684108298048 pytorch_submission_base.py:86] 65000) loss = 2.311, grad_norm = 1.576
I0915 09:13:16.086760 139640336475904 logging_writer.py:48] [65500] global_step=65500, grad_norm=1.590880, loss=2.473520
I0915 09:13:16.092598 139684108298048 pytorch_submission_base.py:86] 65500) loss = 2.474, grad_norm = 1.591
I0915 09:14:50.095832 139684108298048 spec.py:320] Evaluating on the training split.
I0915 09:15:35.551206 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 09:16:20.892766 139684108298048 spec.py:348] Evaluating on the test split.
I0915 09:16:22.284181 139684108298048 submission_runner.py:376] Time since start: 33175.31s, 	Step: 65730, 	{'train/accuracy': 0.769765625, 'train/loss': 0.9068109893798828, 'validation/accuracy': 0.70006, 'validation/loss': 1.21876890625, 'validation/num_examples': 50000, 'test/accuracy': 0.5818, 'test/loss': 1.8299978515625, 'test/num_examples': 10000, 'score': 26880.17323231697, 'total_duration': 33175.3090736866, 'accumulated_submission_time': 26880.17323231697, 'accumulated_eval_time': 6148.201342344284, 'accumulated_logging_time': 1.9110901355743408}
I0915 09:16:22.306528 139639855773440 logging_writer.py:48] [65730] accumulated_eval_time=6148.201342, accumulated_logging_time=1.911090, accumulated_submission_time=26880.173232, global_step=65730, preemption_count=0, score=26880.173232, test/accuracy=0.581800, test/loss=1.829998, test/num_examples=10000, total_duration=33175.309074, train/accuracy=0.769766, train/loss=0.906811, validation/accuracy=0.700060, validation/loss=1.218769, validation/num_examples=50000
I0915 09:18:12.782145 139640336475904 logging_writer.py:48] [66000] global_step=66000, grad_norm=1.546180, loss=2.583704
I0915 09:18:12.788354 139684108298048 pytorch_submission_base.py:86] 66000) loss = 2.584, grad_norm = 1.546
I0915 09:21:38.685783 139639855773440 logging_writer.py:48] [66500] global_step=66500, grad_norm=1.578553, loss=2.380106
I0915 09:21:38.691610 139684108298048 pytorch_submission_base.py:86] 66500) loss = 2.380, grad_norm = 1.579
I0915 09:23:23.656806 139684108298048 spec.py:320] Evaluating on the training split.
I0915 09:24:08.038578 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 09:24:53.545525 139684108298048 spec.py:348] Evaluating on the test split.
I0915 09:24:54.938303 139684108298048 submission_runner.py:376] Time since start: 33687.96s, 	Step: 66756, 	{'train/accuracy': 0.77423828125, 'train/loss': 0.8891181945800781, 'validation/accuracy': 0.70232, 'validation/loss': 1.2098209375, 'validation/num_examples': 50000, 'test/accuracy': 0.5729, 'test/loss': 1.8335244140625, 'test/num_examples': 10000, 'score': 27299.25323200226, 'total_duration': 33687.96317720413, 'accumulated_submission_time': 27299.25323200226, 'accumulated_eval_time': 6239.483256816864, 'accumulated_logging_time': 1.944244623184204}
I0915 09:24:54.961891 139640336475904 logging_writer.py:48] [66756] accumulated_eval_time=6239.483257, accumulated_logging_time=1.944245, accumulated_submission_time=27299.253232, global_step=66756, preemption_count=0, score=27299.253232, test/accuracy=0.572900, test/loss=1.833524, test/num_examples=10000, total_duration=33687.963177, train/accuracy=0.774238, train/loss=0.889118, validation/accuracy=0.702320, validation/loss=1.209821, validation/num_examples=50000
I0915 09:26:35.047634 139639855773440 logging_writer.py:48] [67000] global_step=67000, grad_norm=1.798585, loss=2.167221
I0915 09:26:35.052400 139684108298048 pytorch_submission_base.py:86] 67000) loss = 2.167, grad_norm = 1.799
I0915 09:29:58.370576 139640336475904 logging_writer.py:48] [67500] global_step=67500, grad_norm=1.571789, loss=2.836280
I0915 09:29:58.377266 139684108298048 pytorch_submission_base.py:86] 67500) loss = 2.836, grad_norm = 1.572
I0915 09:31:56.075656 139684108298048 spec.py:320] Evaluating on the training split.
I0915 09:32:41.122288 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 09:33:26.567245 139684108298048 spec.py:348] Evaluating on the test split.
I0915 09:33:27.959064 139684108298048 submission_runner.py:376] Time since start: 34200.98s, 	Step: 67783, 	{'train/accuracy': 0.7783203125, 'train/loss': 0.8725881195068359, 'validation/accuracy': 0.70516, 'validation/loss': 1.19554578125, 'validation/num_examples': 50000, 'test/accuracy': 0.5862, 'test/loss': 1.813583203125, 'test/num_examples': 10000, 'score': 27718.129616498947, 'total_duration': 34200.9839553833, 'accumulated_submission_time': 27718.129616498947, 'accumulated_eval_time': 6331.366873025894, 'accumulated_logging_time': 1.9765729904174805}
I0915 09:33:27.980317 139639855773440 logging_writer.py:48] [67783] accumulated_eval_time=6331.366873, accumulated_logging_time=1.976573, accumulated_submission_time=27718.129616, global_step=67783, preemption_count=0, score=27718.129616, test/accuracy=0.586200, test/loss=1.813583, test/num_examples=10000, total_duration=34200.983955, train/accuracy=0.778320, train/loss=0.872588, validation/accuracy=0.705160, validation/loss=1.195546, validation/num_examples=50000
I0915 09:34:57.306720 139640336475904 logging_writer.py:48] [68000] global_step=68000, grad_norm=1.498054, loss=2.257973
I0915 09:34:57.312865 139684108298048 pytorch_submission_base.py:86] 68000) loss = 2.258, grad_norm = 1.498
I0915 09:38:20.187099 139639855773440 logging_writer.py:48] [68500] global_step=68500, grad_norm=1.552722, loss=2.285471
I0915 09:38:20.194046 139684108298048 pytorch_submission_base.py:86] 68500) loss = 2.285, grad_norm = 1.553
I0915 09:40:29.332079 139684108298048 spec.py:320] Evaluating on the training split.
I0915 09:41:14.906433 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 09:42:03.344164 139684108298048 spec.py:348] Evaluating on the test split.
I0915 09:42:04.736784 139684108298048 submission_runner.py:376] Time since start: 34717.76s, 	Step: 68808, 	{'train/accuracy': 0.77986328125, 'train/loss': 0.8611705017089843, 'validation/accuracy': 0.7064, 'validation/loss': 1.18319203125, 'validation/num_examples': 50000, 'test/accuracy': 0.5909, 'test/loss': 1.7825927734375, 'test/num_examples': 10000, 'score': 28137.16416478157, 'total_duration': 34717.76166844368, 'accumulated_submission_time': 28137.16416478157, 'accumulated_eval_time': 6426.771734952927, 'accumulated_logging_time': 2.007922410964966}
I0915 09:42:04.758161 139640336475904 logging_writer.py:48] [68808] accumulated_eval_time=6426.771735, accumulated_logging_time=2.007922, accumulated_submission_time=28137.164165, global_step=68808, preemption_count=0, score=28137.164165, test/accuracy=0.590900, test/loss=1.782593, test/num_examples=10000, total_duration=34717.761668, train/accuracy=0.779863, train/loss=0.861171, validation/accuracy=0.706400, validation/loss=1.183192, validation/num_examples=50000
I0915 09:43:24.068920 139639855773440 logging_writer.py:48] [69000] global_step=69000, grad_norm=1.545794, loss=2.521198
I0915 09:43:24.073937 139684108298048 pytorch_submission_base.py:86] 69000) loss = 2.521, grad_norm = 1.546
I0915 09:46:47.584236 139640336475904 logging_writer.py:48] [69500] global_step=69500, grad_norm=1.582417, loss=2.466902
I0915 09:46:47.590114 139684108298048 pytorch_submission_base.py:86] 69500) loss = 2.467, grad_norm = 1.582
I0915 09:49:05.970268 139684108298048 spec.py:320] Evaluating on the training split.
I0915 09:49:49.919500 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 09:50:41.968614 139684108298048 spec.py:348] Evaluating on the test split.
I0915 09:50:43.360170 139684108298048 submission_runner.py:376] Time since start: 35236.39s, 	Step: 69838, 	{'train/accuracy': 0.78333984375, 'train/loss': 0.8550749206542969, 'validation/accuracy': 0.70844, 'validation/loss': 1.1818190625, 'validation/num_examples': 50000, 'test/accuracy': 0.5906, 'test/loss': 1.7930822265625, 'test/num_examples': 10000, 'score': 28556.108570337296, 'total_duration': 35236.38508224487, 'accumulated_submission_time': 28556.108570337296, 'accumulated_eval_time': 6524.1618065834045, 'accumulated_logging_time': 2.039173126220703}
I0915 09:50:43.384605 139639855773440 logging_writer.py:48] [69838] accumulated_eval_time=6524.161807, accumulated_logging_time=2.039173, accumulated_submission_time=28556.108570, global_step=69838, preemption_count=0, score=28556.108570, test/accuracy=0.590600, test/loss=1.793082, test/num_examples=10000, total_duration=35236.385082, train/accuracy=0.783340, train/loss=0.855075, validation/accuracy=0.708440, validation/loss=1.181819, validation/num_examples=50000
I0915 09:51:50.405215 139640336475904 logging_writer.py:48] [70000] global_step=70000, grad_norm=1.766929, loss=2.445459
I0915 09:51:50.411493 139684108298048 pytorch_submission_base.py:86] 70000) loss = 2.445, grad_norm = 1.767
I0915 09:55:15.990849 139639855773440 logging_writer.py:48] [70500] global_step=70500, grad_norm=1.612118, loss=2.114904
I0915 09:55:15.996865 139684108298048 pytorch_submission_base.py:86] 70500) loss = 2.115, grad_norm = 1.612
I0915 09:57:44.560577 139684108298048 spec.py:320] Evaluating on the training split.
I0915 09:58:28.747670 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 09:59:16.763433 139684108298048 spec.py:348] Evaluating on the test split.
I0915 09:59:18.157224 139684108298048 submission_runner.py:376] Time since start: 35751.18s, 	Step: 70864, 	{'train/accuracy': 0.7821875, 'train/loss': 0.8429695129394531, 'validation/accuracy': 0.70874, 'validation/loss': 1.169748828125, 'validation/num_examples': 50000, 'test/accuracy': 0.5877, 'test/loss': 1.7950474609375, 'test/num_examples': 10000, 'score': 28975.005259752274, 'total_duration': 35751.1821539402, 'accumulated_submission_time': 28975.005259752274, 'accumulated_eval_time': 6617.758754014969, 'accumulated_logging_time': 2.0743002891540527}
I0915 09:59:18.179810 139640336475904 logging_writer.py:48] [70864] accumulated_eval_time=6617.758754, accumulated_logging_time=2.074300, accumulated_submission_time=28975.005260, global_step=70864, preemption_count=0, score=28975.005260, test/accuracy=0.587700, test/loss=1.795047, test/num_examples=10000, total_duration=35751.182154, train/accuracy=0.782188, train/loss=0.842970, validation/accuracy=0.708740, validation/loss=1.169749, validation/num_examples=50000
I0915 10:00:14.571475 139639855773440 logging_writer.py:48] [71000] global_step=71000, grad_norm=1.622104, loss=1.986598
I0915 10:00:14.577599 139684108298048 pytorch_submission_base.py:86] 71000) loss = 1.987, grad_norm = 1.622
I0915 10:03:41.209069 139640336475904 logging_writer.py:48] [71500] global_step=71500, grad_norm=1.572792, loss=2.332320
I0915 10:03:41.215448 139684108298048 pytorch_submission_base.py:86] 71500) loss = 2.332, grad_norm = 1.573
I0915 10:06:19.467878 139684108298048 spec.py:320] Evaluating on the training split.
I0915 10:07:03.564045 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 10:07:49.011705 139684108298048 spec.py:348] Evaluating on the test split.
I0915 10:07:50.402193 139684108298048 submission_runner.py:376] Time since start: 36263.43s, 	Step: 71887, 	{'train/accuracy': 0.7875, 'train/loss': 0.8254187774658203, 'validation/accuracy': 0.71152, 'validation/loss': 1.15254625, 'validation/num_examples': 50000, 'test/accuracy': 0.5847, 'test/loss': 1.7886955078125, 'test/num_examples': 10000, 'score': 29394.01382470131, 'total_duration': 36263.42708301544, 'accumulated_submission_time': 29394.01382470131, 'accumulated_eval_time': 6708.693472862244, 'accumulated_logging_time': 2.1059341430664062}
I0915 10:07:50.422833 139639855773440 logging_writer.py:48] [71887] accumulated_eval_time=6708.693473, accumulated_logging_time=2.105934, accumulated_submission_time=29394.013825, global_step=71887, preemption_count=0, score=29394.013825, test/accuracy=0.584700, test/loss=1.788696, test/num_examples=10000, total_duration=36263.427083, train/accuracy=0.787500, train/loss=0.825419, validation/accuracy=0.711520, validation/loss=1.152546, validation/num_examples=50000
I0915 10:08:37.342175 139640336475904 logging_writer.py:48] [72000] global_step=72000, grad_norm=1.534222, loss=2.686659
I0915 10:08:37.347543 139684108298048 pytorch_submission_base.py:86] 72000) loss = 2.687, grad_norm = 1.534
I0915 10:12:00.630755 139639855773440 logging_writer.py:48] [72500] global_step=72500, grad_norm=1.599231, loss=2.307428
I0915 10:12:00.637588 139684108298048 pytorch_submission_base.py:86] 72500) loss = 2.307, grad_norm = 1.599
I0915 10:14:51.661597 139684108298048 spec.py:320] Evaluating on the training split.
I0915 10:15:35.979983 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 10:16:21.302022 139684108298048 spec.py:348] Evaluating on the test split.
I0915 10:16:22.696151 139684108298048 submission_runner.py:376] Time since start: 36775.72s, 	Step: 72913, 	{'train/accuracy': 0.78673828125, 'train/loss': 0.8305644226074219, 'validation/accuracy': 0.71048, 'validation/loss': 1.1581178125, 'validation/num_examples': 50000, 'test/accuracy': 0.5843, 'test/loss': 1.7768400390625, 'test/num_examples': 10000, 'score': 29812.978860378265, 'total_duration': 36775.72098135948, 'accumulated_submission_time': 29812.978860378265, 'accumulated_eval_time': 6799.728086709976, 'accumulated_logging_time': 2.136329412460327}
I0915 10:16:22.721290 139640336475904 logging_writer.py:48] [72913] accumulated_eval_time=6799.728087, accumulated_logging_time=2.136329, accumulated_submission_time=29812.978860, global_step=72913, preemption_count=0, score=29812.978860, test/accuracy=0.584300, test/loss=1.776840, test/num_examples=10000, total_duration=36775.720981, train/accuracy=0.786738, train/loss=0.830564, validation/accuracy=0.710480, validation/loss=1.158118, validation/num_examples=50000
I0915 10:16:59.347052 139639855773440 logging_writer.py:48] [73000] global_step=73000, grad_norm=1.639475, loss=2.136225
I0915 10:16:59.351804 139684108298048 pytorch_submission_base.py:86] 73000) loss = 2.136, grad_norm = 1.639
I0915 10:20:22.684844 139640336475904 logging_writer.py:48] [73500] global_step=73500, grad_norm=1.695921, loss=2.091559
I0915 10:20:22.690128 139684108298048 pytorch_submission_base.py:86] 73500) loss = 2.092, grad_norm = 1.696
I0915 10:23:23.794218 139684108298048 spec.py:320] Evaluating on the training split.
I0915 10:24:10.059392 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 10:24:57.940021 139684108298048 spec.py:348] Evaluating on the test split.
I0915 10:24:59.332689 139684108298048 submission_runner.py:376] Time since start: 37292.36s, 	Step: 73938, 	{'train/accuracy': 0.79138671875, 'train/loss': 0.8088320159912109, 'validation/accuracy': 0.71224, 'validation/loss': 1.15182890625, 'validation/num_examples': 50000, 'test/accuracy': 0.5842, 'test/loss': 1.786330078125, 'test/num_examples': 10000, 'score': 30231.840370178223, 'total_duration': 37292.357573747635, 'accumulated_submission_time': 30231.840370178223, 'accumulated_eval_time': 6895.266906499863, 'accumulated_logging_time': 2.171018123626709}
I0915 10:24:59.354156 139639855773440 logging_writer.py:48] [73938] accumulated_eval_time=6895.266906, accumulated_logging_time=2.171018, accumulated_submission_time=30231.840370, global_step=73938, preemption_count=0, score=30231.840370, test/accuracy=0.584200, test/loss=1.786330, test/num_examples=10000, total_duration=37292.357574, train/accuracy=0.791387, train/loss=0.808832, validation/accuracy=0.712240, validation/loss=1.151829, validation/num_examples=50000
I0915 10:25:25.700920 139640336475904 logging_writer.py:48] [74000] global_step=74000, grad_norm=1.769222, loss=1.874916
I0915 10:25:25.704852 139684108298048 pytorch_submission_base.py:86] 74000) loss = 1.875, grad_norm = 1.769
I0915 10:28:48.804970 139639855773440 logging_writer.py:48] [74500] global_step=74500, grad_norm=1.551028, loss=2.700250
I0915 10:28:48.810563 139684108298048 pytorch_submission_base.py:86] 74500) loss = 2.700, grad_norm = 1.551
I0915 10:32:00.441700 139684108298048 spec.py:320] Evaluating on the training split.
I0915 10:32:45.482196 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 10:33:34.001380 139684108298048 spec.py:348] Evaluating on the test split.
I0915 10:33:35.395712 139684108298048 submission_runner.py:376] Time since start: 37808.42s, 	Step: 74970, 	{'train/accuracy': 0.79078125, 'train/loss': 0.8062158966064453, 'validation/accuracy': 0.71454, 'validation/loss': 1.134965234375, 'validation/num_examples': 50000, 'test/accuracy': 0.5893, 'test/loss': 1.7789875, 'test/num_examples': 10000, 'score': 30650.588718891144, 'total_duration': 37808.42060470581, 'accumulated_submission_time': 30650.588718891144, 'accumulated_eval_time': 6990.221202373505, 'accumulated_logging_time': 2.205861806869507}
I0915 10:33:35.418006 139640336475904 logging_writer.py:48] [74970] accumulated_eval_time=6990.221202, accumulated_logging_time=2.205862, accumulated_submission_time=30650.588719, global_step=74970, preemption_count=0, score=30650.588719, test/accuracy=0.589300, test/loss=1.778987, test/num_examples=10000, total_duration=37808.420605, train/accuracy=0.790781, train/loss=0.806216, validation/accuracy=0.714540, validation/loss=1.134965, validation/num_examples=50000
I0915 10:33:48.755520 139639855773440 logging_writer.py:48] [75000] global_step=75000, grad_norm=1.665483, loss=2.432520
I0915 10:33:48.761687 139684108298048 pytorch_submission_base.py:86] 75000) loss = 2.433, grad_norm = 1.665
I0915 10:37:14.276049 139640336475904 logging_writer.py:48] [75500] global_step=75500, grad_norm=1.746459, loss=2.519032
I0915 10:37:14.280779 139684108298048 pytorch_submission_base.py:86] 75500) loss = 2.519, grad_norm = 1.746
I0915 10:40:36.595074 139684108298048 spec.py:320] Evaluating on the training split.
I0915 10:41:20.826230 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 10:42:10.044980 139684108298048 spec.py:348] Evaluating on the test split.
I0915 10:42:11.434082 139684108298048 submission_runner.py:376] Time since start: 38324.46s, 	Step: 75997, 	{'train/accuracy': 0.79373046875, 'train/loss': 0.8122936248779297, 'validation/accuracy': 0.71508, 'validation/loss': 1.150066328125, 'validation/num_examples': 50000, 'test/accuracy': 0.5952, 'test/loss': 1.75751640625, 'test/num_examples': 10000, 'score': 31069.47411108017, 'total_duration': 38324.45893573761, 'accumulated_submission_time': 31069.47411108017, 'accumulated_eval_time': 7085.0603058338165, 'accumulated_logging_time': 2.238262414932251}
I0915 10:42:11.457078 139639855773440 logging_writer.py:48] [75997] accumulated_eval_time=7085.060306, accumulated_logging_time=2.238262, accumulated_submission_time=31069.474111, global_step=75997, preemption_count=0, score=31069.474111, test/accuracy=0.595200, test/loss=1.757516, test/num_examples=10000, total_duration=38324.458936, train/accuracy=0.793730, train/loss=0.812294, validation/accuracy=0.715080, validation/loss=1.150066, validation/num_examples=50000
I0915 10:42:13.898002 139640336475904 logging_writer.py:48] [76000] global_step=76000, grad_norm=1.637140, loss=1.832834
I0915 10:42:13.906006 139684108298048 pytorch_submission_base.py:86] 76000) loss = 1.833, grad_norm = 1.637
I0915 10:45:39.510964 139639855773440 logging_writer.py:48] [76500] global_step=76500, grad_norm=1.667542, loss=2.436783
I0915 10:45:39.517075 139684108298048 pytorch_submission_base.py:86] 76500) loss = 2.437, grad_norm = 1.668
I0915 10:49:02.617406 139640336475904 logging_writer.py:48] [77000] global_step=77000, grad_norm=1.767363, loss=2.031931
I0915 10:49:02.624241 139684108298048 pytorch_submission_base.py:86] 77000) loss = 2.032, grad_norm = 1.767
I0915 10:49:12.632174 139684108298048 spec.py:320] Evaluating on the training split.
I0915 10:49:58.797940 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 10:50:44.041138 139684108298048 spec.py:348] Evaluating on the test split.
I0915 10:50:45.436352 139684108298048 submission_runner.py:376] Time since start: 38838.46s, 	Step: 77023, 	{'train/accuracy': 0.7943359375, 'train/loss': 0.7987835693359375, 'validation/accuracy': 0.72036, 'validation/loss': 1.1305715625, 'validation/num_examples': 50000, 'test/accuracy': 0.5972, 'test/loss': 1.7504921875, 'test/num_examples': 10000, 'score': 31488.35825395584, 'total_duration': 38838.461253643036, 'accumulated_submission_time': 31488.35825395584, 'accumulated_eval_time': 7177.864827632904, 'accumulated_logging_time': 2.272787570953369}
I0915 10:50:45.458578 139639855773440 logging_writer.py:48] [77023] accumulated_eval_time=7177.864828, accumulated_logging_time=2.272788, accumulated_submission_time=31488.358254, global_step=77023, preemption_count=0, score=31488.358254, test/accuracy=0.597200, test/loss=1.750492, test/num_examples=10000, total_duration=38838.461254, train/accuracy=0.794336, train/loss=0.798784, validation/accuracy=0.720360, validation/loss=1.130572, validation/num_examples=50000
I0915 10:54:00.664886 139640336475904 logging_writer.py:48] [77500] global_step=77500, grad_norm=1.997661, loss=2.202488
I0915 10:54:00.670977 139684108298048 pytorch_submission_base.py:86] 77500) loss = 2.202, grad_norm = 1.998
I0915 10:57:27.031810 139639855773440 logging_writer.py:48] [78000] global_step=78000, grad_norm=1.788028, loss=2.241559
I0915 10:57:27.042140 139684108298048 pytorch_submission_base.py:86] 78000) loss = 2.242, grad_norm = 1.788
I0915 10:57:46.836834 139684108298048 spec.py:320] Evaluating on the training split.
I0915 10:58:30.867995 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 10:59:16.588047 139684108298048 spec.py:348] Evaluating on the test split.
I0915 10:59:17.982218 139684108298048 submission_runner.py:376] Time since start: 39351.01s, 	Step: 78047, 	{'train/accuracy': 0.79896484375, 'train/loss': 0.7716001892089843, 'validation/accuracy': 0.72158, 'validation/loss': 1.11550796875, 'validation/num_examples': 50000, 'test/accuracy': 0.5954, 'test/loss': 1.7397462890625, 'test/num_examples': 10000, 'score': 31907.538328886032, 'total_duration': 39351.00712752342, 'accumulated_submission_time': 31907.538328886032, 'accumulated_eval_time': 7269.010290622711, 'accumulated_logging_time': 2.3038971424102783}
I0915 10:59:18.007848 139640336475904 logging_writer.py:48] [78047] accumulated_eval_time=7269.010291, accumulated_logging_time=2.303897, accumulated_submission_time=31907.538329, global_step=78047, preemption_count=0, score=31907.538329, test/accuracy=0.595400, test/loss=1.739746, test/num_examples=10000, total_duration=39351.007128, train/accuracy=0.798965, train/loss=0.771600, validation/accuracy=0.721580, validation/loss=1.115508, validation/num_examples=50000
I0915 11:02:22.854086 139639855773440 logging_writer.py:48] [78500] global_step=78500, grad_norm=1.724393, loss=2.472315
I0915 11:02:22.865094 139684108298048 pytorch_submission_base.py:86] 78500) loss = 2.472, grad_norm = 1.724
I0915 11:05:49.438979 139640336475904 logging_writer.py:48] [79000] global_step=79000, grad_norm=1.793943, loss=2.124998
I0915 11:05:49.443712 139684108298048 pytorch_submission_base.py:86] 79000) loss = 2.125, grad_norm = 1.794
I0915 11:06:19.352984 139684108298048 spec.py:320] Evaluating on the training split.
I0915 11:07:04.257546 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 11:07:49.507127 139684108298048 spec.py:348] Evaluating on the test split.
I0915 11:07:50.898041 139684108298048 submission_runner.py:376] Time since start: 39863.92s, 	Step: 79072, 	{'train/accuracy': 0.7980859375, 'train/loss': 0.7937019348144532, 'validation/accuracy': 0.72054, 'validation/loss': 1.129514375, 'validation/num_examples': 50000, 'test/accuracy': 0.6029, 'test/loss': 1.733080859375, 'test/num_examples': 10000, 'score': 32326.615975618362, 'total_duration': 39863.92292165756, 'accumulated_submission_time': 32326.615975618362, 'accumulated_eval_time': 7360.5557696819305, 'accumulated_logging_time': 2.3390791416168213}
I0915 11:07:50.920437 139639855773440 logging_writer.py:48] [79072] accumulated_eval_time=7360.555770, accumulated_logging_time=2.339079, accumulated_submission_time=32326.615976, global_step=79072, preemption_count=0, score=32326.615976, test/accuracy=0.602900, test/loss=1.733081, test/num_examples=10000, total_duration=39863.922922, train/accuracy=0.798086, train/loss=0.793702, validation/accuracy=0.720540, validation/loss=1.129514, validation/num_examples=50000
I0915 11:10:46.059874 139640336475904 logging_writer.py:48] [79500] global_step=79500, grad_norm=1.926770, loss=2.570907
I0915 11:10:46.067277 139684108298048 pytorch_submission_base.py:86] 79500) loss = 2.571, grad_norm = 1.927
I0915 11:14:10.122940 139639855773440 logging_writer.py:48] [80000] global_step=80000, grad_norm=1.748634, loss=2.515539
I0915 11:14:10.128098 139684108298048 pytorch_submission_base.py:86] 80000) loss = 2.516, grad_norm = 1.749
I0915 11:14:52.234239 139684108298048 spec.py:320] Evaluating on the training split.
I0915 11:15:38.112481 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 11:16:26.915560 139684108298048 spec.py:348] Evaluating on the test split.
I0915 11:16:28.306150 139684108298048 submission_runner.py:376] Time since start: 40381.33s, 	Step: 80097, 	{'train/accuracy': 0.8038671875, 'train/loss': 0.7538491058349609, 'validation/accuracy': 0.7242, 'validation/loss': 1.10110515625, 'validation/num_examples': 50000, 'test/accuracy': 0.5963, 'test/loss': 1.72729921875, 'test/num_examples': 10000, 'score': 32745.75004172325, 'total_duration': 40381.33103609085, 'accumulated_submission_time': 32745.75004172325, 'accumulated_eval_time': 7456.628044128418, 'accumulated_logging_time': 2.3707242012023926}
I0915 11:16:28.329036 139640336475904 logging_writer.py:48] [80097] accumulated_eval_time=7456.628044, accumulated_logging_time=2.370724, accumulated_submission_time=32745.750042, global_step=80097, preemption_count=0, score=32745.750042, test/accuracy=0.596300, test/loss=1.727299, test/num_examples=10000, total_duration=40381.331036, train/accuracy=0.803867, train/loss=0.753849, validation/accuracy=0.724200, validation/loss=1.101105, validation/num_examples=50000
I0915 11:19:13.298704 139639855773440 logging_writer.py:48] [80500] global_step=80500, grad_norm=1.770902, loss=2.227353
I0915 11:19:13.306830 139684108298048 pytorch_submission_base.py:86] 80500) loss = 2.227, grad_norm = 1.771
I0915 11:22:36.206147 139640336475904 logging_writer.py:48] [81000] global_step=81000, grad_norm=1.799509, loss=2.302175
I0915 11:22:36.212006 139684108298048 pytorch_submission_base.py:86] 81000) loss = 2.302, grad_norm = 1.800
I0915 11:23:29.607008 139684108298048 spec.py:320] Evaluating on the training split.
I0915 11:24:14.433546 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 11:25:05.361690 139684108298048 spec.py:348] Evaluating on the test split.
I0915 11:25:06.753010 139684108298048 submission_runner.py:376] Time since start: 40899.78s, 	Step: 81129, 	{'train/accuracy': 0.80361328125, 'train/loss': 0.7598976135253906, 'validation/accuracy': 0.72414, 'validation/loss': 1.10761875, 'validation/num_examples': 50000, 'test/accuracy': 0.602, 'test/loss': 1.729073828125, 'test/num_examples': 10000, 'score': 33164.69205403328, 'total_duration': 40899.77792048454, 'accumulated_submission_time': 33164.69205403328, 'accumulated_eval_time': 7553.774738311768, 'accumulated_logging_time': 2.4024863243103027}
I0915 11:25:06.781301 139639855773440 logging_writer.py:48] [81129] accumulated_eval_time=7553.774738, accumulated_logging_time=2.402486, accumulated_submission_time=33164.692054, global_step=81129, preemption_count=0, score=33164.692054, test/accuracy=0.602000, test/loss=1.729074, test/num_examples=10000, total_duration=40899.777920, train/accuracy=0.803613, train/loss=0.759898, validation/accuracy=0.724140, validation/loss=1.107619, validation/num_examples=50000
I0915 11:27:41.067351 139640336475904 logging_writer.py:48] [81500] global_step=81500, grad_norm=1.889933, loss=2.254890
I0915 11:27:41.072208 139684108298048 pytorch_submission_base.py:86] 81500) loss = 2.255, grad_norm = 1.890
I0915 11:31:04.280130 139639855773440 logging_writer.py:48] [82000] global_step=82000, grad_norm=1.848637, loss=2.743588
I0915 11:31:04.285542 139684108298048 pytorch_submission_base.py:86] 82000) loss = 2.744, grad_norm = 1.849
I0915 11:32:08.067489 139684108298048 spec.py:320] Evaluating on the training split.
I0915 11:32:52.462554 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 11:33:38.271146 139684108298048 spec.py:348] Evaluating on the test split.
I0915 11:33:39.660887 139684108298048 submission_runner.py:376] Time since start: 41412.69s, 	Step: 82156, 	{'train/accuracy': 0.80603515625, 'train/loss': 0.7491520690917969, 'validation/accuracy': 0.72802, 'validation/loss': 1.094786015625, 'validation/num_examples': 50000, 'test/accuracy': 0.6042, 'test/loss': 1.704280078125, 'test/num_examples': 10000, 'score': 33583.65639710426, 'total_duration': 41412.68580532074, 'accumulated_submission_time': 33583.65639710426, 'accumulated_eval_time': 7645.3683960437775, 'accumulated_logging_time': 2.443277597427368}
I0915 11:33:39.683510 139640336475904 logging_writer.py:48] [82156] accumulated_eval_time=7645.368396, accumulated_logging_time=2.443278, accumulated_submission_time=33583.656397, global_step=82156, preemption_count=0, score=33583.656397, test/accuracy=0.604200, test/loss=1.704280, test/num_examples=10000, total_duration=41412.685805, train/accuracy=0.806035, train/loss=0.749152, validation/accuracy=0.728020, validation/loss=1.094786, validation/num_examples=50000
I0915 11:36:01.410204 139639855773440 logging_writer.py:48] [82500] global_step=82500, grad_norm=1.908102, loss=1.817749
I0915 11:36:01.416874 139684108298048 pytorch_submission_base.py:86] 82500) loss = 1.818, grad_norm = 1.908
I0915 11:39:27.013730 139640336475904 logging_writer.py:48] [83000] global_step=83000, grad_norm=1.722360, loss=2.287942
I0915 11:39:27.019799 139684108298048 pytorch_submission_base.py:86] 83000) loss = 2.288, grad_norm = 1.722
I0915 11:40:40.873022 139684108298048 spec.py:320] Evaluating on the training split.
I0915 11:41:25.205645 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 11:42:10.503707 139684108298048 spec.py:348] Evaluating on the test split.
I0915 11:42:11.895913 139684108298048 submission_runner.py:376] Time since start: 41924.92s, 	Step: 83180, 	{'train/accuracy': 0.8066015625, 'train/loss': 0.7520854187011718, 'validation/accuracy': 0.72758, 'validation/loss': 1.096599453125, 'validation/num_examples': 50000, 'test/accuracy': 0.6046, 'test/loss': 1.727405078125, 'test/num_examples': 10000, 'score': 34002.59331560135, 'total_duration': 41924.9207983017, 'accumulated_submission_time': 34002.59331560135, 'accumulated_eval_time': 7736.391632318497, 'accumulated_logging_time': 2.4783074855804443}
I0915 11:42:11.919582 139639855773440 logging_writer.py:48] [83180] accumulated_eval_time=7736.391632, accumulated_logging_time=2.478307, accumulated_submission_time=34002.593316, global_step=83180, preemption_count=0, score=34002.593316, test/accuracy=0.604600, test/loss=1.727405, test/num_examples=10000, total_duration=41924.920798, train/accuracy=0.806602, train/loss=0.752085, validation/accuracy=0.727580, validation/loss=1.096599, validation/num_examples=50000
I0915 11:44:22.763800 139640336475904 logging_writer.py:48] [83500] global_step=83500, grad_norm=1.945966, loss=2.306059
I0915 11:44:22.769341 139684108298048 pytorch_submission_base.py:86] 83500) loss = 2.306, grad_norm = 1.946
I0915 11:47:48.902791 139639855773440 logging_writer.py:48] [84000] global_step=84000, grad_norm=1.767329, loss=1.932225
I0915 11:47:48.911014 139684108298048 pytorch_submission_base.py:86] 84000) loss = 1.932, grad_norm = 1.767
I0915 11:49:13.155737 139684108298048 spec.py:320] Evaluating on the training split.
I0915 11:49:57.412394 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 11:50:42.854589 139684108298048 spec.py:348] Evaluating on the test split.
I0915 11:50:44.247873 139684108298048 submission_runner.py:376] Time since start: 42437.27s, 	Step: 84205, 	{'train/accuracy': 0.80888671875, 'train/loss': 0.7330381011962891, 'validation/accuracy': 0.72752, 'validation/loss': 1.084542109375, 'validation/num_examples': 50000, 'test/accuracy': 0.6036, 'test/loss': 1.715488671875, 'test/num_examples': 10000, 'score': 34421.58802652359, 'total_duration': 42437.272780656815, 'accumulated_submission_time': 34421.58802652359, 'accumulated_eval_time': 7827.484014034271, 'accumulated_logging_time': 2.514688730239868}
I0915 11:50:44.270147 139640336475904 logging_writer.py:48] [84205] accumulated_eval_time=7827.484014, accumulated_logging_time=2.514689, accumulated_submission_time=34421.588027, global_step=84205, preemption_count=0, score=34421.588027, test/accuracy=0.603600, test/loss=1.715489, test/num_examples=10000, total_duration=42437.272781, train/accuracy=0.808887, train/loss=0.733038, validation/accuracy=0.727520, validation/loss=1.084542, validation/num_examples=50000
I0915 11:52:45.178655 139639855773440 logging_writer.py:48] [84500] global_step=84500, grad_norm=1.739662, loss=2.104046
I0915 11:52:45.184156 139684108298048 pytorch_submission_base.py:86] 84500) loss = 2.104, grad_norm = 1.740
I0915 11:56:08.969845 139640336475904 logging_writer.py:48] [85000] global_step=85000, grad_norm=2.111903, loss=2.215455
I0915 11:56:08.977226 139684108298048 pytorch_submission_base.py:86] 85000) loss = 2.215, grad_norm = 2.112
I0915 11:57:45.475409 139684108298048 spec.py:320] Evaluating on the training split.
I0915 11:58:31.774491 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 11:59:19.457153 139684108298048 spec.py:348] Evaluating on the test split.
I0915 11:59:20.852267 139684108298048 submission_runner.py:376] Time since start: 42953.88s, 	Step: 85230, 	{'train/accuracy': 0.8105078125, 'train/loss': 0.7360984802246093, 'validation/accuracy': 0.72796, 'validation/loss': 1.091431875, 'validation/num_examples': 50000, 'test/accuracy': 0.607, 'test/loss': 1.71239609375, 'test/num_examples': 10000, 'score': 34840.57437419891, 'total_duration': 42953.87716841698, 'accumulated_submission_time': 34840.57437419891, 'accumulated_eval_time': 7922.861146450043, 'accumulated_logging_time': 2.5459437370300293}
I0915 11:59:20.880244 139639855773440 logging_writer.py:48] [85230] accumulated_eval_time=7922.861146, accumulated_logging_time=2.545944, accumulated_submission_time=34840.574374, global_step=85230, preemption_count=0, score=34840.574374, test/accuracy=0.607000, test/loss=1.712396, test/num_examples=10000, total_duration=42953.877168, train/accuracy=0.810508, train/loss=0.736098, validation/accuracy=0.727960, validation/loss=1.091432, validation/num_examples=50000
I0915 12:01:12.017346 139640336475904 logging_writer.py:48] [85500] global_step=85500, grad_norm=1.896378, loss=1.990636
I0915 12:01:12.022074 139684108298048 pytorch_submission_base.py:86] 85500) loss = 1.991, grad_norm = 1.896
I0915 12:04:34.862814 139639855773440 logging_writer.py:48] [86000] global_step=86000, grad_norm=1.869849, loss=1.899394
I0915 12:04:34.882887 139684108298048 pytorch_submission_base.py:86] 86000) loss = 1.899, grad_norm = 1.870
I0915 12:06:22.012081 139684108298048 spec.py:320] Evaluating on the training split.
I0915 12:07:07.509283 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 12:07:52.898228 139684108298048 spec.py:348] Evaluating on the test split.
I0915 12:07:54.289719 139684108298048 submission_runner.py:376] Time since start: 43467.31s, 	Step: 86260, 	{'train/accuracy': 0.8151171875, 'train/loss': 0.7176100158691406, 'validation/accuracy': 0.73178, 'validation/loss': 1.07604171875, 'validation/num_examples': 50000, 'test/accuracy': 0.6077, 'test/loss': 1.6872740234375, 'test/num_examples': 10000, 'score': 35259.4027056694, 'total_duration': 43467.31462955475, 'accumulated_submission_time': 35259.4027056694, 'accumulated_eval_time': 8015.13915014267, 'accumulated_logging_time': 2.583099126815796}
I0915 12:07:54.313919 139640336475904 logging_writer.py:48] [86260] accumulated_eval_time=8015.139150, accumulated_logging_time=2.583099, accumulated_submission_time=35259.402706, global_step=86260, preemption_count=0, score=35259.402706, test/accuracy=0.607700, test/loss=1.687274, test/num_examples=10000, total_duration=43467.314630, train/accuracy=0.815117, train/loss=0.717610, validation/accuracy=0.731780, validation/loss=1.076042, validation/num_examples=50000
I0915 12:09:35.066022 139639855773440 logging_writer.py:48] [86500] global_step=86500, grad_norm=1.870121, loss=1.951757
I0915 12:09:35.070551 139684108298048 pytorch_submission_base.py:86] 86500) loss = 1.952, grad_norm = 1.870
I0915 12:12:58.588255 139640336475904 logging_writer.py:48] [87000] global_step=87000, grad_norm=2.063671, loss=2.122296
I0915 12:12:58.595293 139684108298048 pytorch_submission_base.py:86] 87000) loss = 2.122, grad_norm = 2.064
I0915 12:14:55.729302 139684108298048 spec.py:320] Evaluating on the training split.
I0915 12:15:40.069008 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 12:16:32.624889 139684108298048 spec.py:348] Evaluating on the test split.
I0915 12:16:34.021911 139684108298048 submission_runner.py:376] Time since start: 43987.05s, 	Step: 87287, 	{'train/accuracy': 0.8182421875, 'train/loss': 0.691032943725586, 'validation/accuracy': 0.73526, 'validation/loss': 1.042140234375, 'validation/num_examples': 50000, 'test/accuracy': 0.6127, 'test/loss': 1.66265234375, 'test/num_examples': 10000, 'score': 35678.52847766876, 'total_duration': 43987.04681110382, 'accumulated_submission_time': 35678.52847766876, 'accumulated_eval_time': 8113.432203292847, 'accumulated_logging_time': 2.6161394119262695}
I0915 12:16:34.049335 139639855773440 logging_writer.py:48] [87287] accumulated_eval_time=8113.432203, accumulated_logging_time=2.616139, accumulated_submission_time=35678.528478, global_step=87287, preemption_count=0, score=35678.528478, test/accuracy=0.612700, test/loss=1.662652, test/num_examples=10000, total_duration=43987.046811, train/accuracy=0.818242, train/loss=0.691033, validation/accuracy=0.735260, validation/loss=1.042140, validation/num_examples=50000
I0915 12:18:01.606149 139640336475904 logging_writer.py:48] [87500] global_step=87500, grad_norm=1.988918, loss=2.304436
I0915 12:18:01.610625 139684108298048 pytorch_submission_base.py:86] 87500) loss = 2.304, grad_norm = 1.989
I0915 12:21:27.282598 139639855773440 logging_writer.py:48] [88000] global_step=88000, grad_norm=1.845588, loss=2.175851
I0915 12:21:27.293687 139684108298048 pytorch_submission_base.py:86] 88000) loss = 2.176, grad_norm = 1.846
I0915 12:23:35.145893 139684108298048 spec.py:320] Evaluating on the training split.
I0915 12:24:21.401921 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 12:25:07.358677 139684108298048 spec.py:348] Evaluating on the test split.
I0915 12:25:08.750522 139684108298048 submission_runner.py:376] Time since start: 44501.78s, 	Step: 88313, 	{'train/accuracy': 0.81748046875, 'train/loss': 0.7083558654785156, 'validation/accuracy': 0.73422, 'validation/loss': 1.066148046875, 'validation/num_examples': 50000, 'test/accuracy': 0.615, 'test/loss': 1.688865234375, 'test/num_examples': 10000, 'score': 36097.371693611145, 'total_duration': 44501.77542591095, 'accumulated_submission_time': 36097.371693611145, 'accumulated_eval_time': 8207.03715133667, 'accumulated_logging_time': 2.6535825729370117}
I0915 12:25:08.775268 139640336475904 logging_writer.py:48] [88313] accumulated_eval_time=8207.037151, accumulated_logging_time=2.653583, accumulated_submission_time=36097.371694, global_step=88313, preemption_count=0, score=36097.371694, test/accuracy=0.615000, test/loss=1.688865, test/num_examples=10000, total_duration=44501.775426, train/accuracy=0.817480, train/loss=0.708356, validation/accuracy=0.734220, validation/loss=1.066148, validation/num_examples=50000
I0915 12:26:25.704593 139639855773440 logging_writer.py:48] [88500] global_step=88500, grad_norm=1.933579, loss=2.424869
I0915 12:26:25.711711 139684108298048 pytorch_submission_base.py:86] 88500) loss = 2.425, grad_norm = 1.934
I0915 12:29:51.816076 139640336475904 logging_writer.py:48] [89000] global_step=89000, grad_norm=1.866705, loss=2.454774
I0915 12:29:51.822260 139684108298048 pytorch_submission_base.py:86] 89000) loss = 2.455, grad_norm = 1.867
I0915 12:32:09.892228 139684108298048 spec.py:320] Evaluating on the training split.
I0915 12:32:54.057630 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 12:33:39.322692 139684108298048 spec.py:348] Evaluating on the test split.
I0915 12:33:40.715975 139684108298048 submission_runner.py:376] Time since start: 45013.74s, 	Step: 89338, 	{'train/accuracy': 0.81900390625, 'train/loss': 0.6916342163085938, 'validation/accuracy': 0.73518, 'validation/loss': 1.058754921875, 'validation/num_examples': 50000, 'test/accuracy': 0.6123, 'test/loss': 1.681706640625, 'test/num_examples': 10000, 'score': 36516.20099759102, 'total_duration': 45013.740899801254, 'accumulated_submission_time': 36516.20099759102, 'accumulated_eval_time': 8297.861069917679, 'accumulated_logging_time': 2.6913037300109863}
I0915 12:33:40.740199 139639855773440 logging_writer.py:48] [89338] accumulated_eval_time=8297.861070, accumulated_logging_time=2.691304, accumulated_submission_time=36516.200998, global_step=89338, preemption_count=0, score=36516.200998, test/accuracy=0.612300, test/loss=1.681707, test/num_examples=10000, total_duration=45013.740900, train/accuracy=0.819004, train/loss=0.691634, validation/accuracy=0.735180, validation/loss=1.058755, validation/num_examples=50000
I0915 12:34:47.696088 139640336475904 logging_writer.py:48] [89500] global_step=89500, grad_norm=1.899313, loss=2.045064
I0915 12:34:47.701011 139684108298048 pytorch_submission_base.py:86] 89500) loss = 2.045, grad_norm = 1.899
I0915 12:38:11.035292 139639855773440 logging_writer.py:48] [90000] global_step=90000, grad_norm=1.939049, loss=2.404274
I0915 12:38:11.047759 139684108298048 pytorch_submission_base.py:86] 90000) loss = 2.404, grad_norm = 1.939
I0915 12:40:41.957784 139684108298048 spec.py:320] Evaluating on the training split.
I0915 12:41:26.651077 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 12:42:12.048249 139684108298048 spec.py:348] Evaluating on the test split.
I0915 12:42:13.441080 139684108298048 submission_runner.py:376] Time since start: 45526.47s, 	Step: 90363, 	{'train/accuracy': 0.82248046875, 'train/loss': 0.6818931579589844, 'validation/accuracy': 0.73754, 'validation/loss': 1.046389140625, 'validation/num_examples': 50000, 'test/accuracy': 0.618, 'test/loss': 1.653194921875, 'test/num_examples': 10000, 'score': 36935.12146925926, 'total_duration': 45526.46598315239, 'accumulated_submission_time': 36935.12146925926, 'accumulated_eval_time': 8389.344470262527, 'accumulated_logging_time': 2.727031707763672}
I0915 12:42:13.464330 139640336475904 logging_writer.py:48] [90363] accumulated_eval_time=8389.344470, accumulated_logging_time=2.727032, accumulated_submission_time=36935.121469, global_step=90363, preemption_count=0, score=36935.121469, test/accuracy=0.618000, test/loss=1.653195, test/num_examples=10000, total_duration=45526.465983, train/accuracy=0.822480, train/loss=0.681893, validation/accuracy=0.737540, validation/loss=1.046389, validation/num_examples=50000
I0915 12:43:10.238933 139639855773440 logging_writer.py:48] [90500] global_step=90500, grad_norm=1.794037, loss=1.931313
I0915 12:43:10.243700 139684108298048 pytorch_submission_base.py:86] 90500) loss = 1.931, grad_norm = 1.794
I0915 12:46:33.272082 139640336475904 logging_writer.py:48] [91000] global_step=91000, grad_norm=1.919529, loss=2.272823
I0915 12:46:33.280938 139684108298048 pytorch_submission_base.py:86] 91000) loss = 2.273, grad_norm = 1.920
I0915 12:49:14.449154 139684108298048 spec.py:320] Evaluating on the training split.
I0915 12:50:00.323577 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 12:50:51.042365 139684108298048 spec.py:348] Evaluating on the test split.
I0915 12:50:52.431564 139684108298048 submission_runner.py:376] Time since start: 46045.46s, 	Step: 91385, 	{'train/accuracy': 0.82365234375, 'train/loss': 0.6769486999511719, 'validation/accuracy': 0.73814, 'validation/loss': 1.042914375, 'validation/num_examples': 50000, 'test/accuracy': 0.6148, 'test/loss': 1.6550314453125, 'test/num_examples': 10000, 'score': 37353.9124147892, 'total_duration': 46045.45631933212, 'accumulated_submission_time': 37353.9124147892, 'accumulated_eval_time': 8487.327114582062, 'accumulated_logging_time': 2.7591471672058105}
I0915 12:50:52.457032 139639855773440 logging_writer.py:48] [91385] accumulated_eval_time=8487.327115, accumulated_logging_time=2.759147, accumulated_submission_time=37353.912415, global_step=91385, preemption_count=0, score=37353.912415, test/accuracy=0.614800, test/loss=1.655031, test/num_examples=10000, total_duration=46045.456319, train/accuracy=0.823652, train/loss=0.676949, validation/accuracy=0.738140, validation/loss=1.042914, validation/num_examples=50000
I0915 12:51:40.527306 139640336475904 logging_writer.py:48] [91500] global_step=91500, grad_norm=2.214866, loss=2.232997
I0915 12:51:40.531760 139684108298048 pytorch_submission_base.py:86] 91500) loss = 2.233, grad_norm = 2.215
I0915 12:55:03.509023 139639855773440 logging_writer.py:48] [92000] global_step=92000, grad_norm=2.031605, loss=2.243424
I0915 12:55:03.518110 139684108298048 pytorch_submission_base.py:86] 92000) loss = 2.243, grad_norm = 2.032
I0915 12:57:53.636651 139684108298048 spec.py:320] Evaluating on the training split.
I0915 12:58:38.609854 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 12:59:26.315409 139684108298048 spec.py:348] Evaluating on the test split.
I0915 12:59:27.706140 139684108298048 submission_runner.py:376] Time since start: 46560.73s, 	Step: 92417, 	{'train/accuracy': 0.82619140625, 'train/loss': 0.6655417633056641, 'validation/accuracy': 0.74098, 'validation/loss': 1.031601328125, 'validation/num_examples': 50000, 'test/accuracy': 0.6215, 'test/loss': 1.652606640625, 'test/num_examples': 10000, 'score': 37772.74341249466, 'total_duration': 46560.731041669846, 'accumulated_submission_time': 37772.74341249466, 'accumulated_eval_time': 8581.396768808365, 'accumulated_logging_time': 2.793741226196289}
I0915 12:59:27.736093 139640336475904 logging_writer.py:48] [92417] accumulated_eval_time=8581.396769, accumulated_logging_time=2.793741, accumulated_submission_time=37772.743412, global_step=92417, preemption_count=0, score=37772.743412, test/accuracy=0.621500, test/loss=1.652607, test/num_examples=10000, total_duration=46560.731042, train/accuracy=0.826191, train/loss=0.665542, validation/accuracy=0.740980, validation/loss=1.031601, validation/num_examples=50000
I0915 13:00:02.749802 139639855773440 logging_writer.py:48] [92500] global_step=92500, grad_norm=1.916103, loss=1.953136
I0915 13:00:02.756052 139684108298048 pytorch_submission_base.py:86] 92500) loss = 1.953, grad_norm = 1.916
I0915 13:03:28.275055 139640336475904 logging_writer.py:48] [93000] global_step=93000, grad_norm=2.020508, loss=1.949475
I0915 13:03:28.280516 139684108298048 pytorch_submission_base.py:86] 93000) loss = 1.949, grad_norm = 2.021
I0915 13:06:28.813323 139684108298048 spec.py:320] Evaluating on the training split.
I0915 13:07:12.978541 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 13:07:59.499076 139684108298048 spec.py:348] Evaluating on the test split.
I0915 13:08:00.893573 139684108298048 submission_runner.py:376] Time since start: 47073.92s, 	Step: 93443, 	{'train/accuracy': 0.8276953125, 'train/loss': 0.6588883972167969, 'validation/accuracy': 0.7413, 'validation/loss': 1.0315315625, 'validation/num_examples': 50000, 'test/accuracy': 0.6202, 'test/loss': 1.6444001953125, 'test/num_examples': 10000, 'score': 38191.541233778, 'total_duration': 47073.91848015785, 'accumulated_submission_time': 38191.541233778, 'accumulated_eval_time': 8673.477474451065, 'accumulated_logging_time': 2.8332974910736084}
I0915 13:08:00.920032 139639855773440 logging_writer.py:48] [93443] accumulated_eval_time=8673.477474, accumulated_logging_time=2.833297, accumulated_submission_time=38191.541234, global_step=93443, preemption_count=0, score=38191.541234, test/accuracy=0.620200, test/loss=1.644400, test/num_examples=10000, total_duration=47073.918480, train/accuracy=0.827695, train/loss=0.658888, validation/accuracy=0.741300, validation/loss=1.031532, validation/num_examples=50000
I0915 13:08:25.266230 139640336475904 logging_writer.py:48] [93500] global_step=93500, grad_norm=1.964297, loss=1.876363
I0915 13:08:25.271910 139684108298048 pytorch_submission_base.py:86] 93500) loss = 1.876, grad_norm = 1.964
I0915 13:11:51.678972 139639855773440 logging_writer.py:48] [94000] global_step=94000, grad_norm=2.103161, loss=2.127805
I0915 13:11:51.686023 139684108298048 pytorch_submission_base.py:86] 94000) loss = 2.128, grad_norm = 2.103
I0915 13:15:02.097085 139684108298048 spec.py:320] Evaluating on the training split.
I0915 13:15:46.235704 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 13:16:31.707306 139684108298048 spec.py:348] Evaluating on the test split.
I0915 13:16:33.100765 139684108298048 submission_runner.py:376] Time since start: 47586.13s, 	Step: 94467, 	{'train/accuracy': 0.83056640625, 'train/loss': 0.6573970031738281, 'validation/accuracy': 0.74218, 'validation/loss': 1.030728203125, 'validation/num_examples': 50000, 'test/accuracy': 0.621, 'test/loss': 1.64237421875, 'test/num_examples': 10000, 'score': 38610.51299524307, 'total_duration': 47586.12565422058, 'accumulated_submission_time': 38610.51299524307, 'accumulated_eval_time': 8764.48164987564, 'accumulated_logging_time': 2.870373487472534}
I0915 13:16:33.124053 139640336475904 logging_writer.py:48] [94467] accumulated_eval_time=8764.481650, accumulated_logging_time=2.870373, accumulated_submission_time=38610.512995, global_step=94467, preemption_count=0, score=38610.512995, test/accuracy=0.621000, test/loss=1.642374, test/num_examples=10000, total_duration=47586.125654, train/accuracy=0.830566, train/loss=0.657397, validation/accuracy=0.742180, validation/loss=1.030728, validation/num_examples=50000
I0915 13:16:47.573646 139639855773440 logging_writer.py:48] [94500] global_step=94500, grad_norm=1.960755, loss=2.214660
I0915 13:16:47.578628 139684108298048 pytorch_submission_base.py:86] 94500) loss = 2.215, grad_norm = 1.961
I0915 13:20:10.327833 139640336475904 logging_writer.py:48] [95000] global_step=95000, grad_norm=2.053103, loss=2.222558
I0915 13:20:10.336359 139684108298048 pytorch_submission_base.py:86] 95000) loss = 2.223, grad_norm = 2.053
I0915 13:23:34.361715 139684108298048 spec.py:320] Evaluating on the training split.
I0915 13:24:18.603334 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 13:25:03.928887 139684108298048 spec.py:348] Evaluating on the test split.
I0915 13:25:05.320712 139684108298048 submission_runner.py:376] Time since start: 48098.35s, 	Step: 95494, 	{'train/accuracy': 0.83158203125, 'train/loss': 0.6352441024780273, 'validation/accuracy': 0.74338, 'validation/loss': 1.013875, 'validation/num_examples': 50000, 'test/accuracy': 0.6236, 'test/loss': 1.62912900390625, 'test/num_examples': 10000, 'score': 39029.47423171997, 'total_duration': 48098.34556603432, 'accumulated_submission_time': 39029.47423171997, 'accumulated_eval_time': 8855.440926074982, 'accumulated_logging_time': 2.9038188457489014}
I0915 13:25:05.347190 139639855773440 logging_writer.py:48] [95494] accumulated_eval_time=8855.440926, accumulated_logging_time=2.903819, accumulated_submission_time=39029.474232, global_step=95494, preemption_count=0, score=39029.474232, test/accuracy=0.623600, test/loss=1.629129, test/num_examples=10000, total_duration=48098.345566, train/accuracy=0.831582, train/loss=0.635244, validation/accuracy=0.743380, validation/loss=1.013875, validation/num_examples=50000
I0915 13:25:09.007286 139640336475904 logging_writer.py:48] [95500] global_step=95500, grad_norm=2.196978, loss=2.432903
I0915 13:25:09.012594 139684108298048 pytorch_submission_base.py:86] 95500) loss = 2.433, grad_norm = 2.197
I0915 13:28:31.913771 139639855773440 logging_writer.py:48] [96000] global_step=96000, grad_norm=2.040651, loss=2.470679
I0915 13:28:31.923158 139684108298048 pytorch_submission_base.py:86] 96000) loss = 2.471, grad_norm = 2.041
I0915 13:31:58.471330 139640336475904 logging_writer.py:48] [96500] global_step=96500, grad_norm=2.148747, loss=1.596644
I0915 13:31:58.476881 139684108298048 pytorch_submission_base.py:86] 96500) loss = 1.597, grad_norm = 2.149
I0915 13:32:06.400540 139684108298048 spec.py:320] Evaluating on the training split.
I0915 13:32:52.533529 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 13:33:37.921816 139684108298048 spec.py:348] Evaluating on the test split.
I0915 13:33:39.315248 139684108298048 submission_runner.py:376] Time since start: 48612.34s, 	Step: 96518, 	{'train/accuracy': 0.8328125, 'train/loss': 0.630831642150879, 'validation/accuracy': 0.74366, 'validation/loss': 1.013228515625, 'validation/num_examples': 50000, 'test/accuracy': 0.6226, 'test/loss': 1.6283421875, 'test/num_examples': 10000, 'score': 39448.302835702896, 'total_duration': 48612.34012532234, 'accumulated_submission_time': 39448.302835702896, 'accumulated_eval_time': 8948.355902671814, 'accumulated_logging_time': 2.9395039081573486}
I0915 13:33:39.339189 139639855773440 logging_writer.py:48] [96518] accumulated_eval_time=8948.355903, accumulated_logging_time=2.939504, accumulated_submission_time=39448.302836, global_step=96518, preemption_count=0, score=39448.302836, test/accuracy=0.622600, test/loss=1.628342, test/num_examples=10000, total_duration=48612.340125, train/accuracy=0.832812, train/loss=0.630832, validation/accuracy=0.743660, validation/loss=1.013229, validation/num_examples=50000
I0915 13:36:56.753576 139640336475904 logging_writer.py:48] [97000] global_step=97000, grad_norm=2.201969, loss=1.872836
I0915 13:36:56.762028 139684108298048 pytorch_submission_base.py:86] 97000) loss = 1.873, grad_norm = 2.202
I0915 13:40:20.194918 139639855773440 logging_writer.py:48] [97500] global_step=97500, grad_norm=2.192285, loss=2.131216
I0915 13:40:20.201077 139684108298048 pytorch_submission_base.py:86] 97500) loss = 2.131, grad_norm = 2.192
I0915 13:40:40.760437 139684108298048 spec.py:320] Evaluating on the training split.
I0915 13:41:26.179701 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 13:42:13.174069 139684108298048 spec.py:348] Evaluating on the test split.
I0915 13:42:14.565196 139684108298048 submission_runner.py:376] Time since start: 49127.59s, 	Step: 97549, 	{'train/accuracy': 0.8350390625, 'train/loss': 0.6380927276611328, 'validation/accuracy': 0.74606, 'validation/loss': 1.016308046875, 'validation/num_examples': 50000, 'test/accuracy': 0.6262, 'test/loss': 1.63010205078125, 'test/num_examples': 10000, 'score': 39867.39875936508, 'total_duration': 49127.5901222229, 'accumulated_submission_time': 39867.39875936508, 'accumulated_eval_time': 9042.160985946655, 'accumulated_logging_time': 2.973475933074951}
I0915 13:42:14.588428 139640336475904 logging_writer.py:48] [97549] accumulated_eval_time=9042.160986, accumulated_logging_time=2.973476, accumulated_submission_time=39867.398759, global_step=97549, preemption_count=0, score=39867.398759, test/accuracy=0.626200, test/loss=1.630102, test/num_examples=10000, total_duration=49127.590122, train/accuracy=0.835039, train/loss=0.638093, validation/accuracy=0.746060, validation/loss=1.016308, validation/num_examples=50000
I0915 13:45:21.507250 139639855773440 logging_writer.py:48] [98000] global_step=98000, grad_norm=2.147810, loss=1.866629
I0915 13:45:21.513543 139684108298048 pytorch_submission_base.py:86] 98000) loss = 1.867, grad_norm = 2.148
I0915 13:48:44.628735 139640336475904 logging_writer.py:48] [98500] global_step=98500, grad_norm=2.167440, loss=1.850730
I0915 13:48:44.635804 139684108298048 pytorch_submission_base.py:86] 98500) loss = 1.851, grad_norm = 2.167
I0915 13:49:15.719737 139684108298048 spec.py:320] Evaluating on the training split.
I0915 13:50:00.156993 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 13:50:53.436594 139684108298048 spec.py:348] Evaluating on the test split.
I0915 13:50:54.827402 139684108298048 submission_runner.py:376] Time since start: 49647.85s, 	Step: 98575, 	{'train/accuracy': 0.836484375, 'train/loss': 0.6348028945922851, 'validation/accuracy': 0.7487, 'validation/loss': 1.01149390625, 'validation/num_examples': 50000, 'test/accuracy': 0.6298, 'test/loss': 1.61356044921875, 'test/num_examples': 10000, 'score': 40286.21373105049, 'total_duration': 49647.8522644043, 'accumulated_submission_time': 40286.21373105049, 'accumulated_eval_time': 9141.269036531448, 'accumulated_logging_time': 3.0056803226470947}
I0915 13:50:54.852695 139639855773440 logging_writer.py:48] [98575] accumulated_eval_time=9141.269037, accumulated_logging_time=3.005680, accumulated_submission_time=40286.213731, global_step=98575, preemption_count=0, score=40286.213731, test/accuracy=0.629800, test/loss=1.613560, test/num_examples=10000, total_duration=49647.852264, train/accuracy=0.836484, train/loss=0.634803, validation/accuracy=0.748700, validation/loss=1.011494, validation/num_examples=50000
I0915 13:53:51.024888 139640336475904 logging_writer.py:48] [99000] global_step=99000, grad_norm=2.018319, loss=1.821173
I0915 13:53:51.029464 139684108298048 pytorch_submission_base.py:86] 99000) loss = 1.821, grad_norm = 2.018
I0915 13:57:14.199390 139639855773440 logging_writer.py:48] [99500] global_step=99500, grad_norm=2.297153, loss=1.680313
I0915 13:57:14.205286 139684108298048 pytorch_submission_base.py:86] 99500) loss = 1.680, grad_norm = 2.297
I0915 13:57:56.198711 139684108298048 spec.py:320] Evaluating on the training split.
I0915 13:58:41.907002 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 13:59:29.097897 139684108298048 spec.py:348] Evaluating on the test split.
I0915 13:59:30.490501 139684108298048 submission_runner.py:376] Time since start: 50163.52s, 	Step: 99602, 	{'train/accuracy': 0.84017578125, 'train/loss': 0.6095375442504882, 'validation/accuracy': 0.75072, 'validation/loss': 0.996797109375, 'validation/num_examples': 50000, 'test/accuracy': 0.6314, 'test/loss': 1.60039384765625, 'test/num_examples': 10000, 'score': 40705.26306152344, 'total_duration': 50163.51536107063, 'accumulated_submission_time': 40705.26306152344, 'accumulated_eval_time': 9235.560923576355, 'accumulated_logging_time': 3.04288911819458}
I0915 13:59:30.515491 139640336475904 logging_writer.py:48] [99602] accumulated_eval_time=9235.560924, accumulated_logging_time=3.042889, accumulated_submission_time=40705.263062, global_step=99602, preemption_count=0, score=40705.263062, test/accuracy=0.631400, test/loss=1.600394, test/num_examples=10000, total_duration=50163.515361, train/accuracy=0.840176, train/loss=0.609538, validation/accuracy=0.750720, validation/loss=0.996797, validation/num_examples=50000
I0915 14:02:13.601190 139639855773440 logging_writer.py:48] [100000] global_step=100000, grad_norm=2.207259, loss=2.258037
I0915 14:02:13.607107 139684108298048 pytorch_submission_base.py:86] 100000) loss = 2.258, grad_norm = 2.207
I0915 14:05:39.143448 139640336475904 logging_writer.py:48] [100500] global_step=100500, grad_norm=2.184506, loss=1.921122
I0915 14:05:39.149165 139684108298048 pytorch_submission_base.py:86] 100500) loss = 1.921, grad_norm = 2.185
I0915 14:06:31.609853 139684108298048 spec.py:320] Evaluating on the training split.
I0915 14:07:15.926148 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 14:08:01.483617 139684108298048 spec.py:348] Evaluating on the test split.
I0915 14:08:02.878068 139684108298048 submission_runner.py:376] Time since start: 50675.90s, 	Step: 100627, 	{'train/accuracy': 0.8433203125, 'train/loss': 0.5875175476074219, 'validation/accuracy': 0.74966, 'validation/loss': 0.98231171875, 'validation/num_examples': 50000, 'test/accuracy': 0.6297, 'test/loss': 1.59692900390625, 'test/num_examples': 10000, 'score': 41124.04196476936, 'total_duration': 50675.90296983719, 'accumulated_submission_time': 41124.04196476936, 'accumulated_eval_time': 9326.829373598099, 'accumulated_logging_time': 3.0803115367889404}
I0915 14:08:02.905143 139639855773440 logging_writer.py:48] [100627] accumulated_eval_time=9326.829374, accumulated_logging_time=3.080312, accumulated_submission_time=41124.041965, global_step=100627, preemption_count=0, score=41124.041965, test/accuracy=0.629700, test/loss=1.596929, test/num_examples=10000, total_duration=50675.902970, train/accuracy=0.843320, train/loss=0.587518, validation/accuracy=0.749660, validation/loss=0.982312, validation/num_examples=50000
I0915 14:10:35.150782 139640336475904 logging_writer.py:48] [101000] global_step=101000, grad_norm=2.012133, loss=1.863906
I0915 14:10:35.156456 139684108298048 pytorch_submission_base.py:86] 101000) loss = 1.864, grad_norm = 2.012
I0915 14:14:01.150763 139639855773440 logging_writer.py:48] [101500] global_step=101500, grad_norm=2.257795, loss=1.954253
I0915 14:14:01.158138 139684108298048 pytorch_submission_base.py:86] 101500) loss = 1.954, grad_norm = 2.258
I0915 14:15:04.252204 139684108298048 spec.py:320] Evaluating on the training split.
I0915 14:15:48.873608 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 14:16:34.070826 139684108298048 spec.py:348] Evaluating on the test split.
I0915 14:16:35.465621 139684108298048 submission_runner.py:376] Time since start: 51188.49s, 	Step: 101653, 	{'train/accuracy': 0.8445703125, 'train/loss': 0.587913818359375, 'validation/accuracy': 0.75266, 'validation/loss': 0.9801221875, 'validation/num_examples': 50000, 'test/accuracy': 0.6313, 'test/loss': 1.59792314453125, 'test/num_examples': 10000, 'score': 41543.09160733223, 'total_duration': 51188.49051451683, 'accumulated_submission_time': 41543.09160733223, 'accumulated_eval_time': 9418.043019533157, 'accumulated_logging_time': 3.116440534591675}
I0915 14:16:35.493519 139640336475904 logging_writer.py:48] [101653] accumulated_eval_time=9418.043020, accumulated_logging_time=3.116441, accumulated_submission_time=41543.091607, global_step=101653, preemption_count=0, score=41543.091607, test/accuracy=0.631300, test/loss=1.597923, test/num_examples=10000, total_duration=51188.490515, train/accuracy=0.844570, train/loss=0.587914, validation/accuracy=0.752660, validation/loss=0.980122, validation/num_examples=50000
I0915 14:18:57.714861 139639855773440 logging_writer.py:48] [102000] global_step=102000, grad_norm=2.150875, loss=2.143547
I0915 14:18:57.721380 139684108298048 pytorch_submission_base.py:86] 102000) loss = 2.144, grad_norm = 2.151
I0915 14:22:21.016806 139640336475904 logging_writer.py:48] [102500] global_step=102500, grad_norm=2.316696, loss=2.048676
I0915 14:22:21.023212 139684108298048 pytorch_submission_base.py:86] 102500) loss = 2.049, grad_norm = 2.317
I0915 14:23:36.516244 139684108298048 spec.py:320] Evaluating on the training split.
I0915 14:24:22.419265 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 14:25:13.341334 139684108298048 spec.py:348] Evaluating on the test split.
I0915 14:25:14.733119 139684108298048 submission_runner.py:376] Time since start: 51707.76s, 	Step: 102679, 	{'train/accuracy': 0.8463671875, 'train/loss': 0.5783162689208985, 'validation/accuracy': 0.7519, 'validation/loss': 0.974478828125, 'validation/num_examples': 50000, 'test/accuracy': 0.6279, 'test/loss': 1.58693818359375, 'test/num_examples': 10000, 'score': 41961.866085767746, 'total_duration': 51707.758049726486, 'accumulated_submission_time': 41961.866085767746, 'accumulated_eval_time': 9516.260301589966, 'accumulated_logging_time': 3.1542489528656006}
I0915 14:25:14.759179 139639855773440 logging_writer.py:48] [102679] accumulated_eval_time=9516.260302, accumulated_logging_time=3.154249, accumulated_submission_time=41961.866086, global_step=102679, preemption_count=0, score=41961.866086, test/accuracy=0.627900, test/loss=1.586938, test/num_examples=10000, total_duration=51707.758050, train/accuracy=0.846367, train/loss=0.578316, validation/accuracy=0.751900, validation/loss=0.974479, validation/num_examples=50000
I0915 14:27:26.459069 139640336475904 logging_writer.py:48] [103000] global_step=103000, grad_norm=2.348477, loss=1.800207
I0915 14:27:26.464311 139684108298048 pytorch_submission_base.py:86] 103000) loss = 1.800, grad_norm = 2.348
I0915 14:30:49.453857 139639855773440 logging_writer.py:48] [103500] global_step=103500, grad_norm=2.383792, loss=2.069993
I0915 14:30:49.460402 139684108298048 pytorch_submission_base.py:86] 103500) loss = 2.070, grad_norm = 2.384
I0915 14:32:15.983667 139684108298048 spec.py:320] Evaluating on the training split.
I0915 14:33:01.173276 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 14:33:48.415780 139684108298048 spec.py:348] Evaluating on the test split.
I0915 14:33:49.809001 139684108298048 submission_runner.py:376] Time since start: 52222.83s, 	Step: 103709, 	{'train/accuracy': 0.847421875, 'train/loss': 0.5782836532592773, 'validation/accuracy': 0.75458, 'validation/loss': 0.97379921875, 'validation/num_examples': 50000, 'test/accuracy': 0.6294, 'test/loss': 1.59104033203125, 'test/num_examples': 10000, 'score': 42380.79360818863, 'total_duration': 52222.83391237259, 'accumulated_submission_time': 42380.79360818863, 'accumulated_eval_time': 9610.085911512375, 'accumulated_logging_time': 3.191195487976074}
I0915 14:33:49.832857 139640336475904 logging_writer.py:48] [103709] accumulated_eval_time=9610.085912, accumulated_logging_time=3.191195, accumulated_submission_time=42380.793608, global_step=103709, preemption_count=0, score=42380.793608, test/accuracy=0.629400, test/loss=1.591040, test/num_examples=10000, total_duration=52222.833912, train/accuracy=0.847422, train/loss=0.578284, validation/accuracy=0.754580, validation/loss=0.973799, validation/num_examples=50000
I0915 14:35:51.642461 139639855773440 logging_writer.py:48] [104000] global_step=104000, grad_norm=2.145997, loss=2.006563
I0915 14:35:51.648070 139684108298048 pytorch_submission_base.py:86] 104000) loss = 2.007, grad_norm = 2.146
I0915 14:39:14.926254 139640336475904 logging_writer.py:48] [104500] global_step=104500, grad_norm=2.286470, loss=1.989975
I0915 14:39:14.932226 139684108298048 pytorch_submission_base.py:86] 104500) loss = 1.990, grad_norm = 2.286
I0915 14:40:51.248999 139684108298048 spec.py:320] Evaluating on the training split.
I0915 14:41:35.406637 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 14:42:22.779303 139684108298048 spec.py:348] Evaluating on the test split.
I0915 14:42:24.170823 139684108298048 submission_runner.py:376] Time since start: 52737.20s, 	Step: 104736, 	{'train/accuracy': 0.8512890625, 'train/loss': 0.5703498077392578, 'validation/accuracy': 0.75324, 'validation/loss': 0.977637265625, 'validation/num_examples': 50000, 'test/accuracy': 0.6389, 'test/loss': 1.57701064453125, 'test/num_examples': 10000, 'score': 42799.91485095024, 'total_duration': 52737.195675611496, 'accumulated_submission_time': 42799.91485095024, 'accumulated_eval_time': 9703.007879972458, 'accumulated_logging_time': 3.2267842292785645}
I0915 14:42:24.195091 139639855773440 logging_writer.py:48] [104736] accumulated_eval_time=9703.007880, accumulated_logging_time=3.226784, accumulated_submission_time=42799.914851, global_step=104736, preemption_count=0, score=42799.914851, test/accuracy=0.638900, test/loss=1.577011, test/num_examples=10000, total_duration=52737.195676, train/accuracy=0.851289, train/loss=0.570350, validation/accuracy=0.753240, validation/loss=0.977637, validation/num_examples=50000
I0915 14:44:13.207927 139640336475904 logging_writer.py:48] [105000] global_step=105000, grad_norm=2.436055, loss=2.046636
I0915 14:44:13.213988 139684108298048 pytorch_submission_base.py:86] 105000) loss = 2.047, grad_norm = 2.436
I0915 14:47:38.869073 139639855773440 logging_writer.py:48] [105500] global_step=105500, grad_norm=2.430099, loss=2.520085
I0915 14:47:38.874310 139684108298048 pytorch_submission_base.py:86] 105500) loss = 2.520, grad_norm = 2.430
I0915 14:49:25.470435 139684108298048 spec.py:320] Evaluating on the training split.
I0915 14:50:10.855226 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 14:50:56.439280 139684108298048 spec.py:348] Evaluating on the test split.
I0915 14:50:57.827979 139684108298048 submission_runner.py:376] Time since start: 53250.85s, 	Step: 105761, 	{'train/accuracy': 0.852734375, 'train/loss': 0.5586693954467773, 'validation/accuracy': 0.7552, 'validation/loss': 0.967124140625, 'validation/num_examples': 50000, 'test/accuracy': 0.6302, 'test/loss': 1.57986357421875, 'test/num_examples': 10000, 'score': 43218.925899744034, 'total_duration': 53250.85289669037, 'accumulated_submission_time': 43218.925899744034, 'accumulated_eval_time': 9795.36553311348, 'accumulated_logging_time': 3.263418197631836}
I0915 14:50:57.851603 139640336475904 logging_writer.py:48] [105761] accumulated_eval_time=9795.365533, accumulated_logging_time=3.263418, accumulated_submission_time=43218.925900, global_step=105761, preemption_count=0, score=43218.925900, test/accuracy=0.630200, test/loss=1.579864, test/num_examples=10000, total_duration=53250.852897, train/accuracy=0.852734, train/loss=0.558669, validation/accuracy=0.755200, validation/loss=0.967124, validation/num_examples=50000
I0915 14:52:35.764909 139639855773440 logging_writer.py:48] [106000] global_step=106000, grad_norm=2.375769, loss=1.886378
I0915 14:52:35.771430 139684108298048 pytorch_submission_base.py:86] 106000) loss = 1.886, grad_norm = 2.376
I0915 14:56:02.218748 139640336475904 logging_writer.py:48] [106500] global_step=106500, grad_norm=2.363073, loss=2.152572
I0915 14:56:02.232555 139684108298048 pytorch_submission_base.py:86] 106500) loss = 2.153, grad_norm = 2.363
I0915 14:57:59.155905 139684108298048 spec.py:320] Evaluating on the training split.
I0915 14:58:44.061555 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 14:59:29.767455 139684108298048 spec.py:348] Evaluating on the test split.
I0915 14:59:31.159318 139684108298048 submission_runner.py:376] Time since start: 53764.18s, 	Step: 106786, 	{'train/accuracy': 0.8540625, 'train/loss': 0.5444474792480469, 'validation/accuracy': 0.75772, 'validation/loss': 0.9536, 'validation/num_examples': 50000, 'test/accuracy': 0.6402, 'test/loss': 1.55708623046875, 'test/num_examples': 10000, 'score': 43637.99845647812, 'total_duration': 53764.18422079086, 'accumulated_submission_time': 43637.99845647812, 'accumulated_eval_time': 9887.369504451752, 'accumulated_logging_time': 3.3013100624084473}
I0915 14:59:31.184382 139639855773440 logging_writer.py:48] [106786] accumulated_eval_time=9887.369504, accumulated_logging_time=3.301310, accumulated_submission_time=43637.998456, global_step=106786, preemption_count=0, score=43637.998456, test/accuracy=0.640200, test/loss=1.557086, test/num_examples=10000, total_duration=53764.184221, train/accuracy=0.854062, train/loss=0.544447, validation/accuracy=0.757720, validation/loss=0.953600, validation/num_examples=50000
I0915 15:00:59.427185 139640336475904 logging_writer.py:48] [107000] global_step=107000, grad_norm=2.340277, loss=2.127822
I0915 15:00:59.431872 139684108298048 pytorch_submission_base.py:86] 107000) loss = 2.128, grad_norm = 2.340
I0915 15:04:23.419203 139639855773440 logging_writer.py:48] [107500] global_step=107500, grad_norm=2.685761, loss=2.456330
I0915 15:04:23.428340 139684108298048 pytorch_submission_base.py:86] 107500) loss = 2.456, grad_norm = 2.686
I0915 15:06:32.484142 139684108298048 spec.py:320] Evaluating on the training split.
I0915 15:07:17.921302 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 15:08:03.228877 139684108298048 spec.py:348] Evaluating on the test split.
I0915 15:08:04.621655 139684108298048 submission_runner.py:376] Time since start: 54277.65s, 	Step: 107810, 	{'train/accuracy': 0.85595703125, 'train/loss': 0.5424169921875, 'validation/accuracy': 0.75812, 'validation/loss': 0.958324609375, 'validation/num_examples': 50000, 'test/accuracy': 0.6406, 'test/loss': 1.560701171875, 'test/num_examples': 10000, 'score': 44057.00115823746, 'total_duration': 54277.64653611183, 'accumulated_submission_time': 44057.00115823746, 'accumulated_eval_time': 9979.507205963135, 'accumulated_logging_time': 3.3355462551116943}
I0915 15:08:04.648233 139640336475904 logging_writer.py:48] [107810] accumulated_eval_time=9979.507206, accumulated_logging_time=3.335546, accumulated_submission_time=44057.001158, global_step=107810, preemption_count=0, score=44057.001158, test/accuracy=0.640600, test/loss=1.560701, test/num_examples=10000, total_duration=54277.646536, train/accuracy=0.855957, train/loss=0.542417, validation/accuracy=0.758120, validation/loss=0.958325, validation/num_examples=50000
I0915 15:09:23.187864 139639855773440 logging_writer.py:48] [108000] global_step=108000, grad_norm=2.223751, loss=1.792137
I0915 15:09:23.192965 139684108298048 pytorch_submission_base.py:86] 108000) loss = 1.792, grad_norm = 2.224
I0915 15:12:46.017120 139640336475904 logging_writer.py:48] [108500] global_step=108500, grad_norm=2.313291, loss=1.544254
I0915 15:12:46.024013 139684108298048 pytorch_submission_base.py:86] 108500) loss = 1.544, grad_norm = 2.313
I0915 15:15:07.461866 139684108298048 spec.py:320] Evaluating on the training split.
I0915 15:15:53.295464 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 15:16:41.262116 139684108298048 spec.py:348] Evaluating on the test split.
I0915 15:16:42.651068 139684108298048 submission_runner.py:376] Time since start: 54795.68s, 	Step: 108838, 	{'train/accuracy': 0.855859375, 'train/loss': 0.5601757049560547, 'validation/accuracy': 0.75806, 'validation/loss': 0.965975234375, 'validation/num_examples': 50000, 'test/accuracy': 0.6399, 'test/loss': 1.57255400390625, 'test/num_examples': 10000, 'score': 44477.597714185715, 'total_duration': 54795.675968647, 'accumulated_submission_time': 44477.597714185715, 'accumulated_eval_time': 10074.69682431221, 'accumulated_logging_time': 3.371678352355957}
I0915 15:16:42.677087 139639855773440 logging_writer.py:48] [108838] accumulated_eval_time=10074.696824, accumulated_logging_time=3.371678, accumulated_submission_time=44477.597714, global_step=108838, preemption_count=0, score=44477.597714, test/accuracy=0.639900, test/loss=1.572554, test/num_examples=10000, total_duration=54795.675969, train/accuracy=0.855859, train/loss=0.560176, validation/accuracy=0.758060, validation/loss=0.965975, validation/num_examples=50000
I0915 15:17:49.953724 139640336475904 logging_writer.py:48] [109000] global_step=109000, grad_norm=2.311514, loss=1.553972
I0915 15:17:49.958763 139684108298048 pytorch_submission_base.py:86] 109000) loss = 1.554, grad_norm = 2.312
I0915 15:21:13.162883 139639855773440 logging_writer.py:48] [109500] global_step=109500, grad_norm=2.422743, loss=2.112233
I0915 15:21:13.168854 139684108298048 pytorch_submission_base.py:86] 109500) loss = 2.112, grad_norm = 2.423
I0915 15:23:43.792030 139684108298048 spec.py:320] Evaluating on the training split.
I0915 15:24:28.157471 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 15:25:20.809315 139684108298048 spec.py:348] Evaluating on the test split.
I0915 15:25:22.201317 139684108298048 submission_runner.py:376] Time since start: 55315.23s, 	Step: 109870, 	{'train/accuracy': 0.8593359375, 'train/loss': 0.5270893096923828, 'validation/accuracy': 0.76204, 'validation/loss': 0.94185078125, 'validation/num_examples': 50000, 'test/accuracy': 0.6435, 'test/loss': 1.5496615234375, 'test/num_examples': 10000, 'score': 44896.43131685257, 'total_duration': 55315.226239681244, 'accumulated_submission_time': 44896.43131685257, 'accumulated_eval_time': 10173.106612443924, 'accumulated_logging_time': 3.4073944091796875}
I0915 15:25:22.226137 139640336475904 logging_writer.py:48] [109870] accumulated_eval_time=10173.106612, accumulated_logging_time=3.407394, accumulated_submission_time=44896.431317, global_step=109870, preemption_count=0, score=44896.431317, test/accuracy=0.643500, test/loss=1.549662, test/num_examples=10000, total_duration=55315.226240, train/accuracy=0.859336, train/loss=0.527089, validation/accuracy=0.762040, validation/loss=0.941851, validation/num_examples=50000
I0915 15:26:16.399706 139639855773440 logging_writer.py:48] [110000] global_step=110000, grad_norm=2.427896, loss=1.770150
I0915 15:26:16.404799 139684108298048 pytorch_submission_base.py:86] 110000) loss = 1.770, grad_norm = 2.428
I0915 15:29:42.308792 139640336475904 logging_writer.py:48] [110500] global_step=110500, grad_norm=2.425556, loss=1.596815
I0915 15:29:42.314165 139684108298048 pytorch_submission_base.py:86] 110500) loss = 1.597, grad_norm = 2.426
I0915 15:32:23.298972 139684108298048 spec.py:320] Evaluating on the training split.
I0915 15:33:07.721633 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 15:33:53.253143 139684108298048 spec.py:348] Evaluating on the test split.
I0915 15:33:54.645401 139684108298048 submission_runner.py:376] Time since start: 55827.67s, 	Step: 110895, 	{'train/accuracy': 0.86236328125, 'train/loss': 0.5179230117797852, 'validation/accuracy': 0.76282, 'validation/loss': 0.936807265625, 'validation/num_examples': 50000, 'test/accuracy': 0.6403, 'test/loss': 1.54444853515625, 'test/num_examples': 10000, 'score': 45315.21571183205, 'total_duration': 55827.67030262947, 'accumulated_submission_time': 45315.21571183205, 'accumulated_eval_time': 10264.453321695328, 'accumulated_logging_time': 3.4423305988311768}
I0915 15:33:54.671982 139639855773440 logging_writer.py:48] [110895] accumulated_eval_time=10264.453322, accumulated_logging_time=3.442331, accumulated_submission_time=45315.215712, global_step=110895, preemption_count=0, score=45315.215712, test/accuracy=0.640300, test/loss=1.544449, test/num_examples=10000, total_duration=55827.670303, train/accuracy=0.862363, train/loss=0.517923, validation/accuracy=0.762820, validation/loss=0.936807, validation/num_examples=50000
I0915 15:34:38.524351 139640336475904 logging_writer.py:48] [111000] global_step=111000, grad_norm=2.312964, loss=1.877747
I0915 15:34:38.529381 139684108298048 pytorch_submission_base.py:86] 111000) loss = 1.878, grad_norm = 2.313
I0915 15:38:04.485914 139639855773440 logging_writer.py:48] [111500] global_step=111500, grad_norm=2.462005, loss=2.052160
I0915 15:38:04.490936 139684108298048 pytorch_submission_base.py:86] 111500) loss = 2.052, grad_norm = 2.462
I0915 15:40:56.018737 139684108298048 spec.py:320] Evaluating on the training split.
I0915 15:41:40.421716 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 15:42:25.742061 139684108298048 spec.py:348] Evaluating on the test split.
I0915 15:42:27.136675 139684108298048 submission_runner.py:376] Time since start: 56340.16s, 	Step: 111920, 	{'train/accuracy': 0.8644140625, 'train/loss': 0.513069076538086, 'validation/accuracy': 0.76186, 'validation/loss': 0.9369096875, 'validation/num_examples': 50000, 'test/accuracy': 0.6425, 'test/loss': 1.54375908203125, 'test/num_examples': 10000, 'score': 45734.28729915619, 'total_duration': 56340.161566734314, 'accumulated_submission_time': 45734.28729915619, 'accumulated_eval_time': 10355.571375608444, 'accumulated_logging_time': 3.4803314208984375}
I0915 15:42:27.164142 139640336475904 logging_writer.py:48] [111920] accumulated_eval_time=10355.571376, accumulated_logging_time=3.480331, accumulated_submission_time=45734.287299, global_step=111920, preemption_count=0, score=45734.287299, test/accuracy=0.642500, test/loss=1.543759, test/num_examples=10000, total_duration=56340.161567, train/accuracy=0.864414, train/loss=0.513069, validation/accuracy=0.761860, validation/loss=0.936910, validation/num_examples=50000
I0915 15:43:00.691239 139639855773440 logging_writer.py:48] [112000] global_step=112000, grad_norm=2.634053, loss=2.294763
I0915 15:43:00.695351 139684108298048 pytorch_submission_base.py:86] 112000) loss = 2.295, grad_norm = 2.634
I0915 15:46:24.534589 139640336475904 logging_writer.py:48] [112500] global_step=112500, grad_norm=2.664804, loss=2.482322
I0915 15:46:24.543428 139684108298048 pytorch_submission_base.py:86] 112500) loss = 2.482, grad_norm = 2.665
I0915 15:49:28.466497 139684108298048 spec.py:320] Evaluating on the training split.
I0915 15:50:12.621166 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 15:50:58.110986 139684108298048 spec.py:348] Evaluating on the test split.
I0915 15:50:59.503742 139684108298048 submission_runner.py:376] Time since start: 56852.53s, 	Step: 112944, 	{'train/accuracy': 0.86396484375, 'train/loss': 0.5202515029907226, 'validation/accuracy': 0.76554, 'validation/loss': 0.9400953125, 'validation/num_examples': 50000, 'test/accuracy': 0.6474, 'test/loss': 1.5354623046875, 'test/num_examples': 10000, 'score': 46153.360674619675, 'total_duration': 56852.52862691879, 'accumulated_submission_time': 46153.360674619675, 'accumulated_eval_time': 10446.608747005463, 'accumulated_logging_time': 3.5171797275543213}
I0915 15:50:59.527437 139639855773440 logging_writer.py:48] [112944] accumulated_eval_time=10446.608747, accumulated_logging_time=3.517180, accumulated_submission_time=46153.360675, global_step=112944, preemption_count=0, score=46153.360675, test/accuracy=0.647400, test/loss=1.535462, test/num_examples=10000, total_duration=56852.528627, train/accuracy=0.863965, train/loss=0.520252, validation/accuracy=0.765540, validation/loss=0.940095, validation/num_examples=50000
I0915 15:51:23.509291 139640336475904 logging_writer.py:48] [113000] global_step=113000, grad_norm=2.491747, loss=1.643651
I0915 15:51:23.514502 139684108298048 pytorch_submission_base.py:86] 113000) loss = 1.644, grad_norm = 2.492
I0915 15:54:46.586257 139639855773440 logging_writer.py:48] [113500] global_step=113500, grad_norm=2.529945, loss=2.449023
I0915 15:54:46.595905 139684108298048 pytorch_submission_base.py:86] 113500) loss = 2.449, grad_norm = 2.530
I0915 15:58:00.871190 139684108298048 spec.py:320] Evaluating on the training split.
I0915 15:58:47.095150 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 15:59:35.566289 139684108298048 spec.py:348] Evaluating on the test split.
I0915 15:59:36.958677 139684108298048 submission_runner.py:376] Time since start: 57369.98s, 	Step: 113968, 	{'train/accuracy': 0.86662109375, 'train/loss': 0.49989437103271483, 'validation/accuracy': 0.76732, 'validation/loss': 0.924251796875, 'validation/num_examples': 50000, 'test/accuracy': 0.6451, 'test/loss': 1.5386171875, 'test/num_examples': 10000, 'score': 46572.472317934036, 'total_duration': 57369.98356962204, 'accumulated_submission_time': 46572.472317934036, 'accumulated_eval_time': 10542.69648194313, 'accumulated_logging_time': 3.5498931407928467}
I0915 15:59:36.983437 139640336475904 logging_writer.py:48] [113968] accumulated_eval_time=10542.696482, accumulated_logging_time=3.549893, accumulated_submission_time=46572.472318, global_step=113968, preemption_count=0, score=46572.472318, test/accuracy=0.645100, test/loss=1.538617, test/num_examples=10000, total_duration=57369.983570, train/accuracy=0.866621, train/loss=0.499894, validation/accuracy=0.767320, validation/loss=0.924252, validation/num_examples=50000
I0915 15:59:51.186842 139639855773440 logging_writer.py:48] [114000] global_step=114000, grad_norm=2.662662, loss=1.935684
I0915 15:59:51.191891 139684108298048 pytorch_submission_base.py:86] 114000) loss = 1.936, grad_norm = 2.663
I0915 16:03:14.768940 139640336475904 logging_writer.py:48] [114500] global_step=114500, grad_norm=2.603421, loss=1.491574
I0915 16:03:14.774098 139684108298048 pytorch_submission_base.py:86] 114500) loss = 1.492, grad_norm = 2.603
I0915 16:06:38.068853 139684108298048 spec.py:320] Evaluating on the training split.
I0915 16:07:23.373854 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 16:08:09.338992 139684108298048 spec.py:348] Evaluating on the test split.
I0915 16:08:10.732001 139684108298048 submission_runner.py:376] Time since start: 57883.76s, 	Step: 114998, 	{'train/accuracy': 0.8693359375, 'train/loss': 0.48761680603027346, 'validation/accuracy': 0.767, 'validation/loss': 0.916077578125, 'validation/num_examples': 50000, 'test/accuracy': 0.6518, 'test/loss': 1.51863486328125, 'test/num_examples': 10000, 'score': 46991.21198415756, 'total_duration': 57883.75690817833, 'accumulated_submission_time': 46991.21198415756, 'accumulated_eval_time': 10635.36027431488, 'accumulated_logging_time': 3.583712339401245}
I0915 16:08:10.757840 139639855773440 logging_writer.py:48] [114998] accumulated_eval_time=10635.360274, accumulated_logging_time=3.583712, accumulated_submission_time=46991.211984, global_step=114998, preemption_count=0, score=46991.211984, test/accuracy=0.651800, test/loss=1.518635, test/num_examples=10000, total_duration=57883.756908, train/accuracy=0.869336, train/loss=0.487617, validation/accuracy=0.767000, validation/loss=0.916078, validation/num_examples=50000
I0915 16:08:12.855135 139640336475904 logging_writer.py:48] [115000] global_step=115000, grad_norm=2.617222, loss=2.191636
I0915 16:08:12.859210 139684108298048 pytorch_submission_base.py:86] 115000) loss = 2.192, grad_norm = 2.617
I0915 16:11:38.520481 139639855773440 logging_writer.py:48] [115500] global_step=115500, grad_norm=2.467005, loss=1.562458
I0915 16:11:38.525002 139684108298048 pytorch_submission_base.py:86] 115500) loss = 1.562, grad_norm = 2.467
I0915 16:15:01.447835 139640336475904 logging_writer.py:48] [116000] global_step=116000, grad_norm=2.688667, loss=1.629964
I0915 16:15:01.454280 139684108298048 pytorch_submission_base.py:86] 116000) loss = 1.630, grad_norm = 2.689
I0915 16:15:12.212913 139684108298048 spec.py:320] Evaluating on the training split.
I0915 16:15:56.628750 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 16:16:47.875679 139684108298048 spec.py:348] Evaluating on the test split.
I0915 16:16:49.265321 139684108298048 submission_runner.py:376] Time since start: 58402.29s, 	Step: 116025, 	{'train/accuracy': 0.87134765625, 'train/loss': 0.4869023513793945, 'validation/accuracy': 0.76772, 'validation/loss': 0.918648515625, 'validation/num_examples': 50000, 'test/accuracy': 0.6505, 'test/loss': 1.52064853515625, 'test/num_examples': 10000, 'score': 47410.31763482094, 'total_duration': 58402.29022669792, 'accumulated_submission_time': 47410.31763482094, 'accumulated_eval_time': 10732.412917137146, 'accumulated_logging_time': 3.6232876777648926}
I0915 16:16:49.293913 139639855773440 logging_writer.py:48] [116025] accumulated_eval_time=10732.412917, accumulated_logging_time=3.623288, accumulated_submission_time=47410.317635, global_step=116025, preemption_count=0, score=47410.317635, test/accuracy=0.650500, test/loss=1.520649, test/num_examples=10000, total_duration=58402.290227, train/accuracy=0.871348, train/loss=0.486902, validation/accuracy=0.767720, validation/loss=0.918649, validation/num_examples=50000
I0915 16:20:06.146760 139640336475904 logging_writer.py:48] [116500] global_step=116500, grad_norm=2.472685, loss=2.003266
I0915 16:20:06.151567 139684108298048 pytorch_submission_base.py:86] 116500) loss = 2.003, grad_norm = 2.473
I0915 16:23:29.586041 139639855773440 logging_writer.py:48] [117000] global_step=117000, grad_norm=2.768914, loss=2.007155
I0915 16:23:29.590892 139684108298048 pytorch_submission_base.py:86] 117000) loss = 2.007, grad_norm = 2.769
I0915 16:23:50.524974 139684108298048 spec.py:320] Evaluating on the training split.
I0915 16:24:36.535966 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 16:25:21.917059 139684108298048 spec.py:348] Evaluating on the test split.
I0915 16:25:23.306791 139684108298048 submission_runner.py:376] Time since start: 58916.33s, 	Step: 117050, 	{'train/accuracy': 0.87228515625, 'train/loss': 0.47382511138916017, 'validation/accuracy': 0.7698, 'validation/loss': 0.907203828125, 'validation/num_examples': 50000, 'test/accuracy': 0.6497, 'test/loss': 1.51831455078125, 'test/num_examples': 10000, 'score': 47829.2496008873, 'total_duration': 58916.33164405823, 'accumulated_submission_time': 47829.2496008873, 'accumulated_eval_time': 10825.195115327835, 'accumulated_logging_time': 3.660820722579956}
I0915 16:25:23.333972 139640336475904 logging_writer.py:48] [117050] accumulated_eval_time=10825.195115, accumulated_logging_time=3.660821, accumulated_submission_time=47829.249601, global_step=117050, preemption_count=0, score=47829.249601, test/accuracy=0.649700, test/loss=1.518315, test/num_examples=10000, total_duration=58916.331644, train/accuracy=0.872285, train/loss=0.473825, validation/accuracy=0.769800, validation/loss=0.907204, validation/num_examples=50000
I0915 16:28:27.780898 139639855773440 logging_writer.py:48] [117500] global_step=117500, grad_norm=2.386070, loss=1.722396
I0915 16:28:27.791258 139684108298048 pytorch_submission_base.py:86] 117500) loss = 1.722, grad_norm = 2.386
I0915 16:31:53.798537 139640336475904 logging_writer.py:48] [118000] global_step=118000, grad_norm=2.723183, loss=2.387833
I0915 16:31:53.805079 139684108298048 pytorch_submission_base.py:86] 118000) loss = 2.388, grad_norm = 2.723
I0915 16:32:24.590222 139684108298048 spec.py:320] Evaluating on the training split.
I0915 16:33:08.518147 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 16:33:53.954762 139684108298048 spec.py:348] Evaluating on the test split.
I0915 16:33:55.345705 139684108298048 submission_runner.py:376] Time since start: 59428.37s, 	Step: 118074, 	{'train/accuracy': 0.87443359375, 'train/loss': 0.4734429168701172, 'validation/accuracy': 0.76756, 'validation/loss': 0.91150984375, 'validation/num_examples': 50000, 'test/accuracy': 0.6512, 'test/loss': 1.51347451171875, 'test/num_examples': 10000, 'score': 48248.26400375366, 'total_duration': 59428.37057328224, 'accumulated_submission_time': 48248.26400375366, 'accumulated_eval_time': 10915.950778484344, 'accumulated_logging_time': 3.698261022567749}
I0915 16:33:55.374012 139639855773440 logging_writer.py:48] [118074] accumulated_eval_time=10915.950778, accumulated_logging_time=3.698261, accumulated_submission_time=48248.264004, global_step=118074, preemption_count=0, score=48248.264004, test/accuracy=0.651200, test/loss=1.513475, test/num_examples=10000, total_duration=59428.370573, train/accuracy=0.874434, train/loss=0.473443, validation/accuracy=0.767560, validation/loss=0.911510, validation/num_examples=50000
I0915 16:36:49.384021 139640336475904 logging_writer.py:48] [118500] global_step=118500, grad_norm=2.808790, loss=1.628039
I0915 16:36:49.394377 139684108298048 pytorch_submission_base.py:86] 118500) loss = 1.628, grad_norm = 2.809
I0915 16:40:16.705816 139639855773440 logging_writer.py:48] [119000] global_step=119000, grad_norm=2.653029, loss=1.514914
I0915 16:40:16.716478 139684108298048 pytorch_submission_base.py:86] 119000) loss = 1.515, grad_norm = 2.653
I0915 16:40:56.763012 139684108298048 spec.py:320] Evaluating on the training split.
I0915 16:41:41.290777 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 16:42:26.777938 139684108298048 spec.py:348] Evaluating on the test split.
I0915 16:42:28.168917 139684108298048 submission_runner.py:376] Time since start: 59941.19s, 	Step: 119097, 	{'train/accuracy': 0.874609375, 'train/loss': 0.4653433227539063, 'validation/accuracy': 0.76982, 'validation/loss': 0.90433765625, 'validation/num_examples': 50000, 'test/accuracy': 0.653, 'test/loss': 1.50516025390625, 'test/num_examples': 10000, 'score': 48667.40327858925, 'total_duration': 59941.1938188076, 'accumulated_submission_time': 48667.40327858925, 'accumulated_eval_time': 11007.35677909851, 'accumulated_logging_time': 3.73533296585083}
I0915 16:42:28.196526 139640336475904 logging_writer.py:48] [119097] accumulated_eval_time=11007.356779, accumulated_logging_time=3.735333, accumulated_submission_time=48667.403279, global_step=119097, preemption_count=0, score=48667.403279, test/accuracy=0.653000, test/loss=1.505160, test/num_examples=10000, total_duration=59941.193819, train/accuracy=0.874609, train/loss=0.465343, validation/accuracy=0.769820, validation/loss=0.904338, validation/num_examples=50000
I0915 16:45:13.100180 139639855773440 logging_writer.py:48] [119500] global_step=119500, grad_norm=2.647074, loss=1.402266
I0915 16:45:13.105826 139684108298048 pytorch_submission_base.py:86] 119500) loss = 1.402, grad_norm = 2.647
I0915 16:48:36.690724 139640336475904 logging_writer.py:48] [120000] global_step=120000, grad_norm=2.506317, loss=1.634362
I0915 16:48:36.700081 139684108298048 pytorch_submission_base.py:86] 120000) loss = 1.634, grad_norm = 2.506
I0915 16:49:29.495372 139684108298048 spec.py:320] Evaluating on the training split.
I0915 16:50:15.038779 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 16:51:05.814862 139684108298048 spec.py:348] Evaluating on the test split.
I0915 16:51:07.204582 139684108298048 submission_runner.py:376] Time since start: 60460.23s, 	Step: 120123, 	{'train/accuracy': 0.87720703125, 'train/loss': 0.46155826568603514, 'validation/accuracy': 0.77108, 'validation/loss': 0.89914265625, 'validation/num_examples': 50000, 'test/accuracy': 0.6553, 'test/loss': 1.50501767578125, 'test/num_examples': 10000, 'score': 49086.396035432816, 'total_duration': 60460.22948741913, 'accumulated_submission_time': 49086.396035432816, 'accumulated_eval_time': 11105.066396951675, 'accumulated_logging_time': 3.7727248668670654}
I0915 16:51:07.232828 139639855773440 logging_writer.py:48] [120123] accumulated_eval_time=11105.066397, accumulated_logging_time=3.772725, accumulated_submission_time=49086.396035, global_step=120123, preemption_count=0, score=49086.396035, test/accuracy=0.655300, test/loss=1.505018, test/num_examples=10000, total_duration=60460.229487, train/accuracy=0.877207, train/loss=0.461558, validation/accuracy=0.771080, validation/loss=0.899143, validation/num_examples=50000
I0915 16:53:41.968383 139640336475904 logging_writer.py:48] [120500] global_step=120500, grad_norm=2.546894, loss=1.625696
I0915 16:53:41.974084 139684108298048 pytorch_submission_base.py:86] 120500) loss = 1.626, grad_norm = 2.547
I0915 16:57:04.734885 139639855773440 logging_writer.py:48] [121000] global_step=121000, grad_norm=2.893064, loss=1.662257
I0915 16:57:04.744460 139684108298048 pytorch_submission_base.py:86] 121000) loss = 1.662, grad_norm = 2.893
I0915 16:58:08.657394 139684108298048 spec.py:320] Evaluating on the training split.
I0915 16:58:53.539727 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 16:59:42.701123 139684108298048 spec.py:348] Evaluating on the test split.
I0915 16:59:44.094752 139684108298048 submission_runner.py:376] Time since start: 60977.12s, 	Step: 121154, 	{'train/accuracy': 0.87708984375, 'train/loss': 0.45498153686523435, 'validation/accuracy': 0.77144, 'validation/loss': 0.894196953125, 'validation/num_examples': 50000, 'test/accuracy': 0.6554, 'test/loss': 1.50044541015625, 'test/num_examples': 10000, 'score': 49505.52829742432, 'total_duration': 60977.11965084076, 'accumulated_submission_time': 49505.52829742432, 'accumulated_eval_time': 11200.504184007645, 'accumulated_logging_time': 3.8097081184387207}
I0915 16:59:44.119052 139640336475904 logging_writer.py:48] [121154] accumulated_eval_time=11200.504184, accumulated_logging_time=3.809708, accumulated_submission_time=49505.528297, global_step=121154, preemption_count=0, score=49505.528297, test/accuracy=0.655400, test/loss=1.500445, test/num_examples=10000, total_duration=60977.119651, train/accuracy=0.877090, train/loss=0.454982, validation/accuracy=0.771440, validation/loss=0.894197, validation/num_examples=50000
I0915 17:02:08.179688 139639855773440 logging_writer.py:48] [121500] global_step=121500, grad_norm=2.816293, loss=1.684982
I0915 17:02:08.184642 139684108298048 pytorch_submission_base.py:86] 121500) loss = 1.685, grad_norm = 2.816
I0915 17:05:31.668778 139640336475904 logging_writer.py:48] [122000] global_step=122000, grad_norm=3.110149, loss=2.006314
I0915 17:05:31.676158 139684108298048 pytorch_submission_base.py:86] 122000) loss = 2.006, grad_norm = 3.110
I0915 17:06:45.410916 139684108298048 spec.py:320] Evaluating on the training split.
I0915 17:07:29.580713 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 17:08:14.971449 139684108298048 spec.py:348] Evaluating on the test split.
I0915 17:08:16.364436 139684108298048 submission_runner.py:376] Time since start: 61489.39s, 	Step: 122180, 	{'train/accuracy': 0.8786328125, 'train/loss': 0.45640762329101564, 'validation/accuracy': 0.772, 'validation/loss': 0.898678125, 'validation/num_examples': 50000, 'test/accuracy': 0.654, 'test/loss': 1.4994955078125, 'test/num_examples': 10000, 'score': 49924.506761312485, 'total_duration': 61489.38933992386, 'accumulated_submission_time': 49924.506761312485, 'accumulated_eval_time': 11291.458031892776, 'accumulated_logging_time': 3.8429646492004395}
I0915 17:08:16.392589 139639855773440 logging_writer.py:48] [122180] accumulated_eval_time=11291.458032, accumulated_logging_time=3.842965, accumulated_submission_time=49924.506761, global_step=122180, preemption_count=0, score=49924.506761, test/accuracy=0.654000, test/loss=1.499496, test/num_examples=10000, total_duration=61489.389340, train/accuracy=0.878633, train/loss=0.456408, validation/accuracy=0.772000, validation/loss=0.898678, validation/num_examples=50000
I0915 17:10:28.133072 139640336475904 logging_writer.py:48] [122500] global_step=122500, grad_norm=2.916995, loss=1.852766
I0915 17:10:28.139510 139684108298048 pytorch_submission_base.py:86] 122500) loss = 1.853, grad_norm = 2.917
I0915 17:13:54.207359 139639855773440 logging_writer.py:48] [123000] global_step=123000, grad_norm=3.164475, loss=2.194162
I0915 17:13:54.213134 139684108298048 pytorch_submission_base.py:86] 123000) loss = 2.194, grad_norm = 3.164
I0915 17:15:17.771673 139684108298048 spec.py:320] Evaluating on the training split.
I0915 17:16:02.207227 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 17:16:47.552964 139684108298048 spec.py:348] Evaluating on the test split.
I0915 17:16:48.944660 139684108298048 submission_runner.py:376] Time since start: 62001.97s, 	Step: 123204, 	{'train/accuracy': 0.879296875, 'train/loss': 0.4496475601196289, 'validation/accuracy': 0.77348, 'validation/loss': 0.894118046875, 'validation/num_examples': 50000, 'test/accuracy': 0.6516, 'test/loss': 1.4974009765625, 'test/num_examples': 10000, 'score': 50343.63953948021, 'total_duration': 62001.96954059601, 'accumulated_submission_time': 50343.63953948021, 'accumulated_eval_time': 11382.631391525269, 'accumulated_logging_time': 3.881122350692749}
I0915 17:16:48.971134 139640336475904 logging_writer.py:48] [123204] accumulated_eval_time=11382.631392, accumulated_logging_time=3.881122, accumulated_submission_time=50343.639539, global_step=123204, preemption_count=0, score=50343.639539, test/accuracy=0.651600, test/loss=1.497401, test/num_examples=10000, total_duration=62001.969541, train/accuracy=0.879297, train/loss=0.449648, validation/accuracy=0.773480, validation/loss=0.894118, validation/num_examples=50000
I0915 17:18:49.988074 139639855773440 logging_writer.py:48] [123500] global_step=123500, grad_norm=2.788358, loss=1.586928
I0915 17:18:49.994015 139684108298048 pytorch_submission_base.py:86] 123500) loss = 1.587, grad_norm = 2.788
I0915 17:22:16.468128 139640336475904 logging_writer.py:48] [124000] global_step=124000, grad_norm=2.823268, loss=2.295470
I0915 17:22:16.474672 139684108298048 pytorch_submission_base.py:86] 124000) loss = 2.295, grad_norm = 2.823
I0915 17:23:50.242251 139684108298048 spec.py:320] Evaluating on the training split.
I0915 17:24:34.379122 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 17:25:19.597502 139684108298048 spec.py:348] Evaluating on the test split.
I0915 17:25:20.988358 139684108298048 submission_runner.py:376] Time since start: 62514.01s, 	Step: 124229, 	{'train/accuracy': 0.87962890625, 'train/loss': 0.4486012268066406, 'validation/accuracy': 0.77404, 'validation/loss': 0.89386375, 'validation/num_examples': 50000, 'test/accuracy': 0.6553, 'test/loss': 1.4921673828125, 'test/num_examples': 10000, 'score': 50762.70052814484, 'total_duration': 62514.01327896118, 'accumulated_submission_time': 50762.70052814484, 'accumulated_eval_time': 11473.377854347229, 'accumulated_logging_time': 3.9163777828216553}
I0915 17:25:21.016607 139639855773440 logging_writer.py:48] [124229] accumulated_eval_time=11473.377854, accumulated_logging_time=3.916378, accumulated_submission_time=50762.700528, global_step=124229, preemption_count=0, score=50762.700528, test/accuracy=0.655300, test/loss=1.492167, test/num_examples=10000, total_duration=62514.013279, train/accuracy=0.879629, train/loss=0.448601, validation/accuracy=0.774040, validation/loss=0.893864, validation/num_examples=50000
I0915 17:27:12.043195 139640336475904 logging_writer.py:48] [124500] global_step=124500, grad_norm=2.981256, loss=1.852795
I0915 17:27:12.048055 139684108298048 pytorch_submission_base.py:86] 124500) loss = 1.853, grad_norm = 2.981
I0915 17:30:35.551565 139639855773440 logging_writer.py:48] [125000] global_step=125000, grad_norm=3.205132, loss=2.352544
I0915 17:30:35.559176 139684108298048 pytorch_submission_base.py:86] 125000) loss = 2.353, grad_norm = 3.205
I0915 17:32:22.268193 139684108298048 spec.py:320] Evaluating on the training split.
I0915 17:33:08.298163 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 17:33:56.456408 139684108298048 spec.py:348] Evaluating on the test split.
I0915 17:33:57.848003 139684108298048 submission_runner.py:376] Time since start: 63030.87s, 	Step: 125255, 	{'train/accuracy': 0.88146484375, 'train/loss': 0.44205703735351565, 'validation/accuracy': 0.77508, 'validation/loss': 0.885947734375, 'validation/num_examples': 50000, 'test/accuracy': 0.6554, 'test/loss': 1.4920251953125, 'test/num_examples': 10000, 'score': 51181.74163556099, 'total_duration': 63030.87289118767, 'accumulated_submission_time': 51181.74163556099, 'accumulated_eval_time': 11568.957940101624, 'accumulated_logging_time': 3.954512119293213}
I0915 17:33:57.878091 139640336475904 logging_writer.py:48] [125255] accumulated_eval_time=11568.957940, accumulated_logging_time=3.954512, accumulated_submission_time=51181.741636, global_step=125255, preemption_count=0, score=51181.741636, test/accuracy=0.655400, test/loss=1.492025, test/num_examples=10000, total_duration=63030.872891, train/accuracy=0.881465, train/loss=0.442057, validation/accuracy=0.775080, validation/loss=0.885948, validation/num_examples=50000
I0915 17:35:38.801712 139639855773440 logging_writer.py:48] [125500] global_step=125500, grad_norm=3.015462, loss=1.663377
I0915 17:35:38.807704 139684108298048 pytorch_submission_base.py:86] 125500) loss = 1.663, grad_norm = 3.015
I0915 17:39:01.809757 139640336475904 logging_writer.py:48] [126000] global_step=126000, grad_norm=2.828714, loss=1.300779
I0915 17:39:01.816122 139684108298048 pytorch_submission_base.py:86] 126000) loss = 1.301, grad_norm = 2.829
I0915 17:40:59.129888 139684108298048 spec.py:320] Evaluating on the training split.
I0915 17:41:44.590770 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 17:42:29.882940 139684108298048 spec.py:348] Evaluating on the test split.
I0915 17:42:31.275549 139684108298048 submission_runner.py:376] Time since start: 63544.30s, 	Step: 126286, 	{'train/accuracy': 0.88337890625, 'train/loss': 0.43346576690673827, 'validation/accuracy': 0.77514, 'validation/loss': 0.881525390625, 'validation/num_examples': 50000, 'test/accuracy': 0.654, 'test/loss': 1.4870451171875, 'test/num_examples': 10000, 'score': 51600.6655356884, 'total_duration': 63544.30040001869, 'accumulated_submission_time': 51600.6655356884, 'accumulated_eval_time': 11661.104115486145, 'accumulated_logging_time': 3.9934654235839844}
I0915 17:42:31.306409 139639855773440 logging_writer.py:48] [126286] accumulated_eval_time=11661.104115, accumulated_logging_time=3.993465, accumulated_submission_time=51600.665536, global_step=126286, preemption_count=0, score=51600.665536, test/accuracy=0.654000, test/loss=1.487045, test/num_examples=10000, total_duration=63544.300400, train/accuracy=0.883379, train/loss=0.433466, validation/accuracy=0.775140, validation/loss=0.881525, validation/num_examples=50000
I0915 17:44:01.936612 139640336475904 logging_writer.py:48] [126500] global_step=126500, grad_norm=2.951578, loss=1.947938
I0915 17:44:01.941052 139684108298048 pytorch_submission_base.py:86] 126500) loss = 1.948, grad_norm = 2.952
I0915 17:47:25.290741 139639855773440 logging_writer.py:48] [127000] global_step=127000, grad_norm=2.935758, loss=1.679074
I0915 17:47:25.299203 139684108298048 pytorch_submission_base.py:86] 127000) loss = 1.679, grad_norm = 2.936
I0915 17:49:32.792213 139684108298048 spec.py:320] Evaluating on the training split.
I0915 17:50:16.682420 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 17:51:08.711424 139684108298048 spec.py:348] Evaluating on the test split.
I0915 17:51:10.103546 139684108298048 submission_runner.py:376] Time since start: 64063.13s, 	Step: 127313, 	{'train/accuracy': 0.88462890625, 'train/loss': 0.4279958343505859, 'validation/accuracy': 0.77534, 'validation/loss': 0.88004359375, 'validation/num_examples': 50000, 'test/accuracy': 0.6558, 'test/loss': 1.48254462890625, 'test/num_examples': 10000, 'score': 52019.81285524368, 'total_duration': 64063.12843108177, 'accumulated_submission_time': 52019.81285524368, 'accumulated_eval_time': 11758.416033506393, 'accumulated_logging_time': 4.033597469329834}
I0915 17:51:10.128427 139640336475904 logging_writer.py:48] [127313] accumulated_eval_time=11758.416034, accumulated_logging_time=4.033597, accumulated_submission_time=52019.812855, global_step=127313, preemption_count=0, score=52019.812855, test/accuracy=0.655800, test/loss=1.482545, test/num_examples=10000, total_duration=64063.128431, train/accuracy=0.884629, train/loss=0.427996, validation/accuracy=0.775340, validation/loss=0.880044, validation/num_examples=50000
I0915 17:52:28.235338 139639855773440 logging_writer.py:48] [127500] global_step=127500, grad_norm=3.246116, loss=1.951047
I0915 17:52:28.240769 139684108298048 pytorch_submission_base.py:86] 127500) loss = 1.951, grad_norm = 3.246
I0915 17:55:53.999679 139640336475904 logging_writer.py:48] [128000] global_step=128000, grad_norm=3.000928, loss=1.672549
I0915 17:55:54.005354 139684108298048 pytorch_submission_base.py:86] 128000) loss = 1.673, grad_norm = 3.001
I0915 17:58:11.477584 139684108298048 spec.py:320] Evaluating on the training split.
I0915 17:58:57.965475 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 17:59:43.582245 139684108298048 spec.py:348] Evaluating on the test split.
I0915 17:59:44.973846 139684108298048 submission_runner.py:376] Time since start: 64578.00s, 	Step: 128336, 	{'train/accuracy': 0.88435546875, 'train/loss': 0.4303166961669922, 'validation/accuracy': 0.77596, 'validation/loss': 0.878986171875, 'validation/num_examples': 50000, 'test/accuracy': 0.6577, 'test/loss': 1.483891796875, 'test/num_examples': 10000, 'score': 52438.90845966339, 'total_duration': 64577.99871850014, 'accumulated_submission_time': 52438.90845966339, 'accumulated_eval_time': 11851.912655353546, 'accumulated_logging_time': 4.067496061325073}
I0915 17:59:44.999717 139639855773440 logging_writer.py:48] [128336] accumulated_eval_time=11851.912655, accumulated_logging_time=4.067496, accumulated_submission_time=52438.908460, global_step=128336, preemption_count=0, score=52438.908460, test/accuracy=0.657700, test/loss=1.483892, test/num_examples=10000, total_duration=64577.998719, train/accuracy=0.884355, train/loss=0.430317, validation/accuracy=0.775960, validation/loss=0.878986, validation/num_examples=50000
I0915 18:00:52.597710 139640336475904 logging_writer.py:48] [128500] global_step=128500, grad_norm=2.747428, loss=1.449627
I0915 18:00:52.602650 139684108298048 pytorch_submission_base.py:86] 128500) loss = 1.450, grad_norm = 2.747
I0915 18:04:19.532793 139639855773440 logging_writer.py:48] [129000] global_step=129000, grad_norm=2.872783, loss=1.682557
I0915 18:04:19.539049 139684108298048 pytorch_submission_base.py:86] 129000) loss = 1.683, grad_norm = 2.873
I0915 18:06:46.211790 139684108298048 spec.py:320] Evaluating on the training split.
I0915 18:07:30.308894 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 18:08:16.037982 139684108298048 spec.py:348] Evaluating on the test split.
I0915 18:08:17.429286 139684108298048 submission_runner.py:376] Time since start: 65090.45s, 	Step: 129359, 	{'train/accuracy': 0.88505859375, 'train/loss': 0.4245481491088867, 'validation/accuracy': 0.77772, 'validation/loss': 0.874736328125, 'validation/num_examples': 50000, 'test/accuracy': 0.6587, 'test/loss': 1.47700703125, 'test/num_examples': 10000, 'score': 52857.84574651718, 'total_duration': 65090.454199552536, 'accumulated_submission_time': 52857.84574651718, 'accumulated_eval_time': 11943.130467414856, 'accumulated_logging_time': 4.104768991470337}
I0915 18:08:17.458555 139640336475904 logging_writer.py:48] [129359] accumulated_eval_time=11943.130467, accumulated_logging_time=4.104769, accumulated_submission_time=52857.845747, global_step=129359, preemption_count=0, score=52857.845747, test/accuracy=0.658700, test/loss=1.477007, test/num_examples=10000, total_duration=65090.454200, train/accuracy=0.885059, train/loss=0.424548, validation/accuracy=0.777720, validation/loss=0.874736, validation/num_examples=50000
I0915 18:09:15.908941 139639855773440 logging_writer.py:48] [129500] global_step=129500, grad_norm=2.876975, loss=2.082697
I0915 18:09:15.913827 139684108298048 pytorch_submission_base.py:86] 129500) loss = 2.083, grad_norm = 2.877
I0915 18:12:38.808955 139640336475904 logging_writer.py:48] [130000] global_step=130000, grad_norm=2.935901, loss=1.982522
I0915 18:12:38.815166 139684108298048 pytorch_submission_base.py:86] 130000) loss = 1.983, grad_norm = 2.936
I0915 18:15:18.818062 139684108298048 spec.py:320] Evaluating on the training split.
I0915 18:16:03.288377 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 18:16:48.933110 139684108298048 spec.py:348] Evaluating on the test split.
I0915 18:16:50.327761 139684108298048 submission_runner.py:376] Time since start: 65603.35s, 	Step: 130385, 	{'train/accuracy': 0.88658203125, 'train/loss': 0.4211970520019531, 'validation/accuracy': 0.77796, 'validation/loss': 0.873415, 'validation/num_examples': 50000, 'test/accuracy': 0.6603, 'test/loss': 1.476080078125, 'test/num_examples': 10000, 'score': 53276.92240381241, 'total_duration': 65603.35263514519, 'accumulated_submission_time': 53276.92240381241, 'accumulated_eval_time': 12034.640534162521, 'accumulated_logging_time': 4.146943807601929}
I0915 18:16:50.353695 139639855773440 logging_writer.py:48] [130385] accumulated_eval_time=12034.640534, accumulated_logging_time=4.146944, accumulated_submission_time=53276.922404, global_step=130385, preemption_count=0, score=53276.922404, test/accuracy=0.660300, test/loss=1.476080, test/num_examples=10000, total_duration=65603.352635, train/accuracy=0.886582, train/loss=0.421197, validation/accuracy=0.777960, validation/loss=0.873415, validation/num_examples=50000
I0915 18:17:38.301421 139640336475904 logging_writer.py:48] [130500] global_step=130500, grad_norm=2.951608, loss=1.513241
I0915 18:17:38.306986 139684108298048 pytorch_submission_base.py:86] 130500) loss = 1.513, grad_norm = 2.952
I0915 18:21:01.571262 139639855773440 logging_writer.py:48] [131000] global_step=131000, grad_norm=3.138804, loss=1.903284
I0915 18:21:01.580401 139684108298048 pytorch_submission_base.py:86] 131000) loss = 1.903, grad_norm = 3.139
I0915 18:23:51.525150 139684108298048 spec.py:320] Evaluating on the training split.
I0915 18:24:37.338747 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 18:25:28.861263 139684108298048 spec.py:348] Evaluating on the test split.
I0915 18:25:30.253175 139684108298048 submission_runner.py:376] Time since start: 66123.28s, 	Step: 131408, 	{'train/accuracy': 0.8862109375, 'train/loss': 0.4214011764526367, 'validation/accuracy': 0.7775, 'validation/loss': 0.87469390625, 'validation/num_examples': 50000, 'test/accuracy': 0.6594, 'test/loss': 1.47858974609375, 'test/num_examples': 10000, 'score': 53695.83012843132, 'total_duration': 66123.27806687355, 'accumulated_submission_time': 53695.83012843132, 'accumulated_eval_time': 12133.368770599365, 'accumulated_logging_time': 4.182413578033447}
I0915 18:25:30.284466 139640336475904 logging_writer.py:48] [131408] accumulated_eval_time=12133.368771, accumulated_logging_time=4.182414, accumulated_submission_time=53695.830128, global_step=131408, preemption_count=0, score=53695.830128, test/accuracy=0.659400, test/loss=1.478590, test/num_examples=10000, total_duration=66123.278067, train/accuracy=0.886211, train/loss=0.421401, validation/accuracy=0.777500, validation/loss=0.874694, validation/num_examples=50000
I0915 18:26:08.817089 139639855773440 logging_writer.py:48] [131500] global_step=131500, grad_norm=2.938002, loss=1.893849
I0915 18:26:08.822009 139684108298048 pytorch_submission_base.py:86] 131500) loss = 1.894, grad_norm = 2.938
I0915 18:29:32.253777 139640336475904 logging_writer.py:48] [132000] global_step=132000, grad_norm=2.729850, loss=1.257117
I0915 18:29:32.260440 139684108298048 pytorch_submission_base.py:86] 132000) loss = 1.257, grad_norm = 2.730
I0915 18:32:31.750786 139684108298048 spec.py:320] Evaluating on the training split.
I0915 18:33:16.614736 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 18:34:05.135359 139684108298048 spec.py:348] Evaluating on the test split.
I0915 18:34:06.532590 139684108298048 submission_runner.py:376] Time since start: 66639.56s, 	Step: 132441, 	{'train/accuracy': 0.8872265625, 'train/loss': 0.4180831146240234, 'validation/accuracy': 0.77772, 'validation/loss': 0.8720446875, 'validation/num_examples': 50000, 'test/accuracy': 0.6611, 'test/loss': 1.47518642578125, 'test/num_examples': 10000, 'score': 54114.94544124603, 'total_duration': 66639.55735588074, 'accumulated_submission_time': 54114.94544124603, 'accumulated_eval_time': 12228.151146888733, 'accumulated_logging_time': 4.2230565547943115}
I0915 18:34:06.563653 139639855773440 logging_writer.py:48] [132441] accumulated_eval_time=12228.151147, accumulated_logging_time=4.223057, accumulated_submission_time=54114.945441, global_step=132441, preemption_count=0, score=54114.945441, test/accuracy=0.661100, test/loss=1.475186, test/num_examples=10000, total_duration=66639.557356, train/accuracy=0.887227, train/loss=0.418083, validation/accuracy=0.777720, validation/loss=0.872045, validation/num_examples=50000
I0915 18:34:31.788074 139640336475904 logging_writer.py:48] [132500] global_step=132500, grad_norm=3.331679, loss=1.673021
I0915 18:34:31.792387 139684108298048 pytorch_submission_base.py:86] 132500) loss = 1.673, grad_norm = 3.332
I0915 18:37:58.481623 139639855773440 logging_writer.py:48] [133000] global_step=133000, grad_norm=3.081916, loss=1.750055
I0915 18:37:58.492820 139684108298048 pytorch_submission_base.py:86] 133000) loss = 1.750, grad_norm = 3.082
I0915 18:41:07.851736 139684108298048 spec.py:320] Evaluating on the training split.
I0915 18:41:51.766703 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 18:42:37.193284 139684108298048 spec.py:348] Evaluating on the test split.
I0915 18:42:38.584579 139684108298048 submission_runner.py:376] Time since start: 67151.61s, 	Step: 133464, 	{'train/accuracy': 0.887578125, 'train/loss': 0.41458595275878907, 'validation/accuracy': 0.77758, 'validation/loss': 0.868998515625, 'validation/num_examples': 50000, 'test/accuracy': 0.6601, 'test/loss': 1.47671103515625, 'test/num_examples': 10000, 'score': 54533.94416356087, 'total_duration': 67151.60945224762, 'accumulated_submission_time': 54533.94416356087, 'accumulated_eval_time': 12318.884562015533, 'accumulated_logging_time': 4.263211965560913}
I0915 18:42:38.609821 139640336475904 logging_writer.py:48] [133464] accumulated_eval_time=12318.884562, accumulated_logging_time=4.263212, accumulated_submission_time=54533.944164, global_step=133464, preemption_count=0, score=54533.944164, test/accuracy=0.660100, test/loss=1.476711, test/num_examples=10000, total_duration=67151.609452, train/accuracy=0.887578, train/loss=0.414586, validation/accuracy=0.777580, validation/loss=0.868999, validation/num_examples=50000
I0915 18:42:54.290002 139639855773440 logging_writer.py:48] [133500] global_step=133500, grad_norm=2.972933, loss=2.060668
I0915 18:42:54.296015 139684108298048 pytorch_submission_base.py:86] 133500) loss = 2.061, grad_norm = 2.973
I0915 18:46:20.385440 139640336475904 logging_writer.py:48] [134000] global_step=134000, grad_norm=2.978037, loss=1.322709
I0915 18:46:20.391048 139684108298048 pytorch_submission_base.py:86] 134000) loss = 1.323, grad_norm = 2.978
I0915 18:49:39.872952 139684108298048 spec.py:320] Evaluating on the training split.
I0915 18:50:23.940170 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 18:51:09.354724 139684108298048 spec.py:348] Evaluating on the test split.
I0915 18:51:10.745275 139684108298048 submission_runner.py:376] Time since start: 67663.77s, 	Step: 134489, 	{'train/accuracy': 0.88837890625, 'train/loss': 0.4153050231933594, 'validation/accuracy': 0.77728, 'validation/loss': 0.87169921875, 'validation/num_examples': 50000, 'test/accuracy': 0.6599, 'test/loss': 1.47665751953125, 'test/num_examples': 10000, 'score': 54952.920229673386, 'total_duration': 67663.77019453049, 'accumulated_submission_time': 54952.920229673386, 'accumulated_eval_time': 12409.757031202316, 'accumulated_logging_time': 4.3004326820373535}
I0915 18:51:10.774690 139639855773440 logging_writer.py:48] [134489] accumulated_eval_time=12409.757031, accumulated_logging_time=4.300433, accumulated_submission_time=54952.920230, global_step=134489, preemption_count=0, score=54952.920230, test/accuracy=0.659900, test/loss=1.476658, test/num_examples=10000, total_duration=67663.770195, train/accuracy=0.888379, train/loss=0.415305, validation/accuracy=0.777280, validation/loss=0.871699, validation/num_examples=50000
I0915 18:51:16.452837 139640336475904 logging_writer.py:48] [134500] global_step=134500, grad_norm=2.989586, loss=1.961170
I0915 18:51:16.457792 139684108298048 pytorch_submission_base.py:86] 134500) loss = 1.961, grad_norm = 2.990
I0915 18:54:40.969599 139639855773440 logging_writer.py:48] [135000] global_step=135000, grad_norm=2.862175, loss=1.447373
I0915 18:54:40.974871 139684108298048 pytorch_submission_base.py:86] 135000) loss = 1.447, grad_norm = 2.862
I0915 18:58:06.730708 139640336475904 logging_writer.py:48] [135500] global_step=135500, grad_norm=2.762301, loss=1.661705
I0915 18:58:06.739774 139684108298048 pytorch_submission_base.py:86] 135500) loss = 1.662, grad_norm = 2.762
I0915 18:58:11.826701 139684108298048 spec.py:320] Evaluating on the training split.
I0915 18:58:55.989850 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 18:59:41.285565 139684108298048 spec.py:348] Evaluating on the test split.
I0915 18:59:42.678442 139684108298048 submission_runner.py:376] Time since start: 68175.70s, 	Step: 135511, 	{'train/accuracy': 0.88818359375, 'train/loss': 0.41580307006835937, 'validation/accuracy': 0.7778, 'validation/loss': 0.87091265625, 'validation/num_examples': 50000, 'test/accuracy': 0.6618, 'test/loss': 1.4742875, 'test/num_examples': 10000, 'score': 55371.69947171211, 'total_duration': 68175.7032225132, 'accumulated_submission_time': 55371.69947171211, 'accumulated_eval_time': 12500.60895872116, 'accumulated_logging_time': 4.342997789382935}
I0915 18:59:42.713271 139639855773440 logging_writer.py:48] [135511] accumulated_eval_time=12500.608959, accumulated_logging_time=4.342998, accumulated_submission_time=55371.699472, global_step=135511, preemption_count=0, score=55371.699472, test/accuracy=0.661800, test/loss=1.474287, test/num_examples=10000, total_duration=68175.703223, train/accuracy=0.888184, train/loss=0.415803, validation/accuracy=0.777800, validation/loss=0.870913, validation/num_examples=50000
I0915 19:03:02.172105 139640336475904 logging_writer.py:48] [136000] global_step=136000, grad_norm=3.190013, loss=1.464678
I0915 19:03:02.177976 139684108298048 pytorch_submission_base.py:86] 136000) loss = 1.465, grad_norm = 3.190
I0915 19:06:29.870277 139639855773440 logging_writer.py:48] [136500] global_step=136500, grad_norm=3.262361, loss=2.474104
I0915 19:06:29.878016 139684108298048 pytorch_submission_base.py:86] 136500) loss = 2.474, grad_norm = 3.262
I0915 19:06:43.905716 139684108298048 spec.py:320] Evaluating on the training split.
I0915 19:07:29.919227 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 19:08:16.367199 139684108298048 spec.py:348] Evaluating on the test split.
I0915 19:08:17.760174 139684108298048 submission_runner.py:376] Time since start: 68690.79s, 	Step: 136533, 	{'train/accuracy': 0.888359375, 'train/loss': 0.41403865814208984, 'validation/accuracy': 0.77814, 'validation/loss': 0.86959609375, 'validation/num_examples': 50000, 'test/accuracy': 0.6617, 'test/loss': 1.4733244140625, 'test/num_examples': 10000, 'score': 55790.65551114082, 'total_duration': 68690.78505969048, 'accumulated_submission_time': 55790.65551114082, 'accumulated_eval_time': 12594.463595628738, 'accumulated_logging_time': 4.386544227600098}
I0915 19:08:17.787836 139640336475904 logging_writer.py:48] [136533] accumulated_eval_time=12594.463596, accumulated_logging_time=4.386544, accumulated_submission_time=55790.655511, global_step=136533, preemption_count=0, score=55790.655511, test/accuracy=0.661700, test/loss=1.473324, test/num_examples=10000, total_duration=68690.785060, train/accuracy=0.888359, train/loss=0.414039, validation/accuracy=0.778140, validation/loss=0.869596, validation/num_examples=50000
I0915 19:11:29.028501 139639855773440 logging_writer.py:48] [137000] global_step=137000, grad_norm=2.944157, loss=1.392961
I0915 19:11:29.034879 139684108298048 pytorch_submission_base.py:86] 137000) loss = 1.393, grad_norm = 2.944
I0915 19:14:53.137064 139640336475904 logging_writer.py:48] [137500] global_step=137500, grad_norm=2.883149, loss=1.532587
I0915 19:14:53.144245 139684108298048 pytorch_submission_base.py:86] 137500) loss = 1.533, grad_norm = 2.883
I0915 19:15:18.922029 139684108298048 spec.py:320] Evaluating on the training split.
I0915 19:16:04.255080 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 19:16:49.832284 139684108298048 spec.py:348] Evaluating on the test split.
I0915 19:16:51.220147 139684108298048 submission_runner.py:376] Time since start: 69204.25s, 	Step: 137561, 	{'train/accuracy': 0.8884375, 'train/loss': 0.4130818176269531, 'validation/accuracy': 0.7782, 'validation/loss': 0.8689665625, 'validation/num_examples': 50000, 'test/accuracy': 0.6611, 'test/loss': 1.47291494140625, 'test/num_examples': 10000, 'score': 56209.52092504501, 'total_duration': 69204.24505281448, 'accumulated_submission_time': 56209.52092504501, 'accumulated_eval_time': 12686.76236653328, 'accumulated_logging_time': 4.422796249389648}
I0915 19:16:51.245740 139639855773440 logging_writer.py:48] [137561] accumulated_eval_time=12686.762367, accumulated_logging_time=4.422796, accumulated_submission_time=56209.520925, global_step=137561, preemption_count=0, score=56209.520925, test/accuracy=0.661100, test/loss=1.472915, test/num_examples=10000, total_duration=69204.245053, train/accuracy=0.888437, train/loss=0.413082, validation/accuracy=0.778200, validation/loss=0.868967, validation/num_examples=50000
I0915 19:19:52.911309 139640336475904 logging_writer.py:48] [138000] global_step=138000, grad_norm=3.124321, loss=1.958494
I0915 19:19:52.917858 139684108298048 pytorch_submission_base.py:86] 138000) loss = 1.958, grad_norm = 3.124
I0915 19:23:16.084350 139639855773440 logging_writer.py:48] [138500] global_step=138500, grad_norm=2.883471, loss=1.698864
I0915 19:23:16.089304 139684108298048 pytorch_submission_base.py:86] 138500) loss = 1.699, grad_norm = 2.883
I0915 19:23:52.510678 139684108298048 spec.py:320] Evaluating on the training split.
I0915 19:24:36.672795 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 19:25:30.790730 139684108298048 spec.py:348] Evaluating on the test split.
I0915 19:25:32.182086 139684108298048 submission_runner.py:376] Time since start: 69725.21s, 	Step: 138588, 	{'train/accuracy': 0.88880859375, 'train/loss': 0.4131156539916992, 'validation/accuracy': 0.77842, 'validation/loss': 0.868383984375, 'validation/num_examples': 50000, 'test/accuracy': 0.6614, 'test/loss': 1.471919140625, 'test/num_examples': 10000, 'score': 56628.483342409134, 'total_duration': 69725.20699548721, 'accumulated_submission_time': 56628.483342409134, 'accumulated_eval_time': 12786.434039115906, 'accumulated_logging_time': 4.458261966705322}
I0915 19:25:32.208763 139640336475904 logging_writer.py:48] [138588] accumulated_eval_time=12786.434039, accumulated_logging_time=4.458262, accumulated_submission_time=56628.483342, global_step=138588, preemption_count=0, score=56628.483342, test/accuracy=0.661400, test/loss=1.471919, test/num_examples=10000, total_duration=69725.206995, train/accuracy=0.888809, train/loss=0.413116, validation/accuracy=0.778420, validation/loss=0.868384, validation/num_examples=50000
I0915 19:28:23.955029 139639855773440 logging_writer.py:48] [139000] global_step=139000, grad_norm=3.185579, loss=1.731099
I0915 19:28:23.961220 139684108298048 pytorch_submission_base.py:86] 139000) loss = 1.731, grad_norm = 3.186
I0915 19:31:47.111829 139640336475904 logging_writer.py:48] [139500] global_step=139500, grad_norm=2.887619, loss=1.729867
I0915 19:31:47.117717 139684108298048 pytorch_submission_base.py:86] 139500) loss = 1.730, grad_norm = 2.888
I0915 19:32:33.203058 139684108298048 spec.py:320] Evaluating on the training split.
I0915 19:33:19.378502 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 19:34:06.464863 139684108298048 spec.py:348] Evaluating on the test split.
I0915 19:34:07.858936 139684108298048 submission_runner.py:376] Time since start: 70240.88s, 	Step: 139612, 	{'train/accuracy': 0.8887109375, 'train/loss': 0.41284698486328125, 'validation/accuracy': 0.77836, 'validation/loss': 0.868195078125, 'validation/num_examples': 50000, 'test/accuracy': 0.6622, 'test/loss': 1.47205478515625, 'test/num_examples': 10000, 'score': 57047.25692439079, 'total_duration': 70240.88380050659, 'accumulated_submission_time': 57047.25692439079, 'accumulated_eval_time': 12881.090112924576, 'accumulated_logging_time': 4.495534181594849}
I0915 19:34:07.889547 139639855773440 logging_writer.py:48] [139612] accumulated_eval_time=12881.090113, accumulated_logging_time=4.495534, accumulated_submission_time=57047.256924, global_step=139612, preemption_count=0, score=57047.256924, test/accuracy=0.662200, test/loss=1.472055, test/num_examples=10000, total_duration=70240.883801, train/accuracy=0.888711, train/loss=0.412847, validation/accuracy=0.778360, validation/loss=0.868195, validation/num_examples=50000
I0915 19:36:48.002939 139684108298048 spec.py:320] Evaluating on the training split.
I0915 19:37:32.298884 139684108298048 spec.py:332] Evaluating on the validation split.
I0915 19:38:17.484295 139684108298048 spec.py:348] Evaluating on the test split.
I0915 19:38:18.877100 139684108298048 submission_runner.py:376] Time since start: 70491.90s, 	Step: 140000, 	{'train/accuracy': 0.88865234375, 'train/loss': 0.4128573989868164, 'validation/accuracy': 0.77834, 'validation/loss': 0.86820859375, 'validation/num_examples': 50000, 'test/accuracy': 0.6622, 'test/loss': 1.47203828125, 'test/num_examples': 10000, 'score': 57205.48697280884, 'total_duration': 70491.90201473236, 'accumulated_submission_time': 57205.48697280884, 'accumulated_eval_time': 12971.965034484863, 'accumulated_logging_time': 4.539530038833618}
I0915 19:38:18.902055 139640336475904 logging_writer.py:48] [140000] accumulated_eval_time=12971.965034, accumulated_logging_time=4.539530, accumulated_submission_time=57205.486973, global_step=140000, preemption_count=0, score=57205.486973, test/accuracy=0.662200, test/loss=1.472038, test/num_examples=10000, total_duration=70491.902015, train/accuracy=0.888652, train/loss=0.412857, validation/accuracy=0.778340, validation/loss=0.868209, validation/num_examples=50000
I0915 19:38:19.463533 139639855773440 logging_writer.py:48] [140000] global_step=140000, preemption_count=0, score=57205.486973
I0915 19:38:20.096328 139684108298048 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/targets_check_pytorch/nadamw_run_0/imagenet_vit_pytorch/trial_1/checkpoint_140000.
I0915 19:38:20.729766 139684108298048 submission_runner.py:540] Tuning trial 1/1
I0915 19:38:20.730078 139684108298048 submission_runner.py:541] Hyperparameters: Hyperparameters(learning_rate=0.0008445074561975979, beta1=0.8895758153482813, beta2=0.9978504782314613, warmup_steps=6999, weight_decay=0.08135402759553023)
I0915 19:38:20.734997 139684108298048 submission_runner.py:542] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0026171875, 'train/loss': 6.90775634765625, 'validation/accuracy': 0.0024, 'validation/loss': 6.907755625, 'validation/num_examples': 50000, 'test/accuracy': 0.002, 'test/loss': 6.90775546875, 'test/num_examples': 10000, 'score': 65.70964407920837, 'total_duration': 255.70850658416748, 'accumulated_submission_time': 65.70964407920837, 'accumulated_eval_time': 189.55266499519348, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (1033, {'train/accuracy': 0.02626953125, 'train/loss': 6.08369873046875, 'validation/accuracy': 0.02534, 'validation/loss': 6.108815625, 'validation/num_examples': 50000, 'test/accuracy': 0.0176, 'test/loss': 6.18779921875, 'test/num_examples': 10000, 'score': 484.74924492836, 'total_duration': 777.4552552700043, 'accumulated_submission_time': 484.74924492836, 'accumulated_eval_time': 289.82026290893555, 'accumulated_logging_time': 0.030212879180908203, 'global_step': 1033, 'preemption_count': 0}), (2060, {'train/accuracy': 0.0691796875, 'train/loss': 5.352781372070313, 'validation/accuracy': 0.06678, 'validation/loss': 5.3990025, 'validation/num_examples': 50000, 'test/accuracy': 0.0514, 'test/loss': 5.591217578125, 'test/num_examples': 10000, 'score': 903.558568239212, 'total_duration': 1285.668110370636, 'accumulated_submission_time': 903.558568239212, 'accumulated_eval_time': 376.9129524230957, 'accumulated_logging_time': 0.06643295288085938, 'global_step': 2060, 'preemption_count': 0}), (3089, {'train/accuracy': 0.1134765625, 'train/loss': 4.862177429199218, 'validation/accuracy': 0.10374, 'validation/loss': 4.9325371875, 'validation/num_examples': 50000, 'test/accuracy': 0.077, 'test/loss': 5.242923046875, 'test/num_examples': 10000, 'score': 1322.326075553894, 'total_duration': 1795.1200304031372, 'accumulated_submission_time': 1322.326075553894, 'accumulated_eval_time': 465.32336616516113, 'accumulated_logging_time': 0.09168696403503418, 'global_step': 3089, 'preemption_count': 0}), (4118, {'train/accuracy': 0.1684765625, 'train/loss': 4.366781616210938, 'validation/accuracy': 0.16056, 'validation/loss': 4.446858125, 'validation/num_examples': 50000, 'test/accuracy': 0.125, 'test/loss': 4.763651171875, 'test/num_examples': 10000, 'score': 1741.4536910057068, 'total_duration': 2305.948929786682, 'accumulated_submission_time': 1741.4536910057068, 'accumulated_eval_time': 554.7858331203461, 'accumulated_logging_time': 0.12237405776977539, 'global_step': 4118, 'preemption_count': 0}), (5147, {'train/accuracy': 0.22849609375, 'train/loss': 3.8848251342773437, 'validation/accuracy': 0.2131, 'validation/loss': 3.992564375, 'validation/num_examples': 50000, 'test/accuracy': 0.1575, 'test/loss': 4.410009375, 'test/num_examples': 10000, 'score': 2160.4416978359222, 'total_duration': 2818.6436960697174, 'accumulated_submission_time': 2160.4416978359222, 'accumulated_eval_time': 646.2004444599152, 'accumulated_logging_time': 0.1485135555267334, 'global_step': 5147, 'preemption_count': 0}), (6181, {'train/accuracy': 0.2867578125, 'train/loss': 3.4843060302734377, 'validation/accuracy': 0.26574, 'validation/loss': 3.6052284375, 'validation/num_examples': 50000, 'test/accuracy': 0.2008, 'test/loss': 4.079585546875, 'test/num_examples': 10000, 'score': 2579.516234397888, 'total_duration': 3339.805244207382, 'accumulated_submission_time': 2579.516234397888, 'accumulated_eval_time': 745.97585272789, 'accumulated_logging_time': 0.1744997501373291, 'global_step': 6181, 'preemption_count': 0}), (7210, {'train/accuracy': 0.3319140625, 'train/loss': 3.201805419921875, 'validation/accuracy': 0.3065, 'validation/loss': 3.3465034375, 'validation/num_examples': 50000, 'test/accuracy': 0.2317, 'test/loss': 3.844699609375, 'test/num_examples': 10000, 'score': 2998.426082611084, 'total_duration': 3851.3365049362183, 'accumulated_submission_time': 2998.426082611084, 'accumulated_eval_time': 836.2835268974304, 'accumulated_logging_time': 0.19990110397338867, 'global_step': 7210, 'preemption_count': 0}), (8236, {'train/accuracy': 0.3818359375, 'train/loss': 2.876129455566406, 'validation/accuracy': 0.3551, 'validation/loss': 3.021036875, 'validation/num_examples': 50000, 'test/accuracy': 0.275, 'test/loss': 3.566540625, 'test/num_examples': 10000, 'score': 3417.463707447052, 'total_duration': 4364.375236272812, 'accumulated_submission_time': 3417.463707447052, 'accumulated_eval_time': 927.9725637435913, 'accumulated_logging_time': 0.22741484642028809, 'global_step': 8236, 'preemption_count': 0}), (9263, {'train/accuracy': 0.4187109375, 'train/loss': 2.6722613525390626, 'validation/accuracy': 0.38584, 'validation/loss': 2.8444759375, 'validation/num_examples': 50000, 'test/accuracy': 0.2937, 'test/loss': 3.424807421875, 'test/num_examples': 10000, 'score': 3836.348623752594, 'total_duration': 4875.488702297211, 'accumulated_submission_time': 3836.348623752594, 'accumulated_eval_time': 1017.961156129837, 'accumulated_logging_time': 0.25620222091674805, 'global_step': 9263, 'preemption_count': 0}), (10291, {'train/accuracy': 0.4486328125, 'train/loss': 2.4993214416503906, 'validation/accuracy': 0.4168, 'validation/loss': 2.6679325, 'validation/num_examples': 50000, 'test/accuracy': 0.3239, 'test/loss': 3.2349083984375, 'test/num_examples': 10000, 'score': 4255.360187530518, 'total_duration': 5387.489059209824, 'accumulated_submission_time': 4255.360187530518, 'accumulated_eval_time': 1108.723829984665, 'accumulated_logging_time': 0.2835521697998047, 'global_step': 10291, 'preemption_count': 0}), (11320, {'train/accuracy': 0.47462890625, 'train/loss': 2.3745030212402343, 'validation/accuracy': 0.43826, 'validation/loss': 2.5582146875, 'validation/num_examples': 50000, 'test/accuracy': 0.3468, 'test/loss': 3.12915546875, 'test/num_examples': 10000, 'score': 4674.373912572861, 'total_duration': 5901.281381845474, 'accumulated_submission_time': 4674.373912572861, 'accumulated_eval_time': 1201.2859156131744, 'accumulated_logging_time': 0.30875205993652344, 'global_step': 11320, 'preemption_count': 0}), (12354, {'train/accuracy': 0.50400390625, 'train/loss': 2.20080810546875, 'validation/accuracy': 0.46488, 'validation/loss': 2.38894390625, 'validation/num_examples': 50000, 'test/accuracy': 0.3626, 'test/loss': 2.99171875, 'test/num_examples': 10000, 'score': 5093.282171964645, 'total_duration': 6422.80912733078, 'accumulated_submission_time': 5093.282171964645, 'accumulated_eval_time': 1301.562652349472, 'accumulated_logging_time': 0.3387117385864258, 'global_step': 12354, 'preemption_count': 0}), (13381, {'train/accuracy': 0.52501953125, 'train/loss': 2.06103759765625, 'validation/accuracy': 0.4867, 'validation/loss': 2.2611503125, 'validation/num_examples': 50000, 'test/accuracy': 0.3789, 'test/loss': 2.883974609375, 'test/num_examples': 10000, 'score': 5512.209890365601, 'total_duration': 6934.87442111969, 'accumulated_submission_time': 5512.209890365601, 'accumulated_eval_time': 1392.3178429603577, 'accumulated_logging_time': 0.364915132522583, 'global_step': 13381, 'preemption_count': 0}), (14407, {'train/accuracy': 0.542890625, 'train/loss': 1.9765310668945313, 'validation/accuracy': 0.5012, 'validation/loss': 2.1831240625, 'validation/num_examples': 50000, 'test/accuracy': 0.3947, 'test/loss': 2.80878984375, 'test/num_examples': 10000, 'score': 5931.344927072525, 'total_duration': 7446.914384126663, 'accumulated_submission_time': 5931.344927072525, 'accumulated_eval_time': 1482.9080996513367, 'accumulated_logging_time': 0.3952047824859619, 'global_step': 14407, 'preemption_count': 0}), (15435, {'train/accuracy': 0.55765625, 'train/loss': 1.9126416015625, 'validation/accuracy': 0.517, 'validation/loss': 2.12261234375, 'validation/num_examples': 50000, 'test/accuracy': 0.4091, 'test/loss': 2.727919921875, 'test/num_examples': 10000, 'score': 6350.162551641464, 'total_duration': 7958.526209115982, 'accumulated_submission_time': 6350.162551641464, 'accumulated_eval_time': 1573.4109802246094, 'accumulated_logging_time': 0.425351619720459, 'global_step': 15435, 'preemption_count': 0}), (16461, {'train/accuracy': 0.57162109375, 'train/loss': 1.82017822265625, 'validation/accuracy': 0.52508, 'validation/loss': 2.03893109375, 'validation/num_examples': 50000, 'test/accuracy': 0.413, 'test/loss': 2.680346875, 'test/num_examples': 10000, 'score': 6768.91895699501, 'total_duration': 8473.338947534561, 'accumulated_submission_time': 6768.91895699501, 'accumulated_eval_time': 1667.1897485256195, 'accumulated_logging_time': 0.4525120258331299, 'global_step': 16461, 'preemption_count': 0}), (17492, {'train/accuracy': 0.59095703125, 'train/loss': 1.7585520935058594, 'validation/accuracy': 0.54238, 'validation/loss': 1.982668125, 'validation/num_examples': 50000, 'test/accuracy': 0.4277, 'test/loss': 2.6225697265625, 'test/num_examples': 10000, 'score': 7187.769836425781, 'total_duration': 8986.532859563828, 'accumulated_submission_time': 7187.769836425781, 'accumulated_eval_time': 1759.226996421814, 'accumulated_logging_time': 0.48085522651672363, 'global_step': 17492, 'preemption_count': 0}), (18520, {'train/accuracy': 0.60359375, 'train/loss': 1.67911376953125, 'validation/accuracy': 0.55544, 'validation/loss': 1.9092615625, 'validation/num_examples': 50000, 'test/accuracy': 0.4379, 'test/loss': 2.5372498046875, 'test/num_examples': 10000, 'score': 7606.83567404747, 'total_duration': 9506.200477838516, 'accumulated_submission_time': 7606.83567404747, 'accumulated_eval_time': 1857.4695353507996, 'accumulated_logging_time': 0.5122838020324707, 'global_step': 18520, 'preemption_count': 0}), (19547, {'train/accuracy': 0.6109765625, 'train/loss': 1.6482713317871094, 'validation/accuracy': 0.56214, 'validation/loss': 1.881830625, 'validation/num_examples': 50000, 'test/accuracy': 0.4477, 'test/loss': 2.5102265625, 'test/num_examples': 10000, 'score': 8025.950723171234, 'total_duration': 10020.455704689026, 'accumulated_submission_time': 8025.950723171234, 'accumulated_eval_time': 1950.304919242859, 'accumulated_logging_time': 0.5400962829589844, 'global_step': 19547, 'preemption_count': 0}), (20572, {'train/accuracy': 0.61626953125, 'train/loss': 1.6307284545898437, 'validation/accuracy': 0.56518, 'validation/loss': 1.87129125, 'validation/num_examples': 50000, 'test/accuracy': 0.4521, 'test/loss': 2.48384140625, 'test/num_examples': 10000, 'score': 8444.716110944748, 'total_duration': 10532.33020234108, 'accumulated_submission_time': 8444.716110944748, 'accumulated_eval_time': 2041.1175422668457, 'accumulated_logging_time': 0.5693168640136719, 'global_step': 20572, 'preemption_count': 0}), (21597, {'train/accuracy': 0.6278125, 'train/loss': 1.5581813049316406, 'validation/accuracy': 0.57692, 'validation/loss': 1.7992946875, 'validation/num_examples': 50000, 'test/accuracy': 0.4597, 'test/loss': 2.4328720703125, 'test/num_examples': 10000, 'score': 8863.765577316284, 'total_duration': 11044.192291259766, 'accumulated_submission_time': 8863.765577316284, 'accumulated_eval_time': 2131.685292005539, 'accumulated_logging_time': 0.5963025093078613, 'global_step': 21597, 'preemption_count': 0}), (22626, {'train/accuracy': 0.631953125, 'train/loss': 1.5348011779785156, 'validation/accuracy': 0.58222, 'validation/loss': 1.7792, 'validation/num_examples': 50000, 'test/accuracy': 0.4675, 'test/loss': 2.41618671875, 'test/num_examples': 10000, 'score': 9282.886711597443, 'total_duration': 11562.746190071106, 'accumulated_submission_time': 9282.886711597443, 'accumulated_eval_time': 2228.8388845920563, 'accumulated_logging_time': 0.6277039051055908, 'global_step': 22626, 'preemption_count': 0}), (23659, {'train/accuracy': 0.6465625, 'train/loss': 1.463553924560547, 'validation/accuracy': 0.59056, 'validation/loss': 1.713401875, 'validation/num_examples': 50000, 'test/accuracy': 0.4776, 'test/loss': 2.3525095703125, 'test/num_examples': 10000, 'score': 9701.763073205948, 'total_duration': 12077.156704187393, 'accumulated_submission_time': 9701.763073205948, 'accumulated_eval_time': 2322.108835697174, 'accumulated_logging_time': 0.6549313068389893, 'global_step': 23659, 'preemption_count': 0}), (24686, {'train/accuracy': 0.652421875, 'train/loss': 1.4400218200683594, 'validation/accuracy': 0.59774, 'validation/loss': 1.68804703125, 'validation/num_examples': 50000, 'test/accuracy': 0.4759, 'test/loss': 2.3373685546875, 'test/num_examples': 10000, 'score': 10120.81158041954, 'total_duration': 12593.178675174713, 'accumulated_submission_time': 10120.81158041954, 'accumulated_eval_time': 2416.770309448242, 'accumulated_logging_time': 0.682269811630249, 'global_step': 24686, 'preemption_count': 0}), (25712, {'train/accuracy': 0.65755859375, 'train/loss': 1.4183949279785155, 'validation/accuracy': 0.6043, 'validation/loss': 1.6652515625, 'validation/num_examples': 50000, 'test/accuracy': 0.4851, 'test/loss': 2.316401171875, 'test/num_examples': 10000, 'score': 10539.973780155182, 'total_duration': 13106.318683624268, 'accumulated_submission_time': 10539.973780155182, 'accumulated_eval_time': 2508.482878923416, 'accumulated_logging_time': 0.709888219833374, 'global_step': 25712, 'preemption_count': 0}), (26737, {'train/accuracy': 0.65951171875, 'train/loss': 1.3987852478027343, 'validation/accuracy': 0.60434, 'validation/loss': 1.64842859375, 'validation/num_examples': 50000, 'test/accuracy': 0.4824, 'test/loss': 2.2939185546875, 'test/num_examples': 10000, 'score': 10958.973457813263, 'total_duration': 13618.23564505577, 'accumulated_submission_time': 10958.973457813263, 'accumulated_eval_time': 2599.1434013843536, 'accumulated_logging_time': 0.7385730743408203, 'global_step': 26737, 'preemption_count': 0}), (27764, {'train/accuracy': 0.6642578125, 'train/loss': 1.391507110595703, 'validation/accuracy': 0.609, 'validation/loss': 1.64691, 'validation/num_examples': 50000, 'test/accuracy': 0.4861, 'test/loss': 2.2992857421875, 'test/num_examples': 10000, 'score': 11377.977722406387, 'total_duration': 14130.287772655487, 'accumulated_submission_time': 11377.977722406387, 'accumulated_eval_time': 2689.9310009479523, 'accumulated_logging_time': 0.7662363052368164, 'global_step': 27764, 'preemption_count': 0}), (28790, {'train/accuracy': 0.6741015625, 'train/loss': 1.3380560302734374, 'validation/accuracy': 0.61936, 'validation/loss': 1.5933046875, 'validation/num_examples': 50000, 'test/accuracy': 0.4959, 'test/loss': 2.231582421875, 'test/num_examples': 10000, 'score': 11796.862185955048, 'total_duration': 14646.820058584213, 'accumulated_submission_time': 11796.862185955048, 'accumulated_eval_time': 2785.302080631256, 'accumulated_logging_time': 0.7985968589782715, 'global_step': 28790, 'preemption_count': 0}), (29822, {'train/accuracy': 0.67931640625, 'train/loss': 1.3232623291015626, 'validation/accuracy': 0.62336, 'validation/loss': 1.5767871875, 'validation/num_examples': 50000, 'test/accuracy': 0.5012, 'test/loss': 2.210870703125, 'test/num_examples': 10000, 'score': 12215.971857786179, 'total_duration': 15164.855756521225, 'accumulated_submission_time': 12215.971857786179, 'accumulated_eval_time': 2881.9648518562317, 'accumulated_logging_time': 0.8288023471832275, 'global_step': 29822, 'preemption_count': 0}), (30848, {'train/accuracy': 0.68216796875, 'train/loss': 1.3191340637207032, 'validation/accuracy': 0.62474, 'validation/loss': 1.57301953125, 'validation/num_examples': 50000, 'test/accuracy': 0.505, 'test/loss': 2.195338671875, 'test/num_examples': 10000, 'score': 12635.018734931946, 'total_duration': 15676.876236438751, 'accumulated_submission_time': 12635.018734931946, 'accumulated_eval_time': 2972.6803107261658, 'accumulated_logging_time': 0.8579301834106445, 'global_step': 30848, 'preemption_count': 0}), (31874, {'train/accuracy': 0.67888671875, 'train/loss': 1.3131819152832032, 'validation/accuracy': 0.62318, 'validation/loss': 1.5704321875, 'validation/num_examples': 50000, 'test/accuracy': 0.5102, 'test/loss': 2.213048046875, 'test/num_examples': 10000, 'score': 13053.914733409882, 'total_duration': 16188.55485868454, 'accumulated_submission_time': 13053.914733409882, 'accumulated_eval_time': 3063.1874573230743, 'accumulated_logging_time': 0.8888599872589111, 'global_step': 31874, 'preemption_count': 0}), (32902, {'train/accuracy': 0.69193359375, 'train/loss': 1.2588944244384765, 'validation/accuracy': 0.63584, 'validation/loss': 1.5135659375, 'validation/num_examples': 50000, 'test/accuracy': 0.5122, 'test/loss': 2.15730703125, 'test/num_examples': 10000, 'score': 13472.851302623749, 'total_duration': 16700.860886096954, 'accumulated_submission_time': 13472.851302623749, 'accumulated_eval_time': 3154.231927871704, 'accumulated_logging_time': 0.9182641506195068, 'global_step': 32902, 'preemption_count': 0}), (33927, {'train/accuracy': 0.697734375, 'train/loss': 1.2217210388183595, 'validation/accuracy': 0.63848, 'validation/loss': 1.49125875, 'validation/num_examples': 50000, 'test/accuracy': 0.517, 'test/loss': 2.128406640625, 'test/num_examples': 10000, 'score': 13891.836766242981, 'total_duration': 17217.87688279152, 'accumulated_submission_time': 13891.836766242981, 'accumulated_eval_time': 3250.008403778076, 'accumulated_logging_time': 0.9483447074890137, 'global_step': 33927, 'preemption_count': 0}), (34960, {'train/accuracy': 0.69525390625, 'train/loss': 1.240261993408203, 'validation/accuracy': 0.63798, 'validation/loss': 1.4990771875, 'validation/num_examples': 50000, 'test/accuracy': 0.5162, 'test/loss': 2.145701171875, 'test/num_examples': 10000, 'score': 14310.932742118835, 'total_duration': 17731.532814741135, 'accumulated_submission_time': 14310.932742118835, 'accumulated_eval_time': 3342.239068031311, 'accumulated_logging_time': 0.9771223068237305, 'global_step': 34960, 'preemption_count': 0}), (35987, {'train/accuracy': 0.70171875, 'train/loss': 1.2196855926513672, 'validation/accuracy': 0.64092, 'validation/loss': 1.485736875, 'validation/num_examples': 50000, 'test/accuracy': 0.5168, 'test/loss': 2.136860546875, 'test/num_examples': 10000, 'score': 14729.872365951538, 'total_duration': 18249.847893238068, 'accumulated_submission_time': 14729.872365951538, 'accumulated_eval_time': 3439.2978398799896, 'accumulated_logging_time': 1.00677490234375, 'global_step': 35987, 'preemption_count': 0}), (37014, {'train/accuracy': 0.69978515625, 'train/loss': 1.2184580230712891, 'validation/accuracy': 0.64356, 'validation/loss': 1.4832809375, 'validation/num_examples': 50000, 'test/accuracy': 0.521, 'test/loss': 2.12569375, 'test/num_examples': 10000, 'score': 15148.976285934448, 'total_duration': 18764.436487436295, 'accumulated_submission_time': 15148.976285934448, 'accumulated_eval_time': 3532.476112127304, 'accumulated_logging_time': 1.0384349822998047, 'global_step': 37014, 'preemption_count': 0}), (38039, {'train/accuracy': 0.71169921875, 'train/loss': 1.1861380004882813, 'validation/accuracy': 0.65042, 'validation/loss': 1.455365625, 'validation/num_examples': 50000, 'test/accuracy': 0.5259, 'test/loss': 2.084976171875, 'test/num_examples': 10000, 'score': 15567.745805978775, 'total_duration': 19276.039237976074, 'accumulated_submission_time': 15567.745805978775, 'accumulated_eval_time': 3623.043833255768, 'accumulated_logging_time': 1.0669054985046387, 'global_step': 38039, 'preemption_count': 0}), (39067, {'train/accuracy': 0.71400390625, 'train/loss': 1.1646676635742188, 'validation/accuracy': 0.65348, 'validation/loss': 1.436515625, 'validation/num_examples': 50000, 'test/accuracy': 0.5294, 'test/loss': 2.0696662109375, 'test/num_examples': 10000, 'score': 15986.764743804932, 'total_duration': 19788.57683157921, 'accumulated_submission_time': 15986.764743804932, 'accumulated_eval_time': 3714.2696459293365, 'accumulated_logging_time': 1.0964574813842773, 'global_step': 39067, 'preemption_count': 0}), (40092, {'train/accuracy': 0.71607421875, 'train/loss': 1.146628646850586, 'validation/accuracy': 0.65274, 'validation/loss': 1.41732640625, 'validation/num_examples': 50000, 'test/accuracy': 0.5329, 'test/loss': 2.047136328125, 'test/num_examples': 10000, 'score': 16405.679308891296, 'total_duration': 20309.39036488533, 'accumulated_submission_time': 16405.679308891296, 'accumulated_eval_time': 3813.917498588562, 'accumulated_logging_time': 1.1280629634857178, 'global_step': 40092, 'preemption_count': 0}), (41125, {'train/accuracy': 0.71478515625, 'train/loss': 1.1488006591796875, 'validation/accuracy': 0.65094, 'validation/loss': 1.43545109375, 'validation/num_examples': 50000, 'test/accuracy': 0.5312, 'test/loss': 2.077178515625, 'test/num_examples': 10000, 'score': 16824.81717801094, 'total_duration': 20825.225256681442, 'accumulated_submission_time': 16824.81717801094, 'accumulated_eval_time': 3908.342100381851, 'accumulated_logging_time': 1.1604938507080078, 'global_step': 41125, 'preemption_count': 0}), (42150, {'train/accuracy': 0.71998046875, 'train/loss': 1.1204037475585937, 'validation/accuracy': 0.65894, 'validation/loss': 1.3971328125, 'validation/num_examples': 50000, 'test/accuracy': 0.5354, 'test/loss': 2.039900390625, 'test/num_examples': 10000, 'score': 17243.604677677155, 'total_duration': 21336.77097415924, 'accumulated_submission_time': 17243.604677677155, 'accumulated_eval_time': 3998.8128588199615, 'accumulated_logging_time': 1.190061330795288, 'global_step': 42150, 'preemption_count': 0}), (43176, {'train/accuracy': 0.71935546875, 'train/loss': 1.1192827606201172, 'validation/accuracy': 0.65862, 'validation/loss': 1.3972553125, 'validation/num_examples': 50000, 'test/accuracy': 0.5384, 'test/loss': 2.025319921875, 'test/num_examples': 10000, 'score': 17662.550467967987, 'total_duration': 21848.862194299698, 'accumulated_submission_time': 17662.550467967987, 'accumulated_eval_time': 4089.6736998558044, 'accumulated_logging_time': 1.219120740890503, 'global_step': 43176, 'preemption_count': 0}), (44203, {'train/accuracy': 0.7238671875, 'train/loss': 1.1068960571289062, 'validation/accuracy': 0.66084, 'validation/loss': 1.379905, 'validation/num_examples': 50000, 'test/accuracy': 0.5398, 'test/loss': 2.0197302734375, 'test/num_examples': 10000, 'score': 18081.493983745575, 'total_duration': 22360.52747821808, 'accumulated_submission_time': 18081.493983745575, 'accumulated_eval_time': 4180.092182397842, 'accumulated_logging_time': 1.2488369941711426, 'global_step': 44203, 'preemption_count': 0}), (45231, {'train/accuracy': 0.7253515625, 'train/loss': 1.1061186218261718, 'validation/accuracy': 0.66368, 'validation/loss': 1.38838234375, 'validation/num_examples': 50000, 'test/accuracy': 0.5412, 'test/loss': 2.0248123046875, 'test/num_examples': 10000, 'score': 18500.272318840027, 'total_duration': 22874.73406767845, 'accumulated_submission_time': 18500.272318840027, 'accumulated_eval_time': 4273.259990692139, 'accumulated_logging_time': 1.2786579132080078, 'global_step': 45231, 'preemption_count': 0}), (46261, {'train/accuracy': 0.73146484375, 'train/loss': 1.072737274169922, 'validation/accuracy': 0.6682, 'validation/loss': 1.357775625, 'validation/num_examples': 50000, 'test/accuracy': 0.5449, 'test/loss': 1.9881630859375, 'test/num_examples': 10000, 'score': 18919.114461183548, 'total_duration': 23388.53168988228, 'accumulated_submission_time': 18919.114461183548, 'accumulated_eval_time': 4365.901824235916, 'accumulated_logging_time': 1.3087048530578613, 'global_step': 46261, 'preemption_count': 0}), (47287, {'train/accuracy': 0.733203125, 'train/loss': 1.0674948120117187, 'validation/accuracy': 0.67018, 'validation/loss': 1.35777953125, 'validation/num_examples': 50000, 'test/accuracy': 0.5505, 'test/loss': 1.9850087890625, 'test/num_examples': 10000, 'score': 19337.941229581833, 'total_duration': 23909.055931806564, 'accumulated_submission_time': 19337.941229581833, 'accumulated_eval_time': 4465.233575105667, 'accumulated_logging_time': 1.3402297496795654, 'global_step': 47287, 'preemption_count': 0}), (48312, {'train/accuracy': 0.73505859375, 'train/loss': 1.0556340789794922, 'validation/accuracy': 0.66984, 'validation/loss': 1.3533246875, 'validation/num_examples': 50000, 'test/accuracy': 0.5462, 'test/loss': 1.9885140625, 'test/num_examples': 10000, 'score': 19757.0280752182, 'total_duration': 24424.148333072662, 'accumulated_submission_time': 19757.0280752182, 'accumulated_eval_time': 4558.890681266785, 'accumulated_logging_time': 1.370004653930664, 'global_step': 48312, 'preemption_count': 0}), (49337, {'train/accuracy': 0.7382421875, 'train/loss': 1.0397127532958985, 'validation/accuracy': 0.67116, 'validation/loss': 1.34067359375, 'validation/num_examples': 50000, 'test/accuracy': 0.5468, 'test/loss': 1.9801173828125, 'test/num_examples': 10000, 'score': 20175.821433782578, 'total_duration': 24935.97784304619, 'accumulated_submission_time': 20175.821433782578, 'accumulated_eval_time': 4649.673602819443, 'accumulated_logging_time': 1.3998687267303467, 'global_step': 49337, 'preemption_count': 0}), (50363, {'train/accuracy': 0.742265625, 'train/loss': 1.0322038269042968, 'validation/accuracy': 0.6756, 'validation/loss': 1.32815984375, 'validation/num_examples': 50000, 'test/accuracy': 0.5564, 'test/loss': 1.9555203125, 'test/num_examples': 10000, 'score': 20594.957370758057, 'total_duration': 25448.493005752563, 'accumulated_submission_time': 20594.957370758057, 'accumulated_eval_time': 4740.759184360504, 'accumulated_logging_time': 1.4278614521026611, 'global_step': 50363, 'preemption_count': 0}), (51389, {'train/accuracy': 0.74587890625, 'train/loss': 1.0296810150146485, 'validation/accuracy': 0.67772, 'validation/loss': 1.322539375, 'validation/num_examples': 50000, 'test/accuracy': 0.5565, 'test/loss': 1.9421529296875, 'test/num_examples': 10000, 'score': 21013.991913557053, 'total_duration': 25967.81488609314, 'accumulated_submission_time': 21013.991913557053, 'accumulated_eval_time': 4838.775243282318, 'accumulated_logging_time': 1.4578449726104736, 'global_step': 51389, 'preemption_count': 0}), (52419, {'train/accuracy': 0.745, 'train/loss': 1.021488037109375, 'validation/accuracy': 0.6793, 'validation/loss': 1.307887578125, 'validation/num_examples': 50000, 'test/accuracy': 0.5567, 'test/loss': 1.9352248046875, 'test/num_examples': 10000, 'score': 21432.790216207504, 'total_duration': 26482.016530275345, 'accumulated_submission_time': 21432.790216207504, 'accumulated_eval_time': 4931.823822975159, 'accumulated_logging_time': 1.4883503913879395, 'global_step': 52419, 'preemption_count': 0}), (53447, {'train/accuracy': 0.74888671875, 'train/loss': 1.0007962799072265, 'validation/accuracy': 0.68382, 'validation/loss': 1.294533984375, 'validation/num_examples': 50000, 'test/accuracy': 0.5576, 'test/loss': 1.924509375, 'test/num_examples': 10000, 'score': 21851.882763385773, 'total_duration': 26997.782219409943, 'accumulated_submission_time': 21851.882763385773, 'accumulated_eval_time': 5026.212872266769, 'accumulated_logging_time': 1.5215964317321777, 'global_step': 53447, 'preemption_count': 0}), (54461, {'train/accuracy': 0.75017578125, 'train/loss': 0.9845518493652343, 'validation/accuracy': 0.6819, 'validation/loss': 1.284678828125, 'validation/num_examples': 50000, 'test/accuracy': 0.5577, 'test/loss': 1.923010546875, 'test/num_examples': 10000, 'score': 22270.88813996315, 'total_duration': 27511.12437748909, 'accumulated_submission_time': 22270.88813996315, 'accumulated_eval_time': 5118.245020389557, 'accumulated_logging_time': 1.5569963455200195, 'global_step': 54461, 'preemption_count': 0}), (55462, {'train/accuracy': 0.752890625, 'train/loss': 0.979212646484375, 'validation/accuracy': 0.6861, 'validation/loss': 1.2788175, 'validation/num_examples': 50000, 'test/accuracy': 0.5579, 'test/loss': 1.9023837890625, 'test/num_examples': 10000, 'score': 22689.95379137993, 'total_duration': 28023.31267142296, 'accumulated_submission_time': 22689.95379137993, 'accumulated_eval_time': 5209.111755371094, 'accumulated_logging_time': 1.5931775569915771, 'global_step': 55462, 'preemption_count': 0}), (56486, {'train/accuracy': 0.7530078125, 'train/loss': 0.9812405395507813, 'validation/accuracy': 0.68612, 'validation/loss': 1.282058984375, 'validation/num_examples': 50000, 'test/accuracy': 0.5611, 'test/loss': 1.9186826171875, 'test/num_examples': 10000, 'score': 23109.04629802704, 'total_duration': 28535.968436717987, 'accumulated_submission_time': 23109.04629802704, 'accumulated_eval_time': 5300.425964355469, 'accumulated_logging_time': 1.6234455108642578, 'global_step': 56486, 'preemption_count': 0}), (57517, {'train/accuracy': 0.7569140625, 'train/loss': 0.9662100982666015, 'validation/accuracy': 0.69078, 'validation/loss': 1.263790390625, 'validation/num_examples': 50000, 'test/accuracy': 0.5638, 'test/loss': 1.88946796875, 'test/num_examples': 10000, 'score': 23528.19397497177, 'total_duration': 29053.30651664734, 'accumulated_submission_time': 23528.19397497177, 'accumulated_eval_time': 5396.302827358246, 'accumulated_logging_time': 1.653935194015503, 'global_step': 57517, 'preemption_count': 0}), (58545, {'train/accuracy': 0.75435546875, 'train/loss': 0.9642987060546875, 'validation/accuracy': 0.68598, 'validation/loss': 1.27245078125, 'validation/num_examples': 50000, 'test/accuracy': 0.567, 'test/loss': 1.8873513671875, 'test/num_examples': 10000, 'score': 23947.1761302948, 'total_duration': 29572.44074511528, 'accumulated_submission_time': 23947.1761302948, 'accumulated_eval_time': 5494.11896109581, 'accumulated_logging_time': 1.6849124431610107, 'global_step': 58545, 'preemption_count': 0}), (59570, {'train/accuracy': 0.7605078125, 'train/loss': 0.957832260131836, 'validation/accuracy': 0.69118, 'validation/loss': 1.261976640625, 'validation/num_examples': 50000, 'test/accuracy': 0.5661, 'test/loss': 1.8909234375, 'test/num_examples': 10000, 'score': 24366.14768886566, 'total_duration': 30089.04805111885, 'accumulated_submission_time': 24366.14768886566, 'accumulated_eval_time': 5589.488629817963, 'accumulated_logging_time': 1.7184011936187744, 'global_step': 59570, 'preemption_count': 0}), (60593, {'train/accuracy': 0.76001953125, 'train/loss': 0.9597245788574219, 'validation/accuracy': 0.69134, 'validation/loss': 1.264243046875, 'validation/num_examples': 50000, 'test/accuracy': 0.5748, 'test/loss': 1.90301171875, 'test/num_examples': 10000, 'score': 24785.3037545681, 'total_duration': 30601.43651509285, 'accumulated_submission_time': 24785.3037545681, 'accumulated_eval_time': 5680.48707151413, 'accumulated_logging_time': 1.7484703063964844, 'global_step': 60593, 'preemption_count': 0}), (61618, {'train/accuracy': 0.762109375, 'train/loss': 0.9413234710693359, 'validation/accuracy': 0.692, 'validation/loss': 1.25130953125, 'validation/num_examples': 50000, 'test/accuracy': 0.5685, 'test/loss': 1.862825390625, 'test/num_examples': 10000, 'score': 25204.41980266571, 'total_duration': 31113.792841911316, 'accumulated_submission_time': 25204.41980266571, 'accumulated_eval_time': 5771.495392084122, 'accumulated_logging_time': 1.7780542373657227, 'global_step': 61618, 'preemption_count': 0}), (62646, {'train/accuracy': 0.76513671875, 'train/loss': 0.923326644897461, 'validation/accuracy': 0.6933, 'validation/loss': 1.23762875, 'validation/num_examples': 50000, 'test/accuracy': 0.575, 'test/loss': 1.8524271484375, 'test/num_examples': 10000, 'score': 25623.434438943863, 'total_duration': 31630.51397585869, 'accumulated_submission_time': 25623.434438943863, 'accumulated_eval_time': 5866.934550285339, 'accumulated_logging_time': 1.8117358684539795, 'global_step': 62646, 'preemption_count': 0}), (63678, {'train/accuracy': 0.76783203125, 'train/loss': 0.9318679809570313, 'validation/accuracy': 0.6958, 'validation/loss': 1.23982125, 'validation/num_examples': 50000, 'test/accuracy': 0.5728, 'test/loss': 1.8615568359375, 'test/num_examples': 10000, 'score': 26042.256200551987, 'total_duration': 32147.156406402588, 'accumulated_submission_time': 26042.256200551987, 'accumulated_eval_time': 5962.458073854446, 'accumulated_logging_time': 1.8441426753997803, 'global_step': 63678, 'preemption_count': 0}), (64705, {'train/accuracy': 0.77521484375, 'train/loss': 0.8806224060058594, 'validation/accuracy': 0.70328, 'validation/loss': 1.195711328125, 'validation/num_examples': 50000, 'test/accuracy': 0.5759, 'test/loss': 1.837216796875, 'test/num_examples': 10000, 'score': 26461.22221827507, 'total_duration': 32661.944671869278, 'accumulated_submission_time': 26461.22221827507, 'accumulated_eval_time': 6056.012538909912, 'accumulated_logging_time': 1.878692865371704, 'global_step': 64705, 'preemption_count': 0}), (65730, {'train/accuracy': 0.769765625, 'train/loss': 0.9068109893798828, 'validation/accuracy': 0.70006, 'validation/loss': 1.21876890625, 'validation/num_examples': 50000, 'test/accuracy': 0.5818, 'test/loss': 1.8299978515625, 'test/num_examples': 10000, 'score': 26880.17323231697, 'total_duration': 33175.3090736866, 'accumulated_submission_time': 26880.17323231697, 'accumulated_eval_time': 6148.201342344284, 'accumulated_logging_time': 1.9110901355743408, 'global_step': 65730, 'preemption_count': 0}), (66756, {'train/accuracy': 0.77423828125, 'train/loss': 0.8891181945800781, 'validation/accuracy': 0.70232, 'validation/loss': 1.2098209375, 'validation/num_examples': 50000, 'test/accuracy': 0.5729, 'test/loss': 1.8335244140625, 'test/num_examples': 10000, 'score': 27299.25323200226, 'total_duration': 33687.96317720413, 'accumulated_submission_time': 27299.25323200226, 'accumulated_eval_time': 6239.483256816864, 'accumulated_logging_time': 1.944244623184204, 'global_step': 66756, 'preemption_count': 0}), (67783, {'train/accuracy': 0.7783203125, 'train/loss': 0.8725881195068359, 'validation/accuracy': 0.70516, 'validation/loss': 1.19554578125, 'validation/num_examples': 50000, 'test/accuracy': 0.5862, 'test/loss': 1.813583203125, 'test/num_examples': 10000, 'score': 27718.129616498947, 'total_duration': 34200.9839553833, 'accumulated_submission_time': 27718.129616498947, 'accumulated_eval_time': 6331.366873025894, 'accumulated_logging_time': 1.9765729904174805, 'global_step': 67783, 'preemption_count': 0}), (68808, {'train/accuracy': 0.77986328125, 'train/loss': 0.8611705017089843, 'validation/accuracy': 0.7064, 'validation/loss': 1.18319203125, 'validation/num_examples': 50000, 'test/accuracy': 0.5909, 'test/loss': 1.7825927734375, 'test/num_examples': 10000, 'score': 28137.16416478157, 'total_duration': 34717.76166844368, 'accumulated_submission_time': 28137.16416478157, 'accumulated_eval_time': 6426.771734952927, 'accumulated_logging_time': 2.007922410964966, 'global_step': 68808, 'preemption_count': 0}), (69838, {'train/accuracy': 0.78333984375, 'train/loss': 0.8550749206542969, 'validation/accuracy': 0.70844, 'validation/loss': 1.1818190625, 'validation/num_examples': 50000, 'test/accuracy': 0.5906, 'test/loss': 1.7930822265625, 'test/num_examples': 10000, 'score': 28556.108570337296, 'total_duration': 35236.38508224487, 'accumulated_submission_time': 28556.108570337296, 'accumulated_eval_time': 6524.1618065834045, 'accumulated_logging_time': 2.039173126220703, 'global_step': 69838, 'preemption_count': 0}), (70864, {'train/accuracy': 0.7821875, 'train/loss': 0.8429695129394531, 'validation/accuracy': 0.70874, 'validation/loss': 1.169748828125, 'validation/num_examples': 50000, 'test/accuracy': 0.5877, 'test/loss': 1.7950474609375, 'test/num_examples': 10000, 'score': 28975.005259752274, 'total_duration': 35751.1821539402, 'accumulated_submission_time': 28975.005259752274, 'accumulated_eval_time': 6617.758754014969, 'accumulated_logging_time': 2.0743002891540527, 'global_step': 70864, 'preemption_count': 0}), (71887, {'train/accuracy': 0.7875, 'train/loss': 0.8254187774658203, 'validation/accuracy': 0.71152, 'validation/loss': 1.15254625, 'validation/num_examples': 50000, 'test/accuracy': 0.5847, 'test/loss': 1.7886955078125, 'test/num_examples': 10000, 'score': 29394.01382470131, 'total_duration': 36263.42708301544, 'accumulated_submission_time': 29394.01382470131, 'accumulated_eval_time': 6708.693472862244, 'accumulated_logging_time': 2.1059341430664062, 'global_step': 71887, 'preemption_count': 0}), (72913, {'train/accuracy': 0.78673828125, 'train/loss': 0.8305644226074219, 'validation/accuracy': 0.71048, 'validation/loss': 1.1581178125, 'validation/num_examples': 50000, 'test/accuracy': 0.5843, 'test/loss': 1.7768400390625, 'test/num_examples': 10000, 'score': 29812.978860378265, 'total_duration': 36775.72098135948, 'accumulated_submission_time': 29812.978860378265, 'accumulated_eval_time': 6799.728086709976, 'accumulated_logging_time': 2.136329412460327, 'global_step': 72913, 'preemption_count': 0}), (73938, {'train/accuracy': 0.79138671875, 'train/loss': 0.8088320159912109, 'validation/accuracy': 0.71224, 'validation/loss': 1.15182890625, 'validation/num_examples': 50000, 'test/accuracy': 0.5842, 'test/loss': 1.786330078125, 'test/num_examples': 10000, 'score': 30231.840370178223, 'total_duration': 37292.357573747635, 'accumulated_submission_time': 30231.840370178223, 'accumulated_eval_time': 6895.266906499863, 'accumulated_logging_time': 2.171018123626709, 'global_step': 73938, 'preemption_count': 0}), (74970, {'train/accuracy': 0.79078125, 'train/loss': 0.8062158966064453, 'validation/accuracy': 0.71454, 'validation/loss': 1.134965234375, 'validation/num_examples': 50000, 'test/accuracy': 0.5893, 'test/loss': 1.7789875, 'test/num_examples': 10000, 'score': 30650.588718891144, 'total_duration': 37808.42060470581, 'accumulated_submission_time': 30650.588718891144, 'accumulated_eval_time': 6990.221202373505, 'accumulated_logging_time': 2.205861806869507, 'global_step': 74970, 'preemption_count': 0}), (75997, {'train/accuracy': 0.79373046875, 'train/loss': 0.8122936248779297, 'validation/accuracy': 0.71508, 'validation/loss': 1.150066328125, 'validation/num_examples': 50000, 'test/accuracy': 0.5952, 'test/loss': 1.75751640625, 'test/num_examples': 10000, 'score': 31069.47411108017, 'total_duration': 38324.45893573761, 'accumulated_submission_time': 31069.47411108017, 'accumulated_eval_time': 7085.0603058338165, 'accumulated_logging_time': 2.238262414932251, 'global_step': 75997, 'preemption_count': 0}), (77023, {'train/accuracy': 0.7943359375, 'train/loss': 0.7987835693359375, 'validation/accuracy': 0.72036, 'validation/loss': 1.1305715625, 'validation/num_examples': 50000, 'test/accuracy': 0.5972, 'test/loss': 1.7504921875, 'test/num_examples': 10000, 'score': 31488.35825395584, 'total_duration': 38838.461253643036, 'accumulated_submission_time': 31488.35825395584, 'accumulated_eval_time': 7177.864827632904, 'accumulated_logging_time': 2.272787570953369, 'global_step': 77023, 'preemption_count': 0}), (78047, {'train/accuracy': 0.79896484375, 'train/loss': 0.7716001892089843, 'validation/accuracy': 0.72158, 'validation/loss': 1.11550796875, 'validation/num_examples': 50000, 'test/accuracy': 0.5954, 'test/loss': 1.7397462890625, 'test/num_examples': 10000, 'score': 31907.538328886032, 'total_duration': 39351.00712752342, 'accumulated_submission_time': 31907.538328886032, 'accumulated_eval_time': 7269.010290622711, 'accumulated_logging_time': 2.3038971424102783, 'global_step': 78047, 'preemption_count': 0}), (79072, {'train/accuracy': 0.7980859375, 'train/loss': 0.7937019348144532, 'validation/accuracy': 0.72054, 'validation/loss': 1.129514375, 'validation/num_examples': 50000, 'test/accuracy': 0.6029, 'test/loss': 1.733080859375, 'test/num_examples': 10000, 'score': 32326.615975618362, 'total_duration': 39863.92292165756, 'accumulated_submission_time': 32326.615975618362, 'accumulated_eval_time': 7360.5557696819305, 'accumulated_logging_time': 2.3390791416168213, 'global_step': 79072, 'preemption_count': 0}), (80097, {'train/accuracy': 0.8038671875, 'train/loss': 0.7538491058349609, 'validation/accuracy': 0.7242, 'validation/loss': 1.10110515625, 'validation/num_examples': 50000, 'test/accuracy': 0.5963, 'test/loss': 1.72729921875, 'test/num_examples': 10000, 'score': 32745.75004172325, 'total_duration': 40381.33103609085, 'accumulated_submission_time': 32745.75004172325, 'accumulated_eval_time': 7456.628044128418, 'accumulated_logging_time': 2.3707242012023926, 'global_step': 80097, 'preemption_count': 0}), (81129, {'train/accuracy': 0.80361328125, 'train/loss': 0.7598976135253906, 'validation/accuracy': 0.72414, 'validation/loss': 1.10761875, 'validation/num_examples': 50000, 'test/accuracy': 0.602, 'test/loss': 1.729073828125, 'test/num_examples': 10000, 'score': 33164.69205403328, 'total_duration': 40899.77792048454, 'accumulated_submission_time': 33164.69205403328, 'accumulated_eval_time': 7553.774738311768, 'accumulated_logging_time': 2.4024863243103027, 'global_step': 81129, 'preemption_count': 0}), (82156, {'train/accuracy': 0.80603515625, 'train/loss': 0.7491520690917969, 'validation/accuracy': 0.72802, 'validation/loss': 1.094786015625, 'validation/num_examples': 50000, 'test/accuracy': 0.6042, 'test/loss': 1.704280078125, 'test/num_examples': 10000, 'score': 33583.65639710426, 'total_duration': 41412.68580532074, 'accumulated_submission_time': 33583.65639710426, 'accumulated_eval_time': 7645.3683960437775, 'accumulated_logging_time': 2.443277597427368, 'global_step': 82156, 'preemption_count': 0}), (83180, {'train/accuracy': 0.8066015625, 'train/loss': 0.7520854187011718, 'validation/accuracy': 0.72758, 'validation/loss': 1.096599453125, 'validation/num_examples': 50000, 'test/accuracy': 0.6046, 'test/loss': 1.727405078125, 'test/num_examples': 10000, 'score': 34002.59331560135, 'total_duration': 41924.9207983017, 'accumulated_submission_time': 34002.59331560135, 'accumulated_eval_time': 7736.391632318497, 'accumulated_logging_time': 2.4783074855804443, 'global_step': 83180, 'preemption_count': 0}), (84205, {'train/accuracy': 0.80888671875, 'train/loss': 0.7330381011962891, 'validation/accuracy': 0.72752, 'validation/loss': 1.084542109375, 'validation/num_examples': 50000, 'test/accuracy': 0.6036, 'test/loss': 1.715488671875, 'test/num_examples': 10000, 'score': 34421.58802652359, 'total_duration': 42437.272780656815, 'accumulated_submission_time': 34421.58802652359, 'accumulated_eval_time': 7827.484014034271, 'accumulated_logging_time': 2.514688730239868, 'global_step': 84205, 'preemption_count': 0}), (85230, {'train/accuracy': 0.8105078125, 'train/loss': 0.7360984802246093, 'validation/accuracy': 0.72796, 'validation/loss': 1.091431875, 'validation/num_examples': 50000, 'test/accuracy': 0.607, 'test/loss': 1.71239609375, 'test/num_examples': 10000, 'score': 34840.57437419891, 'total_duration': 42953.87716841698, 'accumulated_submission_time': 34840.57437419891, 'accumulated_eval_time': 7922.861146450043, 'accumulated_logging_time': 2.5459437370300293, 'global_step': 85230, 'preemption_count': 0}), (86260, {'train/accuracy': 0.8151171875, 'train/loss': 0.7176100158691406, 'validation/accuracy': 0.73178, 'validation/loss': 1.07604171875, 'validation/num_examples': 50000, 'test/accuracy': 0.6077, 'test/loss': 1.6872740234375, 'test/num_examples': 10000, 'score': 35259.4027056694, 'total_duration': 43467.31462955475, 'accumulated_submission_time': 35259.4027056694, 'accumulated_eval_time': 8015.13915014267, 'accumulated_logging_time': 2.583099126815796, 'global_step': 86260, 'preemption_count': 0}), (87287, {'train/accuracy': 0.8182421875, 'train/loss': 0.691032943725586, 'validation/accuracy': 0.73526, 'validation/loss': 1.042140234375, 'validation/num_examples': 50000, 'test/accuracy': 0.6127, 'test/loss': 1.66265234375, 'test/num_examples': 10000, 'score': 35678.52847766876, 'total_duration': 43987.04681110382, 'accumulated_submission_time': 35678.52847766876, 'accumulated_eval_time': 8113.432203292847, 'accumulated_logging_time': 2.6161394119262695, 'global_step': 87287, 'preemption_count': 0}), (88313, {'train/accuracy': 0.81748046875, 'train/loss': 0.7083558654785156, 'validation/accuracy': 0.73422, 'validation/loss': 1.066148046875, 'validation/num_examples': 50000, 'test/accuracy': 0.615, 'test/loss': 1.688865234375, 'test/num_examples': 10000, 'score': 36097.371693611145, 'total_duration': 44501.77542591095, 'accumulated_submission_time': 36097.371693611145, 'accumulated_eval_time': 8207.03715133667, 'accumulated_logging_time': 2.6535825729370117, 'global_step': 88313, 'preemption_count': 0}), (89338, {'train/accuracy': 0.81900390625, 'train/loss': 0.6916342163085938, 'validation/accuracy': 0.73518, 'validation/loss': 1.058754921875, 'validation/num_examples': 50000, 'test/accuracy': 0.6123, 'test/loss': 1.681706640625, 'test/num_examples': 10000, 'score': 36516.20099759102, 'total_duration': 45013.740899801254, 'accumulated_submission_time': 36516.20099759102, 'accumulated_eval_time': 8297.861069917679, 'accumulated_logging_time': 2.6913037300109863, 'global_step': 89338, 'preemption_count': 0}), (90363, {'train/accuracy': 0.82248046875, 'train/loss': 0.6818931579589844, 'validation/accuracy': 0.73754, 'validation/loss': 1.046389140625, 'validation/num_examples': 50000, 'test/accuracy': 0.618, 'test/loss': 1.653194921875, 'test/num_examples': 10000, 'score': 36935.12146925926, 'total_duration': 45526.46598315239, 'accumulated_submission_time': 36935.12146925926, 'accumulated_eval_time': 8389.344470262527, 'accumulated_logging_time': 2.727031707763672, 'global_step': 90363, 'preemption_count': 0}), (91385, {'train/accuracy': 0.82365234375, 'train/loss': 0.6769486999511719, 'validation/accuracy': 0.73814, 'validation/loss': 1.042914375, 'validation/num_examples': 50000, 'test/accuracy': 0.6148, 'test/loss': 1.6550314453125, 'test/num_examples': 10000, 'score': 37353.9124147892, 'total_duration': 46045.45631933212, 'accumulated_submission_time': 37353.9124147892, 'accumulated_eval_time': 8487.327114582062, 'accumulated_logging_time': 2.7591471672058105, 'global_step': 91385, 'preemption_count': 0}), (92417, {'train/accuracy': 0.82619140625, 'train/loss': 0.6655417633056641, 'validation/accuracy': 0.74098, 'validation/loss': 1.031601328125, 'validation/num_examples': 50000, 'test/accuracy': 0.6215, 'test/loss': 1.652606640625, 'test/num_examples': 10000, 'score': 37772.74341249466, 'total_duration': 46560.731041669846, 'accumulated_submission_time': 37772.74341249466, 'accumulated_eval_time': 8581.396768808365, 'accumulated_logging_time': 2.793741226196289, 'global_step': 92417, 'preemption_count': 0}), (93443, {'train/accuracy': 0.8276953125, 'train/loss': 0.6588883972167969, 'validation/accuracy': 0.7413, 'validation/loss': 1.0315315625, 'validation/num_examples': 50000, 'test/accuracy': 0.6202, 'test/loss': 1.6444001953125, 'test/num_examples': 10000, 'score': 38191.541233778, 'total_duration': 47073.91848015785, 'accumulated_submission_time': 38191.541233778, 'accumulated_eval_time': 8673.477474451065, 'accumulated_logging_time': 2.8332974910736084, 'global_step': 93443, 'preemption_count': 0}), (94467, {'train/accuracy': 0.83056640625, 'train/loss': 0.6573970031738281, 'validation/accuracy': 0.74218, 'validation/loss': 1.030728203125, 'validation/num_examples': 50000, 'test/accuracy': 0.621, 'test/loss': 1.64237421875, 'test/num_examples': 10000, 'score': 38610.51299524307, 'total_duration': 47586.12565422058, 'accumulated_submission_time': 38610.51299524307, 'accumulated_eval_time': 8764.48164987564, 'accumulated_logging_time': 2.870373487472534, 'global_step': 94467, 'preemption_count': 0}), (95494, {'train/accuracy': 0.83158203125, 'train/loss': 0.6352441024780273, 'validation/accuracy': 0.74338, 'validation/loss': 1.013875, 'validation/num_examples': 50000, 'test/accuracy': 0.6236, 'test/loss': 1.62912900390625, 'test/num_examples': 10000, 'score': 39029.47423171997, 'total_duration': 48098.34556603432, 'accumulated_submission_time': 39029.47423171997, 'accumulated_eval_time': 8855.440926074982, 'accumulated_logging_time': 2.9038188457489014, 'global_step': 95494, 'preemption_count': 0}), (96518, {'train/accuracy': 0.8328125, 'train/loss': 0.630831642150879, 'validation/accuracy': 0.74366, 'validation/loss': 1.013228515625, 'validation/num_examples': 50000, 'test/accuracy': 0.6226, 'test/loss': 1.6283421875, 'test/num_examples': 10000, 'score': 39448.302835702896, 'total_duration': 48612.34012532234, 'accumulated_submission_time': 39448.302835702896, 'accumulated_eval_time': 8948.355902671814, 'accumulated_logging_time': 2.9395039081573486, 'global_step': 96518, 'preemption_count': 0}), (97549, {'train/accuracy': 0.8350390625, 'train/loss': 0.6380927276611328, 'validation/accuracy': 0.74606, 'validation/loss': 1.016308046875, 'validation/num_examples': 50000, 'test/accuracy': 0.6262, 'test/loss': 1.63010205078125, 'test/num_examples': 10000, 'score': 39867.39875936508, 'total_duration': 49127.5901222229, 'accumulated_submission_time': 39867.39875936508, 'accumulated_eval_time': 9042.160985946655, 'accumulated_logging_time': 2.973475933074951, 'global_step': 97549, 'preemption_count': 0}), (98575, {'train/accuracy': 0.836484375, 'train/loss': 0.6348028945922851, 'validation/accuracy': 0.7487, 'validation/loss': 1.01149390625, 'validation/num_examples': 50000, 'test/accuracy': 0.6298, 'test/loss': 1.61356044921875, 'test/num_examples': 10000, 'score': 40286.21373105049, 'total_duration': 49647.8522644043, 'accumulated_submission_time': 40286.21373105049, 'accumulated_eval_time': 9141.269036531448, 'accumulated_logging_time': 3.0056803226470947, 'global_step': 98575, 'preemption_count': 0}), (99602, {'train/accuracy': 0.84017578125, 'train/loss': 0.6095375442504882, 'validation/accuracy': 0.75072, 'validation/loss': 0.996797109375, 'validation/num_examples': 50000, 'test/accuracy': 0.6314, 'test/loss': 1.60039384765625, 'test/num_examples': 10000, 'score': 40705.26306152344, 'total_duration': 50163.51536107063, 'accumulated_submission_time': 40705.26306152344, 'accumulated_eval_time': 9235.560923576355, 'accumulated_logging_time': 3.04288911819458, 'global_step': 99602, 'preemption_count': 0}), (100627, {'train/accuracy': 0.8433203125, 'train/loss': 0.5875175476074219, 'validation/accuracy': 0.74966, 'validation/loss': 0.98231171875, 'validation/num_examples': 50000, 'test/accuracy': 0.6297, 'test/loss': 1.59692900390625, 'test/num_examples': 10000, 'score': 41124.04196476936, 'total_duration': 50675.90296983719, 'accumulated_submission_time': 41124.04196476936, 'accumulated_eval_time': 9326.829373598099, 'accumulated_logging_time': 3.0803115367889404, 'global_step': 100627, 'preemption_count': 0}), (101653, {'train/accuracy': 0.8445703125, 'train/loss': 0.587913818359375, 'validation/accuracy': 0.75266, 'validation/loss': 0.9801221875, 'validation/num_examples': 50000, 'test/accuracy': 0.6313, 'test/loss': 1.59792314453125, 'test/num_examples': 10000, 'score': 41543.09160733223, 'total_duration': 51188.49051451683, 'accumulated_submission_time': 41543.09160733223, 'accumulated_eval_time': 9418.043019533157, 'accumulated_logging_time': 3.116440534591675, 'global_step': 101653, 'preemption_count': 0}), (102679, {'train/accuracy': 0.8463671875, 'train/loss': 0.5783162689208985, 'validation/accuracy': 0.7519, 'validation/loss': 0.974478828125, 'validation/num_examples': 50000, 'test/accuracy': 0.6279, 'test/loss': 1.58693818359375, 'test/num_examples': 10000, 'score': 41961.866085767746, 'total_duration': 51707.758049726486, 'accumulated_submission_time': 41961.866085767746, 'accumulated_eval_time': 9516.260301589966, 'accumulated_logging_time': 3.1542489528656006, 'global_step': 102679, 'preemption_count': 0}), (103709, {'train/accuracy': 0.847421875, 'train/loss': 0.5782836532592773, 'validation/accuracy': 0.75458, 'validation/loss': 0.97379921875, 'validation/num_examples': 50000, 'test/accuracy': 0.6294, 'test/loss': 1.59104033203125, 'test/num_examples': 10000, 'score': 42380.79360818863, 'total_duration': 52222.83391237259, 'accumulated_submission_time': 42380.79360818863, 'accumulated_eval_time': 9610.085911512375, 'accumulated_logging_time': 3.191195487976074, 'global_step': 103709, 'preemption_count': 0}), (104736, {'train/accuracy': 0.8512890625, 'train/loss': 0.5703498077392578, 'validation/accuracy': 0.75324, 'validation/loss': 0.977637265625, 'validation/num_examples': 50000, 'test/accuracy': 0.6389, 'test/loss': 1.57701064453125, 'test/num_examples': 10000, 'score': 42799.91485095024, 'total_duration': 52737.195675611496, 'accumulated_submission_time': 42799.91485095024, 'accumulated_eval_time': 9703.007879972458, 'accumulated_logging_time': 3.2267842292785645, 'global_step': 104736, 'preemption_count': 0}), (105761, {'train/accuracy': 0.852734375, 'train/loss': 0.5586693954467773, 'validation/accuracy': 0.7552, 'validation/loss': 0.967124140625, 'validation/num_examples': 50000, 'test/accuracy': 0.6302, 'test/loss': 1.57986357421875, 'test/num_examples': 10000, 'score': 43218.925899744034, 'total_duration': 53250.85289669037, 'accumulated_submission_time': 43218.925899744034, 'accumulated_eval_time': 9795.36553311348, 'accumulated_logging_time': 3.263418197631836, 'global_step': 105761, 'preemption_count': 0}), (106786, {'train/accuracy': 0.8540625, 'train/loss': 0.5444474792480469, 'validation/accuracy': 0.75772, 'validation/loss': 0.9536, 'validation/num_examples': 50000, 'test/accuracy': 0.6402, 'test/loss': 1.55708623046875, 'test/num_examples': 10000, 'score': 43637.99845647812, 'total_duration': 53764.18422079086, 'accumulated_submission_time': 43637.99845647812, 'accumulated_eval_time': 9887.369504451752, 'accumulated_logging_time': 3.3013100624084473, 'global_step': 106786, 'preemption_count': 0}), (107810, {'train/accuracy': 0.85595703125, 'train/loss': 0.5424169921875, 'validation/accuracy': 0.75812, 'validation/loss': 0.958324609375, 'validation/num_examples': 50000, 'test/accuracy': 0.6406, 'test/loss': 1.560701171875, 'test/num_examples': 10000, 'score': 44057.00115823746, 'total_duration': 54277.64653611183, 'accumulated_submission_time': 44057.00115823746, 'accumulated_eval_time': 9979.507205963135, 'accumulated_logging_time': 3.3355462551116943, 'global_step': 107810, 'preemption_count': 0}), (108838, {'train/accuracy': 0.855859375, 'train/loss': 0.5601757049560547, 'validation/accuracy': 0.75806, 'validation/loss': 0.965975234375, 'validation/num_examples': 50000, 'test/accuracy': 0.6399, 'test/loss': 1.57255400390625, 'test/num_examples': 10000, 'score': 44477.597714185715, 'total_duration': 54795.675968647, 'accumulated_submission_time': 44477.597714185715, 'accumulated_eval_time': 10074.69682431221, 'accumulated_logging_time': 3.371678352355957, 'global_step': 108838, 'preemption_count': 0}), (109870, {'train/accuracy': 0.8593359375, 'train/loss': 0.5270893096923828, 'validation/accuracy': 0.76204, 'validation/loss': 0.94185078125, 'validation/num_examples': 50000, 'test/accuracy': 0.6435, 'test/loss': 1.5496615234375, 'test/num_examples': 10000, 'score': 44896.43131685257, 'total_duration': 55315.226239681244, 'accumulated_submission_time': 44896.43131685257, 'accumulated_eval_time': 10173.106612443924, 'accumulated_logging_time': 3.4073944091796875, 'global_step': 109870, 'preemption_count': 0}), (110895, {'train/accuracy': 0.86236328125, 'train/loss': 0.5179230117797852, 'validation/accuracy': 0.76282, 'validation/loss': 0.936807265625, 'validation/num_examples': 50000, 'test/accuracy': 0.6403, 'test/loss': 1.54444853515625, 'test/num_examples': 10000, 'score': 45315.21571183205, 'total_duration': 55827.67030262947, 'accumulated_submission_time': 45315.21571183205, 'accumulated_eval_time': 10264.453321695328, 'accumulated_logging_time': 3.4423305988311768, 'global_step': 110895, 'preemption_count': 0}), (111920, {'train/accuracy': 0.8644140625, 'train/loss': 0.513069076538086, 'validation/accuracy': 0.76186, 'validation/loss': 0.9369096875, 'validation/num_examples': 50000, 'test/accuracy': 0.6425, 'test/loss': 1.54375908203125, 'test/num_examples': 10000, 'score': 45734.28729915619, 'total_duration': 56340.161566734314, 'accumulated_submission_time': 45734.28729915619, 'accumulated_eval_time': 10355.571375608444, 'accumulated_logging_time': 3.4803314208984375, 'global_step': 111920, 'preemption_count': 0}), (112944, {'train/accuracy': 0.86396484375, 'train/loss': 0.5202515029907226, 'validation/accuracy': 0.76554, 'validation/loss': 0.9400953125, 'validation/num_examples': 50000, 'test/accuracy': 0.6474, 'test/loss': 1.5354623046875, 'test/num_examples': 10000, 'score': 46153.360674619675, 'total_duration': 56852.52862691879, 'accumulated_submission_time': 46153.360674619675, 'accumulated_eval_time': 10446.608747005463, 'accumulated_logging_time': 3.5171797275543213, 'global_step': 112944, 'preemption_count': 0}), (113968, {'train/accuracy': 0.86662109375, 'train/loss': 0.49989437103271483, 'validation/accuracy': 0.76732, 'validation/loss': 0.924251796875, 'validation/num_examples': 50000, 'test/accuracy': 0.6451, 'test/loss': 1.5386171875, 'test/num_examples': 10000, 'score': 46572.472317934036, 'total_duration': 57369.98356962204, 'accumulated_submission_time': 46572.472317934036, 'accumulated_eval_time': 10542.69648194313, 'accumulated_logging_time': 3.5498931407928467, 'global_step': 113968, 'preemption_count': 0}), (114998, {'train/accuracy': 0.8693359375, 'train/loss': 0.48761680603027346, 'validation/accuracy': 0.767, 'validation/loss': 0.916077578125, 'validation/num_examples': 50000, 'test/accuracy': 0.6518, 'test/loss': 1.51863486328125, 'test/num_examples': 10000, 'score': 46991.21198415756, 'total_duration': 57883.75690817833, 'accumulated_submission_time': 46991.21198415756, 'accumulated_eval_time': 10635.36027431488, 'accumulated_logging_time': 3.583712339401245, 'global_step': 114998, 'preemption_count': 0}), (116025, {'train/accuracy': 0.87134765625, 'train/loss': 0.4869023513793945, 'validation/accuracy': 0.76772, 'validation/loss': 0.918648515625, 'validation/num_examples': 50000, 'test/accuracy': 0.6505, 'test/loss': 1.52064853515625, 'test/num_examples': 10000, 'score': 47410.31763482094, 'total_duration': 58402.29022669792, 'accumulated_submission_time': 47410.31763482094, 'accumulated_eval_time': 10732.412917137146, 'accumulated_logging_time': 3.6232876777648926, 'global_step': 116025, 'preemption_count': 0}), (117050, {'train/accuracy': 0.87228515625, 'train/loss': 0.47382511138916017, 'validation/accuracy': 0.7698, 'validation/loss': 0.907203828125, 'validation/num_examples': 50000, 'test/accuracy': 0.6497, 'test/loss': 1.51831455078125, 'test/num_examples': 10000, 'score': 47829.2496008873, 'total_duration': 58916.33164405823, 'accumulated_submission_time': 47829.2496008873, 'accumulated_eval_time': 10825.195115327835, 'accumulated_logging_time': 3.660820722579956, 'global_step': 117050, 'preemption_count': 0}), (118074, {'train/accuracy': 0.87443359375, 'train/loss': 0.4734429168701172, 'validation/accuracy': 0.76756, 'validation/loss': 0.91150984375, 'validation/num_examples': 50000, 'test/accuracy': 0.6512, 'test/loss': 1.51347451171875, 'test/num_examples': 10000, 'score': 48248.26400375366, 'total_duration': 59428.37057328224, 'accumulated_submission_time': 48248.26400375366, 'accumulated_eval_time': 10915.950778484344, 'accumulated_logging_time': 3.698261022567749, 'global_step': 118074, 'preemption_count': 0}), (119097, {'train/accuracy': 0.874609375, 'train/loss': 0.4653433227539063, 'validation/accuracy': 0.76982, 'validation/loss': 0.90433765625, 'validation/num_examples': 50000, 'test/accuracy': 0.653, 'test/loss': 1.50516025390625, 'test/num_examples': 10000, 'score': 48667.40327858925, 'total_duration': 59941.1938188076, 'accumulated_submission_time': 48667.40327858925, 'accumulated_eval_time': 11007.35677909851, 'accumulated_logging_time': 3.73533296585083, 'global_step': 119097, 'preemption_count': 0}), (120123, {'train/accuracy': 0.87720703125, 'train/loss': 0.46155826568603514, 'validation/accuracy': 0.77108, 'validation/loss': 0.89914265625, 'validation/num_examples': 50000, 'test/accuracy': 0.6553, 'test/loss': 1.50501767578125, 'test/num_examples': 10000, 'score': 49086.396035432816, 'total_duration': 60460.22948741913, 'accumulated_submission_time': 49086.396035432816, 'accumulated_eval_time': 11105.066396951675, 'accumulated_logging_time': 3.7727248668670654, 'global_step': 120123, 'preemption_count': 0}), (121154, {'train/accuracy': 0.87708984375, 'train/loss': 0.45498153686523435, 'validation/accuracy': 0.77144, 'validation/loss': 0.894196953125, 'validation/num_examples': 50000, 'test/accuracy': 0.6554, 'test/loss': 1.50044541015625, 'test/num_examples': 10000, 'score': 49505.52829742432, 'total_duration': 60977.11965084076, 'accumulated_submission_time': 49505.52829742432, 'accumulated_eval_time': 11200.504184007645, 'accumulated_logging_time': 3.8097081184387207, 'global_step': 121154, 'preemption_count': 0}), (122180, {'train/accuracy': 0.8786328125, 'train/loss': 0.45640762329101564, 'validation/accuracy': 0.772, 'validation/loss': 0.898678125, 'validation/num_examples': 50000, 'test/accuracy': 0.654, 'test/loss': 1.4994955078125, 'test/num_examples': 10000, 'score': 49924.506761312485, 'total_duration': 61489.38933992386, 'accumulated_submission_time': 49924.506761312485, 'accumulated_eval_time': 11291.458031892776, 'accumulated_logging_time': 3.8429646492004395, 'global_step': 122180, 'preemption_count': 0}), (123204, {'train/accuracy': 0.879296875, 'train/loss': 0.4496475601196289, 'validation/accuracy': 0.77348, 'validation/loss': 0.894118046875, 'validation/num_examples': 50000, 'test/accuracy': 0.6516, 'test/loss': 1.4974009765625, 'test/num_examples': 10000, 'score': 50343.63953948021, 'total_duration': 62001.96954059601, 'accumulated_submission_time': 50343.63953948021, 'accumulated_eval_time': 11382.631391525269, 'accumulated_logging_time': 3.881122350692749, 'global_step': 123204, 'preemption_count': 0}), (124229, {'train/accuracy': 0.87962890625, 'train/loss': 0.4486012268066406, 'validation/accuracy': 0.77404, 'validation/loss': 0.89386375, 'validation/num_examples': 50000, 'test/accuracy': 0.6553, 'test/loss': 1.4921673828125, 'test/num_examples': 10000, 'score': 50762.70052814484, 'total_duration': 62514.01327896118, 'accumulated_submission_time': 50762.70052814484, 'accumulated_eval_time': 11473.377854347229, 'accumulated_logging_time': 3.9163777828216553, 'global_step': 124229, 'preemption_count': 0}), (125255, {'train/accuracy': 0.88146484375, 'train/loss': 0.44205703735351565, 'validation/accuracy': 0.77508, 'validation/loss': 0.885947734375, 'validation/num_examples': 50000, 'test/accuracy': 0.6554, 'test/loss': 1.4920251953125, 'test/num_examples': 10000, 'score': 51181.74163556099, 'total_duration': 63030.87289118767, 'accumulated_submission_time': 51181.74163556099, 'accumulated_eval_time': 11568.957940101624, 'accumulated_logging_time': 3.954512119293213, 'global_step': 125255, 'preemption_count': 0}), (126286, {'train/accuracy': 0.88337890625, 'train/loss': 0.43346576690673827, 'validation/accuracy': 0.77514, 'validation/loss': 0.881525390625, 'validation/num_examples': 50000, 'test/accuracy': 0.654, 'test/loss': 1.4870451171875, 'test/num_examples': 10000, 'score': 51600.6655356884, 'total_duration': 63544.30040001869, 'accumulated_submission_time': 51600.6655356884, 'accumulated_eval_time': 11661.104115486145, 'accumulated_logging_time': 3.9934654235839844, 'global_step': 126286, 'preemption_count': 0}), (127313, {'train/accuracy': 0.88462890625, 'train/loss': 0.4279958343505859, 'validation/accuracy': 0.77534, 'validation/loss': 0.88004359375, 'validation/num_examples': 50000, 'test/accuracy': 0.6558, 'test/loss': 1.48254462890625, 'test/num_examples': 10000, 'score': 52019.81285524368, 'total_duration': 64063.12843108177, 'accumulated_submission_time': 52019.81285524368, 'accumulated_eval_time': 11758.416033506393, 'accumulated_logging_time': 4.033597469329834, 'global_step': 127313, 'preemption_count': 0}), (128336, {'train/accuracy': 0.88435546875, 'train/loss': 0.4303166961669922, 'validation/accuracy': 0.77596, 'validation/loss': 0.878986171875, 'validation/num_examples': 50000, 'test/accuracy': 0.6577, 'test/loss': 1.483891796875, 'test/num_examples': 10000, 'score': 52438.90845966339, 'total_duration': 64577.99871850014, 'accumulated_submission_time': 52438.90845966339, 'accumulated_eval_time': 11851.912655353546, 'accumulated_logging_time': 4.067496061325073, 'global_step': 128336, 'preemption_count': 0}), (129359, {'train/accuracy': 0.88505859375, 'train/loss': 0.4245481491088867, 'validation/accuracy': 0.77772, 'validation/loss': 0.874736328125, 'validation/num_examples': 50000, 'test/accuracy': 0.6587, 'test/loss': 1.47700703125, 'test/num_examples': 10000, 'score': 52857.84574651718, 'total_duration': 65090.454199552536, 'accumulated_submission_time': 52857.84574651718, 'accumulated_eval_time': 11943.130467414856, 'accumulated_logging_time': 4.104768991470337, 'global_step': 129359, 'preemption_count': 0}), (130385, {'train/accuracy': 0.88658203125, 'train/loss': 0.4211970520019531, 'validation/accuracy': 0.77796, 'validation/loss': 0.873415, 'validation/num_examples': 50000, 'test/accuracy': 0.6603, 'test/loss': 1.476080078125, 'test/num_examples': 10000, 'score': 53276.92240381241, 'total_duration': 65603.35263514519, 'accumulated_submission_time': 53276.92240381241, 'accumulated_eval_time': 12034.640534162521, 'accumulated_logging_time': 4.146943807601929, 'global_step': 130385, 'preemption_count': 0}), (131408, {'train/accuracy': 0.8862109375, 'train/loss': 0.4214011764526367, 'validation/accuracy': 0.7775, 'validation/loss': 0.87469390625, 'validation/num_examples': 50000, 'test/accuracy': 0.6594, 'test/loss': 1.47858974609375, 'test/num_examples': 10000, 'score': 53695.83012843132, 'total_duration': 66123.27806687355, 'accumulated_submission_time': 53695.83012843132, 'accumulated_eval_time': 12133.368770599365, 'accumulated_logging_time': 4.182413578033447, 'global_step': 131408, 'preemption_count': 0}), (132441, {'train/accuracy': 0.8872265625, 'train/loss': 0.4180831146240234, 'validation/accuracy': 0.77772, 'validation/loss': 0.8720446875, 'validation/num_examples': 50000, 'test/accuracy': 0.6611, 'test/loss': 1.47518642578125, 'test/num_examples': 10000, 'score': 54114.94544124603, 'total_duration': 66639.55735588074, 'accumulated_submission_time': 54114.94544124603, 'accumulated_eval_time': 12228.151146888733, 'accumulated_logging_time': 4.2230565547943115, 'global_step': 132441, 'preemption_count': 0}), (133464, {'train/accuracy': 0.887578125, 'train/loss': 0.41458595275878907, 'validation/accuracy': 0.77758, 'validation/loss': 0.868998515625, 'validation/num_examples': 50000, 'test/accuracy': 0.6601, 'test/loss': 1.47671103515625, 'test/num_examples': 10000, 'score': 54533.94416356087, 'total_duration': 67151.60945224762, 'accumulated_submission_time': 54533.94416356087, 'accumulated_eval_time': 12318.884562015533, 'accumulated_logging_time': 4.263211965560913, 'global_step': 133464, 'preemption_count': 0}), (134489, {'train/accuracy': 0.88837890625, 'train/loss': 0.4153050231933594, 'validation/accuracy': 0.77728, 'validation/loss': 0.87169921875, 'validation/num_examples': 50000, 'test/accuracy': 0.6599, 'test/loss': 1.47665751953125, 'test/num_examples': 10000, 'score': 54952.920229673386, 'total_duration': 67663.77019453049, 'accumulated_submission_time': 54952.920229673386, 'accumulated_eval_time': 12409.757031202316, 'accumulated_logging_time': 4.3004326820373535, 'global_step': 134489, 'preemption_count': 0}), (135511, {'train/accuracy': 0.88818359375, 'train/loss': 0.41580307006835937, 'validation/accuracy': 0.7778, 'validation/loss': 0.87091265625, 'validation/num_examples': 50000, 'test/accuracy': 0.6618, 'test/loss': 1.4742875, 'test/num_examples': 10000, 'score': 55371.69947171211, 'total_duration': 68175.7032225132, 'accumulated_submission_time': 55371.69947171211, 'accumulated_eval_time': 12500.60895872116, 'accumulated_logging_time': 4.342997789382935, 'global_step': 135511, 'preemption_count': 0}), (136533, {'train/accuracy': 0.888359375, 'train/loss': 0.41403865814208984, 'validation/accuracy': 0.77814, 'validation/loss': 0.86959609375, 'validation/num_examples': 50000, 'test/accuracy': 0.6617, 'test/loss': 1.4733244140625, 'test/num_examples': 10000, 'score': 55790.65551114082, 'total_duration': 68690.78505969048, 'accumulated_submission_time': 55790.65551114082, 'accumulated_eval_time': 12594.463595628738, 'accumulated_logging_time': 4.386544227600098, 'global_step': 136533, 'preemption_count': 0}), (137561, {'train/accuracy': 0.8884375, 'train/loss': 0.4130818176269531, 'validation/accuracy': 0.7782, 'validation/loss': 0.8689665625, 'validation/num_examples': 50000, 'test/accuracy': 0.6611, 'test/loss': 1.47291494140625, 'test/num_examples': 10000, 'score': 56209.52092504501, 'total_duration': 69204.24505281448, 'accumulated_submission_time': 56209.52092504501, 'accumulated_eval_time': 12686.76236653328, 'accumulated_logging_time': 4.422796249389648, 'global_step': 137561, 'preemption_count': 0}), (138588, {'train/accuracy': 0.88880859375, 'train/loss': 0.4131156539916992, 'validation/accuracy': 0.77842, 'validation/loss': 0.868383984375, 'validation/num_examples': 50000, 'test/accuracy': 0.6614, 'test/loss': 1.471919140625, 'test/num_examples': 10000, 'score': 56628.483342409134, 'total_duration': 69725.20699548721, 'accumulated_submission_time': 56628.483342409134, 'accumulated_eval_time': 12786.434039115906, 'accumulated_logging_time': 4.458261966705322, 'global_step': 138588, 'preemption_count': 0}), (139612, {'train/accuracy': 0.8887109375, 'train/loss': 0.41284698486328125, 'validation/accuracy': 0.77836, 'validation/loss': 0.868195078125, 'validation/num_examples': 50000, 'test/accuracy': 0.6622, 'test/loss': 1.47205478515625, 'test/num_examples': 10000, 'score': 57047.25692439079, 'total_duration': 70240.88380050659, 'accumulated_submission_time': 57047.25692439079, 'accumulated_eval_time': 12881.090112924576, 'accumulated_logging_time': 4.495534181594849, 'global_step': 139612, 'preemption_count': 0}), (140000, {'train/accuracy': 0.88865234375, 'train/loss': 0.4128573989868164, 'validation/accuracy': 0.77834, 'validation/loss': 0.86820859375, 'validation/num_examples': 50000, 'test/accuracy': 0.6622, 'test/loss': 1.47203828125, 'test/num_examples': 10000, 'score': 57205.48697280884, 'total_duration': 70491.90201473236, 'accumulated_submission_time': 57205.48697280884, 'accumulated_eval_time': 12971.965034484863, 'accumulated_logging_time': 4.539530038833618, 'global_step': 140000, 'preemption_count': 0})], 'global_step': 140000}
I0915 19:38:20.735409 139684108298048 submission_runner.py:543] Timing: 57205.48697280884
I0915 19:38:20.735522 139684108298048 submission_runner.py:545] Total number of evals: 138
I0915 19:38:20.735602 139684108298048 submission_runner.py:546] ====================
I0915 19:38:20.736091 139684108298048 submission_runner.py:614] Final imagenet_vit score: 57205.48697280884
