torchrun --redirects 1:0,2:0,3:0,4:0,5:0,6:0,7:0 --standalone --nnodes=1 --nproc_per_node=8 submission_runner.py --framework=pytorch --workload=librispeech_conformer --submission_path=reference_algorithms/target_setting_algorithms/pytorch_adamw.py --tuning_search_space=reference_algorithms/target_setting_algorithms/librispeech_conformer/tuning_search_space.json --data_dir=/data/librispeech --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=targets_check_conformer/adamw_run_0 --overwrite=true --save_checkpoints=false --max_global_steps=60000 --librispeech_tokenizer_vocab_path=/data/librispeech/spm_model.vocab --torch_compile=true 2>&1 | tee -a /logs/librispeech_conformer_pytorch_10-06-2023-23-33-12.log
master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-10-06 23:33:23.144743: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-10-06 23:33:23.144742: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-10-06 23:33:23.144742: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-10-06 23:33:23.144742: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-10-06 23:33:23.144742: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-10-06 23:33:23.144742: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-10-06 23:33:23.144743: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-10-06 23:33:23.144746: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I1006 23:33:37.373363 139943469840192 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 7
I1006 23:33:37.373399 140344114898752 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
I1006 23:33:37.373425 139969316050752 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 6
I1006 23:33:37.375010 139902833473344 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
I1006 23:33:37.375313 140454947399488 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 4
I1006 23:33:38.363925 140384386467648 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 5
I1006 23:33:38.363956 139812948772672 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
I1006 23:33:38.365363 139932355139392 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
I1006 23:33:38.365816 139932355139392 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I1006 23:33:38.373284 140454947399488 distributed_c10d.py:476] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I1006 23:33:38.373305 140344114898752 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I1006 23:33:38.373423 139943469840192 distributed_c10d.py:476] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I1006 23:33:38.373465 139969316050752 distributed_c10d.py:476] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I1006 23:33:38.373570 139902833473344 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I1006 23:33:38.374508 140384386467648 distributed_c10d.py:476] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I1006 23:33:38.374554 139812948772672 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I1006 23:33:38.887972 139932355139392 logger_utils.py:61] Removing existing experiment directory /experiment_runs/targets_check_conformer/adamw_run_0/librispeech_conformer_pytorch because --overwrite was set.
I1006 23:33:38.895065 139932355139392 logger_utils.py:76] Creating experiment directory at /experiment_runs/targets_check_conformer/adamw_run_0/librispeech_conformer_pytorch.
W1006 23:33:39.653649 139943469840192 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W1006 23:33:39.653824 140454947399488 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W1006 23:33:39.654264 139812948772672 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W1006 23:33:39.654580 140384386467648 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W1006 23:33:39.654767 140344114898752 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W1006 23:33:39.654933 139969316050752 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W1006 23:33:39.655066 139902833473344 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W1006 23:33:39.655176 139932355139392 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I1006 23:33:39.659312 139932355139392 submission_runner.py:510] Using RNG seed 2433722856
I1006 23:33:39.661052 139932355139392 submission_runner.py:519] --- Tuning run 1/1 ---
I1006 23:33:39.661204 139932355139392 submission_runner.py:524] Creating tuning directory at /experiment_runs/targets_check_conformer/adamw_run_0/librispeech_conformer_pytorch/trial_1.
I1006 23:33:39.661399 139932355139392 logger_utils.py:92] Saving hparams to /experiment_runs/targets_check_conformer/adamw_run_0/librispeech_conformer_pytorch/trial_1/hparams.json.
I1006 23:33:39.662220 139932355139392 submission_runner.py:194] Initializing dataset.
I1006 23:33:39.662353 139932355139392 input_pipeline.py:20] Loading split = train-clean-100
I1006 23:33:39.699597 139932355139392 input_pipeline.py:20] Loading split = train-clean-360
I1006 23:33:40.119416 139932355139392 input_pipeline.py:20] Loading split = train-other-500
I1006 23:33:40.606326 139932355139392 submission_runner.py:201] Initializing model.
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
W1006 23:33:47.890351 139812948772672 submission_runner.py:222] These workloads cannot be fully compiled under current PyTorch version. Proceeding with `backend=eager`.
W1006 23:33:47.890376 140454947399488 submission_runner.py:222] These workloads cannot be fully compiled under current PyTorch version. Proceeding with `backend=eager`.
W1006 23:33:47.890480 140344114898752 submission_runner.py:222] These workloads cannot be fully compiled under current PyTorch version. Proceeding with `backend=eager`.
W1006 23:33:47.890486 140384386467648 submission_runner.py:222] These workloads cannot be fully compiled under current PyTorch version. Proceeding with `backend=eager`.
W1006 23:33:47.890564 139902833473344 submission_runner.py:222] These workloads cannot be fully compiled under current PyTorch version. Proceeding with `backend=eager`.
W1006 23:33:47.890619 139969316050752 submission_runner.py:222] These workloads cannot be fully compiled under current PyTorch version. Proceeding with `backend=eager`.
W1006 23:33:47.890697 139932355139392 submission_runner.py:222] These workloads cannot be fully compiled under current PyTorch version. Proceeding with `backend=eager`.
W1006 23:33:47.890727 139943469840192 submission_runner.py:222] These workloads cannot be fully compiled under current PyTorch version. Proceeding with `backend=eager`.
I1006 23:33:48.212675 139932355139392 submission_runner.py:235] Initializing optimizer.
I1006 23:33:48.213971 139932355139392 submission_runner.py:242] Initializing metrics bundle.
I1006 23:33:48.214101 139932355139392 submission_runner.py:260] Initializing checkpoint and logger.
I1006 23:33:48.214703 139932355139392 submission_runner.py:280] Saving meta data to /experiment_runs/targets_check_conformer/adamw_run_0/librispeech_conformer_pytorch/trial_1/meta_data_0.json.
I1006 23:33:48.214962 139932355139392 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I1006 23:33:48.215067 139932355139392 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I1006 23:33:48.484468 139932355139392 logger_utils.py:220] Unable to record git information. Continuing without it.
I1006 23:33:48.708761 139932355139392 submission_runner.py:283] Saving flags to /experiment_runs/targets_check_conformer/adamw_run_0/librispeech_conformer_pytorch/trial_1/flags_0.json.
I1006 23:33:48.722895 139932355139392 submission_runner.py:293] Starting training loop.
[2023-10-06 23:33:50,975] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:51,044] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:51,099] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:51,171] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:51,173] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:51,201] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:51,263] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:51,340] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:52,026] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:52,045] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:52,117] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:52,131] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,132] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,132] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,132] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,135] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:52,153] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:52,155] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,155] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,156] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,156] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,191] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:52,195] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:52,231] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:52,242] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,242] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,243] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,243] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,243] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,243] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,243] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,244] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,300] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,301] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,302] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,302] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,307] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,307] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,308] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,308] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,335] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,336] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,337] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,337] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,348] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,348] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,349] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,349] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,884] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing linear_to_mel_weight_matrix
[2023-10-06 23:33:52,884] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing linear_to_mel_weight_matrix
[2023-10-06 23:33:52,884] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing linear_to_mel_weight_matrix
[2023-10-06 23:33:52,884] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing linear_to_mel_weight_matrix
[2023-10-06 23:33:52,886] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing linear_to_mel_weight_matrix
[2023-10-06 23:33:52,888] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing linear_to_mel_weight_matrix
[2023-10-06 23:33:52,896] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,896] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,896] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,897] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,899] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,900] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,900] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,900] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,900] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,900] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,900] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,901] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,901] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,901] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,901] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,902] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,902] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,902] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,903] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,903] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,903] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,903] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
<eval_with_key>.1:27: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1442.)
  abs_1 = torch.abs(fft_rfft);  fft_rfft = None
[2023-10-06 23:33:52,904] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,904] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,908] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing linear_to_mel_weight_matrix
[2023-10-06 23:33:52,911] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing linear_to_mel_weight_matrix
[2023-10-06 23:33:52,915] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _hertz_to_mel
[2023-10-06 23:33:52,917] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _hertz_to_mel
[2023-10-06 23:33:52,917] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _hertz_to_mel
[2023-10-06 23:33:52,919] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _hertz_to_mel
[2023-10-06 23:33:52,921] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _hertz_to_mel
[2023-10-06 23:33:52,921] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _hertz_to_mel
[2023-10-06 23:33:52,924] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _hertz_to_mel (RETURN_VALUE)
[2023-10-06 23:33:52,924] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,924] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,925] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,925] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,925] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _hertz_to_mel (RETURN_VALUE)
[2023-10-06 23:33:52,925] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,926] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,926] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _hertz_to_mel (RETURN_VALUE)
[2023-10-06 23:33:52,926] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,926] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,926] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,926] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,927] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,927] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,927] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,927] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,927] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,927] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,927] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,927] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,928] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,928] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,929] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _hertz_to_mel (RETURN_VALUE)
[2023-10-06 23:33:52,931] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _hertz_to_mel (RETURN_VALUE)
[2023-10-06 23:33:52,931] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _hertz_to_mel (RETURN_VALUE)
[2023-10-06 23:33:52,931] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,931] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,932] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,932] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,932] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,932] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,932] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,933] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,933] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,933] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,933] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,933] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,939] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in linear_to_mel_weight_matrix>
[2023-10-06 23:33:52,939] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in linear_to_mel_weight_matrix>
[2023-10-06 23:33:52,939] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in linear_to_mel_weight_matrix>
[2023-10-06 23:33:52,940] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in linear_to_mel_weight_matrix>
[2023-10-06 23:33:52,941] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _hertz_to_mel
[2023-10-06 23:33:52,944] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _hertz_to_mel
[2023-10-06 23:33:52,949] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _hertz_to_mel (RETURN_VALUE)
[2023-10-06 23:33:52,951] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,951] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,951] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,951] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,953] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _hertz_to_mel (RETURN_VALUE)
[2023-10-06 23:33:52,954] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,955] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,955] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,955] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,957] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in linear_to_mel_weight_matrix>
[2023-10-06 23:33:52,957] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in linear_to_mel_weight_matrix>
[2023-10-06 23:33:52,962] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in linear_to_mel_weight_matrix>
[2023-10-06 23:33:52,975] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in linear_to_mel_weight_matrix>
[2023-10-06 23:33:52,981] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in linear_to_mel_weight_matrix> (RETURN_VALUE)
[2023-10-06 23:33:52,981] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in linear_to_mel_weight_matrix> (RETURN_VALUE)
[2023-10-06 23:33:52,981] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in linear_to_mel_weight_matrix> (RETURN_VALUE)
[2023-10-06 23:33:52,981] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in linear_to_mel_weight_matrix> (RETURN_VALUE)
[2023-10-06 23:33:52,984] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,984] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,984] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,984] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,985] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,985] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,985] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,985] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:52,985] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,985] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:52,985] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,985] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,985] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,986] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,986] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:52,986] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:52,999] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in linear_to_mel_weight_matrix> (RETURN_VALUE)
[2023-10-06 23:33:53,001] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in linear_to_mel_weight_matrix> (RETURN_VALUE)
[2023-10-06 23:33:53,002] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:53,002] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:53,002] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:53,002] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:53,003] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:53,003] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:53,004] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in linear_to_mel_weight_matrix> (RETURN_VALUE)
[2023-10-06 23:33:53,005] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:53,005] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:53,005] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:53,005] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:53,008] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:53,008] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:53,008] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:53,008] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:53,013] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:53,017] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:53,018] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in linear_to_mel_weight_matrix> (RETURN_VALUE)
[2023-10-06 23:33:53,019] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:53,022] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:53,022] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:53,022] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:53,022] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:53,027] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:53,027] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:53,029] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:53,029] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:53,029] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:53,030] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:53,030] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:53,030] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:53,030] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:53,030] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:53,030] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:53,030] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:53,031] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:53,036] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:53,039] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:53,039] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:53,039] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:53,039] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:53,040] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:53,043] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:53,043] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:53,043] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:53,043] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:53,044] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:53,046] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:53,046] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:53,047] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:53,047] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:53,058] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:53,060] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:53,060] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:53,060] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:53,061] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:53,061] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:53,062] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:53,063] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:53,063] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:53,063] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:53,063] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:53,065] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:53,065] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:53,065] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:53,065] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:53,895] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:53,912] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:53,917] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:53,918] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:53,918] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:53,923] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:53,949] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:53,978] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:54,284] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:54,307] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:54,308] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:54,309] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:54,309] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:54,343] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:54,388] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:54,390] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:54,427] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:54,436] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:54,436] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:54,437] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:54,437] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:54,453] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:54,456] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:54,457] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:54,458] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:54,459] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:54,463] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:54,463] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:54,463] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:54,463] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:54,465] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:54,466] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:54,466] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:54,466] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:54,468] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:54,468] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:54,469] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:54,469] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:54,469] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:54,469] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:54,469] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:54,469] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:54,474] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:54,477] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:54,481] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:54,481] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:54,496] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:54,506] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:54,506] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:54,507] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:54,507] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:54,519] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:54,540] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:54,542] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:54,550] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:54,550] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:54,551] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:54,551] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:54,552] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:54,553] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:54,553] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:54,553] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:54,564] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:54,565] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:54,590] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:54,597] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:54,598] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:54,598] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:54,608] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:54,610] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:54,614] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:54,615] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:54,616] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:54,616] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:54,617] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:54,617] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:54,617] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:54,621] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:54,621] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:54,622] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:54,623] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:54,630] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:54,631] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:54,631] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:54,658] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:54,665] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:54,666] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:54,666] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:54,672] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:54,688] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:54,688] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:54,692] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:54,705] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:54,706] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:54,707] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:54,712] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:54,712] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:54,712] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:54,713] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:54,713] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:54,714] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:54,741] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:54,789] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:54,791] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,437] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __iter__
[2023-10-06 23:33:56,437] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __iter__
[2023-10-06 23:33:56,437] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __iter__
[2023-10-06 23:33:56,445] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,445] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,445] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,482] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __iter__
[2023-10-06 23:33:56,491] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,501] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __iter__
[2023-10-06 23:33:56,509] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,528] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,529] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,529] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,529] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,529] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,529] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,540] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,540] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,540] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,570] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __iter__
[2023-10-06 23:33:56,570] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,571] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __iter__
[2023-10-06 23:33:56,573] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,573] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,574] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,574] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,576] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __iter__
[2023-10-06 23:33:56,580] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,580] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,585] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,585] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,585] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,585] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,590] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,590] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,591] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,596] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,611] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,611] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,611] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,611] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,612] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,613] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,613] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,613] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,616] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,623] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,624] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,625] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,625] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,625] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,626] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,627] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,635] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,636] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:56,637] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,640] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:56,646] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,650] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:56,653] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,653] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,653] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,653] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,665] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,665] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,665] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,665] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,668] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:56,668] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,669] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,669] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,670] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:56,670] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,670] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,671] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,671] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,672] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,672] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,672] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,672] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,673] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,673] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,673] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,673] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,673] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,678] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:56,680] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:56,682] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,683] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,683] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,686] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,689] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,691] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,694] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:56,694] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:56,699] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:56,701] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,705] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:56,708] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:56,709] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,710] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,710] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,711] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,712] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,715] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:56,717] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:56,718] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,718] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,718] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,718] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,718] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,719] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,719] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,720] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,720] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,720] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,722] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,726] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:56,728] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:56,728] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,729] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,729] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,729] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,729] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,729] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,731] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,731] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,731] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,732] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:56,737] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,738] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,738] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,742] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:56,742] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:56,743] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,743] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,743] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,744] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,744] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,744] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,744] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,744] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,746] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:56,747] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,747] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,747] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,748] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,748] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,748] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,748] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,748] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,749] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,749] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,750] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,750] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,751] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,752] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,753] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,754] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:56,755] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:56,757] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,757] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,757] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,757] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,758] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,758] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,759] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,759] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,759] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,761] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,762] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,766] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,771] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:56,772] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,772] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:56,772] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,772] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,772] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,774] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:56,775] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:56,777] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:56,779] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,780] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,780] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,780] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,781] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,786] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:56,789] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,794] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:56,795] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,795] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,795] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,795] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,803] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,805] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:56,806] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:56,808] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,808] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,808] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,809] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,809] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,809] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,818] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:56,820] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,820] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,821] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,828] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,828] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,831] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:56,832] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:56,840] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,843] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:56,847] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,851] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,852] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,853] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:56,854] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:56,855] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,855] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,856] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,856] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,856] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,856] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,857] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,857] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,865] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,865] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:56,866] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,868] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,868] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,868] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,868] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,870] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:56,871] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,871] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:56,871] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,871] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,871] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,872] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,872] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,872] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,872] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,875] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,878] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,879] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,881] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,883] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:56,885] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:56,885] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:56,885] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:56,885] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:56,894] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,898] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,974] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,977] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:56,989] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:57,029] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,033] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,034] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,038] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,039] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,039] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,043] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,043] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,043] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,043] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,043] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,043] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,055] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,064] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,065] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,065] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,076] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,085] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,086] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,086] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,158] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,158] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,161] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,165] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,167] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,167] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,168] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,168] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,168] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,168] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,169] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,171] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,180] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,181] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,181] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,184] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,184] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,184] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,187] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,200] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,206] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,219] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,265] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,265] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,265] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,266] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,266] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,266] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,266] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,266] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,266] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,282] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,282] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,282] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,292] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,294] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,303] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,303] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,304] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,306] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,307] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,307] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,308] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,308] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,309] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,318] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,319] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,319] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,322] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,324] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,333] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,344] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,344] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,344] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,345] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,345] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,345] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,345] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,345] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,346] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,346] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,346] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,346] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,346] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,348] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:57,350] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:57,350] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:57,354] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,359] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,359] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,360] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,360] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,363] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:57,377] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:57,378] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:57,379] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:57,380] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,380] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,380] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,380] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,380] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,381] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,381] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,381] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,381] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,381] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,381] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,381] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,381] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,385] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:57,387] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,387] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,387] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,392] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:57,395] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,395] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,395] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,398] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,398] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,398] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,399] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,400] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,400] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,402] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:57,403] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:57,403] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:57,406] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,406] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,407] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,414] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,414] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:57,417] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,417] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,417] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,417] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:57,423] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:57,424] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:57,425] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:57,425] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,425] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,426] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,426] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,426] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,427] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,427] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,427] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,427] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,427] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,428] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,428] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,429] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,436] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:57,436] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,438] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:57,439] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:57,439] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:57,439] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:57,440] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,441] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,441] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,441] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,441] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,441] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,441] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,442] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,442] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,442] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,442] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,442] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,444] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,444] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,444] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,444] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,444] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,445] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,445] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,445] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,446] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,451] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,451] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:57,452] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:57,452] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,453] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:57,454] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:57,457] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,458] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,458] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,458] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,458] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,460] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,462] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:57,464] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,464] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,464] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,464] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,467] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,467] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,467] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:57,467] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,467] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,471] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:57,473] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:57,478] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,479] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,479] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,479] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,479] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,479] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,480] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,480] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,480] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,483] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:57,488] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,488] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,488] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,488] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,489] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:57,493] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:57,500] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:57,502] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,502] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,503] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,513] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:57,515] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,515] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,515] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,521] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,522] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:57,524] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,524] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,525] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:57,525] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,534] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,538] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:57,544] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,546] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:57,547] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:57,548] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,548] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,548] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,548] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,557] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:57,560] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:57,562] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,562] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,562] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,562] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,562] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,564] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,564] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,564] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,564] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,569] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:57,571] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:57,571] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,572] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,572] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,572] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,573] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:57,576] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,578] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,578] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,578] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,578] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,581] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:57,586] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,587] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:57,587] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,588] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,588] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,588] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,597] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:57,639] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,641] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,644] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,648] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,649] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,649] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,650] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,651] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,651] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,653] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,654] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,654] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,654] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,663] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,664] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,664] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,673] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,682] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,683] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,683] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,767] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,770] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,777] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,777] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,777] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,778] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,778] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,782] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,783] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,786] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:57,787] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,792] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,792] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,793] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,793] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,794] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,796] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,797] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,797] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,801] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,807] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,820] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,868] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,869] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,869] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,876] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,876] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,876] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,876] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,877] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,877] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,884] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,885] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,885] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,902] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,902] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,902] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,909] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,911] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,917] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,918] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,919] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,926] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,926] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,927] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,927] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,928] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,928] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,935] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,942] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,943] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,943] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,945] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,945] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,945] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,945] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,949] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:57,952] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:57,953] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,953] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,953] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,953] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,956] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,956] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,956] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,956] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,957] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:57,960] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:57,962] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,962] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,962] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,962] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,966] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:57,978] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:57,978] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,979] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,979] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,979] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:57,981] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,981] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,981] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,983] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:57,986] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:57,989] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,989] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,989] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,991] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:57,994] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,994] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,994] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:57,996] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:57,998] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:57,998] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:57,999] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,000] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,003] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:58,007] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,007] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,007] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,007] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,010] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:58,012] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,013] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:58,015] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,016] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,016] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,016] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:58,017] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,021] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:58,024] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,024] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,024] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,025] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:58,027] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,027] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,027] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,027] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,032] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:58,032] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,032] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,033] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,034] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,034] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,034] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,034] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,034] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,037] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,038] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:58,038] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:58,040] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,040] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,040] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,040] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,042] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,042] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:58,043] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,043] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,043] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,043] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,043] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,044] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,045] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,045] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,045] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,048] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,049] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,049] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,049] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,050] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,050] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,050] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,052] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,053] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,054] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,055] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,055] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,055] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,055] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,058] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,059] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,060] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:58,060] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,060] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,060] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:58,060] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,061] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,062] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,062] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,062] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,063] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,063] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,066] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,070] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,072] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,076] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:58,076] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,077] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,078] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,078] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,078] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,079] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,086] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,088] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,088] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,089] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,089] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,090] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:58,093] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:58,104] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,104] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,104] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,104] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,109] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:58,118] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,118] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,118] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,118] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,123] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:58,123] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:58,126] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,126] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,126] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,139] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:58,141] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,141] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,142] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,145] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,149] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:58,154] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:58,156] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,157] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,157] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,160] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,164] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:58,171] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:58,173] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,174] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,174] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,174] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,176] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,180] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:58,184] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,186] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:58,188] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,188] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,188] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,188] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,189] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,190] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,190] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,191] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,191] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,199] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,201] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,203] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:58,204] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,205] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,205] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,205] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,205] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,206] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,206] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,206] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,206] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,216] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,216] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,222] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,223] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,223] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,224] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,224] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,233] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,239] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,246] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,246] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,248] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,248] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,248] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,253] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,255] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,256] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,256] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,256] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,256] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,257] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,261] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,262] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,262] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,269] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,279] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,279] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,279] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,367] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,377] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,377] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,380] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:58,383] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,391] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:58,391] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:58,396] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:58,396] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,400] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,406] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,407] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,407] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,413] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:58,428] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,429] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,439] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,439] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,439] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,440] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,440] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,440] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,464] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,464] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,464] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,475] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,475] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,475] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,476] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,476] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,476] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,476] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,476] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,477] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,497] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,497] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,497] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,506] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,518] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,518] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,519] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,537] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,538] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,544] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:58,570] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,570] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,571] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,571] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,571] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,572] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,575] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:58,578] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:58,578] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:58,578] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:58,604] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:58,604] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,604] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,605] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,605] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,606] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,606] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,606] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,606] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,606] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,606] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,606] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,606] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,607] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,607] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,607] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:58,607] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,608] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:58,609] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:58,610] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:58,610] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:58,611] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:58,612] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:58,625] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,629] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:58,635] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,635] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,636] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,636] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,638] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:58,639] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:58,640] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:58,640] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:58,640] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,640] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,640] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,642] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,642] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,642] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,642] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,642] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,643] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,650] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:58,652] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,652] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,653] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,653] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,658] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,661] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,661] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,662] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:58,664] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:58,664] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:58,669] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:58,672] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,672] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,672] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,683] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:58,685] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,685] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,685] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,685] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,685] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:58,686] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:58,687] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,688] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,688] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,688] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,688] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,688] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,688] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,688] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,691] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,693] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,693] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,694] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,694] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:58,701] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,702] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,702] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,705] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,706] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,706] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,715] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:58,717] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,718] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,718] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,718] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,738] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,743] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,746] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,748] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,749] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,749] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,750] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,750] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,751] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,758] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,839] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,840] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,840] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,840] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,844] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,844] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,845] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,845] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,846] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,846] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,846] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,846] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,846] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,846] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,846] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,846] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,847] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,847] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,847] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,847] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,847] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,847] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,847] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,847] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,855] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,856] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,856] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,856] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:58,882] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:58,883] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:58,883] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:58,912] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,912] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,912] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,912] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,912] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,912] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,912] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,912] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,913] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,913] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,913] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,913] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,917] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:58,917] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:58,918] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:33:58,941] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:58,948] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:58,948] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:58,949] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:33:58,950] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,950] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,950] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,951] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,951] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,951] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,951] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,951] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,951] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,951] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,952] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,952] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:58,970] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,970] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,971] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:58,974] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:58,974] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:58,975] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:33:58,997] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:58,997] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:58,998] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:33:58,999] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:58,999] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:58,999] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,000] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,000] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,000] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,000] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,000] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,001] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,001] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,001] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,001] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,038] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:59,038] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:59,041] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:59,042] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:59,047] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,047] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,048] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,048] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,048] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,048] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,050] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,051] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,051] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,052] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,053] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,053] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,071] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,090] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:59,091] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:59,096] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:59,096] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:59,097] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,097] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,097] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,098] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,098] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,098] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,098] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,098] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,108] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:59,108] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:59,166] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:59,167] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:59,167] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,168] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,169] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,172] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:59,173] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,173] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,174] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,174] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,174] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,178] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:59,179] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:59,179] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,180] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,180] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,180] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,181] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:59,182] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:59,184] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:33:59,186] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:59,190] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:59,192] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,192] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,192] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,192] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,192] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:59,194] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:59,194] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,195] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,195] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,195] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,196] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,196] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,196] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,196] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,198] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:59,200] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,200] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,201] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,201] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,304] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:59,315] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,315] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,316] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,383] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:59,391] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:33:59,393] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,394] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,394] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,406] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,406] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,407] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,447] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,459] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:59,471] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:59,472] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,473] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,473] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,473] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,523] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,535] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:59,535] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,546] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:59,547] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:33:59,548] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,548] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,549] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,549] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:33:59,559] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:33:59,560] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:33:59,561] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:33:59,561] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:33:59,561] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I1006 23:34:01.205018 139906428950272 logging_writer.py:48] [0] global_step=0, grad_norm=64.843285, loss=32.609303
I1006 23:34:01.235127 139932355139392 pytorch_submission_base.py:86] 0) loss = 32.609, grad_norm = 64.843
I1006 23:34:01.805450 139932355139392 spec.py:321] Evaluating on the training split.
I1006 23:34:01.806950 139932355139392 input_pipeline.py:20] Loading split = train-clean-100
I1006 23:34:01.844984 139932355139392 input_pipeline.py:20] Loading split = train-clean-360
I1006 23:34:01.985575 139932355139392 input_pipeline.py:20] Loading split = train-other-500
[2023-10-06 23:34:04,856] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:04,878] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:04,880] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:04,894] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:04,956] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:04,990] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,010] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,039] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,047] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,066] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,076] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,080] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,107] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,133] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,133] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,134] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,134] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,159] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,160] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,160] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,160] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,163] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,177] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:05,182] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,183] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,183] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,183] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,193] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:05,199] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:05,199] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,204] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:05,207] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,207] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,207] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,207] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,208] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,208] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,208] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,208] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,220] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,224] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:05,224] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,224] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,225] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:05,225] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,225] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,227] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,227] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,227] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:05,228] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,228] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,230] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,230] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,231] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,231] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,239] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:05,239] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,240] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,241] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,253] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:05,256] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,256] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,256] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,256] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,265] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:05,268] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,268] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,269] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,269] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,269] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,279] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,290] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,290] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,291] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,291] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,309] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,309] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,310] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,310] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,310] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:05,324] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:05,340] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:05,343] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,344] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,344] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,344] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,350] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,351] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,351] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:05,351] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,351] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,354] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,354] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,354] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,354] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,356] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,365] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,375] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:05,385] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:05,393] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,393] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,394] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,402] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:05,404] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,404] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:05,405] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,405] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,405] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,411] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:05,412] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,413] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,413] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,415] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,419] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,420] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,420] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,434] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:05,440] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:05,442] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,442] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,443] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,448] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,449] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,449] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,475] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,495] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,503] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,505] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,523] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,526] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:05,529] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,534] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,535] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,535] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:05,535] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,541] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,543] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,544] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,544] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,566] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,572] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,578] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:05,579] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,586] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,586] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,586] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,609] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,610] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,610] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,616] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,630] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,644] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,644] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,645] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,656] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,662] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,662] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,662] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,667] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,668] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,674] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,674] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,675] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,680] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,680] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,681] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,690] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,694] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,699] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,699] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,699] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,699] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,701] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,703] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,710] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,714] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,722] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,722] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,723] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,730] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,732] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:05,733] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,736] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,737] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,737] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,737] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,740] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,750] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,758] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,758] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,758] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,758] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,766] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,766] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,767] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,767] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,768] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:05,771] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:05,772] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,773] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,773] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,773] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,773] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,774] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,774] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,774] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,780] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,786] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,790] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:05,797] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:05,797] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,797] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,798] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,798] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,802] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:05,804] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:05,811] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:05,814] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,814] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,814] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,826] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,827] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,827] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,828] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:05,831] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,831] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,832] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,834] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:05,837] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:05,838] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,838] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,838] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,838] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,839] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,840] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,840] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,840] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,841] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:05,844] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,844] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,844] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,846] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,847] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,847] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,847] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,848] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:05,856] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,856] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,861] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:05,862] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,867] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:05,868] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,873] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:05,877] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:05,878] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,880] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,880] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,881] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,881] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,885] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:05,888] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:05,889] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,889] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,890] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,890] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,890] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,890] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:05,890] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,891] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,891] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,893] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,893] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,893] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,894] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,894] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,895] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:05,895] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,898] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,898] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,899] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,899] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,901] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:05,901] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:05,903] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:05,903] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,904] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,904] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,904] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,905] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,906] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,906] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:05,907] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,907] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:05,908] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,908] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,908] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,910] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:05,910] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:05,912] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,912] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,912] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:05,912] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,912] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,913] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:05,914] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,914] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,914] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,914] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,915] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:05,916] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,917] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,917] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,917] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,919] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:05,922] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:05,925] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:05,925] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:05,926] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:05,929] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,930] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,930] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,930] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,940] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,940] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,940] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,940] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:05,943] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,953] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:05,963] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:05,964] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:05,966] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:05,967] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:05,967] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:05,971] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:05,994] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,008] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:06,010] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:06,011] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,012] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,012] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,013] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,014] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,014] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,032] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:06,039] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,042] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,044] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:06,051] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:06,062] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:06,074] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:06,077] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,077] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,078] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,078] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,087] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,089] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,091] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,091] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,092] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,092] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,096] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,097] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,097] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,097] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,102] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,107] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,109] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,110] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:06,112] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,112] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,113] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,113] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,114] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,115] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,116] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,116] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,120] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,129] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,134] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,135] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,136] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,138] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,138] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,139] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,143] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,144] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,144] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,145] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,146] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,146] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,162] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,171] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,172] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,172] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,174] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,177] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,178] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,178] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,179] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,179] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,188] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,202] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,203] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,204] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,299] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,320] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,325] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,326] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,338] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:06,338] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:06,339] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,339] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,340] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,344] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:06,348] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,359] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,363] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,367] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:06,373] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,373] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,374] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,411] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:06,446] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,446] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,447] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,447] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,447] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,448] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,448] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,448] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,449] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,462] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,471] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,471] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,472] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,472] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,472] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,473] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,497] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,497] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,497] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,506] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:06,508] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:06,508] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:06,514] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,517] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,517] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,518] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,520] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,520] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,529] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:06,530] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:06,532] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:06,541] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,541] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,542] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,542] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,543] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,543] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,543] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,543] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,544] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,544] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,545] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,545] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,547] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:06,563] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:06,564] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,565] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,565] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,565] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,565] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,566] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:06,574] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:06,584] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:06,599] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:06,602] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:06,610] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,610] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,611] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,612] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,612] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,612] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,621] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:06,625] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,631] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,631] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,632] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:06,632] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,633] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,633] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,633] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,634] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,635] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,635] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,635] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,635] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,635] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,635] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,635] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,636] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,636] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,636] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,636] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,638] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:06,639] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:06,641] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:06,642] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:06,654] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,657] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,659] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:06,674] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:06,677] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,677] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,677] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:06,678] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,678] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,679] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,680] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:06,680] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,680] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,680] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,681] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,682] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,682] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,683] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,683] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,690] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:06,690] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:06,691] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:06,691] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:06,692] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,693] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,693] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,693] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,708] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,712] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:06,714] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,715] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,716] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:06,716] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,717] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,718] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,718] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,718] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,718] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,718] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,718] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,719] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,719] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,719] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,719] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,719] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,719] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,725] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,725] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,725] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,726] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,726] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,727] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,727] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,728] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,728] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,728] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,728] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,728] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,730] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,731] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:06,732] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,733] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,734] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,734] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,734] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,737] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,738] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,738] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,739] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,740] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:06,742] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,742] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,743] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,743] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,743] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,743] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,743] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,744] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,744] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,749] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,749] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:06,751] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,752] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,752] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,753] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,753] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,762] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,771] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:06,781] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,783] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:06,786] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,786] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,786] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,793] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:06,801] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,801] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,801] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,806] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,810] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:06,821] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,824] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,824] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,825] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,825] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,829] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:06,833] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:06,835] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,835] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,836] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,836] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,841] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,842] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,844] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,844] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,844] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,844] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,852] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,856] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:06,861] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:06,863] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,864] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,864] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,881] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:06,883] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,883] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,883] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,884] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,884] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,887] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:06,891] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,891] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,893] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,893] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,893] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,894] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,894] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,895] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,895] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,898] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,898] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,899] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,900] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,900] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,900] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,901] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,901] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,901] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,906] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,910] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:06,913] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,913] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,913] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,913] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,918] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,918] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:06,920] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,920] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:06,921] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,921] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,921] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,921] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:06,924] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,925] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,925] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,927] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:06,927] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:06,927] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:06,929] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,002] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,004] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,005] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,011] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,014] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,014] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,015] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,022] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,022] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,023] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,027] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,029] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,036] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,038] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,079] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,086] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,087] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,087] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,089] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,090] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,090] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,090] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,090] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,091] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,091] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,091] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,091] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,092] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,098] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,098] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,099] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,113] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,114] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,114] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,114] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,114] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,115] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,129] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,129] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,131] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,135] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,137] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,138] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,139] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,145] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,153] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,153] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,161] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,161] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,164] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,164] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,164] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,164] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,165] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,165] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,165] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,165] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,166] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,166] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,166] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,166] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,169] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:07,169] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:07,170] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:07,187] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,188] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,188] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,188] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,188] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,188] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,188] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,188] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,190] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,192] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:07,192] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:07,199] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:07,200] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,200] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:07,201] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:07,201] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,201] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,202] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,202] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,202] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,203] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,203] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,203] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,203] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,204] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,211] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,220] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,222] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,222] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,223] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:07,223] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,223] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:07,223] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,223] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,224] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:07,225] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,225] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,225] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,225] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,225] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,226] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,226] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:07,226] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:07,244] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,244] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,246] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:07,248] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:07,248] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:07,248] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,249] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:07,249] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:07,249] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,249] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,249] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,251] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,251] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,251] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,251] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,251] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,251] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,251] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,251] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,254] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,256] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,256] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,257] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,257] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,257] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,257] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,258] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,258] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,258] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,259] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,259] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,260] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,260] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,260] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,260] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,260] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,260] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,263] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,265] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,268] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,268] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,270] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:07,271] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:07,271] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,272] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,273] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,273] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,273] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,273] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,273] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,273] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,274] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,278] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,278] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,278] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,279] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,279] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,279] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,280] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,280] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,281] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,281] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,281] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,281] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,282] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,282] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,282] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,288] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,289] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,289] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,290] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,290] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,298] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,298] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,299] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,299] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,303] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:07,318] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,326] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,329] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,333] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:07,336] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,336] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,336] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,337] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,353] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,353] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,353] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,353] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,355] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,358] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:07,358] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:07,363] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,363] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,364] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,364] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,368] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:07,381] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:07,383] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,383] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,383] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,383] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,388] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:07,388] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,390] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,391] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,391] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,391] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,391] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,391] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,391] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,391] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,399] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:07,399] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,401] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,401] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,402] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,411] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,414] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:07,419] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,421] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,425] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:07,427] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,427] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,427] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,429] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,436] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,436] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,437] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,437] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,438] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:07,438] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,440] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,441] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,441] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,441] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,443] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,444] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,444] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,445] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,446] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,446] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,446] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,448] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,448] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:07,449] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,449] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,450] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,450] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,450] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,450] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,451] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,451] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,455] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,456] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,457] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,458] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,458] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,458] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,459] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,459] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,463] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,463] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,464] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,466] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,533] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,542] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,551] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,551] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,551] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,551] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,558] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,558] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,558] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,560] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,560] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,561] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,568] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,577] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,616] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,621] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,621] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,622] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,622] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,623] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,623] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,624] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,631] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,632] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,632] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,639] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,639] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,639] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,640] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,640] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,640] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,640] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,640] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,641] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,655] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,656] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,656] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,662] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,664] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,670] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,673] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,679] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,681] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,681] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,686] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,688] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,689] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,696] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,697] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,698] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,698] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,698] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,702] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:07,703] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,713] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,713] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,714] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,714] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,715] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,715] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,716] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,716] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,716] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,717] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,717] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,717] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,718] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:07,720] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:07,721] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:07,729] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,730] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,730] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,731] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,731] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,733] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:07,735] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:07,736] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,736] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,736] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,739] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,739] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,748] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,749] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:07,751] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:07,751] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,752] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,752] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,752] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:07,753] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,753] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,753] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,753] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,753] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,753] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,754] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,755] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,755] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,756] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,760] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:07,766] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:07,769] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,769] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,769] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,772] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,773] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,775] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,775] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:07,777] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:07,779] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:07,783] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:07,785] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,785] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,785] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,785] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,790] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,790] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,792] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,792] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,793] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,793] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,794] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,794] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,794] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:07,798] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:07,799] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:07,800] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,800] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,800] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,801] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,801] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,801] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,801] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:07,802] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,802] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,802] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,802] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,804] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,804] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,804] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,804] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,806] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,807] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,807] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,808] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,809] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,809] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,809] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,809] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,809] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,810] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,810] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,810] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,810] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,811] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,812] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,812] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,813] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,813] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,817] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,817] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,817] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,818] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,818] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:07,819] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,820] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,820] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,820] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,820] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,821] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,825] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,827] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,827] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,827] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,828] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,828] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,828] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,829] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,829] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,829] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,829] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,830] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,830] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,834] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:07,837] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,857] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,864] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:07,864] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,867] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,867] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,867] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,868] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,875] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:07,886] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,890] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:07,891] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,891] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,892] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,892] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,896] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:07,902] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,903] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,903] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,903] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,907] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_weight
[2023-10-06 23:34:07,913] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:07,915] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,915] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,915] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,915] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,920] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,921] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,923] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,923] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,923] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,923] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,926] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:07,929] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,929] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,929] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,932] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,938] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_weight (RETURN_VALUE)
[2023-10-06 23:34:07,940] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,941] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,941] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,949] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,953] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:07,961] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,964] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _scaled_in_proj_bias
[2023-10-06 23:34:07,968] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,968] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,969] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,975] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,975] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,975] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,975] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:07,975] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,976] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,976] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,976] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,976] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,977] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,977] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,978] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,978] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,978] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,978] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,982] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,982] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,983] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,983] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,984] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,986] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,986] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,986] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,986] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,987] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _scaled_in_proj_bias (RETURN_VALUE)
[2023-10-06 23:34:07,989] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,989] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,990] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,990] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,990] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:07,994] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,995] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:07,996] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,997] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,997] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:07,997] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,998] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:07,998] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:07,999] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:07,999] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:08,006] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:08,078] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:08,080] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:08,081] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:08,085] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:08,087] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:08,088] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:08,089] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:08,091] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:08,094] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:08,096] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:08,098] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:08,098] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:08,098] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:08,098] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:08,098] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:08,098] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:08,099] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:08,099] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:08,099] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:08,099] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:08,100] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:08,100] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:08,100] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:08,100] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:08,101] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:08,101] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:08,101] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:08,101] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:08,105] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:08,106] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:08,107] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:08,107] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:08,107] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:08,107] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:08,117] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:08,119] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:08,119] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:08,119] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:08,119] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:08,155] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:08,157] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:08,162] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:08,163] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:08,163] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:08,163] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:08,164] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:08,164] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:08,208] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:08,215] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:08,226] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:08,227] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:08,228] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:08,228] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:08,228] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:08,267] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:08,270] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:08,274] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:08,278] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:08,284] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:08,286] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:08,286] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:08,287] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:08,287] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:08,288] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:08,290] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:08,290] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:08,290] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:08,290] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I1006 23:34:21.300673 139932355139392 spec.py:333] Evaluating on the validation split.
I1006 23:34:21.302086 139932355139392 input_pipeline.py:20] Loading split = dev-clean
I1006 23:34:21.306231 139932355139392 input_pipeline.py:20] Loading split = dev-other
[2023-10-06 23:34:32,331] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,387] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,393] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,397] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,399] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,400] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,407] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,423] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,439] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,496] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,502] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,506] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,507] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,509] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,513] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,532] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,532] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,533] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,533] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,533] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:32,548] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:32,572] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:32,574] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,574] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,575] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,575] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:32,582] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,589] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,589] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,589] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,589] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:32,595] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,595] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,595] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,595] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:32,598] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,598] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,598] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,598] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:32,600] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,600] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,600] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,600] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,600] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,600] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:32,601] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,601] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:32,604] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,604] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:32,604] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,605] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,605] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:32,613] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:32,616] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:32,617] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:32,618] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:32,620] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:32,624] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,625] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,625] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,625] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:32,628] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:32,630] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,631] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,631] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,631] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:32,636] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:32,639] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,639] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,639] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,639] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:32,639] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,639] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:32,640] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:32,641] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:32,642] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,642] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,642] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,642] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:32,643] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,643] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,643] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:32,643] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,643] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:32,643] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,644] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,644] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,644] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:32,644] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:32,646] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,646] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,646] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,646] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:32,647] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,650] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,651] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,652] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,654] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,667] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:32,669] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,670] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,670] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,670] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:32,677] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:32,724] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:32,731] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,732] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,732] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,788] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:32,794] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:32,796] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:32,796] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,796] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,796] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:32,796] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,798] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:32,800] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:32,801] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,802] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,802] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,803] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,803] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,804] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,804] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,804] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,804] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,806] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,806] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,807] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,807] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,808] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,808] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,824] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:32,832] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:32,833] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:32,833] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:32,878] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,092] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,174] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,174] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,174] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,206] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,215] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,223] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,250] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,250] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,250] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,250] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,261] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,268] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,269] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,275] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,277] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:33,278] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:33,279] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,280] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,280] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,280] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,297] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,299] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,299] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,654] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:33,717] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,729] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,734] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,735] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,735] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,735] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,735] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,801] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,801] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,801] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,810] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:33,814] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,814] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,814] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,817] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,817] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,817] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,817] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,817] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,818] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,818] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,818] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,819] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,819] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,819] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,819] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,819] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,819] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,820] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,820] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,820] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,820] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,841] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,848] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,854] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,857] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,858] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,859] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,859] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,860] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,862] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,865] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,865] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,866] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,867] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,867] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,876] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,876] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,877] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,877] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,887] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,889] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,889] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,890] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,890] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,892] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,892] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,892] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,892] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,893] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,893] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,894] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,894] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,894] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,894] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,894] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,894] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,894] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,894] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,895] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,895] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,895] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,895] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,895] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,895] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,901] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,903] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,903] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:33,904] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,905] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,905] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:33,906] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,906] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:33,907] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,907] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,907] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,907] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,915] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:33,917] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:33,919] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:33,919] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:33,920] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,920] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,920] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:33,920] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:33,921] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,921] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,921] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:33,922] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,922] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,922] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:33,922] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:33,922] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,922] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,922] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:33,922] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:33,923] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,923] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,923] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:33,923] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,924] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,924] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,924] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:33,924] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,924] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,924] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,924] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,925] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,925] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,925] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:33,925] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:33,925] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,925] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,925] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:33,925] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:33,929] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:33,930] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:33,932] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:33,932] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:33,933] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:33,934] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:33,934] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,012] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,012] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,012] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,052] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,059] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,068] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,075] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,075] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,076] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,081] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,081] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,081] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,085] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,085] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,085] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,085] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,085] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,086] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,086] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,087] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,088] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,088] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,088] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,088] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,088] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,088] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,088] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,089] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,092] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,092] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,092] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,092] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,093] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,093] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,093] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,093] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,093] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,093] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,094] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,095] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,095] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,095] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,095] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,103] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,178] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,187] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,188] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,190] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,191] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,194] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,195] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,195] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,197] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,200] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,200] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,203] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,204] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,204] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,261] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,265] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,266] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,266] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,268] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,269] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,269] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,274] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,274] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,275] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,277] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,277] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,278] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,278] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,278] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,279] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,280] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,280] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,280] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,282] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,282] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,282] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,282] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,283] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,283] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,305] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,313] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,314] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,317] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,318] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,319] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,321] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,322] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,322] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,324] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,326] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,326] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,329] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,329] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,340] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,340] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,341] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,341] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,347] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,348] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,348] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,348] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,349] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,349] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,350] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,350] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,350] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,350] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,352] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,352] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,353] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,353] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,353] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,353] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,354] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,354] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,354] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,354] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,354] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,354] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,355] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,356] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,357] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,357] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,357] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,357] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,357] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,357] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,357] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,358] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,358] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,358] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,358] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,358] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,359] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,360] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,360] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,360] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,361] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,362] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,362] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,363] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,363] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,363] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,363] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,363] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,363] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,363] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,363] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,363] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,363] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,363] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,364] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,364] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,364] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,365] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,365] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,366] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,366] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,366] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,367] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,367] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,367] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,367] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,367] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,367] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,372] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,372] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,372] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,375] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,375] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,375] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,384] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,461] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,461] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,461] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,500] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,507] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,521] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,524] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,524] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,526] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,528] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,528] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,529] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,529] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,531] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,531] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,531] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,532] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,532] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,532] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,533] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,533] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,533] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,534] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,535] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,535] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,535] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,536] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,536] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,537] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,537] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,541] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,541] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,543] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,543] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,544] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,544] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,544] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,544] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,544] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,544] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,548] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,549] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,549] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,553] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,633] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,637] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,638] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,642] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,646] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,647] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,647] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,649] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,649] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,654] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,656] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,658] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,659] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,663] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,715] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,721] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,721] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,721] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,722] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,722] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,723] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,725] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,725] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,726] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,726] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,726] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,726] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,736] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,736] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,736] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,736] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,736] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,737] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,737] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,737] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,737] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,742] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,742] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,743] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,761] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,766] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,766] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,768] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,773] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,774] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,776] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,777] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,778] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,782] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,783] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,785] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,785] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,789] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,795] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,795] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,795] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,795] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,800] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,800] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,801] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,801] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,801] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,801] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,801] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,801] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,801] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,803] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,804] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,804] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,804] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,804] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,807] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,807] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,809] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,809] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,810] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,810] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,810] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,810] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,810] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,810] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,810] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,810] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,810] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,810] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,811] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,811] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,812] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,813] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,813] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,813] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,813] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,813] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,813] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,813] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,813] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,816] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,816] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,816] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,817] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,817] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,817] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,819] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,819] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,819] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,819] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,819] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,819] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,819] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,820] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,821] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,821] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,822] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,822] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,822] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,822] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,823] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,823] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,823] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,823] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,823] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,824] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,826] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,826] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,826] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,826] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,828] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,828] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,831] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,833] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,835] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,837] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,916] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,916] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,916] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,955] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,960] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,963] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:34,967] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,967] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,968] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,970] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,976] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,977] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,977] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,978] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,981] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,984] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,986] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,986] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,987] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,987] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,988] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,988] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,991] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,991] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,992] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,992] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,992] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,992] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:34,992] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:34,993] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:34,994] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:34,998] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:34,999] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:34,999] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,000] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:35,000] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,001] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,001] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,001] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,001] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,002] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,002] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,003] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,009] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:35,070] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,080] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,083] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,091] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,093] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,099] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,101] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,103] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,110] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,112] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,113] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,115] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,122] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,125] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,158] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,159] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,159] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,161] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:35,168] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,168] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,168] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,172] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,172] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,173] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,180] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,180] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,181] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,189] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,189] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,189] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,190] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,191] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,191] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,198] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,200] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,200] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,201] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,203] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,204] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,204] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,206] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,213] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,220] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,221] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,228] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,229] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,231] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,233] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,233] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,233] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,233] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,237] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,238] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,239] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:35,241] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:35,242] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,242] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,242] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,242] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,242] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,244] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,247] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,248] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,248] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,248] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,249] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,251] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:35,252] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,254] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:35,256] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,256] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,256] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:35,256] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,256] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,257] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,257] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,258] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,258] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,262] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:35,264] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:35,265] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,265] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,265] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,265] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,265] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,265] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,265] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,266] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,266] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,266] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,266] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,266] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,266] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:35,271] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:35,272] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:35,273] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:35,273] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,273] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:35,274] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,274] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,274] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:35,274] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,274] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,274] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,274] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,274] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,274] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,277] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,277] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,278] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,278] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,279] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,280] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,280] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,280] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,280] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,282] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:35,282] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:35,284] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:35,286] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:35,286] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:35,287] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,287] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,288] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,288] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:35,288] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,289] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,289] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,290] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,290] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,291] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:35,293] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,293] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,293] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,293] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,296] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:35,298] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:35,411] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:35,418] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,419] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,419] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,430] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:35,430] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:35,432] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:35,436] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,436] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:35,437] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,437] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,437] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,437] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,438] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,439] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,439] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,440] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,444] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,444] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,445] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,456] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:35,460] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:35,464] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,464] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,464] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,467] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,467] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,468] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,528] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,536] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,538] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,542] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,546] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,547] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:35,548] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,548] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,549] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,549] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,549] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,549] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,555] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,556] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,557] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:35,558] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,558] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,559] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,559] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,561] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:35,562] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,562] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,562] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,563] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,563] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,568] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:35,569] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,569] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,570] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,570] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,574] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:35,574] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,575] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,575] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,576] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,576] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,579] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,582] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,587] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:35,593] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:35,595] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,595] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,595] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,595] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:35,598] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:35,600] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:35,600] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:35,600] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:35,600] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I1006 23:34:35.790326 139932355139392 spec.py:349] Evaluating on the test split.
I1006 23:34:35.791640 139932355139392 input_pipeline.py:20] Loading split = test-clean
[2023-10-06 23:34:42,061] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,166] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,228] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,242] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,242] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,254] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,255] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,255] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,255] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,256] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,268] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:42,290] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:42,292] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,292] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,292] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,292] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,300] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,300] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,301] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,311] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,334] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,345] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,348] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,359] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,404] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,405] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,419] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,424] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,425] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,425] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,425] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,433] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,433] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,434] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,434] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,438] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:42,438] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,439] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,439] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,439] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,447] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:42,447] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:42,448] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,448] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,449] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,449] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,454] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:42,455] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,455] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,455] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,461] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:42,464] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,464] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,464] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:42,464] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,464] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,469] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:42,472] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,472] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,472] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,472] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,473] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,477] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:42,479] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,479] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,479] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,480] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,480] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,487] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,487] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:42,489] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,489] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,490] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,490] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,495] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,495] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,495] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,495] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,496] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,496] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,496] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,496] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,497] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,509] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:42,511] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,512] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,512] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,512] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,514] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:42,530] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:42,531] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:42,533] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,534] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,534] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,534] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,534] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,536] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:42,538] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,539] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,539] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,539] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,541] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,546] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,551] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:42,553] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,553] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,554] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,554] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,561] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:42,621] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:42,624] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:42,625] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:42,628] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,628] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,629] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,631] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,632] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,632] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,632] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,632] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:42,632] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,633] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,639] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,639] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,640] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,675] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:42,681] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,682] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,682] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,688] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:42,695] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,695] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,695] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,701] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,702] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,703] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:42,704] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,707] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,710] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:42,711] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:42,711] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:42,751] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,765] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:42,781] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,188] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,268] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,269] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,269] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,307] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,314] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,342] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,342] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,342] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,342] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,352] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,367] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:43,369] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:43,370] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,370] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,370] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,370] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,378] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:43,528] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:43,535] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,535] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,535] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,555] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,561] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,562] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,562] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,562] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,563] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,563] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,638] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,639] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,639] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,639] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,642] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,642] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,643] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,643] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,643] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,643] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,643] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,643] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,644] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,644] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,644] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,644] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,646] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,646] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,647] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,647] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,647] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,647] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,648] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,680] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,682] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,682] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,683] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,684] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,687] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,687] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,688] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,690] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,690] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,691] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,692] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,694] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,695] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,715] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,715] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,715] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,715] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,716] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,717] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,717] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,717] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,717] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,717] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,717] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,718] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,718] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,718] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,719] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,719] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,720] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,721] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,721] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,721] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,722] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,722] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,722] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,722] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,723] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,723] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,723] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,723] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,726] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,727] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,727] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,727] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,728] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,728] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,730] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,732] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,733] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,734] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,742] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:43,743] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:43,743] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:43,744] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:43,744] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,745] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,745] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:43,745] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:43,745] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,745] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,745] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:43,746] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,746] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,746] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,746] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:43,746] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,746] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,747] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,747] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,747] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,747] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,748] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,748] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:43,748] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:43,748] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,748] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,749] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:43,749] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:43,750] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:43,750] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,750] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,751] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,751] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,751] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:43,751] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,751] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,751] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,751] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,752] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,752] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,752] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,752] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,753] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:43,754] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:43,755] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:43,756] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:43,758] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:43,760] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:43,760] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:43,767] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,775] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:43,802] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,802] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,803] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,803] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,809] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:43,810] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:43,812] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,812] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,812] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,812] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:43,820] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:43,903] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:43,905] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:43,906] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:43,907] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:43,908] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:43,909] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:43,910] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,910] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,910] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,911] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:43,912] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,912] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,912] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,913] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,913] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,913] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,914] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,915] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,915] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,915] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,915] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,916] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,916] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,916] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,917] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,918] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,919] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,920] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:43,975] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:43,982] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:43,982] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:43,983] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,011] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,015] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,016] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,016] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,017] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,018] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,020] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,023] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,024] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,025] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,025] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,026] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,027] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,033] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,090] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,097] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,097] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,097] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,099] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,100] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,100] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,101] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,102] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,102] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,103] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,104] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,104] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,104] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,107] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,107] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,107] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,109] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,109] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,110] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,110] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,111] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,111] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,136] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,139] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,141] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,143] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,144] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,145] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,147] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,148] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,150] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,151] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,151] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,153] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,158] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,159] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,170] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,171] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,171] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,171] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,174] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,174] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,174] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,174] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,176] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,176] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,176] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,176] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,177] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,177] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,178] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,178] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,178] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,179] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,179] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,179] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,179] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,180] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,180] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,180] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,180] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,180] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,180] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,180] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,181] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,181] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,182] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,182] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,183] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,183] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,183] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,184] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,184] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,185] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,185] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,185] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,185] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,185] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,186] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,186] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,186] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,187] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,187] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,187] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,187] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,187] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,188] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,188] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,188] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,188] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,188] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,188] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,189] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,189] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,189] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,189] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,190] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,190] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,192] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,193] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,193] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,194] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,195] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,196] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,196] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,196] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,197] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,197] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,197] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,197] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,197] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,197] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,197] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,198] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,205] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,206] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,217] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,225] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,251] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,252] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,252] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,252] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,258] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,259] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,261] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,261] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,261] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,261] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,269] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,334] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,341] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,341] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,341] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,342] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,342] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,348] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,348] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,348] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,348] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,349] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,349] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,349] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,350] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,355] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,355] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,356] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,356] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,356] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,357] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,357] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,363] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,364] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,364] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,366] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,373] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,374] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,374] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,430] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,437] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,438] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,438] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,443] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,451] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,451] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,453] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,459] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,460] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,460] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,461] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,468] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,471] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,474] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,483] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,485] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,495] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,530] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,530] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,531] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,538] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,538] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,538] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,538] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,539] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,539] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,542] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,548] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,548] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,549] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,551] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,551] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,552] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,552] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,561] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,562] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,562] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,571] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,574] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,574] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,575] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,578] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,578] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,578] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,585] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,585] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,588] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,592] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,596] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,600] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,600] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,606] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,606] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,606] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,606] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,608] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,612] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,612] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,612] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,612] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,612] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,612] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,612] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,612] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,613] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,614] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,614] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,615] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,616] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,616] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,616] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,618] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,618] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,620] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,620] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,621] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,621] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,621] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,621] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,621] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,622] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,622] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,622] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,622] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,623] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,623] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,623] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,623] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,625] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,627] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,627] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,628] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,628] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,629] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,629] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,630] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,630] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,630] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,630] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,631] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,632] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,633] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,633] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,633] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,634] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,635] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,635] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,635] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,635] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,635] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,636] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,637] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,637] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,637] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,641] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,641] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,643] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,644] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,644] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,645] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,645] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,645] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,650] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,650] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,650] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,650] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,653] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,656] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,658] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,659] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,660] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,660] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,660] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,668] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,669] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,676] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,703] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,703] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,704] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,704] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,710] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,712] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,713] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,713] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,713] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,713] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,721] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:44,776] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,782] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,783] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,783] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,788] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,790] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,793] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,795] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,796] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,796] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,797] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,797] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,798] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,800] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,800] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,800] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,811] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,813] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,818] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,818] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,818] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,819] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,820] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,820] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,823] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,829] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,829] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,830] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,874] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:44,880] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,881] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,881] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,887] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,897] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,901] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,904] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,905] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,910] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,913] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,915] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,923] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,924] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,933] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,933] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,933] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,942] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,974] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,974] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,974] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,984] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:44,987] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,988] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,988] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,991] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,991] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:44,991] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:44,991] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,991] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:44,991] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:44,992] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,002] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:45,003] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,003] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,003] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,004] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,008] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,009] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,009] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,009] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,009] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,009] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,013] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,020] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,020] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:45,020] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,021] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,027] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,030] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,031] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,034] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:45,037] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:45,038] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:45,046] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,047] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,047] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,047] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,048] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,048] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,053] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:45,055] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:45,055] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:45,056] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:45,056] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,056] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,056] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,056] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,061] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,061] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,061] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,062] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,062] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,064] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,064] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,064] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,064] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,065] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:45,065] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,065] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,066] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,066] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,068] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:45,068] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:45,069] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:45,070] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:45,071] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,071] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,071] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,071] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,072] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:45,072] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:45,073] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,073] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,073] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,073] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,074] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:45,075] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,075] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,075] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,075] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,079] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:45,081] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:45,082] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,082] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,082] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,082] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,083] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,083] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,083] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,083] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,084] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:45,088] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:45,089] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:45,090] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:45,091] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:45,091] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,091] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,091] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,091] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,092] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,092] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,092] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,092] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,096] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,096] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,097] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,097] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,099] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:45,100] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:45,103] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:45,105] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:45,106] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,106] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,107] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,107] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,115] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-10-06 23:34:45,224] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:45,229] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:45,232] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,232] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,233] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,234] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:45,235] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,236] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,236] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,241] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,241] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,242] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,246] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:45,249] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:45,253] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,254] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,254] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,255] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:45,255] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,256] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,256] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,261] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,262] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,262] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,266] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-10-06 23:34:45,273] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,273] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,273] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,337] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,342] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,343] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,344] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:45,350] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:45,350] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:45,355] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:45,356] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,356] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,356] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,356] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,359] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,360] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:45,361] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:45,362] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,362] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,362] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,362] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,362] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,363] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,363] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,363] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,363] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,366] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,367] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:45,370] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:45,373] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:45,377] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,377] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:45,379] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,379] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,379] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,379] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,381] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:45,382] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,383] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,383] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,383] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,384] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:45,385] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-10-06 23:34:45,386] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,386] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,386] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,386] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-10-06 23:34:45,396] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-10-06 23:34:45,397] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-10-06 23:34:45,397] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-10-06 23:34:45,398] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-10-06 23:34:45,398] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I1006 23:34:45.575862 139932355139392 submission_runner.py:384] Time since start: 56.85s, 	Step: 1, 	{'train/ctc_loss': 31.847735355843593, 'train/wer': 2.028223788699606, 'validation/ctc_loss': 30.695358021900745, 'validation/wer': 2.0094336889875923, 'validation/num_examples': 5348, 'test/ctc_loss': 30.763013742822118, 'test/wer': 2.071435825564154, 'test/num_examples': 2472, 'score': 12.51418662071228, 'total_duration': 56.85322308540344, 'accumulated_submission_time': 12.51418662071228, 'accumulated_eval_time': 43.7703800201416, 'accumulated_logging_time': 0}
I1006 23:34:45.599966 139901538395904 logging_writer.py:48] [1] accumulated_eval_time=43.770380, accumulated_logging_time=0, accumulated_submission_time=12.514187, global_step=1, preemption_count=0, score=12.514187, test/ctc_loss=30.763014, test/num_examples=2472, test/wer=2.071436, total_duration=56.853223, train/ctc_loss=31.847735, train/wer=2.028224, validation/ctc_loss=30.695358, validation/num_examples=5348, validation/wer=2.009434
I1006 23:34:46.289772 139932355139392 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I1006 23:34:46.292109 139812948772672 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I1006 23:34:46.292134 139902833473344 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I1006 23:34:46.292229 139969316050752 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I1006 23:34:46.292711 140384386467648 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I1006 23:34:46.292780 140454947399488 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I1006 23:34:46.292337 140344114898752 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I1006 23:34:46.293806 139943469840192 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I1006 23:34:48.331619 139901530003200 logging_writer.py:48] [1] global_step=1, grad_norm=62.294575, loss=32.009811
I1006 23:34:48.335213 139932355139392 pytorch_submission_base.py:86] 1) loss = 32.010, grad_norm = 62.295
I1006 23:34:50.305275 139901538395904 logging_writer.py:48] [2] global_step=2, grad_norm=76.305885, loss=32.302700
I1006 23:34:50.308694 139932355139392 pytorch_submission_base.py:86] 2) loss = 32.303, grad_norm = 76.306
I1006 23:34:51.981745 139901530003200 logging_writer.py:48] [3] global_step=3, grad_norm=102.808235, loss=31.644979
I1006 23:34:51.985190 139932355139392 pytorch_submission_base.py:86] 3) loss = 31.645, grad_norm = 102.808
I1006 23:34:53.757230 139901538395904 logging_writer.py:48] [4] global_step=4, grad_norm=135.213272, loss=29.985418
I1006 23:34:53.761741 139932355139392 pytorch_submission_base.py:86] 4) loss = 29.985, grad_norm = 135.213
I1006 23:34:55.559224 139901530003200 logging_writer.py:48] [5] global_step=5, grad_norm=156.139938, loss=28.132219
I1006 23:34:55.562969 139932355139392 pytorch_submission_base.py:86] 5) loss = 28.132, grad_norm = 156.140
I1006 23:34:57.259399 139901538395904 logging_writer.py:48] [6] global_step=6, grad_norm=161.165298, loss=25.436899
I1006 23:34:57.262855 139932355139392 pytorch_submission_base.py:86] 6) loss = 25.437, grad_norm = 161.165
I1006 23:34:58.978097 139901530003200 logging_writer.py:48] [7] global_step=7, grad_norm=152.121780, loss=21.523010
I1006 23:34:58.981934 139932355139392 pytorch_submission_base.py:86] 7) loss = 21.523, grad_norm = 152.122
I1006 23:35:00.757064 139901538395904 logging_writer.py:48] [8] global_step=8, grad_norm=146.158524, loss=18.012966
I1006 23:35:00.761117 139932355139392 pytorch_submission_base.py:86] 8) loss = 18.013, grad_norm = 146.159
I1006 23:35:02.566391 139901530003200 logging_writer.py:48] [9] global_step=9, grad_norm=125.265205, loss=14.193632
I1006 23:35:02.569943 139932355139392 pytorch_submission_base.py:86] 9) loss = 14.194, grad_norm = 125.265
I1006 23:35:04.276126 139901538395904 logging_writer.py:48] [10] global_step=10, grad_norm=93.881409, loss=10.884337
I1006 23:35:04.279420 139932355139392 pytorch_submission_base.py:86] 10) loss = 10.884, grad_norm = 93.881
I1006 23:35:05.969810 139901530003200 logging_writer.py:48] [11] global_step=11, grad_norm=52.937550, loss=8.535497
I1006 23:35:05.973761 139932355139392 pytorch_submission_base.py:86] 11) loss = 8.535, grad_norm = 52.938
I1006 23:35:07.757853 139901538395904 logging_writer.py:48] [12] global_step=12, grad_norm=18.215315, loss=7.484205
I1006 23:35:07.761278 139932355139392 pytorch_submission_base.py:86] 12) loss = 7.484, grad_norm = 18.215
I1006 23:35:09.504718 139901530003200 logging_writer.py:48] [13] global_step=13, grad_norm=5.177069, loss=7.300622
I1006 23:35:09.508021 139932355139392 pytorch_submission_base.py:86] 13) loss = 7.301, grad_norm = 5.177
I1006 23:35:11.266817 139901538395904 logging_writer.py:48] [14] global_step=14, grad_norm=14.287284, loss=7.529753
I1006 23:35:11.270183 139932355139392 pytorch_submission_base.py:86] 14) loss = 7.530, grad_norm = 14.287
I1006 23:35:12.994455 139901530003200 logging_writer.py:48] [15] global_step=15, grad_norm=18.859722, loss=7.849737
I1006 23:35:12.997902 139932355139392 pytorch_submission_base.py:86] 15) loss = 7.850, grad_norm = 18.860
I1006 23:35:14.681249 139901538395904 logging_writer.py:48] [16] global_step=16, grad_norm=20.652058, loss=8.080979
I1006 23:35:14.684659 139932355139392 pytorch_submission_base.py:86] 16) loss = 8.081, grad_norm = 20.652
I1006 23:35:16.358400 139901530003200 logging_writer.py:48] [17] global_step=17, grad_norm=21.539570, loss=8.217575
I1006 23:35:16.361807 139932355139392 pytorch_submission_base.py:86] 17) loss = 8.218, grad_norm = 21.540
I1006 23:35:18.043968 139901538395904 logging_writer.py:48] [18] global_step=18, grad_norm=21.886080, loss=8.232048
I1006 23:35:18.047303 139932355139392 pytorch_submission_base.py:86] 18) loss = 8.232, grad_norm = 21.886
I1006 23:35:19.835641 139901530003200 logging_writer.py:48] [19] global_step=19, grad_norm=21.787880, loss=8.142977
I1006 23:35:19.839114 139932355139392 pytorch_submission_base.py:86] 19) loss = 8.143, grad_norm = 21.788
I1006 23:35:21.554531 139901538395904 logging_writer.py:48] [20] global_step=20, grad_norm=21.110613, loss=7.957526
I1006 23:35:21.557901 139932355139392 pytorch_submission_base.py:86] 20) loss = 7.958, grad_norm = 21.111
I1006 23:35:23.331045 139901530003200 logging_writer.py:48] [21] global_step=21, grad_norm=19.023895, loss=7.680532
I1006 23:35:23.334769 139932355139392 pytorch_submission_base.py:86] 21) loss = 7.681, grad_norm = 19.024
I1006 23:35:25.045485 139901538395904 logging_writer.py:48] [22] global_step=22, grad_norm=14.363895, loss=7.354544
I1006 23:35:25.048821 139932355139392 pytorch_submission_base.py:86] 22) loss = 7.355, grad_norm = 14.364
I1006 23:35:26.820195 139901530003200 logging_writer.py:48] [23] global_step=23, grad_norm=6.395205, loss=7.126031
I1006 23:35:26.823830 139932355139392 pytorch_submission_base.py:86] 23) loss = 7.126, grad_norm = 6.395
I1006 23:35:28.643586 139901538395904 logging_writer.py:48] [24] global_step=24, grad_norm=9.202478, loss=7.122190
I1006 23:35:28.647024 139932355139392 pytorch_submission_base.py:86] 24) loss = 7.122, grad_norm = 9.202
I1006 23:35:30.381779 139901530003200 logging_writer.py:48] [25] global_step=25, grad_norm=23.121235, loss=7.315766
I1006 23:35:30.385280 139932355139392 pytorch_submission_base.py:86] 25) loss = 7.316, grad_norm = 23.121
I1006 23:35:32.201033 139901538395904 logging_writer.py:48] [26] global_step=26, grad_norm=25.265013, loss=7.341165
I1006 23:35:32.204745 139932355139392 pytorch_submission_base.py:86] 26) loss = 7.341, grad_norm = 25.265
I1006 23:35:33.859617 139901530003200 logging_writer.py:48] [27] global_step=27, grad_norm=17.159424, loss=7.138794
I1006 23:35:33.862817 139932355139392 pytorch_submission_base.py:86] 27) loss = 7.139, grad_norm = 17.159
I1006 23:35:35.622187 139901538395904 logging_writer.py:48] [28] global_step=28, grad_norm=5.587889, loss=6.935424
I1006 23:35:35.625819 139932355139392 pytorch_submission_base.py:86] 28) loss = 6.935, grad_norm = 5.588
I1006 23:35:37.444986 139901530003200 logging_writer.py:48] [29] global_step=29, grad_norm=4.642429, loss=6.906538
I1006 23:35:37.448205 139932355139392 pytorch_submission_base.py:86] 29) loss = 6.907, grad_norm = 4.642
I1006 23:35:39.210824 139901538395904 logging_writer.py:48] [30] global_step=30, grad_norm=9.028913, loss=6.928116
I1006 23:35:39.214331 139932355139392 pytorch_submission_base.py:86] 30) loss = 6.928, grad_norm = 9.029
I1006 23:35:41.015038 139901530003200 logging_writer.py:48] [31] global_step=31, grad_norm=10.491348, loss=6.915909
I1006 23:35:41.018572 139932355139392 pytorch_submission_base.py:86] 31) loss = 6.916, grad_norm = 10.491
I1006 23:35:42.722528 139901538395904 logging_writer.py:48] [32] global_step=32, grad_norm=9.673998, loss=6.863686
I1006 23:35:42.726142 139932355139392 pytorch_submission_base.py:86] 32) loss = 6.864, grad_norm = 9.674
I1006 23:35:44.495877 139901530003200 logging_writer.py:48] [33] global_step=33, grad_norm=6.122605, loss=6.759397
I1006 23:35:44.499220 139932355139392 pytorch_submission_base.py:86] 33) loss = 6.759, grad_norm = 6.123
I1006 23:35:46.187537 139901538395904 logging_writer.py:48] [34] global_step=34, grad_norm=1.984391, loss=6.662883
I1006 23:35:46.191383 139932355139392 pytorch_submission_base.py:86] 34) loss = 6.663, grad_norm = 1.984
I1006 23:35:47.891324 139901530003200 logging_writer.py:48] [35] global_step=35, grad_norm=7.413379, loss=6.667859
I1006 23:35:47.895131 139932355139392 pytorch_submission_base.py:86] 35) loss = 6.668, grad_norm = 7.413
I1006 23:35:49.503671 139901538395904 logging_writer.py:48] [36] global_step=36, grad_norm=10.591225, loss=6.673839
I1006 23:35:49.507208 139932355139392 pytorch_submission_base.py:86] 36) loss = 6.674, grad_norm = 10.591
I1006 23:35:51.239362 139901530003200 logging_writer.py:48] [37] global_step=37, grad_norm=7.248363, loss=6.573509
I1006 23:35:51.242915 139932355139392 pytorch_submission_base.py:86] 37) loss = 6.574, grad_norm = 7.248
I1006 23:35:52.965884 139901538395904 logging_writer.py:48] [38] global_step=38, grad_norm=2.344337, loss=6.535532
I1006 23:35:52.969620 139932355139392 pytorch_submission_base.py:86] 38) loss = 6.536, grad_norm = 2.344
I1006 23:35:54.600114 139901530003200 logging_writer.py:48] [39] global_step=39, grad_norm=3.484838, loss=6.501410
I1006 23:35:54.603425 139932355139392 pytorch_submission_base.py:86] 39) loss = 6.501, grad_norm = 3.485
I1006 23:35:56.411034 139901538395904 logging_writer.py:48] [40] global_step=40, grad_norm=5.322948, loss=6.476949
I1006 23:35:56.415181 139932355139392 pytorch_submission_base.py:86] 40) loss = 6.477, grad_norm = 5.323
I1006 23:35:58.137156 139901530003200 logging_writer.py:48] [41] global_step=41, grad_norm=4.167352, loss=6.419075
I1006 23:35:58.140991 139932355139392 pytorch_submission_base.py:86] 41) loss = 6.419, grad_norm = 4.167
I1006 23:35:59.950092 139901538395904 logging_writer.py:48] [42] global_step=42, grad_norm=1.472924, loss=6.381290
I1006 23:35:59.953719 139932355139392 pytorch_submission_base.py:86] 42) loss = 6.381, grad_norm = 1.473
I1006 23:36:01.738855 139901530003200 logging_writer.py:48] [43] global_step=43, grad_norm=5.527333, loss=6.366190
I1006 23:36:01.742405 139932355139392 pytorch_submission_base.py:86] 43) loss = 6.366, grad_norm = 5.527
I1006 23:36:03.429829 139901538395904 logging_writer.py:48] [44] global_step=44, grad_norm=4.880441, loss=6.331873
I1006 23:36:03.434317 139932355139392 pytorch_submission_base.py:86] 44) loss = 6.332, grad_norm = 4.880
I1006 23:36:05.175002 139901530003200 logging_writer.py:48] [45] global_step=45, grad_norm=1.092548, loss=6.278520
I1006 23:36:05.179523 139932355139392 pytorch_submission_base.py:86] 45) loss = 6.279, grad_norm = 1.093
I1006 23:36:07.007286 139901538395904 logging_writer.py:48] [46] global_step=46, grad_norm=3.740947, loss=6.249911
I1006 23:36:07.011585 139932355139392 pytorch_submission_base.py:86] 46) loss = 6.250, grad_norm = 3.741
I1006 23:36:08.759799 139901530003200 logging_writer.py:48] [47] global_step=47, grad_norm=2.227177, loss=6.226002
I1006 23:36:08.764068 139932355139392 pytorch_submission_base.py:86] 47) loss = 6.226, grad_norm = 2.227
I1006 23:36:10.470067 139901538395904 logging_writer.py:48] [48] global_step=48, grad_norm=3.080952, loss=6.205006
I1006 23:36:10.474485 139932355139392 pytorch_submission_base.py:86] 48) loss = 6.205, grad_norm = 3.081
I1006 23:36:12.273367 139901530003200 logging_writer.py:48] [49] global_step=49, grad_norm=3.405170, loss=6.177872
I1006 23:36:12.277987 139932355139392 pytorch_submission_base.py:86] 49) loss = 6.178, grad_norm = 3.405
I1006 23:36:14.071557 139901538395904 logging_writer.py:48] [50] global_step=50, grad_norm=1.476700, loss=6.146656
I1006 23:36:14.075676 139932355139392 pytorch_submission_base.py:86] 50) loss = 6.147, grad_norm = 1.477
I1006 23:36:15.852869 139901530003200 logging_writer.py:48] [51] global_step=51, grad_norm=2.718705, loss=6.119340
I1006 23:36:15.857372 139932355139392 pytorch_submission_base.py:86] 51) loss = 6.119, grad_norm = 2.719
I1006 23:36:17.672008 139901538395904 logging_writer.py:48] [52] global_step=52, grad_norm=1.163975, loss=6.096659
I1006 23:36:17.676320 139932355139392 pytorch_submission_base.py:86] 52) loss = 6.097, grad_norm = 1.164
I1006 23:36:19.558358 139901530003200 logging_writer.py:48] [53] global_step=53, grad_norm=3.699561, loss=6.091712
I1006 23:36:19.562100 139932355139392 pytorch_submission_base.py:86] 53) loss = 6.092, grad_norm = 3.700
I1006 23:36:21.406364 139901538395904 logging_writer.py:48] [54] global_step=54, grad_norm=0.995554, loss=6.069939
I1006 23:36:21.410611 139932355139392 pytorch_submission_base.py:86] 54) loss = 6.070, grad_norm = 0.996
I1006 23:36:23.130250 139901530003200 logging_writer.py:48] [55] global_step=55, grad_norm=2.937669, loss=6.054358
I1006 23:36:23.134371 139932355139392 pytorch_submission_base.py:86] 55) loss = 6.054, grad_norm = 2.938
I1006 23:36:24.925954 139901538395904 logging_writer.py:48] [56] global_step=56, grad_norm=1.372160, loss=5.998379
I1006 23:36:24.929951 139932355139392 pytorch_submission_base.py:86] 56) loss = 5.998, grad_norm = 1.372
I1006 23:36:26.720968 139901530003200 logging_writer.py:48] [57] global_step=57, grad_norm=3.428775, loss=6.008177
I1006 23:36:26.724298 139932355139392 pytorch_submission_base.py:86] 57) loss = 6.008, grad_norm = 3.429
I1006 23:36:28.581218 139901538395904 logging_writer.py:48] [58] global_step=58, grad_norm=3.863996, loss=5.991321
I1006 23:36:28.584573 139932355139392 pytorch_submission_base.py:86] 58) loss = 5.991, grad_norm = 3.864
I1006 23:36:30.318638 139901530003200 logging_writer.py:48] [59] global_step=59, grad_norm=0.797376, loss=5.970920
I1006 23:36:30.322101 139932355139392 pytorch_submission_base.py:86] 59) loss = 5.971, grad_norm = 0.797
I1006 23:36:32.072934 139901538395904 logging_writer.py:48] [60] global_step=60, grad_norm=3.256837, loss=5.966606
I1006 23:36:32.076591 139932355139392 pytorch_submission_base.py:86] 60) loss = 5.967, grad_norm = 3.257
I1006 23:36:33.762218 139901530003200 logging_writer.py:48] [61] global_step=61, grad_norm=3.652840, loss=5.940813
I1006 23:36:33.766140 139932355139392 pytorch_submission_base.py:86] 61) loss = 5.941, grad_norm = 3.653
I1006 23:36:35.493523 139901538395904 logging_writer.py:48] [62] global_step=62, grad_norm=1.816385, loss=5.923915
I1006 23:36:35.496922 139932355139392 pytorch_submission_base.py:86] 62) loss = 5.924, grad_norm = 1.816
I1006 23:36:37.269299 139901530003200 logging_writer.py:48] [63] global_step=63, grad_norm=1.378711, loss=5.903968
I1006 23:36:37.273257 139932355139392 pytorch_submission_base.py:86] 63) loss = 5.904, grad_norm = 1.379
I1006 23:36:39.043513 139901538395904 logging_writer.py:48] [64] global_step=64, grad_norm=3.311720, loss=5.896689
I1006 23:36:39.047010 139932355139392 pytorch_submission_base.py:86] 64) loss = 5.897, grad_norm = 3.312
I1006 23:36:40.825181 139901530003200 logging_writer.py:48] [65] global_step=65, grad_norm=4.434610, loss=5.926812
I1006 23:36:40.829050 139932355139392 pytorch_submission_base.py:86] 65) loss = 5.927, grad_norm = 4.435
I1006 23:36:42.642841 139901538395904 logging_writer.py:48] [66] global_step=66, grad_norm=4.054742, loss=5.886142
I1006 23:36:42.646200 139932355139392 pytorch_submission_base.py:86] 66) loss = 5.886, grad_norm = 4.055
I1006 23:36:44.438951 139901530003200 logging_writer.py:48] [67] global_step=67, grad_norm=1.973136, loss=5.859558
I1006 23:36:44.442533 139932355139392 pytorch_submission_base.py:86] 67) loss = 5.860, grad_norm = 1.973
I1006 23:36:46.213053 139901538395904 logging_writer.py:48] [68] global_step=68, grad_norm=1.128150, loss=5.868266
I1006 23:36:46.216427 139932355139392 pytorch_submission_base.py:86] 68) loss = 5.868, grad_norm = 1.128
I1006 23:36:48.002297 139901530003200 logging_writer.py:48] [69] global_step=69, grad_norm=2.326995, loss=5.886679
I1006 23:36:48.006657 139932355139392 pytorch_submission_base.py:86] 69) loss = 5.887, grad_norm = 2.327
I1006 23:36:49.720079 139901538395904 logging_writer.py:48] [70] global_step=70, grad_norm=2.269683, loss=5.853627
I1006 23:36:49.724282 139932355139392 pytorch_submission_base.py:86] 70) loss = 5.854, grad_norm = 2.270
I1006 23:36:51.546000 139901530003200 logging_writer.py:48] [71] global_step=71, grad_norm=1.771405, loss=5.850629
I1006 23:36:51.550266 139932355139392 pytorch_submission_base.py:86] 71) loss = 5.851, grad_norm = 1.771
I1006 23:36:53.378313 139901538395904 logging_writer.py:48] [72] global_step=72, grad_norm=1.189912, loss=5.825419
I1006 23:36:53.382780 139932355139392 pytorch_submission_base.py:86] 72) loss = 5.825, grad_norm = 1.190
I1006 23:36:55.181224 139901530003200 logging_writer.py:48] [73] global_step=73, grad_norm=0.421922, loss=5.829599
I1006 23:36:55.184700 139932355139392 pytorch_submission_base.py:86] 73) loss = 5.830, grad_norm = 0.422
I1006 23:36:56.936948 139901538395904 logging_writer.py:48] [74] global_step=74, grad_norm=0.589522, loss=5.844306
I1006 23:36:56.940584 139932355139392 pytorch_submission_base.py:86] 74) loss = 5.844, grad_norm = 0.590
I1006 23:36:58.655748 139901530003200 logging_writer.py:48] [75] global_step=75, grad_norm=2.481442, loss=5.847866
I1006 23:36:58.659226 139932355139392 pytorch_submission_base.py:86] 75) loss = 5.848, grad_norm = 2.481
I1006 23:37:00.347335 139901538395904 logging_writer.py:48] [76] global_step=76, grad_norm=7.077770, loss=5.886874
I1006 23:37:00.350742 139932355139392 pytorch_submission_base.py:86] 76) loss = 5.887, grad_norm = 7.078
I1006 23:37:02.201868 139901530003200 logging_writer.py:48] [77] global_step=77, grad_norm=15.547015, loss=6.000118
I1006 23:37:02.205487 139932355139392 pytorch_submission_base.py:86] 77) loss = 6.000, grad_norm = 15.547
I1006 23:37:04.008021 139901538395904 logging_writer.py:48] [78] global_step=78, grad_norm=10.140150, loss=5.970486
I1006 23:37:04.011521 139932355139392 pytorch_submission_base.py:86] 78) loss = 5.970, grad_norm = 10.140
I1006 23:37:05.827134 139901530003200 logging_writer.py:48] [79] global_step=79, grad_norm=9.120461, loss=5.933369
I1006 23:37:05.830506 139932355139392 pytorch_submission_base.py:86] 79) loss = 5.933, grad_norm = 9.120
I1006 23:37:07.626663 139901538395904 logging_writer.py:48] [80] global_step=80, grad_norm=7.250230, loss=5.874292
I1006 23:37:07.630208 139932355139392 pytorch_submission_base.py:86] 80) loss = 5.874, grad_norm = 7.250
I1006 23:37:09.360262 139901530003200 logging_writer.py:48] [81] global_step=81, grad_norm=8.422486, loss=5.886944
I1006 23:37:09.363792 139932355139392 pytorch_submission_base.py:86] 81) loss = 5.887, grad_norm = 8.422
I1006 23:37:11.133542 139901538395904 logging_writer.py:48] [82] global_step=82, grad_norm=4.663957, loss=5.848086
I1006 23:37:11.137872 139932355139392 pytorch_submission_base.py:86] 82) loss = 5.848, grad_norm = 4.664
I1006 23:37:12.895341 139901530003200 logging_writer.py:48] [83] global_step=83, grad_norm=6.598255, loss=5.887924
I1006 23:37:12.899598 139932355139392 pytorch_submission_base.py:86] 83) loss = 5.888, grad_norm = 6.598
I1006 23:37:14.677746 139901538395904 logging_writer.py:48] [84] global_step=84, grad_norm=0.469030, loss=5.835856
I1006 23:37:14.682406 139932355139392 pytorch_submission_base.py:86] 84) loss = 5.836, grad_norm = 0.469
I1006 23:37:16.464010 139901530003200 logging_writer.py:48] [85] global_step=85, grad_norm=8.167406, loss=5.869720
I1006 23:37:16.468232 139932355139392 pytorch_submission_base.py:86] 85) loss = 5.870, grad_norm = 8.167
I1006 23:37:18.327041 139901538395904 logging_writer.py:48] [86] global_step=86, grad_norm=1.159934, loss=5.817399
I1006 23:37:18.331346 139932355139392 pytorch_submission_base.py:86] 86) loss = 5.817, grad_norm = 1.160
I1006 23:37:20.158238 139901530003200 logging_writer.py:48] [87] global_step=87, grad_norm=5.504764, loss=5.844811
I1006 23:37:20.162585 139932355139392 pytorch_submission_base.py:86] 87) loss = 5.845, grad_norm = 5.505
I1006 23:37:21.898477 139901538395904 logging_writer.py:48] [88] global_step=88, grad_norm=0.580485, loss=5.833531
I1006 23:37:21.902598 139932355139392 pytorch_submission_base.py:86] 88) loss = 5.834, grad_norm = 0.580
I1006 23:37:23.686009 139901530003200 logging_writer.py:48] [89] global_step=89, grad_norm=5.095488, loss=5.873323
I1006 23:37:23.690418 139932355139392 pytorch_submission_base.py:86] 89) loss = 5.873, grad_norm = 5.095
I1006 23:37:25.486477 139901538395904 logging_writer.py:48] [90] global_step=90, grad_norm=0.511016, loss=5.822189
I1006 23:37:25.490073 139932355139392 pytorch_submission_base.py:86] 90) loss = 5.822, grad_norm = 0.511
I1006 23:37:27.312674 139901530003200 logging_writer.py:48] [91] global_step=91, grad_norm=2.937477, loss=5.833041
I1006 23:37:27.316216 139932355139392 pytorch_submission_base.py:86] 91) loss = 5.833, grad_norm = 2.937
I1006 23:37:29.093908 139901538395904 logging_writer.py:48] [92] global_step=92, grad_norm=0.539404, loss=5.814378
I1006 23:37:29.097421 139932355139392 pytorch_submission_base.py:86] 92) loss = 5.814, grad_norm = 0.539
I1006 23:37:31.028989 139901530003200 logging_writer.py:48] [93] global_step=93, grad_norm=3.174145, loss=5.829410
I1006 23:37:31.032592 139932355139392 pytorch_submission_base.py:86] 93) loss = 5.829, grad_norm = 3.174
I1006 23:37:32.695661 139901538395904 logging_writer.py:48] [94] global_step=94, grad_norm=1.029272, loss=5.826926
I1006 23:37:32.699220 139932355139392 pytorch_submission_base.py:86] 94) loss = 5.827, grad_norm = 1.029
I1006 23:37:34.627678 139901530003200 logging_writer.py:48] [95] global_step=95, grad_norm=1.873454, loss=5.825618
I1006 23:37:34.631081 139932355139392 pytorch_submission_base.py:86] 95) loss = 5.826, grad_norm = 1.873
I1006 23:37:36.483997 139901538395904 logging_writer.py:48] [96] global_step=96, grad_norm=1.950632, loss=5.835294
I1006 23:37:36.487506 139932355139392 pytorch_submission_base.py:86] 96) loss = 5.835, grad_norm = 1.951
I1006 23:37:38.193313 139901530003200 logging_writer.py:48] [97] global_step=97, grad_norm=0.357940, loss=5.809742
I1006 23:37:38.196903 139932355139392 pytorch_submission_base.py:86] 97) loss = 5.810, grad_norm = 0.358
I1006 23:37:39.952460 139901538395904 logging_writer.py:48] [98] global_step=98, grad_norm=0.908310, loss=5.824866
I1006 23:37:39.955916 139932355139392 pytorch_submission_base.py:86] 98) loss = 5.825, grad_norm = 0.908
I1006 23:37:41.689693 139901530003200 logging_writer.py:48] [99] global_step=99, grad_norm=0.935196, loss=5.824142
I1006 23:37:41.693212 139932355139392 pytorch_submission_base.py:86] 99) loss = 5.824, grad_norm = 0.935
I1006 23:37:43.405223 139901538395904 logging_writer.py:48] [100] global_step=100, grad_norm=0.795655, loss=5.817694
I1006 23:37:43.408586 139932355139392 pytorch_submission_base.py:86] 100) loss = 5.818, grad_norm = 0.796
I1006 23:49:29.516765 139901530003200 logging_writer.py:48] [500] global_step=500, grad_norm=0.859620, loss=3.821990
I1006 23:49:29.521046 139932355139392 pytorch_submission_base.py:86] 500) loss = 3.822, grad_norm = 0.860
I1006 23:58:46.417524 139932355139392 spec.py:321] Evaluating on the training split.
I1006 23:58:57.686749 139932355139392 spec.py:333] Evaluating on the validation split.
I1006 23:59:08.892361 139932355139392 spec.py:349] Evaluating on the test split.
I1006 23:59:16.149106 139932355139392 submission_runner.py:384] Time since start: 1527.43s, 	Step: 815, 	{'train/ctc_loss': 4.896786117505857, 'train/wer': 0.8601864543219546, 'validation/ctc_loss': 5.0633872846343175, 'validation/wer': 0.8349249263747405, 'validation/num_examples': 5348, 'test/ctc_loss': 4.909565133234402, 'test/wer': 0.8227205329758496, 'test/num_examples': 2472, 'score': 1451.6175451278687, 'total_duration': 1527.4264228343964, 'accumulated_submission_time': 1451.6175451278687, 'accumulated_eval_time': 73.5019679069519, 'accumulated_logging_time': 0.03444314002990723}
I1006 23:59:16.177349 139901538395904 logging_writer.py:48] [815] accumulated_eval_time=73.501968, accumulated_logging_time=0.034443, accumulated_submission_time=1451.617545, global_step=815, preemption_count=0, score=1451.617545, test/ctc_loss=4.909565, test/num_examples=2472, test/wer=0.822721, total_duration=1527.426423, train/ctc_loss=4.896786, train/wer=0.860186, validation/ctc_loss=5.063387, validation/num_examples=5348, validation/wer=0.834925
I1007 00:04:43.986634 139901530003200 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.791559, loss=2.745151
I1007 00:04:43.990827 139932355139392 pytorch_submission_base.py:86] 1000) loss = 2.745, grad_norm = 0.792
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
I1007 00:19:23.934395 139901538395904 logging_writer.py:48] [1500] global_step=1500, grad_norm=1.078925, loss=2.305409
I1007 00:19:23.945926 139932355139392 pytorch_submission_base.py:86] 1500) loss = 2.305, grad_norm = 1.079
I1007 00:23:18.248987 139932355139392 spec.py:321] Evaluating on the training split.
I1007 00:23:30.249583 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 00:23:41.677496 139932355139392 spec.py:349] Evaluating on the test split.
I1007 00:23:48.930064 139932355139392 submission_runner.py:384] Time since start: 3000.21s, 	Step: 1633, 	{'train/ctc_loss': 3.1465044991134, 'train/wer': 0.6652851206405151, 'validation/ctc_loss': 3.404768183644766, 'validation/wer': 0.6659489209675084, 'validation/num_examples': 5348, 'test/ctc_loss': 3.0245072262726627, 'test/wer': 0.5980744622509293, 'test/num_examples': 2472, 'score': 2891.8515605926514, 'total_duration': 3000.2073078155518, 'accumulated_submission_time': 2891.8515605926514, 'accumulated_eval_time': 104.1828248500824, 'accumulated_logging_time': 0.07716250419616699}
I1007 00:23:48.956867 139901538395904 logging_writer.py:48] [1633] accumulated_eval_time=104.182825, accumulated_logging_time=0.077163, accumulated_submission_time=2891.851561, global_step=1633, preemption_count=0, score=2891.851561, test/ctc_loss=3.024507, test/num_examples=2472, test/wer=0.598074, total_duration=3000.207308, train/ctc_loss=3.146504, train/wer=0.665285, validation/ctc_loss=3.404768, validation/num_examples=5348, validation/wer=0.665949
I1007 00:34:34.946386 139901530003200 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.782462, loss=2.070338
I1007 00:34:34.951379 139932355139392 pytorch_submission_base.py:86] 2000) loss = 2.070, grad_norm = 0.782
I1007 00:47:49.889719 139932355139392 spec.py:321] Evaluating on the training split.
I1007 00:48:02.539428 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 00:48:14.498045 139932355139392 spec.py:349] Evaluating on the test split.
I1007 00:48:21.793853 139932355139392 submission_runner.py:384] Time since start: 4473.07s, 	Step: 2455, 	{'train/ctc_loss': 1.3503556359278108, 'train/wer': 0.38643582881883254, 'validation/ctc_loss': 1.5514714365770041, 'validation/wer': 0.39827161685897744, 'validation/num_examples': 5348, 'test/ctc_loss': 1.2016922462739532, 'test/wer': 0.34578433164747224, 'test/num_examples': 2472, 'score': 4330.894143819809, 'total_duration': 4473.071118116379, 'accumulated_submission_time': 4330.894143819809, 'accumulated_eval_time': 136.08687496185303, 'accumulated_logging_time': 0.11427545547485352}
I1007 00:48:21.823744 139901538395904 logging_writer.py:48] [2455] accumulated_eval_time=136.086875, accumulated_logging_time=0.114275, accumulated_submission_time=4330.894144, global_step=2455, preemption_count=0, score=4330.894144, test/ctc_loss=1.201692, test/num_examples=2472, test/wer=0.345784, total_duration=4473.071118, train/ctc_loss=1.350356, train/wer=0.386436, validation/ctc_loss=1.551471, validation/num_examples=5348, validation/wer=0.398272
I1007 00:49:48.137082 139901530003200 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.885598, loss=2.013815
I1007 00:49:48.141090 139932355139392 pytorch_submission_base.py:86] 2500) loss = 2.014, grad_norm = 0.886
I1007 01:05:03.651620 139901538395904 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.710412, loss=2.027299
I1007 01:05:03.660712 139932355139392 pytorch_submission_base.py:86] 3000) loss = 2.027, grad_norm = 0.710
I1007 01:12:23.767327 139932355139392 spec.py:321] Evaluating on the training split.
I1007 01:12:36.325466 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 01:12:48.135721 139932355139392 spec.py:349] Evaluating on the test split.
I1007 01:12:55.361387 139932355139392 submission_runner.py:384] Time since start: 5946.64s, 	Step: 3241, 	{'train/ctc_loss': 0.8829941269109366, 'train/wer': 0.2890531514479037, 'validation/ctc_loss': 1.0832962486814346, 'validation/wer': 0.3155795876985468, 'validation/num_examples': 5348, 'test/ctc_loss': 0.7975783719917414, 'test/wer': 0.2608209940487072, 'test/num_examples': 2472, 'score': 5771.036632061005, 'total_duration': 5946.638638496399, 'accumulated_submission_time': 5771.036632061005, 'accumulated_eval_time': 167.68099808692932, 'accumulated_logging_time': 0.15583086013793945}
I1007 01:12:55.387851 139901538395904 logging_writer.py:48] [3241] accumulated_eval_time=167.680998, accumulated_logging_time=0.155831, accumulated_submission_time=5771.036632, global_step=3241, preemption_count=0, score=5771.036632, test/ctc_loss=0.797578, test/num_examples=2472, test/wer=0.260821, total_duration=5946.638638, train/ctc_loss=0.882994, train/wer=0.289053, validation/ctc_loss=1.083296, validation/num_examples=5348, validation/wer=0.315580
I1007 01:20:53.294699 139901530003200 logging_writer.py:48] [3500] global_step=3500, grad_norm=1.233311, loss=1.906796
I1007 01:20:53.303983 139932355139392 pytorch_submission_base.py:86] 3500) loss = 1.907, grad_norm = 1.233
I1007 01:36:04.399619 139901538395904 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.847784, loss=1.863210
I1007 01:36:04.404129 139932355139392 pytorch_submission_base.py:86] 4000) loss = 1.863, grad_norm = 0.848
I1007 01:36:57.501322 139932355139392 spec.py:321] Evaluating on the training split.
I1007 01:37:10.362789 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 01:37:21.960826 139932355139392 spec.py:349] Evaluating on the test split.
I1007 01:37:29.625235 139932355139392 submission_runner.py:384] Time since start: 7420.90s, 	Step: 4030, 	{'train/ctc_loss': 0.7314566261057072, 'train/wer': 0.2432282488088245, 'validation/ctc_loss': 0.9405174937525116, 'validation/wer': 0.2764930237049196, 'validation/num_examples': 5348, 'test/ctc_loss': 0.654709477224337, 'test/wer': 0.21329189771088497, 'test/num_examples': 2472, 'score': 7211.425891637802, 'total_duration': 7420.902430295944, 'accumulated_submission_time': 7211.425891637802, 'accumulated_eval_time': 199.80465507507324, 'accumulated_logging_time': 0.19401812553405762}
I1007 01:37:29.654520 139901538395904 logging_writer.py:48] [4030] accumulated_eval_time=199.804655, accumulated_logging_time=0.194018, accumulated_submission_time=7211.425892, global_step=4030, preemption_count=0, score=7211.425892, test/ctc_loss=0.654709, test/num_examples=2472, test/wer=0.213292, total_duration=7420.902430, train/ctc_loss=0.731457, train/wer=0.243228, validation/ctc_loss=0.940517, validation/num_examples=5348, validation/wer=0.276493
I1007 01:51:46.843022 139901538395904 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.894433, loss=1.850230
I1007 01:51:46.851723 139932355139392 pytorch_submission_base.py:86] 4500) loss = 1.850, grad_norm = 0.894
I1007 02:01:30.686225 139932355139392 spec.py:321] Evaluating on the training split.
I1007 02:01:43.477210 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 02:01:55.140629 139932355139392 spec.py:349] Evaluating on the test split.
I1007 02:02:02.639655 139932355139392 submission_runner.py:384] Time since start: 8893.92s, 	Step: 4822, 	{'train/ctc_loss': 0.6526676826684116, 'train/wer': 0.21608141331070643, 'validation/ctc_loss': 0.8584893831939421, 'validation/wer': 0.25384058320861297, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5802005371314278, 'test/wer': 0.19208660857554893, 'test/num_examples': 2472, 'score': 8650.586411476135, 'total_duration': 8893.916859865189, 'accumulated_submission_time': 8650.586411476135, 'accumulated_eval_time': 231.7578477859497, 'accumulated_logging_time': 0.2341477870941162}
I1007 02:02:02.668370 139901538395904 logging_writer.py:48] [4822] accumulated_eval_time=231.757848, accumulated_logging_time=0.234148, accumulated_submission_time=8650.586411, global_step=4822, preemption_count=0, score=8650.586411, test/ctc_loss=0.580201, test/num_examples=2472, test/wer=0.192087, total_duration=8893.916860, train/ctc_loss=0.652668, train/wer=0.216081, validation/ctc_loss=0.858489, validation/num_examples=5348, validation/wer=0.253841
I1007 02:07:30.091543 139901530003200 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.704054, loss=1.753746
I1007 02:07:30.096243 139932355139392 pytorch_submission_base.py:86] 5000) loss = 1.754, grad_norm = 0.704
I1007 02:22:42.064245 139901538395904 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.631622, loss=1.846227
I1007 02:22:42.073670 139932355139392 pytorch_submission_base.py:86] 5500) loss = 1.846, grad_norm = 0.632
I1007 02:26:04.181815 139932355139392 spec.py:321] Evaluating on the training split.
I1007 02:26:16.682336 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 02:26:28.575204 139932355139392 spec.py:349] Evaluating on the test split.
I1007 02:26:36.038825 139932355139392 submission_runner.py:384] Time since start: 10367.32s, 	Step: 5611, 	{'train/ctc_loss': 0.6091326895170996, 'train/wer': 0.2045721558644997, 'validation/ctc_loss': 0.8202054646687261, 'validation/wer': 0.24505383092743688, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5513427781631073, 'test/wer': 0.1848759978063494, 'test/num_examples': 2472, 'score': 10090.206138372421, 'total_duration': 10367.316051721573, 'accumulated_submission_time': 10090.206138372421, 'accumulated_eval_time': 263.61484479904175, 'accumulated_logging_time': 0.27373290061950684}
I1007 02:26:36.065640 139901538395904 logging_writer.py:48] [5611] accumulated_eval_time=263.614845, accumulated_logging_time=0.273733, accumulated_submission_time=10090.206138, global_step=5611, preemption_count=0, score=10090.206138, test/ctc_loss=0.551343, test/num_examples=2472, test/wer=0.184876, total_duration=10367.316052, train/ctc_loss=0.609133, train/wer=0.204572, validation/ctc_loss=0.820205, validation/num_examples=5348, validation/wer=0.245054
I1007 02:38:25.037554 139901530003200 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.657216, loss=1.772584
I1007 02:38:25.042739 139932355139392 pytorch_submission_base.py:86] 6000) loss = 1.773, grad_norm = 0.657
I1007 02:50:38.380388 139932355139392 spec.py:321] Evaluating on the training split.
I1007 02:50:50.838154 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 02:51:03.094688 139932355139392 spec.py:349] Evaluating on the test split.
I1007 02:51:10.313004 139932355139392 submission_runner.py:384] Time since start: 11841.59s, 	Step: 6402, 	{'train/ctc_loss': 0.5800435120547082, 'train/wer': 0.19527119639710203, 'validation/ctc_loss': 0.7908566417238045, 'validation/wer': 0.23395934920098488, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5259389718691528, 'test/wer': 0.17604046066662604, 'test/num_examples': 2472, 'score': 11530.675481796265, 'total_duration': 11841.590258359909, 'accumulated_submission_time': 11530.675481796265, 'accumulated_eval_time': 295.54734325408936, 'accumulated_logging_time': 0.31284284591674805}
I1007 02:51:10.342061 139901538395904 logging_writer.py:48] [6402] accumulated_eval_time=295.547343, accumulated_logging_time=0.312843, accumulated_submission_time=11530.675482, global_step=6402, preemption_count=0, score=11530.675482, test/ctc_loss=0.525939, test/num_examples=2472, test/wer=0.176040, total_duration=11841.590258, train/ctc_loss=0.580044, train/wer=0.195271, validation/ctc_loss=0.790857, validation/num_examples=5348, validation/wer=0.233959
I1007 02:54:10.958540 139901530003200 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.699214, loss=1.737016
I1007 02:54:10.968224 139932355139392 pytorch_submission_base.py:86] 6500) loss = 1.737, grad_norm = 0.699
I1007 03:09:24.017287 139901538395904 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.661981, loss=1.746948
I1007 03:09:24.026490 139932355139392 pytorch_submission_base.py:86] 7000) loss = 1.747, grad_norm = 0.662
I1007 03:15:11.556864 139932355139392 spec.py:321] Evaluating on the training split.
I1007 03:15:24.512736 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 03:15:36.205606 139932355139392 spec.py:349] Evaluating on the test split.
I1007 03:15:43.862613 139932355139392 submission_runner.py:384] Time since start: 13315.14s, 	Step: 7192, 	{'train/ctc_loss': 0.5669485216835567, 'train/wer': 0.19100145769423232, 'validation/ctc_loss': 0.7873705372840064, 'validation/wer': 0.23284893545116594, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5104450791180076, 'test/wer': 0.17100318891800215, 'test/num_examples': 2472, 'score': 12970.172096014023, 'total_duration': 13315.139740228653, 'accumulated_submission_time': 12970.172096014023, 'accumulated_eval_time': 327.8530020713806, 'accumulated_logging_time': 0.3544793128967285}
I1007 03:15:43.892961 139901538395904 logging_writer.py:48] [7192] accumulated_eval_time=327.853002, accumulated_logging_time=0.354479, accumulated_submission_time=12970.172096, global_step=7192, preemption_count=0, score=12970.172096, test/ctc_loss=0.510445, test/num_examples=2472, test/wer=0.171003, total_duration=13315.139740, train/ctc_loss=0.566949, train/wer=0.191001, validation/ctc_loss=0.787371, validation/num_examples=5348, validation/wer=0.232849
I1007 03:25:11.134227 139901538395904 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.696269, loss=1.762274
I1007 03:25:11.147680 139932355139392 pytorch_submission_base.py:86] 7500) loss = 1.762, grad_norm = 0.696
I1007 03:39:45.248728 139932355139392 spec.py:321] Evaluating on the training split.
I1007 03:39:58.126367 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 03:40:09.724767 139932355139392 spec.py:349] Evaluating on the test split.
I1007 03:40:17.132445 139932355139392 submission_runner.py:384] Time since start: 14788.41s, 	Step: 7979, 	{'train/ctc_loss': 0.5510059858211814, 'train/wer': 0.18587777125078866, 'validation/ctc_loss': 0.761068640355008, 'validation/wer': 0.2280596726693381, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5031694585134525, 'test/wer': 0.16698149615095567, 'test/num_examples': 2472, 'score': 14409.625405550003, 'total_duration': 14788.40966463089, 'accumulated_submission_time': 14409.625405550003, 'accumulated_eval_time': 359.7365891933441, 'accumulated_logging_time': 0.396059513092041}
I1007 03:40:17.164828 139901538395904 logging_writer.py:48] [7979] accumulated_eval_time=359.736589, accumulated_logging_time=0.396060, accumulated_submission_time=14409.625406, global_step=7979, preemption_count=0, score=14409.625406, test/ctc_loss=0.503169, test/num_examples=2472, test/wer=0.166981, total_duration=14788.409665, train/ctc_loss=0.551006, train/wer=0.185878, validation/ctc_loss=0.761069, validation/num_examples=5348, validation/wer=0.228060
I1007 03:40:58.919128 139901530003200 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.593575, loss=1.701139
I1007 03:40:58.924915 139932355139392 pytorch_submission_base.py:86] 8000) loss = 1.701, grad_norm = 0.594
I1007 03:56:15.977954 139901538395904 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.722239, loss=1.688015
I1007 03:56:15.985876 139932355139392 pytorch_submission_base.py:86] 8500) loss = 1.688, grad_norm = 0.722
I1007 04:04:18.043749 139932355139392 spec.py:321] Evaluating on the training split.
I1007 04:04:30.992458 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 04:04:43.183805 139932355139392 spec.py:349] Evaluating on the test split.
I1007 04:04:50.559507 139932355139392 submission_runner.py:384] Time since start: 16261.84s, 	Step: 8763, 	{'train/ctc_loss': 0.5333651045781106, 'train/wer': 0.17851315188303635, 'validation/ctc_loss': 0.7334053050281294, 'validation/wer': 0.21694587939941098, 'validation/num_examples': 5348, 'test/ctc_loss': 0.48139073488612166, 'test/wer': 0.1590396685150204, 'test/num_examples': 2472, 'score': 15848.628237009048, 'total_duration': 16261.83667087555, 'accumulated_submission_time': 15848.628237009048, 'accumulated_eval_time': 392.2522087097168, 'accumulated_logging_time': 0.4399905204772949}
I1007 04:04:50.585608 139901538395904 logging_writer.py:48] [8763] accumulated_eval_time=392.252209, accumulated_logging_time=0.439991, accumulated_submission_time=15848.628237, global_step=8763, preemption_count=0, score=15848.628237, test/ctc_loss=0.481391, test/num_examples=2472, test/wer=0.159040, total_duration=16261.836671, train/ctc_loss=0.533365, train/wer=0.178513, validation/ctc_loss=0.733405, validation/num_examples=5348, validation/wer=0.216946
I1007 04:12:08.564917 139901530003200 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.577717, loss=1.725548
I1007 04:12:08.569976 139932355139392 pytorch_submission_base.py:86] 9000) loss = 1.726, grad_norm = 0.578
I1007 04:27:23.528573 139901538395904 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.717174, loss=1.714186
I1007 04:27:23.540838 139932355139392 pytorch_submission_base.py:86] 9500) loss = 1.714, grad_norm = 0.717
I1007 04:28:51.964682 139932355139392 spec.py:321] Evaluating on the training split.
I1007 04:29:04.709038 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 04:29:17.266226 139932355139392 spec.py:349] Evaluating on the test split.
I1007 04:29:24.768678 139932355139392 submission_runner.py:384] Time since start: 17736.05s, 	Step: 9549, 	{'train/ctc_loss': 0.5298267570105816, 'train/wer': 0.17871983987120074, 'validation/ctc_loss': 0.7449853309599156, 'validation/wer': 0.22006469367064163, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4844181479450287, 'test/wer': 0.16253326021164666, 'test/num_examples': 2472, 'score': 17288.262873888016, 'total_duration': 17736.04589653015, 'accumulated_submission_time': 17288.262873888016, 'accumulated_eval_time': 425.0559959411621, 'accumulated_logging_time': 0.47687745094299316}
I1007 04:29:24.796275 139901538395904 logging_writer.py:48] [9549] accumulated_eval_time=425.055996, accumulated_logging_time=0.476877, accumulated_submission_time=17288.262874, global_step=9549, preemption_count=0, score=17288.262874, test/ctc_loss=0.484418, test/num_examples=2472, test/wer=0.162533, total_duration=17736.045897, train/ctc_loss=0.529827, train/wer=0.178720, validation/ctc_loss=0.744985, validation/num_examples=5348, validation/wer=0.220065
I1007 04:43:08.938288 139901530003200 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.717647, loss=1.719394
I1007 04:43:08.943291 139932355139392 pytorch_submission_base.py:86] 10000) loss = 1.719, grad_norm = 0.718
I1007 04:53:25.612643 139932355139392 spec.py:321] Evaluating on the training split.
I1007 04:53:38.278052 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 04:53:50.531216 139932355139392 spec.py:349] Evaluating on the test split.
I1007 04:53:57.909512 139932355139392 submission_runner.py:384] Time since start: 19209.19s, 	Step: 10337, 	{'train/ctc_loss': 0.5161313939453529, 'train/wer': 0.175483541109153, 'validation/ctc_loss': 0.7275638346550382, 'validation/wer': 0.2150726596823251, 'validation/num_examples': 5348, 'test/ctc_loss': 0.47310587578230856, 'test/wer': 0.15832876322791622, 'test/num_examples': 2472, 'score': 18727.216140031815, 'total_duration': 19209.186690568924, 'accumulated_submission_time': 18727.216140031815, 'accumulated_eval_time': 457.352858543396, 'accumulated_logging_time': 0.5146946907043457}
I1007 04:53:57.934042 139901538395904 logging_writer.py:48] [10337] accumulated_eval_time=457.352859, accumulated_logging_time=0.514695, accumulated_submission_time=18727.216140, global_step=10337, preemption_count=0, score=18727.216140, test/ctc_loss=0.473106, test/num_examples=2472, test/wer=0.158329, total_duration=19209.186691, train/ctc_loss=0.516131, train/wer=0.175484, validation/ctc_loss=0.727564, validation/num_examples=5348, validation/wer=0.215073
I1007 04:59:00.347523 139901530003200 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.845060, loss=1.692868
I1007 04:59:00.355299 139932355139392 pytorch_submission_base.py:86] 10500) loss = 1.693, grad_norm = 0.845
I1007 05:14:08.659218 139901538395904 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.602495, loss=1.649364
I1007 05:14:08.669172 139932355139392 pytorch_submission_base.py:86] 11000) loss = 1.649, grad_norm = 0.602
I1007 05:17:59.108285 139932355139392 spec.py:321] Evaluating on the training split.
I1007 05:18:11.818989 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 05:18:23.311033 139932355139392 spec.py:349] Evaluating on the test split.
I1007 05:18:30.675377 139932355139392 submission_runner.py:384] Time since start: 20681.95s, 	Step: 11127, 	{'train/ctc_loss': 0.523792145283729, 'train/wer': 0.17783869634271043, 'validation/ctc_loss': 0.7399534440457354, 'validation/wer': 0.2186163279100082, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4761092449512872, 'test/wer': 0.15932403062986208, 'test/num_examples': 2472, 'score': 20166.62866616249, 'total_duration': 20681.95261001587, 'accumulated_submission_time': 20166.62866616249, 'accumulated_eval_time': 488.9197039604187, 'accumulated_logging_time': 0.5496513843536377}
I1007 05:18:30.705012 139901538395904 logging_writer.py:48] [11127] accumulated_eval_time=488.919704, accumulated_logging_time=0.549651, accumulated_submission_time=20166.628666, global_step=11127, preemption_count=0, score=20166.628666, test/ctc_loss=0.476109, test/num_examples=2472, test/wer=0.159324, total_duration=20681.952610, train/ctc_loss=0.523792, train/wer=0.177839, validation/ctc_loss=0.739953, validation/num_examples=5348, validation/wer=0.218616
I1007 05:29:55.508347 139901538395904 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.776512, loss=1.664232
I1007 05:29:55.515839 139932355139392 pytorch_submission_base.py:86] 11500) loss = 1.664, grad_norm = 0.777
I1007 05:42:31.716478 139932355139392 spec.py:321] Evaluating on the training split.
I1007 05:42:44.527169 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 05:42:56.272063 139932355139392 spec.py:349] Evaluating on the test split.
I1007 05:43:03.871732 139932355139392 submission_runner.py:384] Time since start: 22155.15s, 	Step: 11918, 	{'train/ctc_loss': 0.5150856552194123, 'train/wer': 0.17288906294193154, 'validation/ctc_loss': 0.7280276871264064, 'validation/wer': 0.21274561869357408, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4689193153590554, 'test/wer': 0.15097597140129587, 'test/num_examples': 2472, 'score': 21605.763298988342, 'total_duration': 22155.148891448975, 'accumulated_submission_time': 21605.763298988342, 'accumulated_eval_time': 521.0747001171112, 'accumulated_logging_time': 0.5906224250793457}
I1007 05:43:03.912064 139901538395904 logging_writer.py:48] [11918] accumulated_eval_time=521.074700, accumulated_logging_time=0.590622, accumulated_submission_time=21605.763299, global_step=11918, preemption_count=0, score=21605.763299, test/ctc_loss=0.468919, test/num_examples=2472, test/wer=0.150976, total_duration=22155.148891, train/ctc_loss=0.515086, train/wer=0.172889, validation/ctc_loss=0.728028, validation/num_examples=5348, validation/wer=0.212746
I1007 05:45:35.706061 139901530003200 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.748844, loss=1.733482
I1007 05:45:35.710544 139932355139392 pytorch_submission_base.py:86] 12000) loss = 1.733, grad_norm = 0.749
I1007 06:00:51.049970 139901538395904 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.666046, loss=1.679551
I1007 06:00:51.058825 139932355139392 pytorch_submission_base.py:86] 12500) loss = 1.680, grad_norm = 0.666
I1007 06:07:05.744798 139932355139392 spec.py:321] Evaluating on the training split.
I1007 06:07:18.279092 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 06:07:30.177349 139932355139392 spec.py:349] Evaluating on the test split.
I1007 06:07:37.508772 139932355139392 submission_runner.py:384] Time since start: 23628.79s, 	Step: 12708, 	{'train/ctc_loss': 0.4987111031812495, 'train/wer': 0.16971259491329982, 'validation/ctc_loss': 0.7021680590089411, 'validation/wer': 0.20841983295514893, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4564603966384928, 'test/wer': 0.1525602746125566, 'test/num_examples': 2472, 'score': 23045.742280721664, 'total_duration': 23628.785950422287, 'accumulated_submission_time': 23045.742280721664, 'accumulated_eval_time': 552.8385345935822, 'accumulated_logging_time': 0.6443760395050049}
I1007 06:07:37.535379 139901538395904 logging_writer.py:48] [12708] accumulated_eval_time=552.838535, accumulated_logging_time=0.644376, accumulated_submission_time=23045.742281, global_step=12708, preemption_count=0, score=23045.742281, test/ctc_loss=0.456460, test/num_examples=2472, test/wer=0.152560, total_duration=23628.785950, train/ctc_loss=0.498711, train/wer=0.169713, validation/ctc_loss=0.702168, validation/num_examples=5348, validation/wer=0.208420
I1007 06:16:33.233120 139901530003200 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.808018, loss=1.634140
I1007 06:16:33.242122 139932355139392 pytorch_submission_base.py:86] 13000) loss = 1.634, grad_norm = 0.808
I1007 06:31:38.920032 139932355139392 spec.py:321] Evaluating on the training split.
I1007 06:31:51.576846 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 06:32:03.396473 139932355139392 spec.py:349] Evaluating on the test split.
I1007 06:32:10.910231 139932355139392 submission_runner.py:384] Time since start: 25102.19s, 	Step: 13495, 	{'train/ctc_loss': 0.4861341613917077, 'train/wer': 0.1655081261014294, 'validation/ctc_loss': 0.6935937048705294, 'validation/wer': 0.20582243035774633, 'validation/num_examples': 5348, 'test/ctc_loss': 0.43975684923220854, 'test/wer': 0.1448824975118315, 'test/num_examples': 2472, 'score': 24485.283011436462, 'total_duration': 25102.187395572662, 'accumulated_submission_time': 24485.283011436462, 'accumulated_eval_time': 584.8286349773407, 'accumulated_logging_time': 0.6823859214782715}
I1007 06:32:10.942664 139901538395904 logging_writer.py:48] [13495] accumulated_eval_time=584.828635, accumulated_logging_time=0.682386, accumulated_submission_time=24485.283011, global_step=13495, preemption_count=0, score=24485.283011, test/ctc_loss=0.439757, test/num_examples=2472, test/wer=0.144882, total_duration=25102.187396, train/ctc_loss=0.486134, train/wer=0.165508, validation/ctc_loss=0.693594, validation/num_examples=5348, validation/wer=0.205822
I1007 06:32:22.698265 139901530003200 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.684147, loss=1.606489
I1007 06:32:22.701984 139932355139392 pytorch_submission_base.py:86] 13500) loss = 1.606, grad_norm = 0.684
I1007 06:47:36.122724 139901538395904 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.813185, loss=1.614248
I1007 06:47:36.128561 139932355139392 pytorch_submission_base.py:86] 14000) loss = 1.614, grad_norm = 0.813
I1007 06:56:12.679039 139932355139392 spec.py:321] Evaluating on the training split.
I1007 06:56:25.079552 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 06:56:36.452985 139932355139392 spec.py:349] Evaluating on the test split.
I1007 06:56:43.664581 139932355139392 submission_runner.py:384] Time since start: 26574.94s, 	Step: 14287, 	{'train/ctc_loss': 0.47519956975320987, 'train/wer': 0.16184213389030308, 'validation/ctc_loss': 0.688703043766953, 'validation/wer': 0.20483754164051562, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4332222038518614, 'test/wer': 0.14490280909146305, 'test/num_examples': 2472, 'score': 25925.32388472557, 'total_duration': 26574.94177341461, 'accumulated_submission_time': 25925.32388472557, 'accumulated_eval_time': 615.813844203949, 'accumulated_logging_time': 0.7272837162017822}
I1007 06:56:43.691329 139901538395904 logging_writer.py:48] [14287] accumulated_eval_time=615.813844, accumulated_logging_time=0.727284, accumulated_submission_time=25925.323885, global_step=14287, preemption_count=0, score=25925.323885, test/ctc_loss=0.433222, test/num_examples=2472, test/wer=0.144903, total_duration=26574.941773, train/ctc_loss=0.475200, train/wer=0.161842, validation/ctc_loss=0.688703, validation/num_examples=5348, validation/wer=0.204838
I1007 07:03:12.391478 139901538395904 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.652120, loss=1.622361
I1007 07:03:12.401942 139932355139392 pytorch_submission_base.py:86] 14500) loss = 1.622, grad_norm = 0.652
I1007 07:18:15.703545 139901530003200 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.657633, loss=1.650177
I1007 07:18:15.708101 139932355139392 pytorch_submission_base.py:86] 15000) loss = 1.650, grad_norm = 0.658
I1007 07:20:45.622034 139932355139392 spec.py:321] Evaluating on the training split.
I1007 07:20:58.185155 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 07:21:09.732132 139932355139392 spec.py:349] Evaluating on the test split.
I1007 07:21:16.956958 139932355139392 submission_runner.py:384] Time since start: 28048.23s, 	Step: 15084, 	{'train/ctc_loss': 0.4759622067693518, 'train/wer': 0.1629027696190414, 'validation/ctc_loss': 0.6820636647327707, 'validation/wer': 0.20423888379278715, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4390068008419898, 'test/wer': 0.14677147441756547, 'test/num_examples': 2472, 'score': 27365.50640487671, 'total_duration': 28048.234255075455, 'accumulated_submission_time': 27365.50640487671, 'accumulated_eval_time': 647.148579120636, 'accumulated_logging_time': 0.7639777660369873}
I1007 07:21:16.983670 139901538395904 logging_writer.py:48] [15084] accumulated_eval_time=647.148579, accumulated_logging_time=0.763978, accumulated_submission_time=27365.506405, global_step=15084, preemption_count=0, score=27365.506405, test/ctc_loss=0.439007, test/num_examples=2472, test/wer=0.146771, total_duration=28048.234255, train/ctc_loss=0.475962, train/wer=0.162903, validation/ctc_loss=0.682064, validation/num_examples=5348, validation/wer=0.204239
I1007 07:33:48.707418 139901538395904 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.578212, loss=1.591217
I1007 07:33:48.714768 139932355139392 pytorch_submission_base.py:86] 15500) loss = 1.591, grad_norm = 0.578
I1007 07:45:19.233313 139932355139392 spec.py:321] Evaluating on the training split.
I1007 07:45:31.712367 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 07:45:43.221924 139932355139392 spec.py:349] Evaluating on the test split.
I1007 07:45:50.391479 139932355139392 submission_runner.py:384] Time since start: 29521.67s, 	Step: 15886, 	{'train/ctc_loss': 0.4671631682980332, 'train/wer': 0.160090725148489, 'validation/ctc_loss': 0.6705689433111061, 'validation/wer': 0.20034760778255203, 'validation/num_examples': 5348, 'test/ctc_loss': 0.42642519275437124, 'test/wer': 0.1429325858672029, 'test/num_examples': 2472, 'score': 28805.971977472305, 'total_duration': 29521.668743371964, 'accumulated_submission_time': 28805.971977472305, 'accumulated_eval_time': 678.3066642284393, 'accumulated_logging_time': 0.8004999160766602}
I1007 07:45:50.418303 139901538395904 logging_writer.py:48] [15886] accumulated_eval_time=678.306664, accumulated_logging_time=0.800500, accumulated_submission_time=28805.971977, global_step=15886, preemption_count=0, score=28805.971977, test/ctc_loss=0.426425, test/num_examples=2472, test/wer=0.142933, total_duration=29521.668743, train/ctc_loss=0.467163, train/wer=0.160091, validation/ctc_loss=0.670569, validation/num_examples=5348, validation/wer=0.200348
I1007 07:49:19.574371 139901530003200 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.665664, loss=1.597564
I1007 07:49:19.578276 139932355139392 pytorch_submission_base.py:86] 16000) loss = 1.598, grad_norm = 0.666
I1007 08:04:25.121172 139901538395904 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.668587, loss=1.590280
I1007 08:04:25.128253 139932355139392 pytorch_submission_base.py:86] 16500) loss = 1.590, grad_norm = 0.669
I1007 08:09:52.716366 139932355139392 spec.py:321] Evaluating on the training split.
I1007 08:10:05.316160 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 08:10:16.828425 139932355139392 spec.py:349] Evaluating on the test split.
I1007 08:10:24.009472 139932355139392 submission_runner.py:384] Time since start: 30995.29s, 	Step: 16682, 	{'train/ctc_loss': 0.46418503790511517, 'train/wer': 0.1569740878532733, 'validation/ctc_loss': 0.6746556621395922, 'validation/wer': 0.19788538598947522, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4201800569794826, 'test/wer': 0.13862653098531472, 'test/num_examples': 2472, 'score': 30246.523585796356, 'total_duration': 30995.286702394485, 'accumulated_submission_time': 30246.523585796356, 'accumulated_eval_time': 709.5995194911957, 'accumulated_logging_time': 0.8372371196746826}
I1007 08:10:24.034660 139901538395904 logging_writer.py:48] [16682] accumulated_eval_time=709.599519, accumulated_logging_time=0.837237, accumulated_submission_time=30246.523586, global_step=16682, preemption_count=0, score=30246.523586, test/ctc_loss=0.420180, test/num_examples=2472, test/wer=0.138627, total_duration=30995.286702, train/ctc_loss=0.464185, train/wer=0.156974, validation/ctc_loss=0.674656, validation/num_examples=5348, validation/wer=0.197885
I1007 08:20:01.044992 139901530003200 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.736459, loss=1.602256
I1007 08:20:01.058441 139932355139392 pytorch_submission_base.py:86] 17000) loss = 1.602, grad_norm = 0.736
I1007 08:34:25.560676 139932355139392 spec.py:321] Evaluating on the training split.
I1007 08:34:38.687951 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 08:34:50.112828 139932355139392 spec.py:349] Evaluating on the test split.
I1007 08:34:57.373829 139932355139392 submission_runner.py:384] Time since start: 32468.65s, 	Step: 17481, 	{'train/ctc_loss': 0.4559869018840673, 'train/wer': 0.15681635228335836, 'validation/ctc_loss': 0.6653841557885021, 'validation/wer': 0.19785641867426254, 'validation/num_examples': 5348, 'test/ctc_loss': 0.42495468457642427, 'test/wer': 0.14049519631141713, 'test/num_examples': 2472, 'score': 31686.318539857864, 'total_duration': 32468.651089429855, 'accumulated_submission_time': 31686.318539857864, 'accumulated_eval_time': 741.4124627113342, 'accumulated_logging_time': 0.8720552921295166}
I1007 08:34:57.409391 139901538395904 logging_writer.py:48] [17481] accumulated_eval_time=741.412463, accumulated_logging_time=0.872055, accumulated_submission_time=31686.318540, global_step=17481, preemption_count=0, score=31686.318540, test/ctc_loss=0.424955, test/num_examples=2472, test/wer=0.140495, total_duration=32468.651089, train/ctc_loss=0.455987, train/wer=0.156816, validation/ctc_loss=0.665384, validation/num_examples=5348, validation/wer=0.197856
I1007 08:35:34.399350 139901530003200 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.676437, loss=1.573040
I1007 08:35:34.403158 139932355139392 pytorch_submission_base.py:86] 17500) loss = 1.573, grad_norm = 0.676
I1007 08:50:42.516145 139901538395904 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.879528, loss=1.555458
I1007 08:50:42.528029 139932355139392 pytorch_submission_base.py:86] 18000) loss = 1.555, grad_norm = 0.880
I1007 08:58:59.553375 139932355139392 spec.py:321] Evaluating on the training split.
I1007 08:59:12.295330 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 08:59:23.784650 139932355139392 spec.py:349] Evaluating on the test split.
I1007 08:59:31.122555 139932355139392 submission_runner.py:384] Time since start: 33942.40s, 	Step: 18276, 	{'train/ctc_loss': 0.440777151276331, 'train/wer': 0.14957139438243805, 'validation/ctc_loss': 0.6549465922148131, 'validation/wer': 0.1909815091971226, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4126507909784502, 'test/wer': 0.13639225722584444, 'test/num_examples': 2472, 'score': 33126.71435880661, 'total_duration': 33942.3997695446, 'accumulated_submission_time': 33126.71435880661, 'accumulated_eval_time': 772.9813866615295, 'accumulated_logging_time': 0.9183425903320312}
I1007 08:59:31.156413 139901538395904 logging_writer.py:48] [18276] accumulated_eval_time=772.981387, accumulated_logging_time=0.918343, accumulated_submission_time=33126.714359, global_step=18276, preemption_count=0, score=33126.714359, test/ctc_loss=0.412651, test/num_examples=2472, test/wer=0.136392, total_duration=33942.399770, train/ctc_loss=0.440777, train/wer=0.149571, validation/ctc_loss=0.654947, validation/num_examples=5348, validation/wer=0.190982
I1007 09:06:19.315809 139901530003200 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.695817, loss=1.611287
I1007 09:06:19.319847 139932355139392 pytorch_submission_base.py:86] 18500) loss = 1.611, grad_norm = 0.696
I1007 09:21:28.507775 139901538395904 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.685598, loss=1.557203
I1007 09:21:28.518396 139932355139392 pytorch_submission_base.py:86] 19000) loss = 1.557, grad_norm = 0.686
I1007 09:23:33.601870 139932355139392 spec.py:321] Evaluating on the training split.
I1007 09:23:46.275140 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 09:23:57.476475 139932355139392 spec.py:349] Evaluating on the test split.
I1007 09:24:05.001814 139932355139392 submission_runner.py:384] Time since start: 35416.28s, 	Step: 19070, 	{'train/ctc_loss': 0.44438900251570623, 'train/wer': 0.15135543806975177, 'validation/ctc_loss': 0.6546365723735433, 'validation/wer': 0.1925843673055569, 'validation/num_examples': 5348, 'test/ctc_loss': 0.41069567492257564, 'test/wer': 0.13750939410557958, 'test/num_examples': 2472, 'score': 34567.40010333061, 'total_duration': 35416.27900147438, 'accumulated_submission_time': 34567.40010333061, 'accumulated_eval_time': 804.3810205459595, 'accumulated_logging_time': 0.9632787704467773}
I1007 09:24:05.033151 139901538395904 logging_writer.py:48] [19070] accumulated_eval_time=804.381021, accumulated_logging_time=0.963279, accumulated_submission_time=34567.400103, global_step=19070, preemption_count=0, score=34567.400103, test/ctc_loss=0.410696, test/num_examples=2472, test/wer=0.137509, total_duration=35416.279001, train/ctc_loss=0.444389, train/wer=0.151355, validation/ctc_loss=0.654637, validation/num_examples=5348, validation/wer=0.192584
I1007 09:37:01.682784 139901530003200 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.721803, loss=1.633967
I1007 09:37:01.690711 139932355139392 pytorch_submission_base.py:86] 19500) loss = 1.634, grad_norm = 0.722
I1007 09:48:06.001417 139932355139392 spec.py:321] Evaluating on the training split.
I1007 09:48:18.521402 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 09:48:29.879262 139932355139392 spec.py:349] Evaluating on the test split.
I1007 09:48:37.115176 139932355139392 submission_runner.py:384] Time since start: 36888.39s, 	Step: 19866, 	{'train/ctc_loss': 0.43155406945993685, 'train/wer': 0.14650914866305506, 'validation/ctc_loss': 0.6443166397459564, 'validation/wer': 0.1898131608168783, 'validation/num_examples': 5348, 'test/ctc_loss': 0.40376317121265887, 'test/wer': 0.13326427396258608, 'test/num_examples': 2472, 'score': 36006.63622736931, 'total_duration': 36888.392409563065, 'accumulated_submission_time': 36006.63622736931, 'accumulated_eval_time': 835.494616985321, 'accumulated_logging_time': 1.004608392715454}
I1007 09:48:37.144582 139901538395904 logging_writer.py:48] [19866] accumulated_eval_time=835.494617, accumulated_logging_time=1.004608, accumulated_submission_time=36006.636227, global_step=19866, preemption_count=0, score=36006.636227, test/ctc_loss=0.403763, test/num_examples=2472, test/wer=0.133264, total_duration=36888.392410, train/ctc_loss=0.431554, train/wer=0.146509, validation/ctc_loss=0.644317, validation/num_examples=5348, validation/wer=0.189813
I1007 09:52:42.142869 139901530003200 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.638794, loss=1.571174
I1007 09:52:42.151349 139932355139392 pytorch_submission_base.py:86] 20000) loss = 1.571, grad_norm = 0.639
I1007 10:07:46.726121 139901538395904 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.794080, loss=1.593680
I1007 10:07:46.730781 139932355139392 pytorch_submission_base.py:86] 20500) loss = 1.594, grad_norm = 0.794
I1007 10:12:38.922806 139932355139392 spec.py:321] Evaluating on the training split.
I1007 10:12:51.732547 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 10:13:03.293506 139932355139392 spec.py:349] Evaluating on the test split.
I1007 10:13:10.482047 139932355139392 submission_runner.py:384] Time since start: 38361.76s, 	Step: 20662, 	{'train/ctc_loss': 0.4219872553373996, 'train/wer': 0.14181515566869005, 'validation/ctc_loss': 0.6312034381592827, 'validation/wer': 0.1857867040023174, 'validation/num_examples': 5348, 'test/ctc_loss': 0.39566388355700366, 'test/wer': 0.13135498547722058, 'test/num_examples': 2472, 'score': 37446.6746096611, 'total_duration': 38361.759313583374, 'accumulated_submission_time': 37446.6746096611, 'accumulated_eval_time': 867.0538096427917, 'accumulated_logging_time': 1.0453252792358398}
I1007 10:13:10.510598 139901538395904 logging_writer.py:48] [20662] accumulated_eval_time=867.053810, accumulated_logging_time=1.045325, accumulated_submission_time=37446.674610, global_step=20662, preemption_count=0, score=37446.674610, test/ctc_loss=0.395664, test/num_examples=2472, test/wer=0.131355, total_duration=38361.759314, train/ctc_loss=0.421987, train/wer=0.141815, validation/ctc_loss=0.631203, validation/num_examples=5348, validation/wer=0.185787
I1007 10:23:20.674446 139901530003200 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.754518, loss=1.623339
I1007 10:23:20.682601 139932355139392 pytorch_submission_base.py:86] 21000) loss = 1.623, grad_norm = 0.755
I1007 10:37:12.904438 139932355139392 spec.py:321] Evaluating on the training split.
I1007 10:37:25.382708 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 10:37:36.811271 139932355139392 spec.py:349] Evaluating on the test split.
I1007 10:37:44.137583 139932355139392 submission_runner.py:384] Time since start: 39835.41s, 	Step: 21463, 	{'train/ctc_loss': 0.4139919894506471, 'train/wer': 0.14097208624328264, 'validation/ctc_loss': 0.616669884594133, 'validation/wer': 0.18297687442668856, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3853134678043745, 'test/wer': 0.12670363374159607, 'test/num_examples': 2472, 'score': 38887.39462518692, 'total_duration': 39835.41480970383, 'accumulated_submission_time': 38887.39462518692, 'accumulated_eval_time': 898.2867007255554, 'accumulated_logging_time': 1.083444356918335}
I1007 10:37:44.163641 139901538395904 logging_writer.py:48] [21463] accumulated_eval_time=898.286701, accumulated_logging_time=1.083444, accumulated_submission_time=38887.394625, global_step=21463, preemption_count=0, score=38887.394625, test/ctc_loss=0.385313, test/num_examples=2472, test/wer=0.126704, total_duration=39835.414810, train/ctc_loss=0.413992, train/wer=0.140972, validation/ctc_loss=0.616670, validation/num_examples=5348, validation/wer=0.182977
I1007 10:38:53.218402 139901530003200 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.687587, loss=1.542380
I1007 10:38:53.222128 139932355139392 pytorch_submission_base.py:86] 21500) loss = 1.542, grad_norm = 0.688
I1007 10:53:55.078775 139901538395904 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.744789, loss=1.546880
I1007 10:53:55.090592 139932355139392 pytorch_submission_base.py:86] 22000) loss = 1.547, grad_norm = 0.745
I1007 11:01:45.606227 139932355139392 spec.py:321] Evaluating on the training split.
I1007 11:01:58.201475 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 11:02:09.840858 139932355139392 spec.py:349] Evaluating on the test split.
I1007 11:02:17.162410 139932355139392 submission_runner.py:384] Time since start: 41308.44s, 	Step: 22261, 	{'train/ctc_loss': 0.4094881612204905, 'train/wer': 0.14086330309161718, 'validation/ctc_loss': 0.6147762127662246, 'validation/wer': 0.18337276106792835, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3866734345764243, 'test/wer': 0.1294253854122235, 'test/num_examples': 2472, 'score': 40327.06483769417, 'total_duration': 41308.439687252045, 'accumulated_submission_time': 40327.06483769417, 'accumulated_eval_time': 929.8426556587219, 'accumulated_logging_time': 1.122643232345581}
I1007 11:02:17.185954 139901538395904 logging_writer.py:48] [22261] accumulated_eval_time=929.842656, accumulated_logging_time=1.122643, accumulated_submission_time=40327.064838, global_step=22261, preemption_count=0, score=40327.064838, test/ctc_loss=0.386673, test/num_examples=2472, test/wer=0.129425, total_duration=41308.439687, train/ctc_loss=0.409488, train/wer=0.140863, validation/ctc_loss=0.614776, validation/num_examples=5348, validation/wer=0.183373
I1007 11:09:28.319784 139901530003200 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.638119, loss=1.535409
I1007 11:09:28.324350 139932355139392 pytorch_submission_base.py:86] 22500) loss = 1.535, grad_norm = 0.638
I1007 11:24:33.350630 139901538395904 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.812807, loss=1.511551
I1007 11:24:33.360817 139932355139392 pytorch_submission_base.py:86] 23000) loss = 1.512, grad_norm = 0.813
I1007 11:26:18.862376 139932355139392 spec.py:321] Evaluating on the training split.
I1007 11:26:31.441714 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 11:26:42.738372 139932355139392 spec.py:349] Evaluating on the test split.
I1007 11:26:49.929483 139932355139392 submission_runner.py:384] Time since start: 42781.21s, 	Step: 23059, 	{'train/ctc_loss': 0.40107505013612615, 'train/wer': 0.13801862367556514, 'validation/ctc_loss': 0.6141132019791039, 'validation/wer': 0.18227200308984695, 'validation/num_examples': 5348, 'test/ctc_loss': 0.37435696456222983, 'test/wer': 0.12753640850648956, 'test/num_examples': 2472, 'score': 41766.94707393646, 'total_duration': 42781.20676922798, 'accumulated_submission_time': 41766.94707393646, 'accumulated_eval_time': 960.909558057785, 'accumulated_logging_time': 1.1565148830413818}
I1007 11:26:49.958494 139901538395904 logging_writer.py:48] [23059] accumulated_eval_time=960.909558, accumulated_logging_time=1.156515, accumulated_submission_time=41766.947074, global_step=23059, preemption_count=0, score=41766.947074, test/ctc_loss=0.374357, test/num_examples=2472, test/wer=0.127536, total_duration=42781.206769, train/ctc_loss=0.401075, train/wer=0.138019, validation/ctc_loss=0.614113, validation/num_examples=5348, validation/wer=0.182272
I1007 11:40:06.636581 139901530003200 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.869538, loss=1.492497
I1007 11:40:06.644800 139932355139392 pytorch_submission_base.py:86] 23500) loss = 1.492, grad_norm = 0.870
I1007 11:50:50.718569 139932355139392 spec.py:321] Evaluating on the training split.
I1007 11:51:03.173666 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 11:51:14.595281 139932355139392 spec.py:349] Evaluating on the test split.
I1007 11:51:21.740469 139932355139392 submission_runner.py:384] Time since start: 44253.02s, 	Step: 23856, 	{'train/ctc_loss': 0.395447820922064, 'train/wer': 0.13649565955224854, 'validation/ctc_loss': 0.6004000727565552, 'validation/wer': 0.17896972915560277, 'validation/num_examples': 5348, 'test/ctc_loss': 0.36360102869539973, 'test/wer': 0.1236568967968639, 'test/num_examples': 2472, 'score': 43205.981271505356, 'total_duration': 44253.01757192612, 'accumulated_submission_time': 43205.981271505356, 'accumulated_eval_time': 991.9312038421631, 'accumulated_logging_time': 1.1962718963623047}
I1007 11:51:21.766706 139901538395904 logging_writer.py:48] [23856] accumulated_eval_time=991.931204, accumulated_logging_time=1.196272, accumulated_submission_time=43205.981272, global_step=23856, preemption_count=0, score=43205.981272, test/ctc_loss=0.363601, test/num_examples=2472, test/wer=0.123657, total_duration=44253.017572, train/ctc_loss=0.395448, train/wer=0.136496, validation/ctc_loss=0.600400, validation/num_examples=5348, validation/wer=0.178970
I1007 11:55:45.443423 139901530003200 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.778983, loss=1.503645
I1007 11:55:45.450540 139932355139392 pytorch_submission_base.py:86] 24000) loss = 1.504, grad_norm = 0.779
I1007 12:10:46.191152 139901538395904 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.735123, loss=1.457745
I1007 12:10:46.195914 139932355139392 pytorch_submission_base.py:86] 24500) loss = 1.458, grad_norm = 0.735
I1007 12:15:24.066689 139932355139392 spec.py:321] Evaluating on the training split.
I1007 12:15:36.685177 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 12:15:48.104479 139932355139392 spec.py:349] Evaluating on the test split.
I1007 12:15:55.128560 139932355139392 submission_runner.py:384] Time since start: 45726.41s, 	Step: 24655, 	{'train/ctc_loss': 0.38256105122276207, 'train/wer': 0.13218240758871266, 'validation/ctc_loss': 0.5904237618042998, 'validation/wer': 0.17531984743880655, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3680156784308665, 'test/wer': 0.1240834399691264, 'test/num_examples': 2472, 'score': 44646.64861559868, 'total_duration': 45726.40583252907, 'accumulated_submission_time': 44646.64861559868, 'accumulated_eval_time': 1022.9929101467133, 'accumulated_logging_time': 1.232168436050415}
I1007 12:15:55.153380 139901538395904 logging_writer.py:48] [24655] accumulated_eval_time=1022.992910, accumulated_logging_time=1.232168, accumulated_submission_time=44646.648616, global_step=24655, preemption_count=0, score=44646.648616, test/ctc_loss=0.368016, test/num_examples=2472, test/wer=0.124083, total_duration=45726.405833, train/ctc_loss=0.382561, train/wer=0.132182, validation/ctc_loss=0.590424, validation/num_examples=5348, validation/wer=0.175320
I1007 12:26:23.508123 139901538395904 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.724560, loss=1.542713
I1007 12:26:23.516325 139932355139392 pytorch_submission_base.py:86] 25000) loss = 1.543, grad_norm = 0.725
I1007 12:39:56.179661 139932355139392 spec.py:321] Evaluating on the training split.
I1007 12:40:08.788423 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 12:40:20.455395 139932355139392 spec.py:349] Evaluating on the test split.
I1007 12:40:27.655229 139932355139392 submission_runner.py:384] Time since start: 47198.93s, 	Step: 25451, 	{'train/ctc_loss': 0.37376723084994934, 'train/wer': 0.12922350586341189, 'validation/ctc_loss': 0.57840333110433, 'validation/wer': 0.17166996572201032, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3563313308519904, 'test/wer': 0.11910710295939715, 'test/num_examples': 2472, 'score': 46085.866148233414, 'total_duration': 47198.93251132965, 'accumulated_submission_time': 46085.866148233414, 'accumulated_eval_time': 1054.4684133529663, 'accumulated_logging_time': 1.270362138748169}
I1007 12:40:27.686020 139901538395904 logging_writer.py:48] [25451] accumulated_eval_time=1054.468413, accumulated_logging_time=1.270362, accumulated_submission_time=46085.866148, global_step=25451, preemption_count=0, score=46085.866148, test/ctc_loss=0.356331, test/num_examples=2472, test/wer=0.119107, total_duration=47198.932511, train/ctc_loss=0.373767, train/wer=0.129224, validation/ctc_loss=0.578403, validation/num_examples=5348, validation/wer=0.171670
I1007 12:41:57.601351 139901530003200 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.799789, loss=1.428844
I1007 12:41:57.605344 139932355139392 pytorch_submission_base.py:86] 25500) loss = 1.429, grad_norm = 0.800
I1007 12:57:03.565969 139901538395904 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.744707, loss=1.487851
I1007 12:57:03.572929 139932355139392 pytorch_submission_base.py:86] 26000) loss = 1.488, grad_norm = 0.745
I1007 13:04:29.525581 139932355139392 spec.py:321] Evaluating on the training split.
I1007 13:04:42.236316 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 13:04:53.646436 139932355139392 spec.py:349] Evaluating on the test split.
I1007 13:05:00.987930 139932355139392 submission_runner.py:384] Time since start: 48672.27s, 	Step: 26248, 	{'train/ctc_loss': 0.37283165492444403, 'train/wer': 0.12724365250310032, 'validation/ctc_loss': 0.5780645657524613, 'validation/wer': 0.17058851928740404, 'validation/num_examples': 5348, 'test/ctc_loss': 0.35782237966965613, 'test/wer': 0.11863993662787155, 'test/num_examples': 2472, 'score': 47525.9236330986, 'total_duration': 48672.26515054703, 'accumulated_submission_time': 47525.9236330986, 'accumulated_eval_time': 1085.9304928779602, 'accumulated_logging_time': 1.3144400119781494}
I1007 13:05:01.016541 139901538395904 logging_writer.py:48] [26248] accumulated_eval_time=1085.930493, accumulated_logging_time=1.314440, accumulated_submission_time=47525.923633, global_step=26248, preemption_count=0, score=47525.923633, test/ctc_loss=0.357822, test/num_examples=2472, test/wer=0.118640, total_duration=48672.265151, train/ctc_loss=0.372832, train/wer=0.127244, validation/ctc_loss=0.578065, validation/num_examples=5348, validation/wer=0.170589
I1007 13:12:35.195010 139901530003200 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.775590, loss=1.481438
I1007 13:12:35.199673 139932355139392 pytorch_submission_base.py:86] 26500) loss = 1.481, grad_norm = 0.776
I1007 13:27:40.210463 139901538395904 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.755001, loss=1.458414
I1007 13:27:40.217844 139932355139392 pytorch_submission_base.py:86] 27000) loss = 1.458, grad_norm = 0.755
I1007 13:29:02.143356 139932355139392 spec.py:321] Evaluating on the training split.
I1007 13:29:14.654088 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 13:29:26.016016 139932355139392 spec.py:349] Evaluating on the test split.
I1007 13:29:33.222913 139932355139392 submission_runner.py:384] Time since start: 50144.50s, 	Step: 27046, 	{'train/ctc_loss': 0.35885999751650294, 'train/wer': 0.12571524922220045, 'validation/ctc_loss': 0.5662491307671539, 'validation/wer': 0.16999951721141313, 'validation/num_examples': 5348, 'test/ctc_loss': 0.34174299047519197, 'test/wer': 0.11453699754229886, 'test/num_examples': 2472, 'score': 48965.21668720245, 'total_duration': 50144.50018072128, 'accumulated_submission_time': 48965.21668720245, 'accumulated_eval_time': 1117.0099346637726, 'accumulated_logging_time': 1.3541572093963623}
I1007 13:29:33.248309 139901538395904 logging_writer.py:48] [27046] accumulated_eval_time=1117.009935, accumulated_logging_time=1.354157, accumulated_submission_time=48965.216687, global_step=27046, preemption_count=0, score=48965.216687, test/ctc_loss=0.341743, test/num_examples=2472, test/wer=0.114537, total_duration=50144.500181, train/ctc_loss=0.358860, train/wer=0.125715, validation/ctc_loss=0.566249, validation/num_examples=5348, validation/wer=0.170000
I1007 13:43:15.855919 139901530003200 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.713894, loss=1.429387
I1007 13:43:15.860566 139932355139392 pytorch_submission_base.py:86] 27500) loss = 1.429, grad_norm = 0.714
I1007 13:53:35.172349 139932355139392 spec.py:321] Evaluating on the training split.
I1007 13:53:47.449085 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 13:53:59.022590 139932355139392 spec.py:349] Evaluating on the test split.
I1007 13:54:06.190486 139932355139392 submission_runner.py:384] Time since start: 51617.47s, 	Step: 27844, 	{'train/ctc_loss': 0.35172020841880064, 'train/wer': 0.12108652611883472, 'validation/ctc_loss': 0.5640072752630851, 'validation/wer': 0.16863805339641771, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3384356450416156, 'test/wer': 0.1146385554404566, 'test/num_examples': 2472, 'score': 50405.3672106266, 'total_duration': 51617.46774625778, 'accumulated_submission_time': 50405.3672106266, 'accumulated_eval_time': 1148.0282263755798, 'accumulated_logging_time': 1.390019416809082}
I1007 13:54:06.216064 139901538395904 logging_writer.py:48] [27844] accumulated_eval_time=1148.028226, accumulated_logging_time=1.390019, accumulated_submission_time=50405.367211, global_step=27844, preemption_count=0, score=50405.367211, test/ctc_loss=0.338436, test/num_examples=2472, test/wer=0.114639, total_duration=51617.467746, train/ctc_loss=0.351720, train/wer=0.121087, validation/ctc_loss=0.564007, validation/num_examples=5348, validation/wer=0.168638
I1007 13:58:48.885836 139901530003200 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.670565, loss=1.414106
I1007 13:58:48.890652 139932355139392 pytorch_submission_base.py:86] 28000) loss = 1.414, grad_norm = 0.671
I1007 14:13:50.194467 139901538395904 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.761883, loss=1.475441
I1007 14:13:50.199148 139932355139392 pytorch_submission_base.py:86] 28500) loss = 1.475, grad_norm = 0.762
I1007 14:18:07.288801 139932355139392 spec.py:321] Evaluating on the training split.
I1007 14:18:19.898640 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 14:18:31.375864 139932355139392 spec.py:349] Evaluating on the test split.
I1007 14:18:38.637279 139932355139392 submission_runner.py:384] Time since start: 53089.91s, 	Step: 28643, 	{'train/ctc_loss': 0.3512832655104137, 'train/wer': 0.12197310880490829, 'validation/ctc_loss': 0.5578812930103476, 'validation/wer': 0.1663496354946169, 'validation/num_examples': 5348, 'test/ctc_loss': 0.33963831839957415, 'test/wer': 0.11256677431803871, 'test/num_examples': 2472, 'score': 51844.77876138687, 'total_duration': 53089.91455078125, 'accumulated_submission_time': 51844.77876138687, 'accumulated_eval_time': 1179.3765139579773, 'accumulated_logging_time': 1.4250478744506836}
I1007 14:18:38.664660 139901538395904 logging_writer.py:48] [28643] accumulated_eval_time=1179.376514, accumulated_logging_time=1.425048, accumulated_submission_time=51844.778761, global_step=28643, preemption_count=0, score=51844.778761, test/ctc_loss=0.339638, test/num_examples=2472, test/wer=0.112567, total_duration=53089.914551, train/ctc_loss=0.351283, train/wer=0.121973, validation/ctc_loss=0.557881, validation/num_examples=5348, validation/wer=0.166350
I1007 14:29:28.364095 139901538395904 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.721886, loss=1.390190
I1007 14:29:28.374775 139932355139392 pytorch_submission_base.py:86] 29000) loss = 1.390, grad_norm = 0.722
I1007 14:42:40.647021 139932355139392 spec.py:321] Evaluating on the training split.
I1007 14:42:53.293956 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 14:43:05.199895 139932355139392 spec.py:349] Evaluating on the test split.
I1007 14:43:12.503284 139932355139392 submission_runner.py:384] Time since start: 54563.78s, 	Step: 29440, 	{'train/ctc_loss': 0.3415163359857873, 'train/wer': 0.1170887452951287, 'validation/ctc_loss': 0.5439006735671589, 'validation/wer': 0.15968715299570319, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3287753947835344, 'test/wer': 0.10854508155099223, 'test/num_examples': 2472, 'score': 53284.984095573425, 'total_duration': 54563.78055214882, 'accumulated_submission_time': 53284.984095573425, 'accumulated_eval_time': 1211.2326037883759, 'accumulated_logging_time': 1.462498664855957}
I1007 14:43:12.536214 139901538395904 logging_writer.py:48] [29440] accumulated_eval_time=1211.232604, accumulated_logging_time=1.462499, accumulated_submission_time=53284.984096, global_step=29440, preemption_count=0, score=53284.984096, test/ctc_loss=0.328775, test/num_examples=2472, test/wer=0.108545, total_duration=54563.780552, train/ctc_loss=0.341516, train/wer=0.117089, validation/ctc_loss=0.543901, validation/num_examples=5348, validation/wer=0.159687
I1007 14:45:03.698098 139901530003200 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.799392, loss=1.487859
I1007 14:45:03.701961 139932355139392 pytorch_submission_base.py:86] 29500) loss = 1.488, grad_norm = 0.799
I1007 15:00:06.024723 139901538395904 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.688201, loss=1.437990
I1007 15:00:06.032523 139932355139392 pytorch_submission_base.py:86] 30000) loss = 1.438, grad_norm = 0.688
I1007 15:07:13.531234 139932355139392 spec.py:321] Evaluating on the training split.
I1007 15:07:26.093440 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 15:07:38.208319 139932355139392 spec.py:349] Evaluating on the test split.
I1007 15:07:45.335064 139932355139392 submission_runner.py:384] Time since start: 56036.61s, 	Step: 30238, 	{'train/ctc_loss': 0.32990548407849546, 'train/wer': 0.11388508147858059, 'validation/ctc_loss': 0.5404837840001507, 'validation/wer': 0.1599864819195674, 'validation/num_examples': 5348, 'test/ctc_loss': 0.32092382976321054, 'test/wer': 0.10757012572867793, 'test/num_examples': 2472, 'score': 54724.179874658585, 'total_duration': 56036.612189769745, 'accumulated_submission_time': 54724.179874658585, 'accumulated_eval_time': 1243.0361545085907, 'accumulated_logging_time': 1.506664514541626}
I1007 15:07:45.359564 139901538395904 logging_writer.py:48] [30238] accumulated_eval_time=1243.036155, accumulated_logging_time=1.506665, accumulated_submission_time=54724.179875, global_step=30238, preemption_count=0, score=54724.179875, test/ctc_loss=0.320924, test/num_examples=2472, test/wer=0.107570, total_duration=56036.612190, train/ctc_loss=0.329905, train/wer=0.113885, validation/ctc_loss=0.540484, validation/num_examples=5348, validation/wer=0.159986
I1007 15:15:38.713997 139901530003200 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.800251, loss=1.417160
I1007 15:15:38.719545 139932355139392 pytorch_submission_base.py:86] 30500) loss = 1.417, grad_norm = 0.800
I1007 15:30:45.164182 139901538395904 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.759971, loss=1.438690
I1007 15:30:45.171626 139932355139392 pytorch_submission_base.py:86] 31000) loss = 1.439, grad_norm = 0.760
I1007 15:31:46.039099 139932355139392 spec.py:321] Evaluating on the training split.
I1007 15:31:58.433438 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 15:32:10.234811 139932355139392 spec.py:349] Evaluating on the test split.
I1007 15:32:17.267438 139932355139392 submission_runner.py:384] Time since start: 57508.54s, 	Step: 31034, 	{'train/ctc_loss': 0.32536963208644265, 'train/wer': 0.11328133498683723, 'validation/ctc_loss': 0.5303043413765823, 'validation/wer': 0.15872157582194757, 'validation/num_examples': 5348, 'test/ctc_loss': 0.322294129863217, 'test/wer': 0.10968253001035891, 'test/num_examples': 2472, 'score': 56163.063096284866, 'total_duration': 57508.544682979584, 'accumulated_submission_time': 56163.063096284866, 'accumulated_eval_time': 1274.2642486095428, 'accumulated_logging_time': 1.5409750938415527}
I1007 15:32:17.292369 139901538395904 logging_writer.py:48] [31034] accumulated_eval_time=1274.264249, accumulated_logging_time=1.540975, accumulated_submission_time=56163.063096, global_step=31034, preemption_count=0, score=56163.063096, test/ctc_loss=0.322294, test/num_examples=2472, test/wer=0.109683, total_duration=57508.544683, train/ctc_loss=0.325370, train/wer=0.113281, validation/ctc_loss=0.530304, validation/num_examples=5348, validation/wer=0.158722
I1007 15:46:17.643326 139901530003200 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.879795, loss=1.428176
I1007 15:46:17.648106 139932355139392 pytorch_submission_base.py:86] 31500) loss = 1.428, grad_norm = 0.880
I1007 15:56:18.966002 139932355139392 spec.py:321] Evaluating on the training split.
I1007 15:56:31.243758 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 15:56:42.746555 139932355139392 spec.py:349] Evaluating on the test split.
I1007 15:56:50.267415 139932355139392 submission_runner.py:384] Time since start: 58981.54s, 	Step: 31834, 	{'train/ctc_loss': 0.3130623097115753, 'train/wer': 0.10834801905880817, 'validation/ctc_loss': 0.5201464824128491, 'validation/wer': 0.15367160720320572, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3118973401509775, 'test/wer': 0.1028578392541588, 'test/num_examples': 2472, 'score': 57603.0136950016, 'total_duration': 58981.54469513893, 'accumulated_submission_time': 57603.0136950016, 'accumulated_eval_time': 1305.565472126007, 'accumulated_logging_time': 1.5756821632385254}
I1007 15:56:50.298869 139901538395904 logging_writer.py:48] [31834] accumulated_eval_time=1305.565472, accumulated_logging_time=1.575682, accumulated_submission_time=57603.013695, global_step=31834, preemption_count=0, score=57603.013695, test/ctc_loss=0.311897, test/num_examples=2472, test/wer=0.102858, total_duration=58981.544695, train/ctc_loss=0.313062, train/wer=0.108348, validation/ctc_loss=0.520146, validation/num_examples=5348, validation/wer=0.153672
I1007 16:01:55.686761 139901538395904 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.969153, loss=1.404236
I1007 16:01:55.697679 139932355139392 pytorch_submission_base.py:86] 32000) loss = 1.404, grad_norm = 0.969
I1007 16:16:59.587949 139901530003200 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.707282, loss=1.407872
I1007 16:16:59.593206 139932355139392 pytorch_submission_base.py:86] 32500) loss = 1.408, grad_norm = 0.707
I1007 16:20:51.546044 139932355139392 spec.py:321] Evaluating on the training split.
I1007 16:21:04.475927 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 16:21:15.826650 139932355139392 spec.py:349] Evaluating on the test split.
I1007 16:21:23.175311 139932355139392 submission_runner.py:384] Time since start: 60454.45s, 	Step: 32630, 	{'train/ctc_loss': 0.30947861501388385, 'train/wer': 0.1079727171855623, 'validation/ctc_loss': 0.5126300709827707, 'validation/wer': 0.15132525467097957, 'validation/num_examples': 5348, 'test/ctc_loss': 0.30816874778211495, 'test/wer': 0.10425933824873561, 'test/num_examples': 2472, 'score': 59042.473855018616, 'total_duration': 60454.45255613327, 'accumulated_submission_time': 59042.473855018616, 'accumulated_eval_time': 1337.1945252418518, 'accumulated_logging_time': 1.6176879405975342}
I1007 16:21:23.208513 139901538395904 logging_writer.py:48] [32630] accumulated_eval_time=1337.194525, accumulated_logging_time=1.617688, accumulated_submission_time=59042.473855, global_step=32630, preemption_count=0, score=59042.473855, test/ctc_loss=0.308169, test/num_examples=2472, test/wer=0.104259, total_duration=60454.452556, train/ctc_loss=0.309479, train/wer=0.107973, validation/ctc_loss=0.512630, validation/num_examples=5348, validation/wer=0.151325
I1007 16:32:35.212584 139901538395904 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.854271, loss=1.374077
I1007 16:32:35.220518 139932355139392 pytorch_submission_base.py:86] 33000) loss = 1.374, grad_norm = 0.854
I1007 16:45:24.177618 139932355139392 spec.py:321] Evaluating on the training split.
I1007 16:45:36.683778 139932355139392 spec.py:333] Evaluating on the validation split.
I1007 16:45:48.279946 139932355139392 spec.py:349] Evaluating on the test split.
I1007 16:45:55.711121 139932355139392 submission_runner.py:384] Time since start: 61926.99s, 	Step: 33426, 	{'train/ctc_loss': 0.3012454885962563, 'train/wer': 0.10496486304201205, 'validation/ctc_loss': 0.5104001845991561, 'validation/wer': 0.15108386037754068, 'validation/num_examples': 5348, 'test/ctc_loss': 0.2993975417768888, 'test/wer': 0.10011577600389983, 'test/num_examples': 2472, 'score': 60481.65323495865, 'total_duration': 61926.98834323883, 'accumulated_submission_time': 60481.65323495865, 'accumulated_eval_time': 1368.7278490066528, 'accumulated_logging_time': 1.6608474254608154}
I1007 16:45:55.743885 139901538395904 logging_writer.py:48] [33426] accumulated_eval_time=1368.727849, accumulated_logging_time=1.660847, accumulated_submission_time=60481.653235, global_step=33426, preemption_count=0, score=60481.653235, test/ctc_loss=0.299398, test/num_examples=2472, test/wer=0.100116, total_duration=61926.988343, train/ctc_loss=0.301245, train/wer=0.104965, validation/ctc_loss=0.510400, validation/num_examples=5348, validation/wer=0.151084
I1007 16:48:12.327760 139901530003200 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.722193, loss=1.399610
I1007 16:48:12.332099 139932355139392 pytorch_submission_base.py:86] 33500) loss = 1.400, grad_norm = 0.722
I1007 16:55:43.970515 139901538395904 logging_writer.py:48] [33751] global_step=33751, preemption_count=0, score=61069.024053
I1007 16:55:44.672370 139932355139392 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/targets_check_conformer/adamw_run_0/librispeech_conformer_pytorch/trial_1/checkpoint_33751.
I1007 16:55:44.811108 139932355139392 submission_runner.py:552] Tuning trial 1/1
I1007 16:55:44.811380 139932355139392 submission_runner.py:553] Hyperparameters: Hyperparameters(learning_rate=0.002106913873888147, beta1=0.8231189937738506, beta2=0.8774571227688758, warmup_steps=1199, weight_decay=0.27590534177690645)
I1007 16:55:44.812817 139932355139392 submission_runner.py:554] Metrics: {'eval_results': [(1, {'train/ctc_loss': 31.847735355843593, 'train/wer': 2.028223788699606, 'validation/ctc_loss': 30.695358021900745, 'validation/wer': 2.0094336889875923, 'validation/num_examples': 5348, 'test/ctc_loss': 30.763013742822118, 'test/wer': 2.071435825564154, 'test/num_examples': 2472, 'score': 12.51418662071228, 'total_duration': 56.85322308540344, 'accumulated_submission_time': 12.51418662071228, 'accumulated_eval_time': 43.7703800201416, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (815, {'train/ctc_loss': 4.896786117505857, 'train/wer': 0.8601864543219546, 'validation/ctc_loss': 5.0633872846343175, 'validation/wer': 0.8349249263747405, 'validation/num_examples': 5348, 'test/ctc_loss': 4.909565133234402, 'test/wer': 0.8227205329758496, 'test/num_examples': 2472, 'score': 1451.6175451278687, 'total_duration': 1527.4264228343964, 'accumulated_submission_time': 1451.6175451278687, 'accumulated_eval_time': 73.5019679069519, 'accumulated_logging_time': 0.03444314002990723, 'global_step': 815, 'preemption_count': 0}), (1633, {'train/ctc_loss': 3.1465044991134, 'train/wer': 0.6652851206405151, 'validation/ctc_loss': 3.404768183644766, 'validation/wer': 0.6659489209675084, 'validation/num_examples': 5348, 'test/ctc_loss': 3.0245072262726627, 'test/wer': 0.5980744622509293, 'test/num_examples': 2472, 'score': 2891.8515605926514, 'total_duration': 3000.2073078155518, 'accumulated_submission_time': 2891.8515605926514, 'accumulated_eval_time': 104.1828248500824, 'accumulated_logging_time': 0.07716250419616699, 'global_step': 1633, 'preemption_count': 0}), (2455, {'train/ctc_loss': 1.3503556359278108, 'train/wer': 0.38643582881883254, 'validation/ctc_loss': 1.5514714365770041, 'validation/wer': 0.39827161685897744, 'validation/num_examples': 5348, 'test/ctc_loss': 1.2016922462739532, 'test/wer': 0.34578433164747224, 'test/num_examples': 2472, 'score': 4330.894143819809, 'total_duration': 4473.071118116379, 'accumulated_submission_time': 4330.894143819809, 'accumulated_eval_time': 136.08687496185303, 'accumulated_logging_time': 0.11427545547485352, 'global_step': 2455, 'preemption_count': 0}), (3241, {'train/ctc_loss': 0.8829941269109366, 'train/wer': 0.2890531514479037, 'validation/ctc_loss': 1.0832962486814346, 'validation/wer': 0.3155795876985468, 'validation/num_examples': 5348, 'test/ctc_loss': 0.7975783719917414, 'test/wer': 0.2608209940487072, 'test/num_examples': 2472, 'score': 5771.036632061005, 'total_duration': 5946.638638496399, 'accumulated_submission_time': 5771.036632061005, 'accumulated_eval_time': 167.68099808692932, 'accumulated_logging_time': 0.15583086013793945, 'global_step': 3241, 'preemption_count': 0}), (4030, {'train/ctc_loss': 0.7314566261057072, 'train/wer': 0.2432282488088245, 'validation/ctc_loss': 0.9405174937525116, 'validation/wer': 0.2764930237049196, 'validation/num_examples': 5348, 'test/ctc_loss': 0.654709477224337, 'test/wer': 0.21329189771088497, 'test/num_examples': 2472, 'score': 7211.425891637802, 'total_duration': 7420.902430295944, 'accumulated_submission_time': 7211.425891637802, 'accumulated_eval_time': 199.80465507507324, 'accumulated_logging_time': 0.19401812553405762, 'global_step': 4030, 'preemption_count': 0}), (4822, {'train/ctc_loss': 0.6526676826684116, 'train/wer': 0.21608141331070643, 'validation/ctc_loss': 0.8584893831939421, 'validation/wer': 0.25384058320861297, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5802005371314278, 'test/wer': 0.19208660857554893, 'test/num_examples': 2472, 'score': 8650.586411476135, 'total_duration': 8893.916859865189, 'accumulated_submission_time': 8650.586411476135, 'accumulated_eval_time': 231.7578477859497, 'accumulated_logging_time': 0.2341477870941162, 'global_step': 4822, 'preemption_count': 0}), (5611, {'train/ctc_loss': 0.6091326895170996, 'train/wer': 0.2045721558644997, 'validation/ctc_loss': 0.8202054646687261, 'validation/wer': 0.24505383092743688, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5513427781631073, 'test/wer': 0.1848759978063494, 'test/num_examples': 2472, 'score': 10090.206138372421, 'total_duration': 10367.316051721573, 'accumulated_submission_time': 10090.206138372421, 'accumulated_eval_time': 263.61484479904175, 'accumulated_logging_time': 0.27373290061950684, 'global_step': 5611, 'preemption_count': 0}), (6402, {'train/ctc_loss': 0.5800435120547082, 'train/wer': 0.19527119639710203, 'validation/ctc_loss': 0.7908566417238045, 'validation/wer': 0.23395934920098488, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5259389718691528, 'test/wer': 0.17604046066662604, 'test/num_examples': 2472, 'score': 11530.675481796265, 'total_duration': 11841.590258359909, 'accumulated_submission_time': 11530.675481796265, 'accumulated_eval_time': 295.54734325408936, 'accumulated_logging_time': 0.31284284591674805, 'global_step': 6402, 'preemption_count': 0}), (7192, {'train/ctc_loss': 0.5669485216835567, 'train/wer': 0.19100145769423232, 'validation/ctc_loss': 0.7873705372840064, 'validation/wer': 0.23284893545116594, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5104450791180076, 'test/wer': 0.17100318891800215, 'test/num_examples': 2472, 'score': 12970.172096014023, 'total_duration': 13315.139740228653, 'accumulated_submission_time': 12970.172096014023, 'accumulated_eval_time': 327.8530020713806, 'accumulated_logging_time': 0.3544793128967285, 'global_step': 7192, 'preemption_count': 0}), (7979, {'train/ctc_loss': 0.5510059858211814, 'train/wer': 0.18587777125078866, 'validation/ctc_loss': 0.761068640355008, 'validation/wer': 0.2280596726693381, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5031694585134525, 'test/wer': 0.16698149615095567, 'test/num_examples': 2472, 'score': 14409.625405550003, 'total_duration': 14788.40966463089, 'accumulated_submission_time': 14409.625405550003, 'accumulated_eval_time': 359.7365891933441, 'accumulated_logging_time': 0.396059513092041, 'global_step': 7979, 'preemption_count': 0}), (8763, {'train/ctc_loss': 0.5333651045781106, 'train/wer': 0.17851315188303635, 'validation/ctc_loss': 0.7334053050281294, 'validation/wer': 0.21694587939941098, 'validation/num_examples': 5348, 'test/ctc_loss': 0.48139073488612166, 'test/wer': 0.1590396685150204, 'test/num_examples': 2472, 'score': 15848.628237009048, 'total_duration': 16261.83667087555, 'accumulated_submission_time': 15848.628237009048, 'accumulated_eval_time': 392.2522087097168, 'accumulated_logging_time': 0.4399905204772949, 'global_step': 8763, 'preemption_count': 0}), (9549, {'train/ctc_loss': 0.5298267570105816, 'train/wer': 0.17871983987120074, 'validation/ctc_loss': 0.7449853309599156, 'validation/wer': 0.22006469367064163, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4844181479450287, 'test/wer': 0.16253326021164666, 'test/num_examples': 2472, 'score': 17288.262873888016, 'total_duration': 17736.04589653015, 'accumulated_submission_time': 17288.262873888016, 'accumulated_eval_time': 425.0559959411621, 'accumulated_logging_time': 0.47687745094299316, 'global_step': 9549, 'preemption_count': 0}), (10337, {'train/ctc_loss': 0.5161313939453529, 'train/wer': 0.175483541109153, 'validation/ctc_loss': 0.7275638346550382, 'validation/wer': 0.2150726596823251, 'validation/num_examples': 5348, 'test/ctc_loss': 0.47310587578230856, 'test/wer': 0.15832876322791622, 'test/num_examples': 2472, 'score': 18727.216140031815, 'total_duration': 19209.186690568924, 'accumulated_submission_time': 18727.216140031815, 'accumulated_eval_time': 457.352858543396, 'accumulated_logging_time': 0.5146946907043457, 'global_step': 10337, 'preemption_count': 0}), (11127, {'train/ctc_loss': 0.523792145283729, 'train/wer': 0.17783869634271043, 'validation/ctc_loss': 0.7399534440457354, 'validation/wer': 0.2186163279100082, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4761092449512872, 'test/wer': 0.15932403062986208, 'test/num_examples': 2472, 'score': 20166.62866616249, 'total_duration': 20681.95261001587, 'accumulated_submission_time': 20166.62866616249, 'accumulated_eval_time': 488.9197039604187, 'accumulated_logging_time': 0.5496513843536377, 'global_step': 11127, 'preemption_count': 0}), (11918, {'train/ctc_loss': 0.5150856552194123, 'train/wer': 0.17288906294193154, 'validation/ctc_loss': 0.7280276871264064, 'validation/wer': 0.21274561869357408, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4689193153590554, 'test/wer': 0.15097597140129587, 'test/num_examples': 2472, 'score': 21605.763298988342, 'total_duration': 22155.148891448975, 'accumulated_submission_time': 21605.763298988342, 'accumulated_eval_time': 521.0747001171112, 'accumulated_logging_time': 0.5906224250793457, 'global_step': 11918, 'preemption_count': 0}), (12708, {'train/ctc_loss': 0.4987111031812495, 'train/wer': 0.16971259491329982, 'validation/ctc_loss': 0.7021680590089411, 'validation/wer': 0.20841983295514893, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4564603966384928, 'test/wer': 0.1525602746125566, 'test/num_examples': 2472, 'score': 23045.742280721664, 'total_duration': 23628.785950422287, 'accumulated_submission_time': 23045.742280721664, 'accumulated_eval_time': 552.8385345935822, 'accumulated_logging_time': 0.6443760395050049, 'global_step': 12708, 'preemption_count': 0}), (13495, {'train/ctc_loss': 0.4861341613917077, 'train/wer': 0.1655081261014294, 'validation/ctc_loss': 0.6935937048705294, 'validation/wer': 0.20582243035774633, 'validation/num_examples': 5348, 'test/ctc_loss': 0.43975684923220854, 'test/wer': 0.1448824975118315, 'test/num_examples': 2472, 'score': 24485.283011436462, 'total_duration': 25102.187395572662, 'accumulated_submission_time': 24485.283011436462, 'accumulated_eval_time': 584.8286349773407, 'accumulated_logging_time': 0.6823859214782715, 'global_step': 13495, 'preemption_count': 0}), (14287, {'train/ctc_loss': 0.47519956975320987, 'train/wer': 0.16184213389030308, 'validation/ctc_loss': 0.688703043766953, 'validation/wer': 0.20483754164051562, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4332222038518614, 'test/wer': 0.14490280909146305, 'test/num_examples': 2472, 'score': 25925.32388472557, 'total_duration': 26574.94177341461, 'accumulated_submission_time': 25925.32388472557, 'accumulated_eval_time': 615.813844203949, 'accumulated_logging_time': 0.7272837162017822, 'global_step': 14287, 'preemption_count': 0}), (15084, {'train/ctc_loss': 0.4759622067693518, 'train/wer': 0.1629027696190414, 'validation/ctc_loss': 0.6820636647327707, 'validation/wer': 0.20423888379278715, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4390068008419898, 'test/wer': 0.14677147441756547, 'test/num_examples': 2472, 'score': 27365.50640487671, 'total_duration': 28048.234255075455, 'accumulated_submission_time': 27365.50640487671, 'accumulated_eval_time': 647.148579120636, 'accumulated_logging_time': 0.7639777660369873, 'global_step': 15084, 'preemption_count': 0}), (15886, {'train/ctc_loss': 0.4671631682980332, 'train/wer': 0.160090725148489, 'validation/ctc_loss': 0.6705689433111061, 'validation/wer': 0.20034760778255203, 'validation/num_examples': 5348, 'test/ctc_loss': 0.42642519275437124, 'test/wer': 0.1429325858672029, 'test/num_examples': 2472, 'score': 28805.971977472305, 'total_duration': 29521.668743371964, 'accumulated_submission_time': 28805.971977472305, 'accumulated_eval_time': 678.3066642284393, 'accumulated_logging_time': 0.8004999160766602, 'global_step': 15886, 'preemption_count': 0}), (16682, {'train/ctc_loss': 0.46418503790511517, 'train/wer': 0.1569740878532733, 'validation/ctc_loss': 0.6746556621395922, 'validation/wer': 0.19788538598947522, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4201800569794826, 'test/wer': 0.13862653098531472, 'test/num_examples': 2472, 'score': 30246.523585796356, 'total_duration': 30995.286702394485, 'accumulated_submission_time': 30246.523585796356, 'accumulated_eval_time': 709.5995194911957, 'accumulated_logging_time': 0.8372371196746826, 'global_step': 16682, 'preemption_count': 0}), (17481, {'train/ctc_loss': 0.4559869018840673, 'train/wer': 0.15681635228335836, 'validation/ctc_loss': 0.6653841557885021, 'validation/wer': 0.19785641867426254, 'validation/num_examples': 5348, 'test/ctc_loss': 0.42495468457642427, 'test/wer': 0.14049519631141713, 'test/num_examples': 2472, 'score': 31686.318539857864, 'total_duration': 32468.651089429855, 'accumulated_submission_time': 31686.318539857864, 'accumulated_eval_time': 741.4124627113342, 'accumulated_logging_time': 0.8720552921295166, 'global_step': 17481, 'preemption_count': 0}), (18276, {'train/ctc_loss': 0.440777151276331, 'train/wer': 0.14957139438243805, 'validation/ctc_loss': 0.6549465922148131, 'validation/wer': 0.1909815091971226, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4126507909784502, 'test/wer': 0.13639225722584444, 'test/num_examples': 2472, 'score': 33126.71435880661, 'total_duration': 33942.3997695446, 'accumulated_submission_time': 33126.71435880661, 'accumulated_eval_time': 772.9813866615295, 'accumulated_logging_time': 0.9183425903320312, 'global_step': 18276, 'preemption_count': 0}), (19070, {'train/ctc_loss': 0.44438900251570623, 'train/wer': 0.15135543806975177, 'validation/ctc_loss': 0.6546365723735433, 'validation/wer': 0.1925843673055569, 'validation/num_examples': 5348, 'test/ctc_loss': 0.41069567492257564, 'test/wer': 0.13750939410557958, 'test/num_examples': 2472, 'score': 34567.40010333061, 'total_duration': 35416.27900147438, 'accumulated_submission_time': 34567.40010333061, 'accumulated_eval_time': 804.3810205459595, 'accumulated_logging_time': 0.9632787704467773, 'global_step': 19070, 'preemption_count': 0}), (19866, {'train/ctc_loss': 0.43155406945993685, 'train/wer': 0.14650914866305506, 'validation/ctc_loss': 0.6443166397459564, 'validation/wer': 0.1898131608168783, 'validation/num_examples': 5348, 'test/ctc_loss': 0.40376317121265887, 'test/wer': 0.13326427396258608, 'test/num_examples': 2472, 'score': 36006.63622736931, 'total_duration': 36888.392409563065, 'accumulated_submission_time': 36006.63622736931, 'accumulated_eval_time': 835.494616985321, 'accumulated_logging_time': 1.004608392715454, 'global_step': 19866, 'preemption_count': 0}), (20662, {'train/ctc_loss': 0.4219872553373996, 'train/wer': 0.14181515566869005, 'validation/ctc_loss': 0.6312034381592827, 'validation/wer': 0.1857867040023174, 'validation/num_examples': 5348, 'test/ctc_loss': 0.39566388355700366, 'test/wer': 0.13135498547722058, 'test/num_examples': 2472, 'score': 37446.6746096611, 'total_duration': 38361.759313583374, 'accumulated_submission_time': 37446.6746096611, 'accumulated_eval_time': 867.0538096427917, 'accumulated_logging_time': 1.0453252792358398, 'global_step': 20662, 'preemption_count': 0}), (21463, {'train/ctc_loss': 0.4139919894506471, 'train/wer': 0.14097208624328264, 'validation/ctc_loss': 0.616669884594133, 'validation/wer': 0.18297687442668856, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3853134678043745, 'test/wer': 0.12670363374159607, 'test/num_examples': 2472, 'score': 38887.39462518692, 'total_duration': 39835.41480970383, 'accumulated_submission_time': 38887.39462518692, 'accumulated_eval_time': 898.2867007255554, 'accumulated_logging_time': 1.083444356918335, 'global_step': 21463, 'preemption_count': 0}), (22261, {'train/ctc_loss': 0.4094881612204905, 'train/wer': 0.14086330309161718, 'validation/ctc_loss': 0.6147762127662246, 'validation/wer': 0.18337276106792835, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3866734345764243, 'test/wer': 0.1294253854122235, 'test/num_examples': 2472, 'score': 40327.06483769417, 'total_duration': 41308.439687252045, 'accumulated_submission_time': 40327.06483769417, 'accumulated_eval_time': 929.8426556587219, 'accumulated_logging_time': 1.122643232345581, 'global_step': 22261, 'preemption_count': 0}), (23059, {'train/ctc_loss': 0.40107505013612615, 'train/wer': 0.13801862367556514, 'validation/ctc_loss': 0.6141132019791039, 'validation/wer': 0.18227200308984695, 'validation/num_examples': 5348, 'test/ctc_loss': 0.37435696456222983, 'test/wer': 0.12753640850648956, 'test/num_examples': 2472, 'score': 41766.94707393646, 'total_duration': 42781.20676922798, 'accumulated_submission_time': 41766.94707393646, 'accumulated_eval_time': 960.909558057785, 'accumulated_logging_time': 1.1565148830413818, 'global_step': 23059, 'preemption_count': 0}), (23856, {'train/ctc_loss': 0.395447820922064, 'train/wer': 0.13649565955224854, 'validation/ctc_loss': 0.6004000727565552, 'validation/wer': 0.17896972915560277, 'validation/num_examples': 5348, 'test/ctc_loss': 0.36360102869539973, 'test/wer': 0.1236568967968639, 'test/num_examples': 2472, 'score': 43205.981271505356, 'total_duration': 44253.01757192612, 'accumulated_submission_time': 43205.981271505356, 'accumulated_eval_time': 991.9312038421631, 'accumulated_logging_time': 1.1962718963623047, 'global_step': 23856, 'preemption_count': 0}), (24655, {'train/ctc_loss': 0.38256105122276207, 'train/wer': 0.13218240758871266, 'validation/ctc_loss': 0.5904237618042998, 'validation/wer': 0.17531984743880655, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3680156784308665, 'test/wer': 0.1240834399691264, 'test/num_examples': 2472, 'score': 44646.64861559868, 'total_duration': 45726.40583252907, 'accumulated_submission_time': 44646.64861559868, 'accumulated_eval_time': 1022.9929101467133, 'accumulated_logging_time': 1.232168436050415, 'global_step': 24655, 'preemption_count': 0}), (25451, {'train/ctc_loss': 0.37376723084994934, 'train/wer': 0.12922350586341189, 'validation/ctc_loss': 0.57840333110433, 'validation/wer': 0.17166996572201032, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3563313308519904, 'test/wer': 0.11910710295939715, 'test/num_examples': 2472, 'score': 46085.866148233414, 'total_duration': 47198.93251132965, 'accumulated_submission_time': 46085.866148233414, 'accumulated_eval_time': 1054.4684133529663, 'accumulated_logging_time': 1.270362138748169, 'global_step': 25451, 'preemption_count': 0}), (26248, {'train/ctc_loss': 0.37283165492444403, 'train/wer': 0.12724365250310032, 'validation/ctc_loss': 0.5780645657524613, 'validation/wer': 0.17058851928740404, 'validation/num_examples': 5348, 'test/ctc_loss': 0.35782237966965613, 'test/wer': 0.11863993662787155, 'test/num_examples': 2472, 'score': 47525.9236330986, 'total_duration': 48672.26515054703, 'accumulated_submission_time': 47525.9236330986, 'accumulated_eval_time': 1085.9304928779602, 'accumulated_logging_time': 1.3144400119781494, 'global_step': 26248, 'preemption_count': 0}), (27046, {'train/ctc_loss': 0.35885999751650294, 'train/wer': 0.12571524922220045, 'validation/ctc_loss': 0.5662491307671539, 'validation/wer': 0.16999951721141313, 'validation/num_examples': 5348, 'test/ctc_loss': 0.34174299047519197, 'test/wer': 0.11453699754229886, 'test/num_examples': 2472, 'score': 48965.21668720245, 'total_duration': 50144.50018072128, 'accumulated_submission_time': 48965.21668720245, 'accumulated_eval_time': 1117.0099346637726, 'accumulated_logging_time': 1.3541572093963623, 'global_step': 27046, 'preemption_count': 0}), (27844, {'train/ctc_loss': 0.35172020841880064, 'train/wer': 0.12108652611883472, 'validation/ctc_loss': 0.5640072752630851, 'validation/wer': 0.16863805339641771, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3384356450416156, 'test/wer': 0.1146385554404566, 'test/num_examples': 2472, 'score': 50405.3672106266, 'total_duration': 51617.46774625778, 'accumulated_submission_time': 50405.3672106266, 'accumulated_eval_time': 1148.0282263755798, 'accumulated_logging_time': 1.390019416809082, 'global_step': 27844, 'preemption_count': 0}), (28643, {'train/ctc_loss': 0.3512832655104137, 'train/wer': 0.12197310880490829, 'validation/ctc_loss': 0.5578812930103476, 'validation/wer': 0.1663496354946169, 'validation/num_examples': 5348, 'test/ctc_loss': 0.33963831839957415, 'test/wer': 0.11256677431803871, 'test/num_examples': 2472, 'score': 51844.77876138687, 'total_duration': 53089.91455078125, 'accumulated_submission_time': 51844.77876138687, 'accumulated_eval_time': 1179.3765139579773, 'accumulated_logging_time': 1.4250478744506836, 'global_step': 28643, 'preemption_count': 0}), (29440, {'train/ctc_loss': 0.3415163359857873, 'train/wer': 0.1170887452951287, 'validation/ctc_loss': 0.5439006735671589, 'validation/wer': 0.15968715299570319, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3287753947835344, 'test/wer': 0.10854508155099223, 'test/num_examples': 2472, 'score': 53284.984095573425, 'total_duration': 54563.78055214882, 'accumulated_submission_time': 53284.984095573425, 'accumulated_eval_time': 1211.2326037883759, 'accumulated_logging_time': 1.462498664855957, 'global_step': 29440, 'preemption_count': 0}), (30238, {'train/ctc_loss': 0.32990548407849546, 'train/wer': 0.11388508147858059, 'validation/ctc_loss': 0.5404837840001507, 'validation/wer': 0.1599864819195674, 'validation/num_examples': 5348, 'test/ctc_loss': 0.32092382976321054, 'test/wer': 0.10757012572867793, 'test/num_examples': 2472, 'score': 54724.179874658585, 'total_duration': 56036.612189769745, 'accumulated_submission_time': 54724.179874658585, 'accumulated_eval_time': 1243.0361545085907, 'accumulated_logging_time': 1.506664514541626, 'global_step': 30238, 'preemption_count': 0}), (31034, {'train/ctc_loss': 0.32536963208644265, 'train/wer': 0.11328133498683723, 'validation/ctc_loss': 0.5303043413765823, 'validation/wer': 0.15872157582194757, 'validation/num_examples': 5348, 'test/ctc_loss': 0.322294129863217, 'test/wer': 0.10968253001035891, 'test/num_examples': 2472, 'score': 56163.063096284866, 'total_duration': 57508.544682979584, 'accumulated_submission_time': 56163.063096284866, 'accumulated_eval_time': 1274.2642486095428, 'accumulated_logging_time': 1.5409750938415527, 'global_step': 31034, 'preemption_count': 0}), (31834, {'train/ctc_loss': 0.3130623097115753, 'train/wer': 0.10834801905880817, 'validation/ctc_loss': 0.5201464824128491, 'validation/wer': 0.15367160720320572, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3118973401509775, 'test/wer': 0.1028578392541588, 'test/num_examples': 2472, 'score': 57603.0136950016, 'total_duration': 58981.54469513893, 'accumulated_submission_time': 57603.0136950016, 'accumulated_eval_time': 1305.565472126007, 'accumulated_logging_time': 1.5756821632385254, 'global_step': 31834, 'preemption_count': 0}), (32630, {'train/ctc_loss': 0.30947861501388385, 'train/wer': 0.1079727171855623, 'validation/ctc_loss': 0.5126300709827707, 'validation/wer': 0.15132525467097957, 'validation/num_examples': 5348, 'test/ctc_loss': 0.30816874778211495, 'test/wer': 0.10425933824873561, 'test/num_examples': 2472, 'score': 59042.473855018616, 'total_duration': 60454.45255613327, 'accumulated_submission_time': 59042.473855018616, 'accumulated_eval_time': 1337.1945252418518, 'accumulated_logging_time': 1.6176879405975342, 'global_step': 32630, 'preemption_count': 0}), (33426, {'train/ctc_loss': 0.3012454885962563, 'train/wer': 0.10496486304201205, 'validation/ctc_loss': 0.5104001845991561, 'validation/wer': 0.15108386037754068, 'validation/num_examples': 5348, 'test/ctc_loss': 0.2993975417768888, 'test/wer': 0.10011577600389983, 'test/num_examples': 2472, 'score': 60481.65323495865, 'total_duration': 61926.98834323883, 'accumulated_submission_time': 60481.65323495865, 'accumulated_eval_time': 1368.7278490066528, 'accumulated_logging_time': 1.6608474254608154, 'global_step': 33426, 'preemption_count': 0})], 'global_step': 33751}
I1007 16:55:44.812966 139932355139392 submission_runner.py:555] Timing: 61069.02405285835
I1007 16:55:44.813031 139932355139392 submission_runner.py:557] Total number of evals: 43
I1007 16:55:44.813115 139932355139392 submission_runner.py:558] ====================
I1007 16:55:44.813316 139932355139392 submission_runner.py:628] Final librispeech_conformer score: 61069.02405285835
