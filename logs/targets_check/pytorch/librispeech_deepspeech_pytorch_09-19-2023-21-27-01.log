torchrun --redirects 1:0,2:0,3:0,4:0,5:0,6:0,7:0 --standalone --nnodes=1 --nproc_per_node=8 submission_runner.py --framework=pytorch --workload=librispeech_deepspeech --submission_path=reference_algorithms/target_setting_algorithms/pytorch_nadamw.py --tuning_search_space=reference_algorithms/target_setting_algorithms/librispeech_deepspeech/tuning_search_space.json --data_dir=/data/librispeech --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=targets_check_pytorch/nadamw_run_0 --overwrite=true --save_checkpoints=false --max_global_steps=36000 --librispeech_tokenizer_vocab_path=/data/librispeech/spm_model.vocab --torch_compile=true 2>&1 | tee -a /logs/librispeech_deepspeech_pytorch_09-19-2023-21-27-01.log
master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-09-19 21:27:13.563010: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-19 21:27:13.563013: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-19 21:27:13.563010: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-19 21:27:13.563009: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-19 21:27:13.563013: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-19 21:27:13.563018: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-19 21:27:13.563009: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-19 21:27:13.563021: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0919 21:27:28.272415 139657637054272 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
I0919 21:27:28.272453 140405015336768 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 6
I0919 21:27:28.272472 140711209256768 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
I0919 21:27:28.273830 140625526449984 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 5
I0919 21:27:28.273785 140103122265920 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 7
I0919 21:27:28.273799 140644088158016 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 4
I0919 21:27:28.274373 140025457243968 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
I0919 21:27:28.283969 139961138972480 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
I0919 21:27:28.284513 139961138972480 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0919 21:27:28.284629 140625526449984 distributed_c10d.py:476] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0919 21:27:28.284650 140103122265920 distributed_c10d.py:476] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0919 21:27:28.284688 140644088158016 distributed_c10d.py:476] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0919 21:27:28.285207 140025457243968 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0919 21:27:28.293359 139657637054272 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0919 21:27:28.293393 140405015336768 distributed_c10d.py:476] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0919 21:27:28.293557 140711209256768 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0919 21:27:28.842469 139961138972480 logger_utils.py:61] Removing existing experiment directory /experiment_runs/targets_check_pytorch/nadamw_run_0/librispeech_deepspeech_pytorch because --overwrite was set.
I0919 21:27:28.860375 139961138972480 logger_utils.py:76] Creating experiment directory at /experiment_runs/targets_check_pytorch/nadamw_run_0/librispeech_deepspeech_pytorch.
W0919 21:27:29.672032 140625526449984 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0919 21:27:29.672031 139657637054272 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0919 21:27:29.672034 139961138972480 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0919 21:27:29.672031 140711209256768 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0919 21:27:29.672062 140103122265920 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0919 21:27:29.672100 140025457243968 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0919 21:27:29.672679 140644088158016 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0919 21:27:29.673231 140405015336768 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0919 21:27:29.678112 139961138972480 submission_runner.py:500] Using RNG seed 3091314777
I0919 21:27:29.680661 139961138972480 submission_runner.py:509] --- Tuning run 1/1 ---
I0919 21:27:29.680817 139961138972480 submission_runner.py:514] Creating tuning directory at /experiment_runs/targets_check_pytorch/nadamw_run_0/librispeech_deepspeech_pytorch/trial_1.
I0919 21:27:29.681019 139961138972480 logger_utils.py:92] Saving hparams to /experiment_runs/targets_check_pytorch/nadamw_run_0/librispeech_deepspeech_pytorch/trial_1/hparams.json.
I0919 21:27:29.681885 139961138972480 submission_runner.py:185] Initializing dataset.
I0919 21:27:29.682033 139961138972480 input_pipeline.py:20] Loading split = train-clean-100
I0919 21:27:29.719169 139961138972480 input_pipeline.py:20] Loading split = train-clean-360
I0919 21:27:30.088432 139961138972480 input_pipeline.py:20] Loading split = train-other-500
I0919 21:27:30.548460 139961138972480 submission_runner.py:192] Initializing model.
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
W0919 21:27:38.615643 140625526449984 submission_runner.py:213] These workloads cannot be fully compiled under current PyTorch version. Proceeding with `backend=eager`.
W0919 21:27:38.616142 140405015336768 submission_runner.py:213] These workloads cannot be fully compiled under current PyTorch version. Proceeding with `backend=eager`.
W0919 21:27:38.616209 139657637054272 submission_runner.py:213] These workloads cannot be fully compiled under current PyTorch version. Proceeding with `backend=eager`.
W0919 21:27:38.617246 140025457243968 submission_runner.py:213] These workloads cannot be fully compiled under current PyTorch version. Proceeding with `backend=eager`.
W0919 21:27:38.617869 140711209256768 submission_runner.py:213] These workloads cannot be fully compiled under current PyTorch version. Proceeding with `backend=eager`.
W0919 21:27:38.617977 139961138972480 submission_runner.py:213] These workloads cannot be fully compiled under current PyTorch version. Proceeding with `backend=eager`.
W0919 21:27:38.618235 140103122265920 submission_runner.py:213] These workloads cannot be fully compiled under current PyTorch version. Proceeding with `backend=eager`.
W0919 21:27:38.618309 140644088158016 submission_runner.py:213] These workloads cannot be fully compiled under current PyTorch version. Proceeding with `backend=eager`.
I0919 21:27:38.943335 139961138972480 submission_runner.py:226] Initializing optimizer.
I0919 21:27:38.944080 139961138972480 submission_runner.py:233] Initializing metrics bundle.
I0919 21:27:38.944235 139961138972480 submission_runner.py:251] Initializing checkpoint and logger.
I0919 21:27:38.944842 139961138972480 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0919 21:27:38.944944 139961138972480 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
I0919 21:27:39.447564 139961138972480 submission_runner.py:272] Saving meta data to /experiment_runs/targets_check_pytorch/nadamw_run_0/librispeech_deepspeech_pytorch/trial_1/meta_data_0.json.
I0919 21:27:39.448564 139961138972480 submission_runner.py:275] Saving flags to /experiment_runs/targets_check_pytorch/nadamw_run_0/librispeech_deepspeech_pytorch/trial_1/flags_0.json.
I0919 21:27:39.463783 139961138972480 submission_runner.py:285] Starting training loop.
[2023-09-19 21:27:41,723] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:41,729] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:41,756] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:41,777] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:41,816] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:41,911] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:41,943] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:41,971] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:42,761] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:42,761] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:42,766] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:42,775] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:42,785] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:42,863] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:42,864] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:42,865] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:42,865] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:42,865] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:42,867] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:42,867] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:42,868] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:42,868] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:42,895] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:42,895] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:42,896] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:42,896] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:42,901] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:42,904] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:42,904] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:42,905] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:42,905] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:42,922] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:42,922] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:42,922] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:42,923] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:42,924] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:42,969] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:42,970] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:42,970] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:42,970] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,008] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,008] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,008] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,008] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,070] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,071] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,071] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,071] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
<eval_with_key>.1:27: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1442.)
  abs_1 = torch.abs(fft_rfft);  fft_rfft = None
<eval_with_key>.1:27: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1442.)
  abs_1 = torch.abs(fft_rfft);  fft_rfft = None
<eval_with_key>.1:27: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1442.)
  abs_1 = torch.abs(fft_rfft);  fft_rfft = None
[2023-09-19 21:27:43,659] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing linear_to_mel_weight_matrix
[2023-09-19 21:27:43,659] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing linear_to_mel_weight_matrix
[2023-09-19 21:27:43,659] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing linear_to_mel_weight_matrix
[2023-09-19 21:27:43,659] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing linear_to_mel_weight_matrix
[2023-09-19 21:27:43,659] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing linear_to_mel_weight_matrix
[2023-09-19 21:27:43,660] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing linear_to_mel_weight_matrix
[2023-09-19 21:27:43,670] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,670] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,670] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,670] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,670] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,670] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,670] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,670] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,671] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,671] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,671] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,671] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,671] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,671] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,671] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,671] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,672] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,672] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,672] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,672] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,673] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,673] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,674] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,674] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,682] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing linear_to_mel_weight_matrix
[2023-09-19 21:27:43,689] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing linear_to_mel_weight_matrix
[2023-09-19 21:27:43,690] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _hertz_to_mel
[2023-09-19 21:27:43,690] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _hertz_to_mel
[2023-09-19 21:27:43,690] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _hertz_to_mel
[2023-09-19 21:27:43,690] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _hertz_to_mel
[2023-09-19 21:27:43,690] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _hertz_to_mel
[2023-09-19 21:27:43,693] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,693] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,693] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,693] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,697] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _hertz_to_mel (RETURN_VALUE)
[2023-09-19 21:27:43,698] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _hertz_to_mel (RETURN_VALUE)
[2023-09-19 21:27:43,698] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _hertz_to_mel (RETURN_VALUE)
[2023-09-19 21:27:43,698] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _hertz_to_mel (RETURN_VALUE)
[2023-09-19 21:27:43,699] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,699] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,699] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,699] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,699] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _hertz_to_mel (RETURN_VALUE)
[2023-09-19 21:27:43,700] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,700] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,700] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,700] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,700] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,700] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,700] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,701] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,701] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,701] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,701] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,701] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,701] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,701] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,701] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,702] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,702] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,702] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,702] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,702] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,711] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in linear_to_mel_weight_matrix>
[2023-09-19 21:27:43,712] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in linear_to_mel_weight_matrix>
[2023-09-19 21:27:43,712] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in linear_to_mel_weight_matrix>
[2023-09-19 21:27:43,712] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in linear_to_mel_weight_matrix>
[2023-09-19 21:27:43,712] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in linear_to_mel_weight_matrix>
[2023-09-19 21:27:43,718] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _hertz_to_mel
[2023-09-19 21:27:43,723] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _hertz_to_mel
[2023-09-19 21:27:43,723] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _hertz_to_mel
[2023-09-19 21:27:43,726] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _hertz_to_mel (RETURN_VALUE)
[2023-09-19 21:27:43,728] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,728] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,728] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,729] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,732] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _hertz_to_mel (RETURN_VALUE)
[2023-09-19 21:27:43,732] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing _hertz_to_mel (RETURN_VALUE)
[2023-09-19 21:27:43,733] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,733] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,734] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,734] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,734] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,734] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,735] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,735] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,735] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in linear_to_mel_weight_matrix>
[2023-09-19 21:27:43,744] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in linear_to_mel_weight_matrix>
[2023-09-19 21:27:43,752] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in linear_to_mel_weight_matrix> (RETURN_VALUE)
[2023-09-19 21:27:43,754] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in linear_to_mel_weight_matrix> (RETURN_VALUE)
[2023-09-19 21:27:43,754] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in linear_to_mel_weight_matrix> (RETURN_VALUE)
[2023-09-19 21:27:43,754] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in linear_to_mel_weight_matrix> (RETURN_VALUE)
[2023-09-19 21:27:43,755] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,756] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,756] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,756] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,756] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in linear_to_mel_weight_matrix> (RETURN_VALUE)
[2023-09-19 21:27:43,757] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,757] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,757] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,757] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,758] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,758] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,758] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,758] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,758] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,758] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,758] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,758] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,760] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,760] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,761] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,761] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,764] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in linear_to_mel_weight_matrix>
[2023-09-19 21:27:43,772] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:43,773] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:43,773] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:43,773] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:43,773] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:43,776] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in linear_to_mel_weight_matrix> (RETURN_VALUE)
[2023-09-19 21:27:43,779] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,779] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,780] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,780] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,785] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in linear_to_mel_weight_matrix> (RETURN_VALUE)
[2023-09-19 21:27:43,788] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:43,789] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,789] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,789] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,789] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,794] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:27:43,795] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:27:43,795] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:27:43,795] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:27:43,797] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,797] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,797] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,797] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,797] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,797] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,797] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:43,798] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,798] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:27:43,798] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,798] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,798] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,798] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,798] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,798] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,798] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,798] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,799] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,800] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,800] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,800] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,800] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,810] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in linear_to_mel_weight_matrix> (RETURN_VALUE)
[2023-09-19 21:27:43,811] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:27:43,813] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,813] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,813] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,813] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,813] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,813] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,813] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,813] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,821] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:27:43,822] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:43,824] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,824] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,824] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,824] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,833] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:43,833] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:43,833] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:43,833] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:43,833] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:43,833] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:43,834] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:43,845] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:27:43,847] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:43,847] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:43,847] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:43,847] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:43,856] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:44,179] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:44,179] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:44,179] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:44,179] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:44,179] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:44,180] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:44,181] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:44,185] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:44,528] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:44,528] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:44,530] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:44,533] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:44,533] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:44,538] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:44,539] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:44,549] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:44,676] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:44,678] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:44,679] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:44,682] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:44,683] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:44,686] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:44,687] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:44,687] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:44,687] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:44,688] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:44,688] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:44,688] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:44,688] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:44,688] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:44,689] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:44,689] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:44,690] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:44,690] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:44,690] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:44,692] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:44,692] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:44,693] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:44,693] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:44,693] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:44,694] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:44,694] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:44,694] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:44,697] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:44,698] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:44,698] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:44,698] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:44,700] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:44,700] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:44,700] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:44,700] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:44,704] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:44,710] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:44,710] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:44,710] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:44,711] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:44,711] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:44,711] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:44,712] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:44,714] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:44,714] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:44,715] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:44,715] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:44,727] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:44,824] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:44,825] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:44,825] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:44,825] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:44,826] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:44,829] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:44,829] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:44,830] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:44,831] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:44,831] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:44,831] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:44,831] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:44,832] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:44,832] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:44,832] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:44,832] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:44,832] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:44,832] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:44,833] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:44,833] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:44,833] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:44,833] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:44,835] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:44,836] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:44,836] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:44,836] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:44,836] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:44,836] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:44,843] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:44,848] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:44,849] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:44,849] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:44,897] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:44,897] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:44,897] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:44,897] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:44,897] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:44,899] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:44,899] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:44,911] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:48,905] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __getitem__
[2023-09-19 21:27:48,913] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _get_abs_string_index
[2023-09-19 21:27:48,916] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __len__
[2023-09-19 21:27:48,924] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:48,997] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:48,997] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:48,997] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:48,997] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,112] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __getitem__
[2023-09-19 21:27:49,121] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _get_abs_string_index
[2023-09-19 21:27:49,125] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __len__
[2023-09-19 21:27:49,133] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,136] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __getitem__
[2023-09-19 21:27:49,145] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _get_abs_string_index
[2023-09-19 21:27:49,145] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __getitem__
[2023-09-19 21:27:49,151] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __len__
[2023-09-19 21:27:49,154] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _get_abs_string_index
[2023-09-19 21:27:49,157] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __getitem__
[2023-09-19 21:27:49,157] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __len__
[2023-09-19 21:27:49,159] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,165] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,166] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _get_abs_string_index
[2023-09-19 21:27:49,170] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __len__
[2023-09-19 21:27:49,170] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __getitem__
[2023-09-19 21:27:49,177] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,178] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _get_abs_string_index
[2023-09-19 21:27:49,182] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __len__
[2023-09-19 21:27:49,190] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,191] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __getitem__
[2023-09-19 21:27:49,199] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _get_abs_string_index
[2023-09-19 21:27:49,203] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __len__
[2023-09-19 21:27:49,210] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,215] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,215] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,216] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,216] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,244] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,245] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,245] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,245] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,246] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,246] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,246] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __getitem__
[2023-09-19 21:27:49,247] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,247] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,255] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _get_abs_string_index
[2023-09-19 21:27:49,258] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,258] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __len__
[2023-09-19 21:27:49,258] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,259] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,259] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,266] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,271] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,271] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,271] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,271] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,285] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,286] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,286] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,286] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,342] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,342] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,343] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,343] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,356] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:49,356] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:49,356] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:49,356] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:49,356] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:49,356] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:49,356] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:49,356] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:49,395] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:49,395] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:49,395] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:49,395] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:49,395] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:49,395] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:49,395] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:49,395] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:27:49,757] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,757] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,757] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,759] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,761] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,763] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,768] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,791] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,831] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,831] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,831] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,832] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,832] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,832] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,832] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,832] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,833] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,833] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,834] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,834] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,835] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,835] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,836] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,836] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,837] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,838] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,838] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,838] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,839] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,839] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,839] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,839] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,843] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,843] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,843] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,843] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,866] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,867] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,867] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,867] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,895] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,896] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,896] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,896] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,896] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,897] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,897] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,897] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:49,968] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,968] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,969] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,969] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,969] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,969] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,969] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,969] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,969] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,969] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,969] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,969] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,969] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,969] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,969] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,970] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,970] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,970] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,970] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,970] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,970] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,970] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,971] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,971] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,972] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,972] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,972] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,972] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:49,976] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:49,976] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:49,976] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:49,976] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,005] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,005] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,006] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,006] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,006] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,006] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,006] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,007] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,078] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,079] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,079] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,079] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,079] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,079] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,079] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,079] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,079] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,079] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,080] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,080] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,080] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,080] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,080] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,080] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,080] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,081] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,081] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,081] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,082] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,082] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,082] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,083] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,085] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,085] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,085] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,085] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,086] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,086] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,087] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,087] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,116] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,116] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,116] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,116] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,117] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,117] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,117] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,118] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,188] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,188] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,189] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,189] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,189] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,189] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,189] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,189] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,189] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,189] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,189] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,190] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,190] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,190] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,190] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,190] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,190] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,191] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,191] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,191] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,191] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,191] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,191] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,192] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,192] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,192] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,192] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,192] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,197] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,197] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,197] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,197] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,226] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,226] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,227] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,227] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,228] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,228] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,228] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,229] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,299] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,300] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,300] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,300] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,300] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,300] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,300] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,301] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,301] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,301] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,301] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,301] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,301] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,301] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,301] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,301] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,302] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,302] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,302] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,302] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,302] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,303] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,303] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,303] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,304] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,304] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,304] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,304] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,310] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,310] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,310] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,311] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,338] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,339] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,342] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,342] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,342] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,342] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,343] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,343] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,421] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,422] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,423] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,424] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,425] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,426] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,426] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,427] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,427] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,427] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,427] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,428] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,428] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,428] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,428] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,430] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,430] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,430] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,430] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,430] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,430] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,431] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,431] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,431] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,431] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,431] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,431] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,432] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,433] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,433] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,433] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,433] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,433] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,433] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,433] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,433] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,438] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,438] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,439] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,439] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,440] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,440] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,440] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,441] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,441] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,443] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,443] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,449] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,523] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,523] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,524] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,526] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,527] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,527] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,529] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,529] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,529] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,530] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,530] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,530] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,530] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,530] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,530] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,530] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,531] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,531] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,531] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,533] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,533] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,533] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,533] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,533] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,533] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,534] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,534] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,534] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,534] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,534] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,535] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,536] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,536] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,537] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,537] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,537] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,541] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,541] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,542] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,544] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,544] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,544] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,544] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,545] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,545] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,547] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,549] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,555] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,624] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,624] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,625] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,626] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,628] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,629] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,630] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,630] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,630] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,630] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,631] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,631] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,631] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,631] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,631] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,631] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,631] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,632] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,632] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,632] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,632] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,632] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,634] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,634] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,635] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,635] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,635] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,635] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,635] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,636] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,636] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,640] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,640] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,640] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,641] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,641] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,641] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,642] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,642] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,642] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,645] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,645] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,646] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,646] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,647] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,647] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,651] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,655] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:27:50,661] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,661] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,663] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,663] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,663] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,663] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,664] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,664] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,664] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,664] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,664] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,664] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,665] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,665] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,665] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,665] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,665] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,666] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,666] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,667] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,667] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,667] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,668] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,668] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,668] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,668] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,670] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,670] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,671] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,671] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,671] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,673] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,674] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,674] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,674] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:27:50,678] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:27:50,681] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:27:50,681] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:27:50,681] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:27:50,681] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0919 21:28:16.300653 139935134775040 logging_writer.py:48] [0] global_step=0, grad_norm=21.769981, loss=33.570576
I0919 21:28:16.329792 139961138972480 pytorch_submission_base.py:86] 0) loss = 33.571, grad_norm = 21.770
I0919 21:28:16.703405 139961138972480 spec.py:320] Evaluating on the training split.
I0919 21:28:16.704378 139961138972480 input_pipeline.py:20] Loading split = train-clean-100
I0919 21:28:16.738895 139961138972480 input_pipeline.py:20] Loading split = train-clean-360
I0919 21:28:16.865185 139961138972480 input_pipeline.py:20] Loading split = train-other-500
[2023-09-19 21:28:19,179] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,271] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,282] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,322] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,369] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,371] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,426] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,439] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,445] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,446] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,446] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,447] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,498] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:19,510] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,518] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,525] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:19,528] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,528] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,528] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,528] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,530] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,544] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,558] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,558] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,559] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,559] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,562] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,562] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,563] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,563] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,599] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:19,606] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:19,624] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,624] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,625] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,625] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,625] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:19,628] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,628] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,629] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,629] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,632] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,632] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,632] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,633] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,633] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:19,635] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,636] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,636] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,636] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,638] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:19,639] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,645] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:19,651] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,660] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,663] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:19,666] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,666] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,667] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,667] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,671] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:19,674] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,674] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,675] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,675] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,675] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,684] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,693] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:19,700] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,700] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,701] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,733] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,767] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,767] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,768] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,768] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,772] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,777] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:19,782] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:19,784] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,785] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,785] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,794] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:19,800] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,801] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,801] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,802] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,807] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:19,810] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:19,810] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,811] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,811] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,811] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,817] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,817] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,817] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,820] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,823] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:19,829] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,830] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,830] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,848] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,853] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,854] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,854] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,854] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,855] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,863] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,872] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,887] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,893] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,901] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,909] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,922] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,933] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,941] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:19,943] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,943] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,944] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,944] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,953] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:19,954] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:19,959] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,959] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,959] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,960] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,960] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,961] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,961] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,966] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,967] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,967] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,967] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,972] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,972] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,973] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,973] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:19,979] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,980] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:19,980] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:19,989] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:19,989] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:19,990] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:19,990] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,004] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:20,007] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,007] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,007] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,007] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,015] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,023] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,024] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,024] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,024] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,026] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:20,031] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,039] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:20,041] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:20,049] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,055] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:20,057] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:20,062] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,064] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,067] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:20,073] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:20,081] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,085] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,086] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,086] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,086] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,087] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:20,093] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,095] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,095] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,095] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,095] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,100] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:20,108] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,108] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,108] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,108] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,113] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,113] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,113] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,113] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,114] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,121] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,126] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:20,126] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,127] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,127] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,127] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,129] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,129] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,130] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,130] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,133] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,139] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,143] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,143] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,143] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,143] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,150] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,152] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,156] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,157] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,157] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,163] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,163] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,163] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,164] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,168] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,168] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,168] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,168] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,170] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,179] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,180] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,180] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,180] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,191] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,194] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,197] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,197] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:20,197] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,198] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,198] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,205] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,211] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:20,220] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,220] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,220] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,220] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,223] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,230] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,237] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,239] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,240] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,240] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,240] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,240] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,240] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,241] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,241] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,246] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,250] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,250] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,251] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,251] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,258] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,266] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,269] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,270] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,270] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,271] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,271] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,275] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,276] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,282] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,283] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,283] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,283] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,283] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,284] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,284] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,292] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,292] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,292] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,292] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,296] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,310] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,310] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,310] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,310] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,310] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,313] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,313] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,314] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,314] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,317] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,317] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,318] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,318] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,318] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,320] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,320] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,321] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,321] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,339] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,341] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,341] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,341] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,342] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,344] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,346] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,355] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,355] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,356] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,356] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,356] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,362] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,363] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,363] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,363] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,366] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,383] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,387] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,389] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,390] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,390] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,391] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,391] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,392] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,392] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,392] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,392] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,396] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,400] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,400] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,401] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,401] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,410] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,412] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,413] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,413] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,413] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,415] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:20,416] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,418] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,428] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:20,429] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,430] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,430] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,430] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,434] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,434] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,434] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,435] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,438] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,439] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,439] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,440] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,440] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,456] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,457] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,461] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,469] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,470] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,470] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,470] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,472] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,473] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,476] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,476] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,477] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,477] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,477] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,478] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,478] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,478] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,486] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,494] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,497] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,498] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,498] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,499] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,499] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,502] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,503] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,503] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,503] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,503] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,504] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,504] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,504] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,508] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,523] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,523] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:20,524] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,528] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,529] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,529] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,529] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,529] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,532] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,538] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:20,542] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,548] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,553] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,553] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,554] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,554] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,566] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,566] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,569] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,570] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,572] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,573] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,573] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,573] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,574] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,574] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,575] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,575] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,580] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,581] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,581] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,581] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,583] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,584] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,584] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,584] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,585] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,585] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,588] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,592] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,593] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,593] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,593] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,601] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,609] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,620] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,620] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,620] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,621] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,623] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,625] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,626] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,626] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,627] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,627] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,629] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,629] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,629] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,629] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,634] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,638] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,638] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,638] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,639] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,639] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,650] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,650] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,652] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,654] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,655] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,655] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,655] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,659] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,659] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,660] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,660] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,661] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,664] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,664] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,664] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,664] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,666] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,674] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,674] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,676] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,676] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,678] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,687] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,695] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,698] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,699] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,699] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,700] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,700] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,701] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,704] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,704] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,705] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,705] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,715] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,719] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,719] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,719] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,720] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,727] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,727] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,737] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,737] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,737] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,737] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,750] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,752] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,753] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,753] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,753] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,774] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,774] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,774] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,775] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,775] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,778] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,778] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,779] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,779] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,787] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,795] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,795] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,796] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,796] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,799] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,802] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,804] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,826] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,835] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,838] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,838] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,838] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,838] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,848] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,848] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,849] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,849] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,885] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,886] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,887] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,887] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,887] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,889] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,889] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,889] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,890] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,902] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,910] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,953] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:20,965] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,970] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,970] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,970] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,971] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,971] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:20,977] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:20,977] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:20,978] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:20,978] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:20,990] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:21,008] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:21,009] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:21,009] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:21,009] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:21,011] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:21,035] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:21,038] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:21,038] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:21,038] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:21,038] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:21,051] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:21,055] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:21,055] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:21,055] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:21,055] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:21,065] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:21,123] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:21,161] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:21,165] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:21,165] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:21,165] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:21,165] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:21,184] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:21,188] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:21,188] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:21,189] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:21,189] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:21,195] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:21,209] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:21,217] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:21,220] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:21,220] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:21,221] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:21,221] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:21,258] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:21,262] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:21,263] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:21,263] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:21,263] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:21,279] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:21,336] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:21,340] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:21,340] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:21,341] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:21,341] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:21,351] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:21,372] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:21,374] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:21,375] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:21,375] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:21,375] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0919 21:28:36.733588 139961138972480 spec.py:332] Evaluating on the validation split.
I0919 21:28:36.734815 139961138972480 input_pipeline.py:20] Loading split = dev-clean
I0919 21:28:36.739809 139961138972480 input_pipeline.py:20] Loading split = dev-other
[2023-09-19 21:28:47,994] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,090] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,093] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,135] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,135] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,149] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,169] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,178] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,178] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,179] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,179] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,186] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,192] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:48,213] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:48,216] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,216] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,216] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,216] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,223] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,232] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,232] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,243] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,246] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,267] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,271] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,272] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,272] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,272] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,278] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,282] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:48,303] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:48,305] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,305] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,305] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,305] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,312] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,317] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,317] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,317] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,317] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,318] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,318] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,318] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,319] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,329] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:48,330] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:48,331] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,331] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,331] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,331] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,342] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:48,343] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:48,348] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,350] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,350] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,351] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,351] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:48,351] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:48,353] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,353] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,353] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,353] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,353] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,353] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,354] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,354] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,356] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,356] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,357] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,357] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,360] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,361] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,363] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:48,365] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,366] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,366] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,366] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,369] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:48,373] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,377] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,390] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:48,392] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,392] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,392] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,392] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,399] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,415] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,433] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:48,439] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,439] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,439] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,439] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,440] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,440] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,440] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,455] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:48,462] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,463] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,463] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,463] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,477] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:48,478] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:48,478] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:48,478] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:48,480] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,480] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,480] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,480] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,484] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,485] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,485] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,485] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,485] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,485] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,490] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:48,490] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,495] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,496] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,496] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,498] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:48,500] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,500] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,501] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,501] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,503] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,508] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:48,518] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:48,525] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,525] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,526] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,549] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,550] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,555] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,589] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,612] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:48,618] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,618] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,618] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,627] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:48,633] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:48,633] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:48,634] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:48,678] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:48,696] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:50,809] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:50,848] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:50,849] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:50,849] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:50,849] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:50,855] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:50,872] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:50,890] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:50,931] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:50,932] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:50,932] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:50,932] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:50,950] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:50,990] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:50,990] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:50,990] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:50,990] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,008] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,017] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,037] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,047] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,048] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,048] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,048] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,057] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,057] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,058] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,058] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,065] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:51,066] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,080] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,080] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,080] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,080] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,081] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,087] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:51,094] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:51,096] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,100] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:51,107] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,107] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,107] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,107] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,114] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,120] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,123] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,123] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,124] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,124] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,126] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,131] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:51,139] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,139] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,140] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,140] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,146] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,147] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:51,153] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,153] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,153] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,153] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,160] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,160] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,160] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,160] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,160] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,167] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,167] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,168] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,168] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,172] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,173] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:51,173] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:51,174] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,180] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,186] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,186] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,186] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,186] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,187] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,192] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,193] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:51,193] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,204] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:51,206] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,206] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,206] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,207] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,211] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,211] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,211] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,211] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,213] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:51,218] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,218] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,219] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,219] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,219] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,219] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,219] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,220] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,224] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,226] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:51,230] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:51,231] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,233] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,233] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,234] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,234] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,235] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,235] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,235] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,235] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,239] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:51,239] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,239] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,243] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,243] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,244] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,244] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,249] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,251] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,252] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,253] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,258] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,264] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,264] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,265] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,265] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,270] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,270] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,270] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,270] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,279] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,279] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,279] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,280] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,283] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,289] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,289] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,289] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,289] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,289] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,290] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,290] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,291] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,291] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,292] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,293] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,293] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,293] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,298] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,299] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,301] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,301] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,301] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,301] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,302] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,302] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,302] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,302] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,308] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,309] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,309] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,310] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,322] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,322] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,322] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,322] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,322] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,327] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,327] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,328] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,328] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,338] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,338] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,338] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,338] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,341] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,346] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,346] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,346] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,346] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,347] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,347] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,348] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,348] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,348] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,349] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,349] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,350] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,350] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,358] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,359] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,361] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,362] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,362] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,362] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,363] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,363] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,363] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,363] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,365] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,366] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,367] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,369] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,380] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,380] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,380] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,380] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,380] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,386] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,386] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,386] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,386] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,387] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,389] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,389] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,389] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,389] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,398] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,398] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,398] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,398] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,399] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,404] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,404] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,404] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,404] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,405] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,405] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,405] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,405] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,405] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,407] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,407] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,407] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,407] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,418] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,420] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,420] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,420] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,421] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,422] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,424] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,425] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,438] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,438] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,438] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,439] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,439] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,451] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,454] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,455] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,455] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,455] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,457] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,462] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,462] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,462] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,462] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,462] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,462] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,462] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,462] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,463] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,465] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,465] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,466] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,466] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,466] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,469] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,469] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,469] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,470] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,477] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,478] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,478] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,479] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,479] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,481] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,482] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,483] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,496] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,496] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,497] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,497] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,497] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,509] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,512] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,512] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,512] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,512] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,515] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,519] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,520] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,520] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,520] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,520] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,524] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,528] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,528] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,528] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,528] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,528] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,530] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,531] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,531] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,532] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,532] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,533] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,533] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,533] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,533] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,535] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,535] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,535] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,536] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,536] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,539] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,539] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,541] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,553] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,560] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,564] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,564] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,564] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,564] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,569] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,571] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,572] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,572] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,573] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,573] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,578] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,583] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,584] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,587] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,587] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,587] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,587] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,587] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,588] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,588] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,588] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,588] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,591] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,592] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,592] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,592] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,592] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,593] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,595] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,596] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,596] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,597] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,597] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,597] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,599] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,599] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,599] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,599] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,599] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,600] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,603] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,603] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,603] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,604] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,604] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,610] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,612] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,615] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,615] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,615] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,615] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,619] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,623] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,623] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,623] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,623] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,630] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,645] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,648] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,648] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,648] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,648] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,648] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,650] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,651] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,652] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,652] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,652] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,654] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,654] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,654] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,654] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,656] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,658] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,659] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,660] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,663] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,664] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,664] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,664] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,671] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,675] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,677] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,678] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,678] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,678] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,679] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,680] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,682] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,682] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,683] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,683] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,684] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,684] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,685] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,685] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,690] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,702] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,705] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,705] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,706] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,706] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,707] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,709] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,710] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,710] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,710] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,712] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,718] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,722] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,723] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,723] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,723] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,729] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:51,730] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,733] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,733] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,733] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,733] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:51,748] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:51,750] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:51,750] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:51,750] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:51,750] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0919 21:28:51.964979 139961138972480 spec.py:348] Evaluating on the test split.
I0919 21:28:51.966160 139961138972480 input_pipeline.py:20] Loading split = test-clean
[2023-09-19 21:28:57,665] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:57,683] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:57,763] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:57,783] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:57,837] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:57,848] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:57,848] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:57,848] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:57,848] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:57,858] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:57,859] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:57,869] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:57,869] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:57,869] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:57,870] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:57,874] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:57,879] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:57,882] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:57,882] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:57,882] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:57,882] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:57,882] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:57,889] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:57,897] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:57,903] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:57,906] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:57,906] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:57,906] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:57,906] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:57,910] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:57,913] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:57,938] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:57,957] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:57,973] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:57,996] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:58,002] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:58,007] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:58,012] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:58,012] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,013] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,013] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,025] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,025] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,025] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,025] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:58,033] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:58,036] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:58,039] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,039] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,040] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,044] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,044] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,044] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,044] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:58,054] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:58,057] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:58,059] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,059] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,060] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,060] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:58,060] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,060] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,060] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,061] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:58,068] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:58,070] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:58,076] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:58,078] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,078] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,079] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,079] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:58,079] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:58,083] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,083] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,083] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,083] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:58,086] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:58,092] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:58,094] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,094] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,094] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,094] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:58,096] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:58,100] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,101] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,101] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,101] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:58,102] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:58,107] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:58,113] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:58,117] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:58,120] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,120] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,120] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,120] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:58,127] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:58,134] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:58,137] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,137] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,137] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,137] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:58,145] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:58,193] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,194] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,194] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:58,194] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,194] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:58,200] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,201] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,201] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,212] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:58,215] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:58,218] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,218] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,219] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,221] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,221] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,221] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,248] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:58,253] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,254] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,254] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,265] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:58,267] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:58,271] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,271] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,271] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,282] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:58,316] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:58,333] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:58,389] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:58,411] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-09-19 21:28:58,413] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,413] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,413] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,414] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:58,421] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:58,432] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:58,539] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:28:58,546] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:58,546] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:58,547] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:58,608] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:58,608] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:59,895] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:28:59,937] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:28:59,938] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:28:59,938] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:28:59,938] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:28:59,945] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:59,959] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:28:59,976] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,016] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,016] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,017] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,017] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,035] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,076] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,076] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,076] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,076] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,095] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,139] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,139] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,139] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,139] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,158] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,198] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,198] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,198] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,198] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,216] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,221] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,228] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,242] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,253] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,262] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,263] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,263] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,263] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,269] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,270] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:29:00,273] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,273] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,273] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,273] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,280] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:29:00,282] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:29:00,287] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,287] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,287] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,287] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,293] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:29:00,294] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,294] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,294] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:29:00,294] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,294] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,300] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,301] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:29:00,305] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:29:00,312] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,312] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:29:00,313] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,313] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,314] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,314] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,321] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:29:00,324] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,331] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,333] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:29:00,340] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,340] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,340] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,340] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,351] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,351] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,351] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,352] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,352] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,359] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,366] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,367] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,367] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,367] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,370] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,370] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,370] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,371] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,371] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,386] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,390] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,391] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,391] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,391] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,392] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,398] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,398] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,399] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,399] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,410] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,410] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,411] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,411] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,411] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,417] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,426] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,426] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,427] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,427] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,430] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,430] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,430] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,430] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,430] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,445] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,450] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,451] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,451] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,452] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,452] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,457] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,457] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,457] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,457] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,469] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,469] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,470] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,470] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,471] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,473] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,476] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,485] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,485] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,485] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,485] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,486] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,488] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,489] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,490] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,490] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,490] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,504] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,510] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,510] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,510] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,510] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,511] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,516] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,516] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,516] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,516] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,518] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,518] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,518] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,518] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,525] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:29:00,526] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,526] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,526] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,526] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,528] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,529] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,529] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,529] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,530] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,533] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:29:00,534] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,535] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:29:00,543] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,543] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,544] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,544] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,545] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-09-19 21:29:00,548] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,549] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,549] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,550] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,550] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,553] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,562] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,565] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,569] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,570] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,570] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,570] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,570] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,572] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,573] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,573] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,573] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,574] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,574] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,574] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,575] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,590] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,593] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,594] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,595] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,595] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,596] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,596] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,604] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,605] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,605] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,605] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,615] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,626] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,640] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:00,641] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:00,643] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,643] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,644] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,644] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,644] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,644] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,645] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,645] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,651] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,652] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,655] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,655] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,655] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,655] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,666] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,666] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,666] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,666] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,674] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,687] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,700] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:00,701] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:00,704] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,704] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,704] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,704] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,704] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,705] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,705] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,705] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,712] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,712] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,715] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,715] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,716] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,716] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,727] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,727] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,727] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,727] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,734] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,748] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,758] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:00,760] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:00,761] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,762] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,762] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,762] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,764] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,764] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,764] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,764] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,768] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,770] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,775] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,775] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,775] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,775] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,786] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:00,787] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:00,788] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,788] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,789] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,789] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,789] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,789] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,789] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,789] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,790] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,790] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,790] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,790] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,793] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,809] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,847] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,847] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,848] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,848] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,867] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,912] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:00,913] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,913] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,914] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,914] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,916] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,916] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,916] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,916] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,923] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,928] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,928] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,928] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,928] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,932] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,943] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,943] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,944] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,944] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,946] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,960] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,960] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,960] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,960] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,963] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,972] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:00,975] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,976] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,976] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,976] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,978] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:00,979] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,981] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,981] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,981] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,981] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:00,983] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,988] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:00,992] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:00,996] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:00,996] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:00,996] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:00,996] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,003] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:01,009] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,012] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,012] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,013] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,013] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,020] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:01,026] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,028] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,029] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,030] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,030] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,030] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,031] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,032] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,032] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,032] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,034] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,037] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:01,037] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,038] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,038] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,038] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,038] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:01,045] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:01,050] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,053] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,053] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,053] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,053] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,055] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,057] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,058] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,058] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,058] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,060] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:01,066] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,069] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,070] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,070] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,070] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,077] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:01,088] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,092] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,092] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,092] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,092] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,094] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,097] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,097] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,098] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,098] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,100] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:01,103] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:01,106] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,109] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,109] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,110] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,110] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,115] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:01,120] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,122] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,122] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,123] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,123] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,127] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,130] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,130] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,130] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,131] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,131] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,133] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,134] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,134] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,134] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,136] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:01,146] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,150] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,150] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,150] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,150] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,153] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,155] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,155] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,155] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,155] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,156] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:01,172] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,174] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,175] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,175] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,175] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,252] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,252] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,253] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,253] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,271] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:01,316] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,319] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,320] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,320] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,320] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,327] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:01,377] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,380] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,381] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,381] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,381] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,389] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:01,435] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,438] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,439] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,439] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,439] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-19 21:29:01,445] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-19 21:29:01,464] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-19 21:29:01,466] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-19 21:29:01,466] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-19 21:29:01,467] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-19 21:29:01,467] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0919 21:29:01.633550 139961138972480 submission_runner.py:376] Time since start: 82.17s, 	Step: 1, 	{'train/ctc_loss': 31.04407351330891, 'train/wer': 2.9127041260940403, 'validation/ctc_loss': 30.32050557564798, 'validation/wer': 2.7464780572587264, 'validation/num_examples': 5348, 'test/ctc_loss': 30.387986321698175, 'test/wer': 2.7104584323522842, 'test/num_examples': 2472, 'score': 36.868207693099976, 'total_duration': 82.17002820968628, 'accumulated_submission_time': 36.868207693099976, 'accumulated_eval_time': 44.93013048171997, 'accumulated_logging_time': 0}
I0919 21:29:01.655900 139921109022464 logging_writer.py:48] [1] accumulated_eval_time=44.930130, accumulated_logging_time=0, accumulated_submission_time=36.868208, global_step=1, preemption_count=0, score=36.868208, test/ctc_loss=30.387986, test/num_examples=2472, test/wer=2.710458, total_duration=82.170028, train/ctc_loss=31.044074, train/wer=2.912704, validation/ctc_loss=30.320506, validation/num_examples=5348, validation/wer=2.746478
I0919 21:29:02.022836 139961138972480 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0919 21:29:02.022823 140711209256768 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0919 21:29:02.022995 139657637054272 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0919 21:29:02.023512 140103122265920 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0919 21:29:02.023849 140025457243968 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0919 21:29:02.028367 140625526449984 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0919 21:29:02.028422 140405015336768 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0919 21:29:02.028764 140644088158016 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0919 21:29:02.993497 139921100629760 logging_writer.py:48] [1] global_step=1, grad_norm=22.627991, loss=32.910267
I0919 21:29:02.997691 139961138972480 pytorch_submission_base.py:86] 1) loss = 32.910, grad_norm = 22.628
I0919 21:29:04.084648 139921109022464 logging_writer.py:48] [2] global_step=2, grad_norm=25.737286, loss=33.245556
I0919 21:29:04.088862 139961138972480 pytorch_submission_base.py:86] 2) loss = 33.246, grad_norm = 25.737
I0919 21:29:04.996007 139921100629760 logging_writer.py:48] [3] global_step=3, grad_norm=29.021465, loss=32.876644
I0919 21:29:04.999900 139961138972480 pytorch_submission_base.py:86] 3) loss = 32.877, grad_norm = 29.021
I0919 21:29:05.907202 139921109022464 logging_writer.py:48] [4] global_step=4, grad_norm=35.477814, loss=31.733242
I0919 21:29:05.911329 139961138972480 pytorch_submission_base.py:86] 4) loss = 31.733, grad_norm = 35.478
I0919 21:29:06.821395 139921100629760 logging_writer.py:48] [5] global_step=5, grad_norm=37.160858, loss=31.006002
I0919 21:29:06.825390 139961138972480 pytorch_submission_base.py:86] 5) loss = 31.006, grad_norm = 37.161
I0919 21:29:07.738964 139921109022464 logging_writer.py:48] [6] global_step=6, grad_norm=37.391232, loss=29.970762
I0919 21:29:07.742765 139961138972480 pytorch_submission_base.py:86] 6) loss = 29.971, grad_norm = 37.391
I0919 21:29:08.657222 139921100629760 logging_writer.py:48] [7] global_step=7, grad_norm=35.152164, loss=27.904243
I0919 21:29:08.660881 139961138972480 pytorch_submission_base.py:86] 7) loss = 27.904, grad_norm = 35.152
I0919 21:29:09.586317 139921109022464 logging_writer.py:48] [8] global_step=8, grad_norm=34.369926, loss=27.039219
I0919 21:29:09.589876 139961138972480 pytorch_submission_base.py:86] 8) loss = 27.039, grad_norm = 34.370
I0919 21:29:10.505812 139921100629760 logging_writer.py:48] [9] global_step=9, grad_norm=33.144291, loss=25.829666
I0919 21:29:10.509403 139961138972480 pytorch_submission_base.py:86] 9) loss = 25.830, grad_norm = 33.144
I0919 21:29:11.420667 139921109022464 logging_writer.py:48] [10] global_step=10, grad_norm=32.621967, loss=24.270130
I0919 21:29:11.424050 139961138972480 pytorch_submission_base.py:86] 10) loss = 24.270, grad_norm = 32.622
I0919 21:29:12.349395 139921100629760 logging_writer.py:48] [11] global_step=11, grad_norm=30.992758, loss=23.038332
I0919 21:29:12.353104 139961138972480 pytorch_submission_base.py:86] 11) loss = 23.038, grad_norm = 30.993
I0919 21:29:13.280600 139921109022464 logging_writer.py:48] [12] global_step=12, grad_norm=30.259359, loss=21.951555
I0919 21:29:13.284261 139961138972480 pytorch_submission_base.py:86] 12) loss = 21.952, grad_norm = 30.259
I0919 21:29:14.212368 139921100629760 logging_writer.py:48] [13] global_step=13, grad_norm=29.422604, loss=20.166235
I0919 21:29:14.215813 139961138972480 pytorch_submission_base.py:86] 13) loss = 20.166, grad_norm = 29.423
I0919 21:29:15.136510 139921109022464 logging_writer.py:48] [14] global_step=14, grad_norm=26.793001, loss=18.562315
I0919 21:29:15.139974 139961138972480 pytorch_submission_base.py:86] 14) loss = 18.562, grad_norm = 26.793
I0919 21:29:16.060739 139921100629760 logging_writer.py:48] [15] global_step=15, grad_norm=24.092182, loss=16.715200
I0919 21:29:16.064346 139961138972480 pytorch_submission_base.py:86] 15) loss = 16.715, grad_norm = 24.092
I0919 21:29:16.986740 139921109022464 logging_writer.py:48] [16] global_step=16, grad_norm=22.578531, loss=15.688386
I0919 21:29:16.990583 139961138972480 pytorch_submission_base.py:86] 16) loss = 15.688, grad_norm = 22.579
I0919 21:29:17.916303 139921100629760 logging_writer.py:48] [17] global_step=17, grad_norm=20.142164, loss=14.527984
I0919 21:29:17.919907 139961138972480 pytorch_submission_base.py:86] 17) loss = 14.528, grad_norm = 20.142
I0919 21:29:18.835097 139921109022464 logging_writer.py:48] [18] global_step=18, grad_norm=17.368860, loss=13.211763
I0919 21:29:18.838761 139961138972480 pytorch_submission_base.py:86] 18) loss = 13.212, grad_norm = 17.369
I0919 21:29:19.745314 139921100629760 logging_writer.py:48] [19] global_step=19, grad_norm=14.795828, loss=12.115110
I0919 21:29:19.748877 139961138972480 pytorch_submission_base.py:86] 19) loss = 12.115, grad_norm = 14.796
I0919 21:29:20.662085 139921109022464 logging_writer.py:48] [20] global_step=20, grad_norm=10.981465, loss=10.829556
I0919 21:29:20.665714 139961138972480 pytorch_submission_base.py:86] 20) loss = 10.830, grad_norm = 10.981
I0919 21:29:21.579037 139921100629760 logging_writer.py:48] [21] global_step=21, grad_norm=8.630556, loss=10.173022
I0919 21:29:21.582763 139961138972480 pytorch_submission_base.py:86] 21) loss = 10.173, grad_norm = 8.631
I0919 21:29:22.494816 139921109022464 logging_writer.py:48] [22] global_step=22, grad_norm=7.072670, loss=9.968486
I0919 21:29:22.498433 139961138972480 pytorch_submission_base.py:86] 22) loss = 9.968, grad_norm = 7.073
I0919 21:29:23.413742 139921100629760 logging_writer.py:48] [23] global_step=23, grad_norm=5.379390, loss=9.295115
I0919 21:29:23.417305 139961138972480 pytorch_submission_base.py:86] 23) loss = 9.295, grad_norm = 5.379
I0919 21:29:24.329435 139921109022464 logging_writer.py:48] [24] global_step=24, grad_norm=6.288144, loss=9.275029
I0919 21:29:24.333108 139961138972480 pytorch_submission_base.py:86] 24) loss = 9.275, grad_norm = 6.288
I0919 21:29:25.240578 139921100629760 logging_writer.py:48] [25] global_step=25, grad_norm=5.160064, loss=8.947339
I0919 21:29:25.244123 139961138972480 pytorch_submission_base.py:86] 25) loss = 8.947, grad_norm = 5.160
I0919 21:29:26.158171 139921109022464 logging_writer.py:48] [26] global_step=26, grad_norm=4.162714, loss=8.485359
I0919 21:29:26.161775 139961138972480 pytorch_submission_base.py:86] 26) loss = 8.485, grad_norm = 4.163
I0919 21:29:27.083776 139921100629760 logging_writer.py:48] [27] global_step=27, grad_norm=2.986830, loss=8.294841
I0919 21:29:27.087230 139961138972480 pytorch_submission_base.py:86] 27) loss = 8.295, grad_norm = 2.987
I0919 21:29:28.008261 139921109022464 logging_writer.py:48] [28] global_step=28, grad_norm=2.831159, loss=8.067038
I0919 21:29:28.011895 139961138972480 pytorch_submission_base.py:86] 28) loss = 8.067, grad_norm = 2.831
I0919 21:29:28.926592 139921100629760 logging_writer.py:48] [29] global_step=29, grad_norm=2.538060, loss=7.853025
I0919 21:29:28.930257 139961138972480 pytorch_submission_base.py:86] 29) loss = 7.853, grad_norm = 2.538
I0919 21:29:29.852048 139921109022464 logging_writer.py:48] [30] global_step=30, grad_norm=2.640041, loss=7.663879
I0919 21:29:29.855853 139961138972480 pytorch_submission_base.py:86] 30) loss = 7.664, grad_norm = 2.640
I0919 21:29:30.768973 139921100629760 logging_writer.py:48] [31] global_step=31, grad_norm=2.262233, loss=7.475496
I0919 21:29:30.772949 139961138972480 pytorch_submission_base.py:86] 31) loss = 7.475, grad_norm = 2.262
I0919 21:29:31.695411 139921109022464 logging_writer.py:48] [32] global_step=32, grad_norm=2.192113, loss=7.439644
I0919 21:29:31.699108 139961138972480 pytorch_submission_base.py:86] 32) loss = 7.440, grad_norm = 2.192
I0919 21:29:32.616019 139921100629760 logging_writer.py:48] [33] global_step=33, grad_norm=2.155898, loss=7.238606
I0919 21:29:32.619800 139961138972480 pytorch_submission_base.py:86] 33) loss = 7.239, grad_norm = 2.156
I0919 21:29:33.533521 139921109022464 logging_writer.py:48] [34] global_step=34, grad_norm=1.792678, loss=7.101809
I0919 21:29:33.537318 139961138972480 pytorch_submission_base.py:86] 34) loss = 7.102, grad_norm = 1.793
I0919 21:29:34.469008 139921100629760 logging_writer.py:48] [35] global_step=35, grad_norm=1.632292, loss=6.982408
I0919 21:29:34.472748 139961138972480 pytorch_submission_base.py:86] 35) loss = 6.982, grad_norm = 1.632
I0919 21:29:35.392245 139921109022464 logging_writer.py:48] [36] global_step=36, grad_norm=2.451065, loss=6.897844
I0919 21:29:35.395879 139961138972480 pytorch_submission_base.py:86] 36) loss = 6.898, grad_norm = 2.451
I0919 21:29:36.320615 139921100629760 logging_writer.py:48] [37] global_step=37, grad_norm=3.329339, loss=6.825418
I0919 21:29:36.324373 139961138972480 pytorch_submission_base.py:86] 37) loss = 6.825, grad_norm = 3.329
I0919 21:29:37.243106 139921109022464 logging_writer.py:48] [38] global_step=38, grad_norm=2.253969, loss=6.690038
I0919 21:29:37.246680 139961138972480 pytorch_submission_base.py:86] 38) loss = 6.690, grad_norm = 2.254
I0919 21:29:38.162011 139921100629760 logging_writer.py:48] [39] global_step=39, grad_norm=1.991946, loss=6.554310
I0919 21:29:38.165613 139961138972480 pytorch_submission_base.py:86] 39) loss = 6.554, grad_norm = 1.992
I0919 21:29:39.093904 139921109022464 logging_writer.py:48] [40] global_step=40, grad_norm=6.969691, loss=6.512227
I0919 21:29:39.097609 139961138972480 pytorch_submission_base.py:86] 40) loss = 6.512, grad_norm = 6.970
I0919 21:29:40.034802 139921100629760 logging_writer.py:48] [41] global_step=41, grad_norm=3.078158, loss=6.632204
I0919 21:29:40.038981 139961138972480 pytorch_submission_base.py:86] 41) loss = 6.632, grad_norm = 3.078
I0919 21:29:40.963630 139921109022464 logging_writer.py:48] [42] global_step=42, grad_norm=3.101418, loss=6.531006
I0919 21:29:40.967277 139961138972480 pytorch_submission_base.py:86] 42) loss = 6.531, grad_norm = 3.101
I0919 21:29:41.883371 139921100629760 logging_writer.py:48] [43] global_step=43, grad_norm=4.687098, loss=6.456934
I0919 21:29:41.887105 139961138972480 pytorch_submission_base.py:86] 43) loss = 6.457, grad_norm = 4.687
I0919 21:29:42.796484 139921109022464 logging_writer.py:48] [44] global_step=44, grad_norm=7.615882, loss=6.338456
I0919 21:29:42.800297 139961138972480 pytorch_submission_base.py:86] 44) loss = 6.338, grad_norm = 7.616
I0919 21:29:43.724472 139921100629760 logging_writer.py:48] [45] global_step=45, grad_norm=3.924213, loss=6.299602
I0919 21:29:43.728026 139961138972480 pytorch_submission_base.py:86] 45) loss = 6.300, grad_norm = 3.924
I0919 21:29:44.636834 139921109022464 logging_writer.py:48] [46] global_step=46, grad_norm=0.694021, loss=6.227946
I0919 21:29:44.640909 139961138972480 pytorch_submission_base.py:86] 46) loss = 6.228, grad_norm = 0.694
I0919 21:29:45.579552 139921100629760 logging_writer.py:48] [47] global_step=47, grad_norm=0.592733, loss=6.206611
I0919 21:29:45.583292 139961138972480 pytorch_submission_base.py:86] 47) loss = 6.207, grad_norm = 0.593
I0919 21:29:46.491486 139921109022464 logging_writer.py:48] [48] global_step=48, grad_norm=1.102583, loss=6.186996
I0919 21:29:46.495338 139961138972480 pytorch_submission_base.py:86] 48) loss = 6.187, grad_norm = 1.103
I0919 21:29:47.413185 139921100629760 logging_writer.py:48] [49] global_step=49, grad_norm=1.257595, loss=6.126013
I0919 21:29:47.416841 139961138972480 pytorch_submission_base.py:86] 49) loss = 6.126, grad_norm = 1.258
I0919 21:29:48.320479 139921109022464 logging_writer.py:48] [50] global_step=50, grad_norm=1.884277, loss=6.095114
I0919 21:29:48.324333 139961138972480 pytorch_submission_base.py:86] 50) loss = 6.095, grad_norm = 1.884
I0919 21:29:49.245030 139921100629760 logging_writer.py:48] [51] global_step=51, grad_norm=3.742037, loss=6.086531
I0919 21:29:49.248848 139961138972480 pytorch_submission_base.py:86] 51) loss = 6.087, grad_norm = 3.742
I0919 21:29:50.160248 139921109022464 logging_writer.py:48] [52] global_step=52, grad_norm=5.493569, loss=6.121835
I0919 21:29:50.164011 139961138972480 pytorch_submission_base.py:86] 52) loss = 6.122, grad_norm = 5.494
I0919 21:29:51.078030 139921100629760 logging_writer.py:48] [53] global_step=53, grad_norm=2.663810, loss=6.066217
I0919 21:29:51.081686 139961138972480 pytorch_submission_base.py:86] 53) loss = 6.066, grad_norm = 2.664
I0919 21:29:51.994624 139921109022464 logging_writer.py:48] [54] global_step=54, grad_norm=2.329320, loss=6.044260
I0919 21:29:51.998353 139961138972480 pytorch_submission_base.py:86] 54) loss = 6.044, grad_norm = 2.329
I0919 21:29:52.914497 139921100629760 logging_writer.py:48] [55] global_step=55, grad_norm=4.730612, loss=6.044586
I0919 21:29:52.918138 139961138972480 pytorch_submission_base.py:86] 55) loss = 6.045, grad_norm = 4.731
I0919 21:29:53.839981 139921109022464 logging_writer.py:48] [56] global_step=56, grad_norm=4.107756, loss=6.008073
I0919 21:29:53.843918 139961138972480 pytorch_submission_base.py:86] 56) loss = 6.008, grad_norm = 4.108
I0919 21:29:54.757236 139921100629760 logging_writer.py:48] [57] global_step=57, grad_norm=2.102270, loss=5.998705
I0919 21:29:54.760854 139961138972480 pytorch_submission_base.py:86] 57) loss = 5.999, grad_norm = 2.102
I0919 21:29:55.679867 139921109022464 logging_writer.py:48] [58] global_step=58, grad_norm=1.271084, loss=5.984334
I0919 21:29:55.683691 139961138972480 pytorch_submission_base.py:86] 58) loss = 5.984, grad_norm = 1.271
I0919 21:29:56.613926 139921100629760 logging_writer.py:48] [59] global_step=59, grad_norm=0.727506, loss=5.973631
I0919 21:29:56.617578 139961138972480 pytorch_submission_base.py:86] 59) loss = 5.974, grad_norm = 0.728
I0919 21:29:57.539250 139921109022464 logging_writer.py:48] [60] global_step=60, grad_norm=0.704588, loss=5.973356
I0919 21:29:57.543288 139961138972480 pytorch_submission_base.py:86] 60) loss = 5.973, grad_norm = 0.705
I0919 21:29:58.458190 139921100629760 logging_writer.py:48] [61] global_step=61, grad_norm=1.684058, loss=5.957835
I0919 21:29:58.461958 139961138972480 pytorch_submission_base.py:86] 61) loss = 5.958, grad_norm = 1.684
I0919 21:29:59.377706 139921109022464 logging_writer.py:48] [62] global_step=62, grad_norm=5.445342, loss=5.999450
I0919 21:29:59.382070 139961138972480 pytorch_submission_base.py:86] 62) loss = 5.999, grad_norm = 5.445
I0919 21:30:00.300092 139921100629760 logging_writer.py:48] [63] global_step=63, grad_norm=6.058988, loss=5.995777
I0919 21:30:00.303936 139961138972480 pytorch_submission_base.py:86] 63) loss = 5.996, grad_norm = 6.059
I0919 21:30:01.225977 139921109022464 logging_writer.py:48] [64] global_step=64, grad_norm=1.955850, loss=5.932368
I0919 21:30:01.229634 139961138972480 pytorch_submission_base.py:86] 64) loss = 5.932, grad_norm = 1.956
I0919 21:30:02.147594 139921100629760 logging_writer.py:48] [65] global_step=65, grad_norm=0.380052, loss=5.959074
I0919 21:30:02.151252 139961138972480 pytorch_submission_base.py:86] 65) loss = 5.959, grad_norm = 0.380
I0919 21:30:03.067678 139921109022464 logging_writer.py:48] [66] global_step=66, grad_norm=0.608201, loss=5.917770
I0919 21:30:03.071344 139961138972480 pytorch_submission_base.py:86] 66) loss = 5.918, grad_norm = 0.608
I0919 21:30:03.985305 139921100629760 logging_writer.py:48] [67] global_step=67, grad_norm=1.258829, loss=5.909472
I0919 21:30:03.989133 139961138972480 pytorch_submission_base.py:86] 67) loss = 5.909, grad_norm = 1.259
I0919 21:30:04.934609 139921109022464 logging_writer.py:48] [68] global_step=68, grad_norm=2.429406, loss=5.931587
I0919 21:30:04.938313 139961138972480 pytorch_submission_base.py:86] 68) loss = 5.932, grad_norm = 2.429
I0919 21:30:05.859321 139921100629760 logging_writer.py:48] [69] global_step=69, grad_norm=7.181824, loss=6.007810
I0919 21:30:05.863310 139961138972480 pytorch_submission_base.py:86] 69) loss = 6.008, grad_norm = 7.182
I0919 21:30:06.769942 139921109022464 logging_writer.py:48] [70] global_step=70, grad_norm=5.663903, loss=5.958859
I0919 21:30:06.773756 139961138972480 pytorch_submission_base.py:86] 70) loss = 5.959, grad_norm = 5.664
I0919 21:30:07.684826 139921100629760 logging_writer.py:48] [71] global_step=71, grad_norm=0.438236, loss=5.902483
I0919 21:30:07.688989 139961138972480 pytorch_submission_base.py:86] 71) loss = 5.902, grad_norm = 0.438
I0919 21:30:08.605975 139921109022464 logging_writer.py:48] [72] global_step=72, grad_norm=0.308184, loss=5.887229
I0919 21:30:08.609799 139961138972480 pytorch_submission_base.py:86] 72) loss = 5.887, grad_norm = 0.308
I0919 21:30:09.528599 139921100629760 logging_writer.py:48] [73] global_step=73, grad_norm=0.790268, loss=5.896994
I0919 21:30:09.532626 139961138972480 pytorch_submission_base.py:86] 73) loss = 5.897, grad_norm = 0.790
I0919 21:30:10.444633 139921109022464 logging_writer.py:48] [74] global_step=74, grad_norm=0.602887, loss=5.905422
I0919 21:30:10.448034 139961138972480 pytorch_submission_base.py:86] 74) loss = 5.905, grad_norm = 0.603
I0919 21:30:11.360357 139921100629760 logging_writer.py:48] [75] global_step=75, grad_norm=1.644665, loss=5.907200
I0919 21:30:11.364074 139961138972480 pytorch_submission_base.py:86] 75) loss = 5.907, grad_norm = 1.645
I0919 21:30:12.296939 139921109022464 logging_writer.py:48] [76] global_step=76, grad_norm=4.713381, loss=5.935020
I0919 21:30:12.300683 139961138972480 pytorch_submission_base.py:86] 76) loss = 5.935, grad_norm = 4.713
I0919 21:30:13.218509 139921100629760 logging_writer.py:48] [77] global_step=77, grad_norm=7.474314, loss=5.974118
I0919 21:30:13.222211 139961138972480 pytorch_submission_base.py:86] 77) loss = 5.974, grad_norm = 7.474
I0919 21:30:14.138831 139921109022464 logging_writer.py:48] [78] global_step=78, grad_norm=3.731704, loss=5.937292
I0919 21:30:14.142563 139961138972480 pytorch_submission_base.py:86] 78) loss = 5.937, grad_norm = 3.732
I0919 21:30:15.060536 139921100629760 logging_writer.py:48] [79] global_step=79, grad_norm=0.593879, loss=5.900372
I0919 21:30:15.064503 139961138972480 pytorch_submission_base.py:86] 79) loss = 5.900, grad_norm = 0.594
I0919 21:30:15.975391 139921109022464 logging_writer.py:48] [80] global_step=80, grad_norm=1.043492, loss=5.896241
I0919 21:30:15.979260 139961138972480 pytorch_submission_base.py:86] 80) loss = 5.896, grad_norm = 1.043
I0919 21:30:16.919672 139921100629760 logging_writer.py:48] [81] global_step=81, grad_norm=1.424663, loss=5.889499
I0919 21:30:16.923408 139961138972480 pytorch_submission_base.py:86] 81) loss = 5.889, grad_norm = 1.425
I0919 21:30:17.837400 139921109022464 logging_writer.py:48] [82] global_step=82, grad_norm=2.810372, loss=5.896807
I0919 21:30:17.841026 139961138972480 pytorch_submission_base.py:86] 82) loss = 5.897, grad_norm = 2.810
I0919 21:30:18.759745 139921100629760 logging_writer.py:48] [83] global_step=83, grad_norm=5.035857, loss=5.947172
I0919 21:30:18.763434 139961138972480 pytorch_submission_base.py:86] 83) loss = 5.947, grad_norm = 5.036
I0919 21:30:19.675136 139921109022464 logging_writer.py:48] [84] global_step=84, grad_norm=4.316094, loss=5.928680
I0919 21:30:19.678933 139961138972480 pytorch_submission_base.py:86] 84) loss = 5.929, grad_norm = 4.316
I0919 21:30:20.591864 139921100629760 logging_writer.py:48] [85] global_step=85, grad_norm=2.328344, loss=5.885347
I0919 21:30:20.595850 139961138972480 pytorch_submission_base.py:86] 85) loss = 5.885, grad_norm = 2.328
I0919 21:30:21.509913 139921109022464 logging_writer.py:48] [86] global_step=86, grad_norm=1.701270, loss=5.873917
I0919 21:30:21.513768 139961138972480 pytorch_submission_base.py:86] 86) loss = 5.874, grad_norm = 1.701
I0919 21:30:22.426282 139921100629760 logging_writer.py:48] [87] global_step=87, grad_norm=2.111935, loss=5.875669
I0919 21:30:22.429891 139961138972480 pytorch_submission_base.py:86] 87) loss = 5.876, grad_norm = 2.112
I0919 21:30:23.340266 139921109022464 logging_writer.py:48] [88] global_step=88, grad_norm=4.715644, loss=5.920504
I0919 21:30:23.344338 139961138972480 pytorch_submission_base.py:86] 88) loss = 5.921, grad_norm = 4.716
I0919 21:30:24.259627 139921100629760 logging_writer.py:48] [89] global_step=89, grad_norm=5.387625, loss=5.953625
I0919 21:30:24.263300 139961138972480 pytorch_submission_base.py:86] 89) loss = 5.954, grad_norm = 5.388
I0919 21:30:25.183412 139921109022464 logging_writer.py:48] [90] global_step=90, grad_norm=1.888852, loss=5.875582
I0919 21:30:25.187050 139961138972480 pytorch_submission_base.py:86] 90) loss = 5.876, grad_norm = 1.889
I0919 21:30:26.094492 139921100629760 logging_writer.py:48] [91] global_step=91, grad_norm=0.262639, loss=5.867667
I0919 21:30:26.098406 139961138972480 pytorch_submission_base.py:86] 91) loss = 5.868, grad_norm = 0.263
I0919 21:30:27.015010 139921109022464 logging_writer.py:48] [92] global_step=92, grad_norm=0.356348, loss=5.854365
I0919 21:30:27.019020 139961138972480 pytorch_submission_base.py:86] 92) loss = 5.854, grad_norm = 0.356
I0919 21:30:27.950170 139921100629760 logging_writer.py:48] [93] global_step=93, grad_norm=0.531864, loss=5.859178
I0919 21:30:27.953995 139961138972480 pytorch_submission_base.py:86] 93) loss = 5.859, grad_norm = 0.532
I0919 21:30:28.873224 139921109022464 logging_writer.py:48] [94] global_step=94, grad_norm=1.842492, loss=5.864215
I0919 21:30:28.876890 139961138972480 pytorch_submission_base.py:86] 94) loss = 5.864, grad_norm = 1.842
I0919 21:30:29.793764 139921100629760 logging_writer.py:48] [95] global_step=95, grad_norm=5.213053, loss=5.900861
I0919 21:30:29.797448 139961138972480 pytorch_submission_base.py:86] 95) loss = 5.901, grad_norm = 5.213
I0919 21:30:30.713978 139921109022464 logging_writer.py:48] [96] global_step=96, grad_norm=7.222326, loss=5.937156
I0919 21:30:30.718084 139961138972480 pytorch_submission_base.py:86] 96) loss = 5.937, grad_norm = 7.222
I0919 21:30:31.627873 139921100629760 logging_writer.py:48] [97] global_step=97, grad_norm=3.668688, loss=5.858194
I0919 21:30:31.631589 139961138972480 pytorch_submission_base.py:86] 97) loss = 5.858, grad_norm = 3.669
I0919 21:30:32.560966 139921109022464 logging_writer.py:48] [98] global_step=98, grad_norm=0.567444, loss=5.845964
I0919 21:30:32.565022 139961138972480 pytorch_submission_base.py:86] 98) loss = 5.846, grad_norm = 0.567
I0919 21:30:33.475973 139921100629760 logging_writer.py:48] [99] global_step=99, grad_norm=0.579245, loss=5.845809
I0919 21:30:33.479584 139961138972480 pytorch_submission_base.py:86] 99) loss = 5.846, grad_norm = 0.579
I0919 21:30:34.392342 139921109022464 logging_writer.py:48] [100] global_step=100, grad_norm=0.701517, loss=5.830208
I0919 21:30:34.396074 139961138972480 pytorch_submission_base.py:86] 100) loss = 5.830, grad_norm = 0.702
I0919 21:36:34.952923 139921100629760 logging_writer.py:48] [500] global_step=500, grad_norm=1.903123, loss=3.033230
I0919 21:36:34.957473 139961138972480 pytorch_submission_base.py:86] 500) loss = 3.033, grad_norm = 1.903
I0919 21:44:02.813476 139921109022464 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.534396, loss=2.578811
I0919 21:44:02.820432 139961138972480 pytorch_submission_base.py:86] 1000) loss = 2.579, grad_norm = 1.534
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
I0919 21:51:31.984759 139921109022464 logging_writer.py:48] [1500] global_step=1500, grad_norm=2.521611, loss=2.394839
I0919 21:51:31.991722 139961138972480 pytorch_submission_base.py:86] 1500) loss = 2.395, grad_norm = 2.522
I0919 21:53:02.887930 139961138972480 spec.py:320] Evaluating on the training split.
I0919 21:53:15.886217 139961138972480 spec.py:332] Evaluating on the validation split.
I0919 21:53:26.984763 139961138972480 spec.py:348] Evaluating on the test split.
I0919 21:53:32.654383 139961138972480 submission_runner.py:376] Time since start: 1553.19s, 	Step: 1602, 	{'train/ctc_loss': 1.2508076215308288, 'train/wer': 0.3603390509388312, 'validation/ctc_loss': 1.5011907312700925, 'validation/wer': 0.38953314343648915, 'validation/num_examples': 5348, 'test/ctc_loss': 1.083412538712175, 'test/wer': 0.3199276907765117, 'test/num_examples': 2472, 'score': 1476.5534012317657, 'total_duration': 1553.1907448768616, 'accumulated_submission_time': 1476.5534012317657, 'accumulated_eval_time': 74.6964762210846, 'accumulated_logging_time': 0.03228139877319336}
I0919 21:53:32.689610 139921109022464 logging_writer.py:48] [1602] accumulated_eval_time=74.696476, accumulated_logging_time=0.032281, accumulated_submission_time=1476.553401, global_step=1602, preemption_count=0, score=1476.553401, test/ctc_loss=1.083413, test/num_examples=2472, test/wer=0.319928, total_duration=1553.190745, train/ctc_loss=1.250808, train/wer=0.360339, validation/ctc_loss=1.501191, validation/num_examples=5348, validation/wer=0.389533
I0919 21:59:29.492342 139921100629760 logging_writer.py:48] [2000] global_step=2000, grad_norm=2.442014, loss=2.233025
I0919 21:59:29.500440 139961138972480 pytorch_submission_base.py:86] 2000) loss = 2.233, grad_norm = 2.442
I0919 22:06:58.266551 139921109022464 logging_writer.py:48] [2500] global_step=2500, grad_norm=2.992176, loss=2.117914
I0919 22:06:58.274490 139961138972480 pytorch_submission_base.py:86] 2500) loss = 2.118, grad_norm = 2.992
I0919 22:14:26.662186 139921100629760 logging_writer.py:48] [3000] global_step=3000, grad_norm=5.173032, loss=2.145946
I0919 22:14:26.668814 139961138972480 pytorch_submission_base.py:86] 3000) loss = 2.146, grad_norm = 5.173
I0919 22:17:33.912201 139961138972480 spec.py:320] Evaluating on the training split.
I0919 22:17:46.858191 139961138972480 spec.py:332] Evaluating on the validation split.
I0919 22:17:58.043735 139961138972480 spec.py:348] Evaluating on the test split.
I0919 22:18:03.921737 139961138972480 submission_runner.py:376] Time since start: 3024.46s, 	Step: 3208, 	{'train/ctc_loss': 0.8282067443526692, 'train/wer': 0.25189579488067726, 'validation/ctc_loss': 1.0598616919077757, 'validation/wer': 0.2892869212571815, 'validation/num_examples': 5348, 'test/ctc_loss': 0.7085474264468675, 'test/wer': 0.2214368411431357, 'test/num_examples': 2472, 'score': 2916.092693090439, 'total_duration': 3024.458050966263, 'accumulated_submission_time': 2916.092693090439, 'accumulated_eval_time': 104.70599293708801, 'accumulated_logging_time': 0.07709789276123047}
I0919 22:18:03.957181 139921109022464 logging_writer.py:48] [3208] accumulated_eval_time=104.705993, accumulated_logging_time=0.077098, accumulated_submission_time=2916.092693, global_step=3208, preemption_count=0, score=2916.092693, test/ctc_loss=0.708547, test/num_examples=2472, test/wer=0.221437, total_duration=3024.458051, train/ctc_loss=0.828207, train/wer=0.251896, validation/ctc_loss=1.059862, validation/num_examples=5348, validation/wer=0.289287
I0919 22:22:26.105519 139921100629760 logging_writer.py:48] [3500] global_step=3500, grad_norm=3.704077, loss=2.042960
I0919 22:22:26.110386 139961138972480 pytorch_submission_base.py:86] 3500) loss = 2.043, grad_norm = 3.704
I0919 22:29:52.766487 139921109022464 logging_writer.py:48] [4000] global_step=4000, grad_norm=3.444322, loss=2.028309
I0919 22:29:52.773878 139961138972480 pytorch_submission_base.py:86] 4000) loss = 2.028, grad_norm = 3.444
I0919 22:37:22.398555 139921109022464 logging_writer.py:48] [4500] global_step=4500, grad_norm=3.516872, loss=2.040061
I0919 22:37:22.407660 139961138972480 pytorch_submission_base.py:86] 4500) loss = 2.040, grad_norm = 3.517
I0919 22:42:05.167632 139961138972480 spec.py:320] Evaluating on the training split.
I0919 22:42:18.290209 139961138972480 spec.py:332] Evaluating on the validation split.
I0919 22:42:29.028525 139961138972480 spec.py:348] Evaluating on the test split.
I0919 22:42:34.792955 139961138972480 submission_runner.py:376] Time since start: 4495.33s, 	Step: 4817, 	{'train/ctc_loss': 0.7366871823165209, 'train/wer': 0.22720851307976683, 'validation/ctc_loss': 0.9653922692824493, 'validation/wer': 0.26906773523873895, 'validation/num_examples': 5348, 'test/ctc_loss': 0.6246607644041551, 'test/wer': 0.19645359819633174, 'test/num_examples': 2472, 'score': 4355.545656919479, 'total_duration': 4495.32933306694, 'accumulated_submission_time': 4355.545656919479, 'accumulated_eval_time': 134.33108258247375, 'accumulated_logging_time': 0.12296557426452637}
I0919 22:42:34.830001 139921109022464 logging_writer.py:48] [4817] accumulated_eval_time=134.331083, accumulated_logging_time=0.122966, accumulated_submission_time=4355.545657, global_step=4817, preemption_count=0, score=4355.545657, test/ctc_loss=0.624661, test/num_examples=2472, test/wer=0.196454, total_duration=4495.329333, train/ctc_loss=0.736687, train/wer=0.227209, validation/ctc_loss=0.965392, validation/num_examples=5348, validation/wer=0.269068
I0919 22:45:19.719435 139921100629760 logging_writer.py:48] [5000] global_step=5000, grad_norm=2.726055, loss=1.973798
I0919 22:45:19.723998 139961138972480 pytorch_submission_base.py:86] 5000) loss = 1.974, grad_norm = 2.726
I0919 22:52:48.077550 139921109022464 logging_writer.py:48] [5500] global_step=5500, grad_norm=4.643020, loss=2.085917
I0919 22:52:48.085531 139961138972480 pytorch_submission_base.py:86] 5500) loss = 2.086, grad_norm = 4.643
I0919 23:00:15.612462 139921100629760 logging_writer.py:48] [6000] global_step=6000, grad_norm=2.905073, loss=1.961994
I0919 23:00:15.617279 139961138972480 pytorch_submission_base.py:86] 6000) loss = 1.962, grad_norm = 2.905
I0919 23:06:35.948805 139961138972480 spec.py:320] Evaluating on the training split.
I0919 23:06:48.991938 139961138972480 spec.py:332] Evaluating on the validation split.
I0919 23:06:59.909984 139961138972480 spec.py:348] Evaluating on the test split.
I0919 23:07:05.649997 139961138972480 submission_runner.py:376] Time since start: 5966.19s, 	Step: 6423, 	{'train/ctc_loss': 0.733113190370135, 'train/wer': 0.22596900693365665, 'validation/ctc_loss': 0.9641354135272252, 'validation/wer': 0.26491575339158985, 'validation/num_examples': 5348, 'test/ctc_loss': 0.634859507064972, 'test/wer': 0.19629110555927934, 'test/num_examples': 2472, 'score': 5794.9216940402985, 'total_duration': 5966.186363935471, 'accumulated_submission_time': 5794.9216940402985, 'accumulated_eval_time': 164.03225684165955, 'accumulated_logging_time': 0.16985416412353516}
I0919 23:07:05.671940 139921109022464 logging_writer.py:48] [6423] accumulated_eval_time=164.032257, accumulated_logging_time=0.169854, accumulated_submission_time=5794.921694, global_step=6423, preemption_count=0, score=5794.921694, test/ctc_loss=0.634860, test/num_examples=2472, test/wer=0.196291, total_duration=5966.186364, train/ctc_loss=0.733113, train/wer=0.225969, validation/ctc_loss=0.964135, validation/num_examples=5348, validation/wer=0.264916
I0919 23:08:15.860493 139921100629760 logging_writer.py:48] [6500] global_step=6500, grad_norm=2.526854, loss=1.915853
I0919 23:08:15.867295 139961138972480 pytorch_submission_base.py:86] 6500) loss = 1.916, grad_norm = 2.527
I0919 23:15:41.708283 139921109022464 logging_writer.py:48] [7000] global_step=7000, grad_norm=5.577278, loss=2.028909
I0919 23:15:41.715178 139961138972480 pytorch_submission_base.py:86] 7000) loss = 2.029, grad_norm = 5.577
I0919 23:23:09.283010 139921109022464 logging_writer.py:48] [7500] global_step=7500, grad_norm=2.519009, loss=1.990756
I0919 23:23:09.289396 139961138972480 pytorch_submission_base.py:86] 7500) loss = 1.991, grad_norm = 2.519
I0919 23:30:35.651484 139921100629760 logging_writer.py:48] [8000] global_step=8000, grad_norm=2.450357, loss=1.860322
I0919 23:30:35.656264 139961138972480 pytorch_submission_base.py:86] 8000) loss = 1.860, grad_norm = 2.450
I0919 23:31:06.689046 139961138972480 spec.py:320] Evaluating on the training split.
I0919 23:31:19.776468 139961138972480 spec.py:332] Evaluating on the validation split.
I0919 23:31:30.975829 139961138972480 spec.py:348] Evaluating on the test split.
I0919 23:31:36.835947 139961138972480 submission_runner.py:376] Time since start: 7437.37s, 	Step: 8035, 	{'train/ctc_loss': 0.692546129584443, 'train/wer': 0.2115333611184784, 'validation/ctc_loss': 0.9096526639730259, 'validation/wer': 0.2512914594698981, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5960352784857088, 'test/wer': 0.1830479556395101, 'test/num_examples': 2472, 'score': 7234.23419713974, 'total_duration': 7437.372326850891, 'accumulated_submission_time': 7234.23419713974, 'accumulated_eval_time': 194.17896485328674, 'accumulated_logging_time': 0.20123076438903809}
I0919 23:31:36.867841 139932475582208 logging_writer.py:48] [8035] accumulated_eval_time=194.178965, accumulated_logging_time=0.201231, accumulated_submission_time=7234.234197, global_step=8035, preemption_count=0, score=7234.234197, test/ctc_loss=0.596035, test/num_examples=2472, test/wer=0.183048, total_duration=7437.372327, train/ctc_loss=0.692546, train/wer=0.211533, validation/ctc_loss=0.909653, validation/num_examples=5348, validation/wer=0.251291
I0919 23:38:35.976850 139932475582208 logging_writer.py:48] [8500] global_step=8500, grad_norm=1.935505, loss=1.951208
I0919 23:38:35.987331 139961138972480 pytorch_submission_base.py:86] 8500) loss = 1.951, grad_norm = 1.936
I0919 23:46:03.270568 139932467189504 logging_writer.py:48] [9000] global_step=9000, grad_norm=2.338370, loss=1.896537
I0919 23:46:03.275485 139961138972480 pytorch_submission_base.py:86] 9000) loss = 1.897, grad_norm = 2.338
I0919 23:53:30.636808 139932475582208 logging_writer.py:48] [9500] global_step=9500, grad_norm=3.053959, loss=1.873358
I0919 23:53:30.644177 139961138972480 pytorch_submission_base.py:86] 9500) loss = 1.873, grad_norm = 3.054
I0919 23:55:37.995491 139961138972480 spec.py:320] Evaluating on the training split.
I0919 23:55:50.990926 139961138972480 spec.py:332] Evaluating on the validation split.
I0919 23:56:01.945572 139961138972480 spec.py:348] Evaluating on the test split.
I0919 23:56:07.919932 139961138972480 submission_runner.py:376] Time since start: 8908.46s, 	Step: 9643, 	{'train/ctc_loss': 0.6725744739634731, 'train/wer': 0.20772282694004363, 'validation/ctc_loss': 0.9035184897403054, 'validation/wer': 0.25018104572007915, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5720376617039808, 'test/wer': 0.17705603964820343, 'test/num_examples': 2472, 'score': 8673.728166103363, 'total_duration': 8908.456150531769, 'accumulated_submission_time': 8673.728166103363, 'accumulated_eval_time': 224.10325002670288, 'accumulated_logging_time': 0.24254274368286133}
I0919 23:56:07.943905 139932458796800 logging_writer.py:48] [9643] accumulated_eval_time=224.103250, accumulated_logging_time=0.242543, accumulated_submission_time=8673.728166, global_step=9643, preemption_count=0, score=8673.728166, test/ctc_loss=0.572038, test/num_examples=2472, test/wer=0.177056, total_duration=8908.456151, train/ctc_loss=0.672574, train/wer=0.207723, validation/ctc_loss=0.903518, validation/num_examples=5348, validation/wer=0.250181
I0920 00:01:30.431821 139932450404096 logging_writer.py:48] [10000] global_step=10000, grad_norm=3.342076, loss=1.962876
I0920 00:01:30.435747 139961138972480 pytorch_submission_base.py:86] 10000) loss = 1.963, grad_norm = 3.342
I0920 00:08:58.890997 139932458796800 logging_writer.py:48] [10500] global_step=10500, grad_norm=4.178649, loss=1.919811
I0920 00:08:58.898030 139961138972480 pytorch_submission_base.py:86] 10500) loss = 1.920, grad_norm = 4.179
I0920 00:16:25.719129 139932450404096 logging_writer.py:48] [11000] global_step=11000, grad_norm=3.793296, loss=1.864542
I0920 00:16:25.723955 139961138972480 pytorch_submission_base.py:86] 11000) loss = 1.865, grad_norm = 3.793
I0920 00:20:08.982737 139961138972480 spec.py:320] Evaluating on the training split.
I0920 00:20:22.109228 139961138972480 spec.py:332] Evaluating on the validation split.
I0920 00:20:32.946356 139961138972480 spec.py:348] Evaluating on the test split.
I0920 00:20:38.787847 139961138972480 submission_runner.py:376] Time since start: 10379.32s, 	Step: 11251, 	{'train/ctc_loss': 0.6454252100428535, 'train/wer': 0.19813153920682433, 'validation/ctc_loss': 0.870422498179124, 'validation/wer': 0.2426495437647854, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5504047136105555, 'test/wer': 0.17307497004042005, 'test/num_examples': 2472, 'score': 10113.030045032501, 'total_duration': 10379.324222326279, 'accumulated_submission_time': 10113.030045032501, 'accumulated_eval_time': 253.90812158584595, 'accumulated_logging_time': 0.27747535705566406}
I0920 00:20:38.825449 139932458796800 logging_writer.py:48] [11251] accumulated_eval_time=253.908122, accumulated_logging_time=0.277475, accumulated_submission_time=10113.030045, global_step=11251, preemption_count=0, score=10113.030045, test/ctc_loss=0.550405, test/num_examples=2472, test/wer=0.173075, total_duration=10379.324222, train/ctc_loss=0.645425, train/wer=0.198132, validation/ctc_loss=0.870422, validation/num_examples=5348, validation/wer=0.242650
I0920 00:24:24.062191 139932458796800 logging_writer.py:48] [11500] global_step=11500, grad_norm=3.584864, loss=1.848127
I0920 00:24:24.068300 139961138972480 pytorch_submission_base.py:86] 11500) loss = 1.848, grad_norm = 3.585
I0920 00:31:51.393409 139932450404096 logging_writer.py:48] [12000] global_step=12000, grad_norm=2.350306, loss=1.913604
I0920 00:31:51.398333 139961138972480 pytorch_submission_base.py:86] 12000) loss = 1.914, grad_norm = 2.350
I0920 00:39:19.326843 139932458796800 logging_writer.py:48] [12500] global_step=12500, grad_norm=3.487139, loss=1.842662
I0920 00:39:19.332926 139961138972480 pytorch_submission_base.py:86] 12500) loss = 1.843, grad_norm = 3.487
I0920 00:44:40.151979 139961138972480 spec.py:320] Evaluating on the training split.
I0920 00:44:53.339250 139961138972480 spec.py:332] Evaluating on the validation split.
I0920 00:45:04.321586 139961138972480 spec.py:348] Evaluating on the test split.
I0920 00:45:10.118278 139961138972480 submission_runner.py:376] Time since start: 11850.65s, 	Step: 12859, 	{'train/ctc_loss': 0.6189322244264799, 'train/wer': 0.1934333237709133, 'validation/ctc_loss': 0.8462405581298975, 'validation/wer': 0.23455800704871338, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5306064604974514, 'test/wer': 0.16586435927122054, 'test/num_examples': 2472, 'score': 11552.619503974915, 'total_duration': 11850.654608011246, 'accumulated_submission_time': 11552.619503974915, 'accumulated_eval_time': 283.87430715560913, 'accumulated_logging_time': 0.3247349262237549}
I0920 00:45:10.152556 139932450404096 logging_writer.py:48] [12859] accumulated_eval_time=283.874307, accumulated_logging_time=0.324735, accumulated_submission_time=11552.619504, global_step=12859, preemption_count=0, score=11552.619504, test/ctc_loss=0.530606, test/num_examples=2472, test/wer=0.165864, total_duration=11850.654608, train/ctc_loss=0.618932, train/wer=0.193433, validation/ctc_loss=0.846241, validation/num_examples=5348, validation/wer=0.234558
I0920 00:47:17.519092 139932442011392 logging_writer.py:48] [13000] global_step=13000, grad_norm=1.437387, loss=1.825858
I0920 00:47:17.523654 139961138972480 pytorch_submission_base.py:86] 13000) loss = 1.826, grad_norm = 1.437
I0920 00:54:45.562633 139932450404096 logging_writer.py:48] [13500] global_step=13500, grad_norm=2.944254, loss=1.794140
I0920 00:54:45.569962 139961138972480 pytorch_submission_base.py:86] 13500) loss = 1.794, grad_norm = 2.944
I0920 01:02:12.285321 139932442011392 logging_writer.py:48] [14000] global_step=14000, grad_norm=2.425086, loss=1.752289
I0920 01:02:12.290293 139961138972480 pytorch_submission_base.py:86] 14000) loss = 1.752, grad_norm = 2.425
I0920 01:09:11.611859 139961138972480 spec.py:320] Evaluating on the training split.
I0920 01:09:24.728342 139961138972480 spec.py:332] Evaluating on the validation split.
I0920 01:09:35.573737 139961138972480 spec.py:348] Evaluating on the test split.
I0920 01:09:41.334540 139961138972480 submission_runner.py:376] Time since start: 13321.87s, 	Step: 14469, 	{'train/ctc_loss': 0.5973577352547551, 'train/wer': 0.18628315949575375, 'validation/ctc_loss': 0.8088481428634218, 'validation/wer': 0.22906387293004393, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5167500221788502, 'test/wer': 0.1621676517782788, 'test/num_examples': 2472, 'score': 12992.29988026619, 'total_duration': 13321.870917797089, 'accumulated_submission_time': 12992.29988026619, 'accumulated_eval_time': 313.5970251560211, 'accumulated_logging_time': 0.3718898296356201}
I0920 01:09:41.373256 139932433618688 logging_writer.py:48] [14469] accumulated_eval_time=313.597025, accumulated_logging_time=0.371890, accumulated_submission_time=12992.299880, global_step=14469, preemption_count=0, score=12992.299880, test/ctc_loss=0.516750, test/num_examples=2472, test/wer=0.162168, total_duration=13321.870918, train/ctc_loss=0.597358, train/wer=0.186283, validation/ctc_loss=0.808848, validation/num_examples=5348, validation/wer=0.229064
I0920 01:10:10.691293 139932425225984 logging_writer.py:48] [14500] global_step=14500, grad_norm=2.358725, loss=1.747283
I0920 01:10:10.694916 139961138972480 pytorch_submission_base.py:86] 14500) loss = 1.747, grad_norm = 2.359
I0920 01:17:37.406603 139932433618688 logging_writer.py:48] [15000] global_step=15000, grad_norm=3.121532, loss=1.855589
I0920 01:17:37.413361 139961138972480 pytorch_submission_base.py:86] 15000) loss = 1.856, grad_norm = 3.122
I0920 01:25:05.328764 139932433618688 logging_writer.py:48] [15500] global_step=15500, grad_norm=2.579741, loss=1.738746
I0920 01:25:05.337326 139961138972480 pytorch_submission_base.py:86] 15500) loss = 1.739, grad_norm = 2.580
I0920 01:32:32.960187 139932425225984 logging_writer.py:48] [16000] global_step=16000, grad_norm=2.897190, loss=1.807153
I0920 01:32:32.970772 139961138972480 pytorch_submission_base.py:86] 16000) loss = 1.807, grad_norm = 2.897
I0920 01:33:42.603609 139961138972480 spec.py:320] Evaluating on the training split.
I0920 01:33:55.779064 139961138972480 spec.py:332] Evaluating on the validation split.
I0920 01:34:06.738565 139961138972480 spec.py:348] Evaluating on the test split.
I0920 01:34:12.461313 139961138972480 submission_runner.py:376] Time since start: 14793.00s, 	Step: 16078, 	{'train/ctc_loss': 0.5720028866106552, 'train/wer': 0.18101661154743412, 'validation/ctc_loss': 0.7827905827745127, 'validation/wer': 0.2216965190942886, 'validation/num_examples': 5348, 'test/ctc_loss': 0.49324719538357314, 'test/wer': 0.15654134422034002, 'test/num_examples': 2472, 'score': 14431.795169830322, 'total_duration': 14792.99766588211, 'accumulated_submission_time': 14431.795169830322, 'accumulated_eval_time': 343.4546799659729, 'accumulated_logging_time': 0.42113399505615234}
I0920 01:34:12.495009 139932433618688 logging_writer.py:48] [16078] accumulated_eval_time=343.454680, accumulated_logging_time=0.421134, accumulated_submission_time=14431.795170, global_step=16078, preemption_count=0, score=14431.795170, test/ctc_loss=0.493247, test/num_examples=2472, test/wer=0.156541, total_duration=14792.997666, train/ctc_loss=0.572003, train/wer=0.181017, validation/ctc_loss=0.782791, validation/num_examples=5348, validation/wer=0.221697
I0920 01:40:34.302280 139932433618688 logging_writer.py:48] [16500] global_step=16500, grad_norm=2.947395, loss=1.853709
I0920 01:40:34.309717 139961138972480 pytorch_submission_base.py:86] 16500) loss = 1.854, grad_norm = 2.947
I0920 01:48:00.869000 139932425225984 logging_writer.py:48] [17000] global_step=17000, grad_norm=2.652817, loss=1.786535
I0920 01:48:00.906106 139961138972480 pytorch_submission_base.py:86] 17000) loss = 1.787, grad_norm = 2.653
I0920 01:55:26.556993 139932433618688 logging_writer.py:48] [17500] global_step=17500, grad_norm=2.232255, loss=1.814020
I0920 01:55:26.561660 139961138972480 pytorch_submission_base.py:86] 17500) loss = 1.814, grad_norm = 2.232
I0920 01:58:13.450779 139961138972480 spec.py:320] Evaluating on the training split.
I0920 01:58:26.629603 139961138972480 spec.py:332] Evaluating on the validation split.
I0920 01:58:38.078599 139961138972480 spec.py:348] Evaluating on the test split.
I0920 01:58:43.888328 139961138972480 submission_runner.py:376] Time since start: 16264.42s, 	Step: 17685, 	{'train/ctc_loss': 0.5611470992794668, 'train/wer': 0.17594492046051172, 'validation/ctc_loss': 0.7787338358009342, 'validation/wer': 0.21826872012745618, 'validation/num_examples': 5348, 'test/ctc_loss': 0.49183601563004065, 'test/wer': 0.15408364308492273, 'test/num_examples': 2472, 'score': 15870.984115600586, 'total_duration': 16264.424582004547, 'accumulated_submission_time': 15870.984115600586, 'accumulated_eval_time': 373.8921477794647, 'accumulated_logging_time': 0.46599626541137695}
I0920 01:58:43.923806 139932425225984 logging_writer.py:48] [17685] accumulated_eval_time=373.892148, accumulated_logging_time=0.465996, accumulated_submission_time=15870.984116, global_step=17685, preemption_count=0, score=15870.984116, test/ctc_loss=0.491836, test/num_examples=2472, test/wer=0.154084, total_duration=16264.424582, train/ctc_loss=0.561147, train/wer=0.175945, validation/ctc_loss=0.778734, validation/num_examples=5348, validation/wer=0.218269
I0920 02:03:27.971925 139932416833280 logging_writer.py:48] [18000] global_step=18000, grad_norm=3.382459, loss=1.800227
I0920 02:03:27.976781 139961138972480 pytorch_submission_base.py:86] 18000) loss = 1.800, grad_norm = 3.382
I0920 02:10:56.804188 139932425225984 logging_writer.py:48] [18500] global_step=18500, grad_norm=2.644417, loss=1.806499
I0920 02:10:56.816933 139961138972480 pytorch_submission_base.py:86] 18500) loss = 1.806, grad_norm = 2.644
I0920 02:18:24.737965 139932425225984 logging_writer.py:48] [19000] global_step=19000, grad_norm=2.068591, loss=1.693424
I0920 02:18:24.750172 139961138972480 pytorch_submission_base.py:86] 19000) loss = 1.693, grad_norm = 2.069
I0920 02:22:45.070778 139961138972480 spec.py:320] Evaluating on the training split.
I0920 02:22:58.182660 139961138972480 spec.py:332] Evaluating on the validation split.
I0920 02:23:09.034699 139961138972480 spec.py:348] Evaluating on the test split.
I0920 02:23:14.952506 139961138972480 submission_runner.py:376] Time since start: 17735.49s, 	Step: 19291, 	{'train/ctc_loss': 0.56553726739824, 'train/wer': 0.17782312409675727, 'validation/ctc_loss': 0.7843243470746685, 'validation/wer': 0.2216772075508135, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4799613079876121, 'test/wer': 0.15006195031787622, 'test/num_examples': 2472, 'score': 17310.349919080734, 'total_duration': 17735.488792419434, 'accumulated_submission_time': 17310.349919080734, 'accumulated_eval_time': 403.7736220359802, 'accumulated_logging_time': 0.5115301609039307}
I0920 02:23:14.988039 139932425225984 logging_writer.py:48] [19291] accumulated_eval_time=403.773622, accumulated_logging_time=0.511530, accumulated_submission_time=17310.349919, global_step=19291, preemption_count=0, score=17310.349919, test/ctc_loss=0.479961, test/num_examples=2472, test/wer=0.150062, total_duration=17735.488792, train/ctc_loss=0.565537, train/wer=0.177823, validation/ctc_loss=0.784324, validation/num_examples=5348, validation/wer=0.221677
I0920 02:26:23.519621 139932416833280 logging_writer.py:48] [19500] global_step=19500, grad_norm=2.507555, loss=1.762183
I0920 02:26:23.526145 139961138972480 pytorch_submission_base.py:86] 19500) loss = 1.762, grad_norm = 2.508
I0920 02:33:51.344001 139932425225984 logging_writer.py:48] [20000] global_step=20000, grad_norm=2.841229, loss=1.743506
I0920 02:33:51.351044 139961138972480 pytorch_submission_base.py:86] 20000) loss = 1.744, grad_norm = 2.841
I0920 02:41:17.762007 139932416833280 logging_writer.py:48] [20500] global_step=20500, grad_norm=3.000288, loss=1.757246
I0920 02:41:17.767207 139961138972480 pytorch_submission_base.py:86] 20500) loss = 1.757, grad_norm = 3.000
I0920 02:47:15.906054 139961138972480 spec.py:320] Evaluating on the training split.
I0920 02:47:29.323717 139961138972480 spec.py:332] Evaluating on the validation split.
I0920 02:47:40.019217 139961138972480 spec.py:348] Evaluating on the test split.
I0920 02:47:45.721611 139961138972480 submission_runner.py:376] Time since start: 19206.26s, 	Step: 20900, 	{'train/ctc_loss': 0.5245474383389885, 'train/wer': 0.16665674340057698, 'validation/ctc_loss': 0.7378863671325597, 'validation/wer': 0.20885434268333897, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4533725966191367, 'test/wer': 0.14384660695062254, 'test/num_examples': 2472, 'score': 18749.61420226097, 'total_duration': 19206.258034944534, 'accumulated_submission_time': 18749.61420226097, 'accumulated_eval_time': 433.58908557891846, 'accumulated_logging_time': 0.5568807125091553}
I0920 02:47:45.746870 139932416833280 logging_writer.py:48] [20900] accumulated_eval_time=433.589086, accumulated_logging_time=0.556881, accumulated_submission_time=18749.614202, global_step=20900, preemption_count=0, score=18749.614202, test/ctc_loss=0.453373, test/num_examples=2472, test/wer=0.143847, total_duration=19206.258035, train/ctc_loss=0.524547, train/wer=0.166657, validation/ctc_loss=0.737886, validation/num_examples=5348, validation/wer=0.208854
I0920 02:49:16.743471 139932408440576 logging_writer.py:48] [21000] global_step=21000, grad_norm=2.362539, loss=1.741428
I0920 02:49:16.748440 139961138972480 pytorch_submission_base.py:86] 21000) loss = 1.741, grad_norm = 2.363
I0920 02:56:44.799407 139932416833280 logging_writer.py:48] [21500] global_step=21500, grad_norm=2.357202, loss=1.720588
I0920 02:56:44.804136 139961138972480 pytorch_submission_base.py:86] 21500) loss = 1.721, grad_norm = 2.357
I0920 03:04:13.394603 139932416833280 logging_writer.py:48] [22000] global_step=22000, grad_norm=3.897339, loss=1.718648
I0920 03:04:13.401786 139961138972480 pytorch_submission_base.py:86] 22000) loss = 1.719, grad_norm = 3.897
I0920 03:11:39.997958 139932408440576 logging_writer.py:48] [22500] global_step=22500, grad_norm=2.924187, loss=1.717157
I0920 03:11:40.002896 139961138972480 pytorch_submission_base.py:86] 22500) loss = 1.717, grad_norm = 2.924
I0920 03:11:46.859782 139961138972480 spec.py:320] Evaluating on the training split.
I0920 03:12:00.041167 139961138972480 spec.py:332] Evaluating on the validation split.
I0920 03:12:11.013767 139961138972480 spec.py:348] Evaluating on the test split.
I0920 03:12:16.880799 139961138972480 submission_runner.py:376] Time since start: 20677.42s, 	Step: 22508, 	{'train/ctc_loss': 0.527613379628378, 'train/wer': 0.1654551260886274, 'validation/ctc_loss': 0.7476798546752562, 'validation/wer': 0.2118862550089316, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4595737527421124, 'test/wer': 0.1450449901488839, 'test/num_examples': 2472, 'score': 20188.924441337585, 'total_duration': 20677.41715168953, 'accumulated_submission_time': 20188.924441337585, 'accumulated_eval_time': 463.6098425388336, 'accumulated_logging_time': 0.5915889739990234}
I0920 03:12:16.919688 139932416833280 logging_writer.py:48] [22508] accumulated_eval_time=463.609843, accumulated_logging_time=0.591589, accumulated_submission_time=20188.924441, global_step=22508, preemption_count=0, score=20188.924441, test/ctc_loss=0.459574, test/num_examples=2472, test/wer=0.145045, total_duration=20677.417152, train/ctc_loss=0.527613, train/wer=0.165455, validation/ctc_loss=0.747680, validation/num_examples=5348, validation/wer=0.211886
I0920 03:19:39.592315 139932416833280 logging_writer.py:48] [23000] global_step=23000, grad_norm=2.733712, loss=1.652816
I0920 03:19:39.598929 139961138972480 pytorch_submission_base.py:86] 23000) loss = 1.653, grad_norm = 2.734
I0920 03:27:06.056070 139932408440576 logging_writer.py:48] [23500] global_step=23500, grad_norm=2.193267, loss=1.705695
I0920 03:27:06.060936 139961138972480 pytorch_submission_base.py:86] 23500) loss = 1.706, grad_norm = 2.193
I0920 03:34:36.096953 139932416833280 logging_writer.py:48] [24000] global_step=24000, grad_norm=2.077801, loss=1.705666
I0920 03:34:36.104214 139961138972480 pytorch_submission_base.py:86] 24000) loss = 1.706, grad_norm = 2.078
I0920 03:36:17.488563 139961138972480 spec.py:320] Evaluating on the training split.
I0920 03:36:30.519264 139961138972480 spec.py:332] Evaluating on the validation split.
I0920 03:36:42.291591 139961138972480 spec.py:348] Evaluating on the test split.
I0920 03:36:48.160613 139961138972480 submission_runner.py:376] Time since start: 22148.70s, 	Step: 24114, 	{'train/ctc_loss': 0.5054017808862693, 'train/wer': 0.1602860065710064, 'validation/ctc_loss': 0.7173843429776974, 'validation/wer': 0.2045575242601265, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4408882226272663, 'test/wer': 0.13889058152052486, 'test/num_examples': 2472, 'score': 21627.81825709343, 'total_duration': 22148.695760011673, 'accumulated_submission_time': 21627.81825709343, 'accumulated_eval_time': 494.280597448349, 'accumulated_logging_time': 0.6409873962402344}
I0920 03:36:48.187439 139932416833280 logging_writer.py:48] [24114] accumulated_eval_time=494.280597, accumulated_logging_time=0.640987, accumulated_submission_time=21627.818257, global_step=24114, preemption_count=0, score=21627.818257, test/ctc_loss=0.440888, test/num_examples=2472, test/wer=0.138891, total_duration=22148.695760, train/ctc_loss=0.505402, train/wer=0.160286, validation/ctc_loss=0.717384, validation/num_examples=5348, validation/wer=0.204558
I0920 03:42:35.171889 139932408440576 logging_writer.py:48] [24500] global_step=24500, grad_norm=2.024180, loss=1.660326
I0920 03:42:35.175726 139961138972480 pytorch_submission_base.py:86] 24500) loss = 1.660, grad_norm = 2.024
I0920 03:50:04.363634 139932416833280 logging_writer.py:48] [25000] global_step=25000, grad_norm=2.686488, loss=1.722448
I0920 03:50:04.371401 139961138972480 pytorch_submission_base.py:86] 25000) loss = 1.722, grad_norm = 2.686
I0920 03:57:32.735976 139932408440576 logging_writer.py:48] [25500] global_step=25500, grad_norm=2.891667, loss=1.661265
I0920 03:57:32.743389 139961138972480 pytorch_submission_base.py:86] 25500) loss = 1.661, grad_norm = 2.892
I0920 04:00:49.102649 139961138972480 spec.py:320] Evaluating on the training split.
I0920 04:01:02.329115 139961138972480 spec.py:332] Evaluating on the validation split.
I0920 04:01:13.309406 139961138972480 spec.py:348] Evaluating on the test split.
I0920 04:01:19.206909 139961138972480 submission_runner.py:376] Time since start: 23619.74s, 	Step: 25719, 	{'train/ctc_loss': 0.4801412445250294, 'train/wer': 0.15295722350623273, 'validation/ctc_loss': 0.6967359914199066, 'validation/wer': 0.1989861439675566, 'validation/num_examples': 5348, 'test/ctc_loss': 0.421221681640751, 'test/wer': 0.13324396238295452, 'test/num_examples': 2472, 'score': 23066.921323537827, 'total_duration': 23619.743231773376, 'accumulated_submission_time': 23066.921323537827, 'accumulated_eval_time': 524.3847284317017, 'accumulated_logging_time': 0.6782586574554443}
I0920 04:01:19.246235 139932416833280 logging_writer.py:48] [25719] accumulated_eval_time=524.384728, accumulated_logging_time=0.678259, accumulated_submission_time=23066.921324, global_step=25719, preemption_count=0, score=23066.921324, test/ctc_loss=0.421222, test/num_examples=2472, test/wer=0.133244, total_duration=23619.743232, train/ctc_loss=0.480141, train/wer=0.152957, validation/ctc_loss=0.696736, validation/num_examples=5348, validation/wer=0.198986
I0920 04:05:33.273715 139932416833280 logging_writer.py:48] [26000] global_step=26000, grad_norm=2.987709, loss=1.689450
I0920 04:05:33.280744 139961138972480 pytorch_submission_base.py:86] 26000) loss = 1.689, grad_norm = 2.988
I0920 04:12:59.125486 139932408440576 logging_writer.py:48] [26500] global_step=26500, grad_norm=2.348531, loss=1.647408
I0920 04:12:59.130208 139961138972480 pytorch_submission_base.py:86] 26500) loss = 1.647, grad_norm = 2.349
I0920 04:20:27.860826 139932416833280 logging_writer.py:48] [27000] global_step=27000, grad_norm=3.128850, loss=1.650314
I0920 04:20:27.867205 139961138972480 pytorch_submission_base.py:86] 27000) loss = 1.650, grad_norm = 3.129
I0920 04:25:20.610935 139961138972480 spec.py:320] Evaluating on the training split.
I0920 04:25:33.862011 139961138972480 spec.py:332] Evaluating on the validation split.
I0920 04:25:44.714047 139961138972480 spec.py:348] Evaluating on the test split.
I0920 04:25:50.542483 139961138972480 submission_runner.py:376] Time since start: 25091.08s, 	Step: 27327, 	{'train/ctc_loss': 0.47332842303948736, 'train/wer': 0.1517934950284437, 'validation/ctc_loss': 0.6857051224696102, 'validation/wer': 0.19476657171824457, 'validation/num_examples': 5348, 'test/ctc_loss': 0.41591244293986707, 'test/wer': 0.1315784128531676, 'test/num_examples': 2472, 'score': 24506.454874038696, 'total_duration': 25091.07887482643, 'accumulated_submission_time': 24506.454874038696, 'accumulated_eval_time': 554.3161730766296, 'accumulated_logging_time': 0.7285242080688477}
I0920 04:25:50.580812 139932416833280 logging_writer.py:48] [27327] accumulated_eval_time=554.316173, accumulated_logging_time=0.728524, accumulated_submission_time=24506.454874, global_step=27327, preemption_count=0, score=24506.454874, test/ctc_loss=0.415912, test/num_examples=2472, test/wer=0.131578, total_duration=25091.078875, train/ctc_loss=0.473328, train/wer=0.151793, validation/ctc_loss=0.685705, validation/num_examples=5348, validation/wer=0.194767
I0920 04:28:27.529521 139932408440576 logging_writer.py:48] [27500] global_step=27500, grad_norm=1.988638, loss=1.631484
I0920 04:28:27.533437 139961138972480 pytorch_submission_base.py:86] 27500) loss = 1.631, grad_norm = 1.989
I0920 04:35:56.188837 139932416833280 logging_writer.py:48] [28000] global_step=28000, grad_norm=3.270445, loss=1.632973
I0920 04:35:56.195976 139961138972480 pytorch_submission_base.py:86] 28000) loss = 1.633, grad_norm = 3.270
I0920 04:43:24.063617 139932408440576 logging_writer.py:48] [28500] global_step=28500, grad_norm=2.594431, loss=1.522621
I0920 04:43:24.069077 139961138972480 pytorch_submission_base.py:86] 28500) loss = 1.523, grad_norm = 2.594
I0920 04:49:51.933255 139961138972480 spec.py:320] Evaluating on the training split.
I0920 04:50:04.974672 139961138972480 spec.py:332] Evaluating on the validation split.
I0920 04:50:15.880949 139961138972480 spec.py:348] Evaluating on the test split.
I0920 04:50:22.143200 139961138972480 submission_runner.py:376] Time since start: 26562.68s, 	Step: 28932, 	{'train/ctc_loss': 0.45254148895542967, 'train/wer': 0.1446974576592278, 'validation/ctc_loss': 0.667585983414331, 'validation/wer': 0.1898517839038285, 'validation/num_examples': 5348, 'test/ctc_loss': 0.39916375653267955, 'test/wer': 0.1280238864176467, 'test/num_examples': 2472, 'score': 25946.04491996765, 'total_duration': 26562.679399967194, 'accumulated_submission_time': 25946.04491996765, 'accumulated_eval_time': 584.5260097980499, 'accumulated_logging_time': 0.779895544052124}
I0920 04:50:22.176878 139932416833280 logging_writer.py:48] [28932] accumulated_eval_time=584.526010, accumulated_logging_time=0.779896, accumulated_submission_time=25946.044920, global_step=28932, preemption_count=0, score=25946.044920, test/ctc_loss=0.399164, test/num_examples=2472, test/wer=0.128024, total_duration=26562.679400, train/ctc_loss=0.452541, train/wer=0.144697, validation/ctc_loss=0.667586, validation/num_examples=5348, validation/wer=0.189852
I0920 04:51:24.720482 139932408440576 logging_writer.py:48] [29000] global_step=29000, grad_norm=2.215285, loss=1.594896
I0920 04:51:24.725988 139961138972480 pytorch_submission_base.py:86] 29000) loss = 1.595, grad_norm = 2.215
I0920 04:58:52.161517 139932416833280 logging_writer.py:48] [29500] global_step=29500, grad_norm=2.556335, loss=1.679308
I0920 04:58:52.167023 139961138972480 pytorch_submission_base.py:86] 29500) loss = 1.679, grad_norm = 2.556
I0920 05:06:21.292732 139932416833280 logging_writer.py:48] [30000] global_step=30000, grad_norm=2.784374, loss=1.609454
I0920 05:06:21.300325 139961138972480 pytorch_submission_base.py:86] 30000) loss = 1.609, grad_norm = 2.784
I0920 05:13:47.604249 139932408440576 logging_writer.py:48] [30500] global_step=30500, grad_norm=2.931311, loss=1.558376
I0920 05:13:47.609054 139961138972480 pytorch_submission_base.py:86] 30500) loss = 1.558, grad_norm = 2.931
I0920 05:14:23.167319 139961138972480 spec.py:320] Evaluating on the training split.
I0920 05:14:36.346427 139961138972480 spec.py:332] Evaluating on the validation split.
I0920 05:14:47.470553 139961138972480 spec.py:348] Evaluating on the test split.
I0920 05:14:53.236016 139961138972480 submission_runner.py:376] Time since start: 28033.77s, 	Step: 30540, 	{'train/ctc_loss': 0.42920146962405203, 'train/wer': 0.13973402038419278, 'validation/ctc_loss': 0.64135408621848, 'validation/wer': 0.18345966301356637, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3819899922978902, 'test/wer': 0.12121950724107813, 'test/num_examples': 2472, 'score': 27385.268892288208, 'total_duration': 28033.772387742996, 'accumulated_submission_time': 27385.268892288208, 'accumulated_eval_time': 614.594479560852, 'accumulated_logging_time': 0.8233187198638916}
I0920 05:14:53.270889 139932416833280 logging_writer.py:48] [30540] accumulated_eval_time=614.594480, accumulated_logging_time=0.823319, accumulated_submission_time=27385.268892, global_step=30540, preemption_count=0, score=27385.268892, test/ctc_loss=0.381990, test/num_examples=2472, test/wer=0.121220, total_duration=28033.772388, train/ctc_loss=0.429201, train/wer=0.139734, validation/ctc_loss=0.641354, validation/num_examples=5348, validation/wer=0.183460
I0920 05:21:47.394452 139932416833280 logging_writer.py:48] [31000] global_step=31000, grad_norm=2.256000, loss=1.628379
I0920 05:21:47.405903 139961138972480 pytorch_submission_base.py:86] 31000) loss = 1.628, grad_norm = 2.256
I0920 05:29:15.192746 139932408440576 logging_writer.py:48] [31500] global_step=31500, grad_norm=1.404575, loss=1.617827
I0920 05:29:15.199816 139961138972480 pytorch_submission_base.py:86] 31500) loss = 1.618, grad_norm = 1.405
I0920 05:36:45.360182 139932416833280 logging_writer.py:48] [32000] global_step=32000, grad_norm=3.312717, loss=1.596179
I0920 05:36:45.368179 139961138972480 pytorch_submission_base.py:86] 32000) loss = 1.596, grad_norm = 3.313
I0920 05:38:53.834070 139961138972480 spec.py:320] Evaluating on the training split.
I0920 05:39:07.047966 139961138972480 spec.py:332] Evaluating on the validation split.
I0920 05:39:18.053653 139961138972480 spec.py:348] Evaluating on the test split.
I0920 05:39:24.071258 139961138972480 submission_runner.py:376] Time since start: 29504.61s, 	Step: 32144, 	{'train/ctc_loss': 0.4171962447447041, 'train/wer': 0.13427261557447592, 'validation/ctc_loss': 0.6306932789268134, 'validation/wer': 0.17936561579684257, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3761726310971676, 'test/wer': 0.11890398716308168, 'test/num_examples': 2472, 'score': 28824.049847602844, 'total_duration': 29504.607519626617, 'accumulated_submission_time': 28824.049847602844, 'accumulated_eval_time': 644.8314497470856, 'accumulated_logging_time': 0.8680906295776367}
I0920 05:39:24.110597 139932416833280 logging_writer.py:48] [32144] accumulated_eval_time=644.831450, accumulated_logging_time=0.868091, accumulated_submission_time=28824.049848, global_step=32144, preemption_count=0, score=28824.049848, test/ctc_loss=0.376173, test/num_examples=2472, test/wer=0.118904, total_duration=29504.607520, train/ctc_loss=0.417196, train/wer=0.134273, validation/ctc_loss=0.630693, validation/num_examples=5348, validation/wer=0.179366
I0920 05:44:43.123828 139932408440576 logging_writer.py:48] [32500] global_step=32500, grad_norm=2.318238, loss=1.546873
I0920 05:44:43.128279 139961138972480 pytorch_submission_base.py:86] 32500) loss = 1.547, grad_norm = 2.318
I0920 05:52:10.391683 139932416833280 logging_writer.py:48] [33000] global_step=33000, grad_norm=1.573206, loss=1.541781
I0920 05:52:10.398840 139961138972480 pytorch_submission_base.py:86] 33000) loss = 1.542, grad_norm = 1.573
I0920 05:59:37.861250 139932408440576 logging_writer.py:48] [33500] global_step=33500, grad_norm=1.723203, loss=1.518456
I0920 05:59:37.895890 139961138972480 pytorch_submission_base.py:86] 33500) loss = 1.518, grad_norm = 1.723
I0920 06:03:25.246983 139961138972480 spec.py:320] Evaluating on the training split.
I0920 06:03:38.447156 139961138972480 spec.py:332] Evaluating on the validation split.
I0920 06:03:49.527466 139961138972480 spec.py:348] Evaluating on the test split.
I0920 06:03:55.463889 139961138972480 submission_runner.py:376] Time since start: 30976.00s, 	Step: 33754, 	{'train/ctc_loss': 0.4026355583287145, 'train/wer': 0.13119820731687515, 'validation/ctc_loss': 0.6131695545603526, 'validation/wer': 0.17635301501472506, 'validation/num_examples': 5348, 'test/ctc_loss': 0.36132172337731466, 'test/wer': 0.11557288810350781, 'test/num_examples': 2472, 'score': 30263.43829393387, 'total_duration': 30976.00019311905, 'accumulated_submission_time': 30263.43829393387, 'accumulated_eval_time': 675.0480570793152, 'accumulated_logging_time': 0.917236328125}
I0920 06:03:55.498991 139932416833280 logging_writer.py:48] [33754] accumulated_eval_time=675.048057, accumulated_logging_time=0.917236, accumulated_submission_time=30263.438294, global_step=33754, preemption_count=0, score=30263.438294, test/ctc_loss=0.361322, test/num_examples=2472, test/wer=0.115573, total_duration=30976.000193, train/ctc_loss=0.402636, train/wer=0.131198, validation/ctc_loss=0.613170, validation/num_examples=5348, validation/wer=0.176353
I0920 06:07:38.070337 139932416833280 logging_writer.py:48] [34000] global_step=34000, grad_norm=2.141685, loss=1.487058
I0920 06:07:38.076920 139961138972480 pytorch_submission_base.py:86] 34000) loss = 1.487, grad_norm = 2.142
I0920 06:15:05.104663 139932408440576 logging_writer.py:48] [34500] global_step=34500, grad_norm=3.159763, loss=1.523520
I0920 06:15:05.135594 139961138972480 pytorch_submission_base.py:86] 34500) loss = 1.524, grad_norm = 3.160
I0920 06:22:34.090566 139932416833280 logging_writer.py:48] [35000] global_step=35000, grad_norm=3.752623, loss=1.558876
I0920 06:22:34.095095 139961138972480 pytorch_submission_base.py:86] 35000) loss = 1.559, grad_norm = 3.753
I0920 06:27:56.091389 139961138972480 spec.py:320] Evaluating on the training split.
I0920 06:28:09.127219 139961138972480 spec.py:332] Evaluating on the validation split.
I0920 06:28:20.117294 139961138972480 spec.py:348] Evaluating on the test split.
I0920 06:28:27.429042 139961138972480 submission_runner.py:376] Time since start: 32447.97s, 	Step: 35359, 	{'train/ctc_loss': 0.3901621516465467, 'train/wer': 0.12881121076475904, 'validation/ctc_loss': 0.6021189659935704, 'validation/wer': 0.17467291073239027, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3570643670559391, 'test/wer': 0.1145573091219304, 'test/num_examples': 2472, 'score': 31702.329017162323, 'total_duration': 32447.96523475647, 'accumulated_submission_time': 31702.329017162323, 'accumulated_eval_time': 706.3854501247406, 'accumulated_logging_time': 0.9621999263763428}
I0920 06:28:27.454192 139932416833280 logging_writer.py:48] [35359] accumulated_eval_time=706.385450, accumulated_logging_time=0.962200, accumulated_submission_time=31702.329017, global_step=35359, preemption_count=0, score=31702.329017, test/ctc_loss=0.357064, test/num_examples=2472, test/wer=0.114557, total_duration=32447.965235, train/ctc_loss=0.390162, train/wer=0.128811, validation/ctc_loss=0.602119, validation/num_examples=5348, validation/wer=0.174673
I0920 06:30:34.908843 139932408440576 logging_writer.py:48] [35500] global_step=35500, grad_norm=2.186275, loss=1.544297
I0920 06:30:34.915678 139961138972480 pytorch_submission_base.py:86] 35500) loss = 1.544, grad_norm = 2.186
I0920 06:38:01.750294 139961138972480 spec.py:320] Evaluating on the training split.
I0920 06:38:14.441300 139961138972480 spec.py:332] Evaluating on the validation split.
I0920 06:38:25.905982 139961138972480 spec.py:348] Evaluating on the test split.
I0920 06:38:31.644244 139961138972480 submission_runner.py:376] Time since start: 33052.18s, 	Step: 36000, 	{'train/ctc_loss': 0.38673229484913413, 'train/wer': 0.1259857862744992, 'validation/ctc_loss': 0.6005702893466195, 'validation/wer': 0.1718534253850239, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3538972272404671, 'test/wer': 0.112688643795828, 'test/num_examples': 2472, 'score': 32275.458278417587, 'total_duration': 33052.180570364, 'accumulated_submission_time': 32275.458278417587, 'accumulated_eval_time': 736.2791187763214, 'accumulated_logging_time': 0.9973902702331543}
I0920 06:38:31.683928 139932416833280 logging_writer.py:48] [36000] accumulated_eval_time=736.279119, accumulated_logging_time=0.997390, accumulated_submission_time=32275.458278, global_step=36000, preemption_count=0, score=32275.458278, test/ctc_loss=0.353897, test/num_examples=2472, test/wer=0.112689, total_duration=33052.180570, train/ctc_loss=0.386732, train/wer=0.125986, validation/ctc_loss=0.600570, validation/num_examples=5348, validation/wer=0.171853
I0920 06:38:32.208824 139932408440576 logging_writer.py:48] [36000] global_step=36000, preemption_count=0, score=32275.458278
I0920 06:38:32.627803 139961138972480 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/targets_check_pytorch/nadamw_run_0/librispeech_deepspeech_pytorch/trial_1/checkpoint_36000.
I0920 06:38:32.763951 139961138972480 submission_runner.py:540] Tuning trial 1/1
I0920 06:38:32.764371 139961138972480 submission_runner.py:541] Hyperparameters: Hyperparameters(learning_rate=0.004958460849689891, beta1=0.863744242567442, beta2=0.6291854735396584, warmup_steps=1200, weight_decay=0.1147386261512052)
I0920 06:38:32.765540 139961138972480 submission_runner.py:542] Metrics: {'eval_results': [(1, {'train/ctc_loss': 31.04407351330891, 'train/wer': 2.9127041260940403, 'validation/ctc_loss': 30.32050557564798, 'validation/wer': 2.7464780572587264, 'validation/num_examples': 5348, 'test/ctc_loss': 30.387986321698175, 'test/wer': 2.7104584323522842, 'test/num_examples': 2472, 'score': 36.868207693099976, 'total_duration': 82.17002820968628, 'accumulated_submission_time': 36.868207693099976, 'accumulated_eval_time': 44.93013048171997, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (1602, {'train/ctc_loss': 1.2508076215308288, 'train/wer': 0.3603390509388312, 'validation/ctc_loss': 1.5011907312700925, 'validation/wer': 0.38953314343648915, 'validation/num_examples': 5348, 'test/ctc_loss': 1.083412538712175, 'test/wer': 0.3199276907765117, 'test/num_examples': 2472, 'score': 1476.5534012317657, 'total_duration': 1553.1907448768616, 'accumulated_submission_time': 1476.5534012317657, 'accumulated_eval_time': 74.6964762210846, 'accumulated_logging_time': 0.03228139877319336, 'global_step': 1602, 'preemption_count': 0}), (3208, {'train/ctc_loss': 0.8282067443526692, 'train/wer': 0.25189579488067726, 'validation/ctc_loss': 1.0598616919077757, 'validation/wer': 0.2892869212571815, 'validation/num_examples': 5348, 'test/ctc_loss': 0.7085474264468675, 'test/wer': 0.2214368411431357, 'test/num_examples': 2472, 'score': 2916.092693090439, 'total_duration': 3024.458050966263, 'accumulated_submission_time': 2916.092693090439, 'accumulated_eval_time': 104.70599293708801, 'accumulated_logging_time': 0.07709789276123047, 'global_step': 3208, 'preemption_count': 0}), (4817, {'train/ctc_loss': 0.7366871823165209, 'train/wer': 0.22720851307976683, 'validation/ctc_loss': 0.9653922692824493, 'validation/wer': 0.26906773523873895, 'validation/num_examples': 5348, 'test/ctc_loss': 0.6246607644041551, 'test/wer': 0.19645359819633174, 'test/num_examples': 2472, 'score': 4355.545656919479, 'total_duration': 4495.32933306694, 'accumulated_submission_time': 4355.545656919479, 'accumulated_eval_time': 134.33108258247375, 'accumulated_logging_time': 0.12296557426452637, 'global_step': 4817, 'preemption_count': 0}), (6423, {'train/ctc_loss': 0.733113190370135, 'train/wer': 0.22596900693365665, 'validation/ctc_loss': 0.9641354135272252, 'validation/wer': 0.26491575339158985, 'validation/num_examples': 5348, 'test/ctc_loss': 0.634859507064972, 'test/wer': 0.19629110555927934, 'test/num_examples': 2472, 'score': 5794.9216940402985, 'total_duration': 5966.186363935471, 'accumulated_submission_time': 5794.9216940402985, 'accumulated_eval_time': 164.03225684165955, 'accumulated_logging_time': 0.16985416412353516, 'global_step': 6423, 'preemption_count': 0}), (8035, {'train/ctc_loss': 0.692546129584443, 'train/wer': 0.2115333611184784, 'validation/ctc_loss': 0.9096526639730259, 'validation/wer': 0.2512914594698981, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5960352784857088, 'test/wer': 0.1830479556395101, 'test/num_examples': 2472, 'score': 7234.23419713974, 'total_duration': 7437.372326850891, 'accumulated_submission_time': 7234.23419713974, 'accumulated_eval_time': 194.17896485328674, 'accumulated_logging_time': 0.20123076438903809, 'global_step': 8035, 'preemption_count': 0}), (9643, {'train/ctc_loss': 0.6725744739634731, 'train/wer': 0.20772282694004363, 'validation/ctc_loss': 0.9035184897403054, 'validation/wer': 0.25018104572007915, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5720376617039808, 'test/wer': 0.17705603964820343, 'test/num_examples': 2472, 'score': 8673.728166103363, 'total_duration': 8908.456150531769, 'accumulated_submission_time': 8673.728166103363, 'accumulated_eval_time': 224.10325002670288, 'accumulated_logging_time': 0.24254274368286133, 'global_step': 9643, 'preemption_count': 0}), (11251, {'train/ctc_loss': 0.6454252100428535, 'train/wer': 0.19813153920682433, 'validation/ctc_loss': 0.870422498179124, 'validation/wer': 0.2426495437647854, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5504047136105555, 'test/wer': 0.17307497004042005, 'test/num_examples': 2472, 'score': 10113.030045032501, 'total_duration': 10379.324222326279, 'accumulated_submission_time': 10113.030045032501, 'accumulated_eval_time': 253.90812158584595, 'accumulated_logging_time': 0.27747535705566406, 'global_step': 11251, 'preemption_count': 0}), (12859, {'train/ctc_loss': 0.6189322244264799, 'train/wer': 0.1934333237709133, 'validation/ctc_loss': 0.8462405581298975, 'validation/wer': 0.23455800704871338, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5306064604974514, 'test/wer': 0.16586435927122054, 'test/num_examples': 2472, 'score': 11552.619503974915, 'total_duration': 11850.654608011246, 'accumulated_submission_time': 11552.619503974915, 'accumulated_eval_time': 283.87430715560913, 'accumulated_logging_time': 0.3247349262237549, 'global_step': 12859, 'preemption_count': 0}), (14469, {'train/ctc_loss': 0.5973577352547551, 'train/wer': 0.18628315949575375, 'validation/ctc_loss': 0.8088481428634218, 'validation/wer': 0.22906387293004393, 'validation/num_examples': 5348, 'test/ctc_loss': 0.5167500221788502, 'test/wer': 0.1621676517782788, 'test/num_examples': 2472, 'score': 12992.29988026619, 'total_duration': 13321.870917797089, 'accumulated_submission_time': 12992.29988026619, 'accumulated_eval_time': 313.5970251560211, 'accumulated_logging_time': 0.3718898296356201, 'global_step': 14469, 'preemption_count': 0}), (16078, {'train/ctc_loss': 0.5720028866106552, 'train/wer': 0.18101661154743412, 'validation/ctc_loss': 0.7827905827745127, 'validation/wer': 0.2216965190942886, 'validation/num_examples': 5348, 'test/ctc_loss': 0.49324719538357314, 'test/wer': 0.15654134422034002, 'test/num_examples': 2472, 'score': 14431.795169830322, 'total_duration': 14792.99766588211, 'accumulated_submission_time': 14431.795169830322, 'accumulated_eval_time': 343.4546799659729, 'accumulated_logging_time': 0.42113399505615234, 'global_step': 16078, 'preemption_count': 0}), (17685, {'train/ctc_loss': 0.5611470992794668, 'train/wer': 0.17594492046051172, 'validation/ctc_loss': 0.7787338358009342, 'validation/wer': 0.21826872012745618, 'validation/num_examples': 5348, 'test/ctc_loss': 0.49183601563004065, 'test/wer': 0.15408364308492273, 'test/num_examples': 2472, 'score': 15870.984115600586, 'total_duration': 16264.424582004547, 'accumulated_submission_time': 15870.984115600586, 'accumulated_eval_time': 373.8921477794647, 'accumulated_logging_time': 0.46599626541137695, 'global_step': 17685, 'preemption_count': 0}), (19291, {'train/ctc_loss': 0.56553726739824, 'train/wer': 0.17782312409675727, 'validation/ctc_loss': 0.7843243470746685, 'validation/wer': 0.2216772075508135, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4799613079876121, 'test/wer': 0.15006195031787622, 'test/num_examples': 2472, 'score': 17310.349919080734, 'total_duration': 17735.488792419434, 'accumulated_submission_time': 17310.349919080734, 'accumulated_eval_time': 403.7736220359802, 'accumulated_logging_time': 0.5115301609039307, 'global_step': 19291, 'preemption_count': 0}), (20900, {'train/ctc_loss': 0.5245474383389885, 'train/wer': 0.16665674340057698, 'validation/ctc_loss': 0.7378863671325597, 'validation/wer': 0.20885434268333897, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4533725966191367, 'test/wer': 0.14384660695062254, 'test/num_examples': 2472, 'score': 18749.61420226097, 'total_duration': 19206.258034944534, 'accumulated_submission_time': 18749.61420226097, 'accumulated_eval_time': 433.58908557891846, 'accumulated_logging_time': 0.5568807125091553, 'global_step': 20900, 'preemption_count': 0}), (22508, {'train/ctc_loss': 0.527613379628378, 'train/wer': 0.1654551260886274, 'validation/ctc_loss': 0.7476798546752562, 'validation/wer': 0.2118862550089316, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4595737527421124, 'test/wer': 0.1450449901488839, 'test/num_examples': 2472, 'score': 20188.924441337585, 'total_duration': 20677.41715168953, 'accumulated_submission_time': 20188.924441337585, 'accumulated_eval_time': 463.6098425388336, 'accumulated_logging_time': 0.5915889739990234, 'global_step': 22508, 'preemption_count': 0}), (24114, {'train/ctc_loss': 0.5054017808862693, 'train/wer': 0.1602860065710064, 'validation/ctc_loss': 0.7173843429776974, 'validation/wer': 0.2045575242601265, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4408882226272663, 'test/wer': 0.13889058152052486, 'test/num_examples': 2472, 'score': 21627.81825709343, 'total_duration': 22148.695760011673, 'accumulated_submission_time': 21627.81825709343, 'accumulated_eval_time': 494.280597448349, 'accumulated_logging_time': 0.6409873962402344, 'global_step': 24114, 'preemption_count': 0}), (25719, {'train/ctc_loss': 0.4801412445250294, 'train/wer': 0.15295722350623273, 'validation/ctc_loss': 0.6967359914199066, 'validation/wer': 0.1989861439675566, 'validation/num_examples': 5348, 'test/ctc_loss': 0.421221681640751, 'test/wer': 0.13324396238295452, 'test/num_examples': 2472, 'score': 23066.921323537827, 'total_duration': 23619.743231773376, 'accumulated_submission_time': 23066.921323537827, 'accumulated_eval_time': 524.3847284317017, 'accumulated_logging_time': 0.6782586574554443, 'global_step': 25719, 'preemption_count': 0}), (27327, {'train/ctc_loss': 0.47332842303948736, 'train/wer': 0.1517934950284437, 'validation/ctc_loss': 0.6857051224696102, 'validation/wer': 0.19476657171824457, 'validation/num_examples': 5348, 'test/ctc_loss': 0.41591244293986707, 'test/wer': 0.1315784128531676, 'test/num_examples': 2472, 'score': 24506.454874038696, 'total_duration': 25091.07887482643, 'accumulated_submission_time': 24506.454874038696, 'accumulated_eval_time': 554.3161730766296, 'accumulated_logging_time': 0.7285242080688477, 'global_step': 27327, 'preemption_count': 0}), (28932, {'train/ctc_loss': 0.45254148895542967, 'train/wer': 0.1446974576592278, 'validation/ctc_loss': 0.667585983414331, 'validation/wer': 0.1898517839038285, 'validation/num_examples': 5348, 'test/ctc_loss': 0.39916375653267955, 'test/wer': 0.1280238864176467, 'test/num_examples': 2472, 'score': 25946.04491996765, 'total_duration': 26562.679399967194, 'accumulated_submission_time': 25946.04491996765, 'accumulated_eval_time': 584.5260097980499, 'accumulated_logging_time': 0.779895544052124, 'global_step': 28932, 'preemption_count': 0}), (30540, {'train/ctc_loss': 0.42920146962405203, 'train/wer': 0.13973402038419278, 'validation/ctc_loss': 0.64135408621848, 'validation/wer': 0.18345966301356637, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3819899922978902, 'test/wer': 0.12121950724107813, 'test/num_examples': 2472, 'score': 27385.268892288208, 'total_duration': 28033.772387742996, 'accumulated_submission_time': 27385.268892288208, 'accumulated_eval_time': 614.594479560852, 'accumulated_logging_time': 0.8233187198638916, 'global_step': 30540, 'preemption_count': 0}), (32144, {'train/ctc_loss': 0.4171962447447041, 'train/wer': 0.13427261557447592, 'validation/ctc_loss': 0.6306932789268134, 'validation/wer': 0.17936561579684257, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3761726310971676, 'test/wer': 0.11890398716308168, 'test/num_examples': 2472, 'score': 28824.049847602844, 'total_duration': 29504.607519626617, 'accumulated_submission_time': 28824.049847602844, 'accumulated_eval_time': 644.8314497470856, 'accumulated_logging_time': 0.8680906295776367, 'global_step': 32144, 'preemption_count': 0}), (33754, {'train/ctc_loss': 0.4026355583287145, 'train/wer': 0.13119820731687515, 'validation/ctc_loss': 0.6131695545603526, 'validation/wer': 0.17635301501472506, 'validation/num_examples': 5348, 'test/ctc_loss': 0.36132172337731466, 'test/wer': 0.11557288810350781, 'test/num_examples': 2472, 'score': 30263.43829393387, 'total_duration': 30976.00019311905, 'accumulated_submission_time': 30263.43829393387, 'accumulated_eval_time': 675.0480570793152, 'accumulated_logging_time': 0.917236328125, 'global_step': 33754, 'preemption_count': 0}), (35359, {'train/ctc_loss': 0.3901621516465467, 'train/wer': 0.12881121076475904, 'validation/ctc_loss': 0.6021189659935704, 'validation/wer': 0.17467291073239027, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3570643670559391, 'test/wer': 0.1145573091219304, 'test/num_examples': 2472, 'score': 31702.329017162323, 'total_duration': 32447.96523475647, 'accumulated_submission_time': 31702.329017162323, 'accumulated_eval_time': 706.3854501247406, 'accumulated_logging_time': 0.9621999263763428, 'global_step': 35359, 'preemption_count': 0}), (36000, {'train/ctc_loss': 0.38673229484913413, 'train/wer': 0.1259857862744992, 'validation/ctc_loss': 0.6005702893466195, 'validation/wer': 0.1718534253850239, 'validation/num_examples': 5348, 'test/ctc_loss': 0.3538972272404671, 'test/wer': 0.112688643795828, 'test/num_examples': 2472, 'score': 32275.458278417587, 'total_duration': 33052.180570364, 'accumulated_submission_time': 32275.458278417587, 'accumulated_eval_time': 736.2791187763214, 'accumulated_logging_time': 0.9973902702331543, 'global_step': 36000, 'preemption_count': 0})], 'global_step': 36000}
I0920 06:38:32.765677 139961138972480 submission_runner.py:543] Timing: 32275.458278417587
I0920 06:38:32.765730 139961138972480 submission_runner.py:545] Total number of evals: 24
I0920 06:38:32.765777 139961138972480 submission_runner.py:546] ====================
I0920 06:38:32.765925 139961138972480 submission_runner.py:614] Final librispeech_deepspeech score: 32275.458278417587
