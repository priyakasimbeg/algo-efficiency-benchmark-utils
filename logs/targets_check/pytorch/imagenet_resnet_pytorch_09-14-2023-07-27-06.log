torchrun --redirects 1:0,2:0,3:0,4:0,5:0,6:0,7:0 --standalone --nnodes=1 --nproc_per_node=8 submission_runner.py --framework=pytorch --workload=imagenet_resnet --submission_path=reference_algorithms/target_setting_algorithms/pytorch_momentum.py --tuning_search_space=reference_algorithms/target_setting_algorithms/imagenet_resnet/tuning_search_space.json --data_dir=/data/imagenet/pytorch --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=targets_check_pytorch/momentum_run_0 --overwrite=true --save_checkpoints=false --max_global_steps=140000 --imagenet_v2_data_dir=/data/imagenet/pytorch --torch_compile=true 2>&1 | tee -a /logs/imagenet_resnet_pytorch_09-14-2023-07-27-06.log
master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-09-14 07:27:18.437740: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-14 07:27:18.437741: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-14 07:27:18.437740: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-14 07:27:18.437739: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-14 07:27:18.437740: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-14 07:27:18.437746: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-14 07:27:18.437747: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-14 07:27:18.437763: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0914 07:27:33.582792 140100139824960 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 6
I0914 07:27:33.582813 140679388120896 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 4
I0914 07:27:33.582828 139967587874624 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
I0914 07:27:33.583815 139674672731968 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
I0914 07:27:33.584008 140665363318592 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
I0914 07:27:33.584420 140532238145344 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 5
I0914 07:27:33.584639 139915133245248 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 7
I0914 07:27:33.594230 139834269067072 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
I0914 07:27:33.594593 139674672731968 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0914 07:27:33.594778 139834269067072 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0914 07:27:33.594972 140665363318592 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0914 07:27:33.595226 140532238145344 distributed_c10d.py:476] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0914 07:27:33.595451 139915133245248 distributed_c10d.py:476] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0914 07:27:33.603936 140100139824960 distributed_c10d.py:476] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0914 07:27:33.603962 140679388120896 distributed_c10d.py:476] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0914 07:27:33.603986 139967587874624 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
I0914 07:27:35.112408 139834269067072 logger_utils.py:76] Creating experiment directory at /experiment_runs/targets_check_pytorch/momentum_run_0/imagenet_resnet_pytorch.
W0914 07:27:36.241489 139674672731968 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0914 07:27:36.241488 140679388120896 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0914 07:27:36.241489 140532238145344 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0914 07:27:36.241487 139834269067072 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0914 07:27:36.241512 140100139824960 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0914 07:27:36.241539 139967587874624 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0914 07:27:36.241541 140665363318592 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0914 07:27:36.242892 139915133245248 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0914 07:27:36.249619 139834269067072 submission_runner.py:500] Using RNG seed 3442435321
I0914 07:27:36.251606 139834269067072 submission_runner.py:509] --- Tuning run 1/1 ---
I0914 07:27:36.251747 139834269067072 submission_runner.py:514] Creating tuning directory at /experiment_runs/targets_check_pytorch/momentum_run_0/imagenet_resnet_pytorch/trial_1.
I0914 07:27:36.251937 139834269067072 logger_utils.py:92] Saving hparams to /experiment_runs/targets_check_pytorch/momentum_run_0/imagenet_resnet_pytorch/trial_1/hparams.json.
I0914 07:27:36.252710 139834269067072 submission_runner.py:185] Initializing dataset.
I0914 07:27:42.587494 139834269067072 submission_runner.py:192] Initializing model.
I0914 07:27:47.527713 139834269067072 submission_runner.py:223] Performing `torch.compile`.
I0914 07:27:47.807898 139834269067072 submission_runner.py:226] Initializing optimizer.
I0914 07:27:48.414454 139834269067072 submission_runner.py:233] Initializing metrics bundle.
I0914 07:27:48.414650 139834269067072 submission_runner.py:251] Initializing checkpoint and logger.
I0914 07:27:48.871601 139834269067072 submission_runner.py:272] Saving meta data to /experiment_runs/targets_check_pytorch/momentum_run_0/imagenet_resnet_pytorch/trial_1/meta_data_0.json.
I0914 07:27:48.872510 139834269067072 submission_runner.py:275] Saving flags to /experiment_runs/targets_check_pytorch/momentum_run_0/imagenet_resnet_pytorch/trial_1/flags_0.json.
I0914 07:27:48.972651 139834269067072 submission_runner.py:285] Starting training loop.
[2023-09-14 07:27:51,290] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:27:51,334] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:27:51,342] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:27:51,411] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:27:51,455] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:27:51,540] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:27:51,569] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:27:51,572] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:27:53,402] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:27:53,404] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:27:53,419] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:27:53,436] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:27:53,440] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:27:53,441] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:27:53,450] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:27:53,454] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:27:53,455] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:27:53,457] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:27:53,458] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:27:53,461] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:27:53,462] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:27:53,467] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:27:53,522] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:27:53,525] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:27:53,532] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:27:53,549] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:27:53,551] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:27:53,553] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:27:53,554] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:27:53,591] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:27:53,604] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:27:53,607] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:27:53,613] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:27:53,670] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:27:53,673] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:27:53,674] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:27:53,681] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:27:53,711] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:27:53,714] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:27:53,715] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:28:04,932] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-14 07:28:04,940] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-14 07:28:04,941] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-14 07:28:04,941] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-14 07:28:04,944] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-14 07:28:04,946] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-14 07:28:04,950] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-14 07:28:04,952] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-14 07:28:13,967] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-14 07:28:14,015] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-14 07:28:14,037] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-14 07:28:14,074] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-14 07:28:14,085] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-14 07:28:14,135] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-14 07:28:14,178] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-14 07:28:14,190] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-14 07:28:18,390] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-14 07:28:18,434] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-14 07:28:18,454] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-14 07:28:18,468] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-14 07:28:18,546] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-14 07:28:18,593] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-14 07:28:18,814] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-14 07:28:18,880] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-14 07:28:20,250] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-14 07:28:20,313] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-14 07:28:20,345] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-14 07:28:20,350] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-14 07:28:20,419] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-14 07:28:20,479] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-14 07:28:20,735] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-14 07:28:20,793] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-14 07:28:21,400] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-14 07:28:21,456] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-14 07:28:21,486] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-14 07:28:21,489] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-14 07:28:21,538] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-14 07:28:21,607] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-14 07:28:21,851] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-14 07:28:21,972] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-14 07:28:22,234] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-14 07:28:22,319] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-14 07:28:22,330] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-14 07:28:22,354] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-14 07:28:22,446] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-14 07:28:22,514] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-14 07:28:22,753] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-14 07:28:22,823] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-14 07:28:23,437] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-14 07:28:23,516] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-14 07:28:23,559] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-14 07:28:23,622] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-14 07:28:23,688] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-14 07:28:24,120] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-14 07:28:24,437] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-14 07:28:24,601] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-14 07:28:25,062] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-14 07:28:25,127] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-14 07:28:25,213] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-14 07:28:25,218] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-14 07:28:25,225] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:28:25,238] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-14 07:28:25,256] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-14 07:28:25,258] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-14 07:28:25,272] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-14 07:28:25,279] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-14 07:28:25,285] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:28:25,321] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-14 07:28:25,380] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-14 07:28:25,385] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-14 07:28:25,392] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:28:25,399] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-14 07:28:25,404] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-14 07:28:25,406] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-14 07:28:25,411] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:28:25,412] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-14 07:28:25,419] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:28:25,462] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-14 07:28:25,468] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-14 07:28:25,475] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:28:25,571] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-14 07:28:25,707] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-14 07:28:25,712] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-14 07:28:25,719] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:28:25,778] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-14 07:28:25,981] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-14 07:28:25,986] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-14 07:28:25,993] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:28:31,479] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-14 07:28:31,944] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-14 07:28:32,031] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-14 07:28:32,032] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-14 07:28:32,033] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-14 07:28:32,033] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-14 07:28:32,033] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-14 07:28:32,036] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-14 07:28:32,040] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-14 07:28:32,056] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-14 07:28:32,429] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-14 07:28:32,441] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-14 07:28:32,527] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-14 07:28:32,531] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-14 07:28:32,533] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-14 07:28:32,534] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-14 07:28:32,539] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-14 07:28:32,541] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-14 07:28:32,546] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-14 07:28:32,553] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-14 07:28:32,553] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-14 07:28:32,554] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-14 07:28:32,558] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-14 07:28:32,559] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-14 07:28:33,215] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-14 07:28:33,726] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-14 07:28:33,791] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-14 07:28:33,794] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-14 07:28:33,805] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-14 07:28:33,837] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-14 07:28:33,838] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-14 07:28:33,843] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-14 07:28:34,581] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-14 07:28:34,581] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-14 07:28:34,792] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-14 07:28:34,792] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-14 07:28:34,793] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-14 07:28:34,909] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-14 07:28:34,911] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-14 07:28:34,951] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-14 07:28:35,669] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-14 07:28:35,690] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-14 07:28:35,900] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-14 07:28:35,914] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-14 07:28:35,918] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-14 07:28:36,022] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-14 07:28:36,061] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-14 07:28:36,077] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-14 07:28:37,188] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-14 07:28:37,196] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-14 07:28:37,414] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-14 07:28:37,448] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-14 07:28:37,449] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-14 07:28:37,580] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-14 07:28:37,583] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-14 07:28:37,594] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-14 07:28:39,373] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-14 07:28:39,380] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-14 07:28:39,699] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-14 07:28:39,741] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-14 07:28:39,745] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-14 07:28:39,880] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-14 07:28:39,938] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-14 07:28:39,978] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-14 07:28:40,632] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-14 07:28:40,650] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-14 07:28:40,983] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-14 07:28:41,060] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-14 07:28:41,064] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-14 07:28:41,180] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-14 07:28:41,263] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-14 07:28:41,266] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-14 07:28:45,472] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-14 07:28:45,648] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-14 07:28:46,291] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-14 07:28:46,442] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-14 07:28:46,510] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-14 07:28:46,529] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-14 07:28:46,612] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-14 07:28:46,699] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
I0914 07:28:49.922109 139806705161984 logging_writer.py:48] [0] global_step=0, grad_norm=0.526896, loss=6.931961
I0914 07:28:49.955935 139834269067072 pytorch_submission_base.py:86] 0) loss = 6.932, grad_norm = 0.527
I0914 07:28:50.564924 139834269067072 spec.py:320] Evaluating on the training split.
[2023-09-14 07:29:00,506] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:29:00,522] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:29:00,543] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:29:00,564] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:29:00,580] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:29:00,658] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:29:00,668] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:29:01,067] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:29:01,878] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:29:01,878] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:29:01,898] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:29:01,899] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:29:01,901] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:29:01,902] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:29:01,902] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:29:01,902] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:29:01,940] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:29:01,954] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:29:01,957] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:29:01,960] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:29:01,963] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:29:01,964] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:29:01,974] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:29:01,976] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:29:01,977] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:29:01,977] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:29:01,979] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:29:01,980] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:29:02,010] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:29:02,029] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:29:02,032] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:29:02,032] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:29:02,033] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:29:02,051] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:29:02,054] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:29:02,054] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:29:02,433] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:29:02,453] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:29:02,456] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:29:02,456] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:29:04,453] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-14 07:29:04,476] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-14 07:29:04,536] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-14 07:29:04,539] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-14 07:29:04,593] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-14 07:29:04,596] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-14 07:29:04,670] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-14 07:29:05,083] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-14 07:29:07,724] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-14 07:29:07,820] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-14 07:29:07,832] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-14 07:29:07,880] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-14 07:29:07,939] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-14 07:29:07,950] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-14 07:29:07,984] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-14 07:29:08,477] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-14 07:29:09,811] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-14 07:29:09,907] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-14 07:29:09,955] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-14 07:29:09,973] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-14 07:29:09,975] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-14 07:29:10,031] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-14 07:29:10,072] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-14 07:29:10,473] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-14 07:29:11,076] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-14 07:29:11,209] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-14 07:29:11,259] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-14 07:29:11,311] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-14 07:29:11,342] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-14 07:29:11,355] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-14 07:29:11,423] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-14 07:29:11,741] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-14 07:29:11,831] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-14 07:29:11,889] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-14 07:29:11,900] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-14 07:29:11,947] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-14 07:29:11,982] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-14 07:29:12,000] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-14 07:29:12,084] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-14 07:29:12,345] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-14 07:29:12,500] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-14 07:29:12,518] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-14 07:29:12,520] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-14 07:29:12,579] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-14 07:29:12,616] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-14 07:29:12,636] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-14 07:29:12,711] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-14 07:29:12,926] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-14 07:29:13,079] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-14 07:29:13,081] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-14 07:29:13,087] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-14 07:29:13,145] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-14 07:29:13,171] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-14 07:29:13,195] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-14 07:29:13,286] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-14 07:29:13,592] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-14 07:29:13,693] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-14 07:29:13,714] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-14 07:29:13,719] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-14 07:29:13,721] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-14 07:29:13,725] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:29:13,789] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-14 07:29:13,791] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-14 07:29:13,835] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-14 07:29:13,849] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-14 07:29:13,857] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-14 07:29:13,864] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-14 07:29:13,871] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:29:13,900] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-14 07:29:13,900] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-14 07:29:13,904] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-14 07:29:13,905] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-14 07:29:13,909] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:29:13,910] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:29:13,936] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-14 07:29:13,957] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-14 07:29:13,962] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-14 07:29:13,967] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:29:13,996] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-14 07:29:14,002] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-14 07:29:14,009] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:29:14,052] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-14 07:29:14,057] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-14 07:29:14,063] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:29:14,326] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-14 07:29:14,435] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-14 07:29:14,440] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-14 07:29:14,445] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0914 07:30:07.875996 139834269067072 spec.py:332] Evaluating on the validation split.
[2023-09-14 07:31:01,346] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:01,836] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:01,895] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:02,152] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:02,717] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:02,775] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:31:02,795] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:31:02,798] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:31:02,798] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:31:03,285] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:31:03,298] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:31:03,305] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:31:03,309] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:31:03,309] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:31:03,318] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:31:03,322] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:31:03,322] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:31:03,534] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:31:03,554] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:31:03,557] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:31:03,557] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:31:04,112] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:31:04,132] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:31:04,136] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:31:04,136] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:31:05,170] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:05,418] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-14 07:31:05,661] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:05,936] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-14 07:31:05,961] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-14 07:31:06,152] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-14 07:31:06,365] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:06,551] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:31:06,570] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:31:06,573] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:31:06,574] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:31:06,739] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-14 07:31:07,039] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:31:07,058] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:31:07,061] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:31:07,061] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:31:07,748] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:31:07,771] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:31:07,774] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:31:07,775] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:31:08,271] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-14 07:31:09,096] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-14 07:31:09,126] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-14 07:31:09,297] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-14 07:31:09,462] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-14 07:31:09,867] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-14 07:31:09,985] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-14 07:31:10,498] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-14 07:31:10,685] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-14 07:31:11,153] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-14 07:31:11,182] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-14 07:31:11,352] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-14 07:31:11,759] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-14 07:31:11,880] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-14 07:31:12,410] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-14 07:31:12,460] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-14 07:31:12,534] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-14 07:31:12,561] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-14 07:31:12,764] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-14 07:31:13,168] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-14 07:31:13,177] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-14 07:31:13,191] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-14 07:31:13,278] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-14 07:31:13,290] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-14 07:31:13,498] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-14 07:31:13,781] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-14 07:31:13,787] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-14 07:31:13,789] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-14 07:31:13,945] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-14 07:31:14,085] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-14 07:31:14,139] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-14 07:31:14,362] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-14 07:31:14,400] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-14 07:31:14,507] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-14 07:31:14,512] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-14 07:31:14,517] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:31:14,523] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-14 07:31:14,646] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-14 07:31:14,661] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-14 07:31:14,713] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-14 07:31:14,964] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-14 07:31:15,073] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-14 07:31:15,078] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-14 07:31:15,083] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:31:15,190] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-14 07:31:15,224] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-14 07:31:15,300] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-14 07:31:15,305] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-14 07:31:15,310] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:31:15,323] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-14 07:31:15,435] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-14 07:31:15,436] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-14 07:31:15,440] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-14 07:31:15,446] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:31:15,913] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-14 07:31:15,925] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-14 07:31:15,997] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-14 07:31:16,044] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-14 07:31:16,049] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-14 07:31:16,054] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:31:16,636] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-14 07:31:16,769] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-14 07:31:17,192] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-14 07:31:17,206] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-14 07:31:17,422] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-14 07:31:17,761] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-14 07:31:17,896] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-14 07:31:18,046] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-14 07:31:18,371] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-14 07:31:18,478] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-14 07:31:18,483] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-14 07:31:18,488] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:31:18,517] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-14 07:31:18,639] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-14 07:31:19,080] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-14 07:31:19,243] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-14 07:31:19,350] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-14 07:31:19,355] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-14 07:31:19,360] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:31:19,687] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-14 07:31:19,794] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-14 07:31:19,799] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-14 07:31:19,804] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0914 07:31:20.945547 139834269067072 spec.py:348] Evaluating on the test split.
I0914 07:31:20.961802 139834269067072 dataset_info.py:578] Load dataset info from /data/imagenet/pytorch/imagenet_v2/matched-frequency/3.0.0
I0914 07:31:20.968610 139834269067072 dataset_builder.py:528] Reusing dataset imagenet_v2 (/data/imagenet/pytorch/imagenet_v2/matched-frequency/3.0.0)
I0914 07:31:21.046800 139834269067072 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/pytorch/imagenet_v2/matched-frequency/3.0.0
[2023-09-14 07:31:23,085] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:23,201] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:23,211] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:23,233] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:23,331] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:23,345] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:23,407] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:23,745] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:26,122] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:31:26,141] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:31:26,145] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:31:26,145] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:31:26,278] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:31:26,299] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:31:26,303] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:31:26,303] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:31:26,339] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:31:26,356] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:31:26,358] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:31:26,361] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:31:26,361] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:31:26,375] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:31:26,375] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:31:26,378] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:31:26,378] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:31:26,394] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:31:26,397] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:31:26,397] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:31:26,404] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:31:26,406] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:31:26,422] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:31:26,425] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:31:26,426] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:31:26,426] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:31:26,428] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:31:26,428] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:31:26,516] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:31:26,535] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:31:26,538] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:31:26,538] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:31:28,764] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-14 07:31:28,902] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-14 07:31:28,916] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-14 07:31:28,929] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-14 07:31:28,974] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-14 07:31:28,979] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-14 07:31:29,014] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-14 07:31:29,096] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-14 07:31:35,516] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-14 07:31:35,577] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-14 07:31:35,604] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-14 07:31:35,775] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-14 07:31:35,798] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-14 07:31:35,830] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-14 07:31:35,830] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-14 07:31:35,908] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-14 07:31:37,554] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-14 07:31:37,587] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-14 07:31:37,597] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-14 07:31:37,773] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-14 07:31:37,826] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-14 07:31:37,866] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-14 07:31:37,897] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-14 07:31:37,928] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-14 07:31:42,209] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-14 07:31:42,250] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-14 07:31:42,253] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-14 07:31:42,373] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-14 07:31:42,493] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-14 07:31:42,563] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-14 07:31:42,601] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-14 07:31:42,610] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-14 07:31:42,881] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-14 07:31:42,889] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-14 07:31:42,896] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-14 07:31:42,997] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-14 07:31:43,112] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-14 07:31:43,221] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-14 07:31:43,234] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-14 07:31:43,254] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-14 07:31:43,465] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-14 07:31:43,483] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-14 07:31:43,489] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-14 07:31:43,610] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-14 07:31:43,737] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-14 07:31:43,833] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-14 07:31:43,858] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-14 07:31:43,867] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-14 07:31:44,077] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-14 07:31:44,086] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-14 07:31:44,103] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-14 07:31:44,204] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-14 07:31:44,297] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-14 07:31:44,417] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-14 07:31:44,423] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-14 07:31:44,442] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-14 07:31:47,109] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-14 07:31:47,119] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-14 07:31:47,165] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-14 07:31:47,221] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-14 07:31:47,225] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-14 07:31:47,230] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:31:47,231] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-14 07:31:47,234] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-14 07:31:47,239] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:31:47,275] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-14 07:31:47,279] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-14 07:31:47,284] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-14 07:31:47,284] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:31:47,300] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-14 07:31:47,409] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-14 07:31:47,413] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-14 07:31:47,413] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-14 07:31:47,417] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-14 07:31:47,418] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:31:47,423] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:31:47,465] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-14 07:31:47,573] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-14 07:31:47,577] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-14 07:31:47,582] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:31:47,585] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-14 07:31:47,630] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-14 07:31:47,697] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-14 07:31:47,701] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-14 07:31:47,707] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:31:47,741] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-14 07:31:47,745] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-14 07:31:47,751] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:31:59,208] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:59,494] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:59,601] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:59,606] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:59,635] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:59,645] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:59,655] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:31:59,667] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-14 07:32:00,804] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:32:00,823] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:32:00,826] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:32:00,827] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:32:00,882] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:32:00,902] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:32:00,905] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:32:00,906] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:32:00,958] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:32:00,971] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:32:00,978] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:32:00,981] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:32:00,981] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:32:00,990] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:32:00,992] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:32:00,993] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:32:00,994] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:32:00,997] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:32:01,012] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:32:01,015] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:32:01,015] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:32:01,017] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:32:01,020] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:32:01,021] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:32:01,070] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:32:01,072] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-14 07:32:01,090] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:32:01,092] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-14 07:32:01,093] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:32:01,094] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:32:01,095] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-14 07:32:01,096] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-14 07:32:03,457] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-14 07:32:03,548] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-14 07:32:03,597] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-14 07:32:03,637] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-14 07:32:03,645] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-14 07:32:03,649] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-14 07:32:03,766] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-14 07:32:03,808] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-14 07:32:07,807] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-14 07:32:07,993] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-14 07:32:08,038] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-14 07:32:08,066] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-14 07:32:08,109] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-14 07:32:08,171] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-14 07:32:08,204] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-14 07:32:08,280] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-14 07:32:09,897] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-14 07:32:10,019] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-14 07:32:10,065] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-14 07:32:10,092] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-14 07:32:10,156] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-14 07:32:10,187] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-14 07:32:10,218] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-14 07:32:10,274] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-14 07:32:12,801] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-14 07:32:12,957] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-14 07:32:12,969] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-14 07:32:13,041] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-14 07:32:13,135] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-14 07:32:13,177] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-14 07:32:13,206] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-14 07:32:13,277] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-14 07:32:13,471] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-14 07:32:13,604] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-14 07:32:13,612] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-14 07:32:13,675] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-14 07:32:13,763] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-14 07:32:13,853] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-14 07:32:13,861] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-14 07:32:13,911] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-14 07:32:14,061] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-14 07:32:14,179] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-14 07:32:14,188] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-14 07:32:14,266] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-14 07:32:14,421] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-14 07:32:14,497] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-14 07:32:14,500] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-14 07:32:14,511] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-14 07:32:14,669] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-14 07:32:14,769] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-14 07:32:14,848] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-14 07:32:14,858] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-14 07:32:15,040] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-14 07:32:15,054] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-14 07:32:15,059] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-14 07:32:15,074] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-14 07:32:16,195] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-14 07:32:16,306] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-14 07:32:16,311] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-14 07:32:16,317] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:32:16,318] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-14 07:32:16,369] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-14 07:32:16,377] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-14 07:32:16,430] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-14 07:32:16,435] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-14 07:32:16,440] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:32:16,479] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-14 07:32:16,483] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-14 07:32:16,489] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:32:16,493] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-14 07:32:16,498] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-14 07:32:16,504] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:32:16,572] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-14 07:32:16,589] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-14 07:32:16,611] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-14 07:32:16,616] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-14 07:32:16,682] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-14 07:32:16,687] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-14 07:32:16,692] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:32:16,697] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-14 07:32:16,702] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-14 07:32:16,707] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:32:16,719] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-14 07:32:16,724] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-14 07:32:16,725] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-14 07:32:16,729] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-14 07:32:16,730] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-14 07:32:16,735] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0914 07:32:21.028415 139834269067072 submission_runner.py:376] Time since start: 272.06s, 	Step: 1, 	{'train/accuracy': 0.001096141581632653, 'train/loss': 6.917834223533164, 'validation/accuracy': 0.00096, 'validation/loss': 6.918853125, 'validation/num_examples': 50000, 'test/accuracy': 0.0012, 'test/loss': 6.920421875, 'test/num_examples': 10000, 'score': 60.984593868255615, 'total_duration': 272.05629229545593, 'accumulated_submission_time': 60.984593868255615, 'accumulated_eval_time': 210.4636435508728, 'accumulated_logging_time': 0}
I0914 07:32:21.049076 139787142944512 logging_writer.py:48] [1] accumulated_eval_time=210.463644, accumulated_logging_time=0, accumulated_submission_time=60.984594, global_step=1, preemption_count=0, score=60.984594, test/accuracy=0.001200, test/loss=6.920422, test/num_examples=10000, total_duration=272.056292, train/accuracy=0.001096, train/loss=6.917834, validation/accuracy=0.000960, validation/loss=6.918853, validation/num_examples=50000
I0914 07:32:21.680736 139834269067072 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0914 07:32:21.682831 139915133245248 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0914 07:32:21.682918 139674672731968 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0914 07:32:21.682926 140532238145344 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0914 07:32:21.682955 140665363318592 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0914 07:32:21.682939 140679388120896 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0914 07:32:21.683235 139967587874624 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0914 07:32:21.683235 140100139824960 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 1024, 1, 1], strides() = [1024, 1, 1, 1]
bucket_view.sizes() = [2048, 1024, 1, 1], strides() = [1024, 1, 1024, 1024] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 1024, 1, 1], strides() = [1024, 1, 1, 1]
bucket_view.sizes() = [2048, 1024, 1, 1], strides() = [1024, 1, 1024, 1024] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 1024, 1, 1], strides() = [1024, 1, 1, 1]
bucket_view.sizes() = [2048, 1024, 1, 1], strides() = [1024, 1, 1024, 1024] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 1024, 1, 1], strides() = [1024, 1, 1, 1]
bucket_view.sizes() = [2048, 1024, 1, 1], strides() = [1024, 1, 1024, 1024] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 1024, 1, 1], strides() = [1024, 1, 1, 1]
bucket_view.sizes() = [2048, 1024, 1, 1], strides() = [1024, 1, 1024, 1024] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 1024, 1, 1], strides() = [1024, 1, 1, 1]
bucket_view.sizes() = [2048, 1024, 1, 1], strides() = [1024, 1, 1024, 1024] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 1024, 1, 1], strides() = [1024, 1, 1, 1]
bucket_view.sizes() = [2048, 1024, 1, 1], strides() = [1024, 1, 1024, 1024] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 1024, 1, 1], strides() = [1024, 1, 1, 1]
bucket_view.sizes() = [2048, 1024, 1, 1], strides() = [1024, 1, 1024, 1024] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
I0914 07:32:22.126619 139787134551808 logging_writer.py:48] [1] global_step=1, grad_norm=0.551701, loss=6.920442
I0914 07:32:22.130637 139834269067072 pytorch_submission_base.py:86] 1) loss = 6.920, grad_norm = 0.552
I0914 07:32:22.473272 139787142944512 logging_writer.py:48] [2] global_step=2, grad_norm=0.542089, loss=6.922936
I0914 07:32:22.477298 139834269067072 pytorch_submission_base.py:86] 2) loss = 6.923, grad_norm = 0.542
I0914 07:32:22.824409 139787134551808 logging_writer.py:48] [3] global_step=3, grad_norm=0.540896, loss=6.928603
I0914 07:32:22.829267 139834269067072 pytorch_submission_base.py:86] 3) loss = 6.929, grad_norm = 0.541
I0914 07:32:23.186243 139787142944512 logging_writer.py:48] [4] global_step=4, grad_norm=0.541820, loss=6.932987
I0914 07:32:23.191556 139834269067072 pytorch_submission_base.py:86] 4) loss = 6.933, grad_norm = 0.542
I0914 07:32:23.538696 139787134551808 logging_writer.py:48] [5] global_step=5, grad_norm=0.529164, loss=6.921320
I0914 07:32:23.543274 139834269067072 pytorch_submission_base.py:86] 5) loss = 6.921, grad_norm = 0.529
I0914 07:32:23.894207 139787142944512 logging_writer.py:48] [6] global_step=6, grad_norm=0.547042, loss=6.926368
I0914 07:32:23.900307 139834269067072 pytorch_submission_base.py:86] 6) loss = 6.926, grad_norm = 0.547
I0914 07:32:24.248956 139787134551808 logging_writer.py:48] [7] global_step=7, grad_norm=0.550678, loss=6.930604
I0914 07:32:24.253420 139834269067072 pytorch_submission_base.py:86] 7) loss = 6.931, grad_norm = 0.551
I0914 07:32:24.604994 139787142944512 logging_writer.py:48] [8] global_step=8, grad_norm=0.542285, loss=6.923306
I0914 07:32:24.610023 139834269067072 pytorch_submission_base.py:86] 8) loss = 6.923, grad_norm = 0.542
I0914 07:32:24.966934 139787134551808 logging_writer.py:48] [9] global_step=9, grad_norm=0.551748, loss=6.921955
I0914 07:32:24.972203 139834269067072 pytorch_submission_base.py:86] 9) loss = 6.922, grad_norm = 0.552
I0914 07:32:25.320696 139787142944512 logging_writer.py:48] [10] global_step=10, grad_norm=0.540426, loss=6.926387
I0914 07:32:25.326517 139834269067072 pytorch_submission_base.py:86] 10) loss = 6.926, grad_norm = 0.540
I0914 07:32:25.676620 139787134551808 logging_writer.py:48] [11] global_step=11, grad_norm=0.537804, loss=6.928099
I0914 07:32:25.680738 139834269067072 pytorch_submission_base.py:86] 11) loss = 6.928, grad_norm = 0.538
I0914 07:32:26.037291 139787142944512 logging_writer.py:48] [12] global_step=12, grad_norm=0.527369, loss=6.917002
I0914 07:32:26.043238 139834269067072 pytorch_submission_base.py:86] 12) loss = 6.917, grad_norm = 0.527
I0914 07:32:26.393496 139787134551808 logging_writer.py:48] [13] global_step=13, grad_norm=0.539036, loss=6.920700
I0914 07:32:26.399473 139834269067072 pytorch_submission_base.py:86] 13) loss = 6.921, grad_norm = 0.539
I0914 07:32:26.761438 139787142944512 logging_writer.py:48] [14] global_step=14, grad_norm=0.551666, loss=6.915051
I0914 07:32:26.766263 139834269067072 pytorch_submission_base.py:86] 14) loss = 6.915, grad_norm = 0.552
I0914 07:32:27.119235 139787134551808 logging_writer.py:48] [15] global_step=15, grad_norm=0.528867, loss=6.921980
I0914 07:32:27.124248 139834269067072 pytorch_submission_base.py:86] 15) loss = 6.922, grad_norm = 0.529
I0914 07:32:27.474458 139787142944512 logging_writer.py:48] [16] global_step=16, grad_norm=0.530767, loss=6.927121
I0914 07:32:27.479427 139834269067072 pytorch_submission_base.py:86] 16) loss = 6.927, grad_norm = 0.531
I0914 07:32:27.828797 139787134551808 logging_writer.py:48] [17] global_step=17, grad_norm=0.534838, loss=6.918298
I0914 07:32:27.833102 139834269067072 pytorch_submission_base.py:86] 17) loss = 6.918, grad_norm = 0.535
I0914 07:32:28.187322 139787142944512 logging_writer.py:48] [18] global_step=18, grad_norm=0.541929, loss=6.917254
I0914 07:32:28.192739 139834269067072 pytorch_submission_base.py:86] 18) loss = 6.917, grad_norm = 0.542
I0914 07:32:28.542253 139787134551808 logging_writer.py:48] [19] global_step=19, grad_norm=0.540737, loss=6.918446
I0914 07:32:28.547372 139834269067072 pytorch_submission_base.py:86] 19) loss = 6.918, grad_norm = 0.541
I0914 07:32:28.896763 139787142944512 logging_writer.py:48] [20] global_step=20, grad_norm=0.542968, loss=6.911886
I0914 07:32:28.904153 139834269067072 pytorch_submission_base.py:86] 20) loss = 6.912, grad_norm = 0.543
I0914 07:32:29.254588 139787134551808 logging_writer.py:48] [21] global_step=21, grad_norm=0.534374, loss=6.910212
I0914 07:32:29.259915 139834269067072 pytorch_submission_base.py:86] 21) loss = 6.910, grad_norm = 0.534
I0914 07:32:29.614535 139787142944512 logging_writer.py:48] [22] global_step=22, grad_norm=0.547398, loss=6.912018
I0914 07:32:29.619324 139834269067072 pytorch_submission_base.py:86] 22) loss = 6.912, grad_norm = 0.547
I0914 07:32:29.973269 139787134551808 logging_writer.py:48] [23] global_step=23, grad_norm=0.527235, loss=6.903142
I0914 07:32:29.979590 139834269067072 pytorch_submission_base.py:86] 23) loss = 6.903, grad_norm = 0.527
I0914 07:32:30.331215 139787142944512 logging_writer.py:48] [24] global_step=24, grad_norm=0.537150, loss=6.901305
I0914 07:32:30.339565 139834269067072 pytorch_submission_base.py:86] 24) loss = 6.901, grad_norm = 0.537
I0914 07:32:30.697529 139787134551808 logging_writer.py:48] [25] global_step=25, grad_norm=0.526645, loss=6.898272
I0914 07:32:30.703863 139834269067072 pytorch_submission_base.py:86] 25) loss = 6.898, grad_norm = 0.527
I0914 07:32:31.057432 139787142944512 logging_writer.py:48] [26] global_step=26, grad_norm=0.547578, loss=6.896035
I0914 07:32:31.065654 139834269067072 pytorch_submission_base.py:86] 26) loss = 6.896, grad_norm = 0.548
I0914 07:32:31.473467 139787134551808 logging_writer.py:48] [27] global_step=27, grad_norm=0.526747, loss=6.904052
I0914 07:32:31.484367 139834269067072 pytorch_submission_base.py:86] 27) loss = 6.904, grad_norm = 0.527
I0914 07:32:31.836777 139787142944512 logging_writer.py:48] [28] global_step=28, grad_norm=0.539564, loss=6.897404
I0914 07:32:31.842372 139834269067072 pytorch_submission_base.py:86] 28) loss = 6.897, grad_norm = 0.540
I0914 07:32:32.192847 139787134551808 logging_writer.py:48] [29] global_step=29, grad_norm=0.542347, loss=6.900939
I0914 07:32:32.197541 139834269067072 pytorch_submission_base.py:86] 29) loss = 6.901, grad_norm = 0.542
I0914 07:32:32.547814 139787142944512 logging_writer.py:48] [30] global_step=30, grad_norm=0.534538, loss=6.885602
I0914 07:32:32.554412 139834269067072 pytorch_submission_base.py:86] 30) loss = 6.886, grad_norm = 0.535
I0914 07:32:32.913871 139787134551808 logging_writer.py:48] [31] global_step=31, grad_norm=0.523917, loss=6.894505
I0914 07:32:32.919758 139834269067072 pytorch_submission_base.py:86] 31) loss = 6.895, grad_norm = 0.524
I0914 07:32:33.282188 139787142944512 logging_writer.py:48] [32] global_step=32, grad_norm=0.516475, loss=6.892910
I0914 07:32:33.289310 139834269067072 pytorch_submission_base.py:86] 32) loss = 6.893, grad_norm = 0.516
I0914 07:32:33.640573 139787134551808 logging_writer.py:48] [33] global_step=33, grad_norm=0.549239, loss=6.882234
I0914 07:32:33.645903 139834269067072 pytorch_submission_base.py:86] 33) loss = 6.882, grad_norm = 0.549
I0914 07:32:33.997891 139787142944512 logging_writer.py:48] [34] global_step=34, grad_norm=0.526961, loss=6.882050
I0914 07:32:34.005744 139834269067072 pytorch_submission_base.py:86] 34) loss = 6.882, grad_norm = 0.527
I0914 07:32:34.361480 139787134551808 logging_writer.py:48] [35] global_step=35, grad_norm=0.531718, loss=6.885262
I0914 07:32:34.366886 139834269067072 pytorch_submission_base.py:86] 35) loss = 6.885, grad_norm = 0.532
I0914 07:32:34.722793 139787142944512 logging_writer.py:48] [36] global_step=36, grad_norm=0.540814, loss=6.876978
I0914 07:32:34.727038 139834269067072 pytorch_submission_base.py:86] 36) loss = 6.877, grad_norm = 0.541
I0914 07:32:35.076063 139787134551808 logging_writer.py:48] [37] global_step=37, grad_norm=0.541437, loss=6.885392
I0914 07:32:35.081978 139834269067072 pytorch_submission_base.py:86] 37) loss = 6.885, grad_norm = 0.541
I0914 07:32:35.432788 139787142944512 logging_writer.py:48] [38] global_step=38, grad_norm=0.530122, loss=6.877739
I0914 07:32:35.439038 139834269067072 pytorch_submission_base.py:86] 38) loss = 6.878, grad_norm = 0.530
I0914 07:32:35.794694 139787134551808 logging_writer.py:48] [39] global_step=39, grad_norm=0.540789, loss=6.886802
I0914 07:32:35.800418 139834269067072 pytorch_submission_base.py:86] 39) loss = 6.887, grad_norm = 0.541
I0914 07:32:36.173924 139787142944512 logging_writer.py:48] [40] global_step=40, grad_norm=0.544723, loss=6.873171
I0914 07:32:36.179570 139834269067072 pytorch_submission_base.py:86] 40) loss = 6.873, grad_norm = 0.545
I0914 07:32:36.530088 139787134551808 logging_writer.py:48] [41] global_step=41, grad_norm=0.525840, loss=6.870435
I0914 07:32:36.535044 139834269067072 pytorch_submission_base.py:86] 41) loss = 6.870, grad_norm = 0.526
I0914 07:32:36.892334 139787142944512 logging_writer.py:48] [42] global_step=42, grad_norm=0.534139, loss=6.870687
I0914 07:32:36.896728 139834269067072 pytorch_submission_base.py:86] 42) loss = 6.871, grad_norm = 0.534
I0914 07:32:37.255797 139787134551808 logging_writer.py:48] [43] global_step=43, grad_norm=0.545761, loss=6.864959
I0914 07:32:37.260837 139834269067072 pytorch_submission_base.py:86] 43) loss = 6.865, grad_norm = 0.546
I0914 07:32:37.618554 139787142944512 logging_writer.py:48] [44] global_step=44, grad_norm=0.539556, loss=6.872699
I0914 07:32:37.623677 139834269067072 pytorch_submission_base.py:86] 44) loss = 6.873, grad_norm = 0.540
I0914 07:32:37.977339 139787134551808 logging_writer.py:48] [45] global_step=45, grad_norm=0.529191, loss=6.865037
I0914 07:32:37.982736 139834269067072 pytorch_submission_base.py:86] 45) loss = 6.865, grad_norm = 0.529
I0914 07:32:38.335098 139787142944512 logging_writer.py:48] [46] global_step=46, grad_norm=0.549382, loss=6.861615
I0914 07:32:38.340752 139834269067072 pytorch_submission_base.py:86] 46) loss = 6.862, grad_norm = 0.549
I0914 07:32:38.693846 139787134551808 logging_writer.py:48] [47] global_step=47, grad_norm=0.551047, loss=6.857548
I0914 07:32:38.698257 139834269067072 pytorch_submission_base.py:86] 47) loss = 6.858, grad_norm = 0.551
I0914 07:32:39.046773 139787142944512 logging_writer.py:48] [48] global_step=48, grad_norm=0.537726, loss=6.849146
I0914 07:32:39.051900 139834269067072 pytorch_submission_base.py:86] 48) loss = 6.849, grad_norm = 0.538
I0914 07:32:39.404963 139787134551808 logging_writer.py:48] [49] global_step=49, grad_norm=0.556389, loss=6.858288
I0914 07:32:39.413457 139834269067072 pytorch_submission_base.py:86] 49) loss = 6.858, grad_norm = 0.556
I0914 07:32:39.760417 139787142944512 logging_writer.py:48] [50] global_step=50, grad_norm=0.548310, loss=6.856420
I0914 07:32:39.765508 139834269067072 pytorch_submission_base.py:86] 50) loss = 6.856, grad_norm = 0.548
I0914 07:32:40.114787 139787134551808 logging_writer.py:48] [51] global_step=51, grad_norm=0.546571, loss=6.850068
I0914 07:32:40.120063 139834269067072 pytorch_submission_base.py:86] 51) loss = 6.850, grad_norm = 0.547
I0914 07:32:40.470976 139787142944512 logging_writer.py:48] [52] global_step=52, grad_norm=0.544266, loss=6.846149
I0914 07:32:40.476298 139834269067072 pytorch_submission_base.py:86] 52) loss = 6.846, grad_norm = 0.544
I0914 07:32:40.833233 139787134551808 logging_writer.py:48] [53] global_step=53, grad_norm=0.542646, loss=6.844643
I0914 07:32:40.838352 139834269067072 pytorch_submission_base.py:86] 53) loss = 6.845, grad_norm = 0.543
I0914 07:32:41.193498 139787142944512 logging_writer.py:48] [54] global_step=54, grad_norm=0.555652, loss=6.836208
I0914 07:32:41.199453 139834269067072 pytorch_submission_base.py:86] 54) loss = 6.836, grad_norm = 0.556
I0914 07:32:41.559033 139787134551808 logging_writer.py:48] [55] global_step=55, grad_norm=0.550634, loss=6.857880
I0914 07:32:41.564237 139834269067072 pytorch_submission_base.py:86] 55) loss = 6.858, grad_norm = 0.551
I0914 07:32:41.925188 139787142944512 logging_writer.py:48] [56] global_step=56, grad_norm=0.559554, loss=6.829268
I0914 07:32:41.931823 139834269067072 pytorch_submission_base.py:86] 56) loss = 6.829, grad_norm = 0.560
I0914 07:32:42.302501 139787134551808 logging_writer.py:48] [57] global_step=57, grad_norm=0.561093, loss=6.839175
I0914 07:32:42.308180 139834269067072 pytorch_submission_base.py:86] 57) loss = 6.839, grad_norm = 0.561
I0914 07:32:42.667974 139787142944512 logging_writer.py:48] [58] global_step=58, grad_norm=0.572529, loss=6.827746
I0914 07:32:42.674191 139834269067072 pytorch_submission_base.py:86] 58) loss = 6.828, grad_norm = 0.573
I0914 07:32:43.036135 139787134551808 logging_writer.py:48] [59] global_step=59, grad_norm=0.570312, loss=6.834723
I0914 07:32:43.041729 139834269067072 pytorch_submission_base.py:86] 59) loss = 6.835, grad_norm = 0.570
I0914 07:32:43.394429 139787142944512 logging_writer.py:48] [60] global_step=60, grad_norm=0.552302, loss=6.811781
I0914 07:32:43.399309 139834269067072 pytorch_submission_base.py:86] 60) loss = 6.812, grad_norm = 0.552
I0914 07:32:43.808097 139787134551808 logging_writer.py:48] [61] global_step=61, grad_norm=0.540180, loss=6.818762
I0914 07:32:43.812707 139834269067072 pytorch_submission_base.py:86] 61) loss = 6.819, grad_norm = 0.540
I0914 07:32:44.168583 139787142944512 logging_writer.py:48] [62] global_step=62, grad_norm=0.553768, loss=6.810802
I0914 07:32:44.173512 139834269067072 pytorch_submission_base.py:86] 62) loss = 6.811, grad_norm = 0.554
I0914 07:32:44.527651 139787134551808 logging_writer.py:48] [63] global_step=63, grad_norm=0.580086, loss=6.794678
I0914 07:32:44.534880 139834269067072 pytorch_submission_base.py:86] 63) loss = 6.795, grad_norm = 0.580
I0914 07:32:44.890951 139787142944512 logging_writer.py:48] [64] global_step=64, grad_norm=0.597460, loss=6.809485
I0914 07:32:44.896385 139834269067072 pytorch_submission_base.py:86] 64) loss = 6.809, grad_norm = 0.597
I0914 07:32:45.254607 139787134551808 logging_writer.py:48] [65] global_step=65, grad_norm=0.558454, loss=6.795557
I0914 07:32:45.259629 139834269067072 pytorch_submission_base.py:86] 65) loss = 6.796, grad_norm = 0.558
I0914 07:32:45.608763 139787142944512 logging_writer.py:48] [66] global_step=66, grad_norm=0.568524, loss=6.789633
I0914 07:32:45.613235 139834269067072 pytorch_submission_base.py:86] 66) loss = 6.790, grad_norm = 0.569
I0914 07:32:45.962223 139787134551808 logging_writer.py:48] [67] global_step=67, grad_norm=0.575954, loss=6.804579
I0914 07:32:45.967495 139834269067072 pytorch_submission_base.py:86] 67) loss = 6.805, grad_norm = 0.576
I0914 07:32:46.323882 139787142944512 logging_writer.py:48] [68] global_step=68, grad_norm=0.577826, loss=6.779813
I0914 07:32:46.328791 139834269067072 pytorch_submission_base.py:86] 68) loss = 6.780, grad_norm = 0.578
I0914 07:32:46.690927 139787134551808 logging_writer.py:48] [69] global_step=69, grad_norm=0.558907, loss=6.799858
I0914 07:32:46.696592 139834269067072 pytorch_submission_base.py:86] 69) loss = 6.800, grad_norm = 0.559
I0914 07:32:47.054767 139787142944512 logging_writer.py:48] [70] global_step=70, grad_norm=0.568885, loss=6.770229
I0914 07:32:47.061464 139834269067072 pytorch_submission_base.py:86] 70) loss = 6.770, grad_norm = 0.569
I0914 07:32:47.413324 139787134551808 logging_writer.py:48] [71] global_step=71, grad_norm=0.578998, loss=6.812357
I0914 07:32:47.418231 139834269067072 pytorch_submission_base.py:86] 71) loss = 6.812, grad_norm = 0.579
I0914 07:32:47.772288 139787142944512 logging_writer.py:48] [72] global_step=72, grad_norm=0.583506, loss=6.774558
I0914 07:32:47.777271 139834269067072 pytorch_submission_base.py:86] 72) loss = 6.775, grad_norm = 0.584
I0914 07:32:48.132233 139787134551808 logging_writer.py:48] [73] global_step=73, grad_norm=0.613478, loss=6.776613
I0914 07:32:48.136673 139834269067072 pytorch_submission_base.py:86] 73) loss = 6.777, grad_norm = 0.613
I0914 07:32:48.489819 139787142944512 logging_writer.py:48] [74] global_step=74, grad_norm=0.569288, loss=6.776994
I0914 07:32:48.494921 139834269067072 pytorch_submission_base.py:86] 74) loss = 6.777, grad_norm = 0.569
I0914 07:32:48.847975 139787134551808 logging_writer.py:48] [75] global_step=75, grad_norm=0.564167, loss=6.747491
I0914 07:32:48.853172 139834269067072 pytorch_submission_base.py:86] 75) loss = 6.747, grad_norm = 0.564
I0914 07:32:49.214556 139787142944512 logging_writer.py:48] [76] global_step=76, grad_norm=0.579674, loss=6.778160
I0914 07:32:49.219772 139834269067072 pytorch_submission_base.py:86] 76) loss = 6.778, grad_norm = 0.580
I0914 07:32:49.581934 139787134551808 logging_writer.py:48] [77] global_step=77, grad_norm=0.588912, loss=6.766541
I0914 07:32:49.588375 139834269067072 pytorch_submission_base.py:86] 77) loss = 6.767, grad_norm = 0.589
I0914 07:32:49.947529 139787142944512 logging_writer.py:48] [78] global_step=78, grad_norm=0.600932, loss=6.759520
I0914 07:32:49.952745 139834269067072 pytorch_submission_base.py:86] 78) loss = 6.760, grad_norm = 0.601
I0914 07:32:50.306623 139787134551808 logging_writer.py:48] [79] global_step=79, grad_norm=0.605044, loss=6.774667
I0914 07:32:50.310743 139834269067072 pytorch_submission_base.py:86] 79) loss = 6.775, grad_norm = 0.605
I0914 07:32:50.670002 139787142944512 logging_writer.py:48] [80] global_step=80, grad_norm=0.567146, loss=6.730073
I0914 07:32:50.676366 139834269067072 pytorch_submission_base.py:86] 80) loss = 6.730, grad_norm = 0.567
I0914 07:32:51.038667 139787134551808 logging_writer.py:48] [81] global_step=81, grad_norm=0.576910, loss=6.719033
I0914 07:32:51.044562 139834269067072 pytorch_submission_base.py:86] 81) loss = 6.719, grad_norm = 0.577
I0914 07:32:51.405917 139787142944512 logging_writer.py:48] [82] global_step=82, grad_norm=0.593913, loss=6.724887
I0914 07:32:51.412495 139834269067072 pytorch_submission_base.py:86] 82) loss = 6.725, grad_norm = 0.594
I0914 07:32:51.768537 139787134551808 logging_writer.py:48] [83] global_step=83, grad_norm=0.603381, loss=6.757006
I0914 07:32:51.773114 139834269067072 pytorch_submission_base.py:86] 83) loss = 6.757, grad_norm = 0.603
I0914 07:32:52.128366 139787142944512 logging_writer.py:48] [84] global_step=84, grad_norm=0.599726, loss=6.756614
I0914 07:32:52.133224 139834269067072 pytorch_submission_base.py:86] 84) loss = 6.757, grad_norm = 0.600
I0914 07:32:52.490512 139787134551808 logging_writer.py:48] [85] global_step=85, grad_norm=0.587466, loss=6.713772
I0914 07:32:52.495806 139834269067072 pytorch_submission_base.py:86] 85) loss = 6.714, grad_norm = 0.587
I0914 07:32:52.847546 139787142944512 logging_writer.py:48] [86] global_step=86, grad_norm=0.605533, loss=6.715852
I0914 07:32:52.853621 139834269067072 pytorch_submission_base.py:86] 86) loss = 6.716, grad_norm = 0.606
I0914 07:32:53.205794 139787134551808 logging_writer.py:48] [87] global_step=87, grad_norm=0.610826, loss=6.740644
I0914 07:32:53.211133 139834269067072 pytorch_submission_base.py:86] 87) loss = 6.741, grad_norm = 0.611
I0914 07:32:53.565340 139787142944512 logging_writer.py:48] [88] global_step=88, grad_norm=0.614206, loss=6.760800
I0914 07:32:53.570932 139834269067072 pytorch_submission_base.py:86] 88) loss = 6.761, grad_norm = 0.614
I0914 07:32:53.932002 139787134551808 logging_writer.py:48] [89] global_step=89, grad_norm=0.598010, loss=6.705523
I0914 07:32:53.936919 139834269067072 pytorch_submission_base.py:86] 89) loss = 6.706, grad_norm = 0.598
I0914 07:32:54.290063 139787142944512 logging_writer.py:48] [90] global_step=90, grad_norm=0.613936, loss=6.728477
I0914 07:32:54.296257 139834269067072 pytorch_submission_base.py:86] 90) loss = 6.728, grad_norm = 0.614
I0914 07:32:54.655003 139787134551808 logging_writer.py:48] [91] global_step=91, grad_norm=0.600433, loss=6.712207
I0914 07:32:54.660261 139834269067072 pytorch_submission_base.py:86] 91) loss = 6.712, grad_norm = 0.600
I0914 07:32:55.018390 139787142944512 logging_writer.py:48] [92] global_step=92, grad_norm=0.611377, loss=6.704411
I0914 07:32:55.023508 139834269067072 pytorch_submission_base.py:86] 92) loss = 6.704, grad_norm = 0.611
I0914 07:32:55.384810 139787134551808 logging_writer.py:48] [93] global_step=93, grad_norm=0.592242, loss=6.700635
I0914 07:32:55.391270 139834269067072 pytorch_submission_base.py:86] 93) loss = 6.701, grad_norm = 0.592
I0914 07:32:55.745049 139787142944512 logging_writer.py:48] [94] global_step=94, grad_norm=0.587278, loss=6.725800
I0914 07:32:55.750296 139834269067072 pytorch_submission_base.py:86] 94) loss = 6.726, grad_norm = 0.587
I0914 07:32:56.106577 139787134551808 logging_writer.py:48] [95] global_step=95, grad_norm=0.623668, loss=6.733784
I0914 07:32:56.111735 139834269067072 pytorch_submission_base.py:86] 95) loss = 6.734, grad_norm = 0.624
I0914 07:32:56.463151 139787142944512 logging_writer.py:48] [96] global_step=96, grad_norm=0.589321, loss=6.694387
I0914 07:32:56.467776 139834269067072 pytorch_submission_base.py:86] 96) loss = 6.694, grad_norm = 0.589
I0914 07:32:56.829590 139787134551808 logging_writer.py:48] [97] global_step=97, grad_norm=0.602568, loss=6.679974
I0914 07:32:56.836965 139834269067072 pytorch_submission_base.py:86] 97) loss = 6.680, grad_norm = 0.603
I0914 07:32:57.195429 139787142944512 logging_writer.py:48] [98] global_step=98, grad_norm=0.617787, loss=6.682028
I0914 07:32:57.200988 139834269067072 pytorch_submission_base.py:86] 98) loss = 6.682, grad_norm = 0.618
I0914 07:32:57.580904 139787134551808 logging_writer.py:48] [99] global_step=99, grad_norm=0.596009, loss=6.680842
I0914 07:32:57.587566 139834269067072 pytorch_submission_base.py:86] 99) loss = 6.681, grad_norm = 0.596
I0914 07:32:57.941038 139787142944512 logging_writer.py:48] [100] global_step=100, grad_norm=0.609999, loss=6.697483
I0914 07:32:57.945470 139834269067072 pytorch_submission_base.py:86] 100) loss = 6.697, grad_norm = 0.610
I0914 07:35:25.402567 139787134551808 logging_writer.py:48] [500] global_step=500, grad_norm=0.572340, loss=6.175528
I0914 07:35:25.407279 139834269067072 pytorch_submission_base.py:86] 500) loss = 6.176, grad_norm = 0.572
I0914 07:38:30.971427 139787142944512 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.463989, loss=5.545136
I0914 07:38:30.977613 139834269067072 pytorch_submission_base.py:86] 1000) loss = 5.545, grad_norm = 0.464
I0914 07:40:52.230571 139834269067072 spec.py:320] Evaluating on the training split.
I0914 07:41:34.714856 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 07:42:33.663008 139834269067072 spec.py:348] Evaluating on the test split.
I0914 07:42:34.798086 139834269067072 submission_runner.py:376] Time since start: 885.83s, 	Step: 1382, 	{'train/accuracy': 0.19270169005102042, 'train/loss': 4.24181942063935, 'validation/accuracy': 0.17518, 'validation/loss': 4.3354953125, 'validation/num_examples': 50000, 'test/accuracy': 0.127, 'test/loss': 4.7698484375, 'test/num_examples': 10000, 'score': 569.4610950946808, 'total_duration': 885.8260006904602, 'accumulated_submission_time': 569.4610950946808, 'accumulated_eval_time': 313.03159165382385, 'accumulated_logging_time': 0.029378175735473633}
I0914 07:42:34.815883 139787151337216 logging_writer.py:48] [1382] accumulated_eval_time=313.031592, accumulated_logging_time=0.029378, accumulated_submission_time=569.461095, global_step=1382, preemption_count=0, score=569.461095, test/accuracy=0.127000, test/loss=4.769848, test/num_examples=10000, total_duration=885.826001, train/accuracy=0.192702, train/loss=4.241819, validation/accuracy=0.175180, validation/loss=4.335495, validation/num_examples=50000
I0914 07:43:16.404767 139787159729920 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.461547, loss=5.104912
I0914 07:43:16.409106 139834269067072 pytorch_submission_base.py:86] 1500) loss = 5.105, grad_norm = 0.462
I0914 07:46:08.498253 139787151337216 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.390438, loss=4.795301
I0914 07:46:08.503409 139834269067072 pytorch_submission_base.py:86] 2000) loss = 4.795, grad_norm = 0.390
I0914 07:49:02.932376 139787159729920 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.350087, loss=4.533933
I0914 07:49:02.939889 139834269067072 pytorch_submission_base.py:86] 2500) loss = 4.534, grad_norm = 0.350
I0914 07:51:06.103747 139834269067072 spec.py:320] Evaluating on the training split.
I0914 07:51:52.598818 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 07:52:52.920140 139834269067072 spec.py:348] Evaluating on the test split.
I0914 07:52:54.017333 139834269067072 submission_runner.py:376] Time since start: 1505.05s, 	Step: 2851, 	{'train/accuracy': 0.3761360012755102, 'train/loss': 3.079436633051658, 'validation/accuracy': 0.34818, 'validation/loss': 3.228095, 'validation/num_examples': 50000, 'test/accuracy': 0.2552, 'test/loss': 3.84915703125, 'test/num_examples': 10000, 'score': 1078.0562477111816, 'total_duration': 1505.0452282428741, 'accumulated_submission_time': 1078.0562477111816, 'accumulated_eval_time': 420.9456560611725, 'accumulated_logging_time': 0.05981016159057617}
I0914 07:52:54.041853 139787151337216 logging_writer.py:48] [2851] accumulated_eval_time=420.945656, accumulated_logging_time=0.059810, accumulated_submission_time=1078.056248, global_step=2851, preemption_count=0, score=1078.056248, test/accuracy=0.255200, test/loss=3.849157, test/num_examples=10000, total_duration=1505.045228, train/accuracy=0.376136, train/loss=3.079437, validation/accuracy=0.348180, validation/loss=3.228095, validation/num_examples=50000
I0914 07:53:46.293194 139787159729920 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.315635, loss=4.322581
I0914 07:53:46.297944 139834269067072 pytorch_submission_base.py:86] 3000) loss = 4.323, grad_norm = 0.316
I0914 07:56:38.411194 139787151337216 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.302956, loss=4.095819
I0914 07:56:38.417613 139834269067072 pytorch_submission_base.py:86] 3500) loss = 4.096, grad_norm = 0.303
I0914 07:59:32.411723 139787159729920 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.294802, loss=4.089976
I0914 07:59:32.418663 139834269067072 pytorch_submission_base.py:86] 4000) loss = 4.090, grad_norm = 0.295
I0914 08:01:25.197757 139834269067072 spec.py:320] Evaluating on the training split.
I0914 08:02:07.589559 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 08:03:06.465734 139834269067072 spec.py:348] Evaluating on the test split.
I0914 08:03:07.559403 139834269067072 submission_runner.py:376] Time since start: 2118.59s, 	Step: 4326, 	{'train/accuracy': 0.47793765943877553, 'train/loss': 2.523687401596381, 'validation/accuracy': 0.44296, 'validation/loss': 2.698548125, 'validation/num_examples': 50000, 'test/accuracy': 0.326, 'test/loss': 3.39362734375, 'test/num_examples': 10000, 'score': 1586.5042593479156, 'total_duration': 2118.587264060974, 'accumulated_submission_time': 1586.5042593479156, 'accumulated_eval_time': 523.3074886798859, 'accumulated_logging_time': 0.09416055679321289}
I0914 08:03:07.578591 139787151337216 logging_writer.py:48] [4326] accumulated_eval_time=523.307489, accumulated_logging_time=0.094161, accumulated_submission_time=1586.504259, global_step=4326, preemption_count=0, score=1586.504259, test/accuracy=0.326000, test/loss=3.393627, test/num_examples=10000, total_duration=2118.587264, train/accuracy=0.477938, train/loss=2.523687, validation/accuracy=0.442960, validation/loss=2.698548, validation/num_examples=50000
I0914 08:04:08.382456 139787159729920 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.284863, loss=3.899799
I0914 08:04:08.387595 139834269067072 pytorch_submission_base.py:86] 4500) loss = 3.900, grad_norm = 0.285
I0914 08:07:01.709637 139787151337216 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.262662, loss=3.928503
I0914 08:07:01.716476 139834269067072 pytorch_submission_base.py:86] 5000) loss = 3.929, grad_norm = 0.263
I0914 08:09:55.320943 139787159729920 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.259600, loss=4.019738
I0914 08:09:55.328413 139834269067072 pytorch_submission_base.py:86] 5500) loss = 4.020, grad_norm = 0.260
I0914 08:11:38.812262 139834269067072 spec.py:320] Evaluating on the training split.
I0914 08:12:21.062642 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 08:13:19.576259 139834269067072 spec.py:348] Evaluating on the test split.
I0914 08:13:20.677337 139834269067072 submission_runner.py:376] Time since start: 2731.71s, 	Step: 5799, 	{'train/accuracy': 0.5077327806122449, 'train/loss': 2.4033371283083547, 'validation/accuracy': 0.4707, 'validation/loss': 2.589981875, 'validation/num_examples': 50000, 'test/accuracy': 0.362, 'test/loss': 3.19341875, 'test/num_examples': 10000, 'score': 2094.9969153404236, 'total_duration': 2731.7052235603333, 'accumulated_submission_time': 2094.9969153404236, 'accumulated_eval_time': 625.1727330684662, 'accumulated_logging_time': 0.12300705909729004}
I0914 08:13:20.694658 139787151337216 logging_writer.py:48] [5799] accumulated_eval_time=625.172733, accumulated_logging_time=0.123007, accumulated_submission_time=2094.996915, global_step=5799, preemption_count=0, score=2094.996915, test/accuracy=0.362000, test/loss=3.193419, test/num_examples=10000, total_duration=2731.705224, train/accuracy=0.507733, train/loss=2.403337, validation/accuracy=0.470700, validation/loss=2.589982, validation/num_examples=50000
I0914 08:14:30.883939 139787159729920 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.274878, loss=3.961493
I0914 08:14:30.893293 139834269067072 pytorch_submission_base.py:86] 6000) loss = 3.961, grad_norm = 0.275
I0914 08:17:26.081339 139787151337216 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.249902, loss=3.900762
I0914 08:17:26.087388 139834269067072 pytorch_submission_base.py:86] 6500) loss = 3.901, grad_norm = 0.250
I0914 08:20:18.016957 139787159729920 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.243282, loss=3.893843
I0914 08:20:18.021710 139834269067072 pytorch_submission_base.py:86] 7000) loss = 3.894, grad_norm = 0.243
I0914 08:21:51.941990 139834269067072 spec.py:320] Evaluating on the training split.
I0914 08:22:35.504809 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 08:23:36.119388 139834269067072 spec.py:348] Evaluating on the test split.
I0914 08:23:37.216582 139834269067072 submission_runner.py:376] Time since start: 3348.24s, 	Step: 7271, 	{'train/accuracy': 0.5223214285714286, 'train/loss': 2.307311388911033, 'validation/accuracy': 0.48322, 'validation/loss': 2.49694296875, 'validation/num_examples': 50000, 'test/accuracy': 0.3708, 'test/loss': 3.1751080078125, 'test/num_examples': 10000, 'score': 2603.4704480171204, 'total_duration': 3348.2424252033234, 'accumulated_submission_time': 2603.4704480171204, 'accumulated_eval_time': 730.4458467960358, 'accumulated_logging_time': 0.14911961555480957}
I0914 08:23:37.234344 139787151337216 logging_writer.py:48] [7271] accumulated_eval_time=730.445847, accumulated_logging_time=0.149120, accumulated_submission_time=2603.470448, global_step=7271, preemption_count=0, score=2603.470448, test/accuracy=0.370800, test/loss=3.175108, test/num_examples=10000, total_duration=3348.242425, train/accuracy=0.522321, train/loss=2.307311, validation/accuracy=0.483220, validation/loss=2.496943, validation/num_examples=50000
I0914 08:24:59.436540 139787159729920 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.234446, loss=3.824605
I0914 08:24:59.440316 139834269067072 pytorch_submission_base.py:86] 7500) loss = 3.825, grad_norm = 0.234
I0914 08:27:52.852749 139787151337216 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.247250, loss=3.795770
I0914 08:27:52.857368 139834269067072 pytorch_submission_base.py:86] 8000) loss = 3.796, grad_norm = 0.247
I0914 08:30:44.882669 139787159729920 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.253375, loss=3.783938
I0914 08:30:44.892075 139834269067072 pytorch_submission_base.py:86] 8500) loss = 3.784, grad_norm = 0.253
I0914 08:32:08.603931 139834269067072 spec.py:320] Evaluating on the training split.
I0914 08:32:51.020045 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 08:33:49.552607 139834269067072 spec.py:348] Evaluating on the test split.
I0914 08:33:50.646873 139834269067072 submission_runner.py:376] Time since start: 3961.67s, 	Step: 8739, 	{'train/accuracy': 0.5569395727040817, 'train/loss': 2.1433943145129146, 'validation/accuracy': 0.51116, 'validation/loss': 2.36050140625, 'validation/num_examples': 50000, 'test/accuracy': 0.4004, 'test/loss': 2.9739369140625, 'test/num_examples': 10000, 'score': 3112.0278327465057, 'total_duration': 3961.6747641563416, 'accumulated_submission_time': 3112.0278327465057, 'accumulated_eval_time': 832.4892835617065, 'accumulated_logging_time': 0.17649197578430176}
I0914 08:33:50.666403 139787151337216 logging_writer.py:48] [8739] accumulated_eval_time=832.489284, accumulated_logging_time=0.176492, accumulated_submission_time=3112.027833, global_step=8739, preemption_count=0, score=3112.027833, test/accuracy=0.400400, test/loss=2.973937, test/num_examples=10000, total_duration=3961.674764, train/accuracy=0.556940, train/loss=2.143394, validation/accuracy=0.511160, validation/loss=2.360501, validation/num_examples=50000
I0914 08:35:23.392988 139787159729920 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.238671, loss=3.787276
I0914 08:35:23.399698 139834269067072 pytorch_submission_base.py:86] 9000) loss = 3.787, grad_norm = 0.239
I0914 08:38:15.193179 139787151337216 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.245683, loss=3.788953
I0914 08:38:15.201022 139834269067072 pytorch_submission_base.py:86] 9500) loss = 3.789, grad_norm = 0.246
I0914 08:41:09.137794 139787159729920 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.242606, loss=3.698109
I0914 08:41:09.143435 139834269067072 pytorch_submission_base.py:86] 10000) loss = 3.698, grad_norm = 0.243
I0914 08:42:21.823856 139834269067072 spec.py:320] Evaluating on the training split.
I0914 08:43:03.238508 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 08:44:02.208598 139834269067072 spec.py:348] Evaluating on the test split.
I0914 08:44:03.310546 139834269067072 submission_runner.py:376] Time since start: 4574.34s, 	Step: 10205, 	{'train/accuracy': 0.5587930484693877, 'train/loss': 2.0926851545061385, 'validation/accuracy': 0.51248, 'validation/loss': 2.321938125, 'validation/num_examples': 50000, 'test/accuracy': 0.3796, 'test/loss': 3.0909994140625, 'test/num_examples': 10000, 'score': 3620.4415559768677, 'total_duration': 4574.338397026062, 'accumulated_submission_time': 3620.4415559768677, 'accumulated_eval_time': 933.9763813018799, 'accumulated_logging_time': 0.2047131061553955}
I0914 08:44:03.327817 139787151337216 logging_writer.py:48] [10205] accumulated_eval_time=933.976381, accumulated_logging_time=0.204713, accumulated_submission_time=3620.441556, global_step=10205, preemption_count=0, score=3620.441556, test/accuracy=0.379600, test/loss=3.090999, test/num_examples=10000, total_duration=4574.338397, train/accuracy=0.558793, train/loss=2.092685, validation/accuracy=0.512480, validation/loss=2.321938, validation/num_examples=50000
I0914 08:45:45.613805 139787159729920 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.240667, loss=3.693839
I0914 08:45:45.619176 139834269067072 pytorch_submission_base.py:86] 10500) loss = 3.694, grad_norm = 0.241
I0914 08:48:37.990242 139787151337216 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.246611, loss=3.664759
I0914 08:48:37.996495 139834269067072 pytorch_submission_base.py:86] 11000) loss = 3.665, grad_norm = 0.247
I0914 08:51:33.260951 139787159729920 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.251292, loss=3.658024
I0914 08:51:33.269904 139834269067072 pytorch_submission_base.py:86] 11500) loss = 3.658, grad_norm = 0.251
I0914 08:52:34.286814 139834269067072 spec.py:320] Evaluating on the training split.
I0914 08:53:16.395619 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 08:54:13.814461 139834269067072 spec.py:348] Evaluating on the test split.
I0914 08:54:14.907295 139834269067072 submission_runner.py:376] Time since start: 5185.94s, 	Step: 11676, 	{'train/accuracy': 0.5779655612244898, 'train/loss': 2.068122085259885, 'validation/accuracy': 0.5343, 'validation/loss': 2.2872796875, 'validation/num_examples': 50000, 'test/accuracy': 0.4065, 'test/loss': 2.98098671875, 'test/num_examples': 10000, 'score': 4128.741535663605, 'total_duration': 5185.935208559036, 'accumulated_submission_time': 4128.741535663605, 'accumulated_eval_time': 1034.5970752239227, 'accumulated_logging_time': 0.23186326026916504}
I0914 08:54:14.926731 139787151337216 logging_writer.py:48] [11676] accumulated_eval_time=1034.597075, accumulated_logging_time=0.231863, accumulated_submission_time=4128.741536, global_step=11676, preemption_count=0, score=4128.741536, test/accuracy=0.406500, test/loss=2.980987, test/num_examples=10000, total_duration=5185.935209, train/accuracy=0.577966, train/loss=2.068122, validation/accuracy=0.534300, validation/loss=2.287280, validation/num_examples=50000
I0914 08:56:07.085612 139787159729920 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.244357, loss=3.601095
I0914 08:56:07.089868 139834269067072 pytorch_submission_base.py:86] 12000) loss = 3.601, grad_norm = 0.244
I0914 08:59:00.188795 139787151337216 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.247618, loss=3.698290
I0914 08:59:00.198095 139834269067072 pytorch_submission_base.py:86] 12500) loss = 3.698, grad_norm = 0.248
I0914 09:01:53.753741 139787159729920 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.246444, loss=3.612450
I0914 09:01:53.758992 139834269067072 pytorch_submission_base.py:86] 13000) loss = 3.612, grad_norm = 0.246
I0914 09:02:45.980712 139834269067072 spec.py:320] Evaluating on the training split.
I0914 09:03:28.262152 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 09:04:26.089847 139834269067072 spec.py:348] Evaluating on the test split.
I0914 09:04:27.189061 139834269067072 submission_runner.py:376] Time since start: 5798.22s, 	Step: 13150, 	{'train/accuracy': 0.5659478635204082, 'train/loss': 2.13895338408801, 'validation/accuracy': 0.51816, 'validation/loss': 2.35374046875, 'validation/num_examples': 50000, 'test/accuracy': 0.3873, 'test/loss': 3.1037517578125, 'test/num_examples': 10000, 'score': 4637.100549936295, 'total_duration': 5798.216918468475, 'accumulated_submission_time': 4637.100549936295, 'accumulated_eval_time': 1135.8054895401, 'accumulated_logging_time': 0.26008081436157227}
I0914 09:04:27.243642 139787151337216 logging_writer.py:48] [13150] accumulated_eval_time=1135.805490, accumulated_logging_time=0.260081, accumulated_submission_time=4637.100550, global_step=13150, preemption_count=0, score=4637.100550, test/accuracy=0.387300, test/loss=3.103752, test/num_examples=10000, total_duration=5798.216918, train/accuracy=0.565948, train/loss=2.138953, validation/accuracy=0.518160, validation/loss=2.353740, validation/num_examples=50000
I0914 09:06:28.498595 139787159729920 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.246116, loss=3.627505
I0914 09:06:28.512268 139834269067072 pytorch_submission_base.py:86] 13500) loss = 3.628, grad_norm = 0.246
I0914 09:09:24.947387 139787151337216 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.242855, loss=3.602661
I0914 09:09:24.952031 139834269067072 pytorch_submission_base.py:86] 14000) loss = 3.603, grad_norm = 0.243
I0914 09:12:20.397667 139787159729920 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.246365, loss=3.603156
I0914 09:12:20.402138 139834269067072 pytorch_submission_base.py:86] 14500) loss = 3.603, grad_norm = 0.246
I0914 09:12:58.170125 139834269067072 spec.py:320] Evaluating on the training split.
I0914 09:13:39.753576 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 09:14:36.735425 139834269067072 spec.py:348] Evaluating on the test split.
I0914 09:14:37.832133 139834269067072 submission_runner.py:376] Time since start: 6408.85s, 	Step: 14606, 	{'train/accuracy': 0.5469347895408163, 'train/loss': 2.192572146045918, 'validation/accuracy': 0.50062, 'validation/loss': 2.415928125, 'validation/num_examples': 50000, 'test/accuracy': 0.4003, 'test/loss': 3.00174765625, 'test/num_examples': 10000, 'score': 5145.458602905273, 'total_duration': 6408.853790283203, 'accumulated_submission_time': 5145.458602905273, 'accumulated_eval_time': 1235.4615318775177, 'accumulated_logging_time': 0.32493138313293457}
I0914 09:14:37.853411 139787151337216 logging_writer.py:48] [14606] accumulated_eval_time=1235.461532, accumulated_logging_time=0.324931, accumulated_submission_time=5145.458603, global_step=14606, preemption_count=0, score=5145.458603, test/accuracy=0.400300, test/loss=3.001748, test/num_examples=10000, total_duration=6408.853790, train/accuracy=0.546935, train/loss=2.192572, validation/accuracy=0.500620, validation/loss=2.415928, validation/num_examples=50000
I0914 09:16:57.076615 139787159729920 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.248297, loss=3.573498
I0914 09:16:57.089876 139834269067072 pytorch_submission_base.py:86] 15000) loss = 3.573, grad_norm = 0.248
I0914 09:19:50.542805 139787151337216 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.249008, loss=3.552011
I0914 09:19:50.547107 139834269067072 pytorch_submission_base.py:86] 15500) loss = 3.552, grad_norm = 0.249
I0914 09:22:42.256073 139787159729920 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.247087, loss=3.563164
I0914 09:22:42.264088 139834269067072 pytorch_submission_base.py:86] 16000) loss = 3.563, grad_norm = 0.247
I0914 09:23:09.118959 139834269067072 spec.py:320] Evaluating on the training split.
I0914 09:23:52.379563 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 09:24:50.711353 139834269067072 spec.py:348] Evaluating on the test split.
I0914 09:24:51.801325 139834269067072 submission_runner.py:376] Time since start: 7022.83s, 	Step: 16076, 	{'train/accuracy': 0.5941286670918368, 'train/loss': 2.013149339325574, 'validation/accuracy': 0.54808, 'validation/loss': 2.23813484375, 'validation/num_examples': 50000, 'test/accuracy': 0.4262, 'test/loss': 2.8939173828125, 'test/num_examples': 10000, 'score': 5653.980618476868, 'total_duration': 7022.829247713089, 'accumulated_submission_time': 5653.980618476868, 'accumulated_eval_time': 1338.144369840622, 'accumulated_logging_time': 0.354633092880249}
I0914 09:24:51.824525 139787151337216 logging_writer.py:48] [16076] accumulated_eval_time=1338.144370, accumulated_logging_time=0.354633, accumulated_submission_time=5653.980618, global_step=16076, preemption_count=0, score=5653.980618, test/accuracy=0.426200, test/loss=2.893917, test/num_examples=10000, total_duration=7022.829248, train/accuracy=0.594129, train/loss=2.013149, validation/accuracy=0.548080, validation/loss=2.238135, validation/num_examples=50000
I0914 09:27:21.223305 139787159729920 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.239918, loss=3.553097
I0914 09:27:21.227467 139834269067072 pytorch_submission_base.py:86] 16500) loss = 3.553, grad_norm = 0.240
I0914 09:30:12.910582 139787151337216 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.248751, loss=3.584462
I0914 09:30:12.916688 139834269067072 pytorch_submission_base.py:86] 17000) loss = 3.584, grad_norm = 0.249
I0914 09:33:06.181191 139787159729920 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.252562, loss=3.598814
I0914 09:33:06.190856 139834269067072 pytorch_submission_base.py:86] 17500) loss = 3.599, grad_norm = 0.253
I0914 09:33:22.909433 139834269067072 spec.py:320] Evaluating on the training split.
I0914 09:34:05.495855 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 09:35:02.877329 139834269067072 spec.py:348] Evaluating on the test split.
I0914 09:35:03.966253 139834269067072 submission_runner.py:376] Time since start: 7634.99s, 	Step: 17542, 	{'train/accuracy': 0.6072026466836735, 'train/loss': 1.8829921800263074, 'validation/accuracy': 0.5566, 'validation/loss': 2.10387421875, 'validation/num_examples': 50000, 'test/accuracy': 0.4242, 'test/loss': 2.844534765625, 'test/num_examples': 10000, 'score': 6162.424164772034, 'total_duration': 7634.994186401367, 'accumulated_submission_time': 6162.424164772034, 'accumulated_eval_time': 1439.201328277588, 'accumulated_logging_time': 0.39263010025024414}
I0914 09:35:03.985310 139787151337216 logging_writer.py:48] [17542] accumulated_eval_time=1439.201328, accumulated_logging_time=0.392630, accumulated_submission_time=6162.424165, global_step=17542, preemption_count=0, score=6162.424165, test/accuracy=0.424200, test/loss=2.844535, test/num_examples=10000, total_duration=7634.994186, train/accuracy=0.607203, train/loss=1.882992, validation/accuracy=0.556600, validation/loss=2.103874, validation/num_examples=50000
I0914 09:37:42.034087 139787159729920 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.260626, loss=3.626159
I0914 09:37:42.038462 139834269067072 pytorch_submission_base.py:86] 18000) loss = 3.626, grad_norm = 0.261
I0914 09:40:33.770948 139787151337216 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.260201, loss=3.661133
I0914 09:40:33.776555 139834269067072 pytorch_submission_base.py:86] 18500) loss = 3.661, grad_norm = 0.260
I0914 09:43:29.008985 139787159729920 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.249654, loss=3.527534
I0914 09:43:29.013828 139834269067072 pytorch_submission_base.py:86] 19000) loss = 3.528, grad_norm = 0.250
I0914 09:43:35.127259 139834269067072 spec.py:320] Evaluating on the training split.
I0914 09:44:19.062098 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 09:45:13.112514 139834269067072 spec.py:348] Evaluating on the test split.
I0914 09:45:14.203836 139834269067072 submission_runner.py:376] Time since start: 8245.23s, 	Step: 19016, 	{'train/accuracy': 0.6076211734693877, 'train/loss': 1.842592511858259, 'validation/accuracy': 0.55762, 'validation/loss': 2.07040703125, 'validation/num_examples': 50000, 'test/accuracy': 0.4293, 'test/loss': 2.7867294921875, 'test/num_examples': 10000, 'score': 6670.975220680237, 'total_duration': 8245.231682538986, 'accumulated_submission_time': 6670.975220680237, 'accumulated_eval_time': 1538.278061389923, 'accumulated_logging_time': 0.4204268455505371}
I0914 09:45:14.227010 139787151337216 logging_writer.py:48] [19016] accumulated_eval_time=1538.278061, accumulated_logging_time=0.420427, accumulated_submission_time=6670.975221, global_step=19016, preemption_count=0, score=6670.975221, test/accuracy=0.429300, test/loss=2.786729, test/num_examples=10000, total_duration=8245.231683, train/accuracy=0.607621, train/loss=1.842593, validation/accuracy=0.557620, validation/loss=2.070407, validation/num_examples=50000
I0914 09:48:01.073808 139787159729920 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.246742, loss=3.498566
I0914 09:48:01.078433 139834269067072 pytorch_submission_base.py:86] 19500) loss = 3.499, grad_norm = 0.247
I0914 09:50:52.639910 139787151337216 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.259852, loss=3.496291
I0914 09:50:52.644567 139834269067072 pytorch_submission_base.py:86] 20000) loss = 3.496, grad_norm = 0.260
I0914 09:53:45.142689 139834269067072 spec.py:320] Evaluating on the training split.
I0914 09:54:27.097033 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 09:55:21.032059 139834269067072 spec.py:348] Evaluating on the test split.
I0914 09:55:22.116472 139834269067072 submission_runner.py:376] Time since start: 8853.14s, 	Step: 20496, 	{'train/accuracy': 0.5958824936224489, 'train/loss': 1.9366749354771204, 'validation/accuracy': 0.54774, 'validation/loss': 2.1636615625, 'validation/num_examples': 50000, 'test/accuracy': 0.4189, 'test/loss': 2.882854296875, 'test/num_examples': 10000, 'score': 7179.374185800552, 'total_duration': 8853.144400119781, 'accumulated_submission_time': 7179.374185800552, 'accumulated_eval_time': 1635.2522559165955, 'accumulated_logging_time': 0.45361828804016113}
I0914 09:55:22.133839 139787159729920 logging_writer.py:48] [20496] accumulated_eval_time=1635.252256, accumulated_logging_time=0.453618, accumulated_submission_time=7179.374186, global_step=20496, preemption_count=0, score=7179.374186, test/accuracy=0.418900, test/loss=2.882854, test/num_examples=10000, total_duration=8853.144400, train/accuracy=0.595882, train/loss=1.936675, validation/accuracy=0.547740, validation/loss=2.163662, validation/num_examples=50000
I0914 09:55:24.525998 139787151337216 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.251615, loss=3.495446
I0914 09:55:24.533725 139834269067072 pytorch_submission_base.py:86] 20500) loss = 3.495, grad_norm = 0.252
I0914 09:58:15.936159 139787159729920 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.250021, loss=3.503810
I0914 09:58:15.944318 139834269067072 pytorch_submission_base.py:86] 21000) loss = 3.504, grad_norm = 0.250
I0914 10:01:09.054124 139787151337216 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.250284, loss=3.535450
I0914 10:01:09.059179 139834269067072 pytorch_submission_base.py:86] 21500) loss = 3.535, grad_norm = 0.250
I0914 10:03:53.387395 139834269067072 spec.py:320] Evaluating on the training split.
I0914 10:04:35.551458 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 10:05:29.583390 139834269067072 spec.py:348] Evaluating on the test split.
I0914 10:05:30.671912 139834269067072 submission_runner.py:376] Time since start: 9461.70s, 	Step: 21977, 	{'train/accuracy': 0.621452487244898, 'train/loss': 1.7736855331732302, 'validation/accuracy': 0.56886, 'validation/loss': 2.031190625, 'validation/num_examples': 50000, 'test/accuracy': 0.4331, 'test/loss': 2.746473046875, 'test/num_examples': 10000, 'score': 7688.0603222846985, 'total_duration': 9461.698584794998, 'accumulated_submission_time': 7688.0603222846985, 'accumulated_eval_time': 1732.5357491970062, 'accumulated_logging_time': 0.48201489448547363}
I0914 10:05:30.691939 139787159729920 logging_writer.py:48] [21977] accumulated_eval_time=1732.535749, accumulated_logging_time=0.482015, accumulated_submission_time=7688.060322, global_step=21977, preemption_count=0, score=7688.060322, test/accuracy=0.433100, test/loss=2.746473, test/num_examples=10000, total_duration=9461.698585, train/accuracy=0.621452, train/loss=1.773686, validation/accuracy=0.568860, validation/loss=2.031191, validation/num_examples=50000
I0914 10:05:39.501210 139787151337216 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.258379, loss=3.584319
I0914 10:05:39.505885 139834269067072 pytorch_submission_base.py:86] 22000) loss = 3.584, grad_norm = 0.258
I0914 10:08:30.962640 139787159729920 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.253067, loss=3.510138
I0914 10:08:30.967820 139834269067072 pytorch_submission_base.py:86] 22500) loss = 3.510, grad_norm = 0.253
I0914 10:11:24.243050 139787151337216 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.248221, loss=3.489847
I0914 10:11:24.247548 139834269067072 pytorch_submission_base.py:86] 23000) loss = 3.490, grad_norm = 0.248
I0914 10:14:01.965718 139834269067072 spec.py:320] Evaluating on the training split.
I0914 10:14:44.078503 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 10:15:39.094488 139834269067072 spec.py:348] Evaluating on the test split.
I0914 10:15:40.181959 139834269067072 submission_runner.py:376] Time since start: 10071.21s, 	Step: 23458, 	{'train/accuracy': 0.5976961096938775, 'train/loss': 1.8679202332788585, 'validation/accuracy': 0.5474, 'validation/loss': 2.0991978125, 'validation/num_examples': 50000, 'test/accuracy': 0.4232, 'test/loss': 2.812408984375, 'test/num_examples': 10000, 'score': 8196.768168449402, 'total_duration': 10071.209857463837, 'accumulated_submission_time': 8196.768168449402, 'accumulated_eval_time': 1830.7522647380829, 'accumulated_logging_time': 0.5106523036956787}
I0914 10:15:40.202545 139787159729920 logging_writer.py:48] [23458] accumulated_eval_time=1830.752265, accumulated_logging_time=0.510652, accumulated_submission_time=8196.768168, global_step=23458, preemption_count=0, score=8196.768168, test/accuracy=0.423200, test/loss=2.812409, test/num_examples=10000, total_duration=10071.209857, train/accuracy=0.597696, train/loss=1.867920, validation/accuracy=0.547400, validation/loss=2.099198, validation/num_examples=50000
I0914 10:15:55.549872 139787151337216 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.248401, loss=3.476774
I0914 10:15:55.553578 139834269067072 pytorch_submission_base.py:86] 23500) loss = 3.477, grad_norm = 0.248
I0914 10:18:48.520739 139787159729920 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.252600, loss=3.503389
I0914 10:18:48.525954 139834269067072 pytorch_submission_base.py:86] 24000) loss = 3.503, grad_norm = 0.253
I0914 10:21:40.092173 139787151337216 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.251841, loss=3.522918
I0914 10:21:40.097011 139834269067072 pytorch_submission_base.py:86] 24500) loss = 3.523, grad_norm = 0.252
I0914 10:24:11.350480 139834269067072 spec.py:320] Evaluating on the training split.
I0914 10:24:53.635096 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 10:25:47.431266 139834269067072 spec.py:348] Evaluating on the test split.
I0914 10:25:48.519187 139834269067072 submission_runner.py:376] Time since start: 10679.55s, 	Step: 24939, 	{'train/accuracy': 0.6144770408163265, 'train/loss': 1.8177558743223852, 'validation/accuracy': 0.56678, 'validation/loss': 2.04693484375, 'validation/num_examples': 50000, 'test/accuracy': 0.4438, 'test/loss': 2.7090078125, 'test/num_examples': 10000, 'score': 8705.361060142517, 'total_duration': 10679.547111749649, 'accumulated_submission_time': 8705.361060142517, 'accumulated_eval_time': 1927.9214270114899, 'accumulated_logging_time': 0.5412359237670898}
I0914 10:25:48.536012 139787159729920 logging_writer.py:48] [24939] accumulated_eval_time=1927.921427, accumulated_logging_time=0.541236, accumulated_submission_time=8705.361060, global_step=24939, preemption_count=0, score=8705.361060, test/accuracy=0.443800, test/loss=2.709008, test/num_examples=10000, total_duration=10679.547112, train/accuracy=0.614477, train/loss=1.817756, validation/accuracy=0.566780, validation/loss=2.046935, validation/num_examples=50000
I0914 10:26:10.423652 139787151337216 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.267247, loss=3.511121
I0914 10:26:10.427814 139834269067072 pytorch_submission_base.py:86] 25000) loss = 3.511, grad_norm = 0.267
I0914 10:29:03.563920 139787159729920 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.257989, loss=3.523015
I0914 10:29:03.568371 139834269067072 pytorch_submission_base.py:86] 25500) loss = 3.523, grad_norm = 0.258
I0914 10:31:55.094977 139787151337216 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.253332, loss=3.546847
I0914 10:31:55.099887 139834269067072 pytorch_submission_base.py:86] 26000) loss = 3.547, grad_norm = 0.253
I0914 10:34:19.510409 139834269067072 spec.py:320] Evaluating on the training split.
I0914 10:35:02.395369 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 10:35:55.999692 139834269067072 spec.py:348] Evaluating on the test split.
I0914 10:35:57.084627 139834269067072 submission_runner.py:376] Time since start: 11288.11s, 	Step: 26415, 	{'train/accuracy': 0.6229870854591837, 'train/loss': 1.814096567582111, 'validation/accuracy': 0.57292, 'validation/loss': 2.055635625, 'validation/num_examples': 50000, 'test/accuracy': 0.4407, 'test/loss': 2.7481537109375, 'test/num_examples': 10000, 'score': 9213.80210185051, 'total_duration': 11288.111587762833, 'accumulated_submission_time': 9213.80210185051, 'accumulated_eval_time': 2025.4953210353851, 'accumulated_logging_time': 0.568253755569458}
I0914 10:35:57.102607 139787159729920 logging_writer.py:48] [26415] accumulated_eval_time=2025.495321, accumulated_logging_time=0.568254, accumulated_submission_time=9213.802102, global_step=26415, preemption_count=0, score=9213.802102, test/accuracy=0.440700, test/loss=2.748154, test/num_examples=10000, total_duration=11288.111588, train/accuracy=0.622987, train/loss=1.814097, validation/accuracy=0.572920, validation/loss=2.055636, validation/num_examples=50000
I0914 10:36:27.147303 139787151337216 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.264346, loss=3.529603
I0914 10:36:27.152328 139834269067072 pytorch_submission_base.py:86] 26500) loss = 3.530, grad_norm = 0.264
I0914 10:39:18.587241 139787159729920 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.254943, loss=3.493721
I0914 10:39:18.593960 139834269067072 pytorch_submission_base.py:86] 27000) loss = 3.494, grad_norm = 0.255
I0914 10:42:10.086289 139787151337216 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.260728, loss=3.480938
I0914 10:42:10.093936 139834269067072 pytorch_submission_base.py:86] 27500) loss = 3.481, grad_norm = 0.261
I0914 10:44:28.037517 139834269067072 spec.py:320] Evaluating on the training split.
I0914 10:45:10.197694 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 10:46:03.874888 139834269067072 spec.py:348] Evaluating on the test split.
I0914 10:46:04.963305 139834269067072 submission_runner.py:376] Time since start: 11895.99s, 	Step: 27896, 	{'train/accuracy': 0.616828762755102, 'train/loss': 1.8467724858498087, 'validation/accuracy': 0.56686, 'validation/loss': 2.08724125, 'validation/num_examples': 50000, 'test/accuracy': 0.439, 'test/loss': 2.76180234375, 'test/num_examples': 10000, 'score': 9722.178416013718, 'total_duration': 11895.991220712662, 'accumulated_submission_time': 9722.178416013718, 'accumulated_eval_time': 2122.421482563019, 'accumulated_logging_time': 0.5954921245574951}
I0914 10:46:04.980659 139787159729920 logging_writer.py:48] [27896] accumulated_eval_time=2122.421483, accumulated_logging_time=0.595492, accumulated_submission_time=9722.178416, global_step=27896, preemption_count=0, score=9722.178416, test/accuracy=0.439000, test/loss=2.761802, test/num_examples=10000, total_duration=11895.991221, train/accuracy=0.616829, train/loss=1.846772, validation/accuracy=0.566860, validation/loss=2.087241, validation/num_examples=50000
I0914 10:46:41.557070 139787151337216 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.269872, loss=3.427803
I0914 10:46:41.562207 139834269067072 pytorch_submission_base.py:86] 28000) loss = 3.428, grad_norm = 0.270
I0914 10:49:33.037287 139787159729920 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.251463, loss=3.434590
I0914 10:49:33.041941 139834269067072 pytorch_submission_base.py:86] 28500) loss = 3.435, grad_norm = 0.251
I0914 10:52:27.816305 139787151337216 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.255629, loss=3.440608
I0914 10:52:27.821635 139834269067072 pytorch_submission_base.py:86] 29000) loss = 3.441, grad_norm = 0.256
I0914 10:54:36.135828 139834269067072 spec.py:320] Evaluating on the training split.
I0914 10:55:18.324818 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 10:56:12.143458 139834269067072 spec.py:348] Evaluating on the test split.
I0914 10:56:13.231641 139834269067072 submission_runner.py:376] Time since start: 12504.26s, 	Step: 29364, 	{'train/accuracy': 0.6420599489795918, 'train/loss': 1.7355113126793686, 'validation/accuracy': 0.58606, 'validation/loss': 1.99039484375, 'validation/num_examples': 50000, 'test/accuracy': 0.4697, 'test/loss': 2.6297138671875, 'test/num_examples': 10000, 'score': 10230.789728403091, 'total_duration': 12504.259550094604, 'accumulated_submission_time': 10230.789728403091, 'accumulated_eval_time': 2219.5174429416656, 'accumulated_logging_time': 0.622840166091919}
I0914 10:56:13.251135 139787159729920 logging_writer.py:48] [29364] accumulated_eval_time=2219.517443, accumulated_logging_time=0.622840, accumulated_submission_time=10230.789728, global_step=29364, preemption_count=0, score=10230.789728, test/accuracy=0.469700, test/loss=2.629714, test/num_examples=10000, total_duration=12504.259550, train/accuracy=0.642060, train/loss=1.735511, validation/accuracy=0.586060, validation/loss=1.990395, validation/num_examples=50000
I0914 10:57:01.828533 139787151337216 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.247534, loss=3.426866
I0914 10:57:01.832890 139834269067072 pytorch_submission_base.py:86] 29500) loss = 3.427, grad_norm = 0.248
I0914 10:59:57.224258 139787159729920 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.257157, loss=3.388016
I0914 10:59:57.232959 139834269067072 pytorch_submission_base.py:86] 30000) loss = 3.388, grad_norm = 0.257
I0914 11:02:50.704185 139787151337216 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.268262, loss=3.480135
I0914 11:02:50.708416 139834269067072 pytorch_submission_base.py:86] 30500) loss = 3.480, grad_norm = 0.268
I0914 11:04:44.474148 139834269067072 spec.py:320] Evaluating on the training split.
I0914 11:05:26.834382 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 11:06:20.843223 139834269067072 spec.py:348] Evaluating on the test split.
I0914 11:06:21.933306 139834269067072 submission_runner.py:376] Time since start: 13112.96s, 	Step: 30830, 	{'train/accuracy': 0.6215521364795918, 'train/loss': 1.8206841605050224, 'validation/accuracy': 0.57056, 'validation/loss': 2.06769046875, 'validation/num_examples': 50000, 'test/accuracy': 0.4427, 'test/loss': 2.738627734375, 'test/num_examples': 10000, 'score': 10739.473891019821, 'total_duration': 13112.960005760193, 'accumulated_submission_time': 10739.473891019821, 'accumulated_eval_time': 2316.9756231307983, 'accumulated_logging_time': 0.6508674621582031}
I0914 11:06:21.954078 139787159729920 logging_writer.py:48] [30830] accumulated_eval_time=2316.975623, accumulated_logging_time=0.650867, accumulated_submission_time=10739.473891, global_step=30830, preemption_count=0, score=10739.473891, test/accuracy=0.442700, test/loss=2.738628, test/num_examples=10000, total_duration=13112.960006, train/accuracy=0.621552, train/loss=1.820684, validation/accuracy=0.570560, validation/loss=2.067690, validation/num_examples=50000
I0914 11:07:21.103429 139787151337216 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.257829, loss=3.466738
I0914 11:07:21.108374 139834269067072 pytorch_submission_base.py:86] 31000) loss = 3.467, grad_norm = 0.258
I0914 11:10:14.196140 139787159729920 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.264759, loss=3.446734
I0914 11:10:14.201601 139834269067072 pytorch_submission_base.py:86] 31500) loss = 3.447, grad_norm = 0.265
I0914 11:13:05.721960 139787151337216 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.266933, loss=3.451779
I0914 11:13:05.726244 139834269067072 pytorch_submission_base.py:86] 32000) loss = 3.452, grad_norm = 0.267
I0914 11:14:52.929507 139834269067072 spec.py:320] Evaluating on the training split.
I0914 11:15:35.639249 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 11:16:30.380629 139834269067072 spec.py:348] Evaluating on the test split.
I0914 11:16:31.468017 139834269067072 submission_runner.py:376] Time since start: 13722.50s, 	Step: 32311, 	{'train/accuracy': 0.6493542729591837, 'train/loss': 1.708731982172752, 'validation/accuracy': 0.59184, 'validation/loss': 1.96402828125, 'validation/num_examples': 50000, 'test/accuracy': 0.4698, 'test/loss': 2.63330546875, 'test/num_examples': 10000, 'score': 11247.923557043076, 'total_duration': 13722.49593758583, 'accumulated_submission_time': 11247.923557043076, 'accumulated_eval_time': 2415.5144810676575, 'accumulated_logging_time': 0.6806511878967285}
I0914 11:16:31.486692 139787159729920 logging_writer.py:48] [32311] accumulated_eval_time=2415.514481, accumulated_logging_time=0.680651, accumulated_submission_time=11247.923557, global_step=32311, preemption_count=0, score=11247.923557, test/accuracy=0.469800, test/loss=2.633305, test/num_examples=10000, total_duration=13722.495938, train/accuracy=0.649354, train/loss=1.708732, validation/accuracy=0.591840, validation/loss=1.964028, validation/num_examples=50000
I0914 11:17:37.222138 139787151337216 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.260940, loss=3.522415
I0914 11:17:37.227101 139834269067072 pytorch_submission_base.py:86] 32500) loss = 3.522, grad_norm = 0.261
I0914 11:20:30.209365 139787159729920 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.262612, loss=3.479586
I0914 11:20:30.214239 139834269067072 pytorch_submission_base.py:86] 33000) loss = 3.480, grad_norm = 0.263
I0914 11:23:21.661364 139787151337216 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.279742, loss=3.527148
I0914 11:23:21.668201 139834269067072 pytorch_submission_base.py:86] 33500) loss = 3.527, grad_norm = 0.280
I0914 11:25:02.450716 139834269067072 spec.py:320] Evaluating on the training split.
I0914 11:25:44.912170 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 11:26:38.865788 139834269067072 spec.py:348] Evaluating on the test split.
I0914 11:26:39.953613 139834269067072 submission_runner.py:376] Time since start: 14330.98s, 	Step: 33787, 	{'train/accuracy': 0.6435347576530612, 'train/loss': 1.724915329290896, 'validation/accuracy': 0.59268, 'validation/loss': 1.9648675, 'validation/num_examples': 50000, 'test/accuracy': 0.4594, 'test/loss': 2.6620001953125, 'test/num_examples': 10000, 'score': 11756.360791921616, 'total_duration': 14330.981527805328, 'accumulated_submission_time': 11756.360791921616, 'accumulated_eval_time': 2513.0176084041595, 'accumulated_logging_time': 0.7097623348236084}
I0914 11:26:39.975688 139787159729920 logging_writer.py:48] [33787] accumulated_eval_time=2513.017608, accumulated_logging_time=0.709762, accumulated_submission_time=11756.360792, global_step=33787, preemption_count=0, score=11756.360792, test/accuracy=0.459400, test/loss=2.662000, test/num_examples=10000, total_duration=14330.981528, train/accuracy=0.643535, train/loss=1.724915, validation/accuracy=0.592680, validation/loss=1.964867, validation/num_examples=50000
I0914 11:27:53.878856 139787151337216 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.268241, loss=3.367859
I0914 11:27:53.883118 139834269067072 pytorch_submission_base.py:86] 34000) loss = 3.368, grad_norm = 0.268
I0914 11:30:45.325433 139787159729920 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.263331, loss=3.443129
I0914 11:30:45.330332 139834269067072 pytorch_submission_base.py:86] 34500) loss = 3.443, grad_norm = 0.263
I0914 11:33:36.869150 139787151337216 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.265276, loss=3.403330
I0914 11:33:36.873520 139834269067072 pytorch_submission_base.py:86] 35000) loss = 3.403, grad_norm = 0.265
I0914 11:35:10.933360 139834269067072 spec.py:320] Evaluating on the training split.
I0914 11:35:53.331892 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 11:36:47.170350 139834269067072 spec.py:348] Evaluating on the test split.
I0914 11:36:48.258056 139834269067072 submission_runner.py:376] Time since start: 14939.29s, 	Step: 35268, 	{'train/accuracy': 0.5862165178571429, 'train/loss': 1.9849254063197546, 'validation/accuracy': 0.54216, 'validation/loss': 2.211795625, 'validation/num_examples': 50000, 'test/accuracy': 0.413, 'test/loss': 2.90699765625, 'test/num_examples': 10000, 'score': 12264.80813407898, 'total_duration': 14939.28597187996, 'accumulated_submission_time': 12264.80813407898, 'accumulated_eval_time': 2610.3426213264465, 'accumulated_logging_time': 0.7407073974609375}
I0914 11:36:48.275218 139787159729920 logging_writer.py:48] [35268] accumulated_eval_time=2610.342621, accumulated_logging_time=0.740707, accumulated_submission_time=12264.808134, global_step=35268, preemption_count=0, score=12264.808134, test/accuracy=0.413000, test/loss=2.906998, test/num_examples=10000, total_duration=14939.285972, train/accuracy=0.586217, train/loss=1.984925, validation/accuracy=0.542160, validation/loss=2.211796, validation/num_examples=50000
I0914 11:38:08.665525 139787151337216 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.255303, loss=3.303722
I0914 11:38:08.671432 139834269067072 pytorch_submission_base.py:86] 35500) loss = 3.304, grad_norm = 0.255
I0914 11:41:00.071926 139787159729920 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.277701, loss=3.424382
I0914 11:41:00.076980 139834269067072 pytorch_submission_base.py:86] 36000) loss = 3.424, grad_norm = 0.278
I0914 11:43:53.206831 139787151337216 logging_writer.py:48] [36500] global_step=36500, grad_norm=0.264769, loss=3.421868
I0914 11:43:53.212105 139834269067072 pytorch_submission_base.py:86] 36500) loss = 3.422, grad_norm = 0.265
I0914 11:45:19.265620 139834269067072 spec.py:320] Evaluating on the training split.
I0914 11:46:01.850814 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 11:46:55.603312 139834269067072 spec.py:348] Evaluating on the test split.
I0914 11:46:56.690263 139834269067072 submission_runner.py:376] Time since start: 15547.72s, 	Step: 36749, 	{'train/accuracy': 0.6332708864795918, 'train/loss': 1.7721071827168366, 'validation/accuracy': 0.58038, 'validation/loss': 2.00983140625, 'validation/num_examples': 50000, 'test/accuracy': 0.454, 'test/loss': 2.7004876953125, 'test/num_examples': 10000, 'score': 12773.20137166977, 'total_duration': 15547.718202352524, 'accumulated_submission_time': 12773.20137166977, 'accumulated_eval_time': 2707.767631292343, 'accumulated_logging_time': 0.7669270038604736}
I0914 11:46:56.708058 139787159729920 logging_writer.py:48] [36749] accumulated_eval_time=2707.767631, accumulated_logging_time=0.766927, accumulated_submission_time=12773.201372, global_step=36749, preemption_count=0, score=12773.201372, test/accuracy=0.454000, test/loss=2.700488, test/num_examples=10000, total_duration=15547.718202, train/accuracy=0.633271, train/loss=1.772107, validation/accuracy=0.580380, validation/loss=2.009831, validation/num_examples=50000
I0914 11:48:23.586700 139787151337216 logging_writer.py:48] [37000] global_step=37000, grad_norm=0.259427, loss=3.399525
I0914 11:48:23.592729 139834269067072 pytorch_submission_base.py:86] 37000) loss = 3.400, grad_norm = 0.259
I0914 11:51:15.072271 139787159729920 logging_writer.py:48] [37500] global_step=37500, grad_norm=0.262665, loss=3.375556
I0914 11:51:15.079274 139834269067072 pytorch_submission_base.py:86] 37500) loss = 3.376, grad_norm = 0.263
I0914 11:54:08.102209 139787151337216 logging_writer.py:48] [38000] global_step=38000, grad_norm=0.252994, loss=3.350592
I0914 11:54:08.109055 139834269067072 pytorch_submission_base.py:86] 38000) loss = 3.351, grad_norm = 0.253
I0914 11:55:27.873417 139834269067072 spec.py:320] Evaluating on the training split.
I0914 11:56:10.297729 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 11:57:03.959376 139834269067072 spec.py:348] Evaluating on the test split.
I0914 11:57:05.044185 139834269067072 submission_runner.py:376] Time since start: 16156.07s, 	Step: 38231, 	{'train/accuracy': 0.6286670918367347, 'train/loss': 1.7528034132354113, 'validation/accuracy': 0.57734, 'validation/loss': 1.9919565625, 'validation/num_examples': 50000, 'test/accuracy': 0.4451, 'test/loss': 2.7078625, 'test/num_examples': 10000, 'score': 13281.822976827621, 'total_duration': 16156.070827245712, 'accumulated_submission_time': 13281.822976827621, 'accumulated_eval_time': 2804.9374384880066, 'accumulated_logging_time': 0.7943735122680664}
I0914 11:57:05.065266 139787159729920 logging_writer.py:48] [38231] accumulated_eval_time=2804.937438, accumulated_logging_time=0.794374, accumulated_submission_time=13281.822977, global_step=38231, preemption_count=0, score=13281.822977, test/accuracy=0.445100, test/loss=2.707863, test/num_examples=10000, total_duration=16156.070827, train/accuracy=0.628667, train/loss=1.752803, validation/accuracy=0.577340, validation/loss=1.991957, validation/num_examples=50000
I0914 11:58:38.236318 139787151337216 logging_writer.py:48] [38500] global_step=38500, grad_norm=0.258659, loss=3.388806
I0914 11:58:38.241254 139834269067072 pytorch_submission_base.py:86] 38500) loss = 3.389, grad_norm = 0.259
I0914 12:01:31.412512 139787159729920 logging_writer.py:48] [39000] global_step=39000, grad_norm=0.266611, loss=3.344484
I0914 12:01:31.417165 139834269067072 pytorch_submission_base.py:86] 39000) loss = 3.344, grad_norm = 0.267
I0914 12:04:23.012425 139787151337216 logging_writer.py:48] [39500] global_step=39500, grad_norm=0.271863, loss=3.423596
I0914 12:04:23.021714 139834269067072 pytorch_submission_base.py:86] 39500) loss = 3.424, grad_norm = 0.272
I0914 12:05:36.365382 139834269067072 spec.py:320] Evaluating on the training split.
I0914 12:06:18.887117 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 12:07:12.239546 139834269067072 spec.py:348] Evaluating on the test split.
I0914 12:07:13.323551 139834269067072 submission_runner.py:376] Time since start: 16764.35s, 	Step: 39712, 	{'train/accuracy': 0.6512476084183674, 'train/loss': 1.6841346585020727, 'validation/accuracy': 0.59744, 'validation/loss': 1.9276578125, 'validation/num_examples': 50000, 'test/accuracy': 0.4567, 'test/loss': 2.664127734375, 'test/num_examples': 10000, 'score': 13790.505385875702, 'total_duration': 16764.351469278336, 'accumulated_submission_time': 13790.505385875702, 'accumulated_eval_time': 2901.895949602127, 'accumulated_logging_time': 0.8244600296020508}
I0914 12:07:13.343428 139787159729920 logging_writer.py:48] [39712] accumulated_eval_time=2901.895950, accumulated_logging_time=0.824460, accumulated_submission_time=13790.505386, global_step=39712, preemption_count=0, score=13790.505386, test/accuracy=0.456700, test/loss=2.664128, test/num_examples=10000, total_duration=16764.351469, train/accuracy=0.651248, train/loss=1.684135, validation/accuracy=0.597440, validation/loss=1.927658, validation/num_examples=50000
I0914 12:08:53.013410 139787151337216 logging_writer.py:48] [40000] global_step=40000, grad_norm=0.262973, loss=3.388013
I0914 12:08:53.019224 139834269067072 pytorch_submission_base.py:86] 40000) loss = 3.388, grad_norm = 0.263
I0914 12:11:45.889278 139787159729920 logging_writer.py:48] [40500] global_step=40500, grad_norm=0.270155, loss=3.347816
I0914 12:11:45.893788 139834269067072 pytorch_submission_base.py:86] 40500) loss = 3.348, grad_norm = 0.270
I0914 12:14:37.315495 139787151337216 logging_writer.py:48] [41000] global_step=41000, grad_norm=0.264016, loss=3.397143
I0914 12:14:37.321243 139834269067072 pytorch_submission_base.py:86] 41000) loss = 3.397, grad_norm = 0.264
I0914 12:15:44.454295 139834269067072 spec.py:320] Evaluating on the training split.
I0914 12:16:27.149793 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 12:17:21.732992 139834269067072 spec.py:348] Evaluating on the test split.
I0914 12:17:22.825432 139834269067072 submission_runner.py:376] Time since start: 17373.85s, 	Step: 41194, 	{'train/accuracy': 0.6590999681122449, 'train/loss': 1.6275346717055963, 'validation/accuracy': 0.60234, 'validation/loss': 1.89422546875, 'validation/num_examples': 50000, 'test/accuracy': 0.4731, 'test/loss': 2.5890517578125, 'test/num_examples': 10000, 'score': 14299.102891206741, 'total_duration': 17373.85334086418, 'accumulated_submission_time': 14299.102891206741, 'accumulated_eval_time': 3000.267299890518, 'accumulated_logging_time': 0.8528096675872803}
I0914 12:17:22.846974 139787159729920 logging_writer.py:48] [41194] accumulated_eval_time=3000.267300, accumulated_logging_time=0.852810, accumulated_submission_time=14299.102891, global_step=41194, preemption_count=0, score=14299.102891, test/accuracy=0.473100, test/loss=2.589052, test/num_examples=10000, total_duration=17373.853341, train/accuracy=0.659100, train/loss=1.627535, validation/accuracy=0.602340, validation/loss=1.894225, validation/num_examples=50000
I0914 12:19:10.079963 139787151337216 logging_writer.py:48] [41500] global_step=41500, grad_norm=0.268182, loss=3.352244
I0914 12:19:10.084322 139834269067072 pytorch_submission_base.py:86] 41500) loss = 3.352, grad_norm = 0.268
I0914 12:22:01.539219 139787159729920 logging_writer.py:48] [42000] global_step=42000, grad_norm=0.267276, loss=3.372541
I0914 12:22:01.544392 139834269067072 pytorch_submission_base.py:86] 42000) loss = 3.373, grad_norm = 0.267
I0914 12:24:52.851033 139787151337216 logging_writer.py:48] [42500] global_step=42500, grad_norm=0.271968, loss=3.390442
I0914 12:24:52.860867 139834269067072 pytorch_submission_base.py:86] 42500) loss = 3.390, grad_norm = 0.272
I0914 12:25:54.044713 139834269067072 spec.py:320] Evaluating on the training split.
I0914 12:26:36.676455 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 12:27:30.825525 139834269067072 spec.py:348] Evaluating on the test split.
I0914 12:27:31.916737 139834269067072 submission_runner.py:376] Time since start: 17982.94s, 	Step: 42672, 	{'train/accuracy': 0.6500916772959183, 'train/loss': 1.702062957140864, 'validation/accuracy': 0.59254, 'validation/loss': 1.96739921875, 'validation/num_examples': 50000, 'test/accuracy': 0.4684, 'test/loss': 2.627764453125, 'test/num_examples': 10000, 'score': 14807.709326982498, 'total_duration': 17982.94363808632, 'accumulated_submission_time': 14807.709326982498, 'accumulated_eval_time': 3098.1386892795563, 'accumulated_logging_time': 0.8843719959259033}
I0914 12:27:31.936140 139787159729920 logging_writer.py:48] [42672] accumulated_eval_time=3098.138689, accumulated_logging_time=0.884372, accumulated_submission_time=14807.709327, global_step=42672, preemption_count=0, score=14807.709327, test/accuracy=0.468400, test/loss=2.627764, test/num_examples=10000, total_duration=17982.943638, train/accuracy=0.650092, train/loss=1.702063, validation/accuracy=0.592540, validation/loss=1.967399, validation/num_examples=50000
I0914 12:29:25.232807 139787151337216 logging_writer.py:48] [43000] global_step=43000, grad_norm=0.273896, loss=3.355855
I0914 12:29:25.237719 139834269067072 pytorch_submission_base.py:86] 43000) loss = 3.356, grad_norm = 0.274
I0914 12:32:16.487064 139787159729920 logging_writer.py:48] [43500] global_step=43500, grad_norm=0.262568, loss=3.336616
I0914 12:32:16.494915 139834269067072 pytorch_submission_base.py:86] 43500) loss = 3.337, grad_norm = 0.263
I0914 12:35:11.184911 139787151337216 logging_writer.py:48] [44000] global_step=44000, grad_norm=0.270607, loss=3.370305
I0914 12:35:11.189359 139834269067072 pytorch_submission_base.py:86] 44000) loss = 3.370, grad_norm = 0.271
I0914 12:36:02.941299 139834269067072 spec.py:320] Evaluating on the training split.
I0914 12:36:45.492827 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 12:37:39.080057 139834269067072 spec.py:348] Evaluating on the test split.
I0914 12:37:40.167135 139834269067072 submission_runner.py:376] Time since start: 18591.20s, 	Step: 44146, 	{'train/accuracy': 0.6560108418367347, 'train/loss': 1.6276397705078125, 'validation/accuracy': 0.60274, 'validation/loss': 1.88520734375, 'validation/num_examples': 50000, 'test/accuracy': 0.4754, 'test/loss': 2.567808984375, 'test/num_examples': 10000, 'score': 15316.205023288727, 'total_duration': 18591.195024728775, 'accumulated_submission_time': 15316.205023288727, 'accumulated_eval_time': 3195.364699602127, 'accumulated_logging_time': 0.9136850833892822}
I0914 12:37:40.185615 139787159729920 logging_writer.py:48] [44146] accumulated_eval_time=3195.364700, accumulated_logging_time=0.913685, accumulated_submission_time=15316.205023, global_step=44146, preemption_count=0, score=15316.205023, test/accuracy=0.475400, test/loss=2.567809, test/num_examples=10000, total_duration=18591.195025, train/accuracy=0.656011, train/loss=1.627640, validation/accuracy=0.602740, validation/loss=1.885207, validation/num_examples=50000
I0914 12:39:45.221327 139787151337216 logging_writer.py:48] [44500] global_step=44500, grad_norm=0.279874, loss=3.399959
I0914 12:39:45.228343 139834269067072 pytorch_submission_base.py:86] 44500) loss = 3.400, grad_norm = 0.280
I0914 12:42:40.584723 139787159729920 logging_writer.py:48] [45000] global_step=45000, grad_norm=0.272781, loss=3.311972
I0914 12:42:40.589033 139834269067072 pytorch_submission_base.py:86] 45000) loss = 3.312, grad_norm = 0.273
I0914 12:45:34.079016 139787151337216 logging_writer.py:48] [45500] global_step=45500, grad_norm=0.277168, loss=3.395629
I0914 12:45:34.083651 139834269067072 pytorch_submission_base.py:86] 45500) loss = 3.396, grad_norm = 0.277
I0914 12:46:11.379744 139834269067072 spec.py:320] Evaluating on the training split.
I0914 12:46:54.099841 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 12:47:48.203334 139834269067072 spec.py:348] Evaluating on the test split.
I0914 12:47:49.286074 139834269067072 submission_runner.py:376] Time since start: 19200.31s, 	Step: 45607, 	{'train/accuracy': 0.6733298788265306, 'train/loss': 1.5344853303870376, 'validation/accuracy': 0.61354, 'validation/loss': 1.80135421875, 'validation/num_examples': 50000, 'test/accuracy': 0.4873, 'test/loss': 2.474778515625, 'test/num_examples': 10000, 'score': 15824.82373213768, 'total_duration': 19200.313976049423, 'accumulated_submission_time': 15824.82373213768, 'accumulated_eval_time': 3293.271233320236, 'accumulated_logging_time': 0.9405677318572998}
I0914 12:47:49.306156 139787159729920 logging_writer.py:48] [45607] accumulated_eval_time=3293.271233, accumulated_logging_time=0.940568, accumulated_submission_time=15824.823732, global_step=45607, preemption_count=0, score=15824.823732, test/accuracy=0.487300, test/loss=2.474779, test/num_examples=10000, total_duration=19200.313976, train/accuracy=0.673330, train/loss=1.534485, validation/accuracy=0.613540, validation/loss=1.801354, validation/num_examples=50000
I0914 12:50:04.927200 139787151337216 logging_writer.py:48] [46000] global_step=46000, grad_norm=0.273111, loss=3.398758
I0914 12:50:04.931910 139834269067072 pytorch_submission_base.py:86] 46000) loss = 3.399, grad_norm = 0.273
I0914 12:52:58.108651 139787159729920 logging_writer.py:48] [46500] global_step=46500, grad_norm=0.274439, loss=3.389971
I0914 12:52:58.113911 139834269067072 pytorch_submission_base.py:86] 46500) loss = 3.390, grad_norm = 0.274
I0914 12:55:49.596954 139787151337216 logging_writer.py:48] [47000] global_step=47000, grad_norm=0.275924, loss=3.423101
I0914 12:55:49.601583 139834269067072 pytorch_submission_base.py:86] 47000) loss = 3.423, grad_norm = 0.276
I0914 12:56:20.398175 139834269067072 spec.py:320] Evaluating on the training split.
I0914 12:57:03.109010 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 12:57:58.330143 139834269067072 spec.py:348] Evaluating on the test split.
I0914 12:57:59.418418 139834269067072 submission_runner.py:376] Time since start: 19810.45s, 	Step: 47088, 	{'train/accuracy': 0.6215122767857143, 'train/loss': 1.8686960959921077, 'validation/accuracy': 0.56562, 'validation/loss': 2.12230015625, 'validation/num_examples': 50000, 'test/accuracy': 0.4264, 'test/loss': 2.8546908203125, 'test/num_examples': 10000, 'score': 16333.285156726837, 'total_duration': 19810.44502711296, 'accumulated_submission_time': 16333.285156726837, 'accumulated_eval_time': 3392.2903673648834, 'accumulated_logging_time': 0.9696080684661865}
I0914 12:57:59.437797 139787159729920 logging_writer.py:48] [47088] accumulated_eval_time=3392.290367, accumulated_logging_time=0.969608, accumulated_submission_time=16333.285157, global_step=47088, preemption_count=0, score=16333.285157, test/accuracy=0.426400, test/loss=2.854691, test/num_examples=10000, total_duration=19810.445027, train/accuracy=0.621512, train/loss=1.868696, validation/accuracy=0.565620, validation/loss=2.122300, validation/num_examples=50000
I0914 13:00:21.601356 139787151337216 logging_writer.py:48] [47500] global_step=47500, grad_norm=0.274614, loss=3.380804
I0914 13:00:21.607545 139834269067072 pytorch_submission_base.py:86] 47500) loss = 3.381, grad_norm = 0.275
I0914 13:03:14.725485 139787159729920 logging_writer.py:48] [48000] global_step=48000, grad_norm=0.270162, loss=3.259214
I0914 13:03:14.729424 139834269067072 pytorch_submission_base.py:86] 48000) loss = 3.259, grad_norm = 0.270
I0914 13:06:06.085846 139787151337216 logging_writer.py:48] [48500] global_step=48500, grad_norm=0.272967, loss=3.293122
I0914 13:06:06.091045 139834269067072 pytorch_submission_base.py:86] 48500) loss = 3.293, grad_norm = 0.273
I0914 13:06:30.661427 139834269067072 spec.py:320] Evaluating on the training split.
I0914 13:07:13.425928 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 13:08:09.592720 139834269067072 spec.py:348] Evaluating on the test split.
I0914 13:08:10.680324 139834269067072 submission_runner.py:376] Time since start: 20421.71s, 	Step: 48570, 	{'train/accuracy': 0.6765186543367347, 'train/loss': 1.5396625752351722, 'validation/accuracy': 0.62284, 'validation/loss': 1.79409015625, 'validation/num_examples': 50000, 'test/accuracy': 0.4926, 'test/loss': 2.468009765625, 'test/num_examples': 10000, 'score': 16841.92125248909, 'total_duration': 20421.708201885223, 'accumulated_submission_time': 16841.92125248909, 'accumulated_eval_time': 3492.3094577789307, 'accumulated_logging_time': 0.9975521564483643}
I0914 13:08:10.702106 139787159729920 logging_writer.py:48] [48570] accumulated_eval_time=3492.309458, accumulated_logging_time=0.997552, accumulated_submission_time=16841.921252, global_step=48570, preemption_count=0, score=16841.921252, test/accuracy=0.492600, test/loss=2.468010, test/num_examples=10000, total_duration=20421.708202, train/accuracy=0.676519, train/loss=1.539663, validation/accuracy=0.622840, validation/loss=1.794090, validation/num_examples=50000
I0914 13:10:40.576656 139787151337216 logging_writer.py:48] [49000] global_step=49000, grad_norm=0.272284, loss=3.293020
I0914 13:10:40.580807 139834269067072 pytorch_submission_base.py:86] 49000) loss = 3.293, grad_norm = 0.272
I0914 13:13:31.963676 139787159729920 logging_writer.py:48] [49500] global_step=49500, grad_norm=0.274331, loss=3.266509
I0914 13:13:31.968523 139834269067072 pytorch_submission_base.py:86] 49500) loss = 3.267, grad_norm = 0.274
I0914 13:16:23.519728 139787151337216 logging_writer.py:48] [50000] global_step=50000, grad_norm=0.279358, loss=3.298081
I0914 13:16:23.524373 139834269067072 pytorch_submission_base.py:86] 50000) loss = 3.298, grad_norm = 0.279
I0914 13:16:41.678580 139834269067072 spec.py:320] Evaluating on the training split.
I0914 13:17:24.330542 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 13:18:19.095293 139834269067072 spec.py:348] Evaluating on the test split.
I0914 13:18:20.183562 139834269067072 submission_runner.py:376] Time since start: 21031.21s, 	Step: 50047, 	{'train/accuracy': 0.6688855229591837, 'train/loss': 1.5890923324896364, 'validation/accuracy': 0.60918, 'validation/loss': 1.84859765625, 'validation/num_examples': 50000, 'test/accuracy': 0.4702, 'test/loss': 2.5930892578125, 'test/num_examples': 10000, 'score': 17350.335282564163, 'total_duration': 21031.21148133278, 'accumulated_submission_time': 17350.335282564163, 'accumulated_eval_time': 3590.8148527145386, 'accumulated_logging_time': 1.0316252708435059}
I0914 13:18:20.204068 139787159729920 logging_writer.py:48] [50047] accumulated_eval_time=3590.814853, accumulated_logging_time=1.031625, accumulated_submission_time=17350.335283, global_step=50047, preemption_count=0, score=17350.335283, test/accuracy=0.470200, test/loss=2.593089, test/num_examples=10000, total_duration=21031.211481, train/accuracy=0.668886, train/loss=1.589092, validation/accuracy=0.609180, validation/loss=1.848598, validation/num_examples=50000
I0914 13:20:56.243025 139787151337216 logging_writer.py:48] [50500] global_step=50500, grad_norm=0.286048, loss=3.353597
I0914 13:20:56.247278 139834269067072 pytorch_submission_base.py:86] 50500) loss = 3.354, grad_norm = 0.286
I0914 13:23:47.538855 139787159729920 logging_writer.py:48] [51000] global_step=51000, grad_norm=0.283139, loss=3.313695
I0914 13:23:47.547351 139834269067072 pytorch_submission_base.py:86] 51000) loss = 3.314, grad_norm = 0.283
I0914 13:26:40.470724 139787151337216 logging_writer.py:48] [51500] global_step=51500, grad_norm=0.283442, loss=3.280053
I0914 13:26:40.475352 139834269067072 pytorch_submission_base.py:86] 51500) loss = 3.280, grad_norm = 0.283
I0914 13:26:51.290558 139834269067072 spec.py:320] Evaluating on the training split.
I0914 13:27:33.806068 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 13:28:28.125199 139834269067072 spec.py:348] Evaluating on the test split.
I0914 13:28:29.208149 139834269067072 submission_runner.py:376] Time since start: 21640.24s, 	Step: 51530, 	{'train/accuracy': 0.6559311224489796, 'train/loss': 1.6821876058773118, 'validation/accuracy': 0.59694, 'validation/loss': 1.943536875, 'validation/num_examples': 50000, 'test/accuracy': 0.4748, 'test/loss': 2.60391015625, 'test/num_examples': 10000, 'score': 17858.9150018692, 'total_duration': 21640.23606610298, 'accumulated_submission_time': 17858.9150018692, 'accumulated_eval_time': 3688.7329802513123, 'accumulated_logging_time': 1.0616331100463867}
I0914 13:28:29.228374 139787159729920 logging_writer.py:48] [51530] accumulated_eval_time=3688.732980, accumulated_logging_time=1.061633, accumulated_submission_time=17858.915002, global_step=51530, preemption_count=0, score=17858.915002, test/accuracy=0.474800, test/loss=2.603910, test/num_examples=10000, total_duration=21640.236066, train/accuracy=0.655931, train/loss=1.682188, validation/accuracy=0.596940, validation/loss=1.943537, validation/num_examples=50000
I0914 13:31:11.167198 139787151337216 logging_writer.py:48] [52000] global_step=52000, grad_norm=0.279671, loss=3.387323
I0914 13:31:11.173996 139834269067072 pytorch_submission_base.py:86] 52000) loss = 3.387, grad_norm = 0.280
I0914 13:34:02.627018 139787159729920 logging_writer.py:48] [52500] global_step=52500, grad_norm=0.283419, loss=3.374674
I0914 13:34:02.632882 139834269067072 pytorch_submission_base.py:86] 52500) loss = 3.375, grad_norm = 0.283
I0914 13:36:55.687914 139787151337216 logging_writer.py:48] [53000] global_step=53000, grad_norm=0.283908, loss=3.290450
I0914 13:36:55.696556 139834269067072 pytorch_submission_base.py:86] 53000) loss = 3.290, grad_norm = 0.284
I0914 13:37:00.398234 139834269067072 spec.py:320] Evaluating on the training split.
I0914 13:37:43.159469 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 13:38:37.804291 139834269067072 spec.py:348] Evaluating on the test split.
I0914 13:38:38.890922 139834269067072 submission_runner.py:376] Time since start: 22249.92s, 	Step: 53012, 	{'train/accuracy': 0.6407047193877551, 'train/loss': 1.7762989900550064, 'validation/accuracy': 0.58676, 'validation/loss': 2.040225625, 'validation/num_examples': 50000, 'test/accuracy': 0.4582, 'test/loss': 2.724531640625, 'test/num_examples': 10000, 'score': 18367.534528255463, 'total_duration': 22249.918818712234, 'accumulated_submission_time': 18367.534528255463, 'accumulated_eval_time': 3787.2259769439697, 'accumulated_logging_time': 1.0911426544189453}
I0914 13:38:38.913117 139787159729920 logging_writer.py:48] [53012] accumulated_eval_time=3787.225977, accumulated_logging_time=1.091143, accumulated_submission_time=18367.534528, global_step=53012, preemption_count=0, score=18367.534528, test/accuracy=0.458200, test/loss=2.724532, test/num_examples=10000, total_duration=22249.918819, train/accuracy=0.640705, train/loss=1.776299, validation/accuracy=0.586760, validation/loss=2.040226, validation/num_examples=50000
I0914 13:41:26.956941 139787151337216 logging_writer.py:48] [53500] global_step=53500, grad_norm=0.271660, loss=3.292513
I0914 13:41:26.961573 139834269067072 pytorch_submission_base.py:86] 53500) loss = 3.293, grad_norm = 0.272
I0914 13:44:20.013072 139787159729920 logging_writer.py:48] [54000] global_step=54000, grad_norm=0.289310, loss=3.377124
I0914 13:44:20.021228 139834269067072 pytorch_submission_base.py:86] 54000) loss = 3.377, grad_norm = 0.289
I0914 13:47:09.922784 139834269067072 spec.py:320] Evaluating on the training split.
I0914 13:47:52.167615 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 13:48:47.015747 139834269067072 spec.py:348] Evaluating on the test split.
I0914 13:48:48.105336 139834269067072 submission_runner.py:376] Time since start: 22859.13s, 	Step: 54494, 	{'train/accuracy': 0.682258450255102, 'train/loss': 1.5294913467095823, 'validation/accuracy': 0.62002, 'validation/loss': 1.79784328125, 'validation/num_examples': 50000, 'test/accuracy': 0.4885, 'test/loss': 2.493837890625, 'test/num_examples': 10000, 'score': 18875.995351076126, 'total_duration': 22859.131870746613, 'accumulated_submission_time': 18875.995351076126, 'accumulated_eval_time': 3885.407393217087, 'accumulated_logging_time': 1.122931957244873}
I0914 13:48:48.126034 139787151337216 logging_writer.py:48] [54494] accumulated_eval_time=3885.407393, accumulated_logging_time=1.122932, accumulated_submission_time=18875.995351, global_step=54494, preemption_count=0, score=18875.995351, test/accuracy=0.488500, test/loss=2.493838, test/num_examples=10000, total_duration=22859.131871, train/accuracy=0.682258, train/loss=1.529491, validation/accuracy=0.620020, validation/loss=1.797843, validation/num_examples=50000
I0914 13:48:51.153179 139787159729920 logging_writer.py:48] [54500] global_step=54500, grad_norm=0.278131, loss=3.287704
I0914 13:48:51.158245 139834269067072 pytorch_submission_base.py:86] 54500) loss = 3.288, grad_norm = 0.278
I0914 13:51:42.504873 139787151337216 logging_writer.py:48] [55000] global_step=55000, grad_norm=0.280591, loss=3.323993
I0914 13:51:42.511907 139834269067072 pytorch_submission_base.py:86] 55000) loss = 3.324, grad_norm = 0.281
I0914 13:54:35.698209 139787159729920 logging_writer.py:48] [55500] global_step=55500, grad_norm=0.283309, loss=3.262918
I0914 13:54:35.704142 139834269067072 pytorch_submission_base.py:86] 55500) loss = 3.263, grad_norm = 0.283
I0914 13:57:19.112347 139834269067072 spec.py:320] Evaluating on the training split.
I0914 13:58:01.573917 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 13:58:55.533163 139834269067072 spec.py:348] Evaluating on the test split.
I0914 13:58:56.618610 139834269067072 submission_runner.py:376] Time since start: 23467.65s, 	Step: 55975, 	{'train/accuracy': 0.6935985331632653, 'train/loss': 1.4933748829121491, 'validation/accuracy': 0.6302, 'validation/loss': 1.7671353125, 'validation/num_examples': 50000, 'test/accuracy': 0.5001, 'test/loss': 2.4519333984375, 'test/num_examples': 10000, 'score': 19384.44639134407, 'total_duration': 23467.646543979645, 'accumulated_submission_time': 19384.44639134407, 'accumulated_eval_time': 3982.9139366149902, 'accumulated_logging_time': 1.1527066230773926}
I0914 13:58:56.644449 139787151337216 logging_writer.py:48] [55975] accumulated_eval_time=3982.913937, accumulated_logging_time=1.152707, accumulated_submission_time=19384.446391, global_step=55975, preemption_count=0, score=19384.446391, test/accuracy=0.500100, test/loss=2.451933, test/num_examples=10000, total_duration=23467.646544, train/accuracy=0.693599, train/loss=1.493375, validation/accuracy=0.630200, validation/loss=1.767135, validation/num_examples=50000
I0914 13:59:06.167808 139787159729920 logging_writer.py:48] [56000] global_step=56000, grad_norm=0.281104, loss=3.149975
I0914 13:59:06.173161 139834269067072 pytorch_submission_base.py:86] 56000) loss = 3.150, grad_norm = 0.281
I0914 14:01:59.177350 139787151337216 logging_writer.py:48] [56500] global_step=56500, grad_norm=0.277459, loss=3.170503
I0914 14:01:59.182492 139834269067072 pytorch_submission_base.py:86] 56500) loss = 3.171, grad_norm = 0.277
I0914 14:04:50.512330 139787159729920 logging_writer.py:48] [57000] global_step=57000, grad_norm=0.281800, loss=3.204655
I0914 14:04:50.517172 139834269067072 pytorch_submission_base.py:86] 57000) loss = 3.205, grad_norm = 0.282
I0914 14:07:27.723688 139834269067072 spec.py:320] Evaluating on the training split.
I0914 14:08:10.335711 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 14:09:05.010938 139834269067072 spec.py:348] Evaluating on the test split.
I0914 14:09:06.102344 139834269067072 submission_runner.py:376] Time since start: 24077.13s, 	Step: 57457, 	{'train/accuracy': 0.6787109375, 'train/loss': 1.5602787562779017, 'validation/accuracy': 0.61126, 'validation/loss': 1.84603578125, 'validation/num_examples': 50000, 'test/accuracy': 0.4748, 'test/loss': 2.573128125, 'test/num_examples': 10000, 'score': 19892.948302984238, 'total_duration': 24077.130212783813, 'accumulated_submission_time': 19892.948302984238, 'accumulated_eval_time': 4081.2929215431213, 'accumulated_logging_time': 1.1879127025604248}
I0914 14:09:06.122094 139787151337216 logging_writer.py:48] [57457] accumulated_eval_time=4081.292922, accumulated_logging_time=1.187913, accumulated_submission_time=19892.948303, global_step=57457, preemption_count=0, score=19892.948303, test/accuracy=0.474800, test/loss=2.573128, test/num_examples=10000, total_duration=24077.130213, train/accuracy=0.678711, train/loss=1.560279, validation/accuracy=0.611260, validation/loss=1.846036, validation/num_examples=50000
I0914 14:09:21.813625 139787159729920 logging_writer.py:48] [57500] global_step=57500, grad_norm=0.290229, loss=3.304310
I0914 14:09:21.819591 139834269067072 pytorch_submission_base.py:86] 57500) loss = 3.304, grad_norm = 0.290
I0914 14:12:14.923667 139787151337216 logging_writer.py:48] [58000] global_step=58000, grad_norm=0.288803, loss=3.250185
I0914 14:12:14.928589 139834269067072 pytorch_submission_base.py:86] 58000) loss = 3.250, grad_norm = 0.289
I0914 14:15:06.356667 139787159729920 logging_writer.py:48] [58500] global_step=58500, grad_norm=0.287062, loss=3.348883
I0914 14:15:06.363625 139834269067072 pytorch_submission_base.py:86] 58500) loss = 3.349, grad_norm = 0.287
I0914 14:17:37.047587 139834269067072 spec.py:320] Evaluating on the training split.
I0914 14:18:19.528635 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 14:19:13.236490 139834269067072 spec.py:348] Evaluating on the test split.
I0914 14:19:14.326880 139834269067072 submission_runner.py:376] Time since start: 24685.35s, 	Step: 58931, 	{'train/accuracy': 0.7042410714285714, 'train/loss': 1.4288780056700414, 'validation/accuracy': 0.63958, 'validation/loss': 1.71388984375, 'validation/num_examples': 50000, 'test/accuracy': 0.5109, 'test/loss': 2.3777328125, 'test/num_examples': 10000, 'score': 20401.332453012466, 'total_duration': 24685.353937387466, 'accumulated_submission_time': 20401.332453012466, 'accumulated_eval_time': 4178.57156252861, 'accumulated_logging_time': 1.218522310256958}
I0914 14:19:14.348997 139787151337216 logging_writer.py:48] [58931] accumulated_eval_time=4178.571563, accumulated_logging_time=1.218522, accumulated_submission_time=20401.332453, global_step=58931, preemption_count=0, score=20401.332453, test/accuracy=0.510900, test/loss=2.377733, test/num_examples=10000, total_duration=24685.353937, train/accuracy=0.704241, train/loss=1.428878, validation/accuracy=0.639580, validation/loss=1.713890, validation/num_examples=50000
I0914 14:19:39.484643 139787159729920 logging_writer.py:48] [59000] global_step=59000, grad_norm=0.287376, loss=3.326472
I0914 14:19:39.489321 139834269067072 pytorch_submission_base.py:86] 59000) loss = 3.326, grad_norm = 0.287
I0914 14:22:34.758259 139787151337216 logging_writer.py:48] [59500] global_step=59500, grad_norm=0.291984, loss=3.286025
I0914 14:22:34.762573 139834269067072 pytorch_submission_base.py:86] 59500) loss = 3.286, grad_norm = 0.292
I0914 14:25:30.140552 139787159729920 logging_writer.py:48] [60000] global_step=60000, grad_norm=0.294745, loss=3.248723
I0914 14:25:30.147906 139834269067072 pytorch_submission_base.py:86] 60000) loss = 3.249, grad_norm = 0.295
I0914 14:27:45.222291 139834269067072 spec.py:320] Evaluating on the training split.
I0914 14:28:27.712725 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 14:29:21.331800 139834269067072 spec.py:348] Evaluating on the test split.
I0914 14:29:22.418884 139834269067072 submission_runner.py:376] Time since start: 25293.45s, 	Step: 60387, 	{'train/accuracy': 0.6683075573979592, 'train/loss': 1.6305068658322703, 'validation/accuracy': 0.6088, 'validation/loss': 1.89196734375, 'validation/num_examples': 50000, 'test/accuracy': 0.467, 'test/loss': 2.6293958984375, 'test/num_examples': 10000, 'score': 20909.727929115295, 'total_duration': 25293.446808576584, 'accumulated_submission_time': 20909.727929115295, 'accumulated_eval_time': 4275.768449544907, 'accumulated_logging_time': 1.2514212131500244}
I0914 14:29:22.438040 139787151337216 logging_writer.py:48] [60387] accumulated_eval_time=4275.768450, accumulated_logging_time=1.251421, accumulated_submission_time=20909.727929, global_step=60387, preemption_count=0, score=20909.727929, test/accuracy=0.467000, test/loss=2.629396, test/num_examples=10000, total_duration=25293.446809, train/accuracy=0.668308, train/loss=1.630507, validation/accuracy=0.608800, validation/loss=1.891967, validation/num_examples=50000
I0914 14:30:02.047605 139787159729920 logging_writer.py:48] [60500] global_step=60500, grad_norm=0.300091, loss=3.325499
I0914 14:30:02.053458 139834269067072 pytorch_submission_base.py:86] 60500) loss = 3.325, grad_norm = 0.300
I0914 14:32:53.276406 139787151337216 logging_writer.py:48] [61000] global_step=61000, grad_norm=0.289933, loss=3.230560
I0914 14:32:53.284664 139834269067072 pytorch_submission_base.py:86] 61000) loss = 3.231, grad_norm = 0.290
I0914 14:35:46.453707 139787159729920 logging_writer.py:48] [61500] global_step=61500, grad_norm=0.278681, loss=3.195855
I0914 14:35:46.458016 139834269067072 pytorch_submission_base.py:86] 61500) loss = 3.196, grad_norm = 0.279
I0914 14:37:53.587130 139834269067072 spec.py:320] Evaluating on the training split.
I0914 14:38:36.028490 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 14:39:30.006469 139834269067072 spec.py:348] Evaluating on the test split.
I0914 14:39:31.094798 139834269067072 submission_runner.py:376] Time since start: 25902.12s, 	Step: 61869, 	{'train/accuracy': 0.6826371173469388, 'train/loss': 1.527248460419324, 'validation/accuracy': 0.61796, 'validation/loss': 1.8052246875, 'validation/num_examples': 50000, 'test/accuracy': 0.4845, 'test/loss': 2.503884375, 'test/num_examples': 10000, 'score': 21418.337881565094, 'total_duration': 25902.122715234756, 'accumulated_submission_time': 21418.337881565094, 'accumulated_eval_time': 4373.27636551857, 'accumulated_logging_time': 1.2790701389312744}
I0914 14:39:31.114231 139787151337216 logging_writer.py:48] [61869] accumulated_eval_time=4373.276366, accumulated_logging_time=1.279070, accumulated_submission_time=21418.337882, global_step=61869, preemption_count=0, score=21418.337882, test/accuracy=0.484500, test/loss=2.503884, test/num_examples=10000, total_duration=25902.122715, train/accuracy=0.682637, train/loss=1.527248, validation/accuracy=0.617960, validation/loss=1.805225, validation/num_examples=50000
I0914 14:40:16.911015 139787159729920 logging_writer.py:48] [62000] global_step=62000, grad_norm=0.286554, loss=3.239037
I0914 14:40:16.916075 139834269067072 pytorch_submission_base.py:86] 62000) loss = 3.239, grad_norm = 0.287
I0914 14:43:08.330062 139787151337216 logging_writer.py:48] [62500] global_step=62500, grad_norm=0.290257, loss=3.287248
I0914 14:43:08.335116 139834269067072 pytorch_submission_base.py:86] 62500) loss = 3.287, grad_norm = 0.290
I0914 14:46:01.365833 139787159729920 logging_writer.py:48] [63000] global_step=63000, grad_norm=0.297123, loss=3.273275
I0914 14:46:01.370624 139834269067072 pytorch_submission_base.py:86] 63000) loss = 3.273, grad_norm = 0.297
I0914 14:48:02.307162 139834269067072 spec.py:320] Evaluating on the training split.
I0914 14:48:44.677868 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 14:49:38.298559 139834269067072 spec.py:348] Evaluating on the test split.
I0914 14:49:39.388215 139834269067072 submission_runner.py:376] Time since start: 26510.41s, 	Step: 63351, 	{'train/accuracy': 0.6777543048469388, 'train/loss': 1.5694650143993145, 'validation/accuracy': 0.61524, 'validation/loss': 1.841921875, 'validation/num_examples': 50000, 'test/accuracy': 0.4949, 'test/loss': 2.4961787109375, 'test/num_examples': 10000, 'score': 21926.92738676071, 'total_duration': 26510.414823055267, 'accumulated_submission_time': 21926.92738676071, 'accumulated_eval_time': 4470.356500387192, 'accumulated_logging_time': 1.3085238933563232}
I0914 14:49:39.408555 139787151337216 logging_writer.py:48] [63351] accumulated_eval_time=4470.356500, accumulated_logging_time=1.308524, accumulated_submission_time=21926.927387, global_step=63351, preemption_count=0, score=21926.927387, test/accuracy=0.494900, test/loss=2.496179, test/num_examples=10000, total_duration=26510.414823, train/accuracy=0.677754, train/loss=1.569465, validation/accuracy=0.615240, validation/loss=1.841922, validation/num_examples=50000
I0914 14:50:31.385250 139787159729920 logging_writer.py:48] [63500] global_step=63500, grad_norm=0.296226, loss=3.239049
I0914 14:50:31.393275 139834269067072 pytorch_submission_base.py:86] 63500) loss = 3.239, grad_norm = 0.296
I0914 14:53:24.478465 139787151337216 logging_writer.py:48] [64000] global_step=64000, grad_norm=0.295946, loss=3.210372
I0914 14:53:24.482846 139834269067072 pytorch_submission_base.py:86] 64000) loss = 3.210, grad_norm = 0.296
I0914 14:56:15.808520 139787159729920 logging_writer.py:48] [64500] global_step=64500, grad_norm=0.302680, loss=3.234808
I0914 14:56:15.812788 139834269067072 pytorch_submission_base.py:86] 64500) loss = 3.235, grad_norm = 0.303
I0914 14:58:10.518274 139834269067072 spec.py:320] Evaluating on the training split.
I0914 14:58:53.680921 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 14:59:47.389932 139834269067072 spec.py:348] Evaluating on the test split.
I0914 14:59:48.477433 139834269067072 submission_runner.py:376] Time since start: 27119.51s, 	Step: 64833, 	{'train/accuracy': 0.6993383290816326, 'train/loss': 1.4659992140166613, 'validation/accuracy': 0.63604, 'validation/loss': 1.73947234375, 'validation/num_examples': 50000, 'test/accuracy': 0.5055, 'test/loss': 2.4004876953125, 'test/num_examples': 10000, 'score': 22435.454740524292, 'total_duration': 27119.50536584854, 'accumulated_submission_time': 22435.454740524292, 'accumulated_eval_time': 4568.315970659256, 'accumulated_logging_time': 1.3373308181762695}
I0914 14:59:48.497271 139787151337216 logging_writer.py:48] [64833] accumulated_eval_time=4568.315971, accumulated_logging_time=1.337331, accumulated_submission_time=22435.454741, global_step=64833, preemption_count=0, score=22435.454741, test/accuracy=0.505500, test/loss=2.400488, test/num_examples=10000, total_duration=27119.505366, train/accuracy=0.699338, train/loss=1.465999, validation/accuracy=0.636040, validation/loss=1.739472, validation/num_examples=50000
I0914 15:00:46.594780 139787159729920 logging_writer.py:48] [65000] global_step=65000, grad_norm=0.308625, loss=3.314972
I0914 15:00:46.600008 139834269067072 pytorch_submission_base.py:86] 65000) loss = 3.315, grad_norm = 0.309
I0914 15:03:39.789974 139787151337216 logging_writer.py:48] [65500] global_step=65500, grad_norm=0.306038, loss=3.241114
I0914 15:03:39.795231 139834269067072 pytorch_submission_base.py:86] 65500) loss = 3.241, grad_norm = 0.306
I0914 15:06:31.174497 139787159729920 logging_writer.py:48] [66000] global_step=66000, grad_norm=0.304989, loss=3.309434
I0914 15:06:31.178807 139834269067072 pytorch_submission_base.py:86] 66000) loss = 3.309, grad_norm = 0.305
I0914 15:08:19.657294 139834269067072 spec.py:320] Evaluating on the training split.
I0914 15:09:02.365132 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 15:09:56.611224 139834269067072 spec.py:348] Evaluating on the test split.
I0914 15:09:57.700007 139834269067072 submission_runner.py:376] Time since start: 27728.73s, 	Step: 66310, 	{'train/accuracy': 0.6773955676020408, 'train/loss': 1.573835411850287, 'validation/accuracy': 0.61164, 'validation/loss': 1.86709125, 'validation/num_examples': 50000, 'test/accuracy': 0.469, 'test/loss': 2.6275625, 'test/num_examples': 10000, 'score': 22943.990533828735, 'total_duration': 27728.727930545807, 'accumulated_submission_time': 22943.990533828735, 'accumulated_eval_time': 4666.358915805817, 'accumulated_logging_time': 1.3680715560913086}
I0914 15:09:57.721055 139787151337216 logging_writer.py:48] [66310] accumulated_eval_time=4666.358916, accumulated_logging_time=1.368072, accumulated_submission_time=22943.990534, global_step=66310, preemption_count=0, score=22943.990534, test/accuracy=0.469000, test/loss=2.627562, test/num_examples=10000, total_duration=27728.727931, train/accuracy=0.677396, train/loss=1.573835, validation/accuracy=0.611640, validation/loss=1.867091, validation/num_examples=50000
I0914 15:11:03.771198 139787159729920 logging_writer.py:48] [66500] global_step=66500, grad_norm=0.303871, loss=3.215209
I0914 15:11:03.775508 139834269067072 pytorch_submission_base.py:86] 66500) loss = 3.215, grad_norm = 0.304
I0914 15:13:55.102207 139787151337216 logging_writer.py:48] [67000] global_step=67000, grad_norm=0.291644, loss=3.198730
I0914 15:13:55.106909 139834269067072 pytorch_submission_base.py:86] 67000) loss = 3.199, grad_norm = 0.292
I0914 15:16:46.549252 139787159729920 logging_writer.py:48] [67500] global_step=67500, grad_norm=0.306652, loss=3.291111
I0914 15:16:46.555468 139834269067072 pytorch_submission_base.py:86] 67500) loss = 3.291, grad_norm = 0.307
I0914 15:18:28.753829 139834269067072 spec.py:320] Evaluating on the training split.
I0914 15:19:11.287199 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 15:20:06.952485 139834269067072 spec.py:348] Evaluating on the test split.
I0914 15:20:08.036753 139834269067072 submission_runner.py:376] Time since start: 28339.06s, 	Step: 67792, 	{'train/accuracy': 0.7054767219387755, 'train/loss': 1.4393886644013074, 'validation/accuracy': 0.64126, 'validation/loss': 1.7216865625, 'validation/num_examples': 50000, 'test/accuracy': 0.5079, 'test/loss': 2.4018365234375, 'test/num_examples': 10000, 'score': 23452.494542121887, 'total_duration': 28339.064655780792, 'accumulated_submission_time': 23452.494542121887, 'accumulated_eval_time': 4765.642017841339, 'accumulated_logging_time': 1.399017095565796}
I0914 15:20:08.058276 139787151337216 logging_writer.py:48] [67792] accumulated_eval_time=4765.642018, accumulated_logging_time=1.399017, accumulated_submission_time=23452.494542, global_step=67792, preemption_count=0, score=23452.494542, test/accuracy=0.507900, test/loss=2.401837, test/num_examples=10000, total_duration=28339.064656, train/accuracy=0.705477, train/loss=1.439389, validation/accuracy=0.641260, validation/loss=1.721687, validation/num_examples=50000
I0914 15:21:20.205756 139787159729920 logging_writer.py:48] [68000] global_step=68000, grad_norm=0.297144, loss=3.206376
I0914 15:21:20.210085 139834269067072 pytorch_submission_base.py:86] 68000) loss = 3.206, grad_norm = 0.297
I0914 15:24:11.543437 139787151337216 logging_writer.py:48] [68500] global_step=68500, grad_norm=0.304350, loss=3.215360
I0914 15:24:11.548606 139834269067072 pytorch_submission_base.py:86] 68500) loss = 3.215, grad_norm = 0.304
I0914 15:27:04.539334 139787159729920 logging_writer.py:48] [69000] global_step=69000, grad_norm=0.302020, loss=3.232274
I0914 15:27:04.549921 139834269067072 pytorch_submission_base.py:86] 69000) loss = 3.232, grad_norm = 0.302
I0914 15:28:38.995388 139834269067072 spec.py:320] Evaluating on the training split.
I0914 15:29:21.386211 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 15:30:15.546419 139834269067072 spec.py:348] Evaluating on the test split.
I0914 15:30:16.635826 139834269067072 submission_runner.py:376] Time since start: 28947.66s, 	Step: 69274, 	{'train/accuracy': 0.6935188137755102, 'train/loss': 1.48189420116191, 'validation/accuracy': 0.62898, 'validation/loss': 1.76504390625, 'validation/num_examples': 50000, 'test/accuracy': 0.4917, 'test/loss': 2.4804552734375, 'test/num_examples': 10000, 'score': 23960.92461681366, 'total_duration': 28947.66376209259, 'accumulated_submission_time': 23960.92461681366, 'accumulated_eval_time': 4863.2828323841095, 'accumulated_logging_time': 1.429076910018921}
I0914 15:30:16.655251 139787151337216 logging_writer.py:48] [69274] accumulated_eval_time=4863.282832, accumulated_logging_time=1.429077, accumulated_submission_time=23960.924617, global_step=69274, preemption_count=0, score=23960.924617, test/accuracy=0.491700, test/loss=2.480455, test/num_examples=10000, total_duration=28947.663762, train/accuracy=0.693519, train/loss=1.481894, validation/accuracy=0.628980, validation/loss=1.765044, validation/num_examples=50000
I0914 15:31:35.025416 139787159729920 logging_writer.py:48] [69500] global_step=69500, grad_norm=0.309758, loss=3.231042
I0914 15:31:35.030551 139834269067072 pytorch_submission_base.py:86] 69500) loss = 3.231, grad_norm = 0.310
I0914 15:34:26.439823 139787151337216 logging_writer.py:48] [70000] global_step=70000, grad_norm=0.307049, loss=3.201785
I0914 15:34:26.448646 139834269067072 pytorch_submission_base.py:86] 70000) loss = 3.202, grad_norm = 0.307
I0914 15:37:19.734124 139787159729920 logging_writer.py:48] [70500] global_step=70500, grad_norm=0.314162, loss=3.182816
I0914 15:37:19.738482 139834269067072 pytorch_submission_base.py:86] 70500) loss = 3.183, grad_norm = 0.314
I0914 15:38:47.794734 139834269067072 spec.py:320] Evaluating on the training split.
I0914 15:39:30.152675 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 15:40:23.457855 139834269067072 spec.py:348] Evaluating on the test split.
I0914 15:40:24.547019 139834269067072 submission_runner.py:376] Time since start: 29555.57s, 	Step: 70755, 	{'train/accuracy': 0.7146444515306123, 'train/loss': 1.402004319794324, 'validation/accuracy': 0.64654, 'validation/loss': 1.70901375, 'validation/num_examples': 50000, 'test/accuracy': 0.503, 'test/loss': 2.4030125, 'test/num_examples': 10000, 'score': 24469.44401192665, 'total_duration': 29555.573780298233, 'accumulated_submission_time': 24469.44401192665, 'accumulated_eval_time': 4960.034102678299, 'accumulated_logging_time': 1.4584693908691406}
I0914 15:40:24.566626 139787151337216 logging_writer.py:48] [70755] accumulated_eval_time=4960.034103, accumulated_logging_time=1.458469, accumulated_submission_time=24469.444012, global_step=70755, preemption_count=0, score=24469.444012, test/accuracy=0.503000, test/loss=2.403012, test/num_examples=10000, total_duration=29555.573780, train/accuracy=0.714644, train/loss=1.402004, validation/accuracy=0.646540, validation/loss=1.709014, validation/num_examples=50000
I0914 15:41:49.423884 139787159729920 logging_writer.py:48] [71000] global_step=71000, grad_norm=0.309357, loss=3.232045
I0914 15:41:49.430051 139834269067072 pytorch_submission_base.py:86] 71000) loss = 3.232, grad_norm = 0.309
I0914 15:44:42.771490 139787151337216 logging_writer.py:48] [71500] global_step=71500, grad_norm=0.310526, loss=3.146484
I0914 15:44:42.776612 139834269067072 pytorch_submission_base.py:86] 71500) loss = 3.146, grad_norm = 0.311
I0914 15:47:34.211956 139787159729920 logging_writer.py:48] [72000] global_step=72000, grad_norm=0.315064, loss=3.215726
I0914 15:47:34.216134 139834269067072 pytorch_submission_base.py:86] 72000) loss = 3.216, grad_norm = 0.315
I0914 15:48:55.620993 139834269067072 spec.py:320] Evaluating on the training split.
I0914 15:49:38.422790 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 15:50:32.402760 139834269067072 spec.py:348] Evaluating on the test split.
I0914 15:50:33.488297 139834269067072 submission_runner.py:376] Time since start: 30164.52s, 	Step: 72236, 	{'train/accuracy': 0.6947544642857143, 'train/loss': 1.4518782946528221, 'validation/accuracy': 0.62866, 'validation/loss': 1.75276671875, 'validation/num_examples': 50000, 'test/accuracy': 0.5021, 'test/loss': 2.4525646484375, 'test/num_examples': 10000, 'score': 24977.93445801735, 'total_duration': 30164.51622581482, 'accumulated_submission_time': 24977.93445801735, 'accumulated_eval_time': 5057.901740312576, 'accumulated_logging_time': 1.4876902103424072}
I0914 15:50:33.509218 139787151337216 logging_writer.py:48] [72236] accumulated_eval_time=5057.901740, accumulated_logging_time=1.487690, accumulated_submission_time=24977.934458, global_step=72236, preemption_count=0, score=24977.934458, test/accuracy=0.502100, test/loss=2.452565, test/num_examples=10000, total_duration=30164.516226, train/accuracy=0.694754, train/loss=1.451878, validation/accuracy=0.628660, validation/loss=1.752767, validation/num_examples=50000
I0914 15:52:04.952564 139787159729920 logging_writer.py:48] [72500] global_step=72500, grad_norm=0.304664, loss=3.157250
I0914 15:52:04.957211 139834269067072 pytorch_submission_base.py:86] 72500) loss = 3.157, grad_norm = 0.305
I0914 15:54:58.019880 139787151337216 logging_writer.py:48] [73000] global_step=73000, grad_norm=0.316803, loss=3.228194
I0914 15:54:58.025218 139834269067072 pytorch_submission_base.py:86] 73000) loss = 3.228, grad_norm = 0.317
I0914 15:57:49.224758 139787159729920 logging_writer.py:48] [73500] global_step=73500, grad_norm=0.305221, loss=3.137129
I0914 15:57:49.229443 139834269067072 pytorch_submission_base.py:86] 73500) loss = 3.137, grad_norm = 0.305
I0914 15:59:04.489506 139834269067072 spec.py:320] Evaluating on the training split.
I0914 15:59:46.854517 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 16:00:40.723604 139834269067072 spec.py:348] Evaluating on the test split.
I0914 16:00:41.810774 139834269067072 submission_runner.py:376] Time since start: 30772.84s, 	Step: 73718, 	{'train/accuracy': 0.7057158801020408, 'train/loss': 1.3906905505121971, 'validation/accuracy': 0.6428, 'validation/loss': 1.68640703125, 'validation/num_examples': 50000, 'test/accuracy': 0.5091, 'test/loss': 2.357803125, 'test/num_examples': 10000, 'score': 25486.355399370193, 'total_duration': 30772.83870267868, 'accumulated_submission_time': 25486.355399370193, 'accumulated_eval_time': 5155.223183393478, 'accumulated_logging_time': 1.5201835632324219}
I0914 16:00:41.834208 139787151337216 logging_writer.py:48] [73718] accumulated_eval_time=5155.223183, accumulated_logging_time=1.520184, accumulated_submission_time=25486.355399, global_step=73718, preemption_count=0, score=25486.355399, test/accuracy=0.509100, test/loss=2.357803, test/num_examples=10000, total_duration=30772.838703, train/accuracy=0.705716, train/loss=1.390691, validation/accuracy=0.642800, validation/loss=1.686407, validation/num_examples=50000
I0914 16:02:20.993337 139787159729920 logging_writer.py:48] [74000] global_step=74000, grad_norm=0.308292, loss=3.060805
I0914 16:02:20.998469 139834269067072 pytorch_submission_base.py:86] 74000) loss = 3.061, grad_norm = 0.308
I0914 16:05:12.279434 139787151337216 logging_writer.py:48] [74500] global_step=74500, grad_norm=0.312571, loss=3.182261
I0914 16:05:12.287508 139834269067072 pytorch_submission_base.py:86] 74500) loss = 3.182, grad_norm = 0.313
I0914 16:08:03.591504 139787159729920 logging_writer.py:48] [75000] global_step=75000, grad_norm=0.301227, loss=3.198278
I0914 16:08:03.599364 139834269067072 pytorch_submission_base.py:86] 75000) loss = 3.198, grad_norm = 0.301
I0914 16:09:12.941768 139834269067072 spec.py:320] Evaluating on the training split.
I0914 16:09:55.710220 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 16:10:49.719233 139834269067072 spec.py:348] Evaluating on the test split.
I0914 16:10:50.807641 139834269067072 submission_runner.py:376] Time since start: 31381.83s, 	Step: 75196, 	{'train/accuracy': 0.7043606505102041, 'train/loss': 1.4372384207589286, 'validation/accuracy': 0.63842, 'validation/loss': 1.7249596875, 'validation/num_examples': 50000, 'test/accuracy': 0.5045, 'test/loss': 2.390778515625, 'test/num_examples': 10000, 'score': 25994.948875665665, 'total_duration': 31381.83448410034, 'accumulated_submission_time': 25994.948875665665, 'accumulated_eval_time': 5253.0885989665985, 'accumulated_logging_time': 1.55320405960083}
I0914 16:10:50.828659 139787151337216 logging_writer.py:48] [75196] accumulated_eval_time=5253.088599, accumulated_logging_time=1.553204, accumulated_submission_time=25994.948876, global_step=75196, preemption_count=0, score=25994.948876, test/accuracy=0.504500, test/loss=2.390779, test/num_examples=10000, total_duration=31381.834484, train/accuracy=0.704361, train/loss=1.437238, validation/accuracy=0.638420, validation/loss=1.724960, validation/num_examples=50000
I0914 16:12:35.848410 139787159729920 logging_writer.py:48] [75500] global_step=75500, grad_norm=0.314724, loss=3.180226
I0914 16:12:35.853728 139834269067072 pytorch_submission_base.py:86] 75500) loss = 3.180, grad_norm = 0.315
I0914 16:15:27.180972 139787151337216 logging_writer.py:48] [76000] global_step=76000, grad_norm=0.302615, loss=3.122433
I0914 16:15:27.185642 139834269067072 pytorch_submission_base.py:86] 76000) loss = 3.122, grad_norm = 0.303
I0914 16:18:20.382276 139787159729920 logging_writer.py:48] [76500] global_step=76500, grad_norm=0.313009, loss=3.125819
I0914 16:18:20.390434 139834269067072 pytorch_submission_base.py:86] 76500) loss = 3.126, grad_norm = 0.313
I0914 16:19:22.002010 139834269067072 spec.py:320] Evaluating on the training split.
I0914 16:20:04.567711 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 16:20:58.148610 139834269067072 spec.py:348] Evaluating on the test split.
I0914 16:20:59.235268 139834269067072 submission_runner.py:376] Time since start: 31990.26s, 	Step: 76678, 	{'train/accuracy': 0.7145248724489796, 'train/loss': 1.4213110476124042, 'validation/accuracy': 0.6466, 'validation/loss': 1.71978625, 'validation/num_examples': 50000, 'test/accuracy': 0.5117, 'test/loss': 2.4135134765625, 'test/num_examples': 10000, 'score': 26503.557284116745, 'total_duration': 31990.263199329376, 'accumulated_submission_time': 26503.557284116745, 'accumulated_eval_time': 5350.322155952454, 'accumulated_logging_time': 1.5856475830078125}
I0914 16:20:59.259824 139787151337216 logging_writer.py:48] [76678] accumulated_eval_time=5350.322156, accumulated_logging_time=1.585648, accumulated_submission_time=26503.557284, global_step=76678, preemption_count=0, score=26503.557284, test/accuracy=0.511700, test/loss=2.413513, test/num_examples=10000, total_duration=31990.263199, train/accuracy=0.714525, train/loss=1.421311, validation/accuracy=0.646600, validation/loss=1.719786, validation/num_examples=50000
I0914 16:22:50.434556 139787159729920 logging_writer.py:48] [77000] global_step=77000, grad_norm=0.308037, loss=3.202766
I0914 16:22:50.438654 139834269067072 pytorch_submission_base.py:86] 77000) loss = 3.203, grad_norm = 0.308
I0914 16:25:41.891589 139787151337216 logging_writer.py:48] [77500] global_step=77500, grad_norm=0.326355, loss=3.195731
I0914 16:25:41.897637 139834269067072 pytorch_submission_base.py:86] 77500) loss = 3.196, grad_norm = 0.326
I0914 16:28:35.160627 139787159729920 logging_writer.py:48] [78000] global_step=78000, grad_norm=0.314759, loss=3.121222
I0914 16:28:35.164963 139834269067072 pytorch_submission_base.py:86] 78000) loss = 3.121, grad_norm = 0.315
I0914 16:29:30.247117 139834269067072 spec.py:320] Evaluating on the training split.
I0914 16:30:12.836812 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 16:31:08.545097 139834269067072 spec.py:348] Evaluating on the test split.
I0914 16:31:09.630975 139834269067072 submission_runner.py:376] Time since start: 32600.66s, 	Step: 78159, 	{'train/accuracy': 0.7264827806122449, 'train/loss': 1.2979058246223294, 'validation/accuracy': 0.65736, 'validation/loss': 1.60734390625, 'validation/num_examples': 50000, 'test/accuracy': 0.5228, 'test/loss': 2.2689185546875, 'test/num_examples': 10000, 'score': 27012.015036582947, 'total_duration': 32600.658908843994, 'accumulated_submission_time': 27012.015036582947, 'accumulated_eval_time': 5449.706401348114, 'accumulated_logging_time': 1.6201927661895752}
I0914 16:31:09.650372 139787151337216 logging_writer.py:48] [78159] accumulated_eval_time=5449.706401, accumulated_logging_time=1.620193, accumulated_submission_time=27012.015037, global_step=78159, preemption_count=0, score=27012.015037, test/accuracy=0.522800, test/loss=2.268919, test/num_examples=10000, total_duration=32600.658909, train/accuracy=0.726483, train/loss=1.297906, validation/accuracy=0.657360, validation/loss=1.607344, validation/num_examples=50000
I0914 16:33:07.330200 139787159729920 logging_writer.py:48] [78500] global_step=78500, grad_norm=0.314475, loss=3.165444
I0914 16:33:07.334593 139834269067072 pytorch_submission_base.py:86] 78500) loss = 3.165, grad_norm = 0.314
I0914 16:36:00.362066 139787151337216 logging_writer.py:48] [79000] global_step=79000, grad_norm=0.319388, loss=3.131896
I0914 16:36:00.368459 139834269067072 pytorch_submission_base.py:86] 79000) loss = 3.132, grad_norm = 0.319
I0914 16:38:51.870790 139787159729920 logging_writer.py:48] [79500] global_step=79500, grad_norm=0.329005, loss=3.076829
I0914 16:38:51.875011 139834269067072 pytorch_submission_base.py:86] 79500) loss = 3.077, grad_norm = 0.329
I0914 16:39:40.795968 139834269067072 spec.py:320] Evaluating on the training split.
I0914 16:40:23.229498 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 16:41:17.084585 139834269067072 spec.py:348] Evaluating on the test split.
I0914 16:41:18.173320 139834269067072 submission_runner.py:376] Time since start: 33209.20s, 	Step: 79641, 	{'train/accuracy': 0.7106983418367347, 'train/loss': 1.3923855217135683, 'validation/accuracy': 0.64326, 'validation/loss': 1.702126875, 'validation/num_examples': 50000, 'test/accuracy': 0.5162, 'test/loss': 2.3826181640625, 'test/num_examples': 10000, 'score': 27520.58672785759, 'total_duration': 33209.19947099686, 'accumulated_submission_time': 27520.58672785759, 'accumulated_eval_time': 5547.082329750061, 'accumulated_logging_time': 1.6490223407745361}
I0914 16:41:18.192743 139787151337216 logging_writer.py:48] [79641] accumulated_eval_time=5547.082330, accumulated_logging_time=1.649022, accumulated_submission_time=27520.586728, global_step=79641, preemption_count=0, score=27520.586728, test/accuracy=0.516200, test/loss=2.382618, test/num_examples=10000, total_duration=33209.199471, train/accuracy=0.710698, train/loss=1.392386, validation/accuracy=0.643260, validation/loss=1.702127, validation/num_examples=50000
I0914 16:43:22.284746 139787159729920 logging_writer.py:48] [80000] global_step=80000, grad_norm=0.332583, loss=3.215024
I0914 16:43:22.289330 139834269067072 pytorch_submission_base.py:86] 80000) loss = 3.215, grad_norm = 0.333
I0914 16:46:15.384247 139787151337216 logging_writer.py:48] [80500] global_step=80500, grad_norm=0.323025, loss=3.072646
I0914 16:46:15.390101 139834269067072 pytorch_submission_base.py:86] 80500) loss = 3.073, grad_norm = 0.323
I0914 16:49:06.740210 139787159729920 logging_writer.py:48] [81000] global_step=81000, grad_norm=0.330195, loss=3.175111
I0914 16:49:06.746712 139834269067072 pytorch_submission_base.py:86] 81000) loss = 3.175, grad_norm = 0.330
I0914 16:49:49.143305 139834269067072 spec.py:320] Evaluating on the training split.
I0914 16:50:31.889252 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 16:51:25.620477 139834269067072 spec.py:348] Evaluating on the test split.
I0914 16:51:26.704828 139834269067072 submission_runner.py:376] Time since start: 33817.73s, 	Step: 81122, 	{'train/accuracy': 0.7074896364795918, 'train/loss': 1.4563586176658163, 'validation/accuracy': 0.6397, 'validation/loss': 1.75911375, 'validation/num_examples': 50000, 'test/accuracy': 0.5033, 'test/loss': 2.47553203125, 'test/num_examples': 10000, 'score': 28028.944851875305, 'total_duration': 33817.73270916939, 'accumulated_submission_time': 28028.944851875305, 'accumulated_eval_time': 5644.644223213196, 'accumulated_logging_time': 1.6792192459106445}
I0914 16:51:26.727930 139787151337216 logging_writer.py:48] [81122] accumulated_eval_time=5644.644223, accumulated_logging_time=1.679219, accumulated_submission_time=28028.944852, global_step=81122, preemption_count=0, score=28028.944852, test/accuracy=0.503300, test/loss=2.475532, test/num_examples=10000, total_duration=33817.732709, train/accuracy=0.707490, train/loss=1.456359, validation/accuracy=0.639700, validation/loss=1.759114, validation/num_examples=50000
I0914 16:53:38.750566 139787159729920 logging_writer.py:48] [81500] global_step=81500, grad_norm=0.322658, loss=3.069897
I0914 16:53:38.754802 139834269067072 pytorch_submission_base.py:86] 81500) loss = 3.070, grad_norm = 0.323
I0914 16:56:30.142954 139787151337216 logging_writer.py:48] [82000] global_step=82000, grad_norm=0.331181, loss=3.138559
I0914 16:56:30.147420 139834269067072 pytorch_submission_base.py:86] 82000) loss = 3.139, grad_norm = 0.331
I0914 16:59:21.543123 139787159729920 logging_writer.py:48] [82500] global_step=82500, grad_norm=0.317267, loss=3.090100
I0914 16:59:21.548156 139834269067072 pytorch_submission_base.py:86] 82500) loss = 3.090, grad_norm = 0.317
I0914 16:59:57.642020 139834269067072 spec.py:320] Evaluating on the training split.
I0914 17:00:40.407562 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 17:01:34.790306 139834269067072 spec.py:348] Evaluating on the test split.
I0914 17:01:35.877183 139834269067072 submission_runner.py:376] Time since start: 34426.91s, 	Step: 82599, 	{'train/accuracy': 0.7328404017857143, 'train/loss': 1.352513838787468, 'validation/accuracy': 0.65754, 'validation/loss': 1.67375796875, 'validation/num_examples': 50000, 'test/accuracy': 0.5229, 'test/loss': 2.3591572265625, 'test/num_examples': 10000, 'score': 28537.31317448616, 'total_duration': 34426.90508675575, 'accumulated_submission_time': 28537.31317448616, 'accumulated_eval_time': 5742.879645586014, 'accumulated_logging_time': 1.7108471393585205}
I0914 17:01:35.898768 139787151337216 logging_writer.py:48] [82599] accumulated_eval_time=5742.879646, accumulated_logging_time=1.710847, accumulated_submission_time=28537.313174, global_step=82599, preemption_count=0, score=28537.313174, test/accuracy=0.522900, test/loss=2.359157, test/num_examples=10000, total_duration=34426.905087, train/accuracy=0.732840, train/loss=1.352514, validation/accuracy=0.657540, validation/loss=1.673758, validation/num_examples=50000
I0914 17:03:54.256688 139787159729920 logging_writer.py:48] [83000] global_step=83000, grad_norm=0.334517, loss=3.098158
I0914 17:03:54.261031 139834269067072 pytorch_submission_base.py:86] 83000) loss = 3.098, grad_norm = 0.335
I0914 17:06:45.673369 139787151337216 logging_writer.py:48] [83500] global_step=83500, grad_norm=0.337750, loss=3.140438
I0914 17:06:45.678514 139834269067072 pytorch_submission_base.py:86] 83500) loss = 3.140, grad_norm = 0.338
I0914 17:09:38.463682 139787159729920 logging_writer.py:48] [84000] global_step=84000, grad_norm=0.319906, loss=3.099514
I0914 17:09:38.468540 139834269067072 pytorch_submission_base.py:86] 84000) loss = 3.100, grad_norm = 0.320
I0914 17:10:06.854638 139834269067072 spec.py:320] Evaluating on the training split.
I0914 17:10:49.321109 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 17:11:43.812680 139834269067072 spec.py:348] Evaluating on the test split.
I0914 17:11:44.899070 139834269067072 submission_runner.py:376] Time since start: 35035.93s, 	Step: 84081, 	{'train/accuracy': 0.7400550063775511, 'train/loss': 1.283956800188337, 'validation/accuracy': 0.66616, 'validation/loss': 1.60633515625, 'validation/num_examples': 50000, 'test/accuracy': 0.5298, 'test/loss': 2.28925078125, 'test/num_examples': 10000, 'score': 29045.749613761902, 'total_duration': 35035.92700266838, 'accumulated_submission_time': 29045.749613761902, 'accumulated_eval_time': 5840.924386978149, 'accumulated_logging_time': 1.7425103187561035}
I0914 17:11:44.923044 139787151337216 logging_writer.py:48] [84081] accumulated_eval_time=5840.924387, accumulated_logging_time=1.742510, accumulated_submission_time=29045.749614, global_step=84081, preemption_count=0, score=29045.749614, test/accuracy=0.529800, test/loss=2.289251, test/num_examples=10000, total_duration=35035.927003, train/accuracy=0.740055, train/loss=1.283957, validation/accuracy=0.666160, validation/loss=1.606335, validation/num_examples=50000
I0914 17:14:09.407571 139787159729920 logging_writer.py:48] [84500] global_step=84500, grad_norm=0.328522, loss=3.171967
I0914 17:14:09.413015 139834269067072 pytorch_submission_base.py:86] 84500) loss = 3.172, grad_norm = 0.329
I0914 17:17:00.772531 139787151337216 logging_writer.py:48] [85000] global_step=85000, grad_norm=0.325459, loss=3.102192
I0914 17:17:00.778517 139834269067072 pytorch_submission_base.py:86] 85000) loss = 3.102, grad_norm = 0.325
I0914 17:19:53.630611 139787159729920 logging_writer.py:48] [85500] global_step=85500, grad_norm=0.350696, loss=3.071250
I0914 17:19:53.634694 139834269067072 pytorch_submission_base.py:86] 85500) loss = 3.071, grad_norm = 0.351
I0914 17:20:16.071143 139834269067072 spec.py:320] Evaluating on the training split.
I0914 17:20:58.512753 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 17:21:52.568246 139834269067072 spec.py:348] Evaluating on the test split.
I0914 17:21:53.657214 139834269067072 submission_runner.py:376] Time since start: 35644.69s, 	Step: 85564, 	{'train/accuracy': 0.7429249043367347, 'train/loss': 1.327070275131537, 'validation/accuracy': 0.66402, 'validation/loss': 1.66108, 'validation/num_examples': 50000, 'test/accuracy': 0.5498, 'test/loss': 2.2545830078125, 'test/num_examples': 10000, 'score': 29554.410472154617, 'total_duration': 35644.68516111374, 'accumulated_submission_time': 29554.410472154617, 'accumulated_eval_time': 5938.510777711868, 'accumulated_logging_time': 1.7750868797302246}
I0914 17:21:53.678990 139787151337216 logging_writer.py:48] [85564] accumulated_eval_time=5938.510778, accumulated_logging_time=1.775087, accumulated_submission_time=29554.410472, global_step=85564, preemption_count=0, score=29554.410472, test/accuracy=0.549800, test/loss=2.254583, test/num_examples=10000, total_duration=35644.685161, train/accuracy=0.742925, train/loss=1.327070, validation/accuracy=0.664020, validation/loss=1.661080, validation/num_examples=50000
I0914 17:24:24.018628 139787159729920 logging_writer.py:48] [86000] global_step=86000, grad_norm=0.327291, loss=3.085625
I0914 17:24:24.025618 139834269067072 pytorch_submission_base.py:86] 86000) loss = 3.086, grad_norm = 0.327
I0914 17:27:17.434527 139787151337216 logging_writer.py:48] [86500] global_step=86500, grad_norm=0.341145, loss=3.126628
I0914 17:27:17.438818 139834269067072 pytorch_submission_base.py:86] 86500) loss = 3.127, grad_norm = 0.341
I0914 17:30:08.896995 139787159729920 logging_writer.py:48] [87000] global_step=87000, grad_norm=0.338564, loss=3.096733
I0914 17:30:08.902589 139834269067072 pytorch_submission_base.py:86] 87000) loss = 3.097, grad_norm = 0.339
I0914 17:30:24.992059 139834269067072 spec.py:320] Evaluating on the training split.
I0914 17:31:07.612712 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 17:32:02.373950 139834269067072 spec.py:348] Evaluating on the test split.
I0914 17:32:03.463783 139834269067072 submission_runner.py:376] Time since start: 36254.49s, 	Step: 87045, 	{'train/accuracy': 0.7329599808673469, 'train/loss': 1.3165259847835618, 'validation/accuracy': 0.66028, 'validation/loss': 1.64611875, 'validation/num_examples': 50000, 'test/accuracy': 0.5176, 'test/loss': 2.33102109375, 'test/num_examples': 10000, 'score': 30063.101960897446, 'total_duration': 36254.49019789696, 'accumulated_submission_time': 30063.101960897446, 'accumulated_eval_time': 6036.981278419495, 'accumulated_logging_time': 1.8059322834014893}
I0914 17:32:03.486551 139787151337216 logging_writer.py:48] [87045] accumulated_eval_time=6036.981278, accumulated_logging_time=1.805932, accumulated_submission_time=30063.101961, global_step=87045, preemption_count=0, score=30063.101961, test/accuracy=0.517600, test/loss=2.331021, test/num_examples=10000, total_duration=36254.490198, train/accuracy=0.732960, train/loss=1.316526, validation/accuracy=0.660280, validation/loss=1.646119, validation/num_examples=50000
I0914 17:34:40.353236 139787159729920 logging_writer.py:48] [87500] global_step=87500, grad_norm=0.348547, loss=3.070837
I0914 17:34:40.357548 139834269067072 pytorch_submission_base.py:86] 87500) loss = 3.071, grad_norm = 0.349
I0914 17:37:33.315024 139787151337216 logging_writer.py:48] [88000] global_step=88000, grad_norm=0.342234, loss=3.119226
I0914 17:37:33.323563 139834269067072 pytorch_submission_base.py:86] 88000) loss = 3.119, grad_norm = 0.342
I0914 17:40:24.695236 139787159729920 logging_writer.py:48] [88500] global_step=88500, grad_norm=0.342350, loss=3.078450
I0914 17:40:24.699414 139834269067072 pytorch_submission_base.py:86] 88500) loss = 3.078, grad_norm = 0.342
I0914 17:40:34.549237 139834269067072 spec.py:320] Evaluating on the training split.
I0914 17:41:17.204772 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 17:42:11.119866 139834269067072 spec.py:348] Evaluating on the test split.
I0914 17:42:12.207752 139834269067072 submission_runner.py:376] Time since start: 36863.24s, 	Step: 88527, 	{'train/accuracy': 0.7481863839285714, 'train/loss': 1.232894975311902, 'validation/accuracy': 0.67182, 'validation/loss': 1.55924671875, 'validation/num_examples': 50000, 'test/accuracy': 0.5324, 'test/loss': 2.2488544921875, 'test/num_examples': 10000, 'score': 30571.56608223915, 'total_duration': 36863.23563814163, 'accumulated_submission_time': 30571.56608223915, 'accumulated_eval_time': 6134.640651464462, 'accumulated_logging_time': 1.841278314590454}
I0914 17:42:12.230952 139787151337216 logging_writer.py:48] [88527] accumulated_eval_time=6134.640651, accumulated_logging_time=1.841278, accumulated_submission_time=30571.566082, global_step=88527, preemption_count=0, score=30571.566082, test/accuracy=0.532400, test/loss=2.248854, test/num_examples=10000, total_duration=36863.235638, train/accuracy=0.748186, train/loss=1.232895, validation/accuracy=0.671820, validation/loss=1.559247, validation/num_examples=50000
I0914 17:44:56.856548 139787159729920 logging_writer.py:48] [89000] global_step=89000, grad_norm=0.332242, loss=2.980632
I0914 17:44:56.862898 139834269067072 pytorch_submission_base.py:86] 89000) loss = 2.981, grad_norm = 0.332
I0914 17:47:48.308341 139787151337216 logging_writer.py:48] [89500] global_step=89500, grad_norm=0.337449, loss=3.007010
I0914 17:47:48.313927 139834269067072 pytorch_submission_base.py:86] 89500) loss = 3.007, grad_norm = 0.337
I0914 17:50:39.663906 139787159729920 logging_writer.py:48] [90000] global_step=90000, grad_norm=0.355933, loss=3.130774
I0914 17:50:39.669396 139834269067072 pytorch_submission_base.py:86] 90000) loss = 3.131, grad_norm = 0.356
I0914 17:50:43.353467 139834269067072 spec.py:320] Evaluating on the training split.
I0914 17:51:26.075442 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 17:52:20.484075 139834269067072 spec.py:348] Evaluating on the test split.
I0914 17:52:21.570734 139834269067072 submission_runner.py:376] Time since start: 37472.60s, 	Step: 90009, 	{'train/accuracy': 0.7430644132653061, 'train/loss': 1.2530925517179528, 'validation/accuracy': 0.66584, 'validation/loss': 1.584465625, 'validation/num_examples': 50000, 'test/accuracy': 0.5344, 'test/loss': 2.243312890625, 'test/num_examples': 10000, 'score': 31080.117062568665, 'total_duration': 37472.59866666794, 'accumulated_submission_time': 31080.117062568665, 'accumulated_eval_time': 6232.858266115189, 'accumulated_logging_time': 1.8729259967803955}
I0914 17:52:21.591434 139787151337216 logging_writer.py:48] [90009] accumulated_eval_time=6232.858266, accumulated_logging_time=1.872926, accumulated_submission_time=31080.117063, global_step=90009, preemption_count=0, score=31080.117063, test/accuracy=0.534400, test/loss=2.243313, test/num_examples=10000, total_duration=37472.598667, train/accuracy=0.743064, train/loss=1.253093, validation/accuracy=0.665840, validation/loss=1.584466, validation/num_examples=50000
I0914 17:55:12.615648 139787159729920 logging_writer.py:48] [90500] global_step=90500, grad_norm=0.358392, loss=3.102494
I0914 17:55:12.621219 139834269067072 pytorch_submission_base.py:86] 90500) loss = 3.102, grad_norm = 0.358
I0914 17:58:04.025061 139787151337216 logging_writer.py:48] [91000] global_step=91000, grad_norm=0.344264, loss=3.031043
I0914 17:58:04.030676 139834269067072 pytorch_submission_base.py:86] 91000) loss = 3.031, grad_norm = 0.344
I0914 18:00:52.705719 139834269067072 spec.py:320] Evaluating on the training split.
I0914 18:01:35.409214 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 18:02:30.636928 139834269067072 spec.py:348] Evaluating on the test split.
I0914 18:02:31.726068 139834269067072 submission_runner.py:376] Time since start: 38082.75s, 	Step: 91486, 	{'train/accuracy': 0.7598852040816326, 'train/loss': 1.213304480727838, 'validation/accuracy': 0.67926, 'validation/loss': 1.55280046875, 'validation/num_examples': 50000, 'test/accuracy': 0.5413, 'test/loss': 2.2443806640625, 'test/num_examples': 10000, 'score': 31588.729876756668, 'total_duration': 38082.752670288086, 'accumulated_submission_time': 31588.729876756668, 'accumulated_eval_time': 6331.877485513687, 'accumulated_logging_time': 1.9020140171051025}
I0914 18:02:31.749471 139787159729920 logging_writer.py:48] [91486] accumulated_eval_time=6331.877486, accumulated_logging_time=1.902014, accumulated_submission_time=31588.729877, global_step=91486, preemption_count=0, score=31588.729877, test/accuracy=0.541300, test/loss=2.244381, test/num_examples=10000, total_duration=38082.752670, train/accuracy=0.759885, train/loss=1.213304, validation/accuracy=0.679260, validation/loss=1.552800, validation/num_examples=50000
I0914 18:02:37.546065 139787151337216 logging_writer.py:48] [91500] global_step=91500, grad_norm=0.349640, loss=3.030278
I0914 18:02:37.550714 139834269067072 pytorch_submission_base.py:86] 91500) loss = 3.030, grad_norm = 0.350
I0914 18:05:28.894601 139787159729920 logging_writer.py:48] [92000] global_step=92000, grad_norm=0.346097, loss=3.011575
I0914 18:05:28.898860 139834269067072 pytorch_submission_base.py:86] 92000) loss = 3.012, grad_norm = 0.346
I0914 18:08:20.331356 139787151337216 logging_writer.py:48] [92500] global_step=92500, grad_norm=0.353309, loss=3.036253
I0914 18:08:20.337772 139834269067072 pytorch_submission_base.py:86] 92500) loss = 3.036, grad_norm = 0.353
I0914 18:11:02.729968 139834269067072 spec.py:320] Evaluating on the training split.
I0914 18:11:45.254446 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 18:12:39.078630 139834269067072 spec.py:348] Evaluating on the test split.
I0914 18:12:40.167511 139834269067072 submission_runner.py:376] Time since start: 38691.20s, 	Step: 92967, 	{'train/accuracy': 0.7352120535714286, 'train/loss': 1.3095102115553252, 'validation/accuracy': 0.66134, 'validation/loss': 1.63147203125, 'validation/num_examples': 50000, 'test/accuracy': 0.5272, 'test/loss': 2.321180859375, 'test/num_examples': 10000, 'score': 32097.136334896088, 'total_duration': 38691.19542336464, 'accumulated_submission_time': 32097.136334896088, 'accumulated_eval_time': 6429.315256118774, 'accumulated_logging_time': 1.9345448017120361}
I0914 18:12:40.189688 139787159729920 logging_writer.py:48] [92967] accumulated_eval_time=6429.315256, accumulated_logging_time=1.934545, accumulated_submission_time=32097.136335, global_step=92967, preemption_count=0, score=32097.136335, test/accuracy=0.527200, test/loss=2.321181, test/num_examples=10000, total_duration=38691.195423, train/accuracy=0.735212, train/loss=1.309510, validation/accuracy=0.661340, validation/loss=1.631472, validation/num_examples=50000
I0914 18:12:52.438959 139787151337216 logging_writer.py:48] [93000] global_step=93000, grad_norm=0.372555, loss=3.152447
I0914 18:12:52.442998 139834269067072 pytorch_submission_base.py:86] 93000) loss = 3.152, grad_norm = 0.373
I0914 18:15:43.708276 139787159729920 logging_writer.py:48] [93500] global_step=93500, grad_norm=0.356070, loss=3.072604
I0914 18:15:43.715644 139834269067072 pytorch_submission_base.py:86] 93500) loss = 3.073, grad_norm = 0.356
I0914 18:18:36.794726 139787151337216 logging_writer.py:48] [94000] global_step=94000, grad_norm=0.344647, loss=2.969317
I0914 18:18:36.801730 139834269067072 pytorch_submission_base.py:86] 94000) loss = 2.969, grad_norm = 0.345
I0914 18:21:11.182597 139834269067072 spec.py:320] Evaluating on the training split.
I0914 18:21:53.920461 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 18:22:47.857384 139834269067072 spec.py:348] Evaluating on the test split.
I0914 18:22:48.944181 139834269067072 submission_runner.py:376] Time since start: 39299.97s, 	Step: 94449, 	{'train/accuracy': 0.7669005102040817, 'train/loss': 1.1832038723692602, 'validation/accuracy': 0.68684, 'validation/loss': 1.51809984375, 'validation/num_examples': 50000, 'test/accuracy': 0.551, 'test/loss': 2.2011921875, 'test/num_examples': 10000, 'score': 32605.614151716232, 'total_duration': 39299.97207760811, 'accumulated_submission_time': 32605.614151716232, 'accumulated_eval_time': 6527.077110528946, 'accumulated_logging_time': 1.9651179313659668}
I0914 18:22:48.964557 139787159729920 logging_writer.py:48] [94449] accumulated_eval_time=6527.077111, accumulated_logging_time=1.965118, accumulated_submission_time=32605.614152, global_step=94449, preemption_count=0, score=32605.614152, test/accuracy=0.551000, test/loss=2.201192, test/num_examples=10000, total_duration=39299.972078, train/accuracy=0.766901, train/loss=1.183204, validation/accuracy=0.686840, validation/loss=1.518100, validation/num_examples=50000
I0914 18:23:07.402406 139787151337216 logging_writer.py:48] [94500] global_step=94500, grad_norm=0.360506, loss=3.064410
I0914 18:23:07.406440 139834269067072 pytorch_submission_base.py:86] 94500) loss = 3.064, grad_norm = 0.361
I0914 18:25:58.766693 139787159729920 logging_writer.py:48] [95000] global_step=95000, grad_norm=0.352671, loss=3.009802
I0914 18:25:58.771364 139834269067072 pytorch_submission_base.py:86] 95000) loss = 3.010, grad_norm = 0.353
I0914 18:28:51.793922 139787151337216 logging_writer.py:48] [95500] global_step=95500, grad_norm=0.360453, loss=2.970893
I0914 18:28:51.800293 139834269067072 pytorch_submission_base.py:86] 95500) loss = 2.971, grad_norm = 0.360
I0914 18:31:20.062325 139834269067072 spec.py:320] Evaluating on the training split.
I0914 18:32:03.253016 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 18:32:57.221446 139834269067072 spec.py:348] Evaluating on the test split.
I0914 18:32:58.312333 139834269067072 submission_runner.py:376] Time since start: 39909.34s, 	Step: 95931, 	{'train/accuracy': 0.7582708864795918, 'train/loss': 1.1810301177355709, 'validation/accuracy': 0.67742, 'validation/loss': 1.5409053125, 'validation/num_examples': 50000, 'test/accuracy': 0.5357, 'test/loss': 2.230510546875, 'test/num_examples': 10000, 'score': 33114.18256998062, 'total_duration': 39909.33941435814, 'accumulated_submission_time': 33114.18256998062, 'accumulated_eval_time': 6625.326530456543, 'accumulated_logging_time': 1.9954414367675781}
I0914 18:32:58.336198 139787159729920 logging_writer.py:48] [95931] accumulated_eval_time=6625.326530, accumulated_logging_time=1.995441, accumulated_submission_time=33114.182570, global_step=95931, preemption_count=0, score=33114.182570, test/accuracy=0.535700, test/loss=2.230511, test/num_examples=10000, total_duration=39909.339414, train/accuracy=0.758271, train/loss=1.181030, validation/accuracy=0.677420, validation/loss=1.540905, validation/num_examples=50000
I0914 18:33:22.945210 139787151337216 logging_writer.py:48] [96000] global_step=96000, grad_norm=0.351188, loss=2.996777
I0914 18:33:22.949817 139834269067072 pytorch_submission_base.py:86] 96000) loss = 2.997, grad_norm = 0.351
I0914 18:36:15.763160 139787159729920 logging_writer.py:48] [96500] global_step=96500, grad_norm=0.362181, loss=3.046114
I0914 18:36:15.768596 139834269067072 pytorch_submission_base.py:86] 96500) loss = 3.046, grad_norm = 0.362
I0914 18:39:07.101666 139787151337216 logging_writer.py:48] [97000] global_step=97000, grad_norm=0.375497, loss=3.037463
I0914 18:39:07.106534 139834269067072 pytorch_submission_base.py:86] 97000) loss = 3.037, grad_norm = 0.375
I0914 18:41:29.268412 139834269067072 spec.py:320] Evaluating on the training split.
I0914 18:42:11.695742 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 18:43:05.685271 139834269067072 spec.py:348] Evaluating on the test split.
I0914 18:43:06.772712 139834269067072 submission_runner.py:376] Time since start: 40517.80s, 	Step: 97413, 	{'train/accuracy': 0.7436822385204082, 'train/loss': 1.2725300691565689, 'validation/accuracy': 0.66398, 'validation/loss': 1.6241840625, 'validation/num_examples': 50000, 'test/accuracy': 0.5254, 'test/loss': 2.3220599609375, 'test/num_examples': 10000, 'score': 33622.597786188126, 'total_duration': 40517.80060458183, 'accumulated_submission_time': 33622.597786188126, 'accumulated_eval_time': 6722.831171274185, 'accumulated_logging_time': 2.0279529094696045}
I0914 18:43:06.793329 139787159729920 logging_writer.py:48] [97413] accumulated_eval_time=6722.831171, accumulated_logging_time=2.027953, accumulated_submission_time=33622.597786, global_step=97413, preemption_count=0, score=33622.597786, test/accuracy=0.525400, test/loss=2.322060, test/num_examples=10000, total_duration=40517.800605, train/accuracy=0.743682, train/loss=1.272530, validation/accuracy=0.663980, validation/loss=1.624184, validation/num_examples=50000
I0914 18:43:37.510882 139787151337216 logging_writer.py:48] [97500] global_step=97500, grad_norm=0.372449, loss=3.021079
I0914 18:43:37.515503 139834269067072 pytorch_submission_base.py:86] 97500) loss = 3.021, grad_norm = 0.372
I0914 18:46:30.692341 139787159729920 logging_writer.py:48] [98000] global_step=98000, grad_norm=0.356966, loss=2.961576
I0914 18:46:30.696848 139834269067072 pytorch_submission_base.py:86] 98000) loss = 2.962, grad_norm = 0.357
I0914 18:49:22.043400 139787151337216 logging_writer.py:48] [98500] global_step=98500, grad_norm=0.372803, loss=3.000097
I0914 18:49:22.052606 139834269067072 pytorch_submission_base.py:86] 98500) loss = 3.000, grad_norm = 0.373
I0914 18:51:37.737173 139834269067072 spec.py:320] Evaluating on the training split.
I0914 18:52:20.512402 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 18:53:14.963156 139834269067072 spec.py:348] Evaluating on the test split.
I0914 18:53:16.054244 139834269067072 submission_runner.py:376] Time since start: 41127.08s, 	Step: 98889, 	{'train/accuracy': 0.7581513073979592, 'train/loss': 1.1633832503338248, 'validation/accuracy': 0.67548, 'validation/loss': 1.5260815625, 'validation/num_examples': 50000, 'test/accuracy': 0.538, 'test/loss': 2.21258046875, 'test/num_examples': 10000, 'score': 34131.01906657219, 'total_duration': 41127.082184791565, 'accumulated_submission_time': 34131.01906657219, 'accumulated_eval_time': 6821.148615121841, 'accumulated_logging_time': 2.058075189590454}
I0914 18:53:16.078472 139787159729920 logging_writer.py:48] [98889] accumulated_eval_time=6821.148615, accumulated_logging_time=2.058075, accumulated_submission_time=34131.019067, global_step=98889, preemption_count=0, score=34131.019067, test/accuracy=0.538000, test/loss=2.212580, test/num_examples=10000, total_duration=41127.082185, train/accuracy=0.758151, train/loss=1.163383, validation/accuracy=0.675480, validation/loss=1.526082, validation/num_examples=50000
I0914 18:53:55.048779 139787151337216 logging_writer.py:48] [99000] global_step=99000, grad_norm=0.357746, loss=2.936014
I0914 18:53:55.052656 139834269067072 pytorch_submission_base.py:86] 99000) loss = 2.936, grad_norm = 0.358
I0914 18:56:46.380777 139787159729920 logging_writer.py:48] [99500] global_step=99500, grad_norm=0.364251, loss=2.941751
I0914 18:56:46.385598 139834269067072 pytorch_submission_base.py:86] 99500) loss = 2.942, grad_norm = 0.364
I0914 18:59:37.712558 139787151337216 logging_writer.py:48] [100000] global_step=100000, grad_norm=0.364246, loss=3.042624
I0914 18:59:37.718644 139834269067072 pytorch_submission_base.py:86] 100000) loss = 3.043, grad_norm = 0.364
I0914 19:01:46.983876 139834269067072 spec.py:320] Evaluating on the training split.
I0914 19:02:29.477975 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 19:03:23.342643 139834269067072 spec.py:348] Evaluating on the test split.
I0914 19:03:24.430258 139834269067072 submission_runner.py:376] Time since start: 41735.46s, 	Step: 100370, 	{'train/accuracy': 0.7875876913265306, 'train/loss': 1.0914313647211815, 'validation/accuracy': 0.7016, 'validation/loss': 1.44902921875, 'validation/num_examples': 50000, 'test/accuracy': 0.5652, 'test/loss': 2.0911990234375, 'test/num_examples': 10000, 'score': 34639.38508939743, 'total_duration': 41735.45819926262, 'accumulated_submission_time': 34639.38508939743, 'accumulated_eval_time': 6918.595190048218, 'accumulated_logging_time': 2.091195821762085}
I0914 19:03:24.451718 139787159729920 logging_writer.py:48] [100370] accumulated_eval_time=6918.595190, accumulated_logging_time=2.091196, accumulated_submission_time=34639.385089, global_step=100370, preemption_count=0, score=34639.385089, test/accuracy=0.565200, test/loss=2.091199, test/num_examples=10000, total_duration=41735.458199, train/accuracy=0.787588, train/loss=1.091431, validation/accuracy=0.701600, validation/loss=1.449029, validation/num_examples=50000
I0914 19:04:09.892661 139787151337216 logging_writer.py:48] [100500] global_step=100500, grad_norm=0.368857, loss=2.947764
I0914 19:04:09.896964 139834269067072 pytorch_submission_base.py:86] 100500) loss = 2.948, grad_norm = 0.369
I0914 19:07:01.242234 139787159729920 logging_writer.py:48] [101000] global_step=101000, grad_norm=0.374464, loss=3.051386
I0914 19:07:01.247109 139834269067072 pytorch_submission_base.py:86] 101000) loss = 3.051, grad_norm = 0.374
I0914 19:09:54.253871 139787151337216 logging_writer.py:48] [101500] global_step=101500, grad_norm=0.377475, loss=2.878622
I0914 19:09:54.259321 139834269067072 pytorch_submission_base.py:86] 101500) loss = 2.879, grad_norm = 0.377
I0914 19:11:55.547129 139834269067072 spec.py:320] Evaluating on the training split.
I0914 19:12:38.882504 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 19:13:32.648957 139834269067072 spec.py:348] Evaluating on the test split.
I0914 19:13:33.737982 139834269067072 submission_runner.py:376] Time since start: 42344.77s, 	Step: 101852, 	{'train/accuracy': 0.7821867028061225, 'train/loss': 1.0890828346719548, 'validation/accuracy': 0.69464, 'validation/loss': 1.458545, 'validation/num_examples': 50000, 'test/accuracy': 0.5636, 'test/loss': 2.101974609375, 'test/num_examples': 10000, 'score': 35147.94639635086, 'total_duration': 42344.76590061188, 'accumulated_submission_time': 35147.94639635086, 'accumulated_eval_time': 7016.786299467087, 'accumulated_logging_time': 2.1225504875183105}
I0914 19:13:33.759692 139787159729920 logging_writer.py:48] [101852] accumulated_eval_time=7016.786299, accumulated_logging_time=2.122550, accumulated_submission_time=35147.946396, global_step=101852, preemption_count=0, score=35147.946396, test/accuracy=0.563600, test/loss=2.101975, test/num_examples=10000, total_duration=42344.765901, train/accuracy=0.782187, train/loss=1.089083, validation/accuracy=0.694640, validation/loss=1.458545, validation/num_examples=50000
I0914 19:14:25.428905 139787151337216 logging_writer.py:48] [102000] global_step=102000, grad_norm=0.389754, loss=3.027412
I0914 19:14:25.432689 139834269067072 pytorch_submission_base.py:86] 102000) loss = 3.027, grad_norm = 0.390
I0914 19:17:16.791857 139787159729920 logging_writer.py:48] [102500] global_step=102500, grad_norm=0.386686, loss=2.977622
I0914 19:17:16.798120 139834269067072 pytorch_submission_base.py:86] 102500) loss = 2.978, grad_norm = 0.387
I0914 19:20:09.811542 139787151337216 logging_writer.py:48] [103000] global_step=103000, grad_norm=0.388618, loss=2.910116
I0914 19:20:09.816004 139834269067072 pytorch_submission_base.py:86] 103000) loss = 2.910, grad_norm = 0.389
I0914 19:22:04.853041 139834269067072 spec.py:320] Evaluating on the training split.
I0914 19:22:47.839422 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 19:23:42.161731 139834269067072 spec.py:348] Evaluating on the test split.
I0914 19:23:43.252559 139834269067072 submission_runner.py:376] Time since start: 42954.28s, 	Step: 103334, 	{'train/accuracy': 0.7948222257653061, 'train/loss': 1.0333144518793846, 'validation/accuracy': 0.70436, 'validation/loss': 1.41006375, 'validation/num_examples': 50000, 'test/accuracy': 0.5675, 'test/loss': 2.0741484375, 'test/num_examples': 10000, 'score': 35656.47154355049, 'total_duration': 42954.27954530716, 'accumulated_submission_time': 35656.47154355049, 'accumulated_eval_time': 7115.185396194458, 'accumulated_logging_time': 2.1527843475341797}
I0914 19:23:43.275576 139787159729920 logging_writer.py:48] [103334] accumulated_eval_time=7115.185396, accumulated_logging_time=2.152784, accumulated_submission_time=35656.471544, global_step=103334, preemption_count=0, score=35656.471544, test/accuracy=0.567500, test/loss=2.074148, test/num_examples=10000, total_duration=42954.279545, train/accuracy=0.794822, train/loss=1.033314, validation/accuracy=0.704360, validation/loss=1.410064, validation/num_examples=50000
I0914 19:24:41.134020 139787151337216 logging_writer.py:48] [103500] global_step=103500, grad_norm=0.397718, loss=2.999105
I0914 19:24:41.138283 139834269067072 pytorch_submission_base.py:86] 103500) loss = 2.999, grad_norm = 0.398
I0914 19:27:34.307258 139787159729920 logging_writer.py:48] [104000] global_step=104000, grad_norm=0.388639, loss=2.909772
I0914 19:27:34.312615 139834269067072 pytorch_submission_base.py:86] 104000) loss = 2.910, grad_norm = 0.389
I0914 19:30:25.857372 139787151337216 logging_writer.py:48] [104500] global_step=104500, grad_norm=0.396207, loss=2.950694
I0914 19:30:25.861385 139834269067072 pytorch_submission_base.py:86] 104500) loss = 2.951, grad_norm = 0.396
I0914 19:32:14.441678 139834269067072 spec.py:320] Evaluating on the training split.
I0914 19:32:57.476103 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 19:33:51.384102 139834269067072 spec.py:348] Evaluating on the test split.
I0914 19:33:52.473763 139834269067072 submission_runner.py:376] Time since start: 43563.50s, 	Step: 104815, 	{'train/accuracy': 0.7972935267857143, 'train/loss': 1.0010174342564173, 'validation/accuracy': 0.70666, 'validation/loss': 1.388778125, 'validation/num_examples': 50000, 'test/accuracy': 0.578, 'test/loss': 2.04301953125, 'test/num_examples': 10000, 'score': 36165.05555438995, 'total_duration': 43563.50169682503, 'accumulated_submission_time': 36165.05555438995, 'accumulated_eval_time': 7213.2179255485535, 'accumulated_logging_time': 2.184286594390869}
I0914 19:33:52.498402 139787159729920 logging_writer.py:48] [104815] accumulated_eval_time=7213.217926, accumulated_logging_time=2.184287, accumulated_submission_time=36165.055554, global_step=104815, preemption_count=0, score=36165.055554, test/accuracy=0.578000, test/loss=2.043020, test/num_examples=10000, total_duration=43563.501697, train/accuracy=0.797294, train/loss=1.001017, validation/accuracy=0.706660, validation/loss=1.388778, validation/num_examples=50000
I0914 19:34:56.868074 139787151337216 logging_writer.py:48] [105000] global_step=105000, grad_norm=0.384872, loss=2.930108
I0914 19:34:56.873285 139834269067072 pytorch_submission_base.py:86] 105000) loss = 2.930, grad_norm = 0.385
I0914 19:37:50.043677 139787159729920 logging_writer.py:48] [105500] global_step=105500, grad_norm=0.395797, loss=2.935337
I0914 19:37:50.048975 139834269067072 pytorch_submission_base.py:86] 105500) loss = 2.935, grad_norm = 0.396
I0914 19:40:41.434288 139787151337216 logging_writer.py:48] [106000] global_step=106000, grad_norm=0.397564, loss=2.912009
I0914 19:40:41.442650 139834269067072 pytorch_submission_base.py:86] 106000) loss = 2.912, grad_norm = 0.398
I0914 19:42:23.516138 139834269067072 spec.py:320] Evaluating on the training split.
I0914 19:43:06.627559 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 19:44:00.856049 139834269067072 spec.py:348] Evaluating on the test split.
I0914 19:44:01.946014 139834269067072 submission_runner.py:376] Time since start: 44172.97s, 	Step: 106296, 	{'train/accuracy': 0.7924904336734694, 'train/loss': 1.0111893634406888, 'validation/accuracy': 0.70196, 'validation/loss': 1.40027671875, 'validation/num_examples': 50000, 'test/accuracy': 0.5795, 'test/loss': 2.04285234375, 'test/num_examples': 10000, 'score': 36673.52972269058, 'total_duration': 44172.97391963005, 'accumulated_submission_time': 36673.52972269058, 'accumulated_eval_time': 7311.6480884552, 'accumulated_logging_time': 2.217869997024536}
I0914 19:44:01.972184 139787159729920 logging_writer.py:48] [106296] accumulated_eval_time=7311.648088, accumulated_logging_time=2.217870, accumulated_submission_time=36673.529723, global_step=106296, preemption_count=0, score=36673.529723, test/accuracy=0.579500, test/loss=2.042852, test/num_examples=10000, total_duration=44172.973920, train/accuracy=0.792490, train/loss=1.011189, validation/accuracy=0.701960, validation/loss=1.400277, validation/num_examples=50000
I0914 19:45:14.518413 139787151337216 logging_writer.py:48] [106500] global_step=106500, grad_norm=0.393688, loss=2.816414
I0914 19:45:14.523256 139834269067072 pytorch_submission_base.py:86] 106500) loss = 2.816, grad_norm = 0.394
I0914 19:48:05.958586 139787159729920 logging_writer.py:48] [107000] global_step=107000, grad_norm=0.406510, loss=2.879370
I0914 19:48:05.966290 139834269067072 pytorch_submission_base.py:86] 107000) loss = 2.879, grad_norm = 0.407
I0914 19:50:57.403446 139787151337216 logging_writer.py:48] [107500] global_step=107500, grad_norm=0.423246, loss=2.942085
I0914 19:50:57.408316 139834269067072 pytorch_submission_base.py:86] 107500) loss = 2.942, grad_norm = 0.423
I0914 19:52:33.095079 139834269067072 spec.py:320] Evaluating on the training split.
I0914 19:53:15.982260 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 19:54:10.308996 139834269067072 spec.py:348] Evaluating on the test split.
I0914 19:54:11.398649 139834269067072 submission_runner.py:376] Time since start: 44782.43s, 	Step: 107773, 	{'train/accuracy': 0.8122807716836735, 'train/loss': 0.9815306371572067, 'validation/accuracy': 0.71502, 'validation/loss': 1.38583625, 'validation/num_examples': 50000, 'test/accuracy': 0.5692, 'test/loss': 2.0839748046875, 'test/num_examples': 10000, 'score': 37182.13071346283, 'total_duration': 44782.42561340332, 'accumulated_submission_time': 37182.13071346283, 'accumulated_eval_time': 7409.950815677643, 'accumulated_logging_time': 2.2533953189849854}
I0914 19:54:11.419865 139787159729920 logging_writer.py:48] [107773] accumulated_eval_time=7409.950816, accumulated_logging_time=2.253395, accumulated_submission_time=37182.130713, global_step=107773, preemption_count=0, score=37182.130713, test/accuracy=0.569200, test/loss=2.083975, test/num_examples=10000, total_duration=44782.425613, train/accuracy=0.812281, train/loss=0.981531, validation/accuracy=0.715020, validation/loss=1.385836, validation/num_examples=50000
I0914 19:55:30.094202 139787151337216 logging_writer.py:48] [108000] global_step=108000, grad_norm=0.417663, loss=2.915021
I0914 19:55:30.098101 139834269067072 pytorch_submission_base.py:86] 108000) loss = 2.915, grad_norm = 0.418
I0914 19:58:21.398123 139787159729920 logging_writer.py:48] [108500] global_step=108500, grad_norm=0.417368, loss=2.851797
I0914 19:58:21.402513 139834269067072 pytorch_submission_base.py:86] 108500) loss = 2.852, grad_norm = 0.417
I0914 20:01:14.485734 139787151337216 logging_writer.py:48] [109000] global_step=109000, grad_norm=0.418741, loss=2.916224
I0914 20:01:14.491086 139834269067072 pytorch_submission_base.py:86] 109000) loss = 2.916, grad_norm = 0.419
I0914 20:02:42.513766 139834269067072 spec.py:320] Evaluating on the training split.
I0914 20:03:25.298377 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 20:04:19.951165 139834269067072 spec.py:348] Evaluating on the test split.
I0914 20:04:21.038949 139834269067072 submission_runner.py:376] Time since start: 45392.07s, 	Step: 109255, 	{'train/accuracy': 0.8193957270408163, 'train/loss': 0.9411143088827327, 'validation/accuracy': 0.71856, 'validation/loss': 1.3496496875, 'validation/num_examples': 50000, 'test/accuracy': 0.5894, 'test/loss': 1.9864841796875, 'test/num_examples': 10000, 'score': 37690.652612924576, 'total_duration': 45392.066886901855, 'accumulated_submission_time': 37690.652612924576, 'accumulated_eval_time': 7508.476343870163, 'accumulated_logging_time': 2.2839419841766357}
I0914 20:04:21.061419 139787159729920 logging_writer.py:48] [109255] accumulated_eval_time=7508.476344, accumulated_logging_time=2.283942, accumulated_submission_time=37690.652613, global_step=109255, preemption_count=0, score=37690.652613, test/accuracy=0.589400, test/loss=1.986484, test/num_examples=10000, total_duration=45392.066887, train/accuracy=0.819396, train/loss=0.941114, validation/accuracy=0.718560, validation/loss=1.349650, validation/num_examples=50000
I0914 20:05:45.823995 139787151337216 logging_writer.py:48] [109500] global_step=109500, grad_norm=0.421463, loss=2.851605
I0914 20:05:45.831302 139834269067072 pytorch_submission_base.py:86] 109500) loss = 2.852, grad_norm = 0.421
I0914 20:08:37.225262 139787159729920 logging_writer.py:48] [110000] global_step=110000, grad_norm=0.436104, loss=2.963765
I0914 20:08:37.233104 139834269067072 pytorch_submission_base.py:86] 110000) loss = 2.964, grad_norm = 0.436
I0914 20:11:30.335928 139787151337216 logging_writer.py:48] [110500] global_step=110500, grad_norm=0.433742, loss=2.864681
I0914 20:11:30.340950 139834269067072 pytorch_submission_base.py:86] 110500) loss = 2.865, grad_norm = 0.434
I0914 20:12:52.151545 139834269067072 spec.py:320] Evaluating on the training split.
I0914 20:13:34.750994 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 20:14:30.319238 139834269067072 spec.py:348] Evaluating on the test split.
I0914 20:14:31.409513 139834269067072 submission_runner.py:376] Time since start: 46002.44s, 	Step: 110737, 	{'train/accuracy': 0.8084941007653061, 'train/loss': 0.9723913231674506, 'validation/accuracy': 0.70758, 'validation/loss': 1.398665625, 'validation/num_examples': 50000, 'test/accuracy': 0.5765, 'test/loss': 2.070410546875, 'test/num_examples': 10000, 'score': 38199.252210855484, 'total_duration': 46002.43743228912, 'accumulated_submission_time': 38199.252210855484, 'accumulated_eval_time': 7607.734683036804, 'accumulated_logging_time': 2.316112756729126}
I0914 20:14:31.432865 139787159729920 logging_writer.py:48] [110737] accumulated_eval_time=7607.734683, accumulated_logging_time=2.316113, accumulated_submission_time=38199.252211, global_step=110737, preemption_count=0, score=38199.252211, test/accuracy=0.576500, test/loss=2.070411, test/num_examples=10000, total_duration=46002.437432, train/accuracy=0.808494, train/loss=0.972391, validation/accuracy=0.707580, validation/loss=1.398666, validation/num_examples=50000
I0914 20:16:02.453124 139787151337216 logging_writer.py:48] [111000] global_step=111000, grad_norm=0.423495, loss=2.874311
I0914 20:16:02.460821 139834269067072 pytorch_submission_base.py:86] 111000) loss = 2.874, grad_norm = 0.423
I0914 20:18:55.421026 139787159729920 logging_writer.py:48] [111500] global_step=111500, grad_norm=0.453374, loss=2.854005
I0914 20:18:55.426416 139834269067072 pytorch_submission_base.py:86] 111500) loss = 2.854, grad_norm = 0.453
I0914 20:21:46.835421 139787151337216 logging_writer.py:48] [112000] global_step=112000, grad_norm=0.418720, loss=2.785252
I0914 20:21:46.839671 139834269067072 pytorch_submission_base.py:86] 112000) loss = 2.785, grad_norm = 0.419
I0914 20:23:02.400285 139834269067072 spec.py:320] Evaluating on the training split.
I0914 20:23:44.866847 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 20:24:40.052643 139834269067072 spec.py:348] Evaluating on the test split.
I0914 20:24:41.140391 139834269067072 submission_runner.py:376] Time since start: 46612.17s, 	Step: 112219, 	{'train/accuracy': 0.8267299107142857, 'train/loss': 0.9142226394341917, 'validation/accuracy': 0.7207, 'validation/loss': 1.3367284375, 'validation/num_examples': 50000, 'test/accuracy': 0.5769, 'test/loss': 2.0445177734375, 'test/num_examples': 10000, 'score': 38707.75090289116, 'total_duration': 46612.16760802269, 'accumulated_submission_time': 38707.75090289116, 'accumulated_eval_time': 7706.474244356155, 'accumulated_logging_time': 2.3480684757232666}
I0914 20:24:41.165194 139787159729920 logging_writer.py:48] [112219] accumulated_eval_time=7706.474244, accumulated_logging_time=2.348068, accumulated_submission_time=38707.750903, global_step=112219, preemption_count=0, score=38707.750903, test/accuracy=0.576900, test/loss=2.044518, test/num_examples=10000, total_duration=46612.167608, train/accuracy=0.826730, train/loss=0.914223, validation/accuracy=0.720700, validation/loss=1.336728, validation/num_examples=50000
I0914 20:26:18.410359 139787151337216 logging_writer.py:48] [112500] global_step=112500, grad_norm=0.421808, loss=2.833001
I0914 20:26:18.415970 139834269067072 pytorch_submission_base.py:86] 112500) loss = 2.833, grad_norm = 0.422
I0914 20:29:11.470206 139787159729920 logging_writer.py:48] [113000] global_step=113000, grad_norm=0.416186, loss=2.765698
I0914 20:29:11.474358 139834269067072 pytorch_submission_base.py:86] 113000) loss = 2.766, grad_norm = 0.416
I0914 20:32:02.829535 139787151337216 logging_writer.py:48] [113500] global_step=113500, grad_norm=0.445035, loss=2.812653
I0914 20:32:02.836049 139834269067072 pytorch_submission_base.py:86] 113500) loss = 2.813, grad_norm = 0.445
I0914 20:33:12.236043 139834269067072 spec.py:320] Evaluating on the training split.
I0914 20:33:54.666469 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 20:34:49.240138 139834269067072 spec.py:348] Evaluating on the test split.
I0914 20:34:50.330716 139834269067072 submission_runner.py:376] Time since start: 47221.36s, 	Step: 113700, 	{'train/accuracy': 0.8360570790816326, 'train/loss': 0.837928227015904, 'validation/accuracy': 0.7285, 'validation/loss': 1.271760703125, 'validation/num_examples': 50000, 'test/accuracy': 0.5909, 'test/loss': 1.9631546875, 'test/num_examples': 10000, 'score': 39216.24927473068, 'total_duration': 47221.358583927155, 'accumulated_submission_time': 39216.24927473068, 'accumulated_eval_time': 7804.569121599197, 'accumulated_logging_time': 2.381819248199463}
I0914 20:34:50.353433 139787159729920 logging_writer.py:48] [113700] accumulated_eval_time=7804.569122, accumulated_logging_time=2.381819, accumulated_submission_time=39216.249275, global_step=113700, preemption_count=0, score=39216.249275, test/accuracy=0.590900, test/loss=1.963155, test/num_examples=10000, total_duration=47221.358584, train/accuracy=0.836057, train/loss=0.837928, validation/accuracy=0.728500, validation/loss=1.271761, validation/num_examples=50000
I0914 20:36:35.718975 139787151337216 logging_writer.py:48] [114000] global_step=114000, grad_norm=0.437471, loss=2.810910
I0914 20:36:35.723409 139834269067072 pytorch_submission_base.py:86] 114000) loss = 2.811, grad_norm = 0.437
I0914 20:39:27.029489 139787159729920 logging_writer.py:48] [114500] global_step=114500, grad_norm=0.441869, loss=2.738065
I0914 20:39:27.036185 139834269067072 pytorch_submission_base.py:86] 114500) loss = 2.738, grad_norm = 0.442
I0914 20:42:18.310997 139787151337216 logging_writer.py:48] [115000] global_step=115000, grad_norm=0.448438, loss=2.816972
I0914 20:42:18.316012 139834269067072 pytorch_submission_base.py:86] 115000) loss = 2.817, grad_norm = 0.448
I0914 20:43:21.370840 139834269067072 spec.py:320] Evaluating on the training split.
I0914 20:44:04.085547 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 20:44:58.633609 139834269067072 spec.py:348] Evaluating on the test split.
I0914 20:44:59.721622 139834269067072 submission_runner.py:376] Time since start: 47830.75s, 	Step: 115178, 	{'train/accuracy': 0.8425542091836735, 'train/loss': 0.8308460469148597, 'validation/accuracy': 0.73246, 'validation/loss': 1.285781484375, 'validation/num_examples': 50000, 'test/accuracy': 0.5984, 'test/loss': 1.959775390625, 'test/num_examples': 10000, 'score': 39724.714393138885, 'total_duration': 47830.74952673912, 'accumulated_submission_time': 39724.714393138885, 'accumulated_eval_time': 7902.920233249664, 'accumulated_logging_time': 2.413299083709717}
I0914 20:44:59.746762 139787159729920 logging_writer.py:48] [115178] accumulated_eval_time=7902.920233, accumulated_logging_time=2.413299, accumulated_submission_time=39724.714393, global_step=115178, preemption_count=0, score=39724.714393, test/accuracy=0.598400, test/loss=1.959775, test/num_examples=10000, total_duration=47830.749527, train/accuracy=0.842554, train/loss=0.830846, validation/accuracy=0.732460, validation/loss=1.285781, validation/num_examples=50000
I0914 20:46:50.885204 139787151337216 logging_writer.py:48] [115500] global_step=115500, grad_norm=0.433091, loss=2.704751
I0914 20:46:50.890750 139834269067072 pytorch_submission_base.py:86] 115500) loss = 2.705, grad_norm = 0.433
I0914 20:49:42.227645 139787159729920 logging_writer.py:48] [116000] global_step=116000, grad_norm=0.462645, loss=2.768703
I0914 20:49:42.232064 139834269067072 pytorch_submission_base.py:86] 116000) loss = 2.769, grad_norm = 0.463
I0914 20:52:35.142963 139787151337216 logging_writer.py:48] [116500] global_step=116500, grad_norm=0.460212, loss=2.759240
I0914 20:52:35.148957 139834269067072 pytorch_submission_base.py:86] 116500) loss = 2.759, grad_norm = 0.460
I0914 20:53:30.873249 139834269067072 spec.py:320] Evaluating on the training split.
I0914 20:54:13.502790 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 20:55:07.384168 139834269067072 spec.py:348] Evaluating on the test split.
I0914 20:55:08.473494 139834269067072 submission_runner.py:376] Time since start: 48439.50s, 	Step: 116661, 	{'train/accuracy': 0.8415776466836735, 'train/loss': 0.8580317594567124, 'validation/accuracy': 0.72896, 'validation/loss': 1.32139328125, 'validation/num_examples': 50000, 'test/accuracy': 0.5967, 'test/loss': 1.976644140625, 'test/num_examples': 10000, 'score': 40233.29963469505, 'total_duration': 48439.501412153244, 'accumulated_submission_time': 40233.29963469505, 'accumulated_eval_time': 8000.520615816116, 'accumulated_logging_time': 2.4474093914031982}
I0914 20:55:08.497651 139787159729920 logging_writer.py:48] [116661] accumulated_eval_time=8000.520616, accumulated_logging_time=2.447409, accumulated_submission_time=40233.299635, global_step=116661, preemption_count=0, score=40233.299635, test/accuracy=0.596700, test/loss=1.976644, test/num_examples=10000, total_duration=48439.501412, train/accuracy=0.841578, train/loss=0.858032, validation/accuracy=0.728960, validation/loss=1.321393, validation/num_examples=50000
I0914 20:57:05.484044 139787151337216 logging_writer.py:48] [117000] global_step=117000, grad_norm=0.452853, loss=2.711356
I0914 20:57:05.488466 139834269067072 pytorch_submission_base.py:86] 117000) loss = 2.711, grad_norm = 0.453
I0914 20:59:56.881073 139787159729920 logging_writer.py:48] [117500] global_step=117500, grad_norm=0.471423, loss=2.738347
I0914 20:59:56.886447 139834269067072 pytorch_submission_base.py:86] 117500) loss = 2.738, grad_norm = 0.471
I0914 21:02:49.930026 139787151337216 logging_writer.py:48] [118000] global_step=118000, grad_norm=0.460493, loss=2.732842
I0914 21:02:49.935406 139834269067072 pytorch_submission_base.py:86] 118000) loss = 2.733, grad_norm = 0.460
I0914 21:03:39.546334 139834269067072 spec.py:320] Evaluating on the training split.
I0914 21:04:22.297377 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 21:05:16.483396 139834269067072 spec.py:348] Evaluating on the test split.
I0914 21:05:17.572371 139834269067072 submission_runner.py:376] Time since start: 49048.60s, 	Step: 118143, 	{'train/accuracy': 0.8604113520408163, 'train/loss': 0.7499905021823182, 'validation/accuracy': 0.74354, 'validation/loss': 1.225137578125, 'validation/num_examples': 50000, 'test/accuracy': 0.6119, 'test/loss': 1.8889380859375, 'test/num_examples': 10000, 'score': 40741.797372341156, 'total_duration': 49048.60029196739, 'accumulated_submission_time': 40741.797372341156, 'accumulated_eval_time': 8098.546944141388, 'accumulated_logging_time': 2.480238199234009}
I0914 21:05:17.595930 139787159729920 logging_writer.py:48] [118143] accumulated_eval_time=8098.546944, accumulated_logging_time=2.480238, accumulated_submission_time=40741.797372, global_step=118143, preemption_count=0, score=40741.797372, test/accuracy=0.611900, test/loss=1.888938, test/num_examples=10000, total_duration=49048.600292, train/accuracy=0.860411, train/loss=0.749991, validation/accuracy=0.743540, validation/loss=1.225138, validation/num_examples=50000
I0914 21:07:20.706877 139787151337216 logging_writer.py:48] [118500] global_step=118500, grad_norm=0.470777, loss=2.739211
I0914 21:07:20.711390 139834269067072 pytorch_submission_base.py:86] 118500) loss = 2.739, grad_norm = 0.471
I0914 21:10:13.789969 139787159729920 logging_writer.py:48] [119000] global_step=119000, grad_norm=0.469477, loss=2.684893
I0914 21:10:13.795920 139834269067072 pytorch_submission_base.py:86] 119000) loss = 2.685, grad_norm = 0.469
I0914 21:13:05.177823 139787151337216 logging_writer.py:48] [119500] global_step=119500, grad_norm=0.480818, loss=2.703733
I0914 21:13:05.182605 139834269067072 pytorch_submission_base.py:86] 119500) loss = 2.704, grad_norm = 0.481
I0914 21:13:48.624691 139834269067072 spec.py:320] Evaluating on the training split.
I0914 21:14:31.347031 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 21:15:24.850241 139834269067072 spec.py:348] Evaluating on the test split.
I0914 21:15:25.938364 139834269067072 submission_runner.py:376] Time since start: 49656.97s, 	Step: 119625, 	{'train/accuracy': 0.8644371811224489, 'train/loss': 0.7429367376833546, 'validation/accuracy': 0.74206, 'validation/loss': 1.2332734375, 'validation/num_examples': 50000, 'test/accuracy': 0.6023, 'test/loss': 1.9187119140625, 'test/num_examples': 10000, 'score': 41250.24692440033, 'total_duration': 49656.96551537514, 'accumulated_submission_time': 41250.24692440033, 'accumulated_eval_time': 8195.860199213028, 'accumulated_logging_time': 2.5120468139648438}
I0914 21:15:25.959782 139787159729920 logging_writer.py:48] [119625] accumulated_eval_time=8195.860199, accumulated_logging_time=2.512047, accumulated_submission_time=41250.246924, global_step=119625, preemption_count=0, score=41250.246924, test/accuracy=0.602300, test/loss=1.918712, test/num_examples=10000, total_duration=49656.965515, train/accuracy=0.864437, train/loss=0.742937, validation/accuracy=0.742060, validation/loss=1.233273, validation/num_examples=50000
I0914 21:17:35.313782 139787151337216 logging_writer.py:48] [120000] global_step=120000, grad_norm=0.479772, loss=2.674855
I0914 21:17:35.322649 139834269067072 pytorch_submission_base.py:86] 120000) loss = 2.675, grad_norm = 0.480
I0914 21:20:28.334797 139787159729920 logging_writer.py:48] [120500] global_step=120500, grad_norm=0.460093, loss=2.575885
I0914 21:20:28.338812 139834269067072 pytorch_submission_base.py:86] 120500) loss = 2.576, grad_norm = 0.460
I0914 21:23:19.596575 139787151337216 logging_writer.py:48] [121000] global_step=121000, grad_norm=0.467401, loss=2.556349
I0914 21:23:19.601755 139834269067072 pytorch_submission_base.py:86] 121000) loss = 2.556, grad_norm = 0.467
I0914 21:23:57.199326 139834269067072 spec.py:320] Evaluating on the training split.
I0914 21:24:40.476641 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 21:25:35.123431 139834269067072 spec.py:348] Evaluating on the test split.
I0914 21:25:36.211843 139834269067072 submission_runner.py:376] Time since start: 50267.24s, 	Step: 121108, 	{'train/accuracy': 0.8769331951530612, 'train/loss': 0.7009070260184151, 'validation/accuracy': 0.7511, 'validation/loss': 1.19952140625, 'validation/num_examples': 50000, 'test/accuracy': 0.6162, 'test/loss': 1.850906640625, 'test/num_examples': 10000, 'score': 41758.93402338028, 'total_duration': 50267.23975610733, 'accumulated_submission_time': 41758.93402338028, 'accumulated_eval_time': 8294.873284816742, 'accumulated_logging_time': 2.5419437885284424}
I0914 21:25:36.239096 139787159729920 logging_writer.py:48] [121108] accumulated_eval_time=8294.873285, accumulated_logging_time=2.541944, accumulated_submission_time=41758.934023, global_step=121108, preemption_count=0, score=41758.934023, test/accuracy=0.616200, test/loss=1.850907, test/num_examples=10000, total_duration=50267.239756, train/accuracy=0.876933, train/loss=0.700907, validation/accuracy=0.751100, validation/loss=1.199521, validation/num_examples=50000
I0914 21:27:52.992057 139787151337216 logging_writer.py:48] [121500] global_step=121500, grad_norm=0.486509, loss=2.623842
I0914 21:27:52.996449 139834269067072 pytorch_submission_base.py:86] 121500) loss = 2.624, grad_norm = 0.487
I0914 21:30:44.302701 139787159729920 logging_writer.py:48] [122000] global_step=122000, grad_norm=0.479504, loss=2.652092
I0914 21:30:44.307651 139834269067072 pytorch_submission_base.py:86] 122000) loss = 2.652, grad_norm = 0.480
I0914 21:33:35.606531 139787151337216 logging_writer.py:48] [122500] global_step=122500, grad_norm=0.517442, loss=2.746680
I0914 21:33:35.612809 139834269067072 pytorch_submission_base.py:86] 122500) loss = 2.747, grad_norm = 0.517
I0914 21:34:07.307805 139834269067072 spec.py:320] Evaluating on the training split.
I0914 21:34:50.109827 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 21:35:44.736858 139834269067072 spec.py:348] Evaluating on the test split.
I0914 21:35:45.824017 139834269067072 submission_runner.py:376] Time since start: 50876.85s, 	Step: 122591, 	{'train/accuracy': 0.8881138392857143, 'train/loss': 0.6610058375767299, 'validation/accuracy': 0.76014, 'validation/loss': 1.174136171875, 'validation/num_examples': 50000, 'test/accuracy': 0.6272, 'test/loss': 1.8209953125, 'test/num_examples': 10000, 'score': 42267.46894669533, 'total_duration': 50876.85193657875, 'accumulated_submission_time': 42267.46894669533, 'accumulated_eval_time': 8393.389695882797, 'accumulated_logging_time': 2.5801351070404053}
I0914 21:35:45.847993 139787159729920 logging_writer.py:48] [122591] accumulated_eval_time=8393.389696, accumulated_logging_time=2.580135, accumulated_submission_time=42267.468947, global_step=122591, preemption_count=0, score=42267.468947, test/accuracy=0.627200, test/loss=1.820995, test/num_examples=10000, total_duration=50876.851937, train/accuracy=0.888114, train/loss=0.661006, validation/accuracy=0.760140, validation/loss=1.174136, validation/num_examples=50000
I0914 21:38:08.551034 139787151337216 logging_writer.py:48] [123000] global_step=123000, grad_norm=0.517449, loss=2.641275
I0914 21:38:08.555930 139834269067072 pytorch_submission_base.py:86] 123000) loss = 2.641, grad_norm = 0.517
I0914 21:40:59.940583 139787159729920 logging_writer.py:48] [123500] global_step=123500, grad_norm=0.499343, loss=2.657714
I0914 21:40:59.946482 139834269067072 pytorch_submission_base.py:86] 123500) loss = 2.658, grad_norm = 0.499
I0914 21:43:52.997326 139787151337216 logging_writer.py:48] [124000] global_step=124000, grad_norm=0.493211, loss=2.593932
I0914 21:43:53.007801 139834269067072 pytorch_submission_base.py:86] 124000) loss = 2.594, grad_norm = 0.493
I0914 21:44:16.989114 139834269067072 spec.py:320] Evaluating on the training split.
I0914 21:44:59.642486 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 21:45:53.895748 139834269067072 spec.py:348] Evaluating on the test split.
I0914 21:45:54.986735 139834269067072 submission_runner.py:376] Time since start: 51486.01s, 	Step: 124068, 	{'train/accuracy': 0.8996930803571429, 'train/loss': 0.6147424736801459, 'validation/accuracy': 0.76778, 'validation/loss': 1.14217875, 'validation/num_examples': 50000, 'test/accuracy': 0.6306, 'test/loss': 1.7808302734375, 'test/num_examples': 10000, 'score': 42775.983882665634, 'total_duration': 51486.0146279335, 'accumulated_submission_time': 42775.983882665634, 'accumulated_eval_time': 8491.387544870377, 'accumulated_logging_time': 2.613130569458008}
I0914 21:45:55.012690 139787159729920 logging_writer.py:48] [124068] accumulated_eval_time=8491.387545, accumulated_logging_time=2.613131, accumulated_submission_time=42775.983883, global_step=124068, preemption_count=0, score=42775.983883, test/accuracy=0.630600, test/loss=1.780830, test/num_examples=10000, total_duration=51486.014628, train/accuracy=0.899693, train/loss=0.614742, validation/accuracy=0.767780, validation/loss=1.142179, validation/num_examples=50000
I0914 21:48:23.945966 139787151337216 logging_writer.py:48] [124500] global_step=124500, grad_norm=0.507616, loss=2.578562
I0914 21:48:23.951434 139834269067072 pytorch_submission_base.py:86] 124500) loss = 2.579, grad_norm = 0.508
I0914 21:51:15.320055 139787159729920 logging_writer.py:48] [125000] global_step=125000, grad_norm=0.486449, loss=2.566849
I0914 21:51:15.327598 139834269067072 pytorch_submission_base.py:86] 125000) loss = 2.567, grad_norm = 0.486
I0914 21:54:08.618383 139787151337216 logging_writer.py:48] [125500] global_step=125500, grad_norm=0.517203, loss=2.587921
I0914 21:54:08.623000 139834269067072 pytorch_submission_base.py:86] 125500) loss = 2.588, grad_norm = 0.517
I0914 21:54:26.002025 139834269067072 spec.py:320] Evaluating on the training split.
I0914 21:55:08.673804 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 21:56:02.316906 139834269067072 spec.py:348] Evaluating on the test split.
I0914 21:56:03.402270 139834269067072 submission_runner.py:376] Time since start: 52094.43s, 	Step: 125549, 	{'train/accuracy': 0.9067083864795918, 'train/loss': 0.5877799209283323, 'validation/accuracy': 0.77282, 'validation/loss': 1.1275253125, 'validation/num_examples': 50000, 'test/accuracy': 0.6407, 'test/loss': 1.7580869140625, 'test/num_examples': 10000, 'score': 43284.41992068291, 'total_duration': 52094.43017458916, 'accumulated_submission_time': 43284.41992068291, 'accumulated_eval_time': 8588.787898540497, 'accumulated_logging_time': 2.647573709487915}
I0914 21:56:03.427824 139787159729920 logging_writer.py:48] [125549] accumulated_eval_time=8588.787899, accumulated_logging_time=2.647574, accumulated_submission_time=43284.419921, global_step=125549, preemption_count=0, score=43284.419921, test/accuracy=0.640700, test/loss=1.758087, test/num_examples=10000, total_duration=52094.430175, train/accuracy=0.906708, train/loss=0.587780, validation/accuracy=0.772820, validation/loss=1.127525, validation/num_examples=50000
I0914 21:58:38.804645 139787151337216 logging_writer.py:48] [126000] global_step=126000, grad_norm=0.511122, loss=2.569344
I0914 21:58:38.809247 139834269067072 pytorch_submission_base.py:86] 126000) loss = 2.569, grad_norm = 0.511
I0914 22:01:31.666137 139787159729920 logging_writer.py:48] [126500] global_step=126500, grad_norm=0.488995, loss=2.520930
I0914 22:01:31.671598 139834269067072 pytorch_submission_base.py:86] 126500) loss = 2.521, grad_norm = 0.489
I0914 22:04:23.058634 139787151337216 logging_writer.py:48] [127000] global_step=127000, grad_norm=0.494777, loss=2.570699
I0914 22:04:23.063690 139834269067072 pytorch_submission_base.py:86] 127000) loss = 2.571, grad_norm = 0.495
I0914 22:04:34.602700 139834269067072 spec.py:320] Evaluating on the training split.
I0914 22:05:17.237495 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 22:06:11.679871 139834269067072 spec.py:348] Evaluating on the test split.
I0914 22:06:12.768527 139834269067072 submission_runner.py:376] Time since start: 52703.80s, 	Step: 127032, 	{'train/accuracy': 0.9132653061224489, 'train/loss': 0.5630088339046556, 'validation/accuracy': 0.776, 'validation/loss': 1.1093646875, 'validation/num_examples': 50000, 'test/accuracy': 0.6457, 'test/loss': 1.746294921875, 'test/num_examples': 10000, 'score': 43793.04886460304, 'total_duration': 52703.79640293121, 'accumulated_submission_time': 43793.04886460304, 'accumulated_eval_time': 8686.953979253769, 'accumulated_logging_time': 2.6815497875213623}
I0914 22:06:12.795024 139787159729920 logging_writer.py:48] [127032] accumulated_eval_time=8686.953979, accumulated_logging_time=2.681550, accumulated_submission_time=43793.048865, global_step=127032, preemption_count=0, score=43793.048865, test/accuracy=0.645700, test/loss=1.746295, test/num_examples=10000, total_duration=52703.796403, train/accuracy=0.913265, train/loss=0.563009, validation/accuracy=0.776000, validation/loss=1.109365, validation/num_examples=50000
I0914 22:08:54.025386 139787151337216 logging_writer.py:48] [127500] global_step=127500, grad_norm=0.514502, loss=2.607090
I0914 22:08:54.033411 139834269067072 pytorch_submission_base.py:86] 127500) loss = 2.607, grad_norm = 0.515
I0914 22:11:47.044595 139787159729920 logging_writer.py:48] [128000] global_step=128000, grad_norm=0.501294, loss=2.621491
I0914 22:11:47.048748 139834269067072 pytorch_submission_base.py:86] 128000) loss = 2.621, grad_norm = 0.501
I0914 22:14:38.457236 139787151337216 logging_writer.py:48] [128500] global_step=128500, grad_norm=0.498830, loss=2.570013
I0914 22:14:38.461489 139834269067072 pytorch_submission_base.py:86] 128500) loss = 2.570, grad_norm = 0.499
I0914 22:14:43.872719 139834269067072 spec.py:320] Evaluating on the training split.
I0914 22:15:26.673199 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 22:16:20.077834 139834269067072 spec.py:348] Evaluating on the test split.
I0914 22:16:21.167819 139834269067072 submission_runner.py:376] Time since start: 53312.19s, 	Step: 128514, 	{'train/accuracy': 0.9143215880102041, 'train/loss': 0.5543618883405413, 'validation/accuracy': 0.7772, 'validation/loss': 1.1008584375, 'validation/num_examples': 50000, 'test/accuracy': 0.647, 'test/loss': 1.7333802734375, 'test/num_examples': 10000, 'score': 44301.551661491394, 'total_duration': 53312.194628953934, 'accumulated_submission_time': 44301.551661491394, 'accumulated_eval_time': 8784.248070716858, 'accumulated_logging_time': 2.7169041633605957}
I0914 22:16:21.189955 139787159729920 logging_writer.py:48] [128514] accumulated_eval_time=8784.248071, accumulated_logging_time=2.716904, accumulated_submission_time=44301.551661, global_step=128514, preemption_count=0, score=44301.551661, test/accuracy=0.647000, test/loss=1.733380, test/num_examples=10000, total_duration=53312.194629, train/accuracy=0.914322, train/loss=0.554362, validation/accuracy=0.777200, validation/loss=1.100858, validation/num_examples=50000
I0914 22:19:10.117309 139787151337216 logging_writer.py:48] [129000] global_step=129000, grad_norm=0.495921, loss=2.601190
I0914 22:19:10.121709 139834269067072 pytorch_submission_base.py:86] 129000) loss = 2.601, grad_norm = 0.496
I0914 22:22:01.459820 139787159729920 logging_writer.py:48] [129500] global_step=129500, grad_norm=0.501054, loss=2.525860
I0914 22:22:01.467190 139834269067072 pytorch_submission_base.py:86] 129500) loss = 2.526, grad_norm = 0.501
I0914 22:24:52.350018 139834269067072 spec.py:320] Evaluating on the training split.
I0914 22:25:35.244947 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 22:26:29.518888 139834269067072 spec.py:348] Evaluating on the test split.
I0914 22:26:30.607954 139834269067072 submission_runner.py:376] Time since start: 53921.64s, 	Step: 129997, 	{'train/accuracy': 0.9150589923469388, 'train/loss': 0.5568700128672074, 'validation/accuracy': 0.77688, 'validation/loss': 1.1059775, 'validation/num_examples': 50000, 'test/accuracy': 0.6436, 'test/loss': 1.747789453125, 'test/num_examples': 10000, 'score': 44810.124940633774, 'total_duration': 53921.6358935833, 'accumulated_submission_time': 44810.124940633774, 'accumulated_eval_time': 8882.506386995316, 'accumulated_logging_time': 2.7478830814361572}
I0914 22:26:30.631198 139787151337216 logging_writer.py:48] [129997] accumulated_eval_time=8882.506387, accumulated_logging_time=2.747883, accumulated_submission_time=44810.124941, global_step=129997, preemption_count=0, score=44810.124941, test/accuracy=0.643600, test/loss=1.747789, test/num_examples=10000, total_duration=53921.635894, train/accuracy=0.915059, train/loss=0.556870, validation/accuracy=0.776880, validation/loss=1.105978, validation/num_examples=50000
I0914 22:26:32.654894 139787159729920 logging_writer.py:48] [130000] global_step=130000, grad_norm=0.499093, loss=2.493588
I0914 22:26:32.660187 139834269067072 pytorch_submission_base.py:86] 130000) loss = 2.494, grad_norm = 0.499
I0914 22:29:25.388971 139787151337216 logging_writer.py:48] [130500] global_step=130500, grad_norm=0.495506, loss=2.494561
I0914 22:29:25.393786 139834269067072 pytorch_submission_base.py:86] 130500) loss = 2.495, grad_norm = 0.496
I0914 22:32:16.703667 139787159729920 logging_writer.py:48] [131000] global_step=131000, grad_norm=0.499773, loss=2.574094
I0914 22:32:16.707913 139834269067072 pytorch_submission_base.py:86] 131000) loss = 2.574, grad_norm = 0.500
I0914 22:35:01.739102 139834269067072 spec.py:320] Evaluating on the training split.
I0914 22:35:44.648020 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 22:36:38.546738 139834269067072 spec.py:348] Evaluating on the test split.
I0914 22:36:39.633307 139834269067072 submission_runner.py:376] Time since start: 54530.66s, 	Step: 131475, 	{'train/accuracy': 0.9149792729591837, 'train/loss': 0.5507438426115074, 'validation/accuracy': 0.77678, 'validation/loss': 1.101820703125, 'validation/num_examples': 50000, 'test/accuracy': 0.644, 'test/loss': 1.741523046875, 'test/num_examples': 10000, 'score': 45318.65207242966, 'total_duration': 54530.66124892235, 'accumulated_submission_time': 45318.65207242966, 'accumulated_eval_time': 8980.400998830795, 'accumulated_logging_time': 2.7816193103790283}
I0914 22:36:39.656750 139787151337216 logging_writer.py:48] [131475] accumulated_eval_time=8980.400999, accumulated_logging_time=2.781619, accumulated_submission_time=45318.652072, global_step=131475, preemption_count=0, score=45318.652072, test/accuracy=0.644000, test/loss=1.741523, test/num_examples=10000, total_duration=54530.661249, train/accuracy=0.914979, train/loss=0.550744, validation/accuracy=0.776780, validation/loss=1.101821, validation/num_examples=50000
I0914 22:36:49.171054 139787159729920 logging_writer.py:48] [131500] global_step=131500, grad_norm=0.504129, loss=2.582178
I0914 22:36:49.174867 139834269067072 pytorch_submission_base.py:86] 131500) loss = 2.582, grad_norm = 0.504
I0914 22:39:40.313321 139787151337216 logging_writer.py:48] [132000] global_step=132000, grad_norm=0.487649, loss=2.497156
I0914 22:39:40.317940 139834269067072 pytorch_submission_base.py:86] 132000) loss = 2.497, grad_norm = 0.488
I0914 22:42:31.687238 139787159729920 logging_writer.py:48] [132500] global_step=132500, grad_norm=0.495732, loss=2.523889
I0914 22:42:31.693609 139834269067072 pytorch_submission_base.py:86] 132500) loss = 2.524, grad_norm = 0.496
I0914 22:45:10.732098 139834269067072 spec.py:320] Evaluating on the training split.
I0914 22:45:53.232711 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 22:46:46.797931 139834269067072 spec.py:348] Evaluating on the test split.
I0914 22:46:47.886911 139834269067072 submission_runner.py:376] Time since start: 55138.91s, 	Step: 132958, 	{'train/accuracy': 0.9150390625, 'train/loss': 0.5541359648412588, 'validation/accuracy': 0.77732, 'validation/loss': 1.10516828125, 'validation/num_examples': 50000, 'test/accuracy': 0.6442, 'test/loss': 1.7455205078125, 'test/num_examples': 10000, 'score': 45827.2147693634, 'total_duration': 55138.91485786438, 'accumulated_submission_time': 45827.2147693634, 'accumulated_eval_time': 9077.556076526642, 'accumulated_logging_time': 2.815622568130493}
I0914 22:46:47.911559 139787151337216 logging_writer.py:48] [132958] accumulated_eval_time=9077.556077, accumulated_logging_time=2.815623, accumulated_submission_time=45827.214769, global_step=132958, preemption_count=0, score=45827.214769, test/accuracy=0.644200, test/loss=1.745521, test/num_examples=10000, total_duration=55138.914858, train/accuracy=0.915039, train/loss=0.554136, validation/accuracy=0.777320, validation/loss=1.105168, validation/num_examples=50000
I0914 22:47:03.270002 139787159729920 logging_writer.py:48] [133000] global_step=133000, grad_norm=0.504751, loss=2.556406
I0914 22:47:03.274422 139834269067072 pytorch_submission_base.py:86] 133000) loss = 2.556, grad_norm = 0.505
I0914 22:49:54.334453 139787151337216 logging_writer.py:48] [133500] global_step=133500, grad_norm=0.494860, loss=2.551926
I0914 22:49:54.339296 139834269067072 pytorch_submission_base.py:86] 133500) loss = 2.552, grad_norm = 0.495
I0914 22:52:47.408867 139787159729920 logging_writer.py:48] [134000] global_step=134000, grad_norm=0.491772, loss=2.532806
I0914 22:52:47.413708 139834269067072 pytorch_submission_base.py:86] 134000) loss = 2.533, grad_norm = 0.492
I0914 22:55:18.789917 139834269067072 spec.py:320] Evaluating on the training split.
I0914 22:56:01.392957 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 22:56:56.305328 139834269067072 spec.py:348] Evaluating on the test split.
I0914 22:56:57.394564 139834269067072 submission_runner.py:376] Time since start: 55748.42s, 	Step: 134440, 	{'train/accuracy': 0.9160554846938775, 'train/loss': 0.5545257256955517, 'validation/accuracy': 0.77738, 'validation/loss': 1.107788359375, 'validation/num_examples': 50000, 'test/accuracy': 0.6428, 'test/loss': 1.7522775390625, 'test/num_examples': 10000, 'score': 46335.59037256241, 'total_duration': 55748.42243742943, 'accumulated_submission_time': 46335.59037256241, 'accumulated_eval_time': 9176.160999774933, 'accumulated_logging_time': 2.8491079807281494}
I0914 22:56:57.418842 139787151337216 logging_writer.py:48] [134440] accumulated_eval_time=9176.161000, accumulated_logging_time=2.849108, accumulated_submission_time=46335.590373, global_step=134440, preemption_count=0, score=46335.590373, test/accuracy=0.642800, test/loss=1.752278, test/num_examples=10000, total_duration=55748.422437, train/accuracy=0.916055, train/loss=0.554526, validation/accuracy=0.777380, validation/loss=1.107788, validation/num_examples=50000
I0914 22:57:18.882685 139787159729920 logging_writer.py:48] [134500] global_step=134500, grad_norm=0.507119, loss=2.582273
I0914 22:57:18.886782 139834269067072 pytorch_submission_base.py:86] 134500) loss = 2.582, grad_norm = 0.507
I0914 23:00:10.262024 139787151337216 logging_writer.py:48] [135000] global_step=135000, grad_norm=0.514477, loss=2.549066
I0914 23:00:10.271235 139834269067072 pytorch_submission_base.py:86] 135000) loss = 2.549, grad_norm = 0.514
I0914 23:03:03.213846 139787159729920 logging_writer.py:48] [135500] global_step=135500, grad_norm=0.489963, loss=2.521086
I0914 23:03:03.218357 139834269067072 pytorch_submission_base.py:86] 135500) loss = 2.521, grad_norm = 0.490
I0914 23:05:28.356329 139834269067072 spec.py:320] Evaluating on the training split.
I0914 23:06:10.841735 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 23:07:06.146746 139834269067072 spec.py:348] Evaluating on the test split.
I0914 23:07:07.238480 139834269067072 submission_runner.py:376] Time since start: 56358.26s, 	Step: 135922, 	{'train/accuracy': 0.9161551339285714, 'train/loss': 0.5428472246442523, 'validation/accuracy': 0.77804, 'validation/loss': 1.09486046875, 'validation/num_examples': 50000, 'test/accuracy': 0.6435, 'test/loss': 1.7377451171875, 'test/num_examples': 10000, 'score': 46843.968055963516, 'total_duration': 56358.26499629021, 'accumulated_submission_time': 46843.968055963516, 'accumulated_eval_time': 9275.042012929916, 'accumulated_logging_time': 2.8817646503448486}
I0914 23:07:07.266528 139787151337216 logging_writer.py:48] [135922] accumulated_eval_time=9275.042013, accumulated_logging_time=2.881765, accumulated_submission_time=46843.968056, global_step=135922, preemption_count=0, score=46843.968056, test/accuracy=0.643500, test/loss=1.737745, test/num_examples=10000, total_duration=56358.264996, train/accuracy=0.916155, train/loss=0.542847, validation/accuracy=0.778040, validation/loss=1.094860, validation/num_examples=50000
I0914 23:07:34.911682 139787159729920 logging_writer.py:48] [136000] global_step=136000, grad_norm=0.507640, loss=2.543175
I0914 23:07:34.921379 139834269067072 pytorch_submission_base.py:86] 136000) loss = 2.543, grad_norm = 0.508
I0914 23:10:27.698885 139787151337216 logging_writer.py:48] [136500] global_step=136500, grad_norm=0.500730, loss=2.542896
I0914 23:10:27.703918 139834269067072 pytorch_submission_base.py:86] 136500) loss = 2.543, grad_norm = 0.501
I0914 23:13:19.160763 139787159729920 logging_writer.py:48] [137000] global_step=137000, grad_norm=0.478503, loss=2.500276
I0914 23:13:19.166385 139834269067072 pytorch_submission_base.py:86] 137000) loss = 2.500, grad_norm = 0.479
I0914 23:15:38.208860 139834269067072 spec.py:320] Evaluating on the training split.
I0914 23:16:21.278886 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 23:17:16.351792 139834269067072 spec.py:348] Evaluating on the test split.
I0914 23:17:17.438780 139834269067072 submission_runner.py:376] Time since start: 56968.47s, 	Step: 137404, 	{'train/accuracy': 0.9159757653061225, 'train/loss': 0.5429121134232502, 'validation/accuracy': 0.77764, 'validation/loss': 1.0952590625, 'validation/num_examples': 50000, 'test/accuracy': 0.6454, 'test/loss': 1.73577109375, 'test/num_examples': 10000, 'score': 47352.309515953064, 'total_duration': 56968.466680288315, 'accumulated_submission_time': 47352.309515953064, 'accumulated_eval_time': 9374.272126197815, 'accumulated_logging_time': 2.918630361557007}
I0914 23:17:17.462195 139787151337216 logging_writer.py:48] [137404] accumulated_eval_time=9374.272126, accumulated_logging_time=2.918630, accumulated_submission_time=47352.309516, global_step=137404, preemption_count=0, score=47352.309516, test/accuracy=0.645400, test/loss=1.735771, test/num_examples=10000, total_duration=56968.466680, train/accuracy=0.915976, train/loss=0.542912, validation/accuracy=0.777640, validation/loss=1.095259, validation/num_examples=50000
I0914 23:17:51.328291 139787159729920 logging_writer.py:48] [137500] global_step=137500, grad_norm=0.467366, loss=2.490024
I0914 23:17:51.336511 139834269067072 pytorch_submission_base.py:86] 137500) loss = 2.490, grad_norm = 0.467
I0914 23:20:44.271177 139787151337216 logging_writer.py:48] [138000] global_step=138000, grad_norm=0.516284, loss=2.580642
I0914 23:20:44.277050 139834269067072 pytorch_submission_base.py:86] 138000) loss = 2.581, grad_norm = 0.516
I0914 23:23:35.638241 139787159729920 logging_writer.py:48] [138500] global_step=138500, grad_norm=0.500715, loss=2.507481
I0914 23:23:35.642887 139834269067072 pytorch_submission_base.py:86] 138500) loss = 2.507, grad_norm = 0.501
I0914 23:25:48.496225 139834269067072 spec.py:320] Evaluating on the training split.
I0914 23:26:31.729451 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 23:27:25.995424 139834269067072 spec.py:348] Evaluating on the test split.
I0914 23:27:27.081584 139834269067072 submission_runner.py:376] Time since start: 57578.11s, 	Step: 138881, 	{'train/accuracy': 0.9167530293367347, 'train/loss': 0.5477877247090243, 'validation/accuracy': 0.77794, 'validation/loss': 1.101368046875, 'validation/num_examples': 50000, 'test/accuracy': 0.6449, 'test/loss': 1.7456314453125, 'test/num_examples': 10000, 'score': 47860.87314724922, 'total_duration': 57578.10950231552, 'accumulated_submission_time': 47860.87314724922, 'accumulated_eval_time': 9472.857727527618, 'accumulated_logging_time': 2.95082950592041}
I0914 23:27:27.107815 139787151337216 logging_writer.py:48] [138881] accumulated_eval_time=9472.857728, accumulated_logging_time=2.950830, accumulated_submission_time=47860.873147, global_step=138881, preemption_count=0, score=47860.873147, test/accuracy=0.644900, test/loss=1.745631, test/num_examples=10000, total_duration=57578.109502, train/accuracy=0.916753, train/loss=0.547788, validation/accuracy=0.777940, validation/loss=1.101368, validation/num_examples=50000
I0914 23:28:08.807951 139787159729920 logging_writer.py:48] [139000] global_step=139000, grad_norm=0.472606, loss=2.477542
I0914 23:28:08.812318 139834269067072 pytorch_submission_base.py:86] 139000) loss = 2.478, grad_norm = 0.473
I0914 23:31:00.035305 139787151337216 logging_writer.py:48] [139500] global_step=139500, grad_norm=0.492727, loss=2.532525
I0914 23:31:00.039930 139834269067072 pytorch_submission_base.py:86] 139500) loss = 2.533, grad_norm = 0.493
I0914 23:33:51.882557 139834269067072 spec.py:320] Evaluating on the training split.
I0914 23:34:34.879379 139834269067072 spec.py:332] Evaluating on the validation split.
I0914 23:35:28.331762 139834269067072 spec.py:348] Evaluating on the test split.
I0914 23:35:29.417703 139834269067072 submission_runner.py:376] Time since start: 58060.45s, 	Step: 140000, 	{'train/accuracy': 0.9174306441326531, 'train/loss': 0.5512791069186463, 'validation/accuracy': 0.77784, 'validation/loss': 1.107318671875, 'validation/num_examples': 50000, 'test/accuracy': 0.6462, 'test/loss': 1.7462333984375, 'test/num_examples': 10000, 'score': 48243.38105273247, 'total_duration': 58060.4455780983, 'accumulated_submission_time': 48243.38105273247, 'accumulated_eval_time': 9570.393196344376, 'accumulated_logging_time': 2.9877519607543945}
I0914 23:35:29.441906 139787159729920 logging_writer.py:48] [140000] accumulated_eval_time=9570.393196, accumulated_logging_time=2.987752, accumulated_submission_time=48243.381053, global_step=140000, preemption_count=0, score=48243.381053, test/accuracy=0.646200, test/loss=1.746233, test/num_examples=10000, total_duration=58060.445578, train/accuracy=0.917431, train/loss=0.551279, validation/accuracy=0.777840, validation/loss=1.107319, validation/num_examples=50000
I0914 23:35:29.978640 139787151337216 logging_writer.py:48] [140000] global_step=140000, preemption_count=0, score=48243.381053
I0914 23:35:30.503385 139834269067072 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/targets_check_pytorch/momentum_run_0/imagenet_resnet_pytorch/trial_1/checkpoint_140000.
I0914 23:35:30.850386 139834269067072 submission_runner.py:540] Tuning trial 1/1
I0914 23:35:30.850597 139834269067072 submission_runner.py:541] Hyperparameters: Hyperparameters(learning_rate=4.131896390902391, beta1=0.9274758113254791, beta2=0.9978504782314613, warmup_steps=6999, decay_steps_factor=0.9007765761611038, end_factor=0.001, weight_decay=5.6687777311501786e-06, label_smoothing=0.2)
I0914 23:35:30.852714 139834269067072 submission_runner.py:542] Metrics: {'eval_results': [(1, {'train/accuracy': 0.001096141581632653, 'train/loss': 6.917834223533164, 'validation/accuracy': 0.00096, 'validation/loss': 6.918853125, 'validation/num_examples': 50000, 'test/accuracy': 0.0012, 'test/loss': 6.920421875, 'test/num_examples': 10000, 'score': 60.984593868255615, 'total_duration': 272.05629229545593, 'accumulated_submission_time': 60.984593868255615, 'accumulated_eval_time': 210.4636435508728, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (1382, {'train/accuracy': 0.19270169005102042, 'train/loss': 4.24181942063935, 'validation/accuracy': 0.17518, 'validation/loss': 4.3354953125, 'validation/num_examples': 50000, 'test/accuracy': 0.127, 'test/loss': 4.7698484375, 'test/num_examples': 10000, 'score': 569.4610950946808, 'total_duration': 885.8260006904602, 'accumulated_submission_time': 569.4610950946808, 'accumulated_eval_time': 313.03159165382385, 'accumulated_logging_time': 0.029378175735473633, 'global_step': 1382, 'preemption_count': 0}), (2851, {'train/accuracy': 0.3761360012755102, 'train/loss': 3.079436633051658, 'validation/accuracy': 0.34818, 'validation/loss': 3.228095, 'validation/num_examples': 50000, 'test/accuracy': 0.2552, 'test/loss': 3.84915703125, 'test/num_examples': 10000, 'score': 1078.0562477111816, 'total_duration': 1505.0452282428741, 'accumulated_submission_time': 1078.0562477111816, 'accumulated_eval_time': 420.9456560611725, 'accumulated_logging_time': 0.05981016159057617, 'global_step': 2851, 'preemption_count': 0}), (4326, {'train/accuracy': 0.47793765943877553, 'train/loss': 2.523687401596381, 'validation/accuracy': 0.44296, 'validation/loss': 2.698548125, 'validation/num_examples': 50000, 'test/accuracy': 0.326, 'test/loss': 3.39362734375, 'test/num_examples': 10000, 'score': 1586.5042593479156, 'total_duration': 2118.587264060974, 'accumulated_submission_time': 1586.5042593479156, 'accumulated_eval_time': 523.3074886798859, 'accumulated_logging_time': 0.09416055679321289, 'global_step': 4326, 'preemption_count': 0}), (5799, {'train/accuracy': 0.5077327806122449, 'train/loss': 2.4033371283083547, 'validation/accuracy': 0.4707, 'validation/loss': 2.589981875, 'validation/num_examples': 50000, 'test/accuracy': 0.362, 'test/loss': 3.19341875, 'test/num_examples': 10000, 'score': 2094.9969153404236, 'total_duration': 2731.7052235603333, 'accumulated_submission_time': 2094.9969153404236, 'accumulated_eval_time': 625.1727330684662, 'accumulated_logging_time': 0.12300705909729004, 'global_step': 5799, 'preemption_count': 0}), (7271, {'train/accuracy': 0.5223214285714286, 'train/loss': 2.307311388911033, 'validation/accuracy': 0.48322, 'validation/loss': 2.49694296875, 'validation/num_examples': 50000, 'test/accuracy': 0.3708, 'test/loss': 3.1751080078125, 'test/num_examples': 10000, 'score': 2603.4704480171204, 'total_duration': 3348.2424252033234, 'accumulated_submission_time': 2603.4704480171204, 'accumulated_eval_time': 730.4458467960358, 'accumulated_logging_time': 0.14911961555480957, 'global_step': 7271, 'preemption_count': 0}), (8739, {'train/accuracy': 0.5569395727040817, 'train/loss': 2.1433943145129146, 'validation/accuracy': 0.51116, 'validation/loss': 2.36050140625, 'validation/num_examples': 50000, 'test/accuracy': 0.4004, 'test/loss': 2.9739369140625, 'test/num_examples': 10000, 'score': 3112.0278327465057, 'total_duration': 3961.6747641563416, 'accumulated_submission_time': 3112.0278327465057, 'accumulated_eval_time': 832.4892835617065, 'accumulated_logging_time': 0.17649197578430176, 'global_step': 8739, 'preemption_count': 0}), (10205, {'train/accuracy': 0.5587930484693877, 'train/loss': 2.0926851545061385, 'validation/accuracy': 0.51248, 'validation/loss': 2.321938125, 'validation/num_examples': 50000, 'test/accuracy': 0.3796, 'test/loss': 3.0909994140625, 'test/num_examples': 10000, 'score': 3620.4415559768677, 'total_duration': 4574.338397026062, 'accumulated_submission_time': 3620.4415559768677, 'accumulated_eval_time': 933.9763813018799, 'accumulated_logging_time': 0.2047131061553955, 'global_step': 10205, 'preemption_count': 0}), (11676, {'train/accuracy': 0.5779655612244898, 'train/loss': 2.068122085259885, 'validation/accuracy': 0.5343, 'validation/loss': 2.2872796875, 'validation/num_examples': 50000, 'test/accuracy': 0.4065, 'test/loss': 2.98098671875, 'test/num_examples': 10000, 'score': 4128.741535663605, 'total_duration': 5185.935208559036, 'accumulated_submission_time': 4128.741535663605, 'accumulated_eval_time': 1034.5970752239227, 'accumulated_logging_time': 0.23186326026916504, 'global_step': 11676, 'preemption_count': 0}), (13150, {'train/accuracy': 0.5659478635204082, 'train/loss': 2.13895338408801, 'validation/accuracy': 0.51816, 'validation/loss': 2.35374046875, 'validation/num_examples': 50000, 'test/accuracy': 0.3873, 'test/loss': 3.1037517578125, 'test/num_examples': 10000, 'score': 4637.100549936295, 'total_duration': 5798.216918468475, 'accumulated_submission_time': 4637.100549936295, 'accumulated_eval_time': 1135.8054895401, 'accumulated_logging_time': 0.26008081436157227, 'global_step': 13150, 'preemption_count': 0}), (14606, {'train/accuracy': 0.5469347895408163, 'train/loss': 2.192572146045918, 'validation/accuracy': 0.50062, 'validation/loss': 2.415928125, 'validation/num_examples': 50000, 'test/accuracy': 0.4003, 'test/loss': 3.00174765625, 'test/num_examples': 10000, 'score': 5145.458602905273, 'total_duration': 6408.853790283203, 'accumulated_submission_time': 5145.458602905273, 'accumulated_eval_time': 1235.4615318775177, 'accumulated_logging_time': 0.32493138313293457, 'global_step': 14606, 'preemption_count': 0}), (16076, {'train/accuracy': 0.5941286670918368, 'train/loss': 2.013149339325574, 'validation/accuracy': 0.54808, 'validation/loss': 2.23813484375, 'validation/num_examples': 50000, 'test/accuracy': 0.4262, 'test/loss': 2.8939173828125, 'test/num_examples': 10000, 'score': 5653.980618476868, 'total_duration': 7022.829247713089, 'accumulated_submission_time': 5653.980618476868, 'accumulated_eval_time': 1338.144369840622, 'accumulated_logging_time': 0.354633092880249, 'global_step': 16076, 'preemption_count': 0}), (17542, {'train/accuracy': 0.6072026466836735, 'train/loss': 1.8829921800263074, 'validation/accuracy': 0.5566, 'validation/loss': 2.10387421875, 'validation/num_examples': 50000, 'test/accuracy': 0.4242, 'test/loss': 2.844534765625, 'test/num_examples': 10000, 'score': 6162.424164772034, 'total_duration': 7634.994186401367, 'accumulated_submission_time': 6162.424164772034, 'accumulated_eval_time': 1439.201328277588, 'accumulated_logging_time': 0.39263010025024414, 'global_step': 17542, 'preemption_count': 0}), (19016, {'train/accuracy': 0.6076211734693877, 'train/loss': 1.842592511858259, 'validation/accuracy': 0.55762, 'validation/loss': 2.07040703125, 'validation/num_examples': 50000, 'test/accuracy': 0.4293, 'test/loss': 2.7867294921875, 'test/num_examples': 10000, 'score': 6670.975220680237, 'total_duration': 8245.231682538986, 'accumulated_submission_time': 6670.975220680237, 'accumulated_eval_time': 1538.278061389923, 'accumulated_logging_time': 0.4204268455505371, 'global_step': 19016, 'preemption_count': 0}), (20496, {'train/accuracy': 0.5958824936224489, 'train/loss': 1.9366749354771204, 'validation/accuracy': 0.54774, 'validation/loss': 2.1636615625, 'validation/num_examples': 50000, 'test/accuracy': 0.4189, 'test/loss': 2.882854296875, 'test/num_examples': 10000, 'score': 7179.374185800552, 'total_duration': 8853.144400119781, 'accumulated_submission_time': 7179.374185800552, 'accumulated_eval_time': 1635.2522559165955, 'accumulated_logging_time': 0.45361828804016113, 'global_step': 20496, 'preemption_count': 0}), (21977, {'train/accuracy': 0.621452487244898, 'train/loss': 1.7736855331732302, 'validation/accuracy': 0.56886, 'validation/loss': 2.031190625, 'validation/num_examples': 50000, 'test/accuracy': 0.4331, 'test/loss': 2.746473046875, 'test/num_examples': 10000, 'score': 7688.0603222846985, 'total_duration': 9461.698584794998, 'accumulated_submission_time': 7688.0603222846985, 'accumulated_eval_time': 1732.5357491970062, 'accumulated_logging_time': 0.48201489448547363, 'global_step': 21977, 'preemption_count': 0}), (23458, {'train/accuracy': 0.5976961096938775, 'train/loss': 1.8679202332788585, 'validation/accuracy': 0.5474, 'validation/loss': 2.0991978125, 'validation/num_examples': 50000, 'test/accuracy': 0.4232, 'test/loss': 2.812408984375, 'test/num_examples': 10000, 'score': 8196.768168449402, 'total_duration': 10071.209857463837, 'accumulated_submission_time': 8196.768168449402, 'accumulated_eval_time': 1830.7522647380829, 'accumulated_logging_time': 0.5106523036956787, 'global_step': 23458, 'preemption_count': 0}), (24939, {'train/accuracy': 0.6144770408163265, 'train/loss': 1.8177558743223852, 'validation/accuracy': 0.56678, 'validation/loss': 2.04693484375, 'validation/num_examples': 50000, 'test/accuracy': 0.4438, 'test/loss': 2.7090078125, 'test/num_examples': 10000, 'score': 8705.361060142517, 'total_duration': 10679.547111749649, 'accumulated_submission_time': 8705.361060142517, 'accumulated_eval_time': 1927.9214270114899, 'accumulated_logging_time': 0.5412359237670898, 'global_step': 24939, 'preemption_count': 0}), (26415, {'train/accuracy': 0.6229870854591837, 'train/loss': 1.814096567582111, 'validation/accuracy': 0.57292, 'validation/loss': 2.055635625, 'validation/num_examples': 50000, 'test/accuracy': 0.4407, 'test/loss': 2.7481537109375, 'test/num_examples': 10000, 'score': 9213.80210185051, 'total_duration': 11288.111587762833, 'accumulated_submission_time': 9213.80210185051, 'accumulated_eval_time': 2025.4953210353851, 'accumulated_logging_time': 0.568253755569458, 'global_step': 26415, 'preemption_count': 0}), (27896, {'train/accuracy': 0.616828762755102, 'train/loss': 1.8467724858498087, 'validation/accuracy': 0.56686, 'validation/loss': 2.08724125, 'validation/num_examples': 50000, 'test/accuracy': 0.439, 'test/loss': 2.76180234375, 'test/num_examples': 10000, 'score': 9722.178416013718, 'total_duration': 11895.991220712662, 'accumulated_submission_time': 9722.178416013718, 'accumulated_eval_time': 2122.421482563019, 'accumulated_logging_time': 0.5954921245574951, 'global_step': 27896, 'preemption_count': 0}), (29364, {'train/accuracy': 0.6420599489795918, 'train/loss': 1.7355113126793686, 'validation/accuracy': 0.58606, 'validation/loss': 1.99039484375, 'validation/num_examples': 50000, 'test/accuracy': 0.4697, 'test/loss': 2.6297138671875, 'test/num_examples': 10000, 'score': 10230.789728403091, 'total_duration': 12504.259550094604, 'accumulated_submission_time': 10230.789728403091, 'accumulated_eval_time': 2219.5174429416656, 'accumulated_logging_time': 0.622840166091919, 'global_step': 29364, 'preemption_count': 0}), (30830, {'train/accuracy': 0.6215521364795918, 'train/loss': 1.8206841605050224, 'validation/accuracy': 0.57056, 'validation/loss': 2.06769046875, 'validation/num_examples': 50000, 'test/accuracy': 0.4427, 'test/loss': 2.738627734375, 'test/num_examples': 10000, 'score': 10739.473891019821, 'total_duration': 13112.960005760193, 'accumulated_submission_time': 10739.473891019821, 'accumulated_eval_time': 2316.9756231307983, 'accumulated_logging_time': 0.6508674621582031, 'global_step': 30830, 'preemption_count': 0}), (32311, {'train/accuracy': 0.6493542729591837, 'train/loss': 1.708731982172752, 'validation/accuracy': 0.59184, 'validation/loss': 1.96402828125, 'validation/num_examples': 50000, 'test/accuracy': 0.4698, 'test/loss': 2.63330546875, 'test/num_examples': 10000, 'score': 11247.923557043076, 'total_duration': 13722.49593758583, 'accumulated_submission_time': 11247.923557043076, 'accumulated_eval_time': 2415.5144810676575, 'accumulated_logging_time': 0.6806511878967285, 'global_step': 32311, 'preemption_count': 0}), (33787, {'train/accuracy': 0.6435347576530612, 'train/loss': 1.724915329290896, 'validation/accuracy': 0.59268, 'validation/loss': 1.9648675, 'validation/num_examples': 50000, 'test/accuracy': 0.4594, 'test/loss': 2.6620001953125, 'test/num_examples': 10000, 'score': 11756.360791921616, 'total_duration': 14330.981527805328, 'accumulated_submission_time': 11756.360791921616, 'accumulated_eval_time': 2513.0176084041595, 'accumulated_logging_time': 0.7097623348236084, 'global_step': 33787, 'preemption_count': 0}), (35268, {'train/accuracy': 0.5862165178571429, 'train/loss': 1.9849254063197546, 'validation/accuracy': 0.54216, 'validation/loss': 2.211795625, 'validation/num_examples': 50000, 'test/accuracy': 0.413, 'test/loss': 2.90699765625, 'test/num_examples': 10000, 'score': 12264.80813407898, 'total_duration': 14939.28597187996, 'accumulated_submission_time': 12264.80813407898, 'accumulated_eval_time': 2610.3426213264465, 'accumulated_logging_time': 0.7407073974609375, 'global_step': 35268, 'preemption_count': 0}), (36749, {'train/accuracy': 0.6332708864795918, 'train/loss': 1.7721071827168366, 'validation/accuracy': 0.58038, 'validation/loss': 2.00983140625, 'validation/num_examples': 50000, 'test/accuracy': 0.454, 'test/loss': 2.7004876953125, 'test/num_examples': 10000, 'score': 12773.20137166977, 'total_duration': 15547.718202352524, 'accumulated_submission_time': 12773.20137166977, 'accumulated_eval_time': 2707.767631292343, 'accumulated_logging_time': 0.7669270038604736, 'global_step': 36749, 'preemption_count': 0}), (38231, {'train/accuracy': 0.6286670918367347, 'train/loss': 1.7528034132354113, 'validation/accuracy': 0.57734, 'validation/loss': 1.9919565625, 'validation/num_examples': 50000, 'test/accuracy': 0.4451, 'test/loss': 2.7078625, 'test/num_examples': 10000, 'score': 13281.822976827621, 'total_duration': 16156.070827245712, 'accumulated_submission_time': 13281.822976827621, 'accumulated_eval_time': 2804.9374384880066, 'accumulated_logging_time': 0.7943735122680664, 'global_step': 38231, 'preemption_count': 0}), (39712, {'train/accuracy': 0.6512476084183674, 'train/loss': 1.6841346585020727, 'validation/accuracy': 0.59744, 'validation/loss': 1.9276578125, 'validation/num_examples': 50000, 'test/accuracy': 0.4567, 'test/loss': 2.664127734375, 'test/num_examples': 10000, 'score': 13790.505385875702, 'total_duration': 16764.351469278336, 'accumulated_submission_time': 13790.505385875702, 'accumulated_eval_time': 2901.895949602127, 'accumulated_logging_time': 0.8244600296020508, 'global_step': 39712, 'preemption_count': 0}), (41194, {'train/accuracy': 0.6590999681122449, 'train/loss': 1.6275346717055963, 'validation/accuracy': 0.60234, 'validation/loss': 1.89422546875, 'validation/num_examples': 50000, 'test/accuracy': 0.4731, 'test/loss': 2.5890517578125, 'test/num_examples': 10000, 'score': 14299.102891206741, 'total_duration': 17373.85334086418, 'accumulated_submission_time': 14299.102891206741, 'accumulated_eval_time': 3000.267299890518, 'accumulated_logging_time': 0.8528096675872803, 'global_step': 41194, 'preemption_count': 0}), (42672, {'train/accuracy': 0.6500916772959183, 'train/loss': 1.702062957140864, 'validation/accuracy': 0.59254, 'validation/loss': 1.96739921875, 'validation/num_examples': 50000, 'test/accuracy': 0.4684, 'test/loss': 2.627764453125, 'test/num_examples': 10000, 'score': 14807.709326982498, 'total_duration': 17982.94363808632, 'accumulated_submission_time': 14807.709326982498, 'accumulated_eval_time': 3098.1386892795563, 'accumulated_logging_time': 0.8843719959259033, 'global_step': 42672, 'preemption_count': 0}), (44146, {'train/accuracy': 0.6560108418367347, 'train/loss': 1.6276397705078125, 'validation/accuracy': 0.60274, 'validation/loss': 1.88520734375, 'validation/num_examples': 50000, 'test/accuracy': 0.4754, 'test/loss': 2.567808984375, 'test/num_examples': 10000, 'score': 15316.205023288727, 'total_duration': 18591.195024728775, 'accumulated_submission_time': 15316.205023288727, 'accumulated_eval_time': 3195.364699602127, 'accumulated_logging_time': 0.9136850833892822, 'global_step': 44146, 'preemption_count': 0}), (45607, {'train/accuracy': 0.6733298788265306, 'train/loss': 1.5344853303870376, 'validation/accuracy': 0.61354, 'validation/loss': 1.80135421875, 'validation/num_examples': 50000, 'test/accuracy': 0.4873, 'test/loss': 2.474778515625, 'test/num_examples': 10000, 'score': 15824.82373213768, 'total_duration': 19200.313976049423, 'accumulated_submission_time': 15824.82373213768, 'accumulated_eval_time': 3293.271233320236, 'accumulated_logging_time': 0.9405677318572998, 'global_step': 45607, 'preemption_count': 0}), (47088, {'train/accuracy': 0.6215122767857143, 'train/loss': 1.8686960959921077, 'validation/accuracy': 0.56562, 'validation/loss': 2.12230015625, 'validation/num_examples': 50000, 'test/accuracy': 0.4264, 'test/loss': 2.8546908203125, 'test/num_examples': 10000, 'score': 16333.285156726837, 'total_duration': 19810.44502711296, 'accumulated_submission_time': 16333.285156726837, 'accumulated_eval_time': 3392.2903673648834, 'accumulated_logging_time': 0.9696080684661865, 'global_step': 47088, 'preemption_count': 0}), (48570, {'train/accuracy': 0.6765186543367347, 'train/loss': 1.5396625752351722, 'validation/accuracy': 0.62284, 'validation/loss': 1.79409015625, 'validation/num_examples': 50000, 'test/accuracy': 0.4926, 'test/loss': 2.468009765625, 'test/num_examples': 10000, 'score': 16841.92125248909, 'total_duration': 20421.708201885223, 'accumulated_submission_time': 16841.92125248909, 'accumulated_eval_time': 3492.3094577789307, 'accumulated_logging_time': 0.9975521564483643, 'global_step': 48570, 'preemption_count': 0}), (50047, {'train/accuracy': 0.6688855229591837, 'train/loss': 1.5890923324896364, 'validation/accuracy': 0.60918, 'validation/loss': 1.84859765625, 'validation/num_examples': 50000, 'test/accuracy': 0.4702, 'test/loss': 2.5930892578125, 'test/num_examples': 10000, 'score': 17350.335282564163, 'total_duration': 21031.21148133278, 'accumulated_submission_time': 17350.335282564163, 'accumulated_eval_time': 3590.8148527145386, 'accumulated_logging_time': 1.0316252708435059, 'global_step': 50047, 'preemption_count': 0}), (51530, {'train/accuracy': 0.6559311224489796, 'train/loss': 1.6821876058773118, 'validation/accuracy': 0.59694, 'validation/loss': 1.943536875, 'validation/num_examples': 50000, 'test/accuracy': 0.4748, 'test/loss': 2.60391015625, 'test/num_examples': 10000, 'score': 17858.9150018692, 'total_duration': 21640.23606610298, 'accumulated_submission_time': 17858.9150018692, 'accumulated_eval_time': 3688.7329802513123, 'accumulated_logging_time': 1.0616331100463867, 'global_step': 51530, 'preemption_count': 0}), (53012, {'train/accuracy': 0.6407047193877551, 'train/loss': 1.7762989900550064, 'validation/accuracy': 0.58676, 'validation/loss': 2.040225625, 'validation/num_examples': 50000, 'test/accuracy': 0.4582, 'test/loss': 2.724531640625, 'test/num_examples': 10000, 'score': 18367.534528255463, 'total_duration': 22249.918818712234, 'accumulated_submission_time': 18367.534528255463, 'accumulated_eval_time': 3787.2259769439697, 'accumulated_logging_time': 1.0911426544189453, 'global_step': 53012, 'preemption_count': 0}), (54494, {'train/accuracy': 0.682258450255102, 'train/loss': 1.5294913467095823, 'validation/accuracy': 0.62002, 'validation/loss': 1.79784328125, 'validation/num_examples': 50000, 'test/accuracy': 0.4885, 'test/loss': 2.493837890625, 'test/num_examples': 10000, 'score': 18875.995351076126, 'total_duration': 22859.131870746613, 'accumulated_submission_time': 18875.995351076126, 'accumulated_eval_time': 3885.407393217087, 'accumulated_logging_time': 1.122931957244873, 'global_step': 54494, 'preemption_count': 0}), (55975, {'train/accuracy': 0.6935985331632653, 'train/loss': 1.4933748829121491, 'validation/accuracy': 0.6302, 'validation/loss': 1.7671353125, 'validation/num_examples': 50000, 'test/accuracy': 0.5001, 'test/loss': 2.4519333984375, 'test/num_examples': 10000, 'score': 19384.44639134407, 'total_duration': 23467.646543979645, 'accumulated_submission_time': 19384.44639134407, 'accumulated_eval_time': 3982.9139366149902, 'accumulated_logging_time': 1.1527066230773926, 'global_step': 55975, 'preemption_count': 0}), (57457, {'train/accuracy': 0.6787109375, 'train/loss': 1.5602787562779017, 'validation/accuracy': 0.61126, 'validation/loss': 1.84603578125, 'validation/num_examples': 50000, 'test/accuracy': 0.4748, 'test/loss': 2.573128125, 'test/num_examples': 10000, 'score': 19892.948302984238, 'total_duration': 24077.130212783813, 'accumulated_submission_time': 19892.948302984238, 'accumulated_eval_time': 4081.2929215431213, 'accumulated_logging_time': 1.1879127025604248, 'global_step': 57457, 'preemption_count': 0}), (58931, {'train/accuracy': 0.7042410714285714, 'train/loss': 1.4288780056700414, 'validation/accuracy': 0.63958, 'validation/loss': 1.71388984375, 'validation/num_examples': 50000, 'test/accuracy': 0.5109, 'test/loss': 2.3777328125, 'test/num_examples': 10000, 'score': 20401.332453012466, 'total_duration': 24685.353937387466, 'accumulated_submission_time': 20401.332453012466, 'accumulated_eval_time': 4178.57156252861, 'accumulated_logging_time': 1.218522310256958, 'global_step': 58931, 'preemption_count': 0}), (60387, {'train/accuracy': 0.6683075573979592, 'train/loss': 1.6305068658322703, 'validation/accuracy': 0.6088, 'validation/loss': 1.89196734375, 'validation/num_examples': 50000, 'test/accuracy': 0.467, 'test/loss': 2.6293958984375, 'test/num_examples': 10000, 'score': 20909.727929115295, 'total_duration': 25293.446808576584, 'accumulated_submission_time': 20909.727929115295, 'accumulated_eval_time': 4275.768449544907, 'accumulated_logging_time': 1.2514212131500244, 'global_step': 60387, 'preemption_count': 0}), (61869, {'train/accuracy': 0.6826371173469388, 'train/loss': 1.527248460419324, 'validation/accuracy': 0.61796, 'validation/loss': 1.8052246875, 'validation/num_examples': 50000, 'test/accuracy': 0.4845, 'test/loss': 2.503884375, 'test/num_examples': 10000, 'score': 21418.337881565094, 'total_duration': 25902.122715234756, 'accumulated_submission_time': 21418.337881565094, 'accumulated_eval_time': 4373.27636551857, 'accumulated_logging_time': 1.2790701389312744, 'global_step': 61869, 'preemption_count': 0}), (63351, {'train/accuracy': 0.6777543048469388, 'train/loss': 1.5694650143993145, 'validation/accuracy': 0.61524, 'validation/loss': 1.841921875, 'validation/num_examples': 50000, 'test/accuracy': 0.4949, 'test/loss': 2.4961787109375, 'test/num_examples': 10000, 'score': 21926.92738676071, 'total_duration': 26510.414823055267, 'accumulated_submission_time': 21926.92738676071, 'accumulated_eval_time': 4470.356500387192, 'accumulated_logging_time': 1.3085238933563232, 'global_step': 63351, 'preemption_count': 0}), (64833, {'train/accuracy': 0.6993383290816326, 'train/loss': 1.4659992140166613, 'validation/accuracy': 0.63604, 'validation/loss': 1.73947234375, 'validation/num_examples': 50000, 'test/accuracy': 0.5055, 'test/loss': 2.4004876953125, 'test/num_examples': 10000, 'score': 22435.454740524292, 'total_duration': 27119.50536584854, 'accumulated_submission_time': 22435.454740524292, 'accumulated_eval_time': 4568.315970659256, 'accumulated_logging_time': 1.3373308181762695, 'global_step': 64833, 'preemption_count': 0}), (66310, {'train/accuracy': 0.6773955676020408, 'train/loss': 1.573835411850287, 'validation/accuracy': 0.61164, 'validation/loss': 1.86709125, 'validation/num_examples': 50000, 'test/accuracy': 0.469, 'test/loss': 2.6275625, 'test/num_examples': 10000, 'score': 22943.990533828735, 'total_duration': 27728.727930545807, 'accumulated_submission_time': 22943.990533828735, 'accumulated_eval_time': 4666.358915805817, 'accumulated_logging_time': 1.3680715560913086, 'global_step': 66310, 'preemption_count': 0}), (67792, {'train/accuracy': 0.7054767219387755, 'train/loss': 1.4393886644013074, 'validation/accuracy': 0.64126, 'validation/loss': 1.7216865625, 'validation/num_examples': 50000, 'test/accuracy': 0.5079, 'test/loss': 2.4018365234375, 'test/num_examples': 10000, 'score': 23452.494542121887, 'total_duration': 28339.064655780792, 'accumulated_submission_time': 23452.494542121887, 'accumulated_eval_time': 4765.642017841339, 'accumulated_logging_time': 1.399017095565796, 'global_step': 67792, 'preemption_count': 0}), (69274, {'train/accuracy': 0.6935188137755102, 'train/loss': 1.48189420116191, 'validation/accuracy': 0.62898, 'validation/loss': 1.76504390625, 'validation/num_examples': 50000, 'test/accuracy': 0.4917, 'test/loss': 2.4804552734375, 'test/num_examples': 10000, 'score': 23960.92461681366, 'total_duration': 28947.66376209259, 'accumulated_submission_time': 23960.92461681366, 'accumulated_eval_time': 4863.2828323841095, 'accumulated_logging_time': 1.429076910018921, 'global_step': 69274, 'preemption_count': 0}), (70755, {'train/accuracy': 0.7146444515306123, 'train/loss': 1.402004319794324, 'validation/accuracy': 0.64654, 'validation/loss': 1.70901375, 'validation/num_examples': 50000, 'test/accuracy': 0.503, 'test/loss': 2.4030125, 'test/num_examples': 10000, 'score': 24469.44401192665, 'total_duration': 29555.573780298233, 'accumulated_submission_time': 24469.44401192665, 'accumulated_eval_time': 4960.034102678299, 'accumulated_logging_time': 1.4584693908691406, 'global_step': 70755, 'preemption_count': 0}), (72236, {'train/accuracy': 0.6947544642857143, 'train/loss': 1.4518782946528221, 'validation/accuracy': 0.62866, 'validation/loss': 1.75276671875, 'validation/num_examples': 50000, 'test/accuracy': 0.5021, 'test/loss': 2.4525646484375, 'test/num_examples': 10000, 'score': 24977.93445801735, 'total_duration': 30164.51622581482, 'accumulated_submission_time': 24977.93445801735, 'accumulated_eval_time': 5057.901740312576, 'accumulated_logging_time': 1.4876902103424072, 'global_step': 72236, 'preemption_count': 0}), (73718, {'train/accuracy': 0.7057158801020408, 'train/loss': 1.3906905505121971, 'validation/accuracy': 0.6428, 'validation/loss': 1.68640703125, 'validation/num_examples': 50000, 'test/accuracy': 0.5091, 'test/loss': 2.357803125, 'test/num_examples': 10000, 'score': 25486.355399370193, 'total_duration': 30772.83870267868, 'accumulated_submission_time': 25486.355399370193, 'accumulated_eval_time': 5155.223183393478, 'accumulated_logging_time': 1.5201835632324219, 'global_step': 73718, 'preemption_count': 0}), (75196, {'train/accuracy': 0.7043606505102041, 'train/loss': 1.4372384207589286, 'validation/accuracy': 0.63842, 'validation/loss': 1.7249596875, 'validation/num_examples': 50000, 'test/accuracy': 0.5045, 'test/loss': 2.390778515625, 'test/num_examples': 10000, 'score': 25994.948875665665, 'total_duration': 31381.83448410034, 'accumulated_submission_time': 25994.948875665665, 'accumulated_eval_time': 5253.0885989665985, 'accumulated_logging_time': 1.55320405960083, 'global_step': 75196, 'preemption_count': 0}), (76678, {'train/accuracy': 0.7145248724489796, 'train/loss': 1.4213110476124042, 'validation/accuracy': 0.6466, 'validation/loss': 1.71978625, 'validation/num_examples': 50000, 'test/accuracy': 0.5117, 'test/loss': 2.4135134765625, 'test/num_examples': 10000, 'score': 26503.557284116745, 'total_duration': 31990.263199329376, 'accumulated_submission_time': 26503.557284116745, 'accumulated_eval_time': 5350.322155952454, 'accumulated_logging_time': 1.5856475830078125, 'global_step': 76678, 'preemption_count': 0}), (78159, {'train/accuracy': 0.7264827806122449, 'train/loss': 1.2979058246223294, 'validation/accuracy': 0.65736, 'validation/loss': 1.60734390625, 'validation/num_examples': 50000, 'test/accuracy': 0.5228, 'test/loss': 2.2689185546875, 'test/num_examples': 10000, 'score': 27012.015036582947, 'total_duration': 32600.658908843994, 'accumulated_submission_time': 27012.015036582947, 'accumulated_eval_time': 5449.706401348114, 'accumulated_logging_time': 1.6201927661895752, 'global_step': 78159, 'preemption_count': 0}), (79641, {'train/accuracy': 0.7106983418367347, 'train/loss': 1.3923855217135683, 'validation/accuracy': 0.64326, 'validation/loss': 1.702126875, 'validation/num_examples': 50000, 'test/accuracy': 0.5162, 'test/loss': 2.3826181640625, 'test/num_examples': 10000, 'score': 27520.58672785759, 'total_duration': 33209.19947099686, 'accumulated_submission_time': 27520.58672785759, 'accumulated_eval_time': 5547.082329750061, 'accumulated_logging_time': 1.6490223407745361, 'global_step': 79641, 'preemption_count': 0}), (81122, {'train/accuracy': 0.7074896364795918, 'train/loss': 1.4563586176658163, 'validation/accuracy': 0.6397, 'validation/loss': 1.75911375, 'validation/num_examples': 50000, 'test/accuracy': 0.5033, 'test/loss': 2.47553203125, 'test/num_examples': 10000, 'score': 28028.944851875305, 'total_duration': 33817.73270916939, 'accumulated_submission_time': 28028.944851875305, 'accumulated_eval_time': 5644.644223213196, 'accumulated_logging_time': 1.6792192459106445, 'global_step': 81122, 'preemption_count': 0}), (82599, {'train/accuracy': 0.7328404017857143, 'train/loss': 1.352513838787468, 'validation/accuracy': 0.65754, 'validation/loss': 1.67375796875, 'validation/num_examples': 50000, 'test/accuracy': 0.5229, 'test/loss': 2.3591572265625, 'test/num_examples': 10000, 'score': 28537.31317448616, 'total_duration': 34426.90508675575, 'accumulated_submission_time': 28537.31317448616, 'accumulated_eval_time': 5742.879645586014, 'accumulated_logging_time': 1.7108471393585205, 'global_step': 82599, 'preemption_count': 0}), (84081, {'train/accuracy': 0.7400550063775511, 'train/loss': 1.283956800188337, 'validation/accuracy': 0.66616, 'validation/loss': 1.60633515625, 'validation/num_examples': 50000, 'test/accuracy': 0.5298, 'test/loss': 2.28925078125, 'test/num_examples': 10000, 'score': 29045.749613761902, 'total_duration': 35035.92700266838, 'accumulated_submission_time': 29045.749613761902, 'accumulated_eval_time': 5840.924386978149, 'accumulated_logging_time': 1.7425103187561035, 'global_step': 84081, 'preemption_count': 0}), (85564, {'train/accuracy': 0.7429249043367347, 'train/loss': 1.327070275131537, 'validation/accuracy': 0.66402, 'validation/loss': 1.66108, 'validation/num_examples': 50000, 'test/accuracy': 0.5498, 'test/loss': 2.2545830078125, 'test/num_examples': 10000, 'score': 29554.410472154617, 'total_duration': 35644.68516111374, 'accumulated_submission_time': 29554.410472154617, 'accumulated_eval_time': 5938.510777711868, 'accumulated_logging_time': 1.7750868797302246, 'global_step': 85564, 'preemption_count': 0}), (87045, {'train/accuracy': 0.7329599808673469, 'train/loss': 1.3165259847835618, 'validation/accuracy': 0.66028, 'validation/loss': 1.64611875, 'validation/num_examples': 50000, 'test/accuracy': 0.5176, 'test/loss': 2.33102109375, 'test/num_examples': 10000, 'score': 30063.101960897446, 'total_duration': 36254.49019789696, 'accumulated_submission_time': 30063.101960897446, 'accumulated_eval_time': 6036.981278419495, 'accumulated_logging_time': 1.8059322834014893, 'global_step': 87045, 'preemption_count': 0}), (88527, {'train/accuracy': 0.7481863839285714, 'train/loss': 1.232894975311902, 'validation/accuracy': 0.67182, 'validation/loss': 1.55924671875, 'validation/num_examples': 50000, 'test/accuracy': 0.5324, 'test/loss': 2.2488544921875, 'test/num_examples': 10000, 'score': 30571.56608223915, 'total_duration': 36863.23563814163, 'accumulated_submission_time': 30571.56608223915, 'accumulated_eval_time': 6134.640651464462, 'accumulated_logging_time': 1.841278314590454, 'global_step': 88527, 'preemption_count': 0}), (90009, {'train/accuracy': 0.7430644132653061, 'train/loss': 1.2530925517179528, 'validation/accuracy': 0.66584, 'validation/loss': 1.584465625, 'validation/num_examples': 50000, 'test/accuracy': 0.5344, 'test/loss': 2.243312890625, 'test/num_examples': 10000, 'score': 31080.117062568665, 'total_duration': 37472.59866666794, 'accumulated_submission_time': 31080.117062568665, 'accumulated_eval_time': 6232.858266115189, 'accumulated_logging_time': 1.8729259967803955, 'global_step': 90009, 'preemption_count': 0}), (91486, {'train/accuracy': 0.7598852040816326, 'train/loss': 1.213304480727838, 'validation/accuracy': 0.67926, 'validation/loss': 1.55280046875, 'validation/num_examples': 50000, 'test/accuracy': 0.5413, 'test/loss': 2.2443806640625, 'test/num_examples': 10000, 'score': 31588.729876756668, 'total_duration': 38082.752670288086, 'accumulated_submission_time': 31588.729876756668, 'accumulated_eval_time': 6331.877485513687, 'accumulated_logging_time': 1.9020140171051025, 'global_step': 91486, 'preemption_count': 0}), (92967, {'train/accuracy': 0.7352120535714286, 'train/loss': 1.3095102115553252, 'validation/accuracy': 0.66134, 'validation/loss': 1.63147203125, 'validation/num_examples': 50000, 'test/accuracy': 0.5272, 'test/loss': 2.321180859375, 'test/num_examples': 10000, 'score': 32097.136334896088, 'total_duration': 38691.19542336464, 'accumulated_submission_time': 32097.136334896088, 'accumulated_eval_time': 6429.315256118774, 'accumulated_logging_time': 1.9345448017120361, 'global_step': 92967, 'preemption_count': 0}), (94449, {'train/accuracy': 0.7669005102040817, 'train/loss': 1.1832038723692602, 'validation/accuracy': 0.68684, 'validation/loss': 1.51809984375, 'validation/num_examples': 50000, 'test/accuracy': 0.551, 'test/loss': 2.2011921875, 'test/num_examples': 10000, 'score': 32605.614151716232, 'total_duration': 39299.97207760811, 'accumulated_submission_time': 32605.614151716232, 'accumulated_eval_time': 6527.077110528946, 'accumulated_logging_time': 1.9651179313659668, 'global_step': 94449, 'preemption_count': 0}), (95931, {'train/accuracy': 0.7582708864795918, 'train/loss': 1.1810301177355709, 'validation/accuracy': 0.67742, 'validation/loss': 1.5409053125, 'validation/num_examples': 50000, 'test/accuracy': 0.5357, 'test/loss': 2.230510546875, 'test/num_examples': 10000, 'score': 33114.18256998062, 'total_duration': 39909.33941435814, 'accumulated_submission_time': 33114.18256998062, 'accumulated_eval_time': 6625.326530456543, 'accumulated_logging_time': 1.9954414367675781, 'global_step': 95931, 'preemption_count': 0}), (97413, {'train/accuracy': 0.7436822385204082, 'train/loss': 1.2725300691565689, 'validation/accuracy': 0.66398, 'validation/loss': 1.6241840625, 'validation/num_examples': 50000, 'test/accuracy': 0.5254, 'test/loss': 2.3220599609375, 'test/num_examples': 10000, 'score': 33622.597786188126, 'total_duration': 40517.80060458183, 'accumulated_submission_time': 33622.597786188126, 'accumulated_eval_time': 6722.831171274185, 'accumulated_logging_time': 2.0279529094696045, 'global_step': 97413, 'preemption_count': 0}), (98889, {'train/accuracy': 0.7581513073979592, 'train/loss': 1.1633832503338248, 'validation/accuracy': 0.67548, 'validation/loss': 1.5260815625, 'validation/num_examples': 50000, 'test/accuracy': 0.538, 'test/loss': 2.21258046875, 'test/num_examples': 10000, 'score': 34131.01906657219, 'total_duration': 41127.082184791565, 'accumulated_submission_time': 34131.01906657219, 'accumulated_eval_time': 6821.148615121841, 'accumulated_logging_time': 2.058075189590454, 'global_step': 98889, 'preemption_count': 0}), (100370, {'train/accuracy': 0.7875876913265306, 'train/loss': 1.0914313647211815, 'validation/accuracy': 0.7016, 'validation/loss': 1.44902921875, 'validation/num_examples': 50000, 'test/accuracy': 0.5652, 'test/loss': 2.0911990234375, 'test/num_examples': 10000, 'score': 34639.38508939743, 'total_duration': 41735.45819926262, 'accumulated_submission_time': 34639.38508939743, 'accumulated_eval_time': 6918.595190048218, 'accumulated_logging_time': 2.091195821762085, 'global_step': 100370, 'preemption_count': 0}), (101852, {'train/accuracy': 0.7821867028061225, 'train/loss': 1.0890828346719548, 'validation/accuracy': 0.69464, 'validation/loss': 1.458545, 'validation/num_examples': 50000, 'test/accuracy': 0.5636, 'test/loss': 2.101974609375, 'test/num_examples': 10000, 'score': 35147.94639635086, 'total_duration': 42344.76590061188, 'accumulated_submission_time': 35147.94639635086, 'accumulated_eval_time': 7016.786299467087, 'accumulated_logging_time': 2.1225504875183105, 'global_step': 101852, 'preemption_count': 0}), (103334, {'train/accuracy': 0.7948222257653061, 'train/loss': 1.0333144518793846, 'validation/accuracy': 0.70436, 'validation/loss': 1.41006375, 'validation/num_examples': 50000, 'test/accuracy': 0.5675, 'test/loss': 2.0741484375, 'test/num_examples': 10000, 'score': 35656.47154355049, 'total_duration': 42954.27954530716, 'accumulated_submission_time': 35656.47154355049, 'accumulated_eval_time': 7115.185396194458, 'accumulated_logging_time': 2.1527843475341797, 'global_step': 103334, 'preemption_count': 0}), (104815, {'train/accuracy': 0.7972935267857143, 'train/loss': 1.0010174342564173, 'validation/accuracy': 0.70666, 'validation/loss': 1.388778125, 'validation/num_examples': 50000, 'test/accuracy': 0.578, 'test/loss': 2.04301953125, 'test/num_examples': 10000, 'score': 36165.05555438995, 'total_duration': 43563.50169682503, 'accumulated_submission_time': 36165.05555438995, 'accumulated_eval_time': 7213.2179255485535, 'accumulated_logging_time': 2.184286594390869, 'global_step': 104815, 'preemption_count': 0}), (106296, {'train/accuracy': 0.7924904336734694, 'train/loss': 1.0111893634406888, 'validation/accuracy': 0.70196, 'validation/loss': 1.40027671875, 'validation/num_examples': 50000, 'test/accuracy': 0.5795, 'test/loss': 2.04285234375, 'test/num_examples': 10000, 'score': 36673.52972269058, 'total_duration': 44172.97391963005, 'accumulated_submission_time': 36673.52972269058, 'accumulated_eval_time': 7311.6480884552, 'accumulated_logging_time': 2.217869997024536, 'global_step': 106296, 'preemption_count': 0}), (107773, {'train/accuracy': 0.8122807716836735, 'train/loss': 0.9815306371572067, 'validation/accuracy': 0.71502, 'validation/loss': 1.38583625, 'validation/num_examples': 50000, 'test/accuracy': 0.5692, 'test/loss': 2.0839748046875, 'test/num_examples': 10000, 'score': 37182.13071346283, 'total_duration': 44782.42561340332, 'accumulated_submission_time': 37182.13071346283, 'accumulated_eval_time': 7409.950815677643, 'accumulated_logging_time': 2.2533953189849854, 'global_step': 107773, 'preemption_count': 0}), (109255, {'train/accuracy': 0.8193957270408163, 'train/loss': 0.9411143088827327, 'validation/accuracy': 0.71856, 'validation/loss': 1.3496496875, 'validation/num_examples': 50000, 'test/accuracy': 0.5894, 'test/loss': 1.9864841796875, 'test/num_examples': 10000, 'score': 37690.652612924576, 'total_duration': 45392.066886901855, 'accumulated_submission_time': 37690.652612924576, 'accumulated_eval_time': 7508.476343870163, 'accumulated_logging_time': 2.2839419841766357, 'global_step': 109255, 'preemption_count': 0}), (110737, {'train/accuracy': 0.8084941007653061, 'train/loss': 0.9723913231674506, 'validation/accuracy': 0.70758, 'validation/loss': 1.398665625, 'validation/num_examples': 50000, 'test/accuracy': 0.5765, 'test/loss': 2.070410546875, 'test/num_examples': 10000, 'score': 38199.252210855484, 'total_duration': 46002.43743228912, 'accumulated_submission_time': 38199.252210855484, 'accumulated_eval_time': 7607.734683036804, 'accumulated_logging_time': 2.316112756729126, 'global_step': 110737, 'preemption_count': 0}), (112219, {'train/accuracy': 0.8267299107142857, 'train/loss': 0.9142226394341917, 'validation/accuracy': 0.7207, 'validation/loss': 1.3367284375, 'validation/num_examples': 50000, 'test/accuracy': 0.5769, 'test/loss': 2.0445177734375, 'test/num_examples': 10000, 'score': 38707.75090289116, 'total_duration': 46612.16760802269, 'accumulated_submission_time': 38707.75090289116, 'accumulated_eval_time': 7706.474244356155, 'accumulated_logging_time': 2.3480684757232666, 'global_step': 112219, 'preemption_count': 0}), (113700, {'train/accuracy': 0.8360570790816326, 'train/loss': 0.837928227015904, 'validation/accuracy': 0.7285, 'validation/loss': 1.271760703125, 'validation/num_examples': 50000, 'test/accuracy': 0.5909, 'test/loss': 1.9631546875, 'test/num_examples': 10000, 'score': 39216.24927473068, 'total_duration': 47221.358583927155, 'accumulated_submission_time': 39216.24927473068, 'accumulated_eval_time': 7804.569121599197, 'accumulated_logging_time': 2.381819248199463, 'global_step': 113700, 'preemption_count': 0}), (115178, {'train/accuracy': 0.8425542091836735, 'train/loss': 0.8308460469148597, 'validation/accuracy': 0.73246, 'validation/loss': 1.285781484375, 'validation/num_examples': 50000, 'test/accuracy': 0.5984, 'test/loss': 1.959775390625, 'test/num_examples': 10000, 'score': 39724.714393138885, 'total_duration': 47830.74952673912, 'accumulated_submission_time': 39724.714393138885, 'accumulated_eval_time': 7902.920233249664, 'accumulated_logging_time': 2.413299083709717, 'global_step': 115178, 'preemption_count': 0}), (116661, {'train/accuracy': 0.8415776466836735, 'train/loss': 0.8580317594567124, 'validation/accuracy': 0.72896, 'validation/loss': 1.32139328125, 'validation/num_examples': 50000, 'test/accuracy': 0.5967, 'test/loss': 1.976644140625, 'test/num_examples': 10000, 'score': 40233.29963469505, 'total_duration': 48439.501412153244, 'accumulated_submission_time': 40233.29963469505, 'accumulated_eval_time': 8000.520615816116, 'accumulated_logging_time': 2.4474093914031982, 'global_step': 116661, 'preemption_count': 0}), (118143, {'train/accuracy': 0.8604113520408163, 'train/loss': 0.7499905021823182, 'validation/accuracy': 0.74354, 'validation/loss': 1.225137578125, 'validation/num_examples': 50000, 'test/accuracy': 0.6119, 'test/loss': 1.8889380859375, 'test/num_examples': 10000, 'score': 40741.797372341156, 'total_duration': 49048.60029196739, 'accumulated_submission_time': 40741.797372341156, 'accumulated_eval_time': 8098.546944141388, 'accumulated_logging_time': 2.480238199234009, 'global_step': 118143, 'preemption_count': 0}), (119625, {'train/accuracy': 0.8644371811224489, 'train/loss': 0.7429367376833546, 'validation/accuracy': 0.74206, 'validation/loss': 1.2332734375, 'validation/num_examples': 50000, 'test/accuracy': 0.6023, 'test/loss': 1.9187119140625, 'test/num_examples': 10000, 'score': 41250.24692440033, 'total_duration': 49656.96551537514, 'accumulated_submission_time': 41250.24692440033, 'accumulated_eval_time': 8195.860199213028, 'accumulated_logging_time': 2.5120468139648438, 'global_step': 119625, 'preemption_count': 0}), (121108, {'train/accuracy': 0.8769331951530612, 'train/loss': 0.7009070260184151, 'validation/accuracy': 0.7511, 'validation/loss': 1.19952140625, 'validation/num_examples': 50000, 'test/accuracy': 0.6162, 'test/loss': 1.850906640625, 'test/num_examples': 10000, 'score': 41758.93402338028, 'total_duration': 50267.23975610733, 'accumulated_submission_time': 41758.93402338028, 'accumulated_eval_time': 8294.873284816742, 'accumulated_logging_time': 2.5419437885284424, 'global_step': 121108, 'preemption_count': 0}), (122591, {'train/accuracy': 0.8881138392857143, 'train/loss': 0.6610058375767299, 'validation/accuracy': 0.76014, 'validation/loss': 1.174136171875, 'validation/num_examples': 50000, 'test/accuracy': 0.6272, 'test/loss': 1.8209953125, 'test/num_examples': 10000, 'score': 42267.46894669533, 'total_duration': 50876.85193657875, 'accumulated_submission_time': 42267.46894669533, 'accumulated_eval_time': 8393.389695882797, 'accumulated_logging_time': 2.5801351070404053, 'global_step': 122591, 'preemption_count': 0}), (124068, {'train/accuracy': 0.8996930803571429, 'train/loss': 0.6147424736801459, 'validation/accuracy': 0.76778, 'validation/loss': 1.14217875, 'validation/num_examples': 50000, 'test/accuracy': 0.6306, 'test/loss': 1.7808302734375, 'test/num_examples': 10000, 'score': 42775.983882665634, 'total_duration': 51486.0146279335, 'accumulated_submission_time': 42775.983882665634, 'accumulated_eval_time': 8491.387544870377, 'accumulated_logging_time': 2.613130569458008, 'global_step': 124068, 'preemption_count': 0}), (125549, {'train/accuracy': 0.9067083864795918, 'train/loss': 0.5877799209283323, 'validation/accuracy': 0.77282, 'validation/loss': 1.1275253125, 'validation/num_examples': 50000, 'test/accuracy': 0.6407, 'test/loss': 1.7580869140625, 'test/num_examples': 10000, 'score': 43284.41992068291, 'total_duration': 52094.43017458916, 'accumulated_submission_time': 43284.41992068291, 'accumulated_eval_time': 8588.787898540497, 'accumulated_logging_time': 2.647573709487915, 'global_step': 125549, 'preemption_count': 0}), (127032, {'train/accuracy': 0.9132653061224489, 'train/loss': 0.5630088339046556, 'validation/accuracy': 0.776, 'validation/loss': 1.1093646875, 'validation/num_examples': 50000, 'test/accuracy': 0.6457, 'test/loss': 1.746294921875, 'test/num_examples': 10000, 'score': 43793.04886460304, 'total_duration': 52703.79640293121, 'accumulated_submission_time': 43793.04886460304, 'accumulated_eval_time': 8686.953979253769, 'accumulated_logging_time': 2.6815497875213623, 'global_step': 127032, 'preemption_count': 0}), (128514, {'train/accuracy': 0.9143215880102041, 'train/loss': 0.5543618883405413, 'validation/accuracy': 0.7772, 'validation/loss': 1.1008584375, 'validation/num_examples': 50000, 'test/accuracy': 0.647, 'test/loss': 1.7333802734375, 'test/num_examples': 10000, 'score': 44301.551661491394, 'total_duration': 53312.194628953934, 'accumulated_submission_time': 44301.551661491394, 'accumulated_eval_time': 8784.248070716858, 'accumulated_logging_time': 2.7169041633605957, 'global_step': 128514, 'preemption_count': 0}), (129997, {'train/accuracy': 0.9150589923469388, 'train/loss': 0.5568700128672074, 'validation/accuracy': 0.77688, 'validation/loss': 1.1059775, 'validation/num_examples': 50000, 'test/accuracy': 0.6436, 'test/loss': 1.747789453125, 'test/num_examples': 10000, 'score': 44810.124940633774, 'total_duration': 53921.6358935833, 'accumulated_submission_time': 44810.124940633774, 'accumulated_eval_time': 8882.506386995316, 'accumulated_logging_time': 2.7478830814361572, 'global_step': 129997, 'preemption_count': 0}), (131475, {'train/accuracy': 0.9149792729591837, 'train/loss': 0.5507438426115074, 'validation/accuracy': 0.77678, 'validation/loss': 1.101820703125, 'validation/num_examples': 50000, 'test/accuracy': 0.644, 'test/loss': 1.741523046875, 'test/num_examples': 10000, 'score': 45318.65207242966, 'total_duration': 54530.66124892235, 'accumulated_submission_time': 45318.65207242966, 'accumulated_eval_time': 8980.400998830795, 'accumulated_logging_time': 2.7816193103790283, 'global_step': 131475, 'preemption_count': 0}), (132958, {'train/accuracy': 0.9150390625, 'train/loss': 0.5541359648412588, 'validation/accuracy': 0.77732, 'validation/loss': 1.10516828125, 'validation/num_examples': 50000, 'test/accuracy': 0.6442, 'test/loss': 1.7455205078125, 'test/num_examples': 10000, 'score': 45827.2147693634, 'total_duration': 55138.91485786438, 'accumulated_submission_time': 45827.2147693634, 'accumulated_eval_time': 9077.556076526642, 'accumulated_logging_time': 2.815622568130493, 'global_step': 132958, 'preemption_count': 0}), (134440, {'train/accuracy': 0.9160554846938775, 'train/loss': 0.5545257256955517, 'validation/accuracy': 0.77738, 'validation/loss': 1.107788359375, 'validation/num_examples': 50000, 'test/accuracy': 0.6428, 'test/loss': 1.7522775390625, 'test/num_examples': 10000, 'score': 46335.59037256241, 'total_duration': 55748.42243742943, 'accumulated_submission_time': 46335.59037256241, 'accumulated_eval_time': 9176.160999774933, 'accumulated_logging_time': 2.8491079807281494, 'global_step': 134440, 'preemption_count': 0}), (135922, {'train/accuracy': 0.9161551339285714, 'train/loss': 0.5428472246442523, 'validation/accuracy': 0.77804, 'validation/loss': 1.09486046875, 'validation/num_examples': 50000, 'test/accuracy': 0.6435, 'test/loss': 1.7377451171875, 'test/num_examples': 10000, 'score': 46843.968055963516, 'total_duration': 56358.26499629021, 'accumulated_submission_time': 46843.968055963516, 'accumulated_eval_time': 9275.042012929916, 'accumulated_logging_time': 2.8817646503448486, 'global_step': 135922, 'preemption_count': 0}), (137404, {'train/accuracy': 0.9159757653061225, 'train/loss': 0.5429121134232502, 'validation/accuracy': 0.77764, 'validation/loss': 1.0952590625, 'validation/num_examples': 50000, 'test/accuracy': 0.6454, 'test/loss': 1.73577109375, 'test/num_examples': 10000, 'score': 47352.309515953064, 'total_duration': 56968.466680288315, 'accumulated_submission_time': 47352.309515953064, 'accumulated_eval_time': 9374.272126197815, 'accumulated_logging_time': 2.918630361557007, 'global_step': 137404, 'preemption_count': 0}), (138881, {'train/accuracy': 0.9167530293367347, 'train/loss': 0.5477877247090243, 'validation/accuracy': 0.77794, 'validation/loss': 1.101368046875, 'validation/num_examples': 50000, 'test/accuracy': 0.6449, 'test/loss': 1.7456314453125, 'test/num_examples': 10000, 'score': 47860.87314724922, 'total_duration': 57578.10950231552, 'accumulated_submission_time': 47860.87314724922, 'accumulated_eval_time': 9472.857727527618, 'accumulated_logging_time': 2.95082950592041, 'global_step': 138881, 'preemption_count': 0}), (140000, {'train/accuracy': 0.9174306441326531, 'train/loss': 0.5512791069186463, 'validation/accuracy': 0.77784, 'validation/loss': 1.107318671875, 'validation/num_examples': 50000, 'test/accuracy': 0.6462, 'test/loss': 1.7462333984375, 'test/num_examples': 10000, 'score': 48243.38105273247, 'total_duration': 58060.4455780983, 'accumulated_submission_time': 48243.38105273247, 'accumulated_eval_time': 9570.393196344376, 'accumulated_logging_time': 2.9877519607543945, 'global_step': 140000, 'preemption_count': 0})], 'global_step': 140000}
I0914 23:35:30.852870 139834269067072 submission_runner.py:543] Timing: 48243.38105273247
I0914 23:35:30.852920 139834269067072 submission_runner.py:545] Total number of evals: 96
I0914 23:35:30.852962 139834269067072 submission_runner.py:546] ====================
I0914 23:35:30.853162 139834269067072 submission_runner.py:614] Final imagenet_resnet score: 48243.38105273247
