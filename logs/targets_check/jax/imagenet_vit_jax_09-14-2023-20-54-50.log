python3 submission_runner.py --framework=jax --workload=imagenet_vit --submission_path=reference_algorithms/target_setting_algorithms/jax_nadamw.py --tuning_search_space=reference_algorithms/target_setting_algorithms/imagenet_vit/tuning_search_space.json --data_dir=/data/imagenet/jax --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=targets_check_jax/nadamw_run_0 --overwrite=true --save_checkpoints=false --max_global_steps=140000 --imagenet_v2_data_dir=/data/imagenet/jax 2>&1 | tee -a /logs/imagenet_vit_jax_09-14-2023-20-54-50.log
2023-09-14 20:54:55.372926: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
I0914 20:55:13.766651 140537819772736 logger_utils.py:76] Creating experiment directory at /experiment_runs/targets_check_jax/nadamw_run_0/imagenet_vit_jax.
I0914 20:55:14.777113 140537819772736 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Host Interpreter CUDA
I0914 20:55:14.778661 140537819772736 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0914 20:55:14.778839 140537819772736 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0914 20:55:14.783745 140537819772736 submission_runner.py:500] Using RNG seed 4188252565
I0914 20:55:20.617099 140537819772736 submission_runner.py:509] --- Tuning run 1/1 ---
I0914 20:55:20.617321 140537819772736 submission_runner.py:514] Creating tuning directory at /experiment_runs/targets_check_jax/nadamw_run_0/imagenet_vit_jax/trial_1.
I0914 20:55:20.617518 140537819772736 logger_utils.py:92] Saving hparams to /experiment_runs/targets_check_jax/nadamw_run_0/imagenet_vit_jax/trial_1/hparams.json.
I0914 20:55:20.800808 140537819772736 submission_runner.py:185] Initializing dataset.
I0914 20:55:20.816766 140537819772736 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0914 20:55:20.826972 140537819772736 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0914 20:55:21.200635 140537819772736 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0914 20:55:29.308027 140537819772736 submission_runner.py:192] Initializing model.
I0914 20:55:38.190494 140537819772736 submission_runner.py:226] Initializing optimizer.
I0914 20:55:39.169488 140537819772736 submission_runner.py:233] Initializing metrics bundle.
I0914 20:55:39.169723 140537819772736 submission_runner.py:251] Initializing checkpoint and logger.
I0914 20:55:39.170920 140537819772736 checkpoints.py:915] Found no checkpoint files in /experiment_runs/targets_check_jax/nadamw_run_0/imagenet_vit_jax/trial_1 with prefix checkpoint_
I0914 20:55:40.116455 140537819772736 submission_runner.py:272] Saving meta data to /experiment_runs/targets_check_jax/nadamw_run_0/imagenet_vit_jax/trial_1/meta_data_0.json.
I0914 20:55:40.118326 140537819772736 submission_runner.py:275] Saving flags to /experiment_runs/targets_check_jax/nadamw_run_0/imagenet_vit_jax/trial_1/flags_0.json.
I0914 20:55:40.128131 140537819772736 submission_runner.py:285] Starting training loop.
2023-09-14 20:56:32.692430: E external/xla/xla/service/rendezvous.cc:31] This thread has been waiting for 10 seconds and may be stuck:
2023-09-14 20:56:35.934903: E external/xla/xla/service/rendezvous.cc:36] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.
I0914 20:56:37.483193 140371778598656 logging_writer.py:48] [0] global_step=0, grad_norm=0.37018051743507385, loss=6.9077558517456055
I0914 20:56:37.499995 140537819772736 spec.py:320] Evaluating on the training split.
I0914 20:56:37.508899 140537819772736 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0914 20:56:37.517747 140537819772736 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0914 20:56:37.601582 140537819772736 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0914 20:56:55.434994 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 20:56:55.446864 140537819772736 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0914 20:56:55.465895 140537819772736 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0914 20:56:55.558809 140537819772736 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0914 20:57:12.868711 140537819772736 spec.py:348] Evaluating on the test split.
I0914 20:57:12.876203 140537819772736 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0914 20:57:12.882171 140537819772736 dataset_builder.py:528] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0914 20:57:12.928910 140537819772736 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0914 20:57:21.694948 140537819772736 submission_runner.py:376] Time since start: 101.57s, 	Step: 1, 	{'train/accuracy': 0.0008398437057621777, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 57.37175631523132, 'total_duration': 101.56672477722168, 'accumulated_submission_time': 57.37175631523132, 'accumulated_eval_time': 44.19487500190735, 'accumulated_logging_time': 0}
I0914 20:57:21.713818 140329642608384 logging_writer.py:48] [1] accumulated_eval_time=44.194875, accumulated_logging_time=0, accumulated_submission_time=57.371756, global_step=1, preemption_count=0, score=57.371756, test/accuracy=0.001000, test/loss=6.907757, test/num_examples=10000, total_duration=101.566725, train/accuracy=0.000840, train/loss=6.907756, validation/accuracy=0.001000, validation/loss=6.907756, validation/num_examples=50000
I0914 20:57:45.543091 140373426931456 logging_writer.py:48] [1] global_step=1, grad_norm=0.37416398525238037, loss=6.9077558517456055
I0914 20:57:45.937747 140329667786496 logging_writer.py:48] [2] global_step=2, grad_norm=0.35589131712913513, loss=6.907754898071289
I0914 20:57:46.343578 140373426931456 logging_writer.py:48] [3] global_step=3, grad_norm=0.360586553812027, loss=6.907755374908447
I0914 20:57:46.755920 140329667786496 logging_writer.py:48] [4] global_step=4, grad_norm=0.3677017390727997, loss=6.907751560211182
I0914 20:57:47.164924 140373426931456 logging_writer.py:48] [5] global_step=5, grad_norm=0.351176381111145, loss=6.907759189605713
I0914 20:57:47.582762 140329667786496 logging_writer.py:48] [6] global_step=6, grad_norm=0.3725777864456177, loss=6.907745361328125
I0914 20:57:48.001285 140373426931456 logging_writer.py:48] [7] global_step=7, grad_norm=0.35627928376197815, loss=6.907748222351074
I0914 20:57:48.408745 140329667786496 logging_writer.py:48] [8] global_step=8, grad_norm=0.37418943643569946, loss=6.907742977142334
I0914 20:57:48.824178 140373426931456 logging_writer.py:48] [9] global_step=9, grad_norm=0.37308061122894287, loss=6.90775203704834
I0914 20:57:49.238836 140329667786496 logging_writer.py:48] [10] global_step=10, grad_norm=0.36564990878105164, loss=6.907746315002441
I0914 20:57:49.652295 140373426931456 logging_writer.py:48] [11] global_step=11, grad_norm=0.36601537466049194, loss=6.907725811004639
I0914 20:57:50.060973 140329667786496 logging_writer.py:48] [12] global_step=12, grad_norm=0.37284690141677856, loss=6.907749652862549
I0914 20:57:50.466743 140373426931456 logging_writer.py:48] [13] global_step=13, grad_norm=0.3707316815853119, loss=6.90772008895874
I0914 20:57:50.873638 140329667786496 logging_writer.py:48] [14] global_step=14, grad_norm=0.3616054952144623, loss=6.9077067375183105
I0914 20:57:51.285346 140373426931456 logging_writer.py:48] [15] global_step=15, grad_norm=0.35756534337997437, loss=6.9077301025390625
I0914 20:57:51.688664 140329667786496 logging_writer.py:48] [16] global_step=16, grad_norm=0.37719759345054626, loss=6.907739162445068
I0914 20:57:52.092497 140373426931456 logging_writer.py:48] [17] global_step=17, grad_norm=0.36254048347473145, loss=6.907719135284424
I0914 20:57:52.494908 140329667786496 logging_writer.py:48] [18] global_step=18, grad_norm=0.3647606372833252, loss=6.907679557800293
I0914 20:57:52.900665 140373426931456 logging_writer.py:48] [19] global_step=19, grad_norm=0.3734630346298218, loss=6.907719135284424
I0914 20:57:53.307326 140329667786496 logging_writer.py:48] [20] global_step=20, grad_norm=0.36930859088897705, loss=6.907736778259277
I0914 20:57:53.712601 140373426931456 logging_writer.py:48] [21] global_step=21, grad_norm=0.3611188232898712, loss=6.907693386077881
I0914 20:57:54.120992 140329667786496 logging_writer.py:48] [22] global_step=22, grad_norm=0.3678661584854126, loss=6.907751560211182
I0914 20:57:54.527003 140373426931456 logging_writer.py:48] [23] global_step=23, grad_norm=0.3595677614212036, loss=6.907688617706299
I0914 20:57:54.931841 140329667786496 logging_writer.py:48] [24] global_step=24, grad_norm=0.36908042430877686, loss=6.907618999481201
I0914 20:57:55.340294 140373426931456 logging_writer.py:48] [25] global_step=25, grad_norm=0.36171045899391174, loss=6.907779693603516
I0914 20:57:55.750485 140329667786496 logging_writer.py:48] [26] global_step=26, grad_norm=0.38953518867492676, loss=6.907618999481201
I0914 20:57:56.154871 140373426931456 logging_writer.py:48] [27] global_step=27, grad_norm=0.3599890172481537, loss=6.90763521194458
I0914 20:57:56.568717 140329667786496 logging_writer.py:48] [28] global_step=28, grad_norm=0.3609302341938019, loss=6.907732009887695
I0914 20:57:56.979008 140373426931456 logging_writer.py:48] [29] global_step=29, grad_norm=0.3814542889595032, loss=6.907688617706299
I0914 20:57:57.382377 140329667786496 logging_writer.py:48] [30] global_step=30, grad_norm=0.3588097095489502, loss=6.907664775848389
I0914 20:57:57.789765 140373426931456 logging_writer.py:48] [31] global_step=31, grad_norm=0.3747994303703308, loss=6.90767240524292
I0914 20:57:58.202730 140329667786496 logging_writer.py:48] [32] global_step=32, grad_norm=0.3673507869243622, loss=6.907611846923828
I0914 20:57:58.608806 140373426931456 logging_writer.py:48] [33] global_step=33, grad_norm=0.3790607154369354, loss=6.907644271850586
I0914 20:57:59.015728 140329667786496 logging_writer.py:48] [34] global_step=34, grad_norm=0.3767223060131073, loss=6.907708644866943
I0914 20:57:59.430943 140373426931456 logging_writer.py:48] [35] global_step=35, grad_norm=0.3653969168663025, loss=6.907661437988281
I0914 20:57:59.834679 140329667786496 logging_writer.py:48] [36] global_step=36, grad_norm=0.3971560001373291, loss=6.907645225524902
I0914 20:58:00.245988 140373426931456 logging_writer.py:48] [37] global_step=37, grad_norm=0.3666112422943115, loss=6.907517433166504
I0914 20:58:00.648355 140329667786496 logging_writer.py:48] [38] global_step=38, grad_norm=0.3686845600605011, loss=6.907514572143555
I0914 20:58:01.055689 140373426931456 logging_writer.py:48] [39] global_step=39, grad_norm=0.375258207321167, loss=6.907524108886719
I0914 20:58:01.459849 140329667786496 logging_writer.py:48] [40] global_step=40, grad_norm=0.37733927369117737, loss=6.907555103302002
I0914 20:58:01.865166 140373426931456 logging_writer.py:48] [41] global_step=41, grad_norm=0.35760316252708435, loss=6.907575607299805
I0914 20:58:02.273560 140329667786496 logging_writer.py:48] [42] global_step=42, grad_norm=0.36854302883148193, loss=6.907591819763184
I0914 20:58:02.680182 140373426931456 logging_writer.py:48] [43] global_step=43, grad_norm=0.38916176557540894, loss=6.9074788093566895
I0914 20:58:03.077049 140329667786496 logging_writer.py:48] [44] global_step=44, grad_norm=0.3699219822883606, loss=6.907613277435303
I0914 20:58:03.472209 140373426931456 logging_writer.py:48] [45] global_step=45, grad_norm=0.3842349648475647, loss=6.907479286193848
I0914 20:58:03.866473 140329667786496 logging_writer.py:48] [46] global_step=46, grad_norm=0.3869306147098541, loss=6.907354831695557
I0914 20:58:04.273504 140373426931456 logging_writer.py:48] [47] global_step=47, grad_norm=0.3702245354652405, loss=6.90739631652832
I0914 20:58:04.677168 140329667786496 logging_writer.py:48] [48] global_step=48, grad_norm=0.3680913746356964, loss=6.9074907302856445
I0914 20:58:05.078576 140373426931456 logging_writer.py:48] [49] global_step=49, grad_norm=0.37429195642471313, loss=6.907288074493408
I0914 20:58:05.495349 140329667786496 logging_writer.py:48] [50] global_step=50, grad_norm=0.36941635608673096, loss=6.907465934753418
I0914 20:58:05.900487 140373426931456 logging_writer.py:48] [51] global_step=51, grad_norm=0.37374380230903625, loss=6.907118320465088
I0914 20:58:06.310992 140329667786496 logging_writer.py:48] [52] global_step=52, grad_norm=0.3979688286781311, loss=6.907346248626709
I0914 20:58:06.718972 140373426931456 logging_writer.py:48] [53] global_step=53, grad_norm=0.3945316970348358, loss=6.907329082489014
I0914 20:58:07.126504 140329667786496 logging_writer.py:48] [54] global_step=54, grad_norm=0.37025684118270874, loss=6.907254695892334
I0914 20:58:07.538686 140373426931456 logging_writer.py:48] [55] global_step=55, grad_norm=0.37943312525749207, loss=6.907268047332764
I0914 20:58:07.948881 140329667786496 logging_writer.py:48] [56] global_step=56, grad_norm=0.39899343252182007, loss=6.906931400299072
I0914 20:58:08.354879 140373426931456 logging_writer.py:48] [57] global_step=57, grad_norm=0.4073624014854431, loss=6.906952381134033
I0914 20:58:08.759043 140329667786496 logging_writer.py:48] [58] global_step=58, grad_norm=0.4085967540740967, loss=6.906932353973389
I0914 20:58:09.166350 140373426931456 logging_writer.py:48] [59] global_step=59, grad_norm=0.3726072609424591, loss=6.907235622406006
I0914 20:58:09.570737 140329667786496 logging_writer.py:48] [60] global_step=60, grad_norm=0.3689833879470825, loss=6.907186508178711
I0914 20:58:09.984435 140373426931456 logging_writer.py:48] [61] global_step=61, grad_norm=0.4067145884037018, loss=6.906776428222656
I0914 20:58:10.390979 140329667786496 logging_writer.py:48] [62] global_step=62, grad_norm=0.4215232729911804, loss=6.90693473815918
I0914 20:58:10.799895 140373426931456 logging_writer.py:48] [63] global_step=63, grad_norm=0.4089559018611908, loss=6.906834602355957
I0914 20:58:11.215418 140329667786496 logging_writer.py:48] [64] global_step=64, grad_norm=0.41031524538993835, loss=6.9068427085876465
I0914 20:58:11.627985 140373426931456 logging_writer.py:48] [65] global_step=65, grad_norm=0.42247825860977173, loss=6.906582355499268
I0914 20:58:12.046197 140329667786496 logging_writer.py:48] [66] global_step=66, grad_norm=0.4160589277744293, loss=6.90705680847168
I0914 20:58:12.451547 140373426931456 logging_writer.py:48] [67] global_step=67, grad_norm=0.4072355628013611, loss=6.906711578369141
I0914 20:58:12.855552 140329667786496 logging_writer.py:48] [68] global_step=68, grad_norm=0.4145882725715637, loss=6.90651798248291
I0914 20:58:13.259358 140373426931456 logging_writer.py:48] [69] global_step=69, grad_norm=0.4229569733142853, loss=6.9061384201049805
I0914 20:58:13.664538 140329667786496 logging_writer.py:48] [70] global_step=70, grad_norm=0.4302140474319458, loss=6.9061665534973145
I0914 20:58:14.067978 140373426931456 logging_writer.py:48] [71] global_step=71, grad_norm=0.4206928610801697, loss=6.905937194824219
I0914 20:58:14.474572 140329667786496 logging_writer.py:48] [72] global_step=72, grad_norm=0.40838882327079773, loss=6.9064555168151855
I0914 20:58:14.879988 140373426931456 logging_writer.py:48] [73] global_step=73, grad_norm=0.3922770023345947, loss=6.9060845375061035
I0914 20:58:15.286995 140329667786496 logging_writer.py:48] [74] global_step=74, grad_norm=0.4282713532447815, loss=6.905249118804932
I0914 20:58:15.701925 140373426931456 logging_writer.py:48] [75] global_step=75, grad_norm=0.4445672035217285, loss=6.9061737060546875
I0914 20:58:16.109691 140329667786496 logging_writer.py:48] [76] global_step=76, grad_norm=0.37327560782432556, loss=6.90593147277832
I0914 20:58:16.517662 140373426931456 logging_writer.py:48] [77] global_step=77, grad_norm=0.4379768967628479, loss=6.9053635597229
I0914 20:58:16.928726 140329667786496 logging_writer.py:48] [78] global_step=78, grad_norm=0.4359697103500366, loss=6.90529203414917
I0914 20:58:17.336937 140373426931456 logging_writer.py:48] [79] global_step=79, grad_norm=0.4293625056743622, loss=6.905539512634277
I0914 20:58:17.744877 140329667786496 logging_writer.py:48] [80] global_step=80, grad_norm=0.40065672993659973, loss=6.905517101287842
I0914 20:58:18.151032 140373426931456 logging_writer.py:48] [81] global_step=81, grad_norm=0.3841824531555176, loss=6.905965805053711
I0914 20:58:18.567797 140329667786496 logging_writer.py:48] [82] global_step=82, grad_norm=0.42934584617614746, loss=6.904712677001953
I0914 20:58:18.980229 140373426931456 logging_writer.py:48] [83] global_step=83, grad_norm=0.4548342823982239, loss=6.905178070068359
I0914 20:58:19.386271 140329667786496 logging_writer.py:48] [84] global_step=84, grad_norm=0.3888939619064331, loss=6.906034469604492
I0914 20:58:19.796025 140373426931456 logging_writer.py:48] [85] global_step=85, grad_norm=0.4569280743598938, loss=6.904251575469971
I0914 20:58:20.203390 140329667786496 logging_writer.py:48] [86] global_step=86, grad_norm=0.40436825156211853, loss=6.904733657836914
I0914 20:58:20.610756 140373426931456 logging_writer.py:48] [87] global_step=87, grad_norm=0.4384744167327881, loss=6.903841972351074
I0914 20:58:21.016404 140329667786496 logging_writer.py:48] [88] global_step=88, grad_norm=0.39565691351890564, loss=6.90477991104126
I0914 20:58:21.423044 140373426931456 logging_writer.py:48] [89] global_step=89, grad_norm=0.4325372576713562, loss=6.904199123382568
I0914 20:58:21.831486 140329667786496 logging_writer.py:48] [90] global_step=90, grad_norm=0.458570271730423, loss=6.904375076293945
I0914 20:58:22.238223 140373426931456 logging_writer.py:48] [91] global_step=91, grad_norm=0.4215084910392761, loss=6.904046058654785
I0914 20:58:22.644238 140329667786496 logging_writer.py:48] [92] global_step=92, grad_norm=0.4144861698150635, loss=6.904534816741943
I0914 20:58:23.050528 140373426931456 logging_writer.py:48] [93] global_step=93, grad_norm=0.4627363681793213, loss=6.9027838706970215
I0914 20:58:23.458665 140329667786496 logging_writer.py:48] [94] global_step=94, grad_norm=0.39735767245292664, loss=6.904184341430664
I0914 20:58:23.868848 140373426931456 logging_writer.py:48] [95] global_step=95, grad_norm=0.39312636852264404, loss=6.903451919555664
I0914 20:58:24.281528 140329667786496 logging_writer.py:48] [96] global_step=96, grad_norm=0.4574328064918518, loss=6.902686595916748
I0914 20:58:24.688586 140373426931456 logging_writer.py:48] [97] global_step=97, grad_norm=0.4618329405784607, loss=6.901884078979492
I0914 20:58:25.105881 140329667786496 logging_writer.py:48] [98] global_step=98, grad_norm=0.4636545777320862, loss=6.902655124664307
I0914 20:58:25.510214 140373426931456 logging_writer.py:48] [99] global_step=99, grad_norm=0.46933677792549133, loss=6.902693748474121
I0914 20:58:25.919667 140329667786496 logging_writer.py:48] [100] global_step=100, grad_norm=0.4281512498855591, loss=6.902731895446777
I0914 21:01:06.354964 140373426931456 logging_writer.py:48] [500] global_step=500, grad_norm=0.9347795248031616, loss=6.668060302734375
I0914 21:04:21.897020 140537819772736 spec.py:320] Evaluating on the training split.
I0914 21:04:28.616661 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 21:04:35.250289 140537819772736 spec.py:348] Evaluating on the test split.
I0914 21:04:36.912728 140537819772736 submission_runner.py:376] Time since start: 536.78s, 	Step: 989, 	{'train/accuracy': 0.020390624180436134, 'train/loss': 6.191964149475098, 'validation/accuracy': 0.019700000062584877, 'validation/loss': 6.207623481750488, 'validation/num_examples': 50000, 'test/accuracy': 0.015200000256299973, 'test/loss': 6.279244422912598, 'test/num_examples': 10000, 'score': 477.52748227119446, 'total_duration': 536.7845273017883, 'accumulated_submission_time': 477.52748227119446, 'accumulated_eval_time': 59.21056628227234, 'accumulated_logging_time': 0.02813720703125}
I0914 21:04:36.931542 140329751648000 logging_writer.py:48] [989] accumulated_eval_time=59.210566, accumulated_logging_time=0.028137, accumulated_submission_time=477.527482, global_step=989, preemption_count=0, score=477.527482, test/accuracy=0.015200, test/loss=6.279244, test/num_examples=10000, total_duration=536.784527, train/accuracy=0.020391, train/loss=6.191964, validation/accuracy=0.019700, validation/loss=6.207623, validation/num_examples=50000
I0914 21:04:41.784377 140329760040704 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.3832745552062988, loss=6.391275882720947
I0914 21:08:02.782930 140329751648000 logging_writer.py:48] [1500] global_step=1500, grad_norm=1.562885046005249, loss=6.140567302703857
I0914 21:11:23.760644 140329760040704 logging_writer.py:48] [2000] global_step=2000, grad_norm=1.428897738456726, loss=6.464053630828857
I0914 21:11:37.099952 140537819772736 spec.py:320] Evaluating on the training split.
I0914 21:11:43.848434 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 21:11:50.336049 140537819772736 spec.py:348] Evaluating on the test split.
I0914 21:11:51.964004 140537819772736 submission_runner.py:376] Time since start: 971.84s, 	Step: 2035, 	{'train/accuracy': 0.05357421934604645, 'train/loss': 5.526940822601318, 'validation/accuracy': 0.05407999828457832, 'validation/loss': 5.5634541511535645, 'validation/num_examples': 50000, 'test/accuracy': 0.04130000248551369, 'test/loss': 5.731590270996094, 'test/num_examples': 10000, 'score': 897.6663494110107, 'total_duration': 971.835786819458, 'accumulated_submission_time': 897.6663494110107, 'accumulated_eval_time': 74.07457041740417, 'accumulated_logging_time': 0.05707097053527832}
I0914 21:11:51.981657 140329751648000 logging_writer.py:48] [2035] accumulated_eval_time=74.074570, accumulated_logging_time=0.057071, accumulated_submission_time=897.666349, global_step=2035, preemption_count=0, score=897.666349, test/accuracy=0.041300, test/loss=5.731590, test/num_examples=10000, total_duration=971.835787, train/accuracy=0.053574, train/loss=5.526941, validation/accuracy=0.054080, validation/loss=5.563454, validation/num_examples=50000
I0914 21:14:59.358289 140329760040704 logging_writer.py:48] [2500] global_step=2500, grad_norm=1.3985514640808105, loss=5.703134059906006
I0914 21:18:20.391305 140329751648000 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.9731842279434204, loss=6.568794250488281
I0914 21:18:52.251361 140537819772736 spec.py:320] Evaluating on the training split.
I0914 21:18:58.990009 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 21:19:05.549862 140537819772736 spec.py:348] Evaluating on the test split.
I0914 21:19:07.184812 140537819772736 submission_runner.py:376] Time since start: 1407.06s, 	Step: 3081, 	{'train/accuracy': 0.09001953154802322, 'train/loss': 5.122523784637451, 'validation/accuracy': 0.08184000104665756, 'validation/loss': 5.178854942321777, 'validation/num_examples': 50000, 'test/accuracy': 0.06360000371932983, 'test/loss': 5.407402515411377, 'test/num_examples': 10000, 'score': 1317.906329870224, 'total_duration': 1407.0566093921661, 'accumulated_submission_time': 1317.906329870224, 'accumulated_eval_time': 89.00798153877258, 'accumulated_logging_time': 0.08513021469116211}
I0914 21:19:07.201642 140329760040704 logging_writer.py:48] [3081] accumulated_eval_time=89.007982, accumulated_logging_time=0.085130, accumulated_submission_time=1317.906330, global_step=3081, preemption_count=0, score=1317.906330, test/accuracy=0.063600, test/loss=5.407403, test/num_examples=10000, total_duration=1407.056609, train/accuracy=0.090020, train/loss=5.122524, validation/accuracy=0.081840, validation/loss=5.178855, validation/num_examples=50000
I0914 21:21:56.200992 140329751648000 logging_writer.py:48] [3500] global_step=3500, grad_norm=1.2178643941879272, loss=6.069034576416016
I0914 21:25:17.337060 140329760040704 logging_writer.py:48] [4000] global_step=4000, grad_norm=1.3802592754364014, loss=6.400205135345459
I0914 21:26:07.288807 140537819772736 spec.py:320] Evaluating on the training split.
I0914 21:26:14.040152 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 21:26:20.555342 140537819772736 spec.py:348] Evaluating on the test split.
I0914 21:26:22.183831 140537819772736 submission_runner.py:376] Time since start: 1842.06s, 	Step: 4126, 	{'train/accuracy': 0.14912109076976776, 'train/loss': 4.528235912322998, 'validation/accuracy': 0.13565999269485474, 'validation/loss': 4.610907554626465, 'validation/num_examples': 50000, 'test/accuracy': 0.0999000072479248, 'test/loss': 4.929778575897217, 'test/num_examples': 10000, 'score': 1737.9637939929962, 'total_duration': 1842.0556008815765, 'accumulated_submission_time': 1737.9637939929962, 'accumulated_eval_time': 103.9029438495636, 'accumulated_logging_time': 0.11247086524963379}
I0914 21:26:22.202478 140329751648000 logging_writer.py:48] [4126] accumulated_eval_time=103.902944, accumulated_logging_time=0.112471, accumulated_submission_time=1737.963794, global_step=4126, preemption_count=0, score=1737.963794, test/accuracy=0.099900, test/loss=4.929779, test/num_examples=10000, total_duration=1842.055601, train/accuracy=0.149121, train/loss=4.528236, validation/accuracy=0.135660, validation/loss=4.610908, validation/num_examples=50000
I0914 21:28:53.057278 140329760040704 logging_writer.py:48] [4500] global_step=4500, grad_norm=1.396702766418457, loss=6.075138568878174
I0914 21:32:14.318184 140329751648000 logging_writer.py:48] [5000] global_step=5000, grad_norm=1.4768497943878174, loss=5.733062744140625
I0914 21:33:22.378449 140537819772736 spec.py:320] Evaluating on the training split.
I0914 21:33:29.118869 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 21:33:35.704311 140537819772736 spec.py:348] Evaluating on the test split.
I0914 21:33:37.328754 140537819772736 submission_runner.py:376] Time since start: 2277.20s, 	Step: 5171, 	{'train/accuracy': 0.20302733778953552, 'train/loss': 4.115457534790039, 'validation/accuracy': 0.18803998827934265, 'validation/loss': 4.203698635101318, 'validation/num_examples': 50000, 'test/accuracy': 0.14250001311302185, 'test/loss': 4.573462009429932, 'test/num_examples': 10000, 'score': 2158.109827518463, 'total_duration': 2277.2005586624146, 'accumulated_submission_time': 2158.109827518463, 'accumulated_eval_time': 118.85322332382202, 'accumulated_logging_time': 0.1416316032409668}
I0914 21:33:37.346897 140329760040704 logging_writer.py:48] [5171] accumulated_eval_time=118.853223, accumulated_logging_time=0.141632, accumulated_submission_time=2158.109828, global_step=5171, preemption_count=0, score=2158.109828, test/accuracy=0.142500, test/loss=4.573462, test/num_examples=10000, total_duration=2277.200559, train/accuracy=0.203027, train/loss=4.115458, validation/accuracy=0.188040, validation/loss=4.203699, validation/num_examples=50000
I0914 21:35:50.204990 140329751648000 logging_writer.py:48] [5500] global_step=5500, grad_norm=1.2777847051620483, loss=5.744314670562744
I0914 21:39:11.541961 140329760040704 logging_writer.py:48] [6000] global_step=6000, grad_norm=1.530618667602539, loss=5.1175537109375
I0914 21:40:37.373114 140537819772736 spec.py:320] Evaluating on the training split.
I0914 21:40:44.095088 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 21:40:50.583540 140537819772736 spec.py:348] Evaluating on the test split.
I0914 21:40:52.214024 140537819772736 submission_runner.py:376] Time since start: 2712.09s, 	Step: 6215, 	{'train/accuracy': 0.25273436307907104, 'train/loss': 3.718691825866699, 'validation/accuracy': 0.23617999255657196, 'validation/loss': 3.8217458724975586, 'validation/num_examples': 50000, 'test/accuracy': 0.17830000817775726, 'test/loss': 4.274967193603516, 'test/num_examples': 10000, 'score': 2578.1059305667877, 'total_duration': 2712.0858256816864, 'accumulated_submission_time': 2578.1059305667877, 'accumulated_eval_time': 133.6941261291504, 'accumulated_logging_time': 0.17026925086975098}
I0914 21:40:52.232908 140329751648000 logging_writer.py:48] [6215] accumulated_eval_time=133.694126, accumulated_logging_time=0.170269, accumulated_submission_time=2578.105931, global_step=6215, preemption_count=0, score=2578.105931, test/accuracy=0.178300, test/loss=4.274967, test/num_examples=10000, total_duration=2712.085826, train/accuracy=0.252734, train/loss=3.718692, validation/accuracy=0.236180, validation/loss=3.821746, validation/num_examples=50000
I0914 21:42:47.401695 140329760040704 logging_writer.py:48] [6500] global_step=6500, grad_norm=1.4954075813293457, loss=6.080549240112305
I0914 21:46:08.717469 140329751648000 logging_writer.py:48] [7000] global_step=7000, grad_norm=1.1604033708572388, loss=5.02187967300415
I0914 21:47:52.232719 140537819772736 spec.py:320] Evaluating on the training split.
I0914 21:47:58.965403 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 21:48:05.589477 140537819772736 spec.py:348] Evaluating on the test split.
I0914 21:48:07.220954 140537819772736 submission_runner.py:376] Time since start: 3147.09s, 	Step: 7259, 	{'train/accuracy': 0.3032616972923279, 'train/loss': 3.364391803741455, 'validation/accuracy': 0.280460000038147, 'validation/loss': 3.4938876628875732, 'validation/num_examples': 50000, 'test/accuracy': 0.21380001306533813, 'test/loss': 3.9967336654663086, 'test/num_examples': 10000, 'score': 2998.0750863552094, 'total_duration': 3147.092746734619, 'accumulated_submission_time': 2998.0750863552094, 'accumulated_eval_time': 148.68233180046082, 'accumulated_logging_time': 0.19936871528625488}
I0914 21:48:07.238758 140329760040704 logging_writer.py:48] [7259] accumulated_eval_time=148.682332, accumulated_logging_time=0.199369, accumulated_submission_time=2998.075086, global_step=7259, preemption_count=0, score=2998.075086, test/accuracy=0.213800, test/loss=3.996734, test/num_examples=10000, total_duration=3147.092747, train/accuracy=0.303262, train/loss=3.364392, validation/accuracy=0.280460, validation/loss=3.493888, validation/num_examples=50000
I0914 21:49:44.686618 140329751648000 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.9582319855690002, loss=6.03778076171875
I0914 21:53:06.173550 140329760040704 logging_writer.py:48] [8000] global_step=8000, grad_norm=1.6496431827545166, loss=4.1814985275268555
I0914 21:55:07.415637 140537819772736 spec.py:320] Evaluating on the training split.
I0914 21:55:14.209800 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 21:55:20.891710 140537819772736 spec.py:348] Evaluating on the test split.
I0914 21:55:22.553017 140537819772736 submission_runner.py:376] Time since start: 3582.42s, 	Step: 8303, 	{'train/accuracy': 0.35283201932907104, 'train/loss': 3.0697734355926514, 'validation/accuracy': 0.32486000657081604, 'validation/loss': 3.2185685634613037, 'validation/num_examples': 50000, 'test/accuracy': 0.25210002064704895, 'test/loss': 3.7374329566955566, 'test/num_examples': 10000, 'score': 3418.2163786888123, 'total_duration': 3582.4247949123383, 'accumulated_submission_time': 3418.2163786888123, 'accumulated_eval_time': 163.8197102546692, 'accumulated_logging_time': 0.22786331176757812}
I0914 21:55:22.582030 140329751648000 logging_writer.py:48] [8303] accumulated_eval_time=163.819710, accumulated_logging_time=0.227863, accumulated_submission_time=3418.216379, global_step=8303, preemption_count=0, score=3418.216379, test/accuracy=0.252100, test/loss=3.737433, test/num_examples=10000, total_duration=3582.424795, train/accuracy=0.352832, train/loss=3.069773, validation/accuracy=0.324860, validation/loss=3.218569, validation/num_examples=50000
I0914 21:56:42.299247 140329760040704 logging_writer.py:48] [8500] global_step=8500, grad_norm=1.2601443529129028, loss=4.151809215545654
I0914 22:00:03.775949 140329751648000 logging_writer.py:48] [9000] global_step=9000, grad_norm=1.1304413080215454, loss=3.899786949157715
I0914 22:02:22.784542 140537819772736 spec.py:320] Evaluating on the training split.
I0914 22:02:29.605871 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 22:02:36.351151 140537819772736 spec.py:348] Evaluating on the test split.
I0914 22:02:38.007272 140537819772736 submission_runner.py:376] Time since start: 4017.88s, 	Step: 9347, 	{'train/accuracy': 0.4092187285423279, 'train/loss': 2.7512402534484863, 'validation/accuracy': 0.3658599853515625, 'validation/loss': 2.971527099609375, 'validation/num_examples': 50000, 'test/accuracy': 0.28290000557899475, 'test/loss': 3.519920587539673, 'test/num_examples': 10000, 'score': 3838.3837130069733, 'total_duration': 4017.8790225982666, 'accumulated_submission_time': 3838.3837130069733, 'accumulated_eval_time': 179.0423939228058, 'accumulated_logging_time': 0.26703858375549316}
I0914 22:02:38.033391 140329760040704 logging_writer.py:48] [9347] accumulated_eval_time=179.042394, accumulated_logging_time=0.267039, accumulated_submission_time=3838.383713, global_step=9347, preemption_count=0, score=3838.383713, test/accuracy=0.282900, test/loss=3.519921, test/num_examples=10000, total_duration=4017.879023, train/accuracy=0.409219, train/loss=2.751240, validation/accuracy=0.365860, validation/loss=2.971527, validation/num_examples=50000
I0914 22:03:40.094777 140329751648000 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.8288843631744385, loss=5.913199424743652
I0914 22:07:01.728182 140329760040704 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.7714523077011108, loss=5.898974418640137
I0914 22:09:38.101240 140537819772736 spec.py:320] Evaluating on the training split.
I0914 22:09:45.639219 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 22:09:52.471615 140537819772736 spec.py:348] Evaluating on the test split.
I0914 22:09:54.132152 140537819772736 submission_runner.py:376] Time since start: 4454.00s, 	Step: 10390, 	{'train/accuracy': 0.4185742139816284, 'train/loss': 2.68806791305542, 'validation/accuracy': 0.3880999982357025, 'validation/loss': 2.8474984169006348, 'validation/num_examples': 50000, 'test/accuracy': 0.3035000264644623, 'test/loss': 3.393613338470459, 'test/num_examples': 10000, 'score': 4258.402877569199, 'total_duration': 4454.003902435303, 'accumulated_submission_time': 4258.402877569199, 'accumulated_eval_time': 195.0732707977295, 'accumulated_logging_time': 0.31662440299987793}
I0914 22:09:54.161029 140329751648000 logging_writer.py:48] [10390] accumulated_eval_time=195.073271, accumulated_logging_time=0.316624, accumulated_submission_time=4258.402878, global_step=10390, preemption_count=0, score=4258.402878, test/accuracy=0.303500, test/loss=3.393613, test/num_examples=10000, total_duration=4454.003902, train/accuracy=0.418574, train/loss=2.688068, validation/accuracy=0.388100, validation/loss=2.847498, validation/num_examples=50000
I0914 22:10:38.869342 140329760040704 logging_writer.py:48] [10500] global_step=10500, grad_norm=1.1687681674957275, loss=4.47040319442749
I0914 22:14:00.411414 140329751648000 logging_writer.py:48] [11000] global_step=11000, grad_norm=1.488961100578308, loss=3.612621307373047
I0914 22:16:54.423879 140537819772736 spec.py:320] Evaluating on the training split.
I0914 22:17:01.859471 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 22:17:08.594701 140537819772736 spec.py:348] Evaluating on the test split.
I0914 22:17:10.252713 140537819772736 submission_runner.py:376] Time since start: 4890.12s, 	Step: 11434, 	{'train/accuracy': 0.4561132788658142, 'train/loss': 2.4276394844055176, 'validation/accuracy': 0.4253999888896942, 'validation/loss': 2.592682123184204, 'validation/num_examples': 50000, 'test/accuracy': 0.3281000256538391, 'test/loss': 3.218247413635254, 'test/num_examples': 10000, 'score': 4678.625365257263, 'total_duration': 4890.124463558197, 'accumulated_submission_time': 4678.625365257263, 'accumulated_eval_time': 210.90204763412476, 'accumulated_logging_time': 0.3602902889251709}
I0914 22:17:10.279023 140329760040704 logging_writer.py:48] [11434] accumulated_eval_time=210.902048, accumulated_logging_time=0.360290, accumulated_submission_time=4678.625365, global_step=11434, preemption_count=0, score=4678.625365, test/accuracy=0.328100, test/loss=3.218247, test/num_examples=10000, total_duration=4890.124464, train/accuracy=0.456113, train/loss=2.427639, validation/accuracy=0.425400, validation/loss=2.592682, validation/num_examples=50000
I0914 22:17:37.284678 140329751648000 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.943670392036438, loss=4.23422908782959
I0914 22:20:58.642941 140329760040704 logging_writer.py:48] [12000] global_step=12000, grad_norm=1.1869710683822632, loss=3.7099554538726807
I0914 22:24:10.342180 140537819772736 spec.py:320] Evaluating on the training split.
I0914 22:24:19.024940 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 22:24:25.852794 140537819772736 spec.py:348] Evaluating on the test split.
I0914 22:24:27.503254 140537819772736 submission_runner.py:376] Time since start: 5327.38s, 	Step: 12478, 	{'train/accuracy': 0.482421875, 'train/loss': 2.292179822921753, 'validation/accuracy': 0.44689998030662537, 'validation/loss': 2.4758152961730957, 'validation/num_examples': 50000, 'test/accuracy': 0.34450000524520874, 'test/loss': 3.0888631343841553, 'test/num_examples': 10000, 'score': 5098.642262935638, 'total_duration': 5327.375041007996, 'accumulated_submission_time': 5098.642262935638, 'accumulated_eval_time': 228.06313037872314, 'accumulated_logging_time': 0.40737128257751465}
I0914 22:24:27.529926 140329751648000 logging_writer.py:48] [12478] accumulated_eval_time=228.063130, accumulated_logging_time=0.407371, accumulated_submission_time=5098.642263, global_step=12478, preemption_count=0, score=5098.642263, test/accuracy=0.344500, test/loss=3.088863, test/num_examples=10000, total_duration=5327.375041, train/accuracy=0.482422, train/loss=2.292180, validation/accuracy=0.446900, validation/loss=2.475815, validation/num_examples=50000
I0914 22:24:37.130888 140329760040704 logging_writer.py:48] [12500] global_step=12500, grad_norm=1.016274333000183, loss=4.730247974395752
I0914 22:27:58.605479 140329751648000 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.8708993792533875, loss=5.541352272033691
I0914 22:31:19.911559 140329760040704 logging_writer.py:48] [13500] global_step=13500, grad_norm=1.3784065246582031, loss=3.260796070098877
I0914 22:31:27.656487 140537819772736 spec.py:320] Evaluating on the training split.
I0914 22:31:36.440452 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 22:31:43.287771 140537819772736 spec.py:348] Evaluating on the test split.
I0914 22:31:44.947427 140537819772736 submission_runner.py:376] Time since start: 5764.82s, 	Step: 13521, 	{'train/accuracy': 0.5117577910423279, 'train/loss': 2.186204671859741, 'validation/accuracy': 0.46511998772621155, 'validation/loss': 2.4085850715637207, 'validation/num_examples': 50000, 'test/accuracy': 0.3644000291824341, 'test/loss': 3.017554759979248, 'test/num_examples': 10000, 'score': 5518.719899892807, 'total_duration': 5764.819185256958, 'accumulated_submission_time': 5518.719899892807, 'accumulated_eval_time': 245.35401606559753, 'accumulated_logging_time': 0.4583580493927002}
I0914 22:31:44.975388 140329751648000 logging_writer.py:48] [13521] accumulated_eval_time=245.354016, accumulated_logging_time=0.458358, accumulated_submission_time=5518.719900, global_step=13521, preemption_count=0, score=5518.719900, test/accuracy=0.364400, test/loss=3.017555, test/num_examples=10000, total_duration=5764.819185, train/accuracy=0.511758, train/loss=2.186205, validation/accuracy=0.465120, validation/loss=2.408585, validation/num_examples=50000
I0914 22:34:58.254114 140329760040704 logging_writer.py:48] [14000] global_step=14000, grad_norm=1.200969934463501, loss=3.156698703765869
I0914 22:38:19.692037 140329751648000 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.8424541354179382, loss=4.960617542266846
I0914 22:38:45.106596 140537819772736 spec.py:320] Evaluating on the training split.
I0914 22:38:54.628982 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 22:39:01.513000 140537819772736 spec.py:348] Evaluating on the test split.
I0914 22:39:03.176582 140537819772736 submission_runner.py:376] Time since start: 6203.05s, 	Step: 14565, 	{'train/accuracy': 0.5471093654632568, 'train/loss': 2.0091662406921387, 'validation/accuracy': 0.48787999153137207, 'validation/loss': 2.2879867553710938, 'validation/num_examples': 50000, 'test/accuracy': 0.3759000301361084, 'test/loss': 2.91947865486145, 'test/num_examples': 10000, 'score': 5938.798867464066, 'total_duration': 6203.048347949982, 'accumulated_submission_time': 5938.798867464066, 'accumulated_eval_time': 263.4239389896393, 'accumulated_logging_time': 0.5130276679992676}
I0914 22:39:03.205348 140329760040704 logging_writer.py:48] [14565] accumulated_eval_time=263.423939, accumulated_logging_time=0.513028, accumulated_submission_time=5938.798867, global_step=14565, preemption_count=0, score=5938.798867, test/accuracy=0.375900, test/loss=2.919479, test/num_examples=10000, total_duration=6203.048348, train/accuracy=0.547109, train/loss=2.009166, validation/accuracy=0.487880, validation/loss=2.287987, validation/num_examples=50000
I0914 22:41:58.742309 140329751648000 logging_writer.py:48] [15000] global_step=15000, grad_norm=1.177065372467041, loss=3.0998752117156982
I0914 22:45:20.138445 140329760040704 logging_writer.py:48] [15500] global_step=15500, grad_norm=1.0479310750961304, loss=3.8643362522125244
I0914 22:46:03.292015 140537819772736 spec.py:320] Evaluating on the training split.
I0914 22:46:13.781247 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 22:46:21.503326 140537819772736 spec.py:348] Evaluating on the test split.
I0914 22:46:23.164423 140537819772736 submission_runner.py:376] Time since start: 6643.04s, 	Step: 15609, 	{'train/accuracy': 0.5362109541893005, 'train/loss': 2.009122848510742, 'validation/accuracy': 0.5021600127220154, 'validation/loss': 2.1903953552246094, 'validation/num_examples': 50000, 'test/accuracy': 0.3911000192165375, 'test/loss': 2.830354928970337, 'test/num_examples': 10000, 'score': 6358.846475124359, 'total_duration': 6643.036203861237, 'accumulated_submission_time': 6358.846475124359, 'accumulated_eval_time': 283.2963147163391, 'accumulated_logging_time': 0.5552635192871094}
I0914 22:46:23.191532 140329751648000 logging_writer.py:48] [15609] accumulated_eval_time=283.296315, accumulated_logging_time=0.555264, accumulated_submission_time=6358.846475, global_step=15609, preemption_count=0, score=6358.846475, test/accuracy=0.391100, test/loss=2.830355, test/num_examples=10000, total_duration=6643.036204, train/accuracy=0.536211, train/loss=2.009123, validation/accuracy=0.502160, validation/loss=2.190395, validation/num_examples=50000
I0914 22:49:00.983999 140329760040704 logging_writer.py:48] [16000] global_step=16000, grad_norm=1.2822260856628418, loss=3.0187325477600098
I0914 22:52:22.385290 140329751648000 logging_writer.py:48] [16500] global_step=16500, grad_norm=1.0757312774658203, loss=4.850978374481201
I0914 22:53:23.228396 140537819772736 spec.py:320] Evaluating on the training split.
I0914 22:53:33.152338 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 22:53:41.354655 140537819772736 spec.py:348] Evaluating on the test split.
I0914 22:53:43.015657 140537819772736 submission_runner.py:376] Time since start: 7082.89s, 	Step: 16653, 	{'train/accuracy': 0.5543359518051147, 'train/loss': 1.9230766296386719, 'validation/accuracy': 0.511139988899231, 'validation/loss': 2.13252329826355, 'validation/num_examples': 50000, 'test/accuracy': 0.4011000096797943, 'test/loss': 2.7779672145843506, 'test/num_examples': 10000, 'score': 6778.849031209946, 'total_duration': 7082.887460947037, 'accumulated_submission_time': 6778.849031209946, 'accumulated_eval_time': 303.0835556983948, 'accumulated_logging_time': 0.5919358730316162}
I0914 22:53:43.038834 140329760040704 logging_writer.py:48] [16653] accumulated_eval_time=303.083556, accumulated_logging_time=0.591936, accumulated_submission_time=6778.849031, global_step=16653, preemption_count=0, score=6778.849031, test/accuracy=0.401100, test/loss=2.777967, test/num_examples=10000, total_duration=7082.887461, train/accuracy=0.554336, train/loss=1.923077, validation/accuracy=0.511140, validation/loss=2.132523, validation/num_examples=50000
I0914 22:56:02.882628 140329751648000 logging_writer.py:48] [17000] global_step=17000, grad_norm=1.2617003917694092, loss=2.9960644245147705
I0914 22:59:23.913726 140329760040704 logging_writer.py:48] [17500] global_step=17500, grad_norm=1.3935774564743042, loss=3.163680076599121
I0914 23:00:43.227072 140537819772736 spec.py:320] Evaluating on the training split.
I0914 23:00:53.337867 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 23:01:01.393661 140537819772736 spec.py:348] Evaluating on the test split.
I0914 23:01:03.047742 140537819772736 submission_runner.py:376] Time since start: 7522.92s, 	Step: 17699, 	{'train/accuracy': 0.5710155963897705, 'train/loss': 1.8501490354537964, 'validation/accuracy': 0.5288599729537964, 'validation/loss': 2.0592732429504395, 'validation/num_examples': 50000, 'test/accuracy': 0.4115000069141388, 'test/loss': 2.6851940155029297, 'test/num_examples': 10000, 'score': 7199.002073764801, 'total_duration': 7522.919504165649, 'accumulated_submission_time': 7199.002073764801, 'accumulated_eval_time': 322.9041965007782, 'accumulated_logging_time': 0.6252312660217285}
I0914 23:01:03.075514 140329751648000 logging_writer.py:48] [17699] accumulated_eval_time=322.904197, accumulated_logging_time=0.625231, accumulated_submission_time=7199.002074, global_step=17699, preemption_count=0, score=7199.002074, test/accuracy=0.411500, test/loss=2.685194, test/num_examples=10000, total_duration=7522.919504, train/accuracy=0.571016, train/loss=1.850149, validation/accuracy=0.528860, validation/loss=2.059273, validation/num_examples=50000
I0914 23:03:04.456864 140329760040704 logging_writer.py:48] [18000] global_step=18000, grad_norm=1.1333683729171753, loss=3.1430065631866455
I0914 23:06:25.467638 140329751648000 logging_writer.py:48] [18500] global_step=18500, grad_norm=1.0307838916778564, loss=4.17155647277832
I0914 23:08:03.244154 140537819772736 spec.py:320] Evaluating on the training split.
I0914 23:08:14.327896 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 23:08:22.467616 140537819772736 spec.py:348] Evaluating on the test split.
I0914 23:08:24.128901 140537819772736 submission_runner.py:376] Time since start: 7964.00s, 	Step: 18745, 	{'train/accuracy': 0.5863866806030273, 'train/loss': 1.7722173929214478, 'validation/accuracy': 0.5331999659538269, 'validation/loss': 2.0186984539031982, 'validation/num_examples': 50000, 'test/accuracy': 0.41860002279281616, 'test/loss': 2.6791703701019287, 'test/num_examples': 10000, 'score': 7619.130410909653, 'total_duration': 7964.000683784485, 'accumulated_submission_time': 7619.130410909653, 'accumulated_eval_time': 343.78895258903503, 'accumulated_logging_time': 0.6679136753082275}
I0914 23:08:24.160284 140329760040704 logging_writer.py:48] [18745] accumulated_eval_time=343.788953, accumulated_logging_time=0.667914, accumulated_submission_time=7619.130411, global_step=18745, preemption_count=0, score=7619.130411, test/accuracy=0.418600, test/loss=2.679170, test/num_examples=10000, total_duration=7964.000684, train/accuracy=0.586387, train/loss=1.772217, validation/accuracy=0.533200, validation/loss=2.018698, validation/num_examples=50000
I0914 23:10:07.190133 140329751648000 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.9433646202087402, loss=5.447446346282959
I0914 23:13:28.651687 140329760040704 logging_writer.py:48] [19500] global_step=19500, grad_norm=1.4858520030975342, loss=3.127925395965576
I0914 23:15:24.244186 140537819772736 spec.py:320] Evaluating on the training split.
I0914 23:15:34.902354 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 23:15:43.765949 140537819772736 spec.py:348] Evaluating on the test split.
I0914 23:15:45.408124 140537819772736 submission_runner.py:376] Time since start: 8405.28s, 	Step: 19789, 	{'train/accuracy': 0.6121289134025574, 'train/loss': 1.6709192991256714, 'validation/accuracy': 0.5416799783706665, 'validation/loss': 1.9976913928985596, 'validation/num_examples': 50000, 'test/accuracy': 0.42900002002716064, 'test/loss': 2.639723300933838, 'test/num_examples': 10000, 'score': 8039.176896095276, 'total_duration': 8405.279914617538, 'accumulated_submission_time': 8039.176896095276, 'accumulated_eval_time': 364.95295310020447, 'accumulated_logging_time': 0.7106950283050537}
I0914 23:15:45.428798 140329751648000 logging_writer.py:48] [19789] accumulated_eval_time=364.952953, accumulated_logging_time=0.710695, accumulated_submission_time=8039.176896, global_step=19789, preemption_count=0, score=8039.176896, test/accuracy=0.429000, test/loss=2.639723, test/num_examples=10000, total_duration=8405.279915, train/accuracy=0.612129, train/loss=1.670919, validation/accuracy=0.541680, validation/loss=1.997691, validation/num_examples=50000
I0914 23:17:10.622660 140329760040704 logging_writer.py:48] [20000] global_step=20000, grad_norm=1.4364821910858154, loss=2.822463035583496
I0914 23:20:31.564952 140329751648000 logging_writer.py:48] [20500] global_step=20500, grad_norm=1.203662395477295, loss=2.713209629058838
I0914 23:22:45.587924 140537819772736 spec.py:320] Evaluating on the training split.
I0914 23:22:56.327305 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 23:23:05.304441 140537819772736 spec.py:348] Evaluating on the test split.
I0914 23:23:06.954047 140537819772736 submission_runner.py:376] Time since start: 8846.83s, 	Step: 20835, 	{'train/accuracy': 0.5972851514816284, 'train/loss': 1.719199776649475, 'validation/accuracy': 0.5541999936103821, 'validation/loss': 1.925168752670288, 'validation/num_examples': 50000, 'test/accuracy': 0.4399000108242035, 'test/loss': 2.597055673599243, 'test/num_examples': 10000, 'score': 8459.302201509476, 'total_duration': 8846.825850486755, 'accumulated_submission_time': 8459.302201509476, 'accumulated_eval_time': 386.31907200813293, 'accumulated_logging_time': 0.7411060333251953}
I0914 23:23:06.975712 140329760040704 logging_writer.py:48] [20835] accumulated_eval_time=386.319072, accumulated_logging_time=0.741106, accumulated_submission_time=8459.302202, global_step=20835, preemption_count=0, score=8459.302202, test/accuracy=0.439900, test/loss=2.597056, test/num_examples=10000, total_duration=8846.825850, train/accuracy=0.597285, train/loss=1.719200, validation/accuracy=0.554200, validation/loss=1.925169, validation/num_examples=50000
I0914 23:24:13.682987 140329751648000 logging_writer.py:48] [21000] global_step=21000, grad_norm=1.054955244064331, loss=4.96962308883667
I0914 23:27:34.614125 140329760040704 logging_writer.py:48] [21500] global_step=21500, grad_norm=1.3083302974700928, loss=2.637582778930664
I0914 23:30:07.150514 140537819772736 spec.py:320] Evaluating on the training split.
I0914 23:30:18.249148 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 23:30:26.971792 140537819772736 spec.py:348] Evaluating on the test split.
I0914 23:30:28.625347 140537819772736 submission_runner.py:376] Time since start: 9288.50s, 	Step: 21881, 	{'train/accuracy': 0.6030859351158142, 'train/loss': 1.7660539150238037, 'validation/accuracy': 0.5580199956893921, 'validation/loss': 1.9785405397415161, 'validation/num_examples': 50000, 'test/accuracy': 0.4385000169277191, 'test/loss': 2.6225688457489014, 'test/num_examples': 10000, 'score': 8879.44092464447, 'total_duration': 9288.49713587761, 'accumulated_submission_time': 8879.44092464447, 'accumulated_eval_time': 407.79387283325195, 'accumulated_logging_time': 0.7744174003601074}
I0914 23:30:28.662182 140329751648000 logging_writer.py:48] [21881] accumulated_eval_time=407.793873, accumulated_logging_time=0.774417, accumulated_submission_time=8879.440925, global_step=21881, preemption_count=0, score=8879.440925, test/accuracy=0.438500, test/loss=2.622569, test/num_examples=10000, total_duration=9288.497136, train/accuracy=0.603086, train/loss=1.766054, validation/accuracy=0.558020, validation/loss=1.978541, validation/num_examples=50000
I0914 23:31:16.879456 140329760040704 logging_writer.py:48] [22000] global_step=22000, grad_norm=1.3370835781097412, loss=2.7003016471862793
I0914 23:34:37.834386 140329751648000 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.977641761302948, loss=5.25745153427124
I0914 23:37:28.795948 140537819772736 spec.py:320] Evaluating on the training split.
I0914 23:37:40.361669 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 23:37:49.304093 140537819772736 spec.py:348] Evaluating on the test split.
I0914 23:37:50.948285 140537819772736 submission_runner.py:376] Time since start: 9730.82s, 	Step: 22927, 	{'train/accuracy': 0.6214648485183716, 'train/loss': 1.5782735347747803, 'validation/accuracy': 0.5740000009536743, 'validation/loss': 1.804372787475586, 'validation/num_examples': 50000, 'test/accuracy': 0.45750001072883606, 'test/loss': 2.460386276245117, 'test/num_examples': 10000, 'score': 9299.516573667526, 'total_duration': 9730.820071697235, 'accumulated_submission_time': 9299.516573667526, 'accumulated_eval_time': 429.9462044239044, 'accumulated_logging_time': 0.8441531658172607}
I0914 23:37:50.972260 140329760040704 logging_writer.py:48] [22927] accumulated_eval_time=429.946204, accumulated_logging_time=0.844153, accumulated_submission_time=9299.516574, global_step=22927, preemption_count=0, score=9299.516574, test/accuracy=0.457500, test/loss=2.460386, test/num_examples=10000, total_duration=9730.820072, train/accuracy=0.621465, train/loss=1.578274, validation/accuracy=0.574000, validation/loss=1.804373, validation/num_examples=50000
I0914 23:38:20.731352 140329751648000 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.9933618307113647, loss=4.891023635864258
I0914 23:41:41.708700 140329760040704 logging_writer.py:48] [23500] global_step=23500, grad_norm=1.3114209175109863, loss=2.8002641201019287
I0914 23:44:51.251998 140537819772736 spec.py:320] Evaluating on the training split.
I0914 23:45:02.995231 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 23:45:11.629378 140537819772736 spec.py:348] Evaluating on the test split.
I0914 23:45:13.274524 140537819772736 submission_runner.py:376] Time since start: 10173.15s, 	Step: 23973, 	{'train/accuracy': 0.6368554830551147, 'train/loss': 1.5251083374023438, 'validation/accuracy': 0.5801199674606323, 'validation/loss': 1.7930980920791626, 'validation/num_examples': 50000, 'test/accuracy': 0.4588000178337097, 'test/loss': 2.461763858795166, 'test/num_examples': 10000, 'score': 9719.760099887848, 'total_duration': 10173.146329402924, 'accumulated_submission_time': 9719.760099887848, 'accumulated_eval_time': 451.96873569488525, 'accumulated_logging_time': 0.8795382976531982}
I0914 23:45:13.296376 140329751648000 logging_writer.py:48] [23973] accumulated_eval_time=451.968736, accumulated_logging_time=0.879538, accumulated_submission_time=9719.760100, global_step=23973, preemption_count=0, score=9719.760100, test/accuracy=0.458800, test/loss=2.461764, test/num_examples=10000, total_duration=10173.146329, train/accuracy=0.636855, train/loss=1.525108, validation/accuracy=0.580120, validation/loss=1.793098, validation/num_examples=50000
I0914 23:45:24.573359 140329760040704 logging_writer.py:48] [24000] global_step=24000, grad_norm=1.2907785177230835, loss=2.7141315937042236
I0914 23:48:45.913089 140329751648000 logging_writer.py:48] [24500] global_step=24500, grad_norm=1.2814875841140747, loss=2.694883108139038
I0914 23:52:07.396766 140329760040704 logging_writer.py:48] [25000] global_step=25000, grad_norm=1.217808485031128, loss=3.0806949138641357
I0914 23:52:13.545139 140537819772736 spec.py:320] Evaluating on the training split.
I0914 23:52:24.589111 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 23:52:35.168390 140537819772736 spec.py:348] Evaluating on the test split.
I0914 23:52:36.802033 140537819772736 submission_runner.py:376] Time since start: 10616.67s, 	Step: 25017, 	{'train/accuracy': 0.6592577695846558, 'train/loss': 1.3961186408996582, 'validation/accuracy': 0.5885999798774719, 'validation/loss': 1.7285858392715454, 'validation/num_examples': 50000, 'test/accuracy': 0.46640002727508545, 'test/loss': 2.384011745452881, 'test/num_examples': 10000, 'score': 10139.972554683685, 'total_duration': 10616.673831224442, 'accumulated_submission_time': 10139.972554683685, 'accumulated_eval_time': 475.22561597824097, 'accumulated_logging_time': 0.9130065441131592}
I0914 23:52:36.824421 140329751648000 logging_writer.py:48] [25017] accumulated_eval_time=475.225616, accumulated_logging_time=0.913007, accumulated_submission_time=10139.972555, global_step=25017, preemption_count=0, score=10139.972555, test/accuracy=0.466400, test/loss=2.384012, test/num_examples=10000, total_duration=10616.673831, train/accuracy=0.659258, train/loss=1.396119, validation/accuracy=0.588600, validation/loss=1.728586, validation/num_examples=50000
I0914 23:55:51.343653 140329760040704 logging_writer.py:48] [25500] global_step=25500, grad_norm=1.2052404880523682, loss=2.826047658920288
I0914 23:59:12.442968 140329751648000 logging_writer.py:48] [26000] global_step=26000, grad_norm=1.1093380451202393, loss=3.1940629482269287
I0914 23:59:37.087031 140537819772736 spec.py:320] Evaluating on the training split.
I0914 23:59:47.464351 140537819772736 spec.py:332] Evaluating on the validation split.
I0914 23:59:58.193154 140537819772736 spec.py:348] Evaluating on the test split.
I0914 23:59:59.819954 140537819772736 submission_runner.py:376] Time since start: 11059.69s, 	Step: 26063, 	{'train/accuracy': 0.6375390291213989, 'train/loss': 1.5332105159759521, 'validation/accuracy': 0.5902199745178223, 'validation/loss': 1.7502737045288086, 'validation/num_examples': 50000, 'test/accuracy': 0.47630003094673157, 'test/loss': 2.4023752212524414, 'test/num_examples': 10000, 'score': 10560.198621034622, 'total_duration': 11059.691764354706, 'accumulated_submission_time': 10560.198621034622, 'accumulated_eval_time': 497.9585199356079, 'accumulated_logging_time': 0.9470188617706299}
I0914 23:59:59.840014 140329760040704 logging_writer.py:48] [26063] accumulated_eval_time=497.958520, accumulated_logging_time=0.947019, accumulated_submission_time=10560.198621, global_step=26063, preemption_count=0, score=10560.198621, test/accuracy=0.476300, test/loss=2.402375, test/num_examples=10000, total_duration=11059.691764, train/accuracy=0.637539, train/loss=1.533211, validation/accuracy=0.590220, validation/loss=1.750274, validation/num_examples=50000
I0915 00:02:56.139316 140329751648000 logging_writer.py:48] [26500] global_step=26500, grad_norm=1.5682011842727661, loss=2.4648213386535645
I0915 00:06:17.367954 140329760040704 logging_writer.py:48] [27000] global_step=27000, grad_norm=1.2750060558319092, loss=2.6326160430908203
I0915 00:06:59.889447 140537819772736 spec.py:320] Evaluating on the training split.
I0915 00:07:10.288011 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 00:07:20.916095 140537819772736 spec.py:348] Evaluating on the test split.
I0915 00:07:22.555446 140537819772736 submission_runner.py:376] Time since start: 11502.43s, 	Step: 27107, 	{'train/accuracy': 0.643847644329071, 'train/loss': 1.5001826286315918, 'validation/accuracy': 0.5966599583625793, 'validation/loss': 1.7204481363296509, 'validation/num_examples': 50000, 'test/accuracy': 0.4792000353336334, 'test/loss': 2.3601419925689697, 'test/num_examples': 10000, 'score': 10980.212023735046, 'total_duration': 11502.427257061005, 'accumulated_submission_time': 10980.212023735046, 'accumulated_eval_time': 520.6245007514954, 'accumulated_logging_time': 0.9773416519165039}
I0915 00:07:22.576224 140329751648000 logging_writer.py:48] [27107] accumulated_eval_time=520.624501, accumulated_logging_time=0.977342, accumulated_submission_time=10980.212024, global_step=27107, preemption_count=0, score=10980.212024, test/accuracy=0.479200, test/loss=2.360142, test/num_examples=10000, total_duration=11502.427257, train/accuracy=0.643848, train/loss=1.500183, validation/accuracy=0.596660, validation/loss=1.720448, validation/num_examples=50000
I0915 00:10:01.240477 140329760040704 logging_writer.py:48] [27500] global_step=27500, grad_norm=1.2258882522583008, loss=2.8456830978393555
I0915 00:13:22.556447 140329751648000 logging_writer.py:48] [28000] global_step=28000, grad_norm=1.0470741987228394, loss=3.769587516784668
I0915 00:14:22.749472 140537819772736 spec.py:320] Evaluating on the training split.
I0915 00:14:33.219722 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 00:14:43.893945 140537819772736 spec.py:348] Evaluating on the test split.
I0915 00:14:45.531212 140537819772736 submission_runner.py:376] Time since start: 11945.40s, 	Step: 28151, 	{'train/accuracy': 0.6546484231948853, 'train/loss': 1.4351681470870972, 'validation/accuracy': 0.6003999710083008, 'validation/loss': 1.6897153854370117, 'validation/num_examples': 50000, 'test/accuracy': 0.4782000184059143, 'test/loss': 2.35526967048645, 'test/num_examples': 10000, 'score': 11400.348501682281, 'total_duration': 11945.403007507324, 'accumulated_submission_time': 11400.348501682281, 'accumulated_eval_time': 543.4062235355377, 'accumulated_logging_time': 1.0097651481628418}
I0915 00:14:45.557261 140329760040704 logging_writer.py:48] [28151] accumulated_eval_time=543.406224, accumulated_logging_time=1.009765, accumulated_submission_time=11400.348502, global_step=28151, preemption_count=0, score=11400.348502, test/accuracy=0.478200, test/loss=2.355270, test/num_examples=10000, total_duration=11945.403008, train/accuracy=0.654648, train/loss=1.435168, validation/accuracy=0.600400, validation/loss=1.689715, validation/num_examples=50000
I0915 00:17:06.233905 140329751648000 logging_writer.py:48] [28500] global_step=28500, grad_norm=1.2375978231430054, loss=2.37747859954834
I0915 00:20:27.230513 140329760040704 logging_writer.py:48] [29000] global_step=29000, grad_norm=1.2424206733703613, loss=3.0219500064849854
I0915 00:21:45.862950 140537819772736 spec.py:320] Evaluating on the training split.
I0915 00:21:56.172648 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 00:22:06.992700 140537819772736 spec.py:348] Evaluating on the test split.
I0915 00:22:08.633783 140537819772736 submission_runner.py:376] Time since start: 12388.51s, 	Step: 29197, 	{'train/accuracy': 0.6614453196525574, 'train/loss': 1.3889416456222534, 'validation/accuracy': 0.6024199724197388, 'validation/loss': 1.664762020111084, 'validation/num_examples': 50000, 'test/accuracy': 0.4807000160217285, 'test/loss': 2.3268373012542725, 'test/num_examples': 10000, 'score': 11820.617892742157, 'total_duration': 12388.505590677261, 'accumulated_submission_time': 11820.617892742157, 'accumulated_eval_time': 566.1770503520966, 'accumulated_logging_time': 1.0469262599945068}
I0915 00:22:08.658247 140329751648000 logging_writer.py:48] [29197] accumulated_eval_time=566.177050, accumulated_logging_time=1.046926, accumulated_submission_time=11820.617893, global_step=29197, preemption_count=0, score=11820.617893, test/accuracy=0.480700, test/loss=2.326837, test/num_examples=10000, total_duration=12388.505591, train/accuracy=0.661445, train/loss=1.388942, validation/accuracy=0.602420, validation/loss=1.664762, validation/num_examples=50000
I0915 00:24:10.847163 140329760040704 logging_writer.py:48] [29500] global_step=29500, grad_norm=1.3225035667419434, loss=2.747981309890747
I0915 00:27:31.846131 140329751648000 logging_writer.py:48] [30000] global_step=30000, grad_norm=1.0415616035461426, loss=4.466230392456055
I0915 00:29:08.782248 140537819772736 spec.py:320] Evaluating on the training split.
I0915 00:29:19.388788 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 00:29:29.873468 140537819772736 spec.py:348] Evaluating on the test split.
I0915 00:29:31.507464 140537819772736 submission_runner.py:376] Time since start: 12831.38s, 	Step: 30243, 	{'train/accuracy': 0.6720117330551147, 'train/loss': 1.3487412929534912, 'validation/accuracy': 0.611299991607666, 'validation/loss': 1.6260520219802856, 'validation/num_examples': 50000, 'test/accuracy': 0.49070003628730774, 'test/loss': 2.2795658111572266, 'test/num_examples': 10000, 'score': 12240.705527305603, 'total_duration': 12831.379264831543, 'accumulated_submission_time': 12240.705527305603, 'accumulated_eval_time': 588.9022762775421, 'accumulated_logging_time': 1.0831067562103271}
I0915 00:29:31.529963 140329760040704 logging_writer.py:48] [30243] accumulated_eval_time=588.902276, accumulated_logging_time=1.083107, accumulated_submission_time=12240.705527, global_step=30243, preemption_count=0, score=12240.705527, test/accuracy=0.490700, test/loss=2.279566, test/num_examples=10000, total_duration=12831.379265, train/accuracy=0.672012, train/loss=1.348741, validation/accuracy=0.611300, validation/loss=1.626052, validation/num_examples=50000
I0915 00:31:15.412410 140329751648000 logging_writer.py:48] [30500] global_step=30500, grad_norm=1.3225648403167725, loss=2.6053974628448486
I0915 00:34:36.367463 140329760040704 logging_writer.py:48] [31000] global_step=31000, grad_norm=1.1321204900741577, loss=4.434596061706543
I0915 00:36:31.850178 140537819772736 spec.py:320] Evaluating on the training split.
I0915 00:36:42.253551 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 00:36:52.911250 140537819772736 spec.py:348] Evaluating on the test split.
I0915 00:36:54.543913 140537819772736 submission_runner.py:376] Time since start: 13274.42s, 	Step: 31289, 	{'train/accuracy': 0.6577734351158142, 'train/loss': 1.4198908805847168, 'validation/accuracy': 0.6134600043296814, 'validation/loss': 1.626623511314392, 'validation/num_examples': 50000, 'test/accuracy': 0.4912000298500061, 'test/loss': 2.278754472732544, 'test/num_examples': 10000, 'score': 12660.989580154419, 'total_duration': 13274.41572022438, 'accumulated_submission_time': 12660.989580154419, 'accumulated_eval_time': 611.5960354804993, 'accumulated_logging_time': 1.116150140762329}
I0915 00:36:54.566090 140329751648000 logging_writer.py:48] [31289] accumulated_eval_time=611.596035, accumulated_logging_time=1.116150, accumulated_submission_time=12660.989580, global_step=31289, preemption_count=0, score=12660.989580, test/accuracy=0.491200, test/loss=2.278754, test/num_examples=10000, total_duration=13274.415720, train/accuracy=0.657773, train/loss=1.419891, validation/accuracy=0.613460, validation/loss=1.626624, validation/num_examples=50000
I0915 00:38:19.828080 140329760040704 logging_writer.py:48] [31500] global_step=31500, grad_norm=1.2148323059082031, loss=4.71435546875
I0915 00:41:40.799859 140329751648000 logging_writer.py:48] [32000] global_step=32000, grad_norm=1.065520167350769, loss=4.507961750030518
I0915 00:43:54.696197 140537819772736 spec.py:320] Evaluating on the training split.
I0915 00:44:05.096852 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 00:44:16.011636 140537819772736 spec.py:348] Evaluating on the test split.
I0915 00:44:17.642065 140537819772736 submission_runner.py:376] Time since start: 13717.51s, 	Step: 32335, 	{'train/accuracy': 0.6639062166213989, 'train/loss': 1.4215452671051025, 'validation/accuracy': 0.6152799725532532, 'validation/loss': 1.6467561721801758, 'validation/num_examples': 50000, 'test/accuracy': 0.491100013256073, 'test/loss': 2.315661668777466, 'test/num_examples': 10000, 'score': 13081.082773685455, 'total_duration': 13717.51386976242, 'accumulated_submission_time': 13081.082773685455, 'accumulated_eval_time': 634.5419218540192, 'accumulated_logging_time': 1.1485681533813477}
I0915 00:44:17.664294 140329760040704 logging_writer.py:48] [32335] accumulated_eval_time=634.541922, accumulated_logging_time=1.148568, accumulated_submission_time=13081.082774, global_step=32335, preemption_count=0, score=13081.082774, test/accuracy=0.491100, test/loss=2.315662, test/num_examples=10000, total_duration=13717.513870, train/accuracy=0.663906, train/loss=1.421545, validation/accuracy=0.615280, validation/loss=1.646756, validation/num_examples=50000
I0915 00:45:24.595355 140329751648000 logging_writer.py:48] [32500] global_step=32500, grad_norm=1.4206583499908447, loss=2.395848512649536
I0915 00:48:45.558928 140329760040704 logging_writer.py:48] [33000] global_step=33000, grad_norm=1.5971181392669678, loss=2.5379369258880615
I0915 00:51:17.922131 140537819772736 spec.py:320] Evaluating on the training split.
I0915 00:51:28.202965 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 00:51:38.916897 140537819772736 spec.py:348] Evaluating on the test split.
I0915 00:51:40.557820 140537819772736 submission_runner.py:376] Time since start: 14160.43s, 	Step: 33381, 	{'train/accuracy': 0.6811327934265137, 'train/loss': 1.285815954208374, 'validation/accuracy': 0.6279799938201904, 'validation/loss': 1.549944281578064, 'validation/num_examples': 50000, 'test/accuracy': 0.5012000203132629, 'test/loss': 2.211625576019287, 'test/num_examples': 10000, 'score': 13501.305272102356, 'total_duration': 14160.429625988007, 'accumulated_submission_time': 13501.305272102356, 'accumulated_eval_time': 657.1776139736176, 'accumulated_logging_time': 1.181342363357544}
I0915 00:51:40.580650 140329751648000 logging_writer.py:48] [33381] accumulated_eval_time=657.177614, accumulated_logging_time=1.181342, accumulated_submission_time=13501.305272, global_step=33381, preemption_count=0, score=13501.305272, test/accuracy=0.501200, test/loss=2.211626, test/num_examples=10000, total_duration=14160.429626, train/accuracy=0.681133, train/loss=1.285816, validation/accuracy=0.627980, validation/loss=1.549944, validation/num_examples=50000
I0915 00:52:28.784261 140329760040704 logging_writer.py:48] [33500] global_step=33500, grad_norm=1.2404621839523315, loss=2.8645994663238525
I0915 00:55:49.887815 140329751648000 logging_writer.py:48] [34000] global_step=34000, grad_norm=1.2493536472320557, loss=4.969095230102539
I0915 00:58:40.749464 140537819772736 spec.py:320] Evaluating on the training split.
I0915 00:58:51.300664 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 00:59:01.840706 140537819772736 spec.py:348] Evaluating on the test split.
I0915 00:59:03.486890 140537819772736 submission_runner.py:376] Time since start: 14603.36s, 	Step: 34427, 	{'train/accuracy': 0.6910351514816284, 'train/loss': 1.2600655555725098, 'validation/accuracy': 0.6281599998474121, 'validation/loss': 1.5477452278137207, 'validation/num_examples': 50000, 'test/accuracy': 0.5024999976158142, 'test/loss': 2.2017645835876465, 'test/num_examples': 10000, 'score': 13921.438568115234, 'total_duration': 14603.358687639236, 'accumulated_submission_time': 13921.438568115234, 'accumulated_eval_time': 679.915052652359, 'accumulated_logging_time': 1.2143819332122803}
I0915 00:59:03.512748 140329760040704 logging_writer.py:48] [34427] accumulated_eval_time=679.915053, accumulated_logging_time=1.214382, accumulated_submission_time=13921.438568, global_step=34427, preemption_count=0, score=13921.438568, test/accuracy=0.502500, test/loss=2.201765, test/num_examples=10000, total_duration=14603.358688, train/accuracy=0.691035, train/loss=1.260066, validation/accuracy=0.628160, validation/loss=1.547745, validation/num_examples=50000
I0915 00:59:33.229910 140329751648000 logging_writer.py:48] [34500] global_step=34500, grad_norm=1.241188645362854, loss=2.6119954586029053
I0915 01:02:54.335353 140329760040704 logging_writer.py:48] [35000] global_step=35000, grad_norm=1.1790385246276855, loss=4.651859760284424
I0915 01:06:03.722103 140537819772736 spec.py:320] Evaluating on the training split.
I0915 01:06:13.917320 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 01:06:24.533859 140537819772736 spec.py:348] Evaluating on the test split.
I0915 01:06:26.172030 140537819772736 submission_runner.py:376] Time since start: 15046.04s, 	Step: 35473, 	{'train/accuracy': 0.6890820264816284, 'train/loss': 1.276892900466919, 'validation/accuracy': 0.6319199800491333, 'validation/loss': 1.5410116910934448, 'validation/num_examples': 50000, 'test/accuracy': 0.5051000118255615, 'test/loss': 2.20273756980896, 'test/num_examples': 10000, 'score': 14341.611431360245, 'total_duration': 15046.043815135956, 'accumulated_submission_time': 14341.611431360245, 'accumulated_eval_time': 702.3649613857269, 'accumulated_logging_time': 1.251323938369751}
I0915 01:06:26.196465 140329751648000 logging_writer.py:48] [35473] accumulated_eval_time=702.364961, accumulated_logging_time=1.251324, accumulated_submission_time=14341.611431, global_step=35473, preemption_count=0, score=14341.611431, test/accuracy=0.505100, test/loss=2.202738, test/num_examples=10000, total_duration=15046.043815, train/accuracy=0.689082, train/loss=1.276893, validation/accuracy=0.631920, validation/loss=1.541012, validation/num_examples=50000
I0915 01:06:37.477943 140329760040704 logging_writer.py:48] [35500] global_step=35500, grad_norm=1.22440505027771, loss=5.012158393859863
I0915 01:09:58.538100 140329751648000 logging_writer.py:48] [36000] global_step=36000, grad_norm=1.3573647737503052, loss=2.498790740966797
I0915 01:13:19.572963 140329760040704 logging_writer.py:48] [36500] global_step=36500, grad_norm=1.3245083093643188, loss=2.2175087928771973
I0915 01:13:26.499358 140537819772736 spec.py:320] Evaluating on the training split.
I0915 01:13:36.913193 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 01:13:47.475647 140537819772736 spec.py:348] Evaluating on the test split.
I0915 01:13:49.112307 140537819772736 submission_runner.py:376] Time since start: 15488.98s, 	Step: 36519, 	{'train/accuracy': 0.6860937476158142, 'train/loss': 1.305120825767517, 'validation/accuracy': 0.6332799792289734, 'validation/loss': 1.5361328125, 'validation/num_examples': 50000, 'test/accuracy': 0.5056000351905823, 'test/loss': 2.184114694595337, 'test/num_examples': 10000, 'score': 14761.879046678543, 'total_duration': 15488.98408961296, 'accumulated_submission_time': 14761.879046678543, 'accumulated_eval_time': 724.9778726100922, 'accumulated_logging_time': 1.286210298538208}
I0915 01:13:49.134590 140329751648000 logging_writer.py:48] [36519] accumulated_eval_time=724.977873, accumulated_logging_time=1.286210, accumulated_submission_time=14761.879047, global_step=36519, preemption_count=0, score=14761.879047, test/accuracy=0.505600, test/loss=2.184115, test/num_examples=10000, total_duration=15488.984090, train/accuracy=0.686094, train/loss=1.305121, validation/accuracy=0.633280, validation/loss=1.536133, validation/num_examples=50000
I0915 01:17:02.990744 140329760040704 logging_writer.py:48] [37000] global_step=37000, grad_norm=1.167296290397644, loss=4.724974155426025
I0915 01:20:23.968097 140329751648000 logging_writer.py:48] [37500] global_step=37500, grad_norm=1.2952139377593994, loss=4.712390899658203
I0915 01:20:49.364241 140537819772736 spec.py:320] Evaluating on the training split.
I0915 01:20:59.833121 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 01:21:10.452035 140537819772736 spec.py:348] Evaluating on the test split.
I0915 01:21:12.090042 140537819772736 submission_runner.py:376] Time since start: 15931.96s, 	Step: 37565, 	{'train/accuracy': 0.689453125, 'train/loss': 1.2733736038208008, 'validation/accuracy': 0.6358999609947205, 'validation/loss': 1.5208661556243896, 'validation/num_examples': 50000, 'test/accuracy': 0.5063000321388245, 'test/loss': 2.192904472351074, 'test/num_examples': 10000, 'score': 15182.073817491531, 'total_duration': 15931.961839914322, 'accumulated_submission_time': 15182.073817491531, 'accumulated_eval_time': 747.703675031662, 'accumulated_logging_time': 1.318333387374878}
I0915 01:21:12.111412 140329760040704 logging_writer.py:48] [37565] accumulated_eval_time=747.703675, accumulated_logging_time=1.318333, accumulated_submission_time=15182.073817, global_step=37565, preemption_count=0, score=15182.073817, test/accuracy=0.506300, test/loss=2.192904, test/num_examples=10000, total_duration=15931.961840, train/accuracy=0.689453, train/loss=1.273374, validation/accuracy=0.635900, validation/loss=1.520866, validation/num_examples=50000
I0915 01:24:07.457095 140329751648000 logging_writer.py:48] [38000] global_step=38000, grad_norm=1.368746042251587, loss=2.1393163204193115
I0915 01:27:28.400951 140329760040704 logging_writer.py:48] [38500] global_step=38500, grad_norm=1.1554367542266846, loss=3.654240131378174
I0915 01:28:12.279145 140537819772736 spec.py:320] Evaluating on the training split.
I0915 01:28:22.419802 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 01:28:33.217736 140537819772736 spec.py:348] Evaluating on the test split.
I0915 01:28:34.848668 140537819772736 submission_runner.py:376] Time since start: 16374.72s, 	Step: 38611, 	{'train/accuracy': 0.6935351490974426, 'train/loss': 1.2645710706710815, 'validation/accuracy': 0.6327599883079529, 'validation/loss': 1.5413390398025513, 'validation/num_examples': 50000, 'test/accuracy': 0.5059000253677368, 'test/loss': 2.2100095748901367, 'test/num_examples': 10000, 'score': 15602.20612668991, 'total_duration': 16374.720448493958, 'accumulated_submission_time': 15602.20612668991, 'accumulated_eval_time': 770.2731642723083, 'accumulated_logging_time': 1.3501255512237549}
I0915 01:28:34.876601 140329751648000 logging_writer.py:48] [38611] accumulated_eval_time=770.273164, accumulated_logging_time=1.350126, accumulated_submission_time=15602.206127, global_step=38611, preemption_count=0, score=15602.206127, test/accuracy=0.505900, test/loss=2.210010, test/num_examples=10000, total_duration=16374.720448, train/accuracy=0.693535, train/loss=1.264571, validation/accuracy=0.632760, validation/loss=1.541339, validation/num_examples=50000
I0915 01:31:11.989646 140329760040704 logging_writer.py:48] [39000] global_step=39000, grad_norm=1.2627280950546265, loss=2.276869297027588
I0915 01:34:33.205096 140329751648000 logging_writer.py:48] [39500] global_step=39500, grad_norm=1.4100490808486938, loss=2.43082332611084
I0915 01:35:34.895176 140537819772736 spec.py:320] Evaluating on the training split.
I0915 01:35:45.334683 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 01:35:55.720322 140537819772736 spec.py:348] Evaluating on the test split.
I0915 01:35:57.346792 140537819772736 submission_runner.py:376] Time since start: 16817.22s, 	Step: 39655, 	{'train/accuracy': 0.7108203172683716, 'train/loss': 1.1674636602401733, 'validation/accuracy': 0.6406999826431274, 'validation/loss': 1.480789303779602, 'validation/num_examples': 50000, 'test/accuracy': 0.5179000496864319, 'test/loss': 2.135993480682373, 'test/num_examples': 10000, 'score': 16022.185425043106, 'total_duration': 16817.218598604202, 'accumulated_submission_time': 16022.185425043106, 'accumulated_eval_time': 792.724791765213, 'accumulated_logging_time': 1.392237663269043}
I0915 01:35:57.372294 140329760040704 logging_writer.py:48] [39655] accumulated_eval_time=792.724792, accumulated_logging_time=1.392238, accumulated_submission_time=16022.185425, global_step=39655, preemption_count=0, score=16022.185425, test/accuracy=0.517900, test/loss=2.135993, test/num_examples=10000, total_duration=16817.218599, train/accuracy=0.710820, train/loss=1.167464, validation/accuracy=0.640700, validation/loss=1.480789, validation/num_examples=50000
I0915 01:38:16.870491 140329751648000 logging_writer.py:48] [40000] global_step=40000, grad_norm=1.1525299549102783, loss=3.3290207386016846
I0915 01:41:38.125060 140329760040704 logging_writer.py:48] [40500] global_step=40500, grad_norm=1.4476498365402222, loss=4.87970495223999
I0915 01:42:57.550181 140537819772736 spec.py:320] Evaluating on the training split.
I0915 01:43:08.016921 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 01:43:18.612837 140537819772736 spec.py:348] Evaluating on the test split.
I0915 01:43:20.248280 140537819772736 submission_runner.py:376] Time since start: 17260.12s, 	Step: 40699, 	{'train/accuracy': 0.7011523246765137, 'train/loss': 1.2126903533935547, 'validation/accuracy': 0.6464799642562866, 'validation/loss': 1.4579867124557495, 'validation/num_examples': 50000, 'test/accuracy': 0.51910001039505, 'test/loss': 2.1263158321380615, 'test/num_examples': 10000, 'score': 16442.324369430542, 'total_duration': 17260.120077371597, 'accumulated_submission_time': 16442.324369430542, 'accumulated_eval_time': 815.422857761383, 'accumulated_logging_time': 1.4317491054534912}
I0915 01:43:20.272676 140329751648000 logging_writer.py:48] [40699] accumulated_eval_time=815.422858, accumulated_logging_time=1.431749, accumulated_submission_time=16442.324369, global_step=40699, preemption_count=0, score=16442.324369, test/accuracy=0.519100, test/loss=2.126316, test/num_examples=10000, total_duration=17260.120077, train/accuracy=0.701152, train/loss=1.212690, validation/accuracy=0.646480, validation/loss=1.457987, validation/num_examples=50000
I0915 01:45:21.788266 140329760040704 logging_writer.py:48] [41000] global_step=41000, grad_norm=1.490051507949829, loss=2.117860794067383
I0915 01:48:43.205236 140329751648000 logging_writer.py:48] [41500] global_step=41500, grad_norm=1.4562422037124634, loss=2.2873780727386475
I0915 01:50:20.295692 140537819772736 spec.py:320] Evaluating on the training split.
I0915 01:50:30.816450 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 01:50:41.543174 140537819772736 spec.py:348] Evaluating on the test split.
I0915 01:50:43.176414 140537819772736 submission_runner.py:376] Time since start: 17703.05s, 	Step: 41743, 	{'train/accuracy': 0.7012890577316284, 'train/loss': 1.218484878540039, 'validation/accuracy': 0.6453399658203125, 'validation/loss': 1.464857816696167, 'validation/num_examples': 50000, 'test/accuracy': 0.5200999975204468, 'test/loss': 2.12833833694458, 'test/num_examples': 10000, 'score': 16862.31078505516, 'total_duration': 17703.048202753067, 'accumulated_submission_time': 16862.31078505516, 'accumulated_eval_time': 838.3035740852356, 'accumulated_logging_time': 1.4676263332366943}
I0915 01:50:43.203416 140329760040704 logging_writer.py:48] [41743] accumulated_eval_time=838.303574, accumulated_logging_time=1.467626, accumulated_submission_time=16862.310785, global_step=41743, preemption_count=0, score=16862.310785, test/accuracy=0.520100, test/loss=2.128338, test/num_examples=10000, total_duration=17703.048203, train/accuracy=0.701289, train/loss=1.218485, validation/accuracy=0.645340, validation/loss=1.464858, validation/num_examples=50000
I0915 01:52:27.008044 140329751648000 logging_writer.py:48] [42000] global_step=42000, grad_norm=1.3305178880691528, loss=2.2993216514587402
I0915 01:55:48.389715 140329760040704 logging_writer.py:48] [42500] global_step=42500, grad_norm=1.416202187538147, loss=2.1909146308898926
I0915 01:57:43.558788 140537819772736 spec.py:320] Evaluating on the training split.
I0915 01:57:53.920179 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 01:58:04.459207 140537819772736 spec.py:348] Evaluating on the test split.
I0915 01:58:06.092277 140537819772736 submission_runner.py:376] Time since start: 18145.96s, 	Step: 42788, 	{'train/accuracy': 0.7054687142372131, 'train/loss': 1.1966816186904907, 'validation/accuracy': 0.6466599702835083, 'validation/loss': 1.4641271829605103, 'validation/num_examples': 50000, 'test/accuracy': 0.5159000158309937, 'test/loss': 2.121095895767212, 'test/num_examples': 10000, 'score': 17282.63029909134, 'total_duration': 18145.96408200264, 'accumulated_submission_time': 17282.63029909134, 'accumulated_eval_time': 860.8370833396912, 'accumulated_logging_time': 1.5054385662078857}
I0915 01:58:06.115553 140329751648000 logging_writer.py:48] [42788] accumulated_eval_time=860.837083, accumulated_logging_time=1.505439, accumulated_submission_time=17282.630299, global_step=42788, preemption_count=0, score=17282.630299, test/accuracy=0.515900, test/loss=2.121096, test/num_examples=10000, total_duration=18145.964082, train/accuracy=0.705469, train/loss=1.196682, validation/accuracy=0.646660, validation/loss=1.464127, validation/num_examples=50000
I0915 01:59:31.812477 140329760040704 logging_writer.py:48] [43000] global_step=43000, grad_norm=1.219556212425232, loss=3.698422431945801
I0915 02:02:53.265638 140329751648000 logging_writer.py:48] [43500] global_step=43500, grad_norm=1.4220749139785767, loss=2.452727794647217
I0915 02:05:06.212594 140537819772736 spec.py:320] Evaluating on the training split.
I0915 02:05:16.748087 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 02:05:27.943485 140537819772736 spec.py:348] Evaluating on the test split.
I0915 02:05:29.578111 140537819772736 submission_runner.py:376] Time since start: 18589.45s, 	Step: 43832, 	{'train/accuracy': 0.7114452719688416, 'train/loss': 1.160823941230774, 'validation/accuracy': 0.6499199867248535, 'validation/loss': 1.450548768043518, 'validation/num_examples': 50000, 'test/accuracy': 0.5275000333786011, 'test/loss': 2.1045455932617188, 'test/num_examples': 10000, 'score': 17702.690732479095, 'total_duration': 18589.44991517067, 'accumulated_submission_time': 17702.690732479095, 'accumulated_eval_time': 884.2026906013489, 'accumulated_logging_time': 1.5405313968658447}
I0915 02:05:29.601375 140329760040704 logging_writer.py:48] [43832] accumulated_eval_time=884.202691, accumulated_logging_time=1.540531, accumulated_submission_time=17702.690732, global_step=43832, preemption_count=0, score=17702.690732, test/accuracy=0.527500, test/loss=2.104546, test/num_examples=10000, total_duration=18589.449915, train/accuracy=0.711445, train/loss=1.160824, validation/accuracy=0.649920, validation/loss=1.450549, validation/num_examples=50000
I0915 02:06:37.650388 140329751648000 logging_writer.py:48] [44000] global_step=44000, grad_norm=1.4332072734832764, loss=2.4308857917785645
I0915 02:09:59.078248 140329760040704 logging_writer.py:48] [44500] global_step=44500, grad_norm=1.4618462324142456, loss=2.22772479057312
I0915 02:12:29.748616 140537819772736 spec.py:320] Evaluating on the training split.
I0915 02:12:40.057948 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 02:12:50.642438 140537819772736 spec.py:348] Evaluating on the test split.
I0915 02:12:52.288166 140537819772736 submission_runner.py:376] Time since start: 19032.16s, 	Step: 44876, 	{'train/accuracy': 0.7220116853713989, 'train/loss': 1.1269961595535278, 'validation/accuracy': 0.6525999903678894, 'validation/loss': 1.4376455545425415, 'validation/num_examples': 50000, 'test/accuracy': 0.5297999978065491, 'test/loss': 2.093810558319092, 'test/num_examples': 10000, 'score': 18122.802223920822, 'total_duration': 19032.159947633743, 'accumulated_submission_time': 18122.802223920822, 'accumulated_eval_time': 906.7422378063202, 'accumulated_logging_time': 1.5743987560272217}
I0915 02:12:52.315806 140329751648000 logging_writer.py:48] [44876] accumulated_eval_time=906.742238, accumulated_logging_time=1.574399, accumulated_submission_time=18122.802224, global_step=44876, preemption_count=0, score=18122.802224, test/accuracy=0.529800, test/loss=2.093811, test/num_examples=10000, total_duration=19032.159948, train/accuracy=0.722012, train/loss=1.126996, validation/accuracy=0.652600, validation/loss=1.437646, validation/num_examples=50000
I0915 02:13:42.662853 140329760040704 logging_writer.py:48] [45000] global_step=45000, grad_norm=1.4106098413467407, loss=2.4934520721435547
I0915 02:17:04.097974 140329751648000 logging_writer.py:48] [45500] global_step=45500, grad_norm=1.5715916156768799, loss=2.1486449241638184
I0915 02:19:52.415975 140537819772736 spec.py:320] Evaluating on the training split.
I0915 02:20:02.866204 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 02:20:13.491190 140537819772736 spec.py:348] Evaluating on the test split.
I0915 02:20:15.118420 140537819772736 submission_runner.py:376] Time since start: 19474.99s, 	Step: 45920, 	{'train/accuracy': 0.7103124856948853, 'train/loss': 1.1537997722625732, 'validation/accuracy': 0.6577399969100952, 'validation/loss': 1.4045950174331665, 'validation/num_examples': 50000, 'test/accuracy': 0.5293000340461731, 'test/loss': 2.0719993114471436, 'test/num_examples': 10000, 'score': 18542.8635802269, 'total_duration': 19474.990223884583, 'accumulated_submission_time': 18542.8635802269, 'accumulated_eval_time': 929.4447264671326, 'accumulated_logging_time': 1.6159274578094482}
I0915 02:20:15.142408 140329760040704 logging_writer.py:48] [45920] accumulated_eval_time=929.444726, accumulated_logging_time=1.615927, accumulated_submission_time=18542.863580, global_step=45920, preemption_count=0, score=18542.863580, test/accuracy=0.529300, test/loss=2.071999, test/num_examples=10000, total_duration=19474.990224, train/accuracy=0.710312, train/loss=1.153800, validation/accuracy=0.657740, validation/loss=1.404595, validation/num_examples=50000
I0915 02:20:47.764820 140329751648000 logging_writer.py:48] [46000] global_step=46000, grad_norm=1.2121429443359375, loss=3.008422613143921
I0915 02:24:09.144918 140329760040704 logging_writer.py:48] [46500] global_step=46500, grad_norm=1.4353593587875366, loss=3.0076146125793457
I0915 02:27:15.222637 140537819772736 spec.py:320] Evaluating on the training split.
I0915 02:27:25.438137 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 02:27:36.041857 140537819772736 spec.py:348] Evaluating on the test split.
I0915 02:27:37.673808 140537819772736 submission_runner.py:376] Time since start: 19917.55s, 	Step: 46964, 	{'train/accuracy': 0.7176562547683716, 'train/loss': 1.133830189704895, 'validation/accuracy': 0.6595199704170227, 'validation/loss': 1.3924614191055298, 'validation/num_examples': 50000, 'test/accuracy': 0.5353000164031982, 'test/loss': 2.0363869667053223, 'test/num_examples': 10000, 'score': 18962.907776355743, 'total_duration': 19917.5456097126, 'accumulated_submission_time': 18962.907776355743, 'accumulated_eval_time': 951.8958923816681, 'accumulated_logging_time': 1.6506056785583496}
I0915 02:27:37.697933 140329751648000 logging_writer.py:48] [46964] accumulated_eval_time=951.895892, accumulated_logging_time=1.650606, accumulated_submission_time=18962.907776, global_step=46964, preemption_count=0, score=18962.907776, test/accuracy=0.535300, test/loss=2.036387, test/num_examples=10000, total_duration=19917.545610, train/accuracy=0.717656, train/loss=1.133830, validation/accuracy=0.659520, validation/loss=1.392461, validation/num_examples=50000
I0915 02:27:52.598904 140329760040704 logging_writer.py:48] [47000] global_step=47000, grad_norm=1.2468525171279907, loss=4.331158638000488
I0915 02:31:13.854440 140329751648000 logging_writer.py:48] [47500] global_step=47500, grad_norm=1.411862850189209, loss=3.8978447914123535
I0915 02:34:35.433771 140329760040704 logging_writer.py:48] [48000] global_step=48000, grad_norm=1.354906678199768, loss=3.490166187286377
I0915 02:34:37.931581 140537819772736 spec.py:320] Evaluating on the training split.
I0915 02:34:48.512007 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 02:34:59.000998 140537819772736 spec.py:348] Evaluating on the test split.
I0915 02:35:00.628082 140537819772736 submission_runner.py:376] Time since start: 20360.50s, 	Step: 48008, 	{'train/accuracy': 0.7196484208106995, 'train/loss': 1.1400775909423828, 'validation/accuracy': 0.6626600027084351, 'validation/loss': 1.4136073589324951, 'validation/num_examples': 50000, 'test/accuracy': 0.5332000255584717, 'test/loss': 2.069791793823242, 'test/num_examples': 10000, 'score': 19383.105134487152, 'total_duration': 20360.499856710434, 'accumulated_submission_time': 19383.105134487152, 'accumulated_eval_time': 974.5923511981964, 'accumulated_logging_time': 1.6858062744140625}
I0915 02:35:00.652232 140329751648000 logging_writer.py:48] [48008] accumulated_eval_time=974.592351, accumulated_logging_time=1.685806, accumulated_submission_time=19383.105134, global_step=48008, preemption_count=0, score=19383.105134, test/accuracy=0.533200, test/loss=2.069792, test/num_examples=10000, total_duration=20360.499857, train/accuracy=0.719648, train/loss=1.140078, validation/accuracy=0.662660, validation/loss=1.413607, validation/num_examples=50000
I0915 02:38:19.083191 140329760040704 logging_writer.py:48] [48500] global_step=48500, grad_norm=1.6090302467346191, loss=2.2222020626068115
I0915 02:41:40.523110 140329751648000 logging_writer.py:48] [49000] global_step=49000, grad_norm=1.5176960229873657, loss=2.064034938812256
I0915 02:42:00.763361 140537819772736 spec.py:320] Evaluating on the training split.
I0915 02:42:11.262177 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 02:42:21.760617 140537819772736 spec.py:348] Evaluating on the test split.
I0915 02:42:23.389233 140537819772736 submission_runner.py:376] Time since start: 20803.26s, 	Step: 49052, 	{'train/accuracy': 0.7293164134025574, 'train/loss': 1.0797922611236572, 'validation/accuracy': 0.6621999740600586, 'validation/loss': 1.3735467195510864, 'validation/num_examples': 50000, 'test/accuracy': 0.5355000495910645, 'test/loss': 2.025865316390991, 'test/num_examples': 10000, 'score': 19803.180468320847, 'total_duration': 20803.261009454727, 'accumulated_submission_time': 19803.180468320847, 'accumulated_eval_time': 997.218202829361, 'accumulated_logging_time': 1.7202959060668945}
I0915 02:42:23.411386 140329760040704 logging_writer.py:48] [49052] accumulated_eval_time=997.218203, accumulated_logging_time=1.720296, accumulated_submission_time=19803.180468, global_step=49052, preemption_count=0, score=19803.180468, test/accuracy=0.535500, test/loss=2.025865, test/num_examples=10000, total_duration=20803.261009, train/accuracy=0.729316, train/loss=1.079792, validation/accuracy=0.662200, validation/loss=1.373547, validation/num_examples=50000
I0915 02:45:24.123453 140329751648000 logging_writer.py:48] [49500] global_step=49500, grad_norm=1.3001357316970825, loss=3.6332004070281982
I0915 02:48:45.540198 140329760040704 logging_writer.py:48] [50000] global_step=50000, grad_norm=1.446406364440918, loss=2.0804128646850586
I0915 02:49:23.444101 140537819772736 spec.py:320] Evaluating on the training split.
I0915 02:49:34.059390 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 02:49:44.267349 140537819772736 spec.py:348] Evaluating on the test split.
I0915 02:49:45.899709 140537819772736 submission_runner.py:376] Time since start: 21245.77s, 	Step: 50096, 	{'train/accuracy': 0.7425390481948853, 'train/loss': 1.0094596147537231, 'validation/accuracy': 0.6674599647521973, 'validation/loss': 1.3497782945632935, 'validation/num_examples': 50000, 'test/accuracy': 0.5407000184059143, 'test/loss': 1.9960657358169556, 'test/num_examples': 10000, 'score': 20223.178280830383, 'total_duration': 21245.771508216858, 'accumulated_submission_time': 20223.178280830383, 'accumulated_eval_time': 1019.6738429069519, 'accumulated_logging_time': 1.7522170543670654}
I0915 02:49:45.922648 140329751648000 logging_writer.py:48] [50096] accumulated_eval_time=1019.673843, accumulated_logging_time=1.752217, accumulated_submission_time=20223.178281, global_step=50096, preemption_count=0, score=20223.178281, test/accuracy=0.540700, test/loss=1.996066, test/num_examples=10000, total_duration=21245.771508, train/accuracy=0.742539, train/loss=1.009460, validation/accuracy=0.667460, validation/loss=1.349778, validation/num_examples=50000
I0915 02:52:28.968428 140329760040704 logging_writer.py:48] [50500] global_step=50500, grad_norm=1.4645421504974365, loss=2.1170127391815186
I0915 02:55:50.400270 140329751648000 logging_writer.py:48] [51000] global_step=51000, grad_norm=1.4447418451309204, loss=2.0848581790924072
I0915 02:56:46.084991 140537819772736 spec.py:320] Evaluating on the training split.
I0915 02:56:56.391479 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 02:57:07.200968 140537819772736 spec.py:348] Evaluating on the test split.
I0915 02:57:08.831484 140537819772736 submission_runner.py:376] Time since start: 21688.70s, 	Step: 51140, 	{'train/accuracy': 0.720703125, 'train/loss': 1.1321210861206055, 'validation/accuracy': 0.6626999974250793, 'validation/loss': 1.3917807340621948, 'validation/num_examples': 50000, 'test/accuracy': 0.5369000434875488, 'test/loss': 2.03317928314209, 'test/num_examples': 10000, 'score': 20643.305906772614, 'total_duration': 21688.703287363052, 'accumulated_submission_time': 20643.305906772614, 'accumulated_eval_time': 1042.420334815979, 'accumulated_logging_time': 1.7851319313049316}
I0915 02:57:08.854202 140329760040704 logging_writer.py:48] [51140] accumulated_eval_time=1042.420335, accumulated_logging_time=1.785132, accumulated_submission_time=20643.305907, global_step=51140, preemption_count=0, score=20643.305907, test/accuracy=0.536900, test/loss=2.033179, test/num_examples=10000, total_duration=21688.703287, train/accuracy=0.720703, train/loss=1.132121, validation/accuracy=0.662700, validation/loss=1.391781, validation/num_examples=50000
I0915 02:59:33.865459 140329751648000 logging_writer.py:48] [51500] global_step=51500, grad_norm=1.3646948337554932, loss=2.464489459991455
I0915 03:02:54.952899 140329760040704 logging_writer.py:48] [52000] global_step=52000, grad_norm=1.3657931089401245, loss=2.2672319412231445
I0915 03:04:08.973776 140537819772736 spec.py:320] Evaluating on the training split.
I0915 03:04:18.987985 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 03:04:30.055509 140537819772736 spec.py:348] Evaluating on the test split.
I0915 03:04:31.686608 140537819772736 submission_runner.py:376] Time since start: 22131.56s, 	Step: 52186, 	{'train/accuracy': 0.7272655963897705, 'train/loss': 1.1053509712219238, 'validation/accuracy': 0.6661799550056458, 'validation/loss': 1.3796039819717407, 'validation/num_examples': 50000, 'test/accuracy': 0.5362000465393066, 'test/loss': 2.0262598991394043, 'test/num_examples': 10000, 'score': 21063.390714645386, 'total_duration': 22131.558401346207, 'accumulated_submission_time': 21063.390714645386, 'accumulated_eval_time': 1065.1331419944763, 'accumulated_logging_time': 1.8178050518035889}
I0915 03:04:31.710113 140329751648000 logging_writer.py:48] [52186] accumulated_eval_time=1065.133142, accumulated_logging_time=1.817805, accumulated_submission_time=21063.390715, global_step=52186, preemption_count=0, score=21063.390715, test/accuracy=0.536200, test/loss=2.026260, test/num_examples=10000, total_duration=22131.558401, train/accuracy=0.727266, train/loss=1.105351, validation/accuracy=0.666180, validation/loss=1.379604, validation/num_examples=50000
I0915 03:06:38.460217 140329760040704 logging_writer.py:48] [52500] global_step=52500, grad_norm=1.5551427602767944, loss=2.0096282958984375
I0915 03:09:59.884782 140329751648000 logging_writer.py:48] [53000] global_step=53000, grad_norm=1.5523360967636108, loss=2.1411514282226562
I0915 03:11:31.753757 140537819772736 spec.py:320] Evaluating on the training split.
I0915 03:11:42.316317 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 03:11:52.819123 140537819772736 spec.py:348] Evaluating on the test split.
I0915 03:11:54.451521 140537819772736 submission_runner.py:376] Time since start: 22574.32s, 	Step: 53230, 	{'train/accuracy': 0.7325780987739563, 'train/loss': 1.0678765773773193, 'validation/accuracy': 0.6708599925041199, 'validation/loss': 1.350648283958435, 'validation/num_examples': 50000, 'test/accuracy': 0.5444000363349915, 'test/loss': 1.9937844276428223, 'test/num_examples': 10000, 'score': 21483.39878511429, 'total_duration': 22574.323326587677, 'accumulated_submission_time': 21483.39878511429, 'accumulated_eval_time': 1087.8309314250946, 'accumulated_logging_time': 1.8520488739013672}
I0915 03:11:54.478515 140329760040704 logging_writer.py:48] [53230] accumulated_eval_time=1087.830931, accumulated_logging_time=1.852049, accumulated_submission_time=21483.398785, global_step=53230, preemption_count=0, score=21483.398785, test/accuracy=0.544400, test/loss=1.993784, test/num_examples=10000, total_duration=22574.323327, train/accuracy=0.732578, train/loss=1.067877, validation/accuracy=0.670860, validation/loss=1.350648, validation/num_examples=50000
I0915 03:13:43.364990 140329751648000 logging_writer.py:48] [53500] global_step=53500, grad_norm=1.5062302350997925, loss=2.0445234775543213
I0915 03:17:04.378400 140329760040704 logging_writer.py:48] [54000] global_step=54000, grad_norm=1.4175453186035156, loss=3.320770025253296
I0915 03:18:54.698905 140537819772736 spec.py:320] Evaluating on the training split.
I0915 03:19:05.217640 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 03:19:15.839787 140537819772736 spec.py:348] Evaluating on the test split.
I0915 03:19:17.474153 140537819772736 submission_runner.py:376] Time since start: 23017.35s, 	Step: 54276, 	{'train/accuracy': 0.7409765720367432, 'train/loss': 1.0473791360855103, 'validation/accuracy': 0.6732800006866455, 'validation/loss': 1.3502118587493896, 'validation/num_examples': 50000, 'test/accuracy': 0.5498000383377075, 'test/loss': 2.0068845748901367, 'test/num_examples': 10000, 'score': 21903.58311343193, 'total_duration': 23017.34591269493, 'accumulated_submission_time': 21903.58311343193, 'accumulated_eval_time': 1110.606136083603, 'accumulated_logging_time': 1.8896701335906982}
I0915 03:19:17.498526 140329751648000 logging_writer.py:48] [54276] accumulated_eval_time=1110.606136, accumulated_logging_time=1.889670, accumulated_submission_time=21903.583113, global_step=54276, preemption_count=0, score=21903.583113, test/accuracy=0.549800, test/loss=2.006885, test/num_examples=10000, total_duration=23017.345913, train/accuracy=0.740977, train/loss=1.047379, validation/accuracy=0.673280, validation/loss=1.350212, validation/num_examples=50000
I0915 03:20:47.923732 140329760040704 logging_writer.py:48] [54500] global_step=54500, grad_norm=1.3248931169509888, loss=3.787128210067749
I0915 03:24:08.808160 140329751648000 logging_writer.py:48] [55000] global_step=55000, grad_norm=1.385623812675476, loss=3.5629987716674805
I0915 03:26:17.608486 140537819772736 spec.py:320] Evaluating on the training split.
I0915 03:26:27.975004 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 03:26:39.114336 140537819772736 spec.py:348] Evaluating on the test split.
I0915 03:26:40.750595 140537819772736 submission_runner.py:376] Time since start: 23460.62s, 	Step: 55322, 	{'train/accuracy': 0.7492773532867432, 'train/loss': 1.0066852569580078, 'validation/accuracy': 0.6700800061225891, 'validation/loss': 1.3617175817489624, 'validation/num_examples': 50000, 'test/accuracy': 0.5423000454902649, 'test/loss': 1.99981689453125, 'test/num_examples': 10000, 'score': 22323.654709339142, 'total_duration': 23460.6223859787, 'accumulated_submission_time': 22323.654709339142, 'accumulated_eval_time': 1133.7482361793518, 'accumulated_logging_time': 1.9275503158569336}
I0915 03:26:40.779082 140329760040704 logging_writer.py:48] [55322] accumulated_eval_time=1133.748236, accumulated_logging_time=1.927550, accumulated_submission_time=22323.654709, global_step=55322, preemption_count=0, score=22323.654709, test/accuracy=0.542300, test/loss=1.999817, test/num_examples=10000, total_duration=23460.622386, train/accuracy=0.749277, train/loss=1.006685, validation/accuracy=0.670080, validation/loss=1.361718, validation/num_examples=50000
I0915 03:27:52.671222 140329751648000 logging_writer.py:48] [55500] global_step=55500, grad_norm=1.476830244064331, loss=2.026806592941284
I0915 03:31:13.577205 140329760040704 logging_writer.py:48] [56000] global_step=56000, grad_norm=1.333094596862793, loss=3.72354793548584
I0915 03:33:40.866830 140537819772736 spec.py:320] Evaluating on the training split.
I0915 03:33:50.941481 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 03:34:02.296787 140537819772736 spec.py:348] Evaluating on the test split.
I0915 03:34:03.930731 140537819772736 submission_runner.py:376] Time since start: 23903.80s, 	Step: 56368, 	{'train/accuracy': 0.7328906059265137, 'train/loss': 1.0611153841018677, 'validation/accuracy': 0.6734399795532227, 'validation/loss': 1.3300741910934448, 'validation/num_examples': 50000, 'test/accuracy': 0.5484000444412231, 'test/loss': 1.9824556112289429, 'test/num_examples': 10000, 'score': 22743.70618391037, 'total_duration': 23903.80253624916, 'accumulated_submission_time': 22743.70618391037, 'accumulated_eval_time': 1156.8121283054352, 'accumulated_logging_time': 1.9672307968139648}
I0915 03:34:03.956565 140329751648000 logging_writer.py:48] [56368] accumulated_eval_time=1156.812128, accumulated_logging_time=1.967231, accumulated_submission_time=22743.706184, global_step=56368, preemption_count=0, score=22743.706184, test/accuracy=0.548400, test/loss=1.982456, test/num_examples=10000, total_duration=23903.802536, train/accuracy=0.732891, train/loss=1.061115, validation/accuracy=0.673440, validation/loss=1.330074, validation/num_examples=50000
I0915 03:34:57.382663 140329760040704 logging_writer.py:48] [56500] global_step=56500, grad_norm=1.47505784034729, loss=2.01426362991333
I0915 03:38:18.278526 140329751648000 logging_writer.py:48] [57000] global_step=57000, grad_norm=1.5540544986724854, loss=1.9636735916137695
I0915 03:41:04.070906 140537819772736 spec.py:320] Evaluating on the training split.
I0915 03:41:14.078716 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 03:41:25.354405 140537819772736 spec.py:348] Evaluating on the test split.
I0915 03:41:26.991698 140537819772736 submission_runner.py:376] Time since start: 24346.86s, 	Step: 57414, 	{'train/accuracy': 0.7380077838897705, 'train/loss': 1.0471419095993042, 'validation/accuracy': 0.6793799996376038, 'validation/loss': 1.314753770828247, 'validation/num_examples': 50000, 'test/accuracy': 0.5451000332832336, 'test/loss': 1.9855661392211914, 'test/num_examples': 10000, 'score': 23163.78472018242, 'total_duration': 24346.863499403, 'accumulated_submission_time': 23163.78472018242, 'accumulated_eval_time': 1179.7329053878784, 'accumulated_logging_time': 2.0039446353912354}
I0915 03:41:27.016574 140329760040704 logging_writer.py:48] [57414] accumulated_eval_time=1179.732905, accumulated_logging_time=2.003945, accumulated_submission_time=23163.784720, global_step=57414, preemption_count=0, score=23163.784720, test/accuracy=0.545100, test/loss=1.985566, test/num_examples=10000, total_duration=24346.863499, train/accuracy=0.738008, train/loss=1.047142, validation/accuracy=0.679380, validation/loss=1.314754, validation/num_examples=50000
I0915 03:42:01.971502 140329751648000 logging_writer.py:48] [57500] global_step=57500, grad_norm=1.4813143014907837, loss=2.489309072494507
I0915 03:45:22.808704 140329760040704 logging_writer.py:48] [58000] global_step=58000, grad_norm=1.4350582361221313, loss=4.395947456359863
I0915 03:48:27.146963 140537819772736 spec.py:320] Evaluating on the training split.
I0915 03:48:37.216656 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 03:48:48.450639 140537819772736 spec.py:348] Evaluating on the test split.
I0915 03:48:50.081884 140537819772736 submission_runner.py:376] Time since start: 24789.95s, 	Step: 58460, 	{'train/accuracy': 0.7422851324081421, 'train/loss': 1.0314253568649292, 'validation/accuracy': 0.6783199906349182, 'validation/loss': 1.32110595703125, 'validation/num_examples': 50000, 'test/accuracy': 0.5463000535964966, 'test/loss': 1.967360019683838, 'test/num_examples': 10000, 'score': 23583.87860584259, 'total_duration': 24789.953688383102, 'accumulated_submission_time': 23583.87860584259, 'accumulated_eval_time': 1202.667839050293, 'accumulated_logging_time': 2.040526866912842}
I0915 03:48:50.108131 140329751648000 logging_writer.py:48] [58460] accumulated_eval_time=1202.667839, accumulated_logging_time=2.040527, accumulated_submission_time=23583.878606, global_step=58460, preemption_count=0, score=23583.878606, test/accuracy=0.546300, test/loss=1.967360, test/num_examples=10000, total_duration=24789.953688, train/accuracy=0.742285, train/loss=1.031425, validation/accuracy=0.678320, validation/loss=1.321106, validation/num_examples=50000
I0915 03:49:06.614349 140329760040704 logging_writer.py:48] [58500] global_step=58500, grad_norm=1.3718783855438232, loss=3.929999351501465
I0915 03:52:27.764689 140329751648000 logging_writer.py:48] [59000] global_step=59000, grad_norm=1.610996961593628, loss=4.131406784057617
I0915 03:55:49.218258 140329760040704 logging_writer.py:48] [59500] global_step=59500, grad_norm=1.5929113626480103, loss=1.8723888397216797
I0915 03:55:50.117144 140537819772736 spec.py:320] Evaluating on the training split.
I0915 03:56:00.163915 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 03:56:11.092973 140537819772736 spec.py:348] Evaluating on the test split.
I0915 03:56:12.726922 140537819772736 submission_runner.py:376] Time since start: 25232.60s, 	Step: 59504, 	{'train/accuracy': 0.7533398270606995, 'train/loss': 0.9692489504814148, 'validation/accuracy': 0.681939959526062, 'validation/loss': 1.2824792861938477, 'validation/num_examples': 50000, 'test/accuracy': 0.5559000372886658, 'test/loss': 1.928375482559204, 'test/num_examples': 10000, 'score': 24003.852406978607, 'total_duration': 25232.598729610443, 'accumulated_submission_time': 24003.852406978607, 'accumulated_eval_time': 1225.2775814533234, 'accumulated_logging_time': 2.0775232315063477}
I0915 03:56:12.750230 140329751648000 logging_writer.py:48] [59504] accumulated_eval_time=1225.277581, accumulated_logging_time=2.077523, accumulated_submission_time=24003.852407, global_step=59504, preemption_count=0, score=24003.852407, test/accuracy=0.555900, test/loss=1.928375, test/num_examples=10000, total_duration=25232.598730, train/accuracy=0.753340, train/loss=0.969249, validation/accuracy=0.681940, validation/loss=1.282479, validation/num_examples=50000
I0915 03:59:32.427256 140329760040704 logging_writer.py:48] [60000] global_step=60000, grad_norm=1.3256728649139404, loss=3.325300931930542
I0915 04:02:53.366977 140329751648000 logging_writer.py:48] [60500] global_step=60500, grad_norm=1.5885629653930664, loss=1.8482469320297241
I0915 04:03:12.743046 140537819772736 spec.py:320] Evaluating on the training split.
I0915 04:03:22.676971 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 04:03:33.751502 140537819772736 spec.py:348] Evaluating on the test split.
I0915 04:03:35.381404 140537819772736 submission_runner.py:376] Time since start: 25675.25s, 	Step: 60550, 	{'train/accuracy': 0.7688086032867432, 'train/loss': 0.9273077249526978, 'validation/accuracy': 0.6828399896621704, 'validation/loss': 1.2966340780258179, 'validation/num_examples': 50000, 'test/accuracy': 0.5631999969482422, 'test/loss': 1.9362828731536865, 'test/num_examples': 10000, 'score': 24423.80990076065, 'total_duration': 25675.253208637238, 'accumulated_submission_time': 24423.80990076065, 'accumulated_eval_time': 1247.91592669487, 'accumulated_logging_time': 2.1107754707336426}
I0915 04:03:35.404626 140329760040704 logging_writer.py:48] [60550] accumulated_eval_time=1247.915927, accumulated_logging_time=2.110775, accumulated_submission_time=24423.809901, global_step=60550, preemption_count=0, score=24423.809901, test/accuracy=0.563200, test/loss=1.936283, test/num_examples=10000, total_duration=25675.253209, train/accuracy=0.768809, train/loss=0.927308, validation/accuracy=0.682840, validation/loss=1.296634, validation/num_examples=50000
I0915 04:06:37.012537 140329751648000 logging_writer.py:48] [61000] global_step=61000, grad_norm=1.4732987880706787, loss=3.4262592792510986
I0915 04:09:58.357134 140329760040704 logging_writer.py:48] [61500] global_step=61500, grad_norm=1.56027352809906, loss=1.8974387645721436
I0915 04:10:35.486933 140537819772736 spec.py:320] Evaluating on the training split.
I0915 04:10:45.615683 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 04:10:56.495996 140537819772736 spec.py:348] Evaluating on the test split.
I0915 04:10:58.126364 140537819772736 submission_runner.py:376] Time since start: 26118.00s, 	Step: 61594, 	{'train/accuracy': 0.7467968463897705, 'train/loss': 1.004888892173767, 'validation/accuracy': 0.6855599880218506, 'validation/loss': 1.2787421941757202, 'validation/num_examples': 50000, 'test/accuracy': 0.560200035572052, 'test/loss': 1.9303631782531738, 'test/num_examples': 10000, 'score': 24843.858068466187, 'total_duration': 26117.998169898987, 'accumulated_submission_time': 24843.858068466187, 'accumulated_eval_time': 1270.5553405284882, 'accumulated_logging_time': 2.143885850906372}
I0915 04:10:58.157535 140329751648000 logging_writer.py:48] [61594] accumulated_eval_time=1270.555341, accumulated_logging_time=2.143886, accumulated_submission_time=24843.858068, global_step=61594, preemption_count=0, score=24843.858068, test/accuracy=0.560200, test/loss=1.930363, test/num_examples=10000, total_duration=26117.998170, train/accuracy=0.746797, train/loss=1.004889, validation/accuracy=0.685560, validation/loss=1.278742, validation/num_examples=50000
I0915 04:13:42.062431 140329760040704 logging_writer.py:48] [62000] global_step=62000, grad_norm=1.3396005630493164, loss=2.830371856689453
I0915 04:17:03.367963 140329751648000 logging_writer.py:48] [62500] global_step=62500, grad_norm=1.6117901802062988, loss=1.9383134841918945
I0915 04:17:58.227383 140537819772736 spec.py:320] Evaluating on the training split.
I0915 04:18:08.166245 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 04:18:19.987609 140537819772736 spec.py:348] Evaluating on the test split.
I0915 04:18:21.622118 140537819772736 submission_runner.py:376] Time since start: 26561.49s, 	Step: 62638, 	{'train/accuracy': 0.7509179711341858, 'train/loss': 0.9868904948234558, 'validation/accuracy': 0.6870200037956238, 'validation/loss': 1.2723162174224854, 'validation/num_examples': 50000, 'test/accuracy': 0.5582000017166138, 'test/loss': 1.926504135131836, 'test/num_examples': 10000, 'score': 25263.891897439957, 'total_duration': 26561.49391412735, 'accumulated_submission_time': 25263.891897439957, 'accumulated_eval_time': 1293.9500708580017, 'accumulated_logging_time': 2.185905933380127}
I0915 04:18:21.645597 140329760040704 logging_writer.py:48] [62638] accumulated_eval_time=1293.950071, accumulated_logging_time=2.185906, accumulated_submission_time=25263.891897, global_step=62638, preemption_count=0, score=25263.891897, test/accuracy=0.558200, test/loss=1.926504, test/num_examples=10000, total_duration=26561.493914, train/accuracy=0.750918, train/loss=0.986890, validation/accuracy=0.687020, validation/loss=1.272316, validation/num_examples=50000
I0915 04:20:47.852884 140329751648000 logging_writer.py:48] [63000] global_step=63000, grad_norm=1.6133601665496826, loss=1.9966574907302856
I0915 04:24:09.181207 140329760040704 logging_writer.py:48] [63500] global_step=63500, grad_norm=1.5182255506515503, loss=2.102724075317383
I0915 04:25:21.745790 140537819772736 spec.py:320] Evaluating on the training split.
I0915 04:25:31.822778 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 04:25:43.034600 140537819772736 spec.py:348] Evaluating on the test split.
I0915 04:25:44.659752 140537819772736 submission_runner.py:376] Time since start: 27004.53s, 	Step: 63682, 	{'train/accuracy': 0.7610546946525574, 'train/loss': 0.9363180994987488, 'validation/accuracy': 0.6891199946403503, 'validation/loss': 1.2463955879211426, 'validation/num_examples': 50000, 'test/accuracy': 0.5659000277519226, 'test/loss': 1.8968350887298584, 'test/num_examples': 10000, 'score': 25683.95687198639, 'total_duration': 27004.531557559967, 'accumulated_submission_time': 25683.95687198639, 'accumulated_eval_time': 1316.8640320301056, 'accumulated_logging_time': 2.2196781635284424}
I0915 04:25:44.684497 140329751648000 logging_writer.py:48] [63682] accumulated_eval_time=1316.864032, accumulated_logging_time=2.219678, accumulated_submission_time=25683.956872, global_step=63682, preemption_count=0, score=25683.956872, test/accuracy=0.565900, test/loss=1.896835, test/num_examples=10000, total_duration=27004.531558, train/accuracy=0.761055, train/loss=0.936318, validation/accuracy=0.689120, validation/loss=1.246396, validation/num_examples=50000
I0915 04:27:53.256475 140329760040704 logging_writer.py:48] [64000] global_step=64000, grad_norm=1.4419265985488892, loss=4.331658363342285
I0915 04:31:14.602284 140329751648000 logging_writer.py:48] [64500] global_step=64500, grad_norm=1.6568366289138794, loss=2.053182601928711
I0915 04:32:44.842301 140537819772736 spec.py:320] Evaluating on the training split.
I0915 04:32:54.965153 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 04:33:05.939541 140537819772736 spec.py:348] Evaluating on the test split.
I0915 04:33:07.566082 140537819772736 submission_runner.py:376] Time since start: 27447.44s, 	Step: 64726, 	{'train/accuracy': 0.7672460675239563, 'train/loss': 0.9208914637565613, 'validation/accuracy': 0.6926599740982056, 'validation/loss': 1.2476205825805664, 'validation/num_examples': 50000, 'test/accuracy': 0.5690000057220459, 'test/loss': 1.8818143606185913, 'test/num_examples': 10000, 'score': 26104.077221870422, 'total_duration': 27447.437873125076, 'accumulated_submission_time': 26104.077221870422, 'accumulated_eval_time': 1339.5878205299377, 'accumulated_logging_time': 2.256545305252075}
I0915 04:33:07.590746 140329760040704 logging_writer.py:48] [64726] accumulated_eval_time=1339.587821, accumulated_logging_time=2.256545, accumulated_submission_time=26104.077222, global_step=64726, preemption_count=0, score=26104.077222, test/accuracy=0.569000, test/loss=1.881814, test/num_examples=10000, total_duration=27447.437873, train/accuracy=0.767246, train/loss=0.920891, validation/accuracy=0.692660, validation/loss=1.247621, validation/num_examples=50000
I0915 04:34:58.343409 140329751648000 logging_writer.py:48] [65000] global_step=65000, grad_norm=1.4548404216766357, loss=3.3083043098449707
I0915 04:38:19.577907 140329760040704 logging_writer.py:48] [65500] global_step=65500, grad_norm=1.6663068532943726, loss=1.9385504722595215
I0915 04:40:07.959843 140537819772736 spec.py:320] Evaluating on the training split.
I0915 04:40:18.070405 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 04:40:29.252389 140537819772736 spec.py:348] Evaluating on the test split.
I0915 04:40:30.882972 140537819772736 submission_runner.py:376] Time since start: 27890.75s, 	Step: 65771, 	{'train/accuracy': 0.7828124761581421, 'train/loss': 0.8689783215522766, 'validation/accuracy': 0.6918999552726746, 'validation/loss': 1.257969617843628, 'validation/num_examples': 50000, 'test/accuracy': 0.5678000450134277, 'test/loss': 1.8962740898132324, 'test/num_examples': 10000, 'score': 26524.409328699112, 'total_duration': 27890.754764795303, 'accumulated_submission_time': 26524.409328699112, 'accumulated_eval_time': 1362.5109467506409, 'accumulated_logging_time': 2.2930872440338135}
I0915 04:40:30.913357 140329751648000 logging_writer.py:48] [65771] accumulated_eval_time=1362.510947, accumulated_logging_time=2.293087, accumulated_submission_time=26524.409329, global_step=65771, preemption_count=0, score=26524.409329, test/accuracy=0.567800, test/loss=1.896274, test/num_examples=10000, total_duration=27890.754765, train/accuracy=0.782812, train/loss=0.868978, validation/accuracy=0.691900, validation/loss=1.257970, validation/num_examples=50000
I0915 04:42:03.523716 140329760040704 logging_writer.py:48] [66000] global_step=66000, grad_norm=1.6159615516662598, loss=2.062380790710449
I0915 04:45:24.480133 140329751648000 logging_writer.py:48] [66500] global_step=66500, grad_norm=1.6478875875473022, loss=4.359172344207764
I0915 04:47:31.154925 140537819772736 spec.py:320] Evaluating on the training split.
I0915 04:47:41.254851 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 04:47:52.310319 140537819772736 spec.py:348] Evaluating on the test split.
I0915 04:47:53.931596 140537819772736 submission_runner.py:376] Time since start: 28333.80s, 	Step: 66817, 	{'train/accuracy': 0.7542773485183716, 'train/loss': 0.9646868705749512, 'validation/accuracy': 0.6929999589920044, 'validation/loss': 1.2465510368347168, 'validation/num_examples': 50000, 'test/accuracy': 0.5667999982833862, 'test/loss': 1.9005556106567383, 'test/num_examples': 10000, 'score': 26944.61537194252, 'total_duration': 28333.80340075493, 'accumulated_submission_time': 26944.61537194252, 'accumulated_eval_time': 1385.287623167038, 'accumulated_logging_time': 2.3340845108032227}
I0915 04:47:53.956761 140329760040704 logging_writer.py:48] [66817] accumulated_eval_time=1385.287623, accumulated_logging_time=2.334085, accumulated_submission_time=26944.615372, global_step=66817, preemption_count=0, score=26944.615372, test/accuracy=0.566800, test/loss=1.900556, test/num_examples=10000, total_duration=28333.803401, train/accuracy=0.754277, train/loss=0.964687, validation/accuracy=0.693000, validation/loss=1.246551, validation/num_examples=50000
I0915 04:49:07.894284 140329751648000 logging_writer.py:48] [67000] global_step=67000, grad_norm=1.4364591836929321, loss=3.011441230773926
I0915 04:52:29.085861 140329760040704 logging_writer.py:48] [67500] global_step=67500, grad_norm=1.5926965475082397, loss=2.0556557178497314
I0915 04:54:54.255942 140537819772736 spec.py:320] Evaluating on the training split.
I0915 04:55:04.336454 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 04:55:15.939032 140537819772736 spec.py:348] Evaluating on the test split.
I0915 04:55:17.579934 140537819772736 submission_runner.py:376] Time since start: 28777.45s, 	Step: 67863, 	{'train/accuracy': 0.7608398199081421, 'train/loss': 0.9341602921485901, 'validation/accuracy': 0.6943199634552002, 'validation/loss': 1.2355141639709473, 'validation/num_examples': 50000, 'test/accuracy': 0.5662000179290771, 'test/loss': 1.8756084442138672, 'test/num_examples': 10000, 'score': 27364.878598690033, 'total_duration': 28777.45173764229, 'accumulated_submission_time': 27364.878598690033, 'accumulated_eval_time': 1408.6116247177124, 'accumulated_logging_time': 2.3702986240386963}
I0915 04:55:17.608279 140329751648000 logging_writer.py:48] [67863] accumulated_eval_time=1408.611625, accumulated_logging_time=2.370299, accumulated_submission_time=27364.878599, global_step=67863, preemption_count=0, score=27364.878599, test/accuracy=0.566200, test/loss=1.875608, test/num_examples=10000, total_duration=28777.451738, train/accuracy=0.760840, train/loss=0.934160, validation/accuracy=0.694320, validation/loss=1.235514, validation/num_examples=50000
I0915 04:56:13.128983 140329760040704 logging_writer.py:48] [68000] global_step=68000, grad_norm=1.8120684623718262, loss=1.8639835119247437
I0915 04:59:34.510592 140329751648000 logging_writer.py:48] [68500] global_step=68500, grad_norm=1.7982208728790283, loss=2.36098575592041
I0915 05:02:17.617067 140537819772736 spec.py:320] Evaluating on the training split.
I0915 05:02:27.566869 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 05:02:39.129677 140537819772736 spec.py:348] Evaluating on the test split.
I0915 05:02:40.763051 140537819772736 submission_runner.py:376] Time since start: 29220.63s, 	Step: 68907, 	{'train/accuracy': 0.7695702910423279, 'train/loss': 0.898894727230072, 'validation/accuracy': 0.6972599625587463, 'validation/loss': 1.215494155883789, 'validation/num_examples': 50000, 'test/accuracy': 0.5730000138282776, 'test/loss': 1.8499271869659424, 'test/num_examples': 10000, 'score': 27784.850752592087, 'total_duration': 29220.634857416153, 'accumulated_submission_time': 27784.850752592087, 'accumulated_eval_time': 1431.7575941085815, 'accumulated_logging_time': 2.4106781482696533}
I0915 05:02:40.788347 140329760040704 logging_writer.py:48] [68907] accumulated_eval_time=1431.757594, accumulated_logging_time=2.410678, accumulated_submission_time=27784.850753, global_step=68907, preemption_count=0, score=27784.850753, test/accuracy=0.573000, test/loss=1.849927, test/num_examples=10000, total_duration=29220.634857, train/accuracy=0.769570, train/loss=0.898895, validation/accuracy=0.697260, validation/loss=1.215494, validation/num_examples=50000
I0915 05:03:18.593557 140329751648000 logging_writer.py:48] [69000] global_step=69000, grad_norm=1.8525527715682983, loss=4.304919242858887
I0915 05:06:39.654712 140329760040704 logging_writer.py:48] [69500] global_step=69500, grad_norm=1.5613423585891724, loss=2.191075325012207
I0915 05:09:40.990727 140537819772736 spec.py:320] Evaluating on the training split.
I0915 05:09:51.117761 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 05:10:02.066756 140537819772736 spec.py:348] Evaluating on the test split.
I0915 05:10:03.695793 140537819772736 submission_runner.py:376] Time since start: 29663.57s, 	Step: 69953, 	{'train/accuracy': 0.7740429639816284, 'train/loss': 0.8898206949234009, 'validation/accuracy': 0.7023400068283081, 'validation/loss': 1.2168055772781372, 'validation/num_examples': 50000, 'test/accuracy': 0.5766000151634216, 'test/loss': 1.8437033891677856, 'test/num_examples': 10000, 'score': 28205.016985416412, 'total_duration': 29663.567587137222, 'accumulated_submission_time': 28205.016985416412, 'accumulated_eval_time': 1454.462661743164, 'accumulated_logging_time': 2.44659686088562}
I0915 05:10:03.725358 140329751648000 logging_writer.py:48] [69953] accumulated_eval_time=1454.462662, accumulated_logging_time=2.446597, accumulated_submission_time=28205.016985, global_step=69953, preemption_count=0, score=28205.016985, test/accuracy=0.576600, test/loss=1.843703, test/num_examples=10000, total_duration=29663.567587, train/accuracy=0.774043, train/loss=0.889821, validation/accuracy=0.702340, validation/loss=1.216806, validation/num_examples=50000
I0915 05:10:23.030615 140329760040704 logging_writer.py:48] [70000] global_step=70000, grad_norm=1.5952489376068115, loss=2.090007781982422
I0915 05:13:44.381644 140329751648000 logging_writer.py:48] [70500] global_step=70500, grad_norm=1.6928609609603882, loss=1.9003081321716309
I0915 05:17:04.072788 140537819772736 spec.py:320] Evaluating on the training split.
I0915 05:17:13.899503 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 05:17:25.230555 140537819772736 spec.py:348] Evaluating on the test split.
I0915 05:17:26.858461 140537819772736 submission_runner.py:376] Time since start: 30106.73s, 	Step: 70998, 	{'train/accuracy': 0.7826367020606995, 'train/loss': 0.8583043217658997, 'validation/accuracy': 0.6985399723052979, 'validation/loss': 1.222298264503479, 'validation/num_examples': 50000, 'test/accuracy': 0.5735000371932983, 'test/loss': 1.8572518825531006, 'test/num_examples': 10000, 'score': 28625.32857131958, 'total_duration': 30106.73026561737, 'accumulated_submission_time': 28625.32857131958, 'accumulated_eval_time': 1477.2483327388763, 'accumulated_logging_time': 2.486598014831543}
I0915 05:17:26.883694 140329760040704 logging_writer.py:48] [70998] accumulated_eval_time=1477.248333, accumulated_logging_time=2.486598, accumulated_submission_time=28625.328571, global_step=70998, preemption_count=0, score=28625.328571, test/accuracy=0.573500, test/loss=1.857252, test/num_examples=10000, total_duration=30106.730266, train/accuracy=0.782637, train/loss=0.858304, validation/accuracy=0.698540, validation/loss=1.222298, validation/num_examples=50000
I0915 05:17:28.099181 140329751648000 logging_writer.py:48] [71000] global_step=71000, grad_norm=1.7855780124664307, loss=4.213837623596191
I0915 05:20:49.123430 140329760040704 logging_writer.py:48] [71500] global_step=71500, grad_norm=1.6923588514328003, loss=4.3015546798706055
I0915 05:24:10.030031 140329751648000 logging_writer.py:48] [72000] global_step=72000, grad_norm=1.811881184577942, loss=1.9325273036956787
I0915 05:24:26.966113 140537819772736 spec.py:320] Evaluating on the training split.
I0915 05:24:37.045452 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 05:24:48.081500 140537819772736 spec.py:348] Evaluating on the test split.
I0915 05:24:49.711699 140537819772736 submission_runner.py:376] Time since start: 30549.58s, 	Step: 72044, 	{'train/accuracy': 0.7635937333106995, 'train/loss': 0.9765976667404175, 'validation/accuracy': 0.6970399618148804, 'validation/loss': 1.2639743089675903, 'validation/num_examples': 50000, 'test/accuracy': 0.569100022315979, 'test/loss': 1.9101098775863647, 'test/num_examples': 10000, 'score': 29045.375811338425, 'total_duration': 30549.583501815796, 'accumulated_submission_time': 29045.375811338425, 'accumulated_eval_time': 1499.993905544281, 'accumulated_logging_time': 2.522183418273926}
I0915 05:24:49.735799 140329760040704 logging_writer.py:48] [72044] accumulated_eval_time=1499.993906, accumulated_logging_time=2.522183, accumulated_submission_time=29045.375811, global_step=72044, preemption_count=0, score=29045.375811, test/accuracy=0.569100, test/loss=1.910110, test/num_examples=10000, total_duration=30549.583502, train/accuracy=0.763594, train/loss=0.976598, validation/accuracy=0.697040, validation/loss=1.263974, validation/num_examples=50000
I0915 05:27:53.428016 140329751648000 logging_writer.py:48] [72500] global_step=72500, grad_norm=1.9158893823623657, loss=1.9613654613494873
I0915 05:31:14.378194 140329760040704 logging_writer.py:48] [73000] global_step=73000, grad_norm=1.7142739295959473, loss=3.7657201290130615
I0915 05:31:49.863359 140537819772736 spec.py:320] Evaluating on the training split.
I0915 05:31:59.750609 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 05:32:11.087208 140537819772736 spec.py:348] Evaluating on the test split.
I0915 05:32:12.721211 140537819772736 submission_runner.py:376] Time since start: 30992.59s, 	Step: 73090, 	{'train/accuracy': 0.7737500071525574, 'train/loss': 0.9227266311645508, 'validation/accuracy': 0.7008599638938904, 'validation/loss': 1.2360135316848755, 'validation/num_examples': 50000, 'test/accuracy': 0.5741000175476074, 'test/loss': 1.8782740831375122, 'test/num_examples': 10000, 'score': 29465.468447208405, 'total_duration': 30992.59301328659, 'accumulated_submission_time': 29465.468447208405, 'accumulated_eval_time': 1522.8517498970032, 'accumulated_logging_time': 2.555940866470337}
I0915 05:32:12.745715 140329751648000 logging_writer.py:48] [73090] accumulated_eval_time=1522.851750, accumulated_logging_time=2.555941, accumulated_submission_time=29465.468447, global_step=73090, preemption_count=0, score=29465.468447, test/accuracy=0.574100, test/loss=1.878274, test/num_examples=10000, total_duration=30992.593013, train/accuracy=0.773750, train/loss=0.922727, validation/accuracy=0.700860, validation/loss=1.236014, validation/num_examples=50000
I0915 05:34:57.788313 140329760040704 logging_writer.py:48] [73500] global_step=73500, grad_norm=1.5419310331344604, loss=2.183821439743042
I0915 05:38:18.806277 140329751648000 logging_writer.py:48] [74000] global_step=74000, grad_norm=1.5612311363220215, loss=2.6921212673187256
I0915 05:39:13.119274 140537819772736 spec.py:320] Evaluating on the training split.
I0915 05:39:23.134590 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 05:39:34.245530 140537819772736 spec.py:348] Evaluating on the test split.
I0915 05:39:35.873677 140537819772736 submission_runner.py:376] Time since start: 31435.75s, 	Step: 74137, 	{'train/accuracy': 0.7805273532867432, 'train/loss': 0.8620471954345703, 'validation/accuracy': 0.7059999704360962, 'validation/loss': 1.1919068098068237, 'validation/num_examples': 50000, 'test/accuracy': 0.5764000415802002, 'test/loss': 1.8326680660247803, 'test/num_examples': 10000, 'score': 29885.806559324265, 'total_duration': 31435.74547791481, 'accumulated_submission_time': 29885.806559324265, 'accumulated_eval_time': 1545.6061494350433, 'accumulated_logging_time': 2.590078353881836}
I0915 05:39:35.899644 140329760040704 logging_writer.py:48] [74137] accumulated_eval_time=1545.606149, accumulated_logging_time=2.590078, accumulated_submission_time=29885.806559, global_step=74137, preemption_count=0, score=29885.806559, test/accuracy=0.576400, test/loss=1.832668, test/num_examples=10000, total_duration=31435.745478, train/accuracy=0.780527, train/loss=0.862047, validation/accuracy=0.706000, validation/loss=1.191907, validation/num_examples=50000
I0915 05:42:02.183719 140329751648000 logging_writer.py:48] [74500] global_step=74500, grad_norm=1.8420190811157227, loss=1.8836736679077148
I0915 05:45:23.274111 140329760040704 logging_writer.py:48] [75000] global_step=75000, grad_norm=1.7634787559509277, loss=1.885258436203003
I0915 05:46:36.074184 140537819772736 spec.py:320] Evaluating on the training split.
I0915 05:46:46.077080 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 05:46:57.706777 140537819772736 spec.py:348] Evaluating on the test split.
I0915 05:46:59.333107 140537819772736 submission_runner.py:376] Time since start: 31879.20s, 	Step: 75183, 	{'train/accuracy': 0.7906249761581421, 'train/loss': 0.8165221810340881, 'validation/accuracy': 0.7071999907493591, 'validation/loss': 1.1724038124084473, 'validation/num_examples': 50000, 'test/accuracy': 0.5772000551223755, 'test/loss': 1.8087105751037598, 'test/num_examples': 10000, 'score': 30305.943779706955, 'total_duration': 31879.204911470413, 'accumulated_submission_time': 30305.943779706955, 'accumulated_eval_time': 1568.865062713623, 'accumulated_logging_time': 2.627786874771118}
I0915 05:46:59.364085 140329751648000 logging_writer.py:48] [75183] accumulated_eval_time=1568.865063, accumulated_logging_time=2.627787, accumulated_submission_time=30305.943780, global_step=75183, preemption_count=0, score=30305.943780, test/accuracy=0.577200, test/loss=1.808711, test/num_examples=10000, total_duration=31879.204911, train/accuracy=0.790625, train/loss=0.816522, validation/accuracy=0.707200, validation/loss=1.172404, validation/num_examples=50000
I0915 05:49:07.152251 140329760040704 logging_writer.py:48] [75500] global_step=75500, grad_norm=1.7568215131759644, loss=2.0609428882598877
I0915 05:52:28.193295 140329751648000 logging_writer.py:48] [76000] global_step=76000, grad_norm=1.8316845893859863, loss=1.7995649576187134
I0915 05:53:59.467071 140537819772736 spec.py:320] Evaluating on the training split.
I0915 05:54:09.589625 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 05:54:19.979976 140537819772736 spec.py:348] Evaluating on the test split.
I0915 05:54:21.609333 140537819772736 submission_runner.py:376] Time since start: 32321.48s, 	Step: 76229, 	{'train/accuracy': 0.7838085889816284, 'train/loss': 0.8531697392463684, 'validation/accuracy': 0.7064200043678284, 'validation/loss': 1.1934088468551636, 'validation/num_examples': 50000, 'test/accuracy': 0.5842000246047974, 'test/loss': 1.8177891969680786, 'test/num_examples': 10000, 'score': 30726.010445594788, 'total_duration': 32321.481130599976, 'accumulated_submission_time': 30726.010445594788, 'accumulated_eval_time': 1591.0073211193085, 'accumulated_logging_time': 2.669809579849243}
I0915 05:54:21.639145 140329760040704 logging_writer.py:48] [76229] accumulated_eval_time=1591.007321, accumulated_logging_time=2.669810, accumulated_submission_time=30726.010446, global_step=76229, preemption_count=0, score=30726.010446, test/accuracy=0.584200, test/loss=1.817789, test/num_examples=10000, total_duration=32321.481131, train/accuracy=0.783809, train/loss=0.853170, validation/accuracy=0.706420, validation/loss=1.193409, validation/num_examples=50000
I0915 05:56:11.130950 140329751648000 logging_writer.py:48] [76500] global_step=76500, grad_norm=1.7559447288513184, loss=2.0879783630371094
I0915 05:59:32.486271 140329760040704 logging_writer.py:48] [77000] global_step=77000, grad_norm=1.7387100458145142, loss=3.4905130863189697
I0915 06:01:21.656007 140537819772736 spec.py:320] Evaluating on the training split.
I0915 06:01:31.730309 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 06:01:42.690727 140537819772736 spec.py:348] Evaluating on the test split.
I0915 06:01:44.322496 140537819772736 submission_runner.py:376] Time since start: 32764.19s, 	Step: 77273, 	{'train/accuracy': 0.7840819954872131, 'train/loss': 0.8321162462234497, 'validation/accuracy': 0.7109799981117249, 'validation/loss': 1.1554577350616455, 'validation/num_examples': 50000, 'test/accuracy': 0.5878000259399414, 'test/loss': 1.783922791481018, 'test/num_examples': 10000, 'score': 31145.990751981735, 'total_duration': 32764.194286584854, 'accumulated_submission_time': 31145.990751981735, 'accumulated_eval_time': 1613.673790693283, 'accumulated_logging_time': 2.711463212966919}
I0915 06:01:44.348396 140329751648000 logging_writer.py:48] [77273] accumulated_eval_time=1613.673791, accumulated_logging_time=2.711463, accumulated_submission_time=31145.990752, global_step=77273, preemption_count=0, score=31145.990752, test/accuracy=0.587800, test/loss=1.783923, test/num_examples=10000, total_duration=32764.194287, train/accuracy=0.784082, train/loss=0.832116, validation/accuracy=0.710980, validation/loss=1.155458, validation/num_examples=50000
I0915 06:03:16.105489 140329760040704 logging_writer.py:48] [77500] global_step=77500, grad_norm=1.5146243572235107, loss=2.948970317840576
I0915 06:06:37.522712 140329751648000 logging_writer.py:48] [78000] global_step=78000, grad_norm=1.6998223066329956, loss=2.3330061435699463
I0915 06:08:44.399535 140537819772736 spec.py:320] Evaluating on the training split.
I0915 06:08:54.450485 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 06:09:05.782390 140537819772736 spec.py:348] Evaluating on the test split.
I0915 06:09:07.415784 140537819772736 submission_runner.py:376] Time since start: 33207.29s, 	Step: 78317, 	{'train/accuracy': 0.7808203101158142, 'train/loss': 0.847793459892273, 'validation/accuracy': 0.7127799987792969, 'validation/loss': 1.1588774919509888, 'validation/num_examples': 50000, 'test/accuracy': 0.5850000381469727, 'test/loss': 1.7985299825668335, 'test/num_examples': 10000, 'score': 31566.005507469177, 'total_duration': 33207.28758740425, 'accumulated_submission_time': 31566.005507469177, 'accumulated_eval_time': 1636.690050125122, 'accumulated_logging_time': 2.7483270168304443}
I0915 06:09:07.441988 140329760040704 logging_writer.py:48] [78317] accumulated_eval_time=1636.690050, accumulated_logging_time=2.748327, accumulated_submission_time=31566.005507, global_step=78317, preemption_count=0, score=31566.005507, test/accuracy=0.585000, test/loss=1.798530, test/num_examples=10000, total_duration=33207.287587, train/accuracy=0.780820, train/loss=0.847793, validation/accuracy=0.712780, validation/loss=1.158877, validation/num_examples=50000
I0915 06:10:21.439099 140329751648000 logging_writer.py:48] [78500] global_step=78500, grad_norm=1.8081854581832886, loss=1.6413547992706299
I0915 06:13:42.713255 140329760040704 logging_writer.py:48] [79000] global_step=79000, grad_norm=1.7105987071990967, loss=2.1601345539093018
I0915 06:16:07.708471 140537819772736 spec.py:320] Evaluating on the training split.
I0915 06:16:17.693963 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 06:16:28.784609 140537819772736 spec.py:348] Evaluating on the test split.
I0915 06:16:30.408492 140537819772736 submission_runner.py:376] Time since start: 33650.28s, 	Step: 79362, 	{'train/accuracy': 0.7903124690055847, 'train/loss': 0.8170645236968994, 'validation/accuracy': 0.7137199640274048, 'validation/loss': 1.1454015970230103, 'validation/num_examples': 50000, 'test/accuracy': 0.5854000449180603, 'test/loss': 1.7807621955871582, 'test/num_examples': 10000, 'score': 31986.236578464508, 'total_duration': 33650.28029513359, 'accumulated_submission_time': 31986.236578464508, 'accumulated_eval_time': 1659.390082359314, 'accumulated_logging_time': 2.784764051437378}
I0915 06:16:30.434870 140329751648000 logging_writer.py:48] [79362] accumulated_eval_time=1659.390082, accumulated_logging_time=2.784764, accumulated_submission_time=31986.236578, global_step=79362, preemption_count=0, score=31986.236578, test/accuracy=0.585400, test/loss=1.780762, test/num_examples=10000, total_duration=33650.280295, train/accuracy=0.790312, train/loss=0.817065, validation/accuracy=0.713720, validation/loss=1.145402, validation/num_examples=50000
I0915 06:17:26.374838 140329760040704 logging_writer.py:48] [79500] global_step=79500, grad_norm=1.7124921083450317, loss=2.0459725856781006
I0915 06:20:47.654473 140329751648000 logging_writer.py:48] [80000] global_step=80000, grad_norm=1.9646506309509277, loss=1.8056294918060303
I0915 06:23:30.779937 140537819772736 spec.py:320] Evaluating on the training split.
I0915 06:23:40.884048 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 06:23:52.140951 140537819772736 spec.py:348] Evaluating on the test split.
I0915 06:23:53.772892 140537819772736 submission_runner.py:376] Time since start: 34093.64s, 	Step: 80407, 	{'train/accuracy': 0.7999999523162842, 'train/loss': 0.7721484899520874, 'validation/accuracy': 0.7171199917793274, 'validation/loss': 1.1355528831481934, 'validation/num_examples': 50000, 'test/accuracy': 0.5890000462532043, 'test/loss': 1.780358910560608, 'test/num_examples': 10000, 'score': 32406.544193029404, 'total_duration': 34093.64468455315, 'accumulated_submission_time': 32406.544193029404, 'accumulated_eval_time': 1682.3830344676971, 'accumulated_logging_time': 2.823392391204834}
I0915 06:23:53.800083 140329760040704 logging_writer.py:48] [80407] accumulated_eval_time=1682.383034, accumulated_logging_time=2.823392, accumulated_submission_time=32406.544193, global_step=80407, preemption_count=0, score=32406.544193, test/accuracy=0.589000, test/loss=1.780359, test/num_examples=10000, total_duration=34093.644685, train/accuracy=0.800000, train/loss=0.772148, validation/accuracy=0.717120, validation/loss=1.135553, validation/num_examples=50000
I0915 06:24:31.627131 140329751648000 logging_writer.py:48] [80500] global_step=80500, grad_norm=1.7821574211120605, loss=1.87511146068573
I0915 06:27:52.796984 140329760040704 logging_writer.py:48] [81000] global_step=81000, grad_norm=1.7937099933624268, loss=1.7861816883087158
I0915 06:30:54.131825 140537819772736 spec.py:320] Evaluating on the training split.
I0915 06:31:04.376504 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 06:31:15.905339 140537819772736 spec.py:348] Evaluating on the test split.
I0915 06:31:17.545887 140537819772736 submission_runner.py:376] Time since start: 34537.42s, 	Step: 81452, 	{'train/accuracy': 0.7903906106948853, 'train/loss': 0.827329158782959, 'validation/accuracy': 0.7163999676704407, 'validation/loss': 1.1513112783432007, 'validation/num_examples': 50000, 'test/accuracy': 0.5937000513076782, 'test/loss': 1.776253581047058, 'test/num_examples': 10000, 'score': 32826.838790655136, 'total_duration': 34537.41755390167, 'accumulated_submission_time': 32826.838790655136, 'accumulated_eval_time': 1705.796971321106, 'accumulated_logging_time': 2.8631350994110107}
I0915 06:31:17.575314 140329751648000 logging_writer.py:48] [81452] accumulated_eval_time=1705.796971, accumulated_logging_time=2.863135, accumulated_submission_time=32826.838791, global_step=81452, preemption_count=0, score=32826.838791, test/accuracy=0.593700, test/loss=1.776254, test/num_examples=10000, total_duration=34537.417554, train/accuracy=0.790391, train/loss=0.827329, validation/accuracy=0.716400, validation/loss=1.151311, validation/num_examples=50000
I0915 06:31:37.270583 140329760040704 logging_writer.py:48] [81500] global_step=81500, grad_norm=1.8166751861572266, loss=3.8435099124908447
I0915 06:34:58.472428 140329751648000 logging_writer.py:48] [82000] global_step=82000, grad_norm=1.7273521423339844, loss=2.6188151836395264
I0915 06:38:17.910440 140537819772736 spec.py:320] Evaluating on the training split.
I0915 06:38:27.849267 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 06:38:39.028923 140537819772736 spec.py:348] Evaluating on the test split.
I0915 06:38:40.668545 140537819772736 submission_runner.py:376] Time since start: 34980.54s, 	Step: 82497, 	{'train/accuracy': 0.7898046970367432, 'train/loss': 0.8128694891929626, 'validation/accuracy': 0.7208200097084045, 'validation/loss': 1.130611538887024, 'validation/num_examples': 50000, 'test/accuracy': 0.59170001745224, 'test/loss': 1.7631301879882812, 'test/num_examples': 10000, 'score': 33247.138005018234, 'total_duration': 34980.54034137726, 'accumulated_submission_time': 33247.138005018234, 'accumulated_eval_time': 1728.5550796985626, 'accumulated_logging_time': 2.9031553268432617}
I0915 06:38:40.695452 140329760040704 logging_writer.py:48] [82497] accumulated_eval_time=1728.555080, accumulated_logging_time=2.903155, accumulated_submission_time=33247.138005, global_step=82497, preemption_count=0, score=33247.138005, test/accuracy=0.591700, test/loss=1.763130, test/num_examples=10000, total_duration=34980.540341, train/accuracy=0.789805, train/loss=0.812869, validation/accuracy=0.720820, validation/loss=1.130612, validation/num_examples=50000
I0915 06:38:42.306817 140329751648000 logging_writer.py:48] [82500] global_step=82500, grad_norm=1.8580678701400757, loss=1.6114118099212646
I0915 06:42:03.580717 140329760040704 logging_writer.py:48] [83000] global_step=83000, grad_norm=1.9580883979797363, loss=1.753247618675232
I0915 06:45:24.975263 140329751648000 logging_writer.py:48] [83500] global_step=83500, grad_norm=1.7929563522338867, loss=3.0453574657440186
I0915 06:45:40.786709 140537819772736 spec.py:320] Evaluating on the training split.
I0915 06:45:50.924196 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 06:46:02.046740 140537819772736 spec.py:348] Evaluating on the test split.
I0915 06:46:03.685640 140537819772736 submission_runner.py:376] Time since start: 35423.56s, 	Step: 83541, 	{'train/accuracy': 0.7963476181030273, 'train/loss': 0.8051990866661072, 'validation/accuracy': 0.7178800106048584, 'validation/loss': 1.1363667249679565, 'validation/num_examples': 50000, 'test/accuracy': 0.5927000045776367, 'test/loss': 1.7720719575881958, 'test/num_examples': 10000, 'score': 33667.192929029465, 'total_duration': 35423.55745244026, 'accumulated_submission_time': 33667.192929029465, 'accumulated_eval_time': 1751.4540152549744, 'accumulated_logging_time': 2.941237449645996}
I0915 06:46:03.711980 140329760040704 logging_writer.py:48] [83541] accumulated_eval_time=1751.454015, accumulated_logging_time=2.941237, accumulated_submission_time=33667.192929, global_step=83541, preemption_count=0, score=33667.192929, test/accuracy=0.592700, test/loss=1.772072, test/num_examples=10000, total_duration=35423.557452, train/accuracy=0.796348, train/loss=0.805199, validation/accuracy=0.717880, validation/loss=1.136367, validation/num_examples=50000
I0915 06:49:08.829147 140329751648000 logging_writer.py:48] [84000] global_step=84000, grad_norm=1.9930362701416016, loss=2.3518147468566895
I0915 06:52:30.193981 140329760040704 logging_writer.py:48] [84500] global_step=84500, grad_norm=1.725623607635498, loss=2.5169951915740967
I0915 06:53:04.081214 140537819772736 spec.py:320] Evaluating on the training split.
I0915 06:53:14.148406 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 06:53:25.410306 140537819772736 spec.py:348] Evaluating on the test split.
I0915 06:53:27.034356 140537819772736 submission_runner.py:376] Time since start: 35866.91s, 	Step: 84586, 	{'train/accuracy': 0.8034179210662842, 'train/loss': 0.7592959403991699, 'validation/accuracy': 0.7204799652099609, 'validation/loss': 1.117464303970337, 'validation/num_examples': 50000, 'test/accuracy': 0.5966000556945801, 'test/loss': 1.7558387517929077, 'test/num_examples': 10000, 'score': 34087.52724003792, 'total_duration': 35866.90614461899, 'accumulated_submission_time': 34087.52724003792, 'accumulated_eval_time': 1774.4071393013, 'accumulated_logging_time': 2.9775218963623047}
I0915 06:53:27.063732 140329751648000 logging_writer.py:48] [84586] accumulated_eval_time=1774.407139, accumulated_logging_time=2.977522, accumulated_submission_time=34087.527240, global_step=84586, preemption_count=0, score=34087.527240, test/accuracy=0.596600, test/loss=1.755839, test/num_examples=10000, total_duration=35866.906145, train/accuracy=0.803418, train/loss=0.759296, validation/accuracy=0.720480, validation/loss=1.117464, validation/num_examples=50000
I0915 06:56:14.033441 140329760040704 logging_writer.py:48] [85000] global_step=85000, grad_norm=1.9260849952697754, loss=1.6917262077331543
I0915 06:59:35.435882 140329751648000 logging_writer.py:48] [85500] global_step=85500, grad_norm=1.9865514039993286, loss=1.6632695198059082
I0915 07:00:27.437878 140537819772736 spec.py:320] Evaluating on the training split.
I0915 07:00:37.398482 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 07:00:48.672707 140537819772736 spec.py:348] Evaluating on the test split.
I0915 07:00:50.306424 140537819772736 submission_runner.py:376] Time since start: 36310.18s, 	Step: 85631, 	{'train/accuracy': 0.8080468773841858, 'train/loss': 0.7547733187675476, 'validation/accuracy': 0.7256199717521667, 'validation/loss': 1.1136640310287476, 'validation/num_examples': 50000, 'test/accuracy': 0.5956000089645386, 'test/loss': 1.756873369216919, 'test/num_examples': 10000, 'score': 34507.866179943085, 'total_duration': 36310.178205251694, 'accumulated_submission_time': 34507.866179943085, 'accumulated_eval_time': 1797.2756581306458, 'accumulated_logging_time': 3.016528367996216}
I0915 07:00:50.342866 140329760040704 logging_writer.py:48] [85631] accumulated_eval_time=1797.275658, accumulated_logging_time=3.016528, accumulated_submission_time=34507.866180, global_step=85631, preemption_count=0, score=34507.866180, test/accuracy=0.595600, test/loss=1.756873, test/num_examples=10000, total_duration=36310.178205, train/accuracy=0.808047, train/loss=0.754773, validation/accuracy=0.725620, validation/loss=1.113664, validation/num_examples=50000
I0915 07:03:19.225464 140329751648000 logging_writer.py:48] [86000] global_step=86000, grad_norm=1.9541161060333252, loss=1.7414965629577637
I0915 07:06:40.619447 140329760040704 logging_writer.py:48] [86500] global_step=86500, grad_norm=1.9858800172805786, loss=1.6399250030517578
I0915 07:07:50.357585 140537819772736 spec.py:320] Evaluating on the training split.
I0915 07:08:00.473015 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 07:08:11.789706 140537819772736 spec.py:348] Evaluating on the test split.
I0915 07:08:13.418901 140537819772736 submission_runner.py:376] Time since start: 36753.29s, 	Step: 86675, 	{'train/accuracy': 0.7999023199081421, 'train/loss': 0.7769256234169006, 'validation/accuracy': 0.7250999808311462, 'validation/loss': 1.1005381345748901, 'validation/num_examples': 50000, 'test/accuracy': 0.6010000109672546, 'test/loss': 1.7377148866653442, 'test/num_examples': 10000, 'score': 34927.84551358223, 'total_duration': 36753.29070973396, 'accumulated_submission_time': 34927.84551358223, 'accumulated_eval_time': 1820.3369822502136, 'accumulated_logging_time': 3.0633578300476074}
I0915 07:08:13.445892 140329751648000 logging_writer.py:48] [86675] accumulated_eval_time=1820.336982, accumulated_logging_time=3.063358, accumulated_submission_time=34927.845514, global_step=86675, preemption_count=0, score=34927.845514, test/accuracy=0.601000, test/loss=1.737715, test/num_examples=10000, total_duration=36753.290710, train/accuracy=0.799902, train/loss=0.776926, validation/accuracy=0.725100, validation/loss=1.100538, validation/num_examples=50000
I0915 07:10:24.367584 140329760040704 logging_writer.py:48] [87000] global_step=87000, grad_norm=1.9174216985702515, loss=1.5733342170715332
I0915 07:13:45.243542 140329751648000 logging_writer.py:48] [87500] global_step=87500, grad_norm=1.8399262428283691, loss=3.30576229095459
I0915 07:15:13.496160 140537819772736 spec.py:320] Evaluating on the training split.
I0915 07:15:23.547642 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 07:15:35.041610 140537819772736 spec.py:348] Evaluating on the test split.
I0915 07:15:36.675097 140537819772736 submission_runner.py:376] Time since start: 37196.55s, 	Step: 87721, 	{'train/accuracy': 0.8044140338897705, 'train/loss': 0.756144642829895, 'validation/accuracy': 0.7270999550819397, 'validation/loss': 1.0915273427963257, 'validation/num_examples': 50000, 'test/accuracy': 0.6003000140190125, 'test/loss': 1.7185434103012085, 'test/num_examples': 10000, 'score': 35347.86026406288, 'total_duration': 37196.54690337181, 'accumulated_submission_time': 35347.86026406288, 'accumulated_eval_time': 1843.5159730911255, 'accumulated_logging_time': 3.100771903991699}
I0915 07:15:36.702474 140329760040704 logging_writer.py:48] [87721] accumulated_eval_time=1843.515973, accumulated_logging_time=3.100772, accumulated_submission_time=35347.860264, global_step=87721, preemption_count=0, score=35347.860264, test/accuracy=0.600300, test/loss=1.718543, test/num_examples=10000, total_duration=37196.546903, train/accuracy=0.804414, train/loss=0.756145, validation/accuracy=0.727100, validation/loss=1.091527, validation/num_examples=50000
I0915 07:17:29.148241 140329751648000 logging_writer.py:48] [88000] global_step=88000, grad_norm=2.01900053024292, loss=3.514303207397461
I0915 07:20:49.980614 140329760040704 logging_writer.py:48] [88500] global_step=88500, grad_norm=2.0477099418640137, loss=1.655208706855774
I0915 07:22:37.073916 140537819772736 spec.py:320] Evaluating on the training split.
I0915 07:22:47.193153 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 07:22:58.214038 140537819772736 spec.py:348] Evaluating on the test split.
I0915 07:22:59.848110 140537819772736 submission_runner.py:376] Time since start: 37639.72s, 	Step: 88768, 	{'train/accuracy': 0.8026366829872131, 'train/loss': 0.7944849133491516, 'validation/accuracy': 0.727620005607605, 'validation/loss': 1.126023769378662, 'validation/num_examples': 50000, 'test/accuracy': 0.598800003528595, 'test/loss': 1.7579188346862793, 'test/num_examples': 10000, 'score': 35768.194784879684, 'total_duration': 37639.71990132332, 'accumulated_submission_time': 35768.194784879684, 'accumulated_eval_time': 1866.2901298999786, 'accumulated_logging_time': 3.1405704021453857}
I0915 07:22:59.874892 140329751648000 logging_writer.py:48] [88768] accumulated_eval_time=1866.290130, accumulated_logging_time=3.140570, accumulated_submission_time=35768.194785, global_step=88768, preemption_count=0, score=35768.194785, test/accuracy=0.598800, test/loss=1.757919, test/num_examples=10000, total_duration=37639.719901, train/accuracy=0.802637, train/loss=0.794485, validation/accuracy=0.727620, validation/loss=1.126024, validation/num_examples=50000
I0915 07:24:33.630225 140329760040704 logging_writer.py:48] [89000] global_step=89000, grad_norm=2.0738840103149414, loss=1.5822440385818481
I0915 07:27:54.905871 140329751648000 logging_writer.py:48] [89500] global_step=89500, grad_norm=2.019577741622925, loss=1.5135608911514282
I0915 07:29:59.896908 140537819772736 spec.py:320] Evaluating on the training split.
I0915 07:30:09.912051 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 07:30:21.322726 140537819772736 spec.py:348] Evaluating on the test split.
I0915 07:30:22.950686 140537819772736 submission_runner.py:376] Time since start: 38082.82s, 	Step: 89812, 	{'train/accuracy': 0.8099804520606995, 'train/loss': 0.7534193396568298, 'validation/accuracy': 0.7278800010681152, 'validation/loss': 1.109052062034607, 'validation/num_examples': 50000, 'test/accuracy': 0.6020000576972961, 'test/loss': 1.734480381011963, 'test/num_examples': 10000, 'score': 36188.180827856064, 'total_duration': 38082.822477817535, 'accumulated_submission_time': 36188.180827856064, 'accumulated_eval_time': 1889.3438789844513, 'accumulated_logging_time': 3.1781435012817383}
I0915 07:30:22.979002 140329760040704 logging_writer.py:48] [89812] accumulated_eval_time=1889.343879, accumulated_logging_time=3.178144, accumulated_submission_time=36188.180828, global_step=89812, preemption_count=0, score=36188.180828, test/accuracy=0.602000, test/loss=1.734480, test/num_examples=10000, total_duration=38082.822478, train/accuracy=0.809980, train/loss=0.753419, validation/accuracy=0.727880, validation/loss=1.109052, validation/num_examples=50000
I0915 07:31:39.019096 140329751648000 logging_writer.py:48] [90000] global_step=90000, grad_norm=2.094775676727295, loss=1.6518524885177612
I0915 07:35:00.202537 140329760040704 logging_writer.py:48] [90500] global_step=90500, grad_norm=1.9179776906967163, loss=2.0978341102600098
I0915 07:37:23.321800 140537819772736 spec.py:320] Evaluating on the training split.
I0915 07:37:33.559298 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 07:37:44.538692 140537819772736 spec.py:348] Evaluating on the test split.
I0915 07:37:46.177532 140537819772736 submission_runner.py:376] Time since start: 38526.05s, 	Step: 90857, 	{'train/accuracy': 0.8208593726158142, 'train/loss': 0.7060486674308777, 'validation/accuracy': 0.7312600016593933, 'validation/loss': 1.084007978439331, 'validation/num_examples': 50000, 'test/accuracy': 0.6088000535964966, 'test/loss': 1.7144088745117188, 'test/num_examples': 10000, 'score': 36608.48800897598, 'total_duration': 38526.04933142662, 'accumulated_submission_time': 36608.48800897598, 'accumulated_eval_time': 1912.1996190547943, 'accumulated_logging_time': 3.217334270477295}
I0915 07:37:46.207426 140329751648000 logging_writer.py:48] [90857] accumulated_eval_time=1912.199619, accumulated_logging_time=3.217334, accumulated_submission_time=36608.488009, global_step=90857, preemption_count=0, score=36608.488009, test/accuracy=0.608800, test/loss=1.714409, test/num_examples=10000, total_duration=38526.049331, train/accuracy=0.820859, train/loss=0.706049, validation/accuracy=0.731260, validation/loss=1.084008, validation/num_examples=50000
I0915 07:38:44.149480 140329760040704 logging_writer.py:48] [91000] global_step=91000, grad_norm=1.7882897853851318, loss=2.7667088508605957
I0915 07:42:05.349712 140329751648000 logging_writer.py:48] [91500] global_step=91500, grad_norm=2.005474090576172, loss=1.5152037143707275
I0915 07:44:46.406083 140537819772736 spec.py:320] Evaluating on the training split.
I0915 07:44:56.550355 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 07:45:07.666450 140537819772736 spec.py:348] Evaluating on the test split.
I0915 07:45:09.302775 140537819772736 submission_runner.py:376] Time since start: 38969.17s, 	Step: 91902, 	{'train/accuracy': 0.8119531273841858, 'train/loss': 0.7181794047355652, 'validation/accuracy': 0.7342000007629395, 'validation/loss': 1.0619198083877563, 'validation/num_examples': 50000, 'test/accuracy': 0.6134000420570374, 'test/loss': 1.6721934080123901, 'test/num_examples': 10000, 'score': 37028.64994573593, 'total_duration': 38969.17458200455, 'accumulated_submission_time': 37028.64994573593, 'accumulated_eval_time': 1935.0963258743286, 'accumulated_logging_time': 3.2581679821014404}
I0915 07:45:09.330080 140329760040704 logging_writer.py:48] [91902] accumulated_eval_time=1935.096326, accumulated_logging_time=3.258168, accumulated_submission_time=37028.649946, global_step=91902, preemption_count=0, score=37028.649946, test/accuracy=0.613400, test/loss=1.672193, test/num_examples=10000, total_duration=38969.174582, train/accuracy=0.811953, train/loss=0.718179, validation/accuracy=0.734200, validation/loss=1.061920, validation/num_examples=50000
I0915 07:45:49.352262 140329751648000 logging_writer.py:48] [92000] global_step=92000, grad_norm=2.0570945739746094, loss=2.923262119293213
I0915 07:49:10.585325 140329760040704 logging_writer.py:48] [92500] global_step=92500, grad_norm=2.272031784057617, loss=1.564023494720459
I0915 07:52:09.335837 140537819772736 spec.py:320] Evaluating on the training split.
I0915 07:52:19.266804 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 07:52:30.580693 140537819772736 spec.py:348] Evaluating on the test split.
I0915 07:52:32.218788 140537819772736 submission_runner.py:376] Time since start: 39412.09s, 	Step: 92946, 	{'train/accuracy': 0.8158007860183716, 'train/loss': 0.7065762281417847, 'validation/accuracy': 0.7360000014305115, 'validation/loss': 1.0474801063537598, 'validation/num_examples': 50000, 'test/accuracy': 0.6073000431060791, 'test/loss': 1.6745374202728271, 'test/num_examples': 10000, 'score': 37448.61979484558, 'total_duration': 39412.09059381485, 'accumulated_submission_time': 37448.61979484558, 'accumulated_eval_time': 1957.9792883396149, 'accumulated_logging_time': 3.2959954738616943}
I0915 07:52:32.246151 140329751648000 logging_writer.py:48] [92946] accumulated_eval_time=1957.979288, accumulated_logging_time=3.295995, accumulated_submission_time=37448.619795, global_step=92946, preemption_count=0, score=37448.619795, test/accuracy=0.607300, test/loss=1.674537, test/num_examples=10000, total_duration=39412.090594, train/accuracy=0.815801, train/loss=0.706576, validation/accuracy=0.736000, validation/loss=1.047480, validation/num_examples=50000
I0915 07:52:54.533814 140329760040704 logging_writer.py:48] [93000] global_step=93000, grad_norm=1.9021682739257812, loss=2.3187716007232666
I0915 07:56:15.673210 140329751648000 logging_writer.py:48] [93500] global_step=93500, grad_norm=2.120661735534668, loss=1.6819716691970825
I0915 07:59:32.545779 140537819772736 spec.py:320] Evaluating on the training split.
I0915 07:59:42.614960 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 07:59:54.246701 140537819772736 spec.py:348] Evaluating on the test split.
I0915 07:59:55.878191 140537819772736 submission_runner.py:376] Time since start: 39855.75s, 	Step: 93991, 	{'train/accuracy': 0.8186327815055847, 'train/loss': 0.6984440684318542, 'validation/accuracy': 0.7351399660110474, 'validation/loss': 1.0580488443374634, 'validation/num_examples': 50000, 'test/accuracy': 0.6057000160217285, 'test/loss': 1.6909916400909424, 'test/num_examples': 10000, 'score': 37868.88370323181, 'total_duration': 39855.74999141693, 'accumulated_submission_time': 37868.88370323181, 'accumulated_eval_time': 1981.3117098808289, 'accumulated_logging_time': 3.3336610794067383}
I0915 07:59:55.905245 140329760040704 logging_writer.py:48] [93991] accumulated_eval_time=1981.311710, accumulated_logging_time=3.333661, accumulated_submission_time=37868.883703, global_step=93991, preemption_count=0, score=37868.883703, test/accuracy=0.605700, test/loss=1.690992, test/num_examples=10000, total_duration=39855.749991, train/accuracy=0.818633, train/loss=0.698444, validation/accuracy=0.735140, validation/loss=1.058049, validation/num_examples=50000
I0915 07:59:59.938542 140329751648000 logging_writer.py:48] [94000] global_step=94000, grad_norm=2.1743874549865723, loss=1.612959861755371
I0915 08:03:21.229841 140329760040704 logging_writer.py:48] [94500] global_step=94500, grad_norm=2.243023157119751, loss=1.5095548629760742
I0915 08:06:42.478031 140329751648000 logging_writer.py:48] [95000] global_step=95000, grad_norm=2.2154293060302734, loss=1.455851674079895
I0915 08:06:56.258117 140537819772736 spec.py:320] Evaluating on the training split.
I0915 08:07:06.369141 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 08:07:17.438025 140537819772736 spec.py:348] Evaluating on the test split.
I0915 08:07:19.071092 140537819772736 submission_runner.py:376] Time since start: 40298.94s, 	Step: 95036, 	{'train/accuracy': 0.8239257335662842, 'train/loss': 0.6699681878089905, 'validation/accuracy': 0.7370799779891968, 'validation/loss': 1.0492831468582153, 'validation/num_examples': 50000, 'test/accuracy': 0.6055000424385071, 'test/loss': 1.6872801780700684, 'test/num_examples': 10000, 'score': 38289.20016694069, 'total_duration': 40298.94289398193, 'accumulated_submission_time': 38289.20016694069, 'accumulated_eval_time': 2004.1246738433838, 'accumulated_logging_time': 3.3717031478881836}
I0915 08:07:19.099593 140329760040704 logging_writer.py:48] [95036] accumulated_eval_time=2004.124674, accumulated_logging_time=3.371703, accumulated_submission_time=38289.200167, global_step=95036, preemption_count=0, score=38289.200167, test/accuracy=0.605500, test/loss=1.687280, test/num_examples=10000, total_duration=40298.942894, train/accuracy=0.823926, train/loss=0.669968, validation/accuracy=0.737080, validation/loss=1.049283, validation/num_examples=50000
I0915 08:10:26.037588 140329751648000 logging_writer.py:48] [95500] global_step=95500, grad_norm=2.3139865398406982, loss=1.608579397201538
I0915 08:13:46.942058 140329760040704 logging_writer.py:48] [96000] global_step=96000, grad_norm=1.9538851976394653, loss=1.8637974262237549
I0915 08:14:19.189038 140537819772736 spec.py:320] Evaluating on the training split.
I0915 08:14:29.196147 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 08:14:40.432948 140537819772736 spec.py:348] Evaluating on the test split.
I0915 08:14:42.061828 140537819772736 submission_runner.py:376] Time since start: 40741.93s, 	Step: 96082, 	{'train/accuracy': 0.8350195288658142, 'train/loss': 0.6252655386924744, 'validation/accuracy': 0.7393999695777893, 'validation/loss': 1.0339401960372925, 'validation/num_examples': 50000, 'test/accuracy': 0.612500011920929, 'test/loss': 1.660857081413269, 'test/num_examples': 10000, 'score': 38709.25033950806, 'total_duration': 40741.93362522125, 'accumulated_submission_time': 38709.25033950806, 'accumulated_eval_time': 2026.997453212738, 'accumulated_logging_time': 3.414003849029541}
I0915 08:14:42.088568 140329751648000 logging_writer.py:48] [96082] accumulated_eval_time=2026.997453, accumulated_logging_time=3.414004, accumulated_submission_time=38709.250340, global_step=96082, preemption_count=0, score=38709.250340, test/accuracy=0.612500, test/loss=1.660857, test/num_examples=10000, total_duration=40741.933625, train/accuracy=0.835020, train/loss=0.625266, validation/accuracy=0.739400, validation/loss=1.033940, validation/num_examples=50000
I0915 08:17:30.842755 140329760040704 logging_writer.py:48] [96500] global_step=96500, grad_norm=1.9336642026901245, loss=2.6666293144226074
I0915 08:20:52.090743 140329751648000 logging_writer.py:48] [97000] global_step=97000, grad_norm=2.3349838256835938, loss=1.4725877046585083
I0915 08:21:42.083040 140537819772736 spec.py:320] Evaluating on the training split.
I0915 08:21:52.274443 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 08:22:03.460836 140537819772736 spec.py:348] Evaluating on the test split.
I0915 08:22:05.091475 140537819772736 submission_runner.py:376] Time since start: 41184.96s, 	Step: 97126, 	{'train/accuracy': 0.8185351490974426, 'train/loss': 0.695246696472168, 'validation/accuracy': 0.7389599680900574, 'validation/loss': 1.0398509502410889, 'validation/num_examples': 50000, 'test/accuracy': 0.6117000579833984, 'test/loss': 1.684255599975586, 'test/num_examples': 10000, 'score': 39129.209339141846, 'total_duration': 41184.96327972412, 'accumulated_submission_time': 39129.209339141846, 'accumulated_eval_time': 2050.0059106349945, 'accumulated_logging_time': 3.4506795406341553}
I0915 08:22:05.119384 140329760040704 logging_writer.py:48] [97126] accumulated_eval_time=2050.005911, accumulated_logging_time=3.450680, accumulated_submission_time=39129.209339, global_step=97126, preemption_count=0, score=39129.209339, test/accuracy=0.611700, test/loss=1.684256, test/num_examples=10000, total_duration=41184.963280, train/accuracy=0.818535, train/loss=0.695247, validation/accuracy=0.738960, validation/loss=1.039851, validation/num_examples=50000
I0915 08:24:36.158936 140329751648000 logging_writer.py:48] [97500] global_step=97500, grad_norm=1.913503885269165, loss=1.9508076906204224
I0915 08:27:57.406968 140329760040704 logging_writer.py:48] [98000] global_step=98000, grad_norm=2.3792061805725098, loss=1.4944015741348267
I0915 08:29:05.122070 140537819772736 spec.py:320] Evaluating on the training split.
I0915 08:29:15.136883 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 08:29:26.616220 140537819772736 spec.py:348] Evaluating on the test split.
I0915 08:29:28.244520 140537819772736 submission_runner.py:376] Time since start: 41628.12s, 	Step: 98170, 	{'train/accuracy': 0.8245898485183716, 'train/loss': 0.6779055595397949, 'validation/accuracy': 0.740839958190918, 'validation/loss': 1.0352259874343872, 'validation/num_examples': 50000, 'test/accuracy': 0.6186000108718872, 'test/loss': 1.6553895473480225, 'test/num_examples': 10000, 'score': 39549.17415523529, 'total_duration': 41628.11632466316, 'accumulated_submission_time': 39549.17415523529, 'accumulated_eval_time': 2073.1283807754517, 'accumulated_logging_time': 3.4909555912017822}
I0915 08:29:28.273780 140329751648000 logging_writer.py:48] [98170] accumulated_eval_time=2073.128381, accumulated_logging_time=3.490956, accumulated_submission_time=39549.174155, global_step=98170, preemption_count=0, score=39549.174155, test/accuracy=0.618600, test/loss=1.655390, test/num_examples=10000, total_duration=41628.116325, train/accuracy=0.824590, train/loss=0.677906, validation/accuracy=0.740840, validation/loss=1.035226, validation/num_examples=50000
I0915 08:31:41.613604 140329760040704 logging_writer.py:48] [98500] global_step=98500, grad_norm=2.237260341644287, loss=1.6248433589935303
I0915 08:35:02.840646 140329751648000 logging_writer.py:48] [99000] global_step=99000, grad_norm=2.1500918865203857, loss=1.5401170253753662
I0915 08:36:28.643755 140537819772736 spec.py:320] Evaluating on the training split.
I0915 08:36:38.789949 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 08:36:50.368030 140537819772736 spec.py:348] Evaluating on the test split.
I0915 08:36:52.002430 140537819772736 submission_runner.py:376] Time since start: 42071.87s, 	Step: 99215, 	{'train/accuracy': 0.8324413895606995, 'train/loss': 0.6326121091842651, 'validation/accuracy': 0.7423799633979797, 'validation/loss': 1.017187476158142, 'validation/num_examples': 50000, 'test/accuracy': 0.6147000193595886, 'test/loss': 1.649651050567627, 'test/num_examples': 10000, 'score': 39969.50755906105, 'total_duration': 42071.874230861664, 'accumulated_submission_time': 39969.50755906105, 'accumulated_eval_time': 2096.4870545864105, 'accumulated_logging_time': 3.5312397480010986}
I0915 08:36:52.034430 140329760040704 logging_writer.py:48] [99215] accumulated_eval_time=2096.487055, accumulated_logging_time=3.531240, accumulated_submission_time=39969.507559, global_step=99215, preemption_count=0, score=39969.507559, test/accuracy=0.614700, test/loss=1.649651, test/num_examples=10000, total_duration=42071.874231, train/accuracy=0.832441, train/loss=0.632612, validation/accuracy=0.742380, validation/loss=1.017187, validation/num_examples=50000
I0915 08:38:47.211432 140329751648000 logging_writer.py:48] [99500] global_step=99500, grad_norm=2.2083756923675537, loss=3.746046543121338
I0915 08:42:08.447423 140329760040704 logging_writer.py:48] [100000] global_step=100000, grad_norm=2.5841407775878906, loss=3.6303255558013916
I0915 08:43:52.387108 140537819772736 spec.py:320] Evaluating on the training split.
I0915 08:44:02.524871 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 08:44:13.923147 140537819772736 spec.py:348] Evaluating on the test split.
I0915 08:44:15.556624 140537819772736 submission_runner.py:376] Time since start: 42515.43s, 	Step: 100260, 	{'train/accuracy': 0.8389452695846558, 'train/loss': 0.6219362020492554, 'validation/accuracy': 0.7434999942779541, 'validation/loss': 1.022175908088684, 'validation/num_examples': 50000, 'test/accuracy': 0.6147000193595886, 'test/loss': 1.6470781564712524, 'test/num_examples': 10000, 'score': 40389.82040929794, 'total_duration': 42515.428419589996, 'accumulated_submission_time': 40389.82040929794, 'accumulated_eval_time': 2119.656588792801, 'accumulated_logging_time': 3.57741379737854}
I0915 08:44:15.585189 140329751648000 logging_writer.py:48] [100260] accumulated_eval_time=2119.656589, accumulated_logging_time=3.577414, accumulated_submission_time=40389.820409, global_step=100260, preemption_count=0, score=40389.820409, test/accuracy=0.614700, test/loss=1.647078, test/num_examples=10000, total_duration=42515.428420, train/accuracy=0.838945, train/loss=0.621936, validation/accuracy=0.743500, validation/loss=1.022176, validation/num_examples=50000
I0915 08:45:52.524323 140329760040704 logging_writer.py:48] [100500] global_step=100500, grad_norm=2.4794373512268066, loss=3.021483898162842
I0915 08:49:13.930835 140329751648000 logging_writer.py:48] [101000] global_step=101000, grad_norm=2.1422533988952637, loss=2.6223409175872803
I0915 08:51:15.958361 140537819772736 spec.py:320] Evaluating on the training split.
I0915 08:51:25.884397 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 08:51:37.345514 140537819772736 spec.py:348] Evaluating on the test split.
I0915 08:51:38.979947 140537819772736 submission_runner.py:376] Time since start: 42958.85s, 	Step: 101305, 	{'train/accuracy': 0.8449609279632568, 'train/loss': 0.6025171279907227, 'validation/accuracy': 0.7428799867630005, 'validation/loss': 1.0217797756195068, 'validation/num_examples': 50000, 'test/accuracy': 0.6155000329017639, 'test/loss': 1.640717625617981, 'test/num_examples': 10000, 'score': 40810.15608167648, 'total_duration': 42958.85174679756, 'accumulated_submission_time': 40810.15608167648, 'accumulated_eval_time': 2142.678171157837, 'accumulated_logging_time': 3.6179349422454834}
I0915 08:51:39.008071 140329760040704 logging_writer.py:48] [101305] accumulated_eval_time=2142.678171, accumulated_logging_time=3.617935, accumulated_submission_time=40810.156082, global_step=101305, preemption_count=0, score=40810.156082, test/accuracy=0.615500, test/loss=1.640718, test/num_examples=10000, total_duration=42958.851747, train/accuracy=0.844961, train/loss=0.602517, validation/accuracy=0.742880, validation/loss=1.021780, validation/num_examples=50000
I0915 08:52:57.857542 140329751648000 logging_writer.py:48] [101500] global_step=101500, grad_norm=2.1338918209075928, loss=1.4760332107543945
I0915 08:56:19.155289 140329760040704 logging_writer.py:48] [102000] global_step=102000, grad_norm=2.273576498031616, loss=3.06937837600708
I0915 08:58:39.293141 140537819772736 spec.py:320] Evaluating on the training split.
I0915 08:58:49.630555 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 08:59:00.094828 140537819772736 spec.py:348] Evaluating on the test split.
I0915 08:59:01.729229 140537819772736 submission_runner.py:376] Time since start: 43401.60s, 	Step: 102350, 	{'train/accuracy': 0.8340234160423279, 'train/loss': 0.6444380283355713, 'validation/accuracy': 0.7454400062561035, 'validation/loss': 1.013909935951233, 'validation/num_examples': 50000, 'test/accuracy': 0.6213000416755676, 'test/loss': 1.636124610900879, 'test/num_examples': 10000, 'score': 41230.40488195419, 'total_duration': 43401.60101008415, 'accumulated_submission_time': 41230.40488195419, 'accumulated_eval_time': 2165.1142427921295, 'accumulated_logging_time': 3.656766891479492}
I0915 08:59:01.758882 140329751648000 logging_writer.py:48] [102350] accumulated_eval_time=2165.114243, accumulated_logging_time=3.656767, accumulated_submission_time=41230.404882, global_step=102350, preemption_count=0, score=41230.404882, test/accuracy=0.621300, test/loss=1.636125, test/num_examples=10000, total_duration=43401.601010, train/accuracy=0.834023, train/loss=0.644438, validation/accuracy=0.745440, validation/loss=1.013910, validation/num_examples=50000
I0915 09:00:02.532371 140329760040704 logging_writer.py:48] [102500] global_step=102500, grad_norm=2.4984421730041504, loss=2.464599609375
I0915 09:03:23.960832 140329751648000 logging_writer.py:48] [103000] global_step=103000, grad_norm=2.3199405670166016, loss=1.575162649154663
I0915 09:06:01.889793 140537819772736 spec.py:320] Evaluating on the training split.
I0915 09:06:11.849389 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 09:06:23.307067 140537819772736 spec.py:348] Evaluating on the test split.
I0915 09:06:24.942994 140537819772736 submission_runner.py:376] Time since start: 43844.81s, 	Step: 103394, 	{'train/accuracy': 0.8389062285423279, 'train/loss': 0.6242377161979675, 'validation/accuracy': 0.7505799531936646, 'validation/loss': 1.0007450580596924, 'validation/num_examples': 50000, 'test/accuracy': 0.6234000325202942, 'test/loss': 1.6206493377685547, 'test/num_examples': 10000, 'score': 41650.50008225441, 'total_duration': 43844.81479001045, 'accumulated_submission_time': 41650.50008225441, 'accumulated_eval_time': 2188.1674411296844, 'accumulated_logging_time': 3.697463274002075}
I0915 09:06:24.970676 140329760040704 logging_writer.py:48] [103394] accumulated_eval_time=2188.167441, accumulated_logging_time=3.697463, accumulated_submission_time=41650.500082, global_step=103394, preemption_count=0, score=41650.500082, test/accuracy=0.623400, test/loss=1.620649, test/num_examples=10000, total_duration=43844.814790, train/accuracy=0.838906, train/loss=0.624238, validation/accuracy=0.750580, validation/loss=1.000745, validation/num_examples=50000
I0915 09:07:08.008013 140329751648000 logging_writer.py:48] [103500] global_step=103500, grad_norm=2.566011905670166, loss=1.4402166604995728
I0915 09:10:28.920308 140329760040704 logging_writer.py:48] [104000] global_step=104000, grad_norm=2.566455602645874, loss=3.498394727706909
I0915 09:13:24.969371 140537819772736 spec.py:320] Evaluating on the training split.
I0915 09:13:35.146957 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 09:13:46.323168 140537819772736 spec.py:348] Evaluating on the test split.
I0915 09:13:47.954763 140537819772736 submission_runner.py:376] Time since start: 44287.83s, 	Step: 104440, 	{'train/accuracy': 0.8372265696525574, 'train/loss': 0.6193738579750061, 'validation/accuracy': 0.7492199540138245, 'validation/loss': 1.0026942491531372, 'validation/num_examples': 50000, 'test/accuracy': 0.6220000386238098, 'test/loss': 1.6266696453094482, 'test/num_examples': 10000, 'score': 42070.46156835556, 'total_duration': 44287.82656097412, 'accumulated_submission_time': 42070.46156835556, 'accumulated_eval_time': 2211.152854204178, 'accumulated_logging_time': 3.7372419834136963}
I0915 09:13:47.983783 140329751648000 logging_writer.py:48] [104440] accumulated_eval_time=2211.152854, accumulated_logging_time=3.737242, accumulated_submission_time=42070.461568, global_step=104440, preemption_count=0, score=42070.461568, test/accuracy=0.622000, test/loss=1.626670, test/num_examples=10000, total_duration=44287.826561, train/accuracy=0.837227, train/loss=0.619374, validation/accuracy=0.749220, validation/loss=1.002694, validation/num_examples=50000
I0915 09:14:12.490129 140329760040704 logging_writer.py:48] [104500] global_step=104500, grad_norm=2.3346452713012695, loss=2.071287155151367
I0915 09:17:33.485173 140329751648000 logging_writer.py:48] [105000] global_step=105000, grad_norm=2.2796249389648438, loss=1.4754631519317627
I0915 09:20:48.032630 140537819772736 spec.py:320] Evaluating on the training split.
I0915 09:20:58.181875 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 09:21:10.141697 140537819772736 spec.py:348] Evaluating on the test split.
I0915 09:21:11.771394 140537819772736 submission_runner.py:376] Time since start: 44731.64s, 	Step: 105486, 	{'train/accuracy': 0.84730464220047, 'train/loss': 0.5663691163063049, 'validation/accuracy': 0.7495200037956238, 'validation/loss': 0.9787986278533936, 'validation/num_examples': 50000, 'test/accuracy': 0.6267000436782837, 'test/loss': 1.6092926263809204, 'test/num_examples': 10000, 'score': 42490.475023031235, 'total_duration': 44731.64317655563, 'accumulated_submission_time': 42490.475023031235, 'accumulated_eval_time': 2234.891610145569, 'accumulated_logging_time': 3.777486562728882}
I0915 09:21:11.801505 140329760040704 logging_writer.py:48] [105486] accumulated_eval_time=2234.891610, accumulated_logging_time=3.777487, accumulated_submission_time=42490.475023, global_step=105486, preemption_count=0, score=42490.475023, test/accuracy=0.626700, test/loss=1.609293, test/num_examples=10000, total_duration=44731.643177, train/accuracy=0.847305, train/loss=0.566369, validation/accuracy=0.749520, validation/loss=0.978799, validation/num_examples=50000
I0915 09:21:17.832866 140329751648000 logging_writer.py:48] [105500] global_step=105500, grad_norm=2.430988073348999, loss=1.6105175018310547
I0915 09:24:38.749776 140329760040704 logging_writer.py:48] [106000] global_step=106000, grad_norm=2.335707664489746, loss=1.7262626886367798
I0915 09:27:59.653809 140329751648000 logging_writer.py:48] [106500] global_step=106500, grad_norm=2.8101208209991455, loss=3.7343854904174805
I0915 09:28:11.799501 140537819772736 spec.py:320] Evaluating on the training split.
I0915 09:28:21.971502 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 09:28:33.506390 140537819772736 spec.py:348] Evaluating on the test split.
I0915 09:28:35.136446 140537819772736 submission_runner.py:376] Time since start: 45175.01s, 	Step: 106532, 	{'train/accuracy': 0.8542187213897705, 'train/loss': 0.5452814102172852, 'validation/accuracy': 0.752020001411438, 'validation/loss': 0.9748799204826355, 'validation/num_examples': 50000, 'test/accuracy': 0.6295000314712524, 'test/loss': 1.5967910289764404, 'test/num_examples': 10000, 'score': 42910.437056303024, 'total_duration': 45175.0082552433, 'accumulated_submission_time': 42910.437056303024, 'accumulated_eval_time': 2258.228541612625, 'accumulated_logging_time': 3.818650484085083}
I0915 09:28:35.163900 140329760040704 logging_writer.py:48] [106532] accumulated_eval_time=2258.228542, accumulated_logging_time=3.818650, accumulated_submission_time=42910.437056, global_step=106532, preemption_count=0, score=42910.437056, test/accuracy=0.629500, test/loss=1.596791, test/num_examples=10000, total_duration=45175.008255, train/accuracy=0.854219, train/loss=0.545281, validation/accuracy=0.752020, validation/loss=0.974880, validation/num_examples=50000
I0915 09:31:43.793880 140329751648000 logging_writer.py:48] [107000] global_step=107000, grad_norm=2.452653169631958, loss=1.3850295543670654
I0915 09:35:05.129398 140329760040704 logging_writer.py:48] [107500] global_step=107500, grad_norm=2.763596534729004, loss=3.7554001808166504
I0915 09:35:35.407038 140537819772736 spec.py:320] Evaluating on the training split.
I0915 09:35:45.589269 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 09:35:57.299297 140537819772736 spec.py:348] Evaluating on the test split.
I0915 09:35:58.929420 140537819772736 submission_runner.py:376] Time since start: 45618.80s, 	Step: 107577, 	{'train/accuracy': 0.8407617211341858, 'train/loss': 0.5951334834098816, 'validation/accuracy': 0.7549799680709839, 'validation/loss': 0.9696326851844788, 'validation/num_examples': 50000, 'test/accuracy': 0.6306000351905823, 'test/loss': 1.5867396593093872, 'test/num_examples': 10000, 'score': 43330.64552640915, 'total_duration': 45618.80122709274, 'accumulated_submission_time': 43330.64552640915, 'accumulated_eval_time': 2281.7509183883667, 'accumulated_logging_time': 3.8563034534454346}
I0915 09:35:58.956445 140329751648000 logging_writer.py:48] [107577] accumulated_eval_time=2281.750918, accumulated_logging_time=3.856303, accumulated_submission_time=43330.645526, global_step=107577, preemption_count=0, score=43330.645526, test/accuracy=0.630600, test/loss=1.586740, test/num_examples=10000, total_duration=45618.801227, train/accuracy=0.840762, train/loss=0.595133, validation/accuracy=0.754980, validation/loss=0.969633, validation/num_examples=50000
I0915 09:38:49.475095 140329760040704 logging_writer.py:48] [108000] global_step=108000, grad_norm=2.310011625289917, loss=3.091986656188965
I0915 09:42:10.856346 140329751648000 logging_writer.py:48] [108500] global_step=108500, grad_norm=2.8031277656555176, loss=3.52303409576416
I0915 09:42:59.264405 140537819772736 spec.py:320] Evaluating on the training split.
I0915 09:43:09.564601 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 09:43:20.426549 140537819772736 spec.py:348] Evaluating on the test split.
I0915 09:43:22.050025 140537819772736 submission_runner.py:376] Time since start: 46061.92s, 	Step: 108622, 	{'train/accuracy': 0.8445116877555847, 'train/loss': 0.5901142954826355, 'validation/accuracy': 0.7546799778938293, 'validation/loss': 0.9761546850204468, 'validation/num_examples': 50000, 'test/accuracy': 0.6291000247001648, 'test/loss': 1.590201735496521, 'test/num_examples': 10000, 'score': 43750.918407678604, 'total_duration': 46061.92183113098, 'accumulated_submission_time': 43750.918407678604, 'accumulated_eval_time': 2304.5365624427795, 'accumulated_logging_time': 3.8930726051330566}
I0915 09:43:22.078450 140329760040704 logging_writer.py:48] [108622] accumulated_eval_time=2304.536562, accumulated_logging_time=3.893073, accumulated_submission_time=43750.918408, global_step=108622, preemption_count=0, score=43750.918408, test/accuracy=0.629100, test/loss=1.590202, test/num_examples=10000, total_duration=46061.921831, train/accuracy=0.844512, train/loss=0.590114, validation/accuracy=0.754680, validation/loss=0.976155, validation/num_examples=50000
I0915 09:45:54.281295 140329751648000 logging_writer.py:48] [109000] global_step=109000, grad_norm=3.0397870540618896, loss=3.644069194793701
I0915 09:49:15.233304 140329760040704 logging_writer.py:48] [109500] global_step=109500, grad_norm=2.4337873458862305, loss=2.6911566257476807
I0915 09:50:22.409464 140537819772736 spec.py:320] Evaluating on the training split.
I0915 09:50:32.442639 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 09:50:43.485310 140537819772736 spec.py:348] Evaluating on the test split.
I0915 09:50:45.116860 140537819772736 submission_runner.py:376] Time since start: 46504.99s, 	Step: 109669, 	{'train/accuracy': 0.849609375, 'train/loss': 0.5754680633544922, 'validation/accuracy': 0.7551199793815613, 'validation/loss': 0.9709078073501587, 'validation/num_examples': 50000, 'test/accuracy': 0.6338000297546387, 'test/loss': 1.585841178894043, 'test/num_examples': 10000, 'score': 44171.21485042572, 'total_duration': 46504.98866915703, 'accumulated_submission_time': 44171.21485042572, 'accumulated_eval_time': 2327.243965148926, 'accumulated_logging_time': 3.931236982345581}
I0915 09:50:45.147087 140329751648000 logging_writer.py:48] [109669] accumulated_eval_time=2327.243965, accumulated_logging_time=3.931237, accumulated_submission_time=44171.214850, global_step=109669, preemption_count=0, score=44171.214850, test/accuracy=0.633800, test/loss=1.585841, test/num_examples=10000, total_duration=46504.988669, train/accuracy=0.849609, train/loss=0.575468, validation/accuracy=0.755120, validation/loss=0.970908, validation/num_examples=50000
I0915 09:52:58.517181 140329760040704 logging_writer.py:48] [110000] global_step=110000, grad_norm=3.014296293258667, loss=3.5913679599761963
I0915 09:56:19.491753 140329751648000 logging_writer.py:48] [110500] global_step=110500, grad_norm=2.6328284740448, loss=3.2438855171203613
I0915 09:57:45.122676 140537819772736 spec.py:320] Evaluating on the training split.
I0915 09:57:55.319715 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 09:58:06.524160 140537819772736 spec.py:348] Evaluating on the test split.
I0915 09:58:08.150438 140537819772736 submission_runner.py:376] Time since start: 46948.02s, 	Step: 110715, 	{'train/accuracy': 0.8553320169448853, 'train/loss': 0.5444430112838745, 'validation/accuracy': 0.7557799816131592, 'validation/loss': 0.9649862051010132, 'validation/num_examples': 50000, 'test/accuracy': 0.6357000470161438, 'test/loss': 1.5745275020599365, 'test/num_examples': 10000, 'score': 44591.15257000923, 'total_duration': 46948.02224588394, 'accumulated_submission_time': 44591.15257000923, 'accumulated_eval_time': 2350.271733522415, 'accumulated_logging_time': 3.974497079849243}
I0915 09:58:08.179817 140329760040704 logging_writer.py:48] [110715] accumulated_eval_time=2350.271734, accumulated_logging_time=3.974497, accumulated_submission_time=44591.152570, global_step=110715, preemption_count=0, score=44591.152570, test/accuracy=0.635700, test/loss=1.574528, test/num_examples=10000, total_duration=46948.022246, train/accuracy=0.855332, train/loss=0.544443, validation/accuracy=0.755780, validation/loss=0.964986, validation/num_examples=50000
I0915 10:00:03.090124 140329751648000 logging_writer.py:48] [111000] global_step=111000, grad_norm=2.4511444568634033, loss=1.6891505718231201
I0915 10:03:24.173790 140329760040704 logging_writer.py:48] [111500] global_step=111500, grad_norm=2.5865676403045654, loss=1.3626564741134644
I0915 10:05:08.335186 140537819772736 spec.py:320] Evaluating on the training split.
I0915 10:05:18.549453 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 10:05:29.707314 140537819772736 spec.py:348] Evaluating on the test split.
I0915 10:05:31.338886 140537819772736 submission_runner.py:376] Time since start: 47391.21s, 	Step: 111761, 	{'train/accuracy': 0.8616796731948853, 'train/loss': 0.5260344743728638, 'validation/accuracy': 0.7577799558639526, 'validation/loss': 0.9589682817459106, 'validation/num_examples': 50000, 'test/accuracy': 0.6353000402450562, 'test/loss': 1.566028356552124, 'test/num_examples': 10000, 'score': 45011.27219748497, 'total_duration': 47391.21069025993, 'accumulated_submission_time': 45011.27219748497, 'accumulated_eval_time': 2373.275441646576, 'accumulated_logging_time': 4.014634370803833}
I0915 10:05:31.371335 140329751648000 logging_writer.py:48] [111761] accumulated_eval_time=2373.275442, accumulated_logging_time=4.014634, accumulated_submission_time=45011.272197, global_step=111761, preemption_count=0, score=45011.272197, test/accuracy=0.635300, test/loss=1.566028, test/num_examples=10000, total_duration=47391.210690, train/accuracy=0.861680, train/loss=0.526034, validation/accuracy=0.757780, validation/loss=0.958968, validation/num_examples=50000
I0915 10:07:07.780099 140329760040704 logging_writer.py:48] [112000] global_step=112000, grad_norm=2.625331163406372, loss=3.3624813556671143
I0915 10:10:28.840696 140329751648000 logging_writer.py:48] [112500] global_step=112500, grad_norm=2.7562427520751953, loss=1.3560943603515625
I0915 10:12:31.424227 140537819772736 spec.py:320] Evaluating on the training split.
I0915 10:12:41.603878 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 10:12:53.160414 140537819772736 spec.py:348] Evaluating on the test split.
I0915 10:12:54.789592 140537819772736 submission_runner.py:376] Time since start: 47834.66s, 	Step: 112807, 	{'train/accuracy': 0.8544335961341858, 'train/loss': 0.5604527592658997, 'validation/accuracy': 0.7591399550437927, 'validation/loss': 0.9580339789390564, 'validation/num_examples': 50000, 'test/accuracy': 0.6363000273704529, 'test/loss': 1.5757502317428589, 'test/num_examples': 10000, 'score': 45431.288873910904, 'total_duration': 47834.66138648987, 'accumulated_submission_time': 45431.288873910904, 'accumulated_eval_time': 2396.6408009529114, 'accumulated_logging_time': 4.05814266204834}
I0915 10:12:54.820225 140329760040704 logging_writer.py:48] [112807] accumulated_eval_time=2396.640801, accumulated_logging_time=4.058143, accumulated_submission_time=45431.288874, global_step=112807, preemption_count=0, score=45431.288874, test/accuracy=0.636300, test/loss=1.575750, test/num_examples=10000, total_duration=47834.661386, train/accuracy=0.854434, train/loss=0.560453, validation/accuracy=0.759140, validation/loss=0.958034, validation/num_examples=50000
I0915 10:14:12.776751 140329751648000 logging_writer.py:48] [113000] global_step=113000, grad_norm=2.431248426437378, loss=1.392471194267273
I0915 10:17:33.635496 140329760040704 logging_writer.py:48] [113500] global_step=113500, grad_norm=2.6445136070251465, loss=1.2896491289138794
I0915 10:19:54.924504 140537819772736 spec.py:320] Evaluating on the training split.
I0915 10:20:05.112951 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 10:20:16.722314 140537819772736 spec.py:348] Evaluating on the test split.
I0915 10:20:18.343155 140537819772736 submission_runner.py:376] Time since start: 48278.21s, 	Step: 113853, 	{'train/accuracy': 0.8554101586341858, 'train/loss': 0.5423293709754944, 'validation/accuracy': 0.7605999708175659, 'validation/loss': 0.9480263590812683, 'validation/num_examples': 50000, 'test/accuracy': 0.6361000537872314, 'test/loss': 1.5560686588287354, 'test/num_examples': 10000, 'score': 45851.356169462204, 'total_duration': 48278.21495509148, 'accumulated_submission_time': 45851.356169462204, 'accumulated_eval_time': 2420.05947804451, 'accumulated_logging_time': 4.100126266479492}
I0915 10:20:18.372277 140329751648000 logging_writer.py:48] [113853] accumulated_eval_time=2420.059478, accumulated_logging_time=4.100126, accumulated_submission_time=45851.356169, global_step=113853, preemption_count=0, score=45851.356169, test/accuracy=0.636100, test/loss=1.556069, test/num_examples=10000, total_duration=48278.214955, train/accuracy=0.855410, train/loss=0.542329, validation/accuracy=0.760600, validation/loss=0.948026, validation/num_examples=50000
I0915 10:21:17.833244 140329760040704 logging_writer.py:48] [114000] global_step=114000, grad_norm=2.563843011856079, loss=1.321471929550171
I0915 10:24:38.678850 140329751648000 logging_writer.py:48] [114500] global_step=114500, grad_norm=2.437089204788208, loss=1.3824068307876587
I0915 10:27:18.394351 140537819772736 spec.py:320] Evaluating on the training split.
I0915 10:27:28.509430 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 10:27:39.460179 140537819772736 spec.py:348] Evaluating on the test split.
I0915 10:27:41.096166 140537819772736 submission_runner.py:376] Time since start: 48720.97s, 	Step: 114899, 	{'train/accuracy': 0.86048823595047, 'train/loss': 0.518140971660614, 'validation/accuracy': 0.7630999684333801, 'validation/loss': 0.9346221685409546, 'validation/num_examples': 50000, 'test/accuracy': 0.636900007724762, 'test/loss': 1.5563948154449463, 'test/num_examples': 10000, 'score': 46271.33834147453, 'total_duration': 48720.967970371246, 'accumulated_submission_time': 46271.33834147453, 'accumulated_eval_time': 2442.7613065242767, 'accumulated_logging_time': 4.1434714794158936}
I0915 10:27:41.125824 140329760040704 logging_writer.py:48] [114899] accumulated_eval_time=2442.761307, accumulated_logging_time=4.143471, accumulated_submission_time=46271.338341, global_step=114899, preemption_count=0, score=46271.338341, test/accuracy=0.636900, test/loss=1.556395, test/num_examples=10000, total_duration=48720.967970, train/accuracy=0.860488, train/loss=0.518141, validation/accuracy=0.763100, validation/loss=0.934622, validation/num_examples=50000
I0915 10:28:22.120989 140329751648000 logging_writer.py:48] [115000] global_step=115000, grad_norm=2.4404211044311523, loss=1.5149682760238647
I0915 10:31:42.966366 140329760040704 logging_writer.py:48] [115500] global_step=115500, grad_norm=2.529125928878784, loss=1.2026891708374023
I0915 10:34:41.152523 140537819772736 spec.py:320] Evaluating on the training split.
I0915 10:34:51.207509 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 10:35:02.794662 140537819772736 spec.py:348] Evaluating on the test split.
I0915 10:35:04.430419 140537819772736 submission_runner.py:376] Time since start: 49164.30s, 	Step: 115945, 	{'train/accuracy': 0.8642578125, 'train/loss': 0.5147847533226013, 'validation/accuracy': 0.7607199549674988, 'validation/loss': 0.9394441843032837, 'validation/num_examples': 50000, 'test/accuracy': 0.6388000249862671, 'test/loss': 1.5594556331634521, 'test/num_examples': 10000, 'score': 46691.32644343376, 'total_duration': 49164.30221223831, 'accumulated_submission_time': 46691.32644343376, 'accumulated_eval_time': 2466.039196252823, 'accumulated_logging_time': 4.186267137527466}
I0915 10:35:04.459794 140329751648000 logging_writer.py:48] [115945] accumulated_eval_time=2466.039196, accumulated_logging_time=4.186267, accumulated_submission_time=46691.326443, global_step=115945, preemption_count=0, score=46691.326443, test/accuracy=0.638800, test/loss=1.559456, test/num_examples=10000, total_duration=49164.302212, train/accuracy=0.864258, train/loss=0.514785, validation/accuracy=0.760720, validation/loss=0.939444, validation/num_examples=50000
I0915 10:35:26.992246 140329760040704 logging_writer.py:48] [116000] global_step=116000, grad_norm=2.6876327991485596, loss=2.4479899406433105
I0915 10:38:48.126331 140329751648000 logging_writer.py:48] [116500] global_step=116500, grad_norm=3.1410958766937256, loss=3.550320863723755
I0915 10:42:04.536425 140537819772736 spec.py:320] Evaluating on the training split.
I0915 10:42:14.545447 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 10:42:25.432011 140537819772736 spec.py:348] Evaluating on the test split.
I0915 10:42:27.070780 140537819772736 submission_runner.py:376] Time since start: 49606.94s, 	Step: 116990, 	{'train/accuracy': 0.8674023151397705, 'train/loss': 0.49553409218788147, 'validation/accuracy': 0.7648599743843079, 'validation/loss': 0.9223268628120422, 'validation/num_examples': 50000, 'test/accuracy': 0.6458000540733337, 'test/loss': 1.5338842868804932, 'test/num_examples': 10000, 'score': 47111.366933107376, 'total_duration': 49606.9425778389, 'accumulated_submission_time': 47111.366933107376, 'accumulated_eval_time': 2488.573524236679, 'accumulated_logging_time': 4.226797580718994}
I0915 10:42:27.099866 140329760040704 logging_writer.py:48] [116990] accumulated_eval_time=2488.573524, accumulated_logging_time=4.226798, accumulated_submission_time=47111.366933, global_step=116990, preemption_count=0, score=47111.366933, test/accuracy=0.645800, test/loss=1.533884, test/num_examples=10000, total_duration=49606.942578, train/accuracy=0.867402, train/loss=0.495534, validation/accuracy=0.764860, validation/loss=0.922327, validation/num_examples=50000
I0915 10:42:31.525516 140329751648000 logging_writer.py:48] [117000] global_step=117000, grad_norm=2.621685028076172, loss=1.5223733186721802
I0915 10:45:52.357258 140329760040704 logging_writer.py:48] [117500] global_step=117500, grad_norm=2.656712293624878, loss=1.2903637886047363
I0915 10:49:13.324883 140329751648000 logging_writer.py:48] [118000] global_step=118000, grad_norm=2.550463914871216, loss=1.2730441093444824
I0915 10:49:27.087612 140537819772736 spec.py:320] Evaluating on the training split.
I0915 10:49:37.218562 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 10:49:48.333604 140537819772736 spec.py:348] Evaluating on the test split.
I0915 10:49:49.965109 140537819772736 submission_runner.py:376] Time since start: 50049.84s, 	Step: 118036, 	{'train/accuracy': 0.8635546565055847, 'train/loss': 0.5169057846069336, 'validation/accuracy': 0.7652999758720398, 'validation/loss': 0.9303491711616516, 'validation/num_examples': 50000, 'test/accuracy': 0.6498000025749207, 'test/loss': 1.5330860614776611, 'test/num_examples': 10000, 'score': 47531.31885385513, 'total_duration': 50049.83691740036, 'accumulated_submission_time': 47531.31885385513, 'accumulated_eval_time': 2511.451023578644, 'accumulated_logging_time': 4.266953945159912}
I0915 10:49:49.994971 140329760040704 logging_writer.py:48] [118036] accumulated_eval_time=2511.451024, accumulated_logging_time=4.266954, accumulated_submission_time=47531.318854, global_step=118036, preemption_count=0, score=47531.318854, test/accuracy=0.649800, test/loss=1.533086, test/num_examples=10000, total_duration=50049.836917, train/accuracy=0.863555, train/loss=0.516906, validation/accuracy=0.765300, validation/loss=0.930349, validation/num_examples=50000
I0915 10:52:56.809422 140329751648000 logging_writer.py:48] [118500] global_step=118500, grad_norm=2.8264882564544678, loss=1.3300961256027222
I0915 10:56:17.707822 140329760040704 logging_writer.py:48] [119000] global_step=119000, grad_norm=2.6307590007781982, loss=2.6642379760742188
I0915 10:56:50.331951 140537819772736 spec.py:320] Evaluating on the training split.
I0915 10:57:00.324513 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 10:57:12.161333 140537819772736 spec.py:348] Evaluating on the test split.
I0915 10:57:13.792474 140537819772736 submission_runner.py:376] Time since start: 50493.66s, 	Step: 119083, 	{'train/accuracy': 0.8630468845367432, 'train/loss': 0.5217750668525696, 'validation/accuracy': 0.7639200091362, 'validation/loss': 0.9328798055648804, 'validation/num_examples': 50000, 'test/accuracy': 0.647100031375885, 'test/loss': 1.5337120294570923, 'test/num_examples': 10000, 'score': 47951.62020754814, 'total_duration': 50493.6642639637, 'accumulated_submission_time': 47951.62020754814, 'accumulated_eval_time': 2534.9115228652954, 'accumulated_logging_time': 4.306902647018433}
I0915 10:57:13.820169 140329751648000 logging_writer.py:48] [119083] accumulated_eval_time=2534.911523, accumulated_logging_time=4.306903, accumulated_submission_time=47951.620208, global_step=119083, preemption_count=0, score=47951.620208, test/accuracy=0.647100, test/loss=1.533712, test/num_examples=10000, total_duration=50493.664264, train/accuracy=0.863047, train/loss=0.521775, validation/accuracy=0.763920, validation/loss=0.932880, validation/num_examples=50000
I0915 11:00:01.797015 140329760040704 logging_writer.py:48] [119500] global_step=119500, grad_norm=2.96677827835083, loss=2.3636295795440674
I0915 11:03:22.678306 140329751648000 logging_writer.py:48] [120000] global_step=120000, grad_norm=2.834188461303711, loss=1.2219746112823486
I0915 11:04:13.918497 140537819772736 spec.py:320] Evaluating on the training split.
I0915 11:04:23.857025 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 11:04:35.227250 140537819772736 spec.py:348] Evaluating on the test split.
I0915 11:04:36.861326 140537819772736 submission_runner.py:376] Time since start: 50936.73s, 	Step: 120129, 	{'train/accuracy': 0.8668944835662842, 'train/loss': 0.5051093697547913, 'validation/accuracy': 0.7659399509429932, 'validation/loss': 0.9179466962814331, 'validation/num_examples': 50000, 'test/accuracy': 0.6451000571250916, 'test/loss': 1.5264827013015747, 'test/num_examples': 10000, 'score': 48371.683430194855, 'total_duration': 50936.7331302166, 'accumulated_submission_time': 48371.683430194855, 'accumulated_eval_time': 2557.854325532913, 'accumulated_logging_time': 4.344862461090088}
I0915 11:04:36.889995 140329760040704 logging_writer.py:48] [120129] accumulated_eval_time=2557.854326, accumulated_logging_time=4.344862, accumulated_submission_time=48371.683430, global_step=120129, preemption_count=0, score=48371.683430, test/accuracy=0.645100, test/loss=1.526483, test/num_examples=10000, total_duration=50936.733130, train/accuracy=0.866894, train/loss=0.505109, validation/accuracy=0.765940, validation/loss=0.917947, validation/num_examples=50000
I0915 11:07:06.344743 140329751648000 logging_writer.py:48] [120500] global_step=120500, grad_norm=2.7003185749053955, loss=1.8343061208724976
I0915 11:10:27.185445 140329760040704 logging_writer.py:48] [121000] global_step=121000, grad_norm=2.702545642852783, loss=1.8425025939941406
I0915 11:11:36.905784 140537819772736 spec.py:320] Evaluating on the training split.
I0915 11:11:47.110057 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 11:11:58.396335 140537819772736 spec.py:348] Evaluating on the test split.
I0915 11:12:00.028158 140537819772736 submission_runner.py:376] Time since start: 51379.90s, 	Step: 121175, 	{'train/accuracy': 0.8700780868530273, 'train/loss': 0.4844999313354492, 'validation/accuracy': 0.767300009727478, 'validation/loss': 0.916588306427002, 'validation/num_examples': 50000, 'test/accuracy': 0.6470000147819519, 'test/loss': 1.5228590965270996, 'test/num_examples': 10000, 'score': 48791.66497206688, 'total_duration': 51379.899960279465, 'accumulated_submission_time': 48791.66497206688, 'accumulated_eval_time': 2580.976679801941, 'accumulated_logging_time': 4.383501052856445}
I0915 11:12:00.063066 140329751648000 logging_writer.py:48] [121175] accumulated_eval_time=2580.976680, accumulated_logging_time=4.383501, accumulated_submission_time=48791.664972, global_step=121175, preemption_count=0, score=48791.664972, test/accuracy=0.647000, test/loss=1.522859, test/num_examples=10000, total_duration=51379.899960, train/accuracy=0.870078, train/loss=0.484500, validation/accuracy=0.767300, validation/loss=0.916588, validation/num_examples=50000
I0915 11:14:11.002844 140329760040704 logging_writer.py:48] [121500] global_step=121500, grad_norm=2.6016812324523926, loss=2.296703338623047
I0915 11:17:31.836722 140329751648000 logging_writer.py:48] [122000] global_step=122000, grad_norm=2.778796434402466, loss=1.6853018999099731
I0915 11:19:00.047791 140537819772736 spec.py:320] Evaluating on the training split.
I0915 11:19:10.150862 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 11:19:21.301997 140537819772736 spec.py:348] Evaluating on the test split.
I0915 11:19:22.927707 140537819772736 submission_runner.py:376] Time since start: 51822.80s, 	Step: 122221, 	{'train/accuracy': 0.8710546493530273, 'train/loss': 0.49914517998695374, 'validation/accuracy': 0.7683199644088745, 'validation/loss': 0.9202027320861816, 'validation/num_examples': 50000, 'test/accuracy': 0.6494000554084778, 'test/loss': 1.5301061868667603, 'test/num_examples': 10000, 'score': 49211.61485552788, 'total_duration': 51822.79950904846, 'accumulated_submission_time': 49211.61485552788, 'accumulated_eval_time': 2603.8565814495087, 'accumulated_logging_time': 4.427901983261108}
I0915 11:19:22.957721 140329760040704 logging_writer.py:48] [122221] accumulated_eval_time=2603.856581, accumulated_logging_time=4.427902, accumulated_submission_time=49211.614856, global_step=122221, preemption_count=0, score=49211.614856, test/accuracy=0.649400, test/loss=1.530106, test/num_examples=10000, total_duration=51822.799509, train/accuracy=0.871055, train/loss=0.499145, validation/accuracy=0.768320, validation/loss=0.920203, validation/num_examples=50000
I0915 11:21:15.453106 140329751648000 logging_writer.py:48] [122500] global_step=122500, grad_norm=3.1318604946136475, loss=3.04946231842041
I0915 11:24:36.235717 140329760040704 logging_writer.py:48] [123000] global_step=123000, grad_norm=2.8757147789001465, loss=1.406370759010315
I0915 11:26:23.156702 140537819772736 spec.py:320] Evaluating on the training split.
I0915 11:26:33.347899 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 11:26:44.470197 140537819772736 spec.py:348] Evaluating on the test split.
I0915 11:26:46.097491 140537819772736 submission_runner.py:376] Time since start: 52265.97s, 	Step: 123268, 	{'train/accuracy': 0.8720117211341858, 'train/loss': 0.478810578584671, 'validation/accuracy': 0.768559992313385, 'validation/loss': 0.9037069082260132, 'validation/num_examples': 50000, 'test/accuracy': 0.652400016784668, 'test/loss': 1.5106265544891357, 'test/num_examples': 10000, 'score': 49631.779134750366, 'total_duration': 52265.969289541245, 'accumulated_submission_time': 49631.779134750366, 'accumulated_eval_time': 2626.7973709106445, 'accumulated_logging_time': 4.468078136444092}
I0915 11:26:46.125419 140329751648000 logging_writer.py:48] [123268] accumulated_eval_time=2626.797371, accumulated_logging_time=4.468078, accumulated_submission_time=49631.779135, global_step=123268, preemption_count=0, score=49631.779135, test/accuracy=0.652400, test/loss=1.510627, test/num_examples=10000, total_duration=52265.969290, train/accuracy=0.872012, train/loss=0.478811, validation/accuracy=0.768560, validation/loss=0.903707, validation/num_examples=50000
I0915 11:28:19.909140 140329760040704 logging_writer.py:48] [123500] global_step=123500, grad_norm=3.061055898666382, loss=3.1026129722595215
I0915 11:31:40.774751 140329751648000 logging_writer.py:48] [124000] global_step=124000, grad_norm=2.6196696758270264, loss=1.6550743579864502
I0915 11:33:46.231123 140537819772736 spec.py:320] Evaluating on the training split.
I0915 11:33:56.231268 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 11:34:07.748090 140537819772736 spec.py:348] Evaluating on the test split.
I0915 11:34:09.391152 140537819772736 submission_runner.py:376] Time since start: 52709.26s, 	Step: 124314, 	{'train/accuracy': 0.8717382550239563, 'train/loss': 0.47148576378822327, 'validation/accuracy': 0.7697399854660034, 'validation/loss': 0.9006651043891907, 'validation/num_examples': 50000, 'test/accuracy': 0.6484000086784363, 'test/loss': 1.5056315660476685, 'test/num_examples': 10000, 'score': 50051.849461078644, 'total_duration': 52709.26294159889, 'accumulated_submission_time': 50051.849461078644, 'accumulated_eval_time': 2649.957382440567, 'accumulated_logging_time': 4.506983995437622}
I0915 11:34:09.420550 140329760040704 logging_writer.py:48] [124314] accumulated_eval_time=2649.957382, accumulated_logging_time=4.506984, accumulated_submission_time=50051.849461, global_step=124314, preemption_count=0, score=50051.849461, test/accuracy=0.648400, test/loss=1.505632, test/num_examples=10000, total_duration=52709.262942, train/accuracy=0.871738, train/loss=0.471486, validation/accuracy=0.769740, validation/loss=0.900665, validation/num_examples=50000
I0915 11:35:24.694200 140329751648000 logging_writer.py:48] [124500] global_step=124500, grad_norm=3.059715986251831, loss=1.1846553087234497
I0915 11:38:45.583959 140329760040704 logging_writer.py:48] [125000] global_step=125000, grad_norm=2.7096240520477295, loss=1.2201991081237793
I0915 11:41:09.480556 140537819772736 spec.py:320] Evaluating on the training split.
I0915 11:41:19.699472 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 11:41:31.060572 140537819772736 spec.py:348] Evaluating on the test split.
I0915 11:41:32.693927 140537819772736 submission_runner.py:376] Time since start: 53152.57s, 	Step: 125360, 	{'train/accuracy': 0.8754101395606995, 'train/loss': 0.47015872597694397, 'validation/accuracy': 0.7717199921607971, 'validation/loss': 0.9034016728401184, 'validation/num_examples': 50000, 'test/accuracy': 0.6516000032424927, 'test/loss': 1.510228157043457, 'test/num_examples': 10000, 'score': 50471.87348651886, 'total_duration': 53152.56572031975, 'accumulated_submission_time': 50471.87348651886, 'accumulated_eval_time': 2673.1708047389984, 'accumulated_logging_time': 4.547850131988525}
I0915 11:41:32.725368 140329751648000 logging_writer.py:48] [125360] accumulated_eval_time=2673.170805, accumulated_logging_time=4.547850, accumulated_submission_time=50471.873487, global_step=125360, preemption_count=0, score=50471.873487, test/accuracy=0.651600, test/loss=1.510228, test/num_examples=10000, total_duration=53152.565720, train/accuracy=0.875410, train/loss=0.470159, validation/accuracy=0.771720, validation/loss=0.903402, validation/num_examples=50000
I0915 11:42:29.528379 140329760040704 logging_writer.py:48] [125500] global_step=125500, grad_norm=2.8533310890197754, loss=1.3686574697494507
I0915 11:45:50.384140 140329751648000 logging_writer.py:48] [126000] global_step=126000, grad_norm=3.6651718616485596, loss=3.485704183578491
I0915 11:48:32.759997 140537819772736 spec.py:320] Evaluating on the training split.
I0915 11:48:42.887425 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 11:48:54.359221 140537819772736 spec.py:348] Evaluating on the test split.
I0915 11:48:55.988296 140537819772736 submission_runner.py:376] Time since start: 53595.86s, 	Step: 126406, 	{'train/accuracy': 0.8778710961341858, 'train/loss': 0.46044984459877014, 'validation/accuracy': 0.7697799801826477, 'validation/loss': 0.9043248295783997, 'validation/num_examples': 50000, 'test/accuracy': 0.6458000540733337, 'test/loss': 1.5100255012512207, 'test/num_examples': 10000, 'score': 50891.871772289276, 'total_duration': 53595.86010169983, 'accumulated_submission_time': 50891.871772289276, 'accumulated_eval_time': 2696.3991055488586, 'accumulated_logging_time': 4.590073823928833}
I0915 11:48:56.018600 140329760040704 logging_writer.py:48] [126406] accumulated_eval_time=2696.399106, accumulated_logging_time=4.590074, accumulated_submission_time=50891.871772, global_step=126406, preemption_count=0, score=50891.871772, test/accuracy=0.645800, test/loss=1.510026, test/num_examples=10000, total_duration=53595.860102, train/accuracy=0.877871, train/loss=0.460450, validation/accuracy=0.769780, validation/loss=0.904325, validation/num_examples=50000
I0915 11:49:34.242151 140329751648000 logging_writer.py:48] [126500] global_step=126500, grad_norm=3.2363810539245605, loss=3.337761163711548
I0915 11:52:55.224144 140329760040704 logging_writer.py:48] [127000] global_step=127000, grad_norm=2.941256523132324, loss=1.2875317335128784
I0915 11:55:56.078816 140537819772736 spec.py:320] Evaluating on the training split.
I0915 11:56:06.236762 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 11:56:17.508692 140537819772736 spec.py:348] Evaluating on the test split.
I0915 11:56:19.136832 140537819772736 submission_runner.py:376] Time since start: 54039.01s, 	Step: 127452, 	{'train/accuracy': 0.8773632645606995, 'train/loss': 0.4648609161376953, 'validation/accuracy': 0.7706999778747559, 'validation/loss': 0.902042806148529, 'validation/num_examples': 50000, 'test/accuracy': 0.650700032711029, 'test/loss': 1.5087542533874512, 'test/num_examples': 10000, 'score': 51311.89664435387, 'total_duration': 54039.00860953331, 'accumulated_submission_time': 51311.89664435387, 'accumulated_eval_time': 2719.4571118354797, 'accumulated_logging_time': 4.630898714065552}
I0915 11:56:19.190488 140329751648000 logging_writer.py:48] [127452] accumulated_eval_time=2719.457112, accumulated_logging_time=4.630899, accumulated_submission_time=51311.896644, global_step=127452, preemption_count=0, score=51311.896644, test/accuracy=0.650700, test/loss=1.508754, test/num_examples=10000, total_duration=54039.008610, train/accuracy=0.877363, train/loss=0.464861, validation/accuracy=0.770700, validation/loss=0.902043, validation/num_examples=50000
I0915 11:56:38.907156 140329760040704 logging_writer.py:48] [127500] global_step=127500, grad_norm=2.86072039604187, loss=1.6770985126495361
I0915 11:59:59.912917 140329751648000 logging_writer.py:48] [128000] global_step=128000, grad_norm=2.9118154048919678, loss=1.2449225187301636
I0915 12:03:19.198323 140537819772736 spec.py:320] Evaluating on the training split.
I0915 12:03:29.367293 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 12:03:40.134918 140537819772736 spec.py:348] Evaluating on the test split.
I0915 12:03:41.770119 140537819772736 submission_runner.py:376] Time since start: 54481.64s, 	Step: 128498, 	{'train/accuracy': 0.87806636095047, 'train/loss': 0.453902930021286, 'validation/accuracy': 0.7717799544334412, 'validation/loss': 0.8938944339752197, 'validation/num_examples': 50000, 'test/accuracy': 0.6511000394821167, 'test/loss': 1.5032665729522705, 'test/num_examples': 10000, 'score': 51731.86476254463, 'total_duration': 54481.64192318916, 'accumulated_submission_time': 51731.86476254463, 'accumulated_eval_time': 2742.028912305832, 'accumulated_logging_time': 4.699326515197754}
I0915 12:03:41.805383 140329760040704 logging_writer.py:48] [128498] accumulated_eval_time=2742.028912, accumulated_logging_time=4.699327, accumulated_submission_time=51731.864763, global_step=128498, preemption_count=0, score=51731.864763, test/accuracy=0.651100, test/loss=1.503267, test/num_examples=10000, total_duration=54481.641923, train/accuracy=0.878066, train/loss=0.453903, validation/accuracy=0.771780, validation/loss=0.893894, validation/num_examples=50000
I0915 12:03:43.015950 140329751648000 logging_writer.py:48] [128500] global_step=128500, grad_norm=2.7060546875, loss=1.5282883644104004
I0915 12:07:04.040802 140329760040704 logging_writer.py:48] [129000] global_step=129000, grad_norm=2.9849722385406494, loss=1.2304283380508423
I0915 12:10:24.915803 140329751648000 logging_writer.py:48] [129500] global_step=129500, grad_norm=2.981154680252075, loss=1.3179004192352295
I0915 12:10:41.876213 140537819772736 spec.py:320] Evaluating on the training split.
I0915 12:10:52.091227 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 12:11:03.725913 140537819772736 spec.py:348] Evaluating on the test split.
I0915 12:11:05.355449 140537819772736 submission_runner.py:376] Time since start: 54925.23s, 	Step: 129544, 	{'train/accuracy': 0.8783398270606995, 'train/loss': 0.45605409145355225, 'validation/accuracy': 0.7703799605369568, 'validation/loss': 0.8932573199272156, 'validation/num_examples': 50000, 'test/accuracy': 0.6485000252723694, 'test/loss': 1.503004789352417, 'test/num_examples': 10000, 'score': 52151.900840997696, 'total_duration': 54925.22724056244, 'accumulated_submission_time': 52151.900840997696, 'accumulated_eval_time': 2765.508107662201, 'accumulated_logging_time': 4.7451441287994385}
I0915 12:11:05.384639 140329760040704 logging_writer.py:48] [129544] accumulated_eval_time=2765.508108, accumulated_logging_time=4.745144, accumulated_submission_time=52151.900841, global_step=129544, preemption_count=0, score=52151.900841, test/accuracy=0.648500, test/loss=1.503005, test/num_examples=10000, total_duration=54925.227241, train/accuracy=0.878340, train/loss=0.456054, validation/accuracy=0.770380, validation/loss=0.893257, validation/num_examples=50000
I0915 12:14:09.114151 140329751648000 logging_writer.py:48] [130000] global_step=130000, grad_norm=2.9010491371154785, loss=1.0868048667907715
I0915 12:17:30.006299 140329760040704 logging_writer.py:48] [130500] global_step=130500, grad_norm=2.9173967838287354, loss=1.282782793045044
I0915 12:18:05.473115 140537819772736 spec.py:320] Evaluating on the training split.
I0915 12:18:15.681903 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 12:18:26.759645 140537819772736 spec.py:348] Evaluating on the test split.
I0915 12:18:28.394874 140537819772736 submission_runner.py:376] Time since start: 55368.27s, 	Step: 130590, 	{'train/accuracy': 0.8764843344688416, 'train/loss': 0.46228593587875366, 'validation/accuracy': 0.7726799845695496, 'validation/loss': 0.8918628096580505, 'validation/num_examples': 50000, 'test/accuracy': 0.6512000560760498, 'test/loss': 1.501344084739685, 'test/num_examples': 10000, 'score': 52571.95457935333, 'total_duration': 55368.266671180725, 'accumulated_submission_time': 52571.95457935333, 'accumulated_eval_time': 2788.4298362731934, 'accumulated_logging_time': 4.784155607223511}
I0915 12:18:28.423019 140329751648000 logging_writer.py:48] [130590] accumulated_eval_time=2788.429836, accumulated_logging_time=4.784156, accumulated_submission_time=52571.954579, global_step=130590, preemption_count=0, score=52571.954579, test/accuracy=0.651200, test/loss=1.501344, test/num_examples=10000, total_duration=55368.266671, train/accuracy=0.876484, train/loss=0.462286, validation/accuracy=0.772680, validation/loss=0.891863, validation/num_examples=50000
I0915 12:21:13.966995 140329760040704 logging_writer.py:48] [131000] global_step=131000, grad_norm=3.0270767211914062, loss=1.9314357042312622
I0915 12:24:35.263141 140329751648000 logging_writer.py:48] [131500] global_step=131500, grad_norm=2.8398497104644775, loss=1.3086891174316406
I0915 12:25:28.500751 140537819772736 spec.py:320] Evaluating on the training split.
I0915 12:25:38.808139 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 12:25:50.516710 140537819772736 spec.py:348] Evaluating on the test split.
I0915 12:25:52.149613 140537819772736 submission_runner.py:376] Time since start: 55812.02s, 	Step: 131634, 	{'train/accuracy': 0.8810546398162842, 'train/loss': 0.4481064975261688, 'validation/accuracy': 0.772819995880127, 'validation/loss': 0.8874424695968628, 'validation/num_examples': 50000, 'test/accuracy': 0.6551000475883484, 'test/loss': 1.499834418296814, 'test/num_examples': 10000, 'score': 52991.996413469315, 'total_duration': 55812.02141904831, 'accumulated_submission_time': 52991.996413469315, 'accumulated_eval_time': 2812.0786912441254, 'accumulated_logging_time': 4.823890209197998}
I0915 12:25:52.179956 140329760040704 logging_writer.py:48] [131634] accumulated_eval_time=2812.078691, accumulated_logging_time=4.823890, accumulated_submission_time=52991.996413, global_step=131634, preemption_count=0, score=52991.996413, test/accuracy=0.655100, test/loss=1.499834, test/num_examples=10000, total_duration=55812.021419, train/accuracy=0.881055, train/loss=0.448106, validation/accuracy=0.772820, validation/loss=0.887442, validation/num_examples=50000
I0915 12:28:19.729964 140329751648000 logging_writer.py:48] [132000] global_step=132000, grad_norm=3.166135549545288, loss=3.0834572315216064
I0915 12:31:40.553952 140329760040704 logging_writer.py:48] [132500] global_step=132500, grad_norm=3.1754448413848877, loss=3.0844483375549316
I0915 12:32:52.537102 140537819772736 spec.py:320] Evaluating on the training split.
I0915 12:33:02.813943 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 12:33:14.265330 140537819772736 spec.py:348] Evaluating on the test split.
I0915 12:33:15.899073 140537819772736 submission_runner.py:376] Time since start: 56255.77s, 	Step: 132681, 	{'train/accuracy': 0.8777539134025574, 'train/loss': 0.4599067270755768, 'validation/accuracy': 0.7736799716949463, 'validation/loss': 0.8873386383056641, 'validation/num_examples': 50000, 'test/accuracy': 0.6551000475883484, 'test/loss': 1.4969558715820312, 'test/num_examples': 10000, 'score': 53412.317210674286, 'total_duration': 56255.77086687088, 'accumulated_submission_time': 53412.317210674286, 'accumulated_eval_time': 2835.440642595291, 'accumulated_logging_time': 4.86470103263855}
I0915 12:33:15.930109 140329751648000 logging_writer.py:48] [132681] accumulated_eval_time=2835.440643, accumulated_logging_time=4.864701, accumulated_submission_time=53412.317211, global_step=132681, preemption_count=0, score=53412.317211, test/accuracy=0.655100, test/loss=1.496956, test/num_examples=10000, total_duration=56255.770867, train/accuracy=0.877754, train/loss=0.459907, validation/accuracy=0.773680, validation/loss=0.887339, validation/num_examples=50000
I0915 12:35:24.451599 140329760040704 logging_writer.py:48] [133000] global_step=133000, grad_norm=2.8837242126464844, loss=1.266739845275879
I0915 12:38:45.391591 140329751648000 logging_writer.py:48] [133500] global_step=133500, grad_norm=3.1965296268463135, loss=1.2936512231826782
I0915 12:40:16.244473 140537819772736 spec.py:320] Evaluating on the training split.
I0915 12:40:26.266890 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 12:40:37.581296 140537819772736 spec.py:348] Evaluating on the test split.
I0915 12:40:39.215093 140537819772736 submission_runner.py:376] Time since start: 56699.09s, 	Step: 133728, 	{'train/accuracy': 0.8803515434265137, 'train/loss': 0.4515140950679779, 'validation/accuracy': 0.7734999656677246, 'validation/loss': 0.88714200258255, 'validation/num_examples': 50000, 'test/accuracy': 0.6547000408172607, 'test/loss': 1.4963185787200928, 'test/num_examples': 10000, 'score': 53832.59554314613, 'total_duration': 56699.08690428734, 'accumulated_submission_time': 53832.59554314613, 'accumulated_eval_time': 2858.4112660884857, 'accumulated_logging_time': 4.9065163135528564}
I0915 12:40:39.244314 140329760040704 logging_writer.py:48] [133728] accumulated_eval_time=2858.411266, accumulated_logging_time=4.906516, accumulated_submission_time=53832.595543, global_step=133728, preemption_count=0, score=53832.595543, test/accuracy=0.654700, test/loss=1.496319, test/num_examples=10000, total_duration=56699.086904, train/accuracy=0.880352, train/loss=0.451514, validation/accuracy=0.773500, validation/loss=0.887142, validation/num_examples=50000
I0915 12:42:29.081388 140329751648000 logging_writer.py:48] [134000] global_step=134000, grad_norm=3.0121524333953857, loss=1.1233952045440674
I0915 12:45:50.419520 140329760040704 logging_writer.py:48] [134500] global_step=134500, grad_norm=2.9004547595977783, loss=1.8098334074020386
I0915 12:47:39.534527 140537819772736 spec.py:320] Evaluating on the training split.
I0915 12:47:49.696119 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 12:48:00.769418 140537819772736 spec.py:348] Evaluating on the test split.
I0915 12:48:02.397275 140537819772736 submission_runner.py:376] Time since start: 57142.27s, 	Step: 134773, 	{'train/accuracy': 0.8775976300239563, 'train/loss': 0.45085039734840393, 'validation/accuracy': 0.7738800048828125, 'validation/loss': 0.8861609101295471, 'validation/num_examples': 50000, 'test/accuracy': 0.65420001745224, 'test/loss': 1.4922659397125244, 'test/num_examples': 10000, 'score': 54252.85058236122, 'total_duration': 57142.26908612251, 'accumulated_submission_time': 54252.85058236122, 'accumulated_eval_time': 2881.274034023285, 'accumulated_logging_time': 4.946626663208008}
I0915 12:48:02.428231 140329751648000 logging_writer.py:48] [134773] accumulated_eval_time=2881.274034, accumulated_logging_time=4.946627, accumulated_submission_time=54252.850582, global_step=134773, preemption_count=0, score=54252.850582, test/accuracy=0.654200, test/loss=1.492266, test/num_examples=10000, total_duration=57142.269086, train/accuracy=0.877598, train/loss=0.450850, validation/accuracy=0.773880, validation/loss=0.886161, validation/num_examples=50000
I0915 12:49:34.183135 140329760040704 logging_writer.py:48] [135000] global_step=135000, grad_norm=2.98461651802063, loss=1.4198147058486938
I0915 12:52:55.544077 140329751648000 logging_writer.py:48] [135500] global_step=135500, grad_norm=3.107142925262451, loss=1.244013786315918
I0915 12:55:02.410100 140537819772736 spec.py:320] Evaluating on the training split.
I0915 12:55:12.561190 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 12:55:23.948789 140537819772736 spec.py:348] Evaluating on the test split.
I0915 12:55:25.573003 140537819772736 submission_runner.py:376] Time since start: 57585.44s, 	Step: 135817, 	{'train/accuracy': 0.8817577958106995, 'train/loss': 0.4485340118408203, 'validation/accuracy': 0.7741599678993225, 'validation/loss': 0.8862265348434448, 'validation/num_examples': 50000, 'test/accuracy': 0.6541000604629517, 'test/loss': 1.4930837154388428, 'test/num_examples': 10000, 'score': 54672.79440379143, 'total_duration': 57585.444811820984, 'accumulated_submission_time': 54672.79440379143, 'accumulated_eval_time': 2904.436939716339, 'accumulated_logging_time': 4.991543531417847}
I0915 12:55:25.604465 140329760040704 logging_writer.py:48] [135817] accumulated_eval_time=2904.436940, accumulated_logging_time=4.991544, accumulated_submission_time=54672.794404, global_step=135817, preemption_count=0, score=54672.794404, test/accuracy=0.654100, test/loss=1.493084, test/num_examples=10000, total_duration=57585.444812, train/accuracy=0.881758, train/loss=0.448534, validation/accuracy=0.774160, validation/loss=0.886227, validation/num_examples=50000
I0915 12:56:39.538401 140329751648000 logging_writer.py:48] [136000] global_step=136000, grad_norm=3.0940005779266357, loss=2.919088125228882
I0915 13:00:00.412959 140329760040704 logging_writer.py:48] [136500] global_step=136500, grad_norm=3.219163656234741, loss=1.4355388879776
I0915 13:02:25.889165 140537819772736 spec.py:320] Evaluating on the training split.
I0915 13:02:36.075962 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 13:02:47.733256 140537819772736 spec.py:348] Evaluating on the test split.
I0915 13:02:49.368902 140537819772736 submission_runner.py:376] Time since start: 58029.24s, 	Step: 136864, 	{'train/accuracy': 0.8799218535423279, 'train/loss': 0.44930076599121094, 'validation/accuracy': 0.7742999792098999, 'validation/loss': 0.8853731155395508, 'validation/num_examples': 50000, 'test/accuracy': 0.6544000506401062, 'test/loss': 1.4933710098266602, 'test/num_examples': 10000, 'score': 55093.04386639595, 'total_duration': 58029.240710020065, 'accumulated_submission_time': 55093.04386639595, 'accumulated_eval_time': 2927.9166820049286, 'accumulated_logging_time': 5.033738851547241}
I0915 13:02:49.403114 140329751648000 logging_writer.py:48] [136864] accumulated_eval_time=2927.916682, accumulated_logging_time=5.033739, accumulated_submission_time=55093.043866, global_step=136864, preemption_count=0, score=55093.043866, test/accuracy=0.654400, test/loss=1.493371, test/num_examples=10000, total_duration=58029.240710, train/accuracy=0.879922, train/loss=0.449301, validation/accuracy=0.774300, validation/loss=0.885373, validation/num_examples=50000
I0915 13:03:44.422178 140329760040704 logging_writer.py:48] [137000] global_step=137000, grad_norm=3.0080742835998535, loss=1.7363852262496948
I0915 13:07:05.393919 140329751648000 logging_writer.py:48] [137500] global_step=137500, grad_norm=3.059514045715332, loss=1.4035587310791016
I0915 13:09:49.754822 140537819772736 spec.py:320] Evaluating on the training split.
I0915 13:10:00.069005 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 13:10:11.730963 140537819772736 spec.py:348] Evaluating on the test split.
I0915 13:10:13.359431 140537819772736 submission_runner.py:376] Time since start: 58473.23s, 	Step: 137911, 	{'train/accuracy': 0.8807616829872131, 'train/loss': 0.4524763822555542, 'validation/accuracy': 0.7742999792098999, 'validation/loss': 0.8846887350082397, 'validation/num_examples': 50000, 'test/accuracy': 0.6538000106811523, 'test/loss': 1.4922215938568115, 'test/num_examples': 10000, 'score': 55513.35981178284, 'total_duration': 58473.231236219406, 'accumulated_submission_time': 55513.35981178284, 'accumulated_eval_time': 2951.521292448044, 'accumulated_logging_time': 5.07880425453186}
I0915 13:10:13.393614 140329760040704 logging_writer.py:48] [137911] accumulated_eval_time=2951.521292, accumulated_logging_time=5.078804, accumulated_submission_time=55513.359812, global_step=137911, preemption_count=0, score=55513.359812, test/accuracy=0.653800, test/loss=1.492222, test/num_examples=10000, total_duration=58473.231236, train/accuracy=0.880762, train/loss=0.452476, validation/accuracy=0.774300, validation/loss=0.884689, validation/num_examples=50000
I0915 13:10:49.526430 140329751648000 logging_writer.py:48] [138000] global_step=138000, grad_norm=2.9622066020965576, loss=1.4223828315734863
I0915 13:14:10.562061 140329760040704 logging_writer.py:48] [138500] global_step=138500, grad_norm=3.2266547679901123, loss=1.899462342262268
I0915 13:17:13.402859 140537819772736 spec.py:320] Evaluating on the training split.
I0915 13:17:23.451334 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 13:17:35.155383 140537819772736 spec.py:348] Evaluating on the test split.
I0915 13:17:36.785590 140537819772736 submission_runner.py:376] Time since start: 58916.66s, 	Step: 138957, 	{'train/accuracy': 0.8803125023841858, 'train/loss': 0.4506169557571411, 'validation/accuracy': 0.7745800018310547, 'validation/loss': 0.8848632574081421, 'validation/num_examples': 50000, 'test/accuracy': 0.6551000475883484, 'test/loss': 1.4922782182693481, 'test/num_examples': 10000, 'score': 55933.33145284653, 'total_duration': 58916.6573946476, 'accumulated_submission_time': 55933.33145284653, 'accumulated_eval_time': 2974.9040195941925, 'accumulated_logging_time': 5.125922203063965}
I0915 13:17:36.818648 140329751648000 logging_writer.py:48] [138957] accumulated_eval_time=2974.904020, accumulated_logging_time=5.125922, accumulated_submission_time=55933.331453, global_step=138957, preemption_count=0, score=55933.331453, test/accuracy=0.655100, test/loss=1.492278, test/num_examples=10000, total_duration=58916.657395, train/accuracy=0.880313, train/loss=0.450617, validation/accuracy=0.774580, validation/loss=0.884863, validation/num_examples=50000
I0915 13:17:54.513838 140329760040704 logging_writer.py:48] [139000] global_step=139000, grad_norm=3.1856532096862793, loss=1.82692551612854
I0915 13:21:15.351130 140329751648000 logging_writer.py:48] [139500] global_step=139500, grad_norm=3.105417013168335, loss=1.158381700515747
I0915 13:24:35.598095 140537819772736 spec.py:320] Evaluating on the training split.
I0915 13:24:45.795940 140537819772736 spec.py:332] Evaluating on the validation split.
I0915 13:24:56.945926 140537819772736 spec.py:348] Evaluating on the test split.
I0915 13:24:58.573831 140537819772736 submission_runner.py:376] Time since start: 59358.45s, 	Step: 140000, 	{'train/accuracy': 0.8816796541213989, 'train/loss': 0.45050865411758423, 'validation/accuracy': 0.7745599746704102, 'validation/loss': 0.8846639394760132, 'validation/num_examples': 50000, 'test/accuracy': 0.6549000144004822, 'test/loss': 1.4921404123306274, 'test/num_examples': 10000, 'score': 56352.07413482666, 'total_duration': 59358.44564127922, 'accumulated_submission_time': 56352.07413482666, 'accumulated_eval_time': 2997.8797721862793, 'accumulated_logging_time': 5.170516014099121}
I0915 13:24:58.603983 140329760040704 logging_writer.py:48] [140000] accumulated_eval_time=2997.879772, accumulated_logging_time=5.170516, accumulated_submission_time=56352.074135, global_step=140000, preemption_count=0, score=56352.074135, test/accuracy=0.654900, test/loss=1.492140, test/num_examples=10000, total_duration=59358.445641, train/accuracy=0.881680, train/loss=0.450509, validation/accuracy=0.774560, validation/loss=0.884664, validation/num_examples=50000
I0915 13:24:58.629655 140329751648000 logging_writer.py:48] [140000] global_step=140000, preemption_count=0, score=56352.074135
I0915 13:24:58.917203 140537819772736 checkpoints.py:490] Saving checkpoint at step: 140000
I0915 13:24:59.971957 140537819772736 checkpoints.py:422] Saved checkpoint at /experiment_runs/targets_check_jax/nadamw_run_0/imagenet_vit_jax/trial_1/checkpoint_140000
I0915 13:24:59.998513 140537819772736 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/targets_check_jax/nadamw_run_0/imagenet_vit_jax/trial_1/checkpoint_140000.
I0915 13:25:00.594181 140537819772736 submission_runner.py:540] Tuning trial 1/1
I0915 13:25:00.594419 140537819772736 submission_runner.py:541] Hyperparameters: Hyperparameters(learning_rate=0.0008445074561975979, beta1=0.8895758153482813, beta2=0.9978504782314613, warmup_steps=6999, weight_decay=0.08135402759553023)
I0915 13:25:00.597338 140537819772736 submission_runner.py:542] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0008398437057621777, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 57.37175631523132, 'total_duration': 101.56672477722168, 'accumulated_submission_time': 57.37175631523132, 'accumulated_eval_time': 44.19487500190735, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (989, {'train/accuracy': 0.020390624180436134, 'train/loss': 6.191964149475098, 'validation/accuracy': 0.019700000062584877, 'validation/loss': 6.207623481750488, 'validation/num_examples': 50000, 'test/accuracy': 0.015200000256299973, 'test/loss': 6.279244422912598, 'test/num_examples': 10000, 'score': 477.52748227119446, 'total_duration': 536.7845273017883, 'accumulated_submission_time': 477.52748227119446, 'accumulated_eval_time': 59.21056628227234, 'accumulated_logging_time': 0.02813720703125, 'global_step': 989, 'preemption_count': 0}), (2035, {'train/accuracy': 0.05357421934604645, 'train/loss': 5.526940822601318, 'validation/accuracy': 0.05407999828457832, 'validation/loss': 5.5634541511535645, 'validation/num_examples': 50000, 'test/accuracy': 0.04130000248551369, 'test/loss': 5.731590270996094, 'test/num_examples': 10000, 'score': 897.6663494110107, 'total_duration': 971.835786819458, 'accumulated_submission_time': 897.6663494110107, 'accumulated_eval_time': 74.07457041740417, 'accumulated_logging_time': 0.05707097053527832, 'global_step': 2035, 'preemption_count': 0}), (3081, {'train/accuracy': 0.09001953154802322, 'train/loss': 5.122523784637451, 'validation/accuracy': 0.08184000104665756, 'validation/loss': 5.178854942321777, 'validation/num_examples': 50000, 'test/accuracy': 0.06360000371932983, 'test/loss': 5.407402515411377, 'test/num_examples': 10000, 'score': 1317.906329870224, 'total_duration': 1407.0566093921661, 'accumulated_submission_time': 1317.906329870224, 'accumulated_eval_time': 89.00798153877258, 'accumulated_logging_time': 0.08513021469116211, 'global_step': 3081, 'preemption_count': 0}), (4126, {'train/accuracy': 0.14912109076976776, 'train/loss': 4.528235912322998, 'validation/accuracy': 0.13565999269485474, 'validation/loss': 4.610907554626465, 'validation/num_examples': 50000, 'test/accuracy': 0.0999000072479248, 'test/loss': 4.929778575897217, 'test/num_examples': 10000, 'score': 1737.9637939929962, 'total_duration': 1842.0556008815765, 'accumulated_submission_time': 1737.9637939929962, 'accumulated_eval_time': 103.9029438495636, 'accumulated_logging_time': 0.11247086524963379, 'global_step': 4126, 'preemption_count': 0}), (5171, {'train/accuracy': 0.20302733778953552, 'train/loss': 4.115457534790039, 'validation/accuracy': 0.18803998827934265, 'validation/loss': 4.203698635101318, 'validation/num_examples': 50000, 'test/accuracy': 0.14250001311302185, 'test/loss': 4.573462009429932, 'test/num_examples': 10000, 'score': 2158.109827518463, 'total_duration': 2277.2005586624146, 'accumulated_submission_time': 2158.109827518463, 'accumulated_eval_time': 118.85322332382202, 'accumulated_logging_time': 0.1416316032409668, 'global_step': 5171, 'preemption_count': 0}), (6215, {'train/accuracy': 0.25273436307907104, 'train/loss': 3.718691825866699, 'validation/accuracy': 0.23617999255657196, 'validation/loss': 3.8217458724975586, 'validation/num_examples': 50000, 'test/accuracy': 0.17830000817775726, 'test/loss': 4.274967193603516, 'test/num_examples': 10000, 'score': 2578.1059305667877, 'total_duration': 2712.0858256816864, 'accumulated_submission_time': 2578.1059305667877, 'accumulated_eval_time': 133.6941261291504, 'accumulated_logging_time': 0.17026925086975098, 'global_step': 6215, 'preemption_count': 0}), (7259, {'train/accuracy': 0.3032616972923279, 'train/loss': 3.364391803741455, 'validation/accuracy': 0.280460000038147, 'validation/loss': 3.4938876628875732, 'validation/num_examples': 50000, 'test/accuracy': 0.21380001306533813, 'test/loss': 3.9967336654663086, 'test/num_examples': 10000, 'score': 2998.0750863552094, 'total_duration': 3147.092746734619, 'accumulated_submission_time': 2998.0750863552094, 'accumulated_eval_time': 148.68233180046082, 'accumulated_logging_time': 0.19936871528625488, 'global_step': 7259, 'preemption_count': 0}), (8303, {'train/accuracy': 0.35283201932907104, 'train/loss': 3.0697734355926514, 'validation/accuracy': 0.32486000657081604, 'validation/loss': 3.2185685634613037, 'validation/num_examples': 50000, 'test/accuracy': 0.25210002064704895, 'test/loss': 3.7374329566955566, 'test/num_examples': 10000, 'score': 3418.2163786888123, 'total_duration': 3582.4247949123383, 'accumulated_submission_time': 3418.2163786888123, 'accumulated_eval_time': 163.8197102546692, 'accumulated_logging_time': 0.22786331176757812, 'global_step': 8303, 'preemption_count': 0}), (9347, {'train/accuracy': 0.4092187285423279, 'train/loss': 2.7512402534484863, 'validation/accuracy': 0.3658599853515625, 'validation/loss': 2.971527099609375, 'validation/num_examples': 50000, 'test/accuracy': 0.28290000557899475, 'test/loss': 3.519920587539673, 'test/num_examples': 10000, 'score': 3838.3837130069733, 'total_duration': 4017.8790225982666, 'accumulated_submission_time': 3838.3837130069733, 'accumulated_eval_time': 179.0423939228058, 'accumulated_logging_time': 0.26703858375549316, 'global_step': 9347, 'preemption_count': 0}), (10390, {'train/accuracy': 0.4185742139816284, 'train/loss': 2.68806791305542, 'validation/accuracy': 0.3880999982357025, 'validation/loss': 2.8474984169006348, 'validation/num_examples': 50000, 'test/accuracy': 0.3035000264644623, 'test/loss': 3.393613338470459, 'test/num_examples': 10000, 'score': 4258.402877569199, 'total_duration': 4454.003902435303, 'accumulated_submission_time': 4258.402877569199, 'accumulated_eval_time': 195.0732707977295, 'accumulated_logging_time': 0.31662440299987793, 'global_step': 10390, 'preemption_count': 0}), (11434, {'train/accuracy': 0.4561132788658142, 'train/loss': 2.4276394844055176, 'validation/accuracy': 0.4253999888896942, 'validation/loss': 2.592682123184204, 'validation/num_examples': 50000, 'test/accuracy': 0.3281000256538391, 'test/loss': 3.218247413635254, 'test/num_examples': 10000, 'score': 4678.625365257263, 'total_duration': 4890.124463558197, 'accumulated_submission_time': 4678.625365257263, 'accumulated_eval_time': 210.90204763412476, 'accumulated_logging_time': 0.3602902889251709, 'global_step': 11434, 'preemption_count': 0}), (12478, {'train/accuracy': 0.482421875, 'train/loss': 2.292179822921753, 'validation/accuracy': 0.44689998030662537, 'validation/loss': 2.4758152961730957, 'validation/num_examples': 50000, 'test/accuracy': 0.34450000524520874, 'test/loss': 3.0888631343841553, 'test/num_examples': 10000, 'score': 5098.642262935638, 'total_duration': 5327.375041007996, 'accumulated_submission_time': 5098.642262935638, 'accumulated_eval_time': 228.06313037872314, 'accumulated_logging_time': 0.40737128257751465, 'global_step': 12478, 'preemption_count': 0}), (13521, {'train/accuracy': 0.5117577910423279, 'train/loss': 2.186204671859741, 'validation/accuracy': 0.46511998772621155, 'validation/loss': 2.4085850715637207, 'validation/num_examples': 50000, 'test/accuracy': 0.3644000291824341, 'test/loss': 3.017554759979248, 'test/num_examples': 10000, 'score': 5518.719899892807, 'total_duration': 5764.819185256958, 'accumulated_submission_time': 5518.719899892807, 'accumulated_eval_time': 245.35401606559753, 'accumulated_logging_time': 0.4583580493927002, 'global_step': 13521, 'preemption_count': 0}), (14565, {'train/accuracy': 0.5471093654632568, 'train/loss': 2.0091662406921387, 'validation/accuracy': 0.48787999153137207, 'validation/loss': 2.2879867553710938, 'validation/num_examples': 50000, 'test/accuracy': 0.3759000301361084, 'test/loss': 2.91947865486145, 'test/num_examples': 10000, 'score': 5938.798867464066, 'total_duration': 6203.048347949982, 'accumulated_submission_time': 5938.798867464066, 'accumulated_eval_time': 263.4239389896393, 'accumulated_logging_time': 0.5130276679992676, 'global_step': 14565, 'preemption_count': 0}), (15609, {'train/accuracy': 0.5362109541893005, 'train/loss': 2.009122848510742, 'validation/accuracy': 0.5021600127220154, 'validation/loss': 2.1903953552246094, 'validation/num_examples': 50000, 'test/accuracy': 0.3911000192165375, 'test/loss': 2.830354928970337, 'test/num_examples': 10000, 'score': 6358.846475124359, 'total_duration': 6643.036203861237, 'accumulated_submission_time': 6358.846475124359, 'accumulated_eval_time': 283.2963147163391, 'accumulated_logging_time': 0.5552635192871094, 'global_step': 15609, 'preemption_count': 0}), (16653, {'train/accuracy': 0.5543359518051147, 'train/loss': 1.9230766296386719, 'validation/accuracy': 0.511139988899231, 'validation/loss': 2.13252329826355, 'validation/num_examples': 50000, 'test/accuracy': 0.4011000096797943, 'test/loss': 2.7779672145843506, 'test/num_examples': 10000, 'score': 6778.849031209946, 'total_duration': 7082.887460947037, 'accumulated_submission_time': 6778.849031209946, 'accumulated_eval_time': 303.0835556983948, 'accumulated_logging_time': 0.5919358730316162, 'global_step': 16653, 'preemption_count': 0}), (17699, {'train/accuracy': 0.5710155963897705, 'train/loss': 1.8501490354537964, 'validation/accuracy': 0.5288599729537964, 'validation/loss': 2.0592732429504395, 'validation/num_examples': 50000, 'test/accuracy': 0.4115000069141388, 'test/loss': 2.6851940155029297, 'test/num_examples': 10000, 'score': 7199.002073764801, 'total_duration': 7522.919504165649, 'accumulated_submission_time': 7199.002073764801, 'accumulated_eval_time': 322.9041965007782, 'accumulated_logging_time': 0.6252312660217285, 'global_step': 17699, 'preemption_count': 0}), (18745, {'train/accuracy': 0.5863866806030273, 'train/loss': 1.7722173929214478, 'validation/accuracy': 0.5331999659538269, 'validation/loss': 2.0186984539031982, 'validation/num_examples': 50000, 'test/accuracy': 0.41860002279281616, 'test/loss': 2.6791703701019287, 'test/num_examples': 10000, 'score': 7619.130410909653, 'total_duration': 7964.000683784485, 'accumulated_submission_time': 7619.130410909653, 'accumulated_eval_time': 343.78895258903503, 'accumulated_logging_time': 0.6679136753082275, 'global_step': 18745, 'preemption_count': 0}), (19789, {'train/accuracy': 0.6121289134025574, 'train/loss': 1.6709192991256714, 'validation/accuracy': 0.5416799783706665, 'validation/loss': 1.9976913928985596, 'validation/num_examples': 50000, 'test/accuracy': 0.42900002002716064, 'test/loss': 2.639723300933838, 'test/num_examples': 10000, 'score': 8039.176896095276, 'total_duration': 8405.279914617538, 'accumulated_submission_time': 8039.176896095276, 'accumulated_eval_time': 364.95295310020447, 'accumulated_logging_time': 0.7106950283050537, 'global_step': 19789, 'preemption_count': 0}), (20835, {'train/accuracy': 0.5972851514816284, 'train/loss': 1.719199776649475, 'validation/accuracy': 0.5541999936103821, 'validation/loss': 1.925168752670288, 'validation/num_examples': 50000, 'test/accuracy': 0.4399000108242035, 'test/loss': 2.597055673599243, 'test/num_examples': 10000, 'score': 8459.302201509476, 'total_duration': 8846.825850486755, 'accumulated_submission_time': 8459.302201509476, 'accumulated_eval_time': 386.31907200813293, 'accumulated_logging_time': 0.7411060333251953, 'global_step': 20835, 'preemption_count': 0}), (21881, {'train/accuracy': 0.6030859351158142, 'train/loss': 1.7660539150238037, 'validation/accuracy': 0.5580199956893921, 'validation/loss': 1.9785405397415161, 'validation/num_examples': 50000, 'test/accuracy': 0.4385000169277191, 'test/loss': 2.6225688457489014, 'test/num_examples': 10000, 'score': 8879.44092464447, 'total_duration': 9288.49713587761, 'accumulated_submission_time': 8879.44092464447, 'accumulated_eval_time': 407.79387283325195, 'accumulated_logging_time': 0.7744174003601074, 'global_step': 21881, 'preemption_count': 0}), (22927, {'train/accuracy': 0.6214648485183716, 'train/loss': 1.5782735347747803, 'validation/accuracy': 0.5740000009536743, 'validation/loss': 1.804372787475586, 'validation/num_examples': 50000, 'test/accuracy': 0.45750001072883606, 'test/loss': 2.460386276245117, 'test/num_examples': 10000, 'score': 9299.516573667526, 'total_duration': 9730.820071697235, 'accumulated_submission_time': 9299.516573667526, 'accumulated_eval_time': 429.9462044239044, 'accumulated_logging_time': 0.8441531658172607, 'global_step': 22927, 'preemption_count': 0}), (23973, {'train/accuracy': 0.6368554830551147, 'train/loss': 1.5251083374023438, 'validation/accuracy': 0.5801199674606323, 'validation/loss': 1.7930980920791626, 'validation/num_examples': 50000, 'test/accuracy': 0.4588000178337097, 'test/loss': 2.461763858795166, 'test/num_examples': 10000, 'score': 9719.760099887848, 'total_duration': 10173.146329402924, 'accumulated_submission_time': 9719.760099887848, 'accumulated_eval_time': 451.96873569488525, 'accumulated_logging_time': 0.8795382976531982, 'global_step': 23973, 'preemption_count': 0}), (25017, {'train/accuracy': 0.6592577695846558, 'train/loss': 1.3961186408996582, 'validation/accuracy': 0.5885999798774719, 'validation/loss': 1.7285858392715454, 'validation/num_examples': 50000, 'test/accuracy': 0.46640002727508545, 'test/loss': 2.384011745452881, 'test/num_examples': 10000, 'score': 10139.972554683685, 'total_duration': 10616.673831224442, 'accumulated_submission_time': 10139.972554683685, 'accumulated_eval_time': 475.22561597824097, 'accumulated_logging_time': 0.9130065441131592, 'global_step': 25017, 'preemption_count': 0}), (26063, {'train/accuracy': 0.6375390291213989, 'train/loss': 1.5332105159759521, 'validation/accuracy': 0.5902199745178223, 'validation/loss': 1.7502737045288086, 'validation/num_examples': 50000, 'test/accuracy': 0.47630003094673157, 'test/loss': 2.4023752212524414, 'test/num_examples': 10000, 'score': 10560.198621034622, 'total_duration': 11059.691764354706, 'accumulated_submission_time': 10560.198621034622, 'accumulated_eval_time': 497.9585199356079, 'accumulated_logging_time': 0.9470188617706299, 'global_step': 26063, 'preemption_count': 0}), (27107, {'train/accuracy': 0.643847644329071, 'train/loss': 1.5001826286315918, 'validation/accuracy': 0.5966599583625793, 'validation/loss': 1.7204481363296509, 'validation/num_examples': 50000, 'test/accuracy': 0.4792000353336334, 'test/loss': 2.3601419925689697, 'test/num_examples': 10000, 'score': 10980.212023735046, 'total_duration': 11502.427257061005, 'accumulated_submission_time': 10980.212023735046, 'accumulated_eval_time': 520.6245007514954, 'accumulated_logging_time': 0.9773416519165039, 'global_step': 27107, 'preemption_count': 0}), (28151, {'train/accuracy': 0.6546484231948853, 'train/loss': 1.4351681470870972, 'validation/accuracy': 0.6003999710083008, 'validation/loss': 1.6897153854370117, 'validation/num_examples': 50000, 'test/accuracy': 0.4782000184059143, 'test/loss': 2.35526967048645, 'test/num_examples': 10000, 'score': 11400.348501682281, 'total_duration': 11945.403007507324, 'accumulated_submission_time': 11400.348501682281, 'accumulated_eval_time': 543.4062235355377, 'accumulated_logging_time': 1.0097651481628418, 'global_step': 28151, 'preemption_count': 0}), (29197, {'train/accuracy': 0.6614453196525574, 'train/loss': 1.3889416456222534, 'validation/accuracy': 0.6024199724197388, 'validation/loss': 1.664762020111084, 'validation/num_examples': 50000, 'test/accuracy': 0.4807000160217285, 'test/loss': 2.3268373012542725, 'test/num_examples': 10000, 'score': 11820.617892742157, 'total_duration': 12388.505590677261, 'accumulated_submission_time': 11820.617892742157, 'accumulated_eval_time': 566.1770503520966, 'accumulated_logging_time': 1.0469262599945068, 'global_step': 29197, 'preemption_count': 0}), (30243, {'train/accuracy': 0.6720117330551147, 'train/loss': 1.3487412929534912, 'validation/accuracy': 0.611299991607666, 'validation/loss': 1.6260520219802856, 'validation/num_examples': 50000, 'test/accuracy': 0.49070003628730774, 'test/loss': 2.2795658111572266, 'test/num_examples': 10000, 'score': 12240.705527305603, 'total_duration': 12831.379264831543, 'accumulated_submission_time': 12240.705527305603, 'accumulated_eval_time': 588.9022762775421, 'accumulated_logging_time': 1.0831067562103271, 'global_step': 30243, 'preemption_count': 0}), (31289, {'train/accuracy': 0.6577734351158142, 'train/loss': 1.4198908805847168, 'validation/accuracy': 0.6134600043296814, 'validation/loss': 1.626623511314392, 'validation/num_examples': 50000, 'test/accuracy': 0.4912000298500061, 'test/loss': 2.278754472732544, 'test/num_examples': 10000, 'score': 12660.989580154419, 'total_duration': 13274.41572022438, 'accumulated_submission_time': 12660.989580154419, 'accumulated_eval_time': 611.5960354804993, 'accumulated_logging_time': 1.116150140762329, 'global_step': 31289, 'preemption_count': 0}), (32335, {'train/accuracy': 0.6639062166213989, 'train/loss': 1.4215452671051025, 'validation/accuracy': 0.6152799725532532, 'validation/loss': 1.6467561721801758, 'validation/num_examples': 50000, 'test/accuracy': 0.491100013256073, 'test/loss': 2.315661668777466, 'test/num_examples': 10000, 'score': 13081.082773685455, 'total_duration': 13717.51386976242, 'accumulated_submission_time': 13081.082773685455, 'accumulated_eval_time': 634.5419218540192, 'accumulated_logging_time': 1.1485681533813477, 'global_step': 32335, 'preemption_count': 0}), (33381, {'train/accuracy': 0.6811327934265137, 'train/loss': 1.285815954208374, 'validation/accuracy': 0.6279799938201904, 'validation/loss': 1.549944281578064, 'validation/num_examples': 50000, 'test/accuracy': 0.5012000203132629, 'test/loss': 2.211625576019287, 'test/num_examples': 10000, 'score': 13501.305272102356, 'total_duration': 14160.429625988007, 'accumulated_submission_time': 13501.305272102356, 'accumulated_eval_time': 657.1776139736176, 'accumulated_logging_time': 1.181342363357544, 'global_step': 33381, 'preemption_count': 0}), (34427, {'train/accuracy': 0.6910351514816284, 'train/loss': 1.2600655555725098, 'validation/accuracy': 0.6281599998474121, 'validation/loss': 1.5477452278137207, 'validation/num_examples': 50000, 'test/accuracy': 0.5024999976158142, 'test/loss': 2.2017645835876465, 'test/num_examples': 10000, 'score': 13921.438568115234, 'total_duration': 14603.358687639236, 'accumulated_submission_time': 13921.438568115234, 'accumulated_eval_time': 679.915052652359, 'accumulated_logging_time': 1.2143819332122803, 'global_step': 34427, 'preemption_count': 0}), (35473, {'train/accuracy': 0.6890820264816284, 'train/loss': 1.276892900466919, 'validation/accuracy': 0.6319199800491333, 'validation/loss': 1.5410116910934448, 'validation/num_examples': 50000, 'test/accuracy': 0.5051000118255615, 'test/loss': 2.20273756980896, 'test/num_examples': 10000, 'score': 14341.611431360245, 'total_duration': 15046.043815135956, 'accumulated_submission_time': 14341.611431360245, 'accumulated_eval_time': 702.3649613857269, 'accumulated_logging_time': 1.251323938369751, 'global_step': 35473, 'preemption_count': 0}), (36519, {'train/accuracy': 0.6860937476158142, 'train/loss': 1.305120825767517, 'validation/accuracy': 0.6332799792289734, 'validation/loss': 1.5361328125, 'validation/num_examples': 50000, 'test/accuracy': 0.5056000351905823, 'test/loss': 2.184114694595337, 'test/num_examples': 10000, 'score': 14761.879046678543, 'total_duration': 15488.98408961296, 'accumulated_submission_time': 14761.879046678543, 'accumulated_eval_time': 724.9778726100922, 'accumulated_logging_time': 1.286210298538208, 'global_step': 36519, 'preemption_count': 0}), (37565, {'train/accuracy': 0.689453125, 'train/loss': 1.2733736038208008, 'validation/accuracy': 0.6358999609947205, 'validation/loss': 1.5208661556243896, 'validation/num_examples': 50000, 'test/accuracy': 0.5063000321388245, 'test/loss': 2.192904472351074, 'test/num_examples': 10000, 'score': 15182.073817491531, 'total_duration': 15931.961839914322, 'accumulated_submission_time': 15182.073817491531, 'accumulated_eval_time': 747.703675031662, 'accumulated_logging_time': 1.318333387374878, 'global_step': 37565, 'preemption_count': 0}), (38611, {'train/accuracy': 0.6935351490974426, 'train/loss': 1.2645710706710815, 'validation/accuracy': 0.6327599883079529, 'validation/loss': 1.5413390398025513, 'validation/num_examples': 50000, 'test/accuracy': 0.5059000253677368, 'test/loss': 2.2100095748901367, 'test/num_examples': 10000, 'score': 15602.20612668991, 'total_duration': 16374.720448493958, 'accumulated_submission_time': 15602.20612668991, 'accumulated_eval_time': 770.2731642723083, 'accumulated_logging_time': 1.3501255512237549, 'global_step': 38611, 'preemption_count': 0}), (39655, {'train/accuracy': 0.7108203172683716, 'train/loss': 1.1674636602401733, 'validation/accuracy': 0.6406999826431274, 'validation/loss': 1.480789303779602, 'validation/num_examples': 50000, 'test/accuracy': 0.5179000496864319, 'test/loss': 2.135993480682373, 'test/num_examples': 10000, 'score': 16022.185425043106, 'total_duration': 16817.218598604202, 'accumulated_submission_time': 16022.185425043106, 'accumulated_eval_time': 792.724791765213, 'accumulated_logging_time': 1.392237663269043, 'global_step': 39655, 'preemption_count': 0}), (40699, {'train/accuracy': 0.7011523246765137, 'train/loss': 1.2126903533935547, 'validation/accuracy': 0.6464799642562866, 'validation/loss': 1.4579867124557495, 'validation/num_examples': 50000, 'test/accuracy': 0.51910001039505, 'test/loss': 2.1263158321380615, 'test/num_examples': 10000, 'score': 16442.324369430542, 'total_duration': 17260.120077371597, 'accumulated_submission_time': 16442.324369430542, 'accumulated_eval_time': 815.422857761383, 'accumulated_logging_time': 1.4317491054534912, 'global_step': 40699, 'preemption_count': 0}), (41743, {'train/accuracy': 0.7012890577316284, 'train/loss': 1.218484878540039, 'validation/accuracy': 0.6453399658203125, 'validation/loss': 1.464857816696167, 'validation/num_examples': 50000, 'test/accuracy': 0.5200999975204468, 'test/loss': 2.12833833694458, 'test/num_examples': 10000, 'score': 16862.31078505516, 'total_duration': 17703.048202753067, 'accumulated_submission_time': 16862.31078505516, 'accumulated_eval_time': 838.3035740852356, 'accumulated_logging_time': 1.4676263332366943, 'global_step': 41743, 'preemption_count': 0}), (42788, {'train/accuracy': 0.7054687142372131, 'train/loss': 1.1966816186904907, 'validation/accuracy': 0.6466599702835083, 'validation/loss': 1.4641271829605103, 'validation/num_examples': 50000, 'test/accuracy': 0.5159000158309937, 'test/loss': 2.121095895767212, 'test/num_examples': 10000, 'score': 17282.63029909134, 'total_duration': 18145.96408200264, 'accumulated_submission_time': 17282.63029909134, 'accumulated_eval_time': 860.8370833396912, 'accumulated_logging_time': 1.5054385662078857, 'global_step': 42788, 'preemption_count': 0}), (43832, {'train/accuracy': 0.7114452719688416, 'train/loss': 1.160823941230774, 'validation/accuracy': 0.6499199867248535, 'validation/loss': 1.450548768043518, 'validation/num_examples': 50000, 'test/accuracy': 0.5275000333786011, 'test/loss': 2.1045455932617188, 'test/num_examples': 10000, 'score': 17702.690732479095, 'total_duration': 18589.44991517067, 'accumulated_submission_time': 17702.690732479095, 'accumulated_eval_time': 884.2026906013489, 'accumulated_logging_time': 1.5405313968658447, 'global_step': 43832, 'preemption_count': 0}), (44876, {'train/accuracy': 0.7220116853713989, 'train/loss': 1.1269961595535278, 'validation/accuracy': 0.6525999903678894, 'validation/loss': 1.4376455545425415, 'validation/num_examples': 50000, 'test/accuracy': 0.5297999978065491, 'test/loss': 2.093810558319092, 'test/num_examples': 10000, 'score': 18122.802223920822, 'total_duration': 19032.159947633743, 'accumulated_submission_time': 18122.802223920822, 'accumulated_eval_time': 906.7422378063202, 'accumulated_logging_time': 1.5743987560272217, 'global_step': 44876, 'preemption_count': 0}), (45920, {'train/accuracy': 0.7103124856948853, 'train/loss': 1.1537997722625732, 'validation/accuracy': 0.6577399969100952, 'validation/loss': 1.4045950174331665, 'validation/num_examples': 50000, 'test/accuracy': 0.5293000340461731, 'test/loss': 2.0719993114471436, 'test/num_examples': 10000, 'score': 18542.8635802269, 'total_duration': 19474.990223884583, 'accumulated_submission_time': 18542.8635802269, 'accumulated_eval_time': 929.4447264671326, 'accumulated_logging_time': 1.6159274578094482, 'global_step': 45920, 'preemption_count': 0}), (46964, {'train/accuracy': 0.7176562547683716, 'train/loss': 1.133830189704895, 'validation/accuracy': 0.6595199704170227, 'validation/loss': 1.3924614191055298, 'validation/num_examples': 50000, 'test/accuracy': 0.5353000164031982, 'test/loss': 2.0363869667053223, 'test/num_examples': 10000, 'score': 18962.907776355743, 'total_duration': 19917.5456097126, 'accumulated_submission_time': 18962.907776355743, 'accumulated_eval_time': 951.8958923816681, 'accumulated_logging_time': 1.6506056785583496, 'global_step': 46964, 'preemption_count': 0}), (48008, {'train/accuracy': 0.7196484208106995, 'train/loss': 1.1400775909423828, 'validation/accuracy': 0.6626600027084351, 'validation/loss': 1.4136073589324951, 'validation/num_examples': 50000, 'test/accuracy': 0.5332000255584717, 'test/loss': 2.069791793823242, 'test/num_examples': 10000, 'score': 19383.105134487152, 'total_duration': 20360.499856710434, 'accumulated_submission_time': 19383.105134487152, 'accumulated_eval_time': 974.5923511981964, 'accumulated_logging_time': 1.6858062744140625, 'global_step': 48008, 'preemption_count': 0}), (49052, {'train/accuracy': 0.7293164134025574, 'train/loss': 1.0797922611236572, 'validation/accuracy': 0.6621999740600586, 'validation/loss': 1.3735467195510864, 'validation/num_examples': 50000, 'test/accuracy': 0.5355000495910645, 'test/loss': 2.025865316390991, 'test/num_examples': 10000, 'score': 19803.180468320847, 'total_duration': 20803.261009454727, 'accumulated_submission_time': 19803.180468320847, 'accumulated_eval_time': 997.218202829361, 'accumulated_logging_time': 1.7202959060668945, 'global_step': 49052, 'preemption_count': 0}), (50096, {'train/accuracy': 0.7425390481948853, 'train/loss': 1.0094596147537231, 'validation/accuracy': 0.6674599647521973, 'validation/loss': 1.3497782945632935, 'validation/num_examples': 50000, 'test/accuracy': 0.5407000184059143, 'test/loss': 1.9960657358169556, 'test/num_examples': 10000, 'score': 20223.178280830383, 'total_duration': 21245.771508216858, 'accumulated_submission_time': 20223.178280830383, 'accumulated_eval_time': 1019.6738429069519, 'accumulated_logging_time': 1.7522170543670654, 'global_step': 50096, 'preemption_count': 0}), (51140, {'train/accuracy': 0.720703125, 'train/loss': 1.1321210861206055, 'validation/accuracy': 0.6626999974250793, 'validation/loss': 1.3917807340621948, 'validation/num_examples': 50000, 'test/accuracy': 0.5369000434875488, 'test/loss': 2.03317928314209, 'test/num_examples': 10000, 'score': 20643.305906772614, 'total_duration': 21688.703287363052, 'accumulated_submission_time': 20643.305906772614, 'accumulated_eval_time': 1042.420334815979, 'accumulated_logging_time': 1.7851319313049316, 'global_step': 51140, 'preemption_count': 0}), (52186, {'train/accuracy': 0.7272655963897705, 'train/loss': 1.1053509712219238, 'validation/accuracy': 0.6661799550056458, 'validation/loss': 1.3796039819717407, 'validation/num_examples': 50000, 'test/accuracy': 0.5362000465393066, 'test/loss': 2.0262598991394043, 'test/num_examples': 10000, 'score': 21063.390714645386, 'total_duration': 22131.558401346207, 'accumulated_submission_time': 21063.390714645386, 'accumulated_eval_time': 1065.1331419944763, 'accumulated_logging_time': 1.8178050518035889, 'global_step': 52186, 'preemption_count': 0}), (53230, {'train/accuracy': 0.7325780987739563, 'train/loss': 1.0678765773773193, 'validation/accuracy': 0.6708599925041199, 'validation/loss': 1.350648283958435, 'validation/num_examples': 50000, 'test/accuracy': 0.5444000363349915, 'test/loss': 1.9937844276428223, 'test/num_examples': 10000, 'score': 21483.39878511429, 'total_duration': 22574.323326587677, 'accumulated_submission_time': 21483.39878511429, 'accumulated_eval_time': 1087.8309314250946, 'accumulated_logging_time': 1.8520488739013672, 'global_step': 53230, 'preemption_count': 0}), (54276, {'train/accuracy': 0.7409765720367432, 'train/loss': 1.0473791360855103, 'validation/accuracy': 0.6732800006866455, 'validation/loss': 1.3502118587493896, 'validation/num_examples': 50000, 'test/accuracy': 0.5498000383377075, 'test/loss': 2.0068845748901367, 'test/num_examples': 10000, 'score': 21903.58311343193, 'total_duration': 23017.34591269493, 'accumulated_submission_time': 21903.58311343193, 'accumulated_eval_time': 1110.606136083603, 'accumulated_logging_time': 1.8896701335906982, 'global_step': 54276, 'preemption_count': 0}), (55322, {'train/accuracy': 0.7492773532867432, 'train/loss': 1.0066852569580078, 'validation/accuracy': 0.6700800061225891, 'validation/loss': 1.3617175817489624, 'validation/num_examples': 50000, 'test/accuracy': 0.5423000454902649, 'test/loss': 1.99981689453125, 'test/num_examples': 10000, 'score': 22323.654709339142, 'total_duration': 23460.6223859787, 'accumulated_submission_time': 22323.654709339142, 'accumulated_eval_time': 1133.7482361793518, 'accumulated_logging_time': 1.9275503158569336, 'global_step': 55322, 'preemption_count': 0}), (56368, {'train/accuracy': 0.7328906059265137, 'train/loss': 1.0611153841018677, 'validation/accuracy': 0.6734399795532227, 'validation/loss': 1.3300741910934448, 'validation/num_examples': 50000, 'test/accuracy': 0.5484000444412231, 'test/loss': 1.9824556112289429, 'test/num_examples': 10000, 'score': 22743.70618391037, 'total_duration': 23903.80253624916, 'accumulated_submission_time': 22743.70618391037, 'accumulated_eval_time': 1156.8121283054352, 'accumulated_logging_time': 1.9672307968139648, 'global_step': 56368, 'preemption_count': 0}), (57414, {'train/accuracy': 0.7380077838897705, 'train/loss': 1.0471419095993042, 'validation/accuracy': 0.6793799996376038, 'validation/loss': 1.314753770828247, 'validation/num_examples': 50000, 'test/accuracy': 0.5451000332832336, 'test/loss': 1.9855661392211914, 'test/num_examples': 10000, 'score': 23163.78472018242, 'total_duration': 24346.863499403, 'accumulated_submission_time': 23163.78472018242, 'accumulated_eval_time': 1179.7329053878784, 'accumulated_logging_time': 2.0039446353912354, 'global_step': 57414, 'preemption_count': 0}), (58460, {'train/accuracy': 0.7422851324081421, 'train/loss': 1.0314253568649292, 'validation/accuracy': 0.6783199906349182, 'validation/loss': 1.32110595703125, 'validation/num_examples': 50000, 'test/accuracy': 0.5463000535964966, 'test/loss': 1.967360019683838, 'test/num_examples': 10000, 'score': 23583.87860584259, 'total_duration': 24789.953688383102, 'accumulated_submission_time': 23583.87860584259, 'accumulated_eval_time': 1202.667839050293, 'accumulated_logging_time': 2.040526866912842, 'global_step': 58460, 'preemption_count': 0}), (59504, {'train/accuracy': 0.7533398270606995, 'train/loss': 0.9692489504814148, 'validation/accuracy': 0.681939959526062, 'validation/loss': 1.2824792861938477, 'validation/num_examples': 50000, 'test/accuracy': 0.5559000372886658, 'test/loss': 1.928375482559204, 'test/num_examples': 10000, 'score': 24003.852406978607, 'total_duration': 25232.598729610443, 'accumulated_submission_time': 24003.852406978607, 'accumulated_eval_time': 1225.2775814533234, 'accumulated_logging_time': 2.0775232315063477, 'global_step': 59504, 'preemption_count': 0}), (60550, {'train/accuracy': 0.7688086032867432, 'train/loss': 0.9273077249526978, 'validation/accuracy': 0.6828399896621704, 'validation/loss': 1.2966340780258179, 'validation/num_examples': 50000, 'test/accuracy': 0.5631999969482422, 'test/loss': 1.9362828731536865, 'test/num_examples': 10000, 'score': 24423.80990076065, 'total_duration': 25675.253208637238, 'accumulated_submission_time': 24423.80990076065, 'accumulated_eval_time': 1247.91592669487, 'accumulated_logging_time': 2.1107754707336426, 'global_step': 60550, 'preemption_count': 0}), (61594, {'train/accuracy': 0.7467968463897705, 'train/loss': 1.004888892173767, 'validation/accuracy': 0.6855599880218506, 'validation/loss': 1.2787421941757202, 'validation/num_examples': 50000, 'test/accuracy': 0.560200035572052, 'test/loss': 1.9303631782531738, 'test/num_examples': 10000, 'score': 24843.858068466187, 'total_duration': 26117.998169898987, 'accumulated_submission_time': 24843.858068466187, 'accumulated_eval_time': 1270.5553405284882, 'accumulated_logging_time': 2.143885850906372, 'global_step': 61594, 'preemption_count': 0}), (62638, {'train/accuracy': 0.7509179711341858, 'train/loss': 0.9868904948234558, 'validation/accuracy': 0.6870200037956238, 'validation/loss': 1.2723162174224854, 'validation/num_examples': 50000, 'test/accuracy': 0.5582000017166138, 'test/loss': 1.926504135131836, 'test/num_examples': 10000, 'score': 25263.891897439957, 'total_duration': 26561.49391412735, 'accumulated_submission_time': 25263.891897439957, 'accumulated_eval_time': 1293.9500708580017, 'accumulated_logging_time': 2.185905933380127, 'global_step': 62638, 'preemption_count': 0}), (63682, {'train/accuracy': 0.7610546946525574, 'train/loss': 0.9363180994987488, 'validation/accuracy': 0.6891199946403503, 'validation/loss': 1.2463955879211426, 'validation/num_examples': 50000, 'test/accuracy': 0.5659000277519226, 'test/loss': 1.8968350887298584, 'test/num_examples': 10000, 'score': 25683.95687198639, 'total_duration': 27004.531557559967, 'accumulated_submission_time': 25683.95687198639, 'accumulated_eval_time': 1316.8640320301056, 'accumulated_logging_time': 2.2196781635284424, 'global_step': 63682, 'preemption_count': 0}), (64726, {'train/accuracy': 0.7672460675239563, 'train/loss': 0.9208914637565613, 'validation/accuracy': 0.6926599740982056, 'validation/loss': 1.2476205825805664, 'validation/num_examples': 50000, 'test/accuracy': 0.5690000057220459, 'test/loss': 1.8818143606185913, 'test/num_examples': 10000, 'score': 26104.077221870422, 'total_duration': 27447.437873125076, 'accumulated_submission_time': 26104.077221870422, 'accumulated_eval_time': 1339.5878205299377, 'accumulated_logging_time': 2.256545305252075, 'global_step': 64726, 'preemption_count': 0}), (65771, {'train/accuracy': 0.7828124761581421, 'train/loss': 0.8689783215522766, 'validation/accuracy': 0.6918999552726746, 'validation/loss': 1.257969617843628, 'validation/num_examples': 50000, 'test/accuracy': 0.5678000450134277, 'test/loss': 1.8962740898132324, 'test/num_examples': 10000, 'score': 26524.409328699112, 'total_duration': 27890.754764795303, 'accumulated_submission_time': 26524.409328699112, 'accumulated_eval_time': 1362.5109467506409, 'accumulated_logging_time': 2.2930872440338135, 'global_step': 65771, 'preemption_count': 0}), (66817, {'train/accuracy': 0.7542773485183716, 'train/loss': 0.9646868705749512, 'validation/accuracy': 0.6929999589920044, 'validation/loss': 1.2465510368347168, 'validation/num_examples': 50000, 'test/accuracy': 0.5667999982833862, 'test/loss': 1.9005556106567383, 'test/num_examples': 10000, 'score': 26944.61537194252, 'total_duration': 28333.80340075493, 'accumulated_submission_time': 26944.61537194252, 'accumulated_eval_time': 1385.287623167038, 'accumulated_logging_time': 2.3340845108032227, 'global_step': 66817, 'preemption_count': 0}), (67863, {'train/accuracy': 0.7608398199081421, 'train/loss': 0.9341602921485901, 'validation/accuracy': 0.6943199634552002, 'validation/loss': 1.2355141639709473, 'validation/num_examples': 50000, 'test/accuracy': 0.5662000179290771, 'test/loss': 1.8756084442138672, 'test/num_examples': 10000, 'score': 27364.878598690033, 'total_duration': 28777.45173764229, 'accumulated_submission_time': 27364.878598690033, 'accumulated_eval_time': 1408.6116247177124, 'accumulated_logging_time': 2.3702986240386963, 'global_step': 67863, 'preemption_count': 0}), (68907, {'train/accuracy': 0.7695702910423279, 'train/loss': 0.898894727230072, 'validation/accuracy': 0.6972599625587463, 'validation/loss': 1.215494155883789, 'validation/num_examples': 50000, 'test/accuracy': 0.5730000138282776, 'test/loss': 1.8499271869659424, 'test/num_examples': 10000, 'score': 27784.850752592087, 'total_duration': 29220.634857416153, 'accumulated_submission_time': 27784.850752592087, 'accumulated_eval_time': 1431.7575941085815, 'accumulated_logging_time': 2.4106781482696533, 'global_step': 68907, 'preemption_count': 0}), (69953, {'train/accuracy': 0.7740429639816284, 'train/loss': 0.8898206949234009, 'validation/accuracy': 0.7023400068283081, 'validation/loss': 1.2168055772781372, 'validation/num_examples': 50000, 'test/accuracy': 0.5766000151634216, 'test/loss': 1.8437033891677856, 'test/num_examples': 10000, 'score': 28205.016985416412, 'total_duration': 29663.567587137222, 'accumulated_submission_time': 28205.016985416412, 'accumulated_eval_time': 1454.462661743164, 'accumulated_logging_time': 2.44659686088562, 'global_step': 69953, 'preemption_count': 0}), (70998, {'train/accuracy': 0.7826367020606995, 'train/loss': 0.8583043217658997, 'validation/accuracy': 0.6985399723052979, 'validation/loss': 1.222298264503479, 'validation/num_examples': 50000, 'test/accuracy': 0.5735000371932983, 'test/loss': 1.8572518825531006, 'test/num_examples': 10000, 'score': 28625.32857131958, 'total_duration': 30106.73026561737, 'accumulated_submission_time': 28625.32857131958, 'accumulated_eval_time': 1477.2483327388763, 'accumulated_logging_time': 2.486598014831543, 'global_step': 70998, 'preemption_count': 0}), (72044, {'train/accuracy': 0.7635937333106995, 'train/loss': 0.9765976667404175, 'validation/accuracy': 0.6970399618148804, 'validation/loss': 1.2639743089675903, 'validation/num_examples': 50000, 'test/accuracy': 0.569100022315979, 'test/loss': 1.9101098775863647, 'test/num_examples': 10000, 'score': 29045.375811338425, 'total_duration': 30549.583501815796, 'accumulated_submission_time': 29045.375811338425, 'accumulated_eval_time': 1499.993905544281, 'accumulated_logging_time': 2.522183418273926, 'global_step': 72044, 'preemption_count': 0}), (73090, {'train/accuracy': 0.7737500071525574, 'train/loss': 0.9227266311645508, 'validation/accuracy': 0.7008599638938904, 'validation/loss': 1.2360135316848755, 'validation/num_examples': 50000, 'test/accuracy': 0.5741000175476074, 'test/loss': 1.8782740831375122, 'test/num_examples': 10000, 'score': 29465.468447208405, 'total_duration': 30992.59301328659, 'accumulated_submission_time': 29465.468447208405, 'accumulated_eval_time': 1522.8517498970032, 'accumulated_logging_time': 2.555940866470337, 'global_step': 73090, 'preemption_count': 0}), (74137, {'train/accuracy': 0.7805273532867432, 'train/loss': 0.8620471954345703, 'validation/accuracy': 0.7059999704360962, 'validation/loss': 1.1919068098068237, 'validation/num_examples': 50000, 'test/accuracy': 0.5764000415802002, 'test/loss': 1.8326680660247803, 'test/num_examples': 10000, 'score': 29885.806559324265, 'total_duration': 31435.74547791481, 'accumulated_submission_time': 29885.806559324265, 'accumulated_eval_time': 1545.6061494350433, 'accumulated_logging_time': 2.590078353881836, 'global_step': 74137, 'preemption_count': 0}), (75183, {'train/accuracy': 0.7906249761581421, 'train/loss': 0.8165221810340881, 'validation/accuracy': 0.7071999907493591, 'validation/loss': 1.1724038124084473, 'validation/num_examples': 50000, 'test/accuracy': 0.5772000551223755, 'test/loss': 1.8087105751037598, 'test/num_examples': 10000, 'score': 30305.943779706955, 'total_duration': 31879.204911470413, 'accumulated_submission_time': 30305.943779706955, 'accumulated_eval_time': 1568.865062713623, 'accumulated_logging_time': 2.627786874771118, 'global_step': 75183, 'preemption_count': 0}), (76229, {'train/accuracy': 0.7838085889816284, 'train/loss': 0.8531697392463684, 'validation/accuracy': 0.7064200043678284, 'validation/loss': 1.1934088468551636, 'validation/num_examples': 50000, 'test/accuracy': 0.5842000246047974, 'test/loss': 1.8177891969680786, 'test/num_examples': 10000, 'score': 30726.010445594788, 'total_duration': 32321.481130599976, 'accumulated_submission_time': 30726.010445594788, 'accumulated_eval_time': 1591.0073211193085, 'accumulated_logging_time': 2.669809579849243, 'global_step': 76229, 'preemption_count': 0}), (77273, {'train/accuracy': 0.7840819954872131, 'train/loss': 0.8321162462234497, 'validation/accuracy': 0.7109799981117249, 'validation/loss': 1.1554577350616455, 'validation/num_examples': 50000, 'test/accuracy': 0.5878000259399414, 'test/loss': 1.783922791481018, 'test/num_examples': 10000, 'score': 31145.990751981735, 'total_duration': 32764.194286584854, 'accumulated_submission_time': 31145.990751981735, 'accumulated_eval_time': 1613.673790693283, 'accumulated_logging_time': 2.711463212966919, 'global_step': 77273, 'preemption_count': 0}), (78317, {'train/accuracy': 0.7808203101158142, 'train/loss': 0.847793459892273, 'validation/accuracy': 0.7127799987792969, 'validation/loss': 1.1588774919509888, 'validation/num_examples': 50000, 'test/accuracy': 0.5850000381469727, 'test/loss': 1.7985299825668335, 'test/num_examples': 10000, 'score': 31566.005507469177, 'total_duration': 33207.28758740425, 'accumulated_submission_time': 31566.005507469177, 'accumulated_eval_time': 1636.690050125122, 'accumulated_logging_time': 2.7483270168304443, 'global_step': 78317, 'preemption_count': 0}), (79362, {'train/accuracy': 0.7903124690055847, 'train/loss': 0.8170645236968994, 'validation/accuracy': 0.7137199640274048, 'validation/loss': 1.1454015970230103, 'validation/num_examples': 50000, 'test/accuracy': 0.5854000449180603, 'test/loss': 1.7807621955871582, 'test/num_examples': 10000, 'score': 31986.236578464508, 'total_duration': 33650.28029513359, 'accumulated_submission_time': 31986.236578464508, 'accumulated_eval_time': 1659.390082359314, 'accumulated_logging_time': 2.784764051437378, 'global_step': 79362, 'preemption_count': 0}), (80407, {'train/accuracy': 0.7999999523162842, 'train/loss': 0.7721484899520874, 'validation/accuracy': 0.7171199917793274, 'validation/loss': 1.1355528831481934, 'validation/num_examples': 50000, 'test/accuracy': 0.5890000462532043, 'test/loss': 1.780358910560608, 'test/num_examples': 10000, 'score': 32406.544193029404, 'total_duration': 34093.64468455315, 'accumulated_submission_time': 32406.544193029404, 'accumulated_eval_time': 1682.3830344676971, 'accumulated_logging_time': 2.823392391204834, 'global_step': 80407, 'preemption_count': 0}), (81452, {'train/accuracy': 0.7903906106948853, 'train/loss': 0.827329158782959, 'validation/accuracy': 0.7163999676704407, 'validation/loss': 1.1513112783432007, 'validation/num_examples': 50000, 'test/accuracy': 0.5937000513076782, 'test/loss': 1.776253581047058, 'test/num_examples': 10000, 'score': 32826.838790655136, 'total_duration': 34537.41755390167, 'accumulated_submission_time': 32826.838790655136, 'accumulated_eval_time': 1705.796971321106, 'accumulated_logging_time': 2.8631350994110107, 'global_step': 81452, 'preemption_count': 0}), (82497, {'train/accuracy': 0.7898046970367432, 'train/loss': 0.8128694891929626, 'validation/accuracy': 0.7208200097084045, 'validation/loss': 1.130611538887024, 'validation/num_examples': 50000, 'test/accuracy': 0.59170001745224, 'test/loss': 1.7631301879882812, 'test/num_examples': 10000, 'score': 33247.138005018234, 'total_duration': 34980.54034137726, 'accumulated_submission_time': 33247.138005018234, 'accumulated_eval_time': 1728.5550796985626, 'accumulated_logging_time': 2.9031553268432617, 'global_step': 82497, 'preemption_count': 0}), (83541, {'train/accuracy': 0.7963476181030273, 'train/loss': 0.8051990866661072, 'validation/accuracy': 0.7178800106048584, 'validation/loss': 1.1363667249679565, 'validation/num_examples': 50000, 'test/accuracy': 0.5927000045776367, 'test/loss': 1.7720719575881958, 'test/num_examples': 10000, 'score': 33667.192929029465, 'total_duration': 35423.55745244026, 'accumulated_submission_time': 33667.192929029465, 'accumulated_eval_time': 1751.4540152549744, 'accumulated_logging_time': 2.941237449645996, 'global_step': 83541, 'preemption_count': 0}), (84586, {'train/accuracy': 0.8034179210662842, 'train/loss': 0.7592959403991699, 'validation/accuracy': 0.7204799652099609, 'validation/loss': 1.117464303970337, 'validation/num_examples': 50000, 'test/accuracy': 0.5966000556945801, 'test/loss': 1.7558387517929077, 'test/num_examples': 10000, 'score': 34087.52724003792, 'total_duration': 35866.90614461899, 'accumulated_submission_time': 34087.52724003792, 'accumulated_eval_time': 1774.4071393013, 'accumulated_logging_time': 2.9775218963623047, 'global_step': 84586, 'preemption_count': 0}), (85631, {'train/accuracy': 0.8080468773841858, 'train/loss': 0.7547733187675476, 'validation/accuracy': 0.7256199717521667, 'validation/loss': 1.1136640310287476, 'validation/num_examples': 50000, 'test/accuracy': 0.5956000089645386, 'test/loss': 1.756873369216919, 'test/num_examples': 10000, 'score': 34507.866179943085, 'total_duration': 36310.178205251694, 'accumulated_submission_time': 34507.866179943085, 'accumulated_eval_time': 1797.2756581306458, 'accumulated_logging_time': 3.016528367996216, 'global_step': 85631, 'preemption_count': 0}), (86675, {'train/accuracy': 0.7999023199081421, 'train/loss': 0.7769256234169006, 'validation/accuracy': 0.7250999808311462, 'validation/loss': 1.1005381345748901, 'validation/num_examples': 50000, 'test/accuracy': 0.6010000109672546, 'test/loss': 1.7377148866653442, 'test/num_examples': 10000, 'score': 34927.84551358223, 'total_duration': 36753.29070973396, 'accumulated_submission_time': 34927.84551358223, 'accumulated_eval_time': 1820.3369822502136, 'accumulated_logging_time': 3.0633578300476074, 'global_step': 86675, 'preemption_count': 0}), (87721, {'train/accuracy': 0.8044140338897705, 'train/loss': 0.756144642829895, 'validation/accuracy': 0.7270999550819397, 'validation/loss': 1.0915273427963257, 'validation/num_examples': 50000, 'test/accuracy': 0.6003000140190125, 'test/loss': 1.7185434103012085, 'test/num_examples': 10000, 'score': 35347.86026406288, 'total_duration': 37196.54690337181, 'accumulated_submission_time': 35347.86026406288, 'accumulated_eval_time': 1843.5159730911255, 'accumulated_logging_time': 3.100771903991699, 'global_step': 87721, 'preemption_count': 0}), (88768, {'train/accuracy': 0.8026366829872131, 'train/loss': 0.7944849133491516, 'validation/accuracy': 0.727620005607605, 'validation/loss': 1.126023769378662, 'validation/num_examples': 50000, 'test/accuracy': 0.598800003528595, 'test/loss': 1.7579188346862793, 'test/num_examples': 10000, 'score': 35768.194784879684, 'total_duration': 37639.71990132332, 'accumulated_submission_time': 35768.194784879684, 'accumulated_eval_time': 1866.2901298999786, 'accumulated_logging_time': 3.1405704021453857, 'global_step': 88768, 'preemption_count': 0}), (89812, {'train/accuracy': 0.8099804520606995, 'train/loss': 0.7534193396568298, 'validation/accuracy': 0.7278800010681152, 'validation/loss': 1.109052062034607, 'validation/num_examples': 50000, 'test/accuracy': 0.6020000576972961, 'test/loss': 1.734480381011963, 'test/num_examples': 10000, 'score': 36188.180827856064, 'total_duration': 38082.822477817535, 'accumulated_submission_time': 36188.180827856064, 'accumulated_eval_time': 1889.3438789844513, 'accumulated_logging_time': 3.1781435012817383, 'global_step': 89812, 'preemption_count': 0}), (90857, {'train/accuracy': 0.8208593726158142, 'train/loss': 0.7060486674308777, 'validation/accuracy': 0.7312600016593933, 'validation/loss': 1.084007978439331, 'validation/num_examples': 50000, 'test/accuracy': 0.6088000535964966, 'test/loss': 1.7144088745117188, 'test/num_examples': 10000, 'score': 36608.48800897598, 'total_duration': 38526.04933142662, 'accumulated_submission_time': 36608.48800897598, 'accumulated_eval_time': 1912.1996190547943, 'accumulated_logging_time': 3.217334270477295, 'global_step': 90857, 'preemption_count': 0}), (91902, {'train/accuracy': 0.8119531273841858, 'train/loss': 0.7181794047355652, 'validation/accuracy': 0.7342000007629395, 'validation/loss': 1.0619198083877563, 'validation/num_examples': 50000, 'test/accuracy': 0.6134000420570374, 'test/loss': 1.6721934080123901, 'test/num_examples': 10000, 'score': 37028.64994573593, 'total_duration': 38969.17458200455, 'accumulated_submission_time': 37028.64994573593, 'accumulated_eval_time': 1935.0963258743286, 'accumulated_logging_time': 3.2581679821014404, 'global_step': 91902, 'preemption_count': 0}), (92946, {'train/accuracy': 0.8158007860183716, 'train/loss': 0.7065762281417847, 'validation/accuracy': 0.7360000014305115, 'validation/loss': 1.0474801063537598, 'validation/num_examples': 50000, 'test/accuracy': 0.6073000431060791, 'test/loss': 1.6745374202728271, 'test/num_examples': 10000, 'score': 37448.61979484558, 'total_duration': 39412.09059381485, 'accumulated_submission_time': 37448.61979484558, 'accumulated_eval_time': 1957.9792883396149, 'accumulated_logging_time': 3.2959954738616943, 'global_step': 92946, 'preemption_count': 0}), (93991, {'train/accuracy': 0.8186327815055847, 'train/loss': 0.6984440684318542, 'validation/accuracy': 0.7351399660110474, 'validation/loss': 1.0580488443374634, 'validation/num_examples': 50000, 'test/accuracy': 0.6057000160217285, 'test/loss': 1.6909916400909424, 'test/num_examples': 10000, 'score': 37868.88370323181, 'total_duration': 39855.74999141693, 'accumulated_submission_time': 37868.88370323181, 'accumulated_eval_time': 1981.3117098808289, 'accumulated_logging_time': 3.3336610794067383, 'global_step': 93991, 'preemption_count': 0}), (95036, {'train/accuracy': 0.8239257335662842, 'train/loss': 0.6699681878089905, 'validation/accuracy': 0.7370799779891968, 'validation/loss': 1.0492831468582153, 'validation/num_examples': 50000, 'test/accuracy': 0.6055000424385071, 'test/loss': 1.6872801780700684, 'test/num_examples': 10000, 'score': 38289.20016694069, 'total_duration': 40298.94289398193, 'accumulated_submission_time': 38289.20016694069, 'accumulated_eval_time': 2004.1246738433838, 'accumulated_logging_time': 3.3717031478881836, 'global_step': 95036, 'preemption_count': 0}), (96082, {'train/accuracy': 0.8350195288658142, 'train/loss': 0.6252655386924744, 'validation/accuracy': 0.7393999695777893, 'validation/loss': 1.0339401960372925, 'validation/num_examples': 50000, 'test/accuracy': 0.612500011920929, 'test/loss': 1.660857081413269, 'test/num_examples': 10000, 'score': 38709.25033950806, 'total_duration': 40741.93362522125, 'accumulated_submission_time': 38709.25033950806, 'accumulated_eval_time': 2026.997453212738, 'accumulated_logging_time': 3.414003849029541, 'global_step': 96082, 'preemption_count': 0}), (97126, {'train/accuracy': 0.8185351490974426, 'train/loss': 0.695246696472168, 'validation/accuracy': 0.7389599680900574, 'validation/loss': 1.0398509502410889, 'validation/num_examples': 50000, 'test/accuracy': 0.6117000579833984, 'test/loss': 1.684255599975586, 'test/num_examples': 10000, 'score': 39129.209339141846, 'total_duration': 41184.96327972412, 'accumulated_submission_time': 39129.209339141846, 'accumulated_eval_time': 2050.0059106349945, 'accumulated_logging_time': 3.4506795406341553, 'global_step': 97126, 'preemption_count': 0}), (98170, {'train/accuracy': 0.8245898485183716, 'train/loss': 0.6779055595397949, 'validation/accuracy': 0.740839958190918, 'validation/loss': 1.0352259874343872, 'validation/num_examples': 50000, 'test/accuracy': 0.6186000108718872, 'test/loss': 1.6553895473480225, 'test/num_examples': 10000, 'score': 39549.17415523529, 'total_duration': 41628.11632466316, 'accumulated_submission_time': 39549.17415523529, 'accumulated_eval_time': 2073.1283807754517, 'accumulated_logging_time': 3.4909555912017822, 'global_step': 98170, 'preemption_count': 0}), (99215, {'train/accuracy': 0.8324413895606995, 'train/loss': 0.6326121091842651, 'validation/accuracy': 0.7423799633979797, 'validation/loss': 1.017187476158142, 'validation/num_examples': 50000, 'test/accuracy': 0.6147000193595886, 'test/loss': 1.649651050567627, 'test/num_examples': 10000, 'score': 39969.50755906105, 'total_duration': 42071.874230861664, 'accumulated_submission_time': 39969.50755906105, 'accumulated_eval_time': 2096.4870545864105, 'accumulated_logging_time': 3.5312397480010986, 'global_step': 99215, 'preemption_count': 0}), (100260, {'train/accuracy': 0.8389452695846558, 'train/loss': 0.6219362020492554, 'validation/accuracy': 0.7434999942779541, 'validation/loss': 1.022175908088684, 'validation/num_examples': 50000, 'test/accuracy': 0.6147000193595886, 'test/loss': 1.6470781564712524, 'test/num_examples': 10000, 'score': 40389.82040929794, 'total_duration': 42515.428419589996, 'accumulated_submission_time': 40389.82040929794, 'accumulated_eval_time': 2119.656588792801, 'accumulated_logging_time': 3.57741379737854, 'global_step': 100260, 'preemption_count': 0}), (101305, {'train/accuracy': 0.8449609279632568, 'train/loss': 0.6025171279907227, 'validation/accuracy': 0.7428799867630005, 'validation/loss': 1.0217797756195068, 'validation/num_examples': 50000, 'test/accuracy': 0.6155000329017639, 'test/loss': 1.640717625617981, 'test/num_examples': 10000, 'score': 40810.15608167648, 'total_duration': 42958.85174679756, 'accumulated_submission_time': 40810.15608167648, 'accumulated_eval_time': 2142.678171157837, 'accumulated_logging_time': 3.6179349422454834, 'global_step': 101305, 'preemption_count': 0}), (102350, {'train/accuracy': 0.8340234160423279, 'train/loss': 0.6444380283355713, 'validation/accuracy': 0.7454400062561035, 'validation/loss': 1.013909935951233, 'validation/num_examples': 50000, 'test/accuracy': 0.6213000416755676, 'test/loss': 1.636124610900879, 'test/num_examples': 10000, 'score': 41230.40488195419, 'total_duration': 43401.60101008415, 'accumulated_submission_time': 41230.40488195419, 'accumulated_eval_time': 2165.1142427921295, 'accumulated_logging_time': 3.656766891479492, 'global_step': 102350, 'preemption_count': 0}), (103394, {'train/accuracy': 0.8389062285423279, 'train/loss': 0.6242377161979675, 'validation/accuracy': 0.7505799531936646, 'validation/loss': 1.0007450580596924, 'validation/num_examples': 50000, 'test/accuracy': 0.6234000325202942, 'test/loss': 1.6206493377685547, 'test/num_examples': 10000, 'score': 41650.50008225441, 'total_duration': 43844.81479001045, 'accumulated_submission_time': 41650.50008225441, 'accumulated_eval_time': 2188.1674411296844, 'accumulated_logging_time': 3.697463274002075, 'global_step': 103394, 'preemption_count': 0}), (104440, {'train/accuracy': 0.8372265696525574, 'train/loss': 0.6193738579750061, 'validation/accuracy': 0.7492199540138245, 'validation/loss': 1.0026942491531372, 'validation/num_examples': 50000, 'test/accuracy': 0.6220000386238098, 'test/loss': 1.6266696453094482, 'test/num_examples': 10000, 'score': 42070.46156835556, 'total_duration': 44287.82656097412, 'accumulated_submission_time': 42070.46156835556, 'accumulated_eval_time': 2211.152854204178, 'accumulated_logging_time': 3.7372419834136963, 'global_step': 104440, 'preemption_count': 0}), (105486, {'train/accuracy': 0.84730464220047, 'train/loss': 0.5663691163063049, 'validation/accuracy': 0.7495200037956238, 'validation/loss': 0.9787986278533936, 'validation/num_examples': 50000, 'test/accuracy': 0.6267000436782837, 'test/loss': 1.6092926263809204, 'test/num_examples': 10000, 'score': 42490.475023031235, 'total_duration': 44731.64317655563, 'accumulated_submission_time': 42490.475023031235, 'accumulated_eval_time': 2234.891610145569, 'accumulated_logging_time': 3.777486562728882, 'global_step': 105486, 'preemption_count': 0}), (106532, {'train/accuracy': 0.8542187213897705, 'train/loss': 0.5452814102172852, 'validation/accuracy': 0.752020001411438, 'validation/loss': 0.9748799204826355, 'validation/num_examples': 50000, 'test/accuracy': 0.6295000314712524, 'test/loss': 1.5967910289764404, 'test/num_examples': 10000, 'score': 42910.437056303024, 'total_duration': 45175.0082552433, 'accumulated_submission_time': 42910.437056303024, 'accumulated_eval_time': 2258.228541612625, 'accumulated_logging_time': 3.818650484085083, 'global_step': 106532, 'preemption_count': 0}), (107577, {'train/accuracy': 0.8407617211341858, 'train/loss': 0.5951334834098816, 'validation/accuracy': 0.7549799680709839, 'validation/loss': 0.9696326851844788, 'validation/num_examples': 50000, 'test/accuracy': 0.6306000351905823, 'test/loss': 1.5867396593093872, 'test/num_examples': 10000, 'score': 43330.64552640915, 'total_duration': 45618.80122709274, 'accumulated_submission_time': 43330.64552640915, 'accumulated_eval_time': 2281.7509183883667, 'accumulated_logging_time': 3.8563034534454346, 'global_step': 107577, 'preemption_count': 0}), (108622, {'train/accuracy': 0.8445116877555847, 'train/loss': 0.5901142954826355, 'validation/accuracy': 0.7546799778938293, 'validation/loss': 0.9761546850204468, 'validation/num_examples': 50000, 'test/accuracy': 0.6291000247001648, 'test/loss': 1.590201735496521, 'test/num_examples': 10000, 'score': 43750.918407678604, 'total_duration': 46061.92183113098, 'accumulated_submission_time': 43750.918407678604, 'accumulated_eval_time': 2304.5365624427795, 'accumulated_logging_time': 3.8930726051330566, 'global_step': 108622, 'preemption_count': 0}), (109669, {'train/accuracy': 0.849609375, 'train/loss': 0.5754680633544922, 'validation/accuracy': 0.7551199793815613, 'validation/loss': 0.9709078073501587, 'validation/num_examples': 50000, 'test/accuracy': 0.6338000297546387, 'test/loss': 1.585841178894043, 'test/num_examples': 10000, 'score': 44171.21485042572, 'total_duration': 46504.98866915703, 'accumulated_submission_time': 44171.21485042572, 'accumulated_eval_time': 2327.243965148926, 'accumulated_logging_time': 3.931236982345581, 'global_step': 109669, 'preemption_count': 0}), (110715, {'train/accuracy': 0.8553320169448853, 'train/loss': 0.5444430112838745, 'validation/accuracy': 0.7557799816131592, 'validation/loss': 0.9649862051010132, 'validation/num_examples': 50000, 'test/accuracy': 0.6357000470161438, 'test/loss': 1.5745275020599365, 'test/num_examples': 10000, 'score': 44591.15257000923, 'total_duration': 46948.02224588394, 'accumulated_submission_time': 44591.15257000923, 'accumulated_eval_time': 2350.271733522415, 'accumulated_logging_time': 3.974497079849243, 'global_step': 110715, 'preemption_count': 0}), (111761, {'train/accuracy': 0.8616796731948853, 'train/loss': 0.5260344743728638, 'validation/accuracy': 0.7577799558639526, 'validation/loss': 0.9589682817459106, 'validation/num_examples': 50000, 'test/accuracy': 0.6353000402450562, 'test/loss': 1.566028356552124, 'test/num_examples': 10000, 'score': 45011.27219748497, 'total_duration': 47391.21069025993, 'accumulated_submission_time': 45011.27219748497, 'accumulated_eval_time': 2373.275441646576, 'accumulated_logging_time': 4.014634370803833, 'global_step': 111761, 'preemption_count': 0}), (112807, {'train/accuracy': 0.8544335961341858, 'train/loss': 0.5604527592658997, 'validation/accuracy': 0.7591399550437927, 'validation/loss': 0.9580339789390564, 'validation/num_examples': 50000, 'test/accuracy': 0.6363000273704529, 'test/loss': 1.5757502317428589, 'test/num_examples': 10000, 'score': 45431.288873910904, 'total_duration': 47834.66138648987, 'accumulated_submission_time': 45431.288873910904, 'accumulated_eval_time': 2396.6408009529114, 'accumulated_logging_time': 4.05814266204834, 'global_step': 112807, 'preemption_count': 0}), (113853, {'train/accuracy': 0.8554101586341858, 'train/loss': 0.5423293709754944, 'validation/accuracy': 0.7605999708175659, 'validation/loss': 0.9480263590812683, 'validation/num_examples': 50000, 'test/accuracy': 0.6361000537872314, 'test/loss': 1.5560686588287354, 'test/num_examples': 10000, 'score': 45851.356169462204, 'total_duration': 48278.21495509148, 'accumulated_submission_time': 45851.356169462204, 'accumulated_eval_time': 2420.05947804451, 'accumulated_logging_time': 4.100126266479492, 'global_step': 113853, 'preemption_count': 0}), (114899, {'train/accuracy': 0.86048823595047, 'train/loss': 0.518140971660614, 'validation/accuracy': 0.7630999684333801, 'validation/loss': 0.9346221685409546, 'validation/num_examples': 50000, 'test/accuracy': 0.636900007724762, 'test/loss': 1.5563948154449463, 'test/num_examples': 10000, 'score': 46271.33834147453, 'total_duration': 48720.967970371246, 'accumulated_submission_time': 46271.33834147453, 'accumulated_eval_time': 2442.7613065242767, 'accumulated_logging_time': 4.1434714794158936, 'global_step': 114899, 'preemption_count': 0}), (115945, {'train/accuracy': 0.8642578125, 'train/loss': 0.5147847533226013, 'validation/accuracy': 0.7607199549674988, 'validation/loss': 0.9394441843032837, 'validation/num_examples': 50000, 'test/accuracy': 0.6388000249862671, 'test/loss': 1.5594556331634521, 'test/num_examples': 10000, 'score': 46691.32644343376, 'total_duration': 49164.30221223831, 'accumulated_submission_time': 46691.32644343376, 'accumulated_eval_time': 2466.039196252823, 'accumulated_logging_time': 4.186267137527466, 'global_step': 115945, 'preemption_count': 0}), (116990, {'train/accuracy': 0.8674023151397705, 'train/loss': 0.49553409218788147, 'validation/accuracy': 0.7648599743843079, 'validation/loss': 0.9223268628120422, 'validation/num_examples': 50000, 'test/accuracy': 0.6458000540733337, 'test/loss': 1.5338842868804932, 'test/num_examples': 10000, 'score': 47111.366933107376, 'total_duration': 49606.9425778389, 'accumulated_submission_time': 47111.366933107376, 'accumulated_eval_time': 2488.573524236679, 'accumulated_logging_time': 4.226797580718994, 'global_step': 116990, 'preemption_count': 0}), (118036, {'train/accuracy': 0.8635546565055847, 'train/loss': 0.5169057846069336, 'validation/accuracy': 0.7652999758720398, 'validation/loss': 0.9303491711616516, 'validation/num_examples': 50000, 'test/accuracy': 0.6498000025749207, 'test/loss': 1.5330860614776611, 'test/num_examples': 10000, 'score': 47531.31885385513, 'total_duration': 50049.83691740036, 'accumulated_submission_time': 47531.31885385513, 'accumulated_eval_time': 2511.451023578644, 'accumulated_logging_time': 4.266953945159912, 'global_step': 118036, 'preemption_count': 0}), (119083, {'train/accuracy': 0.8630468845367432, 'train/loss': 0.5217750668525696, 'validation/accuracy': 0.7639200091362, 'validation/loss': 0.9328798055648804, 'validation/num_examples': 50000, 'test/accuracy': 0.647100031375885, 'test/loss': 1.5337120294570923, 'test/num_examples': 10000, 'score': 47951.62020754814, 'total_duration': 50493.6642639637, 'accumulated_submission_time': 47951.62020754814, 'accumulated_eval_time': 2534.9115228652954, 'accumulated_logging_time': 4.306902647018433, 'global_step': 119083, 'preemption_count': 0}), (120129, {'train/accuracy': 0.8668944835662842, 'train/loss': 0.5051093697547913, 'validation/accuracy': 0.7659399509429932, 'validation/loss': 0.9179466962814331, 'validation/num_examples': 50000, 'test/accuracy': 0.6451000571250916, 'test/loss': 1.5264827013015747, 'test/num_examples': 10000, 'score': 48371.683430194855, 'total_duration': 50936.7331302166, 'accumulated_submission_time': 48371.683430194855, 'accumulated_eval_time': 2557.854325532913, 'accumulated_logging_time': 4.344862461090088, 'global_step': 120129, 'preemption_count': 0}), (121175, {'train/accuracy': 0.8700780868530273, 'train/loss': 0.4844999313354492, 'validation/accuracy': 0.767300009727478, 'validation/loss': 0.916588306427002, 'validation/num_examples': 50000, 'test/accuracy': 0.6470000147819519, 'test/loss': 1.5228590965270996, 'test/num_examples': 10000, 'score': 48791.66497206688, 'total_duration': 51379.899960279465, 'accumulated_submission_time': 48791.66497206688, 'accumulated_eval_time': 2580.976679801941, 'accumulated_logging_time': 4.383501052856445, 'global_step': 121175, 'preemption_count': 0}), (122221, {'train/accuracy': 0.8710546493530273, 'train/loss': 0.49914517998695374, 'validation/accuracy': 0.7683199644088745, 'validation/loss': 0.9202027320861816, 'validation/num_examples': 50000, 'test/accuracy': 0.6494000554084778, 'test/loss': 1.5301061868667603, 'test/num_examples': 10000, 'score': 49211.61485552788, 'total_duration': 51822.79950904846, 'accumulated_submission_time': 49211.61485552788, 'accumulated_eval_time': 2603.8565814495087, 'accumulated_logging_time': 4.427901983261108, 'global_step': 122221, 'preemption_count': 0}), (123268, {'train/accuracy': 0.8720117211341858, 'train/loss': 0.478810578584671, 'validation/accuracy': 0.768559992313385, 'validation/loss': 0.9037069082260132, 'validation/num_examples': 50000, 'test/accuracy': 0.652400016784668, 'test/loss': 1.5106265544891357, 'test/num_examples': 10000, 'score': 49631.779134750366, 'total_duration': 52265.969289541245, 'accumulated_submission_time': 49631.779134750366, 'accumulated_eval_time': 2626.7973709106445, 'accumulated_logging_time': 4.468078136444092, 'global_step': 123268, 'preemption_count': 0}), (124314, {'train/accuracy': 0.8717382550239563, 'train/loss': 0.47148576378822327, 'validation/accuracy': 0.7697399854660034, 'validation/loss': 0.9006651043891907, 'validation/num_examples': 50000, 'test/accuracy': 0.6484000086784363, 'test/loss': 1.5056315660476685, 'test/num_examples': 10000, 'score': 50051.849461078644, 'total_duration': 52709.26294159889, 'accumulated_submission_time': 50051.849461078644, 'accumulated_eval_time': 2649.957382440567, 'accumulated_logging_time': 4.506983995437622, 'global_step': 124314, 'preemption_count': 0}), (125360, {'train/accuracy': 0.8754101395606995, 'train/loss': 0.47015872597694397, 'validation/accuracy': 0.7717199921607971, 'validation/loss': 0.9034016728401184, 'validation/num_examples': 50000, 'test/accuracy': 0.6516000032424927, 'test/loss': 1.510228157043457, 'test/num_examples': 10000, 'score': 50471.87348651886, 'total_duration': 53152.56572031975, 'accumulated_submission_time': 50471.87348651886, 'accumulated_eval_time': 2673.1708047389984, 'accumulated_logging_time': 4.547850131988525, 'global_step': 125360, 'preemption_count': 0}), (126406, {'train/accuracy': 0.8778710961341858, 'train/loss': 0.46044984459877014, 'validation/accuracy': 0.7697799801826477, 'validation/loss': 0.9043248295783997, 'validation/num_examples': 50000, 'test/accuracy': 0.6458000540733337, 'test/loss': 1.5100255012512207, 'test/num_examples': 10000, 'score': 50891.871772289276, 'total_duration': 53595.86010169983, 'accumulated_submission_time': 50891.871772289276, 'accumulated_eval_time': 2696.3991055488586, 'accumulated_logging_time': 4.590073823928833, 'global_step': 126406, 'preemption_count': 0}), (127452, {'train/accuracy': 0.8773632645606995, 'train/loss': 0.4648609161376953, 'validation/accuracy': 0.7706999778747559, 'validation/loss': 0.902042806148529, 'validation/num_examples': 50000, 'test/accuracy': 0.650700032711029, 'test/loss': 1.5087542533874512, 'test/num_examples': 10000, 'score': 51311.89664435387, 'total_duration': 54039.00860953331, 'accumulated_submission_time': 51311.89664435387, 'accumulated_eval_time': 2719.4571118354797, 'accumulated_logging_time': 4.630898714065552, 'global_step': 127452, 'preemption_count': 0}), (128498, {'train/accuracy': 0.87806636095047, 'train/loss': 0.453902930021286, 'validation/accuracy': 0.7717799544334412, 'validation/loss': 0.8938944339752197, 'validation/num_examples': 50000, 'test/accuracy': 0.6511000394821167, 'test/loss': 1.5032665729522705, 'test/num_examples': 10000, 'score': 51731.86476254463, 'total_duration': 54481.64192318916, 'accumulated_submission_time': 51731.86476254463, 'accumulated_eval_time': 2742.028912305832, 'accumulated_logging_time': 4.699326515197754, 'global_step': 128498, 'preemption_count': 0}), (129544, {'train/accuracy': 0.8783398270606995, 'train/loss': 0.45605409145355225, 'validation/accuracy': 0.7703799605369568, 'validation/loss': 0.8932573199272156, 'validation/num_examples': 50000, 'test/accuracy': 0.6485000252723694, 'test/loss': 1.503004789352417, 'test/num_examples': 10000, 'score': 52151.900840997696, 'total_duration': 54925.22724056244, 'accumulated_submission_time': 52151.900840997696, 'accumulated_eval_time': 2765.508107662201, 'accumulated_logging_time': 4.7451441287994385, 'global_step': 129544, 'preemption_count': 0}), (130590, {'train/accuracy': 0.8764843344688416, 'train/loss': 0.46228593587875366, 'validation/accuracy': 0.7726799845695496, 'validation/loss': 0.8918628096580505, 'validation/num_examples': 50000, 'test/accuracy': 0.6512000560760498, 'test/loss': 1.501344084739685, 'test/num_examples': 10000, 'score': 52571.95457935333, 'total_duration': 55368.266671180725, 'accumulated_submission_time': 52571.95457935333, 'accumulated_eval_time': 2788.4298362731934, 'accumulated_logging_time': 4.784155607223511, 'global_step': 130590, 'preemption_count': 0}), (131634, {'train/accuracy': 0.8810546398162842, 'train/loss': 0.4481064975261688, 'validation/accuracy': 0.772819995880127, 'validation/loss': 0.8874424695968628, 'validation/num_examples': 50000, 'test/accuracy': 0.6551000475883484, 'test/loss': 1.499834418296814, 'test/num_examples': 10000, 'score': 52991.996413469315, 'total_duration': 55812.02141904831, 'accumulated_submission_time': 52991.996413469315, 'accumulated_eval_time': 2812.0786912441254, 'accumulated_logging_time': 4.823890209197998, 'global_step': 131634, 'preemption_count': 0}), (132681, {'train/accuracy': 0.8777539134025574, 'train/loss': 0.4599067270755768, 'validation/accuracy': 0.7736799716949463, 'validation/loss': 0.8873386383056641, 'validation/num_examples': 50000, 'test/accuracy': 0.6551000475883484, 'test/loss': 1.4969558715820312, 'test/num_examples': 10000, 'score': 53412.317210674286, 'total_duration': 56255.77086687088, 'accumulated_submission_time': 53412.317210674286, 'accumulated_eval_time': 2835.440642595291, 'accumulated_logging_time': 4.86470103263855, 'global_step': 132681, 'preemption_count': 0}), (133728, {'train/accuracy': 0.8803515434265137, 'train/loss': 0.4515140950679779, 'validation/accuracy': 0.7734999656677246, 'validation/loss': 0.88714200258255, 'validation/num_examples': 50000, 'test/accuracy': 0.6547000408172607, 'test/loss': 1.4963185787200928, 'test/num_examples': 10000, 'score': 53832.59554314613, 'total_duration': 56699.08690428734, 'accumulated_submission_time': 53832.59554314613, 'accumulated_eval_time': 2858.4112660884857, 'accumulated_logging_time': 4.9065163135528564, 'global_step': 133728, 'preemption_count': 0}), (134773, {'train/accuracy': 0.8775976300239563, 'train/loss': 0.45085039734840393, 'validation/accuracy': 0.7738800048828125, 'validation/loss': 0.8861609101295471, 'validation/num_examples': 50000, 'test/accuracy': 0.65420001745224, 'test/loss': 1.4922659397125244, 'test/num_examples': 10000, 'score': 54252.85058236122, 'total_duration': 57142.26908612251, 'accumulated_submission_time': 54252.85058236122, 'accumulated_eval_time': 2881.274034023285, 'accumulated_logging_time': 4.946626663208008, 'global_step': 134773, 'preemption_count': 0}), (135817, {'train/accuracy': 0.8817577958106995, 'train/loss': 0.4485340118408203, 'validation/accuracy': 0.7741599678993225, 'validation/loss': 0.8862265348434448, 'validation/num_examples': 50000, 'test/accuracy': 0.6541000604629517, 'test/loss': 1.4930837154388428, 'test/num_examples': 10000, 'score': 54672.79440379143, 'total_duration': 57585.444811820984, 'accumulated_submission_time': 54672.79440379143, 'accumulated_eval_time': 2904.436939716339, 'accumulated_logging_time': 4.991543531417847, 'global_step': 135817, 'preemption_count': 0}), (136864, {'train/accuracy': 0.8799218535423279, 'train/loss': 0.44930076599121094, 'validation/accuracy': 0.7742999792098999, 'validation/loss': 0.8853731155395508, 'validation/num_examples': 50000, 'test/accuracy': 0.6544000506401062, 'test/loss': 1.4933710098266602, 'test/num_examples': 10000, 'score': 55093.04386639595, 'total_duration': 58029.240710020065, 'accumulated_submission_time': 55093.04386639595, 'accumulated_eval_time': 2927.9166820049286, 'accumulated_logging_time': 5.033738851547241, 'global_step': 136864, 'preemption_count': 0}), (137911, {'train/accuracy': 0.8807616829872131, 'train/loss': 0.4524763822555542, 'validation/accuracy': 0.7742999792098999, 'validation/loss': 0.8846887350082397, 'validation/num_examples': 50000, 'test/accuracy': 0.6538000106811523, 'test/loss': 1.4922215938568115, 'test/num_examples': 10000, 'score': 55513.35981178284, 'total_duration': 58473.231236219406, 'accumulated_submission_time': 55513.35981178284, 'accumulated_eval_time': 2951.521292448044, 'accumulated_logging_time': 5.07880425453186, 'global_step': 137911, 'preemption_count': 0}), (138957, {'train/accuracy': 0.8803125023841858, 'train/loss': 0.4506169557571411, 'validation/accuracy': 0.7745800018310547, 'validation/loss': 0.8848632574081421, 'validation/num_examples': 50000, 'test/accuracy': 0.6551000475883484, 'test/loss': 1.4922782182693481, 'test/num_examples': 10000, 'score': 55933.33145284653, 'total_duration': 58916.6573946476, 'accumulated_submission_time': 55933.33145284653, 'accumulated_eval_time': 2974.9040195941925, 'accumulated_logging_time': 5.125922203063965, 'global_step': 138957, 'preemption_count': 0}), (140000, {'train/accuracy': 0.8816796541213989, 'train/loss': 0.45050865411758423, 'validation/accuracy': 0.7745599746704102, 'validation/loss': 0.8846639394760132, 'validation/num_examples': 50000, 'test/accuracy': 0.6549000144004822, 'test/loss': 1.4921404123306274, 'test/num_examples': 10000, 'score': 56352.07413482666, 'total_duration': 59358.44564127922, 'accumulated_submission_time': 56352.07413482666, 'accumulated_eval_time': 2997.8797721862793, 'accumulated_logging_time': 5.170516014099121, 'global_step': 140000, 'preemption_count': 0})], 'global_step': 140000}
I0915 13:25:00.597816 140537819772736 submission_runner.py:543] Timing: 56352.07413482666
I0915 13:25:00.597903 140537819772736 submission_runner.py:545] Total number of evals: 135
I0915 13:25:00.597953 140537819772736 submission_runner.py:546] ====================
I0915 13:25:00.598270 140537819772736 submission_runner.py:614] Final imagenet_vit score: 56352.07413482666
