python3 submission_runner.py --framework=jax --workload=librispeech_conformer --submission_path=reference_algorithms/target_setting_algorithms/jax_adamw.py --tuning_search_space=reference_algorithms/target_setting_algorithms/librispeech_conformer/tuning_search_space.json --data_dir=/data/librispeech --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=targets_check_conformer/adamw_run_0 --overwrite=true --save_checkpoints=false --max_global_steps=60000 --librispeech_tokenizer_vocab_path=/data/librispeech/spm_model.vocab 2>&1 | tee -a /logs/librispeech_conformer_jax_10-04-2023-01-17-04.log
2023-10-04 01:17:09.839265: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I1004 01:17:28.026748 140439319918400 logger_utils.py:76] Creating experiment directory at /experiment_runs/targets_check_conformer/adamw_run_0/librispeech_conformer_jax.
I1004 01:17:29.102779 140439319918400 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Host Interpreter CUDA
I1004 01:17:29.103383 140439319918400 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I1004 01:17:29.103518 140439319918400 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I1004 01:17:29.108445 140439319918400 submission_runner.py:507] Using RNG seed 1072113051
I1004 01:17:35.086994 140439319918400 submission_runner.py:516] --- Tuning run 1/1 ---
I1004 01:17:35.087191 140439319918400 submission_runner.py:521] Creating tuning directory at /experiment_runs/targets_check_conformer/adamw_run_0/librispeech_conformer_jax/trial_1.
I1004 01:17:35.087354 140439319918400 logger_utils.py:92] Saving hparams to /experiment_runs/targets_check_conformer/adamw_run_0/librispeech_conformer_jax/trial_1/hparams.json.
I1004 01:17:35.263322 140439319918400 submission_runner.py:191] Initializing dataset.
I1004 01:17:35.263497 140439319918400 submission_runner.py:198] Initializing model.
I1004 01:17:39.885512 140439319918400 submission_runner.py:232] Initializing optimizer.
I1004 01:17:41.128608 140439319918400 submission_runner.py:239] Initializing metrics bundle.
I1004 01:17:41.128790 140439319918400 submission_runner.py:257] Initializing checkpoint and logger.
I1004 01:17:41.130191 140439319918400 checkpoints.py:915] Found no checkpoint files in /experiment_runs/targets_check_conformer/adamw_run_0/librispeech_conformer_jax/trial_1 with prefix checkpoint_
I1004 01:17:41.130321 140439319918400 submission_runner.py:277] Saving meta data to /experiment_runs/targets_check_conformer/adamw_run_0/librispeech_conformer_jax/trial_1/meta_data_0.json.
I1004 01:17:41.130495 140439319918400 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I1004 01:17:41.130557 140439319918400 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I1004 01:17:41.416768 140439319918400 logger_utils.py:220] Unable to record git information. Continuing without it.
I1004 01:17:41.682232 140439319918400 submission_runner.py:280] Saving flags to /experiment_runs/targets_check_conformer/adamw_run_0/librispeech_conformer_jax/trial_1/flags_0.json.
I1004 01:17:41.698406 140439319918400 submission_runner.py:290] Starting training loop.
I1004 01:17:41.988198 140439319918400 input_pipeline.py:20] Loading split = train-clean-100
I1004 01:17:42.032388 140439319918400 input_pipeline.py:20] Loading split = train-clean-360
I1004 01:17:42.416462 140439319918400 input_pipeline.py:20] Loading split = train-other-500
2023-10-04 01:18:52.604988: E external/xla/xla/service/rendezvous.cc:31] This thread has been waiting for 10 seconds and may be stuck:
2023-10-04 01:18:55.087485: E external/xla/xla/service/rendezvous.cc:36] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.
/usr/local/lib/python3.8/dist-packages/jax/_src/interpreters/mlir.py:582: UserWarning: Some donated buffers were not usable: ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]).
See an explanation at https://jax.readthedocs.io/en/latest/faq.html#buffer-donation.
  warnings.warn(f"Some donated buffers were not usable: {', '.join(unused_donations)}.\n{msg}")
I1004 01:18:57.057265 140263766882048 logging_writer.py:48] [0] global_step=0, grad_norm=29.87761116027832, loss=32.54839324951172
I1004 01:18:57.094410 140439319918400 spec.py:321] Evaluating on the training split.
I1004 01:18:57.257266 140439319918400 input_pipeline.py:20] Loading split = train-clean-100
I1004 01:18:57.292276 140439319918400 input_pipeline.py:20] Loading split = train-clean-360
I1004 01:18:57.700055 140439319918400 input_pipeline.py:20] Loading split = train-other-500
/usr/local/lib/python3.8/dist-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.
  warnings.warn("scatter inputs have incompatible types: cannot safely cast "
I1004 01:20:13.082695 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 01:20:13.193944 140439319918400 input_pipeline.py:20] Loading split = dev-clean
I1004 01:20:13.199038 140439319918400 input_pipeline.py:20] Loading split = dev-other
I1004 01:21:05.746692 140439319918400 spec.py:349] Evaluating on the test split.
I1004 01:21:05.859825 140439319918400 input_pipeline.py:20] Loading split = test-clean
I1004 01:21:42.669111 140439319918400 submission_runner.py:381] Time since start: 240.97s, 	Step: 1, 	{'train/ctc_loss': Array(31.98603, dtype=float32), 'train/wer': 1.3190138058846803, 'validation/ctc_loss': Array(31.149433, dtype=float32), 'validation/wer': 1.0245154318903222, 'validation/num_examples': 5348, 'test/ctc_loss': Array(31.20991, dtype=float32), 'test/wer': 1.0714967603030487, 'test/num_examples': 2472, 'score': 75.39593124389648, 'total_duration': 240.96851873397827, 'accumulated_submission_time': 75.39593124389648, 'accumulated_eval_time': 165.57253074645996, 'accumulated_logging_time': 0}
I1004 01:21:42.697133 140258154899200 logging_writer.py:48] [1] accumulated_eval_time=165.572531, accumulated_logging_time=0, accumulated_submission_time=75.395931, global_step=1, preemption_count=0, score=75.395931, test/ctc_loss=31.209909439086914, test/num_examples=2472, test/wer=1.071497, total_duration=240.968519, train/ctc_loss=31.98603057861328, train/wer=1.319014, validation/ctc_loss=31.149433135986328, validation/num_examples=5348, validation/wer=1.024515
I1004 01:22:03.945574 140265890985728 logging_writer.py:48] [1] global_step=1, grad_norm=30.083656311035156, loss=32.84653091430664
I1004 01:22:04.825654 140265899378432 logging_writer.py:48] [2] global_step=2, grad_norm=33.96491241455078, loss=32.5300178527832
I1004 01:22:05.701701 140265890985728 logging_writer.py:48] [3] global_step=3, grad_norm=36.209373474121094, loss=32.60873794555664
I1004 01:22:06.524966 140265899378432 logging_writer.py:48] [4] global_step=4, grad_norm=40.26200485229492, loss=31.52754783630371
I1004 01:22:07.408973 140265890985728 logging_writer.py:48] [5] global_step=5, grad_norm=41.16997528076172, loss=31.1866512298584
I1004 01:22:08.294198 140265899378432 logging_writer.py:48] [6] global_step=6, grad_norm=42.04922866821289, loss=30.04354476928711
I1004 01:22:09.175082 140265890985728 logging_writer.py:48] [7] global_step=7, grad_norm=43.34331512451172, loss=29.93158721923828
I1004 01:22:10.047596 140265899378432 logging_writer.py:48] [8] global_step=8, grad_norm=43.027889251708984, loss=28.434972763061523
I1004 01:22:10.937203 140265890985728 logging_writer.py:48] [9] global_step=9, grad_norm=36.424320220947266, loss=27.851558685302734
I1004 01:22:11.824251 140265899378432 logging_writer.py:48] [10] global_step=10, grad_norm=42.49740982055664, loss=27.03485107421875
I1004 01:22:12.707090 140265890985728 logging_writer.py:48] [11] global_step=11, grad_norm=33.2188606262207, loss=27.635114669799805
I1004 01:22:13.583829 140265899378432 logging_writer.py:48] [12] global_step=12, grad_norm=35.198692321777344, loss=25.412466049194336
I1004 01:22:14.464374 140265890985728 logging_writer.py:48] [13] global_step=13, grad_norm=40.429473876953125, loss=24.096769332885742
I1004 01:22:15.335171 140265899378432 logging_writer.py:48] [14] global_step=14, grad_norm=82.5035400390625, loss=23.616987228393555
I1004 01:22:16.208363 140265890985728 logging_writer.py:48] [15] global_step=15, grad_norm=73.97161865234375, loss=20.622425079345703
I1004 01:22:17.085363 140265899378432 logging_writer.py:48] [16] global_step=16, grad_norm=105.07428741455078, loss=18.381696701049805
I1004 01:22:17.970269 140265890985728 logging_writer.py:48] [17] global_step=17, grad_norm=123.92868041992188, loss=14.032569885253906
I1004 01:22:18.846495 140265899378432 logging_writer.py:48] [18] global_step=18, grad_norm=81.64958953857422, loss=9.58758544921875
I1004 01:22:19.724593 140265890985728 logging_writer.py:48] [19] global_step=19, grad_norm=20.563045501708984, loss=7.497236728668213
I1004 01:22:20.605394 140265899378432 logging_writer.py:48] [20] global_step=20, grad_norm=10.484391212463379, loss=7.336498737335205
I1004 01:22:21.488346 140265890985728 logging_writer.py:48] [21] global_step=21, grad_norm=19.504430770874023, loss=7.7180657386779785
I1004 01:22:22.361571 140265899378432 logging_writer.py:48] [22] global_step=22, grad_norm=22.20132064819336, loss=8.043218612670898
I1004 01:22:23.238146 140265890985728 logging_writer.py:48] [23] global_step=23, grad_norm=22.92170524597168, loss=8.164973258972168
I1004 01:22:24.119757 140265899378432 logging_writer.py:48] [24] global_step=24, grad_norm=22.799638748168945, loss=8.120416641235352
I1004 01:22:25.008194 140265890985728 logging_writer.py:48] [25] global_step=25, grad_norm=21.943700790405273, loss=7.926074504852295
I1004 01:22:25.886560 140265899378432 logging_writer.py:48] [26] global_step=26, grad_norm=19.7485408782959, loss=7.637413501739502
I1004 01:22:26.754720 140265890985728 logging_writer.py:48] [27] global_step=27, grad_norm=15.278919219970703, loss=7.291438102722168
I1004 01:22:27.637255 140265899378432 logging_writer.py:48] [28] global_step=28, grad_norm=6.064847469329834, loss=7.023779392242432
I1004 01:22:28.525664 140265890985728 logging_writer.py:48] [29] global_step=29, grad_norm=9.898725509643555, loss=7.037325382232666
I1004 01:22:29.401323 140265899378432 logging_writer.py:48] [30] global_step=30, grad_norm=23.5676326751709, loss=7.23853063583374
I1004 01:22:30.278088 140265890985728 logging_writer.py:48] [31] global_step=31, grad_norm=23.740177154541016, loss=7.226871490478516
I1004 01:22:31.163117 140265899378432 logging_writer.py:48] [32] global_step=32, grad_norm=15.147905349731445, loss=7.044372081756592
I1004 01:22:32.053577 140265890985728 logging_writer.py:48] [33] global_step=33, grad_norm=3.180877685546875, loss=6.853606224060059
I1004 01:22:32.938739 140265899378432 logging_writer.py:48] [34] global_step=34, grad_norm=5.887948036193848, loss=6.8422064781188965
I1004 01:22:33.821338 140265890985728 logging_writer.py:48] [35] global_step=35, grad_norm=9.369013786315918, loss=6.872541427612305
I1004 01:22:34.712060 140265899378432 logging_writer.py:48] [36] global_step=36, grad_norm=10.530856132507324, loss=6.8724470138549805
I1004 01:22:35.608956 140265890985728 logging_writer.py:48] [37] global_step=37, grad_norm=9.226541519165039, loss=6.79592227935791
I1004 01:22:36.488934 140265899378432 logging_writer.py:48] [38] global_step=38, grad_norm=5.993599891662598, loss=6.7105021476745605
I1004 01:22:37.370089 140265890985728 logging_writer.py:48] [39] global_step=39, grad_norm=1.9767965078353882, loss=6.609527587890625
I1004 01:22:38.258046 140265899378432 logging_writer.py:48] [40] global_step=40, grad_norm=6.451928615570068, loss=6.62106466293335
I1004 01:22:39.150259 140265890985728 logging_writer.py:48] [41] global_step=41, grad_norm=9.737722396850586, loss=6.608867168426514
I1004 01:22:40.045953 140265899378432 logging_writer.py:48] [42] global_step=42, grad_norm=8.64748764038086, loss=6.571052551269531
I1004 01:22:40.942904 140265890985728 logging_writer.py:48] [43] global_step=43, grad_norm=3.566197156906128, loss=6.485830307006836
I1004 01:22:41.858701 140265899378432 logging_writer.py:48] [44] global_step=44, grad_norm=2.7929210662841797, loss=6.435091018676758
I1004 01:22:42.754070 140265890985728 logging_writer.py:48] [45] global_step=45, grad_norm=5.250225067138672, loss=6.4273834228515625
I1004 01:22:43.646143 140265899378432 logging_writer.py:48] [46] global_step=46, grad_norm=5.812340259552002, loss=6.394338130950928
I1004 01:22:44.537814 140265890985728 logging_writer.py:48] [47] global_step=47, grad_norm=1.5478912591934204, loss=6.342658996582031
I1004 01:22:45.443702 140265899378432 logging_writer.py:48] [48] global_step=48, grad_norm=2.8375468254089355, loss=6.2998528480529785
I1004 01:22:46.333806 140265890985728 logging_writer.py:48] [49] global_step=49, grad_norm=5.092654705047607, loss=6.275442600250244
I1004 01:22:47.219485 140265899378432 logging_writer.py:48] [50] global_step=50, grad_norm=4.44393253326416, loss=6.238049030303955
I1004 01:22:48.108286 140265890985728 logging_writer.py:48] [51] global_step=51, grad_norm=1.4042680263519287, loss=6.2155938148498535
I1004 01:22:48.998541 140265899378432 logging_writer.py:48] [52] global_step=52, grad_norm=3.8024163246154785, loss=6.182489395141602
I1004 01:22:49.885138 140265890985728 logging_writer.py:48] [53] global_step=53, grad_norm=1.8132725954055786, loss=6.166815757751465
I1004 01:22:50.769473 140265899378432 logging_writer.py:48] [54] global_step=54, grad_norm=1.2693572044372559, loss=6.12312650680542
I1004 01:22:51.658417 140265890985728 logging_writer.py:48] [55] global_step=55, grad_norm=3.825441598892212, loss=6.100451469421387
I1004 01:22:52.558603 140265899378432 logging_writer.py:48] [56] global_step=56, grad_norm=0.8244678378105164, loss=6.068629741668701
I1004 01:22:53.445875 140265890985728 logging_writer.py:48] [57] global_step=57, grad_norm=1.8886808156967163, loss=6.057227611541748
I1004 01:22:54.331314 140265899378432 logging_writer.py:48] [58] global_step=58, grad_norm=0.9080742597579956, loss=6.0257744789123535
I1004 01:22:55.218077 140265890985728 logging_writer.py:48] [59] global_step=59, grad_norm=1.493588924407959, loss=6.0231804847717285
I1004 01:22:56.113961 140265899378432 logging_writer.py:48] [60] global_step=60, grad_norm=0.8882756233215332, loss=5.993353366851807
I1004 01:22:57.003592 140265890985728 logging_writer.py:48] [61] global_step=61, grad_norm=0.9868553280830383, loss=5.998688220977783
I1004 01:22:57.888597 140265899378432 logging_writer.py:48] [62] global_step=62, grad_norm=0.5853326916694641, loss=5.944533824920654
I1004 01:22:58.772900 140265890985728 logging_writer.py:48] [63] global_step=63, grad_norm=1.2882189750671387, loss=5.953670024871826
I1004 01:22:59.666856 140265899378432 logging_writer.py:48] [64] global_step=64, grad_norm=0.7092342376708984, loss=5.9370341300964355
I1004 01:23:00.557651 140265890985728 logging_writer.py:48] [65] global_step=65, grad_norm=0.7816231846809387, loss=5.925568103790283
I1004 01:23:01.438777 140265899378432 logging_writer.py:48] [66] global_step=66, grad_norm=1.703467845916748, loss=5.909287452697754
I1004 01:23:02.329203 140265890985728 logging_writer.py:48] [67] global_step=67, grad_norm=1.2492903470993042, loss=5.905165672302246
I1004 01:23:03.230033 140265899378432 logging_writer.py:48] [68] global_step=68, grad_norm=0.8178460001945496, loss=5.875939846038818
I1004 01:23:04.120194 140265890985728 logging_writer.py:48] [69] global_step=69, grad_norm=0.8610868453979492, loss=5.869599342346191
I1004 01:23:05.009201 140265899378432 logging_writer.py:48] [70] global_step=70, grad_norm=1.359567642211914, loss=5.860603332519531
I1004 01:23:05.902234 140265890985728 logging_writer.py:48] [71] global_step=71, grad_norm=1.6023095846176147, loss=5.886767864227295
I1004 01:23:06.803507 140265899378432 logging_writer.py:48] [72] global_step=72, grad_norm=2.8501458168029785, loss=5.877098560333252
I1004 01:23:07.691945 140265890985728 logging_writer.py:48] [73] global_step=73, grad_norm=5.427755355834961, loss=5.884291172027588
I1004 01:23:08.583137 140265899378432 logging_writer.py:48] [74] global_step=74, grad_norm=7.580637454986572, loss=5.878779411315918
I1004 01:23:09.481184 140265890985728 logging_writer.py:48] [75] global_step=75, grad_norm=5.308282375335693, loss=5.889531135559082
I1004 01:23:10.373045 140265899378432 logging_writer.py:48] [76] global_step=76, grad_norm=2.0762338638305664, loss=5.850156307220459
I1004 01:23:11.264322 140265890985728 logging_writer.py:48] [77] global_step=77, grad_norm=8.75191879272461, loss=5.927005290985107
I1004 01:23:12.144931 140265899378432 logging_writer.py:48] [78] global_step=78, grad_norm=6.611853122711182, loss=5.881540298461914
I1004 01:23:13.031285 140265890985728 logging_writer.py:48] [79] global_step=79, grad_norm=3.7444188594818115, loss=5.859383583068848
I1004 01:23:13.923698 140265899378432 logging_writer.py:48] [80] global_step=80, grad_norm=8.893614768981934, loss=5.900739669799805
I1004 01:23:14.813881 140265890985728 logging_writer.py:48] [81] global_step=81, grad_norm=1.7185171842575073, loss=5.830122947692871
I1004 01:23:15.699711 140265899378432 logging_writer.py:48] [82] global_step=82, grad_norm=5.8290815353393555, loss=5.858779430389404
I1004 01:23:16.594804 140265890985728 logging_writer.py:48] [83] global_step=83, grad_norm=1.4009113311767578, loss=5.826850414276123
I1004 01:23:17.484378 140265899378432 logging_writer.py:48] [84] global_step=84, grad_norm=6.539258003234863, loss=5.868235111236572
I1004 01:23:18.369524 140265890985728 logging_writer.py:48] [85] global_step=85, grad_norm=4.140806674957275, loss=5.850255489349365
I1004 01:23:19.256932 140265899378432 logging_writer.py:48] [86] global_step=86, grad_norm=4.218390941619873, loss=5.843585968017578
I1004 01:23:20.139516 140265890985728 logging_writer.py:48] [87] global_step=87, grad_norm=5.027060031890869, loss=5.860232353210449
I1004 01:23:21.026693 140265899378432 logging_writer.py:48] [88] global_step=88, grad_norm=0.7951269149780273, loss=5.809805393218994
I1004 01:23:21.910507 140265890985728 logging_writer.py:48] [89] global_step=89, grad_norm=2.5542585849761963, loss=5.828204154968262
I1004 01:23:22.795790 140265899378432 logging_writer.py:48] [90] global_step=90, grad_norm=0.961033821105957, loss=5.84060525894165
I1004 01:23:23.679227 140265890985728 logging_writer.py:48] [91] global_step=91, grad_norm=3.8923163414001465, loss=5.857443332672119
I1004 01:23:24.565816 140265899378432 logging_writer.py:48] [92] global_step=92, grad_norm=2.657636880874634, loss=5.840512752532959
I1004 01:23:25.451679 140265890985728 logging_writer.py:48] [93] global_step=93, grad_norm=1.5809956789016724, loss=5.841614723205566
I1004 01:23:26.336760 140265899378432 logging_writer.py:48] [94] global_step=94, grad_norm=3.428273916244507, loss=5.829783916473389
I1004 01:23:27.227175 140265890985728 logging_writer.py:48] [95] global_step=95, grad_norm=0.7295413613319397, loss=5.799427032470703
I1004 01:23:28.109885 140265899378432 logging_writer.py:48] [96] global_step=96, grad_norm=2.6636433601379395, loss=5.835598468780518
I1004 01:23:28.995510 140265890985728 logging_writer.py:48] [97] global_step=97, grad_norm=3.4436652660369873, loss=5.83006477355957
I1004 01:23:29.877809 140265899378432 logging_writer.py:48] [98] global_step=98, grad_norm=1.2967392206192017, loss=5.8170366287231445
I1004 01:23:30.754650 140265890985728 logging_writer.py:48] [99] global_step=99, grad_norm=2.118021011352539, loss=5.83335018157959
I1004 01:23:31.637365 140265899378432 logging_writer.py:48] [100] global_step=100, grad_norm=4.215831279754639, loss=5.839430332183838
I1004 01:28:35.945024 140265890985728 logging_writer.py:48] [500] global_step=500, grad_norm=0.9110736846923828, loss=4.278042793273926
I1004 01:35:25.947050 140265899378432 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.9151813387870789, loss=2.6854043006896973
I1004 01:41:51.915471 140259893405440 logging_writer.py:48] [1500] global_step=1500, grad_norm=1.0276362895965576, loss=2.3222672939300537
I1004 01:45:43.430254 140439319918400 spec.py:321] Evaluating on the training split.
I1004 01:46:33.201277 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 01:47:21.141846 140439319918400 spec.py:349] Evaluating on the test split.
I1004 01:47:45.223072 140439319918400 submission_runner.py:381] Time since start: 1803.52s, 	Step: 1788, 	{'train/ctc_loss': Array(2.1337428, dtype=float32), 'train/wer': 0.5123066466190191, 'validation/ctc_loss': Array(2.652203, dtype=float32), 'validation/wer': 0.5496917481114145, 'validation/num_examples': 5348, 'test/ctc_loss': Array(2.2688458, dtype=float32), 'test/wer': 0.5073426360368046, 'test/num_examples': 2472, 'score': 1516.0885436534882, 'total_duration': 1803.5193746089935, 'accumulated_submission_time': 1516.0885436534882, 'accumulated_eval_time': 287.36010932922363, 'accumulated_logging_time': 0.040886878967285156}
I1004 01:47:45.264168 140259893405440 logging_writer.py:48] [1788] accumulated_eval_time=287.360109, accumulated_logging_time=0.040887, accumulated_submission_time=1516.088544, global_step=1788, preemption_count=0, score=1516.088544, test/ctc_loss=2.268845796585083, test/num_examples=2472, test/wer=0.507343, total_duration=1803.519375, train/ctc_loss=2.1337428092956543, train/wer=0.512307, validation/ctc_loss=2.65220308303833, validation/num_examples=5348, validation/wer=0.549692
I1004 01:50:27.374709 140259885012736 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.7158941030502319, loss=2.081084728240967
I1004 01:56:50.955618 140266605094656 logging_writer.py:48] [2500] global_step=2500, grad_norm=1.1322510242462158, loss=1.9760046005249023
I1004 02:03:44.865824 140266596701952 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.5870882868766785, loss=1.9557369947433472
I1004 02:10:14.786139 140266605094656 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.8451109528541565, loss=1.9544250965118408
I1004 02:11:45.678621 140439319918400 spec.py:321] Evaluating on the training split.
I1004 02:12:36.278248 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 02:13:24.568615 140439319918400 spec.py:349] Evaluating on the test split.
I1004 02:13:49.584542 140439319918400 submission_runner.py:381] Time since start: 3367.88s, 	Step: 3618, 	{'train/ctc_loss': Array(0.6710612, dtype=float32), 'train/wer': 0.22796793010681085, 'validation/ctc_loss': Array(0.99554235, dtype=float32), 'validation/wer': 0.28647647348261923, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.70161444, dtype=float32), 'test/wer': 0.2290130603457031, 'test/num_examples': 2472, 'score': 2956.459987640381, 'total_duration': 3367.879745721817, 'accumulated_submission_time': 2956.459987640381, 'accumulated_eval_time': 411.2596890926361, 'accumulated_logging_time': 0.09616494178771973}
I1004 02:13:49.618579 140266605094656 logging_writer.py:48] [3618] accumulated_eval_time=411.259689, accumulated_logging_time=0.096165, accumulated_submission_time=2956.459988, global_step=3618, preemption_count=0, score=2956.459988, test/ctc_loss=0.7016144394874573, test/num_examples=2472, test/wer=0.229013, total_duration=3367.879746, train/ctc_loss=0.6710612177848816, train/wer=0.227968, validation/ctc_loss=0.9955423474311829, validation/num_examples=5348, validation/wer=0.286476
I1004 02:18:41.621271 140266596701952 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.8305920958518982, loss=1.8725630044937134
I1004 02:25:14.063904 140266605094656 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.6077006459236145, loss=1.8494758605957031
I1004 02:32:05.320591 140266596701952 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.62144535779953, loss=1.7800472974777222
I1004 02:37:50.175392 140439319918400 spec.py:321] Evaluating on the training split.
I1004 02:38:41.485302 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 02:39:31.083529 140439319918400 spec.py:349] Evaluating on the test split.
I1004 02:39:55.386938 140439319918400 submission_runner.py:381] Time since start: 4933.68s, 	Step: 5438, 	{'train/ctc_loss': Array(0.49043533, dtype=float32), 'train/wer': 0.17396988050244847, 'validation/ctc_loss': Array(0.83833593, dtype=float32), 'validation/wer': 0.24725757122596456, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.55463874, dtype=float32), 'test/wer': 0.18579001888976907, 'test/num_examples': 2472, 'score': 4396.973568677902, 'total_duration': 4933.6836478710175, 'accumulated_submission_time': 4396.973568677902, 'accumulated_eval_time': 536.4664764404297, 'accumulated_logging_time': 0.14515447616577148}
I1004 02:39:55.420566 140266605094656 logging_writer.py:48] [5438] accumulated_eval_time=536.466476, accumulated_logging_time=0.145154, accumulated_submission_time=4396.973569, global_step=5438, preemption_count=0, score=4396.973569, test/ctc_loss=0.5546387434005737, test/num_examples=2472, test/wer=0.185790, total_duration=4933.683648, train/ctc_loss=0.49043533205986023, train/wer=0.173970, validation/ctc_loss=0.8383359313011169, validation/num_examples=5348, validation/wer=0.247258
I1004 02:40:42.945616 140266596701952 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.6454315185546875, loss=1.787552833557129
I1004 02:47:21.419049 140266605094656 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.8663202524185181, loss=1.7470275163650513
I1004 02:53:59.278128 140265985574656 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.640847384929657, loss=1.7937934398651123
I1004 03:00:45.918824 140265977181952 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.6446368098258972, loss=1.8104918003082275
I1004 03:03:55.709805 140439319918400 spec.py:321] Evaluating on the training split.
I1004 03:04:47.717719 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 03:05:35.952410 140439319918400 spec.py:349] Evaluating on the test split.
I1004 03:06:00.145130 140439319918400 submission_runner.py:381] Time since start: 6498.44s, 	Step: 7225, 	{'train/ctc_loss': Array(0.46202254, dtype=float32), 'train/wer': 0.16068342950496917, 'validation/ctc_loss': Array(0.77811944, dtype=float32), 'validation/wer': 0.22934133469690976, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.50803596, dtype=float32), 'test/wer': 0.16759084353990208, 'test/num_examples': 2472, 'score': 5837.2188131809235, 'total_duration': 6498.44083237648, 'accumulated_submission_time': 5837.2188131809235, 'accumulated_eval_time': 660.8961136341095, 'accumulated_logging_time': 0.19434285163879395}
I1004 03:06:00.187037 140266605094656 logging_writer.py:48] [7225] accumulated_eval_time=660.896114, accumulated_logging_time=0.194343, accumulated_submission_time=5837.218813, global_step=7225, preemption_count=0, score=5837.218813, test/ctc_loss=0.5080359578132629, test/num_examples=2472, test/wer=0.167591, total_duration=6498.440832, train/ctc_loss=0.4620225429534912, train/wer=0.160683, validation/ctc_loss=0.7781194448471069, validation/num_examples=5348, validation/wer=0.229341
I1004 03:09:29.675454 140266596701952 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.6720422506332397, loss=1.7101027965545654
I1004 03:16:05.990063 140266605094656 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.6420648097991943, loss=1.8202638626098633
I1004 03:22:48.224686 140266605094656 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.6996785402297974, loss=1.7983949184417725
I1004 03:29:30.175406 140266596701952 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.9872446060180664, loss=1.7398370504379272
I1004 03:30:00.360313 140439319918400 spec.py:321] Evaluating on the training split.
I1004 03:30:51.726701 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 03:31:40.206790 140439319918400 spec.py:349] Evaluating on the test split.
I1004 03:32:05.151476 140439319918400 submission_runner.py:381] Time since start: 8063.45s, 	Step: 9037, 	{'train/ctc_loss': Array(0.45497754, dtype=float32), 'train/wer': 0.15755398029963688, 'validation/ctc_loss': Array(0.7485645, dtype=float32), 'validation/wer': 0.22010824995899622, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.50134647, dtype=float32), 'test/wer': 0.16523470030264253, 'test/num_examples': 2472, 'score': 7277.350239515305, 'total_duration': 8063.447151422501, 'accumulated_submission_time': 7277.350239515305, 'accumulated_eval_time': 785.6813886165619, 'accumulated_logging_time': 0.24946308135986328}
I1004 03:32:05.185345 140266605094656 logging_writer.py:48] [9037] accumulated_eval_time=785.681389, accumulated_logging_time=0.249463, accumulated_submission_time=7277.350240, global_step=9037, preemption_count=0, score=7277.350240, test/ctc_loss=0.5013464689254761, test/num_examples=2472, test/wer=0.165235, total_duration=8063.447151, train/ctc_loss=0.45497754216194153, train/wer=0.157554, validation/ctc_loss=0.7485644817352295, validation/num_examples=5348, validation/wer=0.220108
I1004 03:37:59.394595 140266605094656 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.7120446562767029, loss=1.7174381017684937
I1004 03:44:46.987192 140266596701952 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.8471445441246033, loss=1.6706396341323853
I1004 03:51:39.379851 140265330214656 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.9684224128723145, loss=1.7532267570495605
I1004 03:56:05.813847 140439319918400 spec.py:321] Evaluating on the training split.
I1004 03:56:57.478150 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 03:57:45.997689 140439319918400 spec.py:349] Evaluating on the test split.
I1004 03:58:10.623382 140439319918400 submission_runner.py:381] Time since start: 9628.92s, 	Step: 10834, 	{'train/ctc_loss': Array(0.4864511, dtype=float32), 'train/wer': 0.168785442595665, 'validation/ctc_loss': Array(0.76815295, dtype=float32), 'validation/wer': 0.22873351407152986, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.49692217, dtype=float32), 'test/wer': 0.16553937399711577, 'test/num_examples': 2472, 'score': 8717.935256958008, 'total_duration': 9628.919127464294, 'accumulated_submission_time': 8717.935256958008, 'accumulated_eval_time': 910.4851367473602, 'accumulated_logging_time': 0.2971150875091553}
I1004 03:58:10.655690 140265330214656 logging_writer.py:48] [10834] accumulated_eval_time=910.485137, accumulated_logging_time=0.297115, accumulated_submission_time=8717.935257, global_step=10834, preemption_count=0, score=8717.935257, test/ctc_loss=0.49692216515541077, test/num_examples=2472, test/wer=0.165539, total_duration=9628.919127, train/ctc_loss=0.48645108938217163, train/wer=0.168785, validation/ctc_loss=0.7681529521942139, validation/num_examples=5348, validation/wer=0.228734
I1004 04:00:16.930833 140265321821952 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.6716176271438599, loss=1.7013884782791138
I1004 04:06:57.291657 140265330214656 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.8406624794006348, loss=1.7096095085144043
I1004 04:13:41.989174 140265321821952 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.9389395117759705, loss=1.6930389404296875
I1004 04:20:47.716240 140265330214656 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.8967486023902893, loss=1.6943436861038208
I1004 04:22:10.724982 140439319918400 spec.py:321] Evaluating on the training split.
I1004 04:23:02.695471 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 04:23:52.478796 140439319918400 spec.py:349] Evaluating on the test split.
I1004 04:24:17.754681 140439319918400 submission_runner.py:381] Time since start: 11196.05s, 	Step: 12611, 	{'train/ctc_loss': Array(0.4464734, dtype=float32), 'train/wer': 0.15742985982600557, 'validation/ctc_loss': Array(0.7385711, dtype=float32), 'validation/wer': 0.22081255004872213, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.47573552, dtype=float32), 'test/wer': 0.15889748745759957, 'test/num_examples': 2472, 'score': 10157.961879253387, 'total_duration': 11196.050883769989, 'accumulated_submission_time': 10157.961879253387, 'accumulated_eval_time': 1037.5094816684723, 'accumulated_logging_time': 0.3439316749572754}
I1004 04:24:17.787406 140266175014656 logging_writer.py:48] [12611] accumulated_eval_time=1037.509482, accumulated_logging_time=0.343932, accumulated_submission_time=10157.961879, global_step=12611, preemption_count=0, score=10157.961879, test/ctc_loss=0.47573551535606384, test/num_examples=2472, test/wer=0.158897, total_duration=11196.050884, train/ctc_loss=0.4464733898639679, train/wer=0.157430, validation/ctc_loss=0.7385711073875427, validation/num_examples=5348, validation/wer=0.220813
I1004 04:29:20.366886 140266166621952 logging_writer.py:48] [13000] global_step=13000, grad_norm=1.5705814361572266, loss=1.7285947799682617
I1004 04:36:22.865209 140266175014656 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.9456501603126526, loss=1.6365106105804443
I1004 04:42:58.658776 140266166621952 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.8129532337188721, loss=1.6378095149993896
I1004 04:48:17.786299 140439319918400 spec.py:321] Evaluating on the training split.
I1004 04:49:10.860784 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 04:50:00.854184 140439319918400 spec.py:349] Evaluating on the test split.
I1004 04:50:25.680602 140439319918400 submission_runner.py:381] Time since start: 12763.98s, 	Step: 14375, 	{'train/ctc_loss': Array(0.423981, dtype=float32), 'train/wer': 0.15203203411425154, 'validation/ctc_loss': Array(0.7461639, dtype=float32), 'validation/wer': 0.22219220638887013, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.4849085, dtype=float32), 'test/wer': 0.16312229602096154, 'test/num_examples': 2472, 'score': 11597.919181585312, 'total_duration': 12763.976046800613, 'accumulated_submission_time': 11597.919181585312, 'accumulated_eval_time': 1165.3976945877075, 'accumulated_logging_time': 0.38990259170532227}
I1004 04:50:25.719300 140266175014656 logging_writer.py:48] [14375] accumulated_eval_time=1165.397695, accumulated_logging_time=0.389903, accumulated_submission_time=11597.919182, global_step=14375, preemption_count=0, score=11597.919182, test/ctc_loss=0.48490849137306213, test/num_examples=2472, test/wer=0.163122, total_duration=12763.976047, train/ctc_loss=0.4239810109138489, train/wer=0.152032, validation/ctc_loss=0.7461639046669006, validation/num_examples=5348, validation/wer=0.222192
I1004 04:52:04.487404 140265555494656 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.8745011687278748, loss=1.6807606220245361
I1004 04:58:42.732198 140265547101952 logging_writer.py:48] [15000] global_step=15000, grad_norm=1.2291209697723389, loss=1.7008960247039795
I1004 05:05:53.214100 140265555494656 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.7139877676963806, loss=1.674770712852478
I1004 05:12:26.692745 140265547101952 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.8608378171920776, loss=1.6430950164794922
I1004 05:14:26.175632 140439319918400 spec.py:321] Evaluating on the training split.
I1004 05:15:18.301988 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 05:16:07.317959 140439319918400 spec.py:349] Evaluating on the test split.
I1004 05:16:32.172146 140439319918400 submission_runner.py:381] Time since start: 14330.47s, 	Step: 16142, 	{'train/ctc_loss': Array(0.38078287, dtype=float32), 'train/wer': 0.13283041352563454, 'validation/ctc_loss': Array(0.701938, dtype=float32), 'validation/wer': 0.20639851807542764, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.4447674, dtype=float32), 'test/wer': 0.14754331444356428, 'test/num_examples': 2472, 'score': 13038.33169579506, 'total_duration': 14330.466711997986, 'accumulated_submission_time': 13038.33169579506, 'accumulated_eval_time': 1291.3872356414795, 'accumulated_logging_time': 0.4437692165374756}
I1004 05:16:32.208144 140266605094656 logging_writer.py:48] [16142] accumulated_eval_time=1291.387236, accumulated_logging_time=0.443769, accumulated_submission_time=13038.331696, global_step=16142, preemption_count=0, score=13038.331696, test/ctc_loss=0.44476738572120667, test/num_examples=2472, test/wer=0.147543, total_duration=14330.466712, train/ctc_loss=0.3807828724384308, train/wer=0.132830, validation/ctc_loss=0.7019379734992981, validation/num_examples=5348, validation/wer=0.206399
I1004 05:21:16.556166 140266605094656 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.8002614378929138, loss=1.6542060375213623
I1004 05:27:49.142536 140266596701952 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.8592579960823059, loss=1.7604931592941284
I1004 05:35:03.848506 140266605094656 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.6899144649505615, loss=1.7181894779205322
I1004 05:40:32.518752 140439319918400 spec.py:321] Evaluating on the training split.
I1004 05:41:24.674435 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 05:42:13.484871 140439319918400 spec.py:349] Evaluating on the test split.
I1004 05:42:38.162947 140439319918400 submission_runner.py:381] Time since start: 15896.46s, 	Step: 17930, 	{'train/ctc_loss': Array(0.38881645, dtype=float32), 'train/wer': 0.13868941957558173, 'validation/ctc_loss': Array(0.6963872, dtype=float32), 'validation/wer': 0.206195911200301, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.44702426, dtype=float32), 'test/wer': 0.14904637133629883, 'test/num_examples': 2472, 'score': 14478.592161655426, 'total_duration': 15896.458851337433, 'accumulated_submission_time': 14478.592161655426, 'accumulated_eval_time': 1417.025891304016, 'accumulated_logging_time': 0.5001053810119629}
I1004 05:42:38.205856 140265519654656 logging_writer.py:48] [17930] accumulated_eval_time=1417.025891, accumulated_logging_time=0.500105, accumulated_submission_time=14478.592162, global_step=17930, preemption_count=0, score=14478.592162, test/ctc_loss=0.44702425599098206, test/num_examples=2472, test/wer=0.149046, total_duration=15896.458851, train/ctc_loss=0.3888164460659027, train/wer=0.138689, validation/ctc_loss=0.6963871717453003, validation/num_examples=5348, validation/wer=0.206196
I1004 05:43:31.820760 140265511261952 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.634154736995697, loss=1.6291027069091797
I1004 05:50:29.986937 140265519654656 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.749742865562439, loss=1.6743502616882324
I1004 05:57:00.757722 140265519654656 logging_writer.py:48] [19000] global_step=19000, grad_norm=1.2436082363128662, loss=1.6536941528320312
I1004 06:04:16.455286 140265511261952 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.6770285367965698, loss=1.6580333709716797
I1004 06:06:38.650511 140439319918400 spec.py:321] Evaluating on the training split.
I1004 06:07:31.153591 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 06:08:21.712602 140439319918400 spec.py:349] Evaluating on the test split.
I1004 06:08:46.651934 140439319918400 submission_runner.py:381] Time since start: 17464.95s, 	Step: 19675, 	{'train/ctc_loss': Array(0.3790502, dtype=float32), 'train/wer': 0.13150532800973055, 'validation/ctc_loss': Array(0.66619724, dtype=float32), 'validation/wer': 0.19507182896120562, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.41767335, dtype=float32), 'test/wer': 0.13956086364836592, 'test/num_examples': 2472, 'score': 15918.993396997452, 'total_duration': 17464.947844028473, 'accumulated_submission_time': 15918.993396997452, 'accumulated_eval_time': 1545.021859884262, 'accumulated_logging_time': 0.5574085712432861}
I1004 06:08:46.686621 140265519654656 logging_writer.py:48] [19675] accumulated_eval_time=1545.021860, accumulated_logging_time=0.557409, accumulated_submission_time=15918.993397, global_step=19675, preemption_count=0, score=15918.993397, test/ctc_loss=0.41767334938049316, test/num_examples=2472, test/wer=0.139561, total_duration=17464.947844, train/ctc_loss=0.37905019521713257, train/wer=0.131505, validation/ctc_loss=0.6661972403526306, validation/num_examples=5348, validation/wer=0.195072
I1004 06:12:53.859664 140265511261952 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.7756346464157104, loss=1.5718200206756592
I1004 06:19:59.051975 140265519654656 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.8576313853263855, loss=1.6373275518417358
I1004 06:26:33.015934 140265519654656 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.763393759727478, loss=1.5794181823730469
I1004 06:32:47.177525 140439319918400 spec.py:321] Evaluating on the training split.
I1004 06:33:39.829519 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 06:34:29.835453 140439319918400 spec.py:349] Evaluating on the test split.
I1004 06:34:54.589533 140439319918400 submission_runner.py:381] Time since start: 19032.88s, 	Step: 21427, 	{'train/ctc_loss': Array(0.39123425, dtype=float32), 'train/wer': 0.13665022291397366, 'validation/ctc_loss': Array(0.674069, dtype=float32), 'validation/wer': 0.19815917182027806, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.41924185, dtype=float32), 'test/wer': 0.14104360896146895, 'test/num_examples': 2472, 'score': 17359.441693544388, 'total_duration': 19032.884077072144, 'accumulated_submission_time': 17359.441693544388, 'accumulated_eval_time': 1672.4268674850464, 'accumulated_logging_time': 0.6066875457763672}
I1004 06:34:54.627204 140265883174656 logging_writer.py:48] [21427] accumulated_eval_time=1672.426867, accumulated_logging_time=0.606688, accumulated_submission_time=17359.441694, global_step=21427, preemption_count=0, score=17359.441694, test/ctc_loss=0.41924184560775757, test/num_examples=2472, test/wer=0.141044, total_duration=19032.884077, train/ctc_loss=0.39123424887657166, train/wer=0.136650, validation/ctc_loss=0.6740689873695374, validation/num_examples=5348, validation/wer=0.198159
I1004 06:35:50.655270 140265874781952 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.9965440034866333, loss=1.6086347103118896
I1004 06:42:14.658573 140265883174656 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.635233461856842, loss=1.6470497846603394
I1004 06:49:28.178189 140265874781952 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.7117065787315369, loss=1.5885257720947266
I1004 06:56:10.492762 140265883174656 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.7604351043701172, loss=1.6440825462341309
I1004 06:58:54.942265 140439319918400 spec.py:321] Evaluating on the training split.
I1004 06:59:48.781683 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 07:00:39.681567 140439319918400 spec.py:349] Evaluating on the test split.
I1004 07:01:05.825623 140439319918400 submission_runner.py:381] Time since start: 20604.12s, 	Step: 23198, 	{'train/ctc_loss': Array(0.37585106, dtype=float32), 'train/wer': 0.1322203930445519, 'validation/ctc_loss': Array(0.6593281, dtype=float32), 'validation/wer': 0.1934702698530618, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.40895495, dtype=float32), 'test/wer': 0.13720472041110637, 'test/num_examples': 2472, 'score': 18799.712696313858, 'total_duration': 20604.11959052086, 'accumulated_submission_time': 18799.712696313858, 'accumulated_eval_time': 1803.3026480674744, 'accumulated_logging_time': 0.6593880653381348}
I1004 07:01:05.860807 140265883174656 logging_writer.py:48] [23198] accumulated_eval_time=1803.302648, accumulated_logging_time=0.659388, accumulated_submission_time=18799.712696, global_step=23198, preemption_count=0, score=18799.712696, test/ctc_loss=0.4089549481868744, test/num_examples=2472, test/wer=0.137205, total_duration=20604.119591, train/ctc_loss=0.3758510649204254, train/wer=0.132220, validation/ctc_loss=0.6593281030654907, validation/num_examples=5348, validation/wer=0.193470
I1004 07:05:01.799118 140265874781952 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.7897204160690308, loss=1.571509838104248
I1004 07:11:43.781115 140265883174656 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.8978404402732849, loss=1.5545507669448853
I1004 07:18:50.363991 140265874781952 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.8228836059570312, loss=1.5846096277236938
I1004 07:25:06.126286 140439319918400 spec.py:321] Evaluating on the training split.
I1004 07:25:59.347697 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 07:26:49.097464 140439319918400 spec.py:349] Evaluating on the test split.
I1004 07:27:14.160679 140439319918400 submission_runner.py:381] Time since start: 22172.46s, 	Step: 24963, 	{'train/ctc_loss': Array(0.3455431, dtype=float32), 'train/wer': 0.12042882479625015, 'validation/ctc_loss': Array(0.634761, dtype=float32), 'validation/wer': 0.18502831672278555, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.39881578, dtype=float32), 'test/wer': 0.13174090549021997, 'test/num_examples': 2472, 'score': 20239.93368458748, 'total_duration': 22172.456852912903, 'accumulated_submission_time': 20239.93368458748, 'accumulated_eval_time': 1931.3317387104034, 'accumulated_logging_time': 0.7098081111907959}
I1004 07:27:14.201038 140266313254656 logging_writer.py:48] [24963] accumulated_eval_time=1931.331739, accumulated_logging_time=0.709808, accumulated_submission_time=20239.933685, global_step=24963, preemption_count=0, score=20239.933685, test/ctc_loss=0.398815780878067, test/num_examples=2472, test/wer=0.131741, total_duration=22172.456853, train/ctc_loss=0.3455430865287781, train/wer=0.120429, validation/ctc_loss=0.6347609758377075, validation/num_examples=5348, validation/wer=0.185028
I1004 07:27:42.898699 140266304861952 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.8735917806625366, loss=1.529176950454712
I1004 07:34:27.501675 140266313254656 logging_writer.py:48] [25500] global_step=25500, grad_norm=1.210979700088501, loss=1.554255723953247
I1004 07:41:19.261302 140266313254656 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.7750595808029175, loss=1.5292809009552002
I1004 07:48:13.340664 140266304861952 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.9503647685050964, loss=1.5598087310791016
I1004 07:51:14.679453 140439319918400 spec.py:321] Evaluating on the training split.
I1004 07:52:08.209446 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 07:52:58.026943 140439319918400 spec.py:349] Evaluating on the test split.
I1004 07:53:23.017378 140439319918400 submission_runner.py:381] Time since start: 23741.31s, 	Step: 26710, 	{'train/ctc_loss': Array(0.31516305, dtype=float32), 'train/wer': 0.1125955293565299, 'validation/ctc_loss': Array(0.5985893, dtype=float32), 'validation/wer': 0.17722312805719304, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.37163034, dtype=float32), 'test/wer': 0.12467247577844129, 'test/num_examples': 2472, 'score': 21680.36767578125, 'total_duration': 23741.31293654442, 'accumulated_submission_time': 21680.36767578125, 'accumulated_eval_time': 2059.6636905670166, 'accumulated_logging_time': 0.7654232978820801}
I1004 07:53:23.051456 140266390054656 logging_writer.py:48] [26710] accumulated_eval_time=2059.663691, accumulated_logging_time=0.765423, accumulated_submission_time=21680.367676, global_step=26710, preemption_count=0, score=21680.367676, test/ctc_loss=0.37163034081459045, test/num_examples=2472, test/wer=0.124672, total_duration=23741.312937, train/ctc_loss=0.3151630461215973, train/wer=0.112596, validation/ctc_loss=0.598589301109314, validation/num_examples=5348, validation/wer=0.177223
I1004 07:57:06.879228 140266390054656 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.984637439250946, loss=1.5163307189941406
I1004 08:04:08.352041 140266381661952 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.8625352382659912, loss=1.5543015003204346
I1004 08:11:08.380456 140266390054656 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.6186507344245911, loss=1.455612301826477
I1004 08:17:23.394119 140439319918400 spec.py:321] Evaluating on the training split.
I1004 08:18:16.685471 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 08:19:07.127522 140439319918400 spec.py:349] Evaluating on the test split.
I1004 08:19:32.607624 140439319918400 submission_runner.py:381] Time since start: 25310.90s, 	Step: 28456, 	{'train/ctc_loss': Array(0.2942566, dtype=float32), 'train/wer': 0.10323613341379345, 'validation/ctc_loss': Array(0.5838246, dtype=float32), 'validation/wer': 0.1707686518924447, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.35414937, dtype=float32), 'test/wer': 0.1167915828814007, 'test/num_examples': 2472, 'score': 23120.666944503784, 'total_duration': 25310.901830673218, 'accumulated_submission_time': 23120.666944503784, 'accumulated_eval_time': 2188.8698608875275, 'accumulated_logging_time': 0.814436674118042}
I1004 08:19:32.652776 140266098214656 logging_writer.py:48] [28456] accumulated_eval_time=2188.869861, accumulated_logging_time=0.814437, accumulated_submission_time=23120.666945, global_step=28456, preemption_count=0, score=23120.666945, test/ctc_loss=0.35414937138557434, test/num_examples=2472, test/wer=0.116792, total_duration=25310.901831, train/ctc_loss=0.2942565977573395, train/wer=0.103236, validation/ctc_loss=0.5838245749473572, validation/num_examples=5348, validation/wer=0.170769
I1004 08:20:06.641923 140266089821952 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.9400855302810669, loss=1.5260469913482666
I1004 08:26:41.638206 140266098214656 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.8302022218704224, loss=1.4636465311050415
I1004 08:33:42.148182 140266089821952 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.7826782464981079, loss=1.490964651107788
I1004 08:40:49.298456 140265442854656 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.86739581823349, loss=1.532546877861023
I1004 08:43:32.621389 140439319918400 spec.py:321] Evaluating on the training split.
I1004 08:44:24.790332 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 08:45:14.139363 140439319918400 spec.py:349] Evaluating on the test split.
I1004 08:45:40.733921 140439319918400 submission_runner.py:381] Time since start: 26879.03s, 	Step: 30217, 	{'train/ctc_loss': Array(0.3031742, dtype=float32), 'train/wer': 0.10695636158779684, 'validation/ctc_loss': Array(0.5573894, dtype=float32), 'validation/wer': 0.16575171974645198, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.341485, dtype=float32), 'test/wer': 0.11498385229419292, 'test/num_examples': 2472, 'score': 24560.585616350174, 'total_duration': 26879.02878499031, 'accumulated_submission_time': 24560.585616350174, 'accumulated_eval_time': 2316.9757130146027, 'accumulated_logging_time': 0.8803038597106934}
I1004 08:45:40.771591 140266605094656 logging_writer.py:48] [30217] accumulated_eval_time=2316.975713, accumulated_logging_time=0.880304, accumulated_submission_time=24560.585616, global_step=30217, preemption_count=0, score=24560.585616, test/ctc_loss=0.34148499369621277, test/num_examples=2472, test/wer=0.114984, total_duration=26879.028785, train/ctc_loss=0.3031741976737976, train/wer=0.106956, validation/ctc_loss=0.5573893785476685, validation/num_examples=5348, validation/wer=0.165752
I1004 08:49:19.937295 140266596701952 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.8139647841453552, loss=1.4635365009307861
I1004 08:56:27.724311 140265442854656 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.6813805103302002, loss=1.4513752460479736
I1004 09:03:12.769997 140265434461952 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.9170618653297424, loss=1.3905991315841675
I1004 09:09:41.352342 140439319918400 spec.py:321] Evaluating on the training split.
I1004 09:10:33.110501 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 09:11:24.010402 140439319918400 spec.py:349] Evaluating on the test split.
I1004 09:11:49.019876 140439319918400 submission_runner.py:381] Time since start: 28447.32s, 	Step: 31944, 	{'train/ctc_loss': Array(0.2831307, dtype=float32), 'train/wer': 0.09695657599878459, 'validation/ctc_loss': Array(0.5510053, dtype=float32), 'validation/wer': 0.16162239867244257, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.3258699, dtype=float32), 'test/wer': 0.10698108991936303, 'test/num_examples': 2472, 'score': 26001.12089252472, 'total_duration': 28447.315212726593, 'accumulated_submission_time': 26001.12089252472, 'accumulated_eval_time': 2444.637258052826, 'accumulated_logging_time': 0.934779167175293}
I1004 09:11:49.054474 140265519654656 logging_writer.py:48] [31944] accumulated_eval_time=2444.637258, accumulated_logging_time=0.934779, accumulated_submission_time=26001.120893, global_step=31944, preemption_count=0, score=26001.120893, test/ctc_loss=0.3258698880672455, test/num_examples=2472, test/wer=0.106981, total_duration=28447.315213, train/ctc_loss=0.2831307053565979, train/wer=0.096957, validation/ctc_loss=0.5510053038597107, validation/num_examples=5348, validation/wer=0.161622
I1004 09:12:32.053478 140265511261952 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.7898122668266296, loss=1.3983098268508911
I1004 09:18:59.296400 140265519654656 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.8109117746353149, loss=1.4565147161483765
I1004 09:26:16.614519 140265519654656 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.9752296209335327, loss=1.4210375547409058
I1004 09:32:53.760662 140265511261952 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.7738649249076843, loss=1.4023622274398804
I1004 09:35:49.120525 140439319918400 spec.py:321] Evaluating on the training split.
I1004 09:36:42.730628 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 09:37:32.379866 140439319918400 spec.py:349] Evaluating on the test split.
I1004 09:37:57.851936 140439319918400 submission_runner.py:381] Time since start: 30016.15s, 	Step: 33700, 	{'train/ctc_loss': Array(0.27834785, dtype=float32), 'train/wer': 0.09709301429606151, 'validation/ctc_loss': Array(0.52099866, dtype=float32), 'validation/wer': 0.15428031143571092, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.3104823, dtype=float32), 'test/wer': 0.10503117827473443, 'test/num_examples': 2472, 'score': 27441.136357545853, 'total_duration': 30016.147325992584, 'accumulated_submission_time': 27441.136357545853, 'accumulated_eval_time': 2573.3625144958496, 'accumulated_logging_time': 0.9903042316436768}
I1004 09:37:57.885218 140265949734656 logging_writer.py:48] [33700] accumulated_eval_time=2573.362514, accumulated_logging_time=0.990304, accumulated_submission_time=27441.136358, global_step=33700, preemption_count=0, score=27441.136358, test/ctc_loss=0.31048229336738586, test/num_examples=2472, test/wer=0.105031, total_duration=30016.147326, train/ctc_loss=0.27834784984588623, train/wer=0.097093, validation/ctc_loss=0.5209986567497253, validation/num_examples=5348, validation/wer=0.154280
I1004 09:41:52.782851 140266605094656 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.8887006044387817, loss=1.39755117893219
I1004 09:48:27.135505 140266596701952 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.6909047365188599, loss=1.3604767322540283
I1004 09:55:50.016985 140266605094656 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.8510668277740479, loss=1.3784748315811157
I1004 10:01:58.037910 140439319918400 spec.py:321] Evaluating on the training split.
I1004 10:02:51.885895 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 10:03:41.798763 140439319918400 spec.py:349] Evaluating on the test split.
I1004 10:04:07.654491 140439319918400 submission_runner.py:381] Time since start: 31585.95s, 	Step: 35470, 	{'train/ctc_loss': Array(0.27073327, dtype=float32), 'train/wer': 0.09125398297047008, 'validation/ctc_loss': Array(0.50969666, dtype=float32), 'validation/wer': 0.14986155196866346, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.30261588, dtype=float32), 'test/wer': 0.10153758657810819, 'test/num_examples': 2472, 'score': 28881.243389606476, 'total_duration': 31585.95036506653, 'accumulated_submission_time': 28881.243389606476, 'accumulated_eval_time': 2702.9735271930695, 'accumulated_logging_time': 1.038757562637329}
I1004 10:04:07.695005 140265949734656 logging_writer.py:48] [35470] accumulated_eval_time=2702.973527, accumulated_logging_time=1.038758, accumulated_submission_time=28881.243390, global_step=35470, preemption_count=0, score=28881.243390, test/ctc_loss=0.3026158809661865, test/num_examples=2472, test/wer=0.101538, total_duration=31585.950365, train/ctc_loss=0.2707332670688629, train/wer=0.091254, validation/ctc_loss=0.5096966624259949, validation/num_examples=5348, validation/wer=0.149862
I1004 10:04:31.181484 140265941341952 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.8662094473838806, loss=1.3206970691680908
I1004 10:11:30.138560 140265949734656 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.7664552330970764, loss=1.3499730825424194
I1004 10:18:11.039049 140266605094656 logging_writer.py:48] [36500] global_step=36500, grad_norm=0.7782258987426758, loss=1.3612171411514282
I1004 10:25:35.945349 140266596701952 logging_writer.py:48] [37000] global_step=37000, grad_norm=0.9511268138885498, loss=1.4175883531570435
I1004 10:28:08.392457 140439319918400 spec.py:321] Evaluating on the training split.
I1004 10:29:01.964640 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 10:29:51.887357 140439319918400 spec.py:349] Evaluating on the test split.
I1004 10:30:17.414387 140439319918400 submission_runner.py:381] Time since start: 33155.71s, 	Step: 37184, 	{'train/ctc_loss': Array(0.20574616, dtype=float32), 'train/wer': 0.07377796910714103, 'validation/ctc_loss': Array(0.4880934, dtype=float32), 'validation/wer': 0.14304045383940028, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.28866056, dtype=float32), 'test/wer': 0.09611439481648487, 'test/num_examples': 2472, 'score': 30321.89643239975, 'total_duration': 33155.71012830734, 'accumulated_submission_time': 30321.89643239975, 'accumulated_eval_time': 2831.9898529052734, 'accumulated_logging_time': 1.09462308883667}
I1004 10:30:17.456416 140265949734656 logging_writer.py:48] [37184] accumulated_eval_time=2831.989853, accumulated_logging_time=1.094623, accumulated_submission_time=30321.896432, global_step=37184, preemption_count=0, score=30321.896432, test/ctc_loss=0.28866055607795715, test/num_examples=2472, test/wer=0.096114, total_duration=33155.710128, train/ctc_loss=0.20574615895748138, train/wer=0.073778, validation/ctc_loss=0.48809340596199036, validation/num_examples=5348, validation/wer=0.143040
I1004 10:34:17.436929 140265941341952 logging_writer.py:48] [37500] global_step=37500, grad_norm=0.865863025188446, loss=1.3438167572021484
I1004 10:41:31.493222 140265949734656 logging_writer.py:48] [38000] global_step=38000, grad_norm=0.8034151792526245, loss=1.3016637563705444
I1004 10:48:09.449546 140265949734656 logging_writer.py:48] [38500] global_step=38500, grad_norm=1.0775399208068848, loss=1.348497748374939
I1004 10:54:17.944688 140439319918400 spec.py:321] Evaluating on the training split.
I1004 10:55:11.109102 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 10:56:01.493880 140439319918400 spec.py:349] Evaluating on the test split.
I1004 10:56:26.598065 140439319918400 submission_runner.py:381] Time since start: 34724.89s, 	Step: 38921, 	{'train/ctc_loss': Array(0.22578067, dtype=float32), 'train/wer': 0.08017254123460962, 'validation/ctc_loss': Array(0.47240302, dtype=float32), 'validation/wer': 0.1403969165163195, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.2732842, dtype=float32), 'test/wer': 0.0928645420754372, 'test/num_examples': 2472, 'score': 31762.3391726017, 'total_duration': 34724.89362120628, 'accumulated_submission_time': 31762.3391726017, 'accumulated_eval_time': 2960.637261867523, 'accumulated_logging_time': 1.1521766185760498}
I1004 10:56:26.640189 140266021414656 logging_writer.py:48] [38921] accumulated_eval_time=2960.637262, accumulated_logging_time=1.152177, accumulated_submission_time=31762.339173, global_step=38921, preemption_count=0, score=31762.339173, test/ctc_loss=0.2732841968536377, test/num_examples=2472, test/wer=0.092865, total_duration=34724.893621, train/ctc_loss=0.2257806658744812, train/wer=0.080173, validation/ctc_loss=0.47240301966667175, validation/num_examples=5348, validation/wer=0.140397
I1004 10:57:27.280509 140266013021952 logging_writer.py:48] [39000] global_step=39000, grad_norm=0.8946783542633057, loss=1.255136489868164
I1004 11:03:52.865152 140266021414656 logging_writer.py:48] [39500] global_step=39500, grad_norm=0.8341097235679626, loss=1.3059968948364258
I1004 11:11:12.364047 140266013021952 logging_writer.py:48] [40000] global_step=40000, grad_norm=0.8250041604042053, loss=1.3164432048797607
I1004 11:17:58.018662 140266021414656 logging_writer.py:48] [40500] global_step=40500, grad_norm=1.0486971139907837, loss=1.2507139444351196
I1004 11:20:26.698185 140439319918400 spec.py:321] Evaluating on the training split.
I1004 11:21:19.298683 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 11:22:09.825979 140439319918400 spec.py:349] Evaluating on the test split.
I1004 11:22:35.500830 140439319918400 submission_runner.py:381] Time since start: 36293.80s, 	Step: 40676, 	{'train/ctc_loss': Array(0.26900163, dtype=float32), 'train/wer': 0.09557232199519426, 'validation/ctc_loss': Array(0.44807506, dtype=float32), 'validation/wer': 0.1335179307084487, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.26067665, dtype=float32), 'test/wer': 0.08870066825096988, 'test/num_examples': 2472, 'score': 33202.350559711456, 'total_duration': 36293.79698777199, 'accumulated_submission_time': 33202.350559711456, 'accumulated_eval_time': 3089.434543609619, 'accumulated_logging_time': 1.2108683586120605}
I1004 11:22:35.533444 140266021414656 logging_writer.py:48] [40676] accumulated_eval_time=3089.434544, accumulated_logging_time=1.210868, accumulated_submission_time=33202.350560, global_step=40676, preemption_count=0, score=33202.350560, test/ctc_loss=0.26067665219306946, test/num_examples=2472, test/wer=0.088701, total_duration=36293.796988, train/ctc_loss=0.26900163292884827, train/wer=0.095572, validation/ctc_loss=0.4480750560760498, validation/num_examples=5348, validation/wer=0.133518
I1004 11:26:52.269155 140266013021952 logging_writer.py:48] [41000] global_step=41000, grad_norm=0.9487407207489014, loss=1.2491623163223267
I1004 11:33:44.475822 140266021414656 logging_writer.py:48] [41500] global_step=41500, grad_norm=0.8124244809150696, loss=1.2305197715759277
I1004 11:40:58.064591 140266013021952 logging_writer.py:48] [42000] global_step=42000, grad_norm=1.18796706199646, loss=1.25912344455719
I1004 11:46:36.221786 140439319918400 spec.py:321] Evaluating on the training split.
I1004 11:47:27.540240 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 11:48:18.009602 140439319918400 spec.py:349] Evaluating on the test split.
I1004 11:48:44.076271 140439319918400 submission_runner.py:381] Time since start: 37862.37s, 	Step: 42405, 	{'train/ctc_loss': Array(0.2662538, dtype=float32), 'train/wer': 0.09314022105397558, 'validation/ctc_loss': Array(0.43428874, dtype=float32), 'validation/wer': 0.1272564134723924, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.24629119, dtype=float32), 'test/wer': 0.08376495440050373, 'test/num_examples': 2472, 'score': 34642.995950460434, 'total_duration': 37862.372670173645, 'accumulated_submission_time': 34642.995950460434, 'accumulated_eval_time': 3217.2839591503143, 'accumulated_logging_time': 1.2571029663085938}
I1004 11:48:44.117839 140266175014656 logging_writer.py:48] [42405] accumulated_eval_time=3217.283959, accumulated_logging_time=1.257103, accumulated_submission_time=34642.995950, global_step=42405, preemption_count=0, score=34642.995950, test/ctc_loss=0.24629119038581848, test/num_examples=2472, test/wer=0.083765, total_duration=37862.372670, train/ctc_loss=0.266253799200058, train/wer=0.093140, validation/ctc_loss=0.43428874015808105, validation/num_examples=5348, validation/wer=0.127256
I1004 11:49:56.664726 140266166621952 logging_writer.py:48] [42500] global_step=42500, grad_norm=0.8312158584594727, loss=1.2109193801879883
I1004 11:56:47.936209 140266175014656 logging_writer.py:48] [43000] global_step=43000, grad_norm=1.4453980922698975, loss=1.2225782871246338
I1004 12:03:44.203030 140266175014656 logging_writer.py:48] [43500] global_step=43500, grad_norm=0.9833350777626038, loss=1.2861257791519165
I1004 12:10:54.582912 140266166621952 logging_writer.py:48] [44000] global_step=44000, grad_norm=0.8517322540283203, loss=1.210111379623413
I1004 12:12:44.104399 140439319918400 spec.py:321] Evaluating on the training split.
I1004 12:13:34.713348 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 12:14:25.275942 140439319918400 spec.py:349] Evaluating on the test split.
I1004 12:14:51.294020 140439319918400 submission_runner.py:381] Time since start: 39429.59s, 	Step: 44123, 	{'train/ctc_loss': Array(0.28787172, dtype=float32), 'train/wer': 0.10207018385385286, 'validation/ctc_loss': Array(0.40810177, dtype=float32), 'validation/wer': 0.12124574284363573, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.23438783, dtype=float32), 'test/wer': 0.07645278573314647, 'test/num_examples': 2472, 'score': 36082.93872523308, 'total_duration': 39429.58925819397, 'accumulated_submission_time': 36082.93872523308, 'accumulated_eval_time': 3344.4672725200653, 'accumulated_logging_time': 1.3135323524475098}
I1004 12:14:51.328903 140266175014656 logging_writer.py:48] [44123] accumulated_eval_time=3344.467273, accumulated_logging_time=1.313532, accumulated_submission_time=36082.938725, global_step=44123, preemption_count=0, score=36082.938725, test/ctc_loss=0.2343878298997879, test/num_examples=2472, test/wer=0.076453, total_duration=39429.589258, train/ctc_loss=0.28787171840667725, train/wer=0.102070, validation/ctc_loss=0.40810176730155945, validation/num_examples=5348, validation/wer=0.121246
I1004 12:19:40.866839 140266175014656 logging_writer.py:48] [44500] global_step=44500, grad_norm=0.854386031627655, loss=1.238224983215332
I1004 12:26:51.619926 140266166621952 logging_writer.py:48] [45000] global_step=45000, grad_norm=1.2392820119857788, loss=1.2342815399169922
I1004 12:33:59.683678 140266175014656 logging_writer.py:48] [45500] global_step=45500, grad_norm=0.829465389251709, loss=1.1990556716918945
I1004 12:38:51.336338 140439319918400 spec.py:321] Evaluating on the training split.
I1004 12:39:41.448383 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 12:40:31.819069 140439319918400 spec.py:349] Evaluating on the test split.
I1004 12:40:57.601654 140439319918400 submission_runner.py:381] Time since start: 40995.90s, 	Step: 45855, 	{'train/ctc_loss': Array(0.24147134, dtype=float32), 'train/wer': 0.08287361126647787, 'validation/ctc_loss': Array(0.39788356, dtype=float32), 'validation/wer': 0.11674979980511148, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.2260457, dtype=float32), 'test/wer': 0.07505128673856966, 'test/num_examples': 2472, 'score': 37522.90286588669, 'total_duration': 40995.897117614746, 'accumulated_submission_time': 37522.90286588669, 'accumulated_eval_time': 3470.726508140564, 'accumulated_logging_time': 1.362656593322754}
I1004 12:40:57.651287 140266605094656 logging_writer.py:48] [45855] accumulated_eval_time=3470.726508, accumulated_logging_time=1.362657, accumulated_submission_time=37522.902866, global_step=45855, preemption_count=0, score=37522.902866, test/ctc_loss=0.22604569792747498, test/num_examples=2472, test/wer=0.075051, total_duration=40995.897118, train/ctc_loss=0.2414713352918625, train/wer=0.082874, validation/ctc_loss=0.3978835642337799, validation/num_examples=5348, validation/wer=0.116750
I1004 12:42:47.948258 140266596701952 logging_writer.py:48] [46000] global_step=46000, grad_norm=1.0025348663330078, loss=1.187966227531433
I1004 12:49:45.645437 140266277414656 logging_writer.py:48] [46500] global_step=46500, grad_norm=0.8489891886711121, loss=1.1609910726547241
I1004 12:56:47.799718 140266269021952 logging_writer.py:48] [47000] global_step=47000, grad_norm=1.4051527976989746, loss=1.1295565366744995
I1004 13:04:02.346087 140266277414656 logging_writer.py:48] [47500] global_step=47500, grad_norm=0.9131507277488708, loss=1.1062755584716797
I1004 13:04:57.654010 140439319918400 spec.py:321] Evaluating on the training split.
I1004 13:05:48.837457 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 13:06:39.494067 140439319918400 spec.py:349] Evaluating on the test split.
I1004 13:07:05.342143 140439319918400 submission_runner.py:381] Time since start: 42563.64s, 	Step: 47574, 	{'train/ctc_loss': Array(0.2142926, dtype=float32), 'train/wer': 0.0779230178259272, 'validation/ctc_loss': Array(0.37880367, dtype=float32), 'validation/wer': 0.1113565977481693, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.21749084, dtype=float32), 'test/wer': 0.07129364450673328, 'test/num_examples': 2472, 'score': 38962.84694170952, 'total_duration': 42563.63844156265, 'accumulated_submission_time': 38962.84694170952, 'accumulated_eval_time': 3598.4093978405, 'accumulated_logging_time': 1.4419493675231934}
I1004 13:07:05.374816 140266021414656 logging_writer.py:48] [47574] accumulated_eval_time=3598.409398, accumulated_logging_time=1.441949, accumulated_submission_time=38962.846942, global_step=47574, preemption_count=0, score=38962.846942, test/ctc_loss=0.21749083697795868, test/num_examples=2472, test/wer=0.071294, total_duration=42563.638442, train/ctc_loss=0.21429260075092316, train/wer=0.077923, validation/ctc_loss=0.37880367040634155, validation/num_examples=5348, validation/wer=0.111357
I1004 13:12:42.749426 140266013021952 logging_writer.py:48] [48000] global_step=48000, grad_norm=0.9720180630683899, loss=1.179006814956665
I1004 13:19:53.842299 140266021414656 logging_writer.py:48] [48500] global_step=48500, grad_norm=1.1976430416107178, loss=1.0983355045318604
I1004 13:26:40.856489 140266013021952 logging_writer.py:48] [49000] global_step=49000, grad_norm=0.9006257653236389, loss=1.1194003820419312
I1004 13:31:05.592346 140439319918400 spec.py:321] Evaluating on the training split.
I1004 13:31:57.971022 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 13:32:48.705435 140439319918400 spec.py:349] Evaluating on the test split.
I1004 13:33:14.583230 140439319918400 submission_runner.py:381] Time since start: 44132.88s, 	Step: 49300, 	{'train/ctc_loss': Array(0.1722954, dtype=float32), 'train/wer': 0.062186646945589404, 'validation/ctc_loss': Array(0.3584863, dtype=float32), 'validation/wer': 0.1050757846192438, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.20170058, dtype=float32), 'test/wer': 0.06733288647858143, 'test/num_examples': 2472, 'score': 40403.02093362808, 'total_duration': 44132.87708950043, 'accumulated_submission_time': 40403.02093362808, 'accumulated_eval_time': 3727.3926265239716, 'accumulated_logging_time': 1.489212989807129}
I1004 13:33:14.623558 140266021414656 logging_writer.py:48] [49300] accumulated_eval_time=3727.392627, accumulated_logging_time=1.489213, accumulated_submission_time=40403.020934, global_step=49300, preemption_count=0, score=40403.020934, test/ctc_loss=0.2017005831003189, test/num_examples=2472, test/wer=0.067333, total_duration=44132.877090, train/ctc_loss=0.17229540646076202, train/wer=0.062187, validation/ctc_loss=0.3584862947463989, validation/num_examples=5348, validation/wer=0.105076
I1004 13:35:50.745333 140266021414656 logging_writer.py:48] [49500] global_step=49500, grad_norm=1.3596343994140625, loss=1.130245566368103
I1004 13:42:39.473025 140266013021952 logging_writer.py:48] [50000] global_step=50000, grad_norm=1.060979962348938, loss=1.1786751747131348
I1004 13:50:02.766803 140266021414656 logging_writer.py:48] [50500] global_step=50500, grad_norm=1.0801984071731567, loss=1.092872977256775
I1004 13:56:45.069263 140266013021952 logging_writer.py:48] [51000] global_step=51000, grad_norm=1.0832431316375732, loss=1.087672233581543
I1004 13:57:14.599494 140439319918400 spec.py:321] Evaluating on the training split.
I1004 13:58:07.027951 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 13:58:58.535303 140439319918400 spec.py:349] Evaluating on the test split.
I1004 13:59:24.445785 140439319918400 submission_runner.py:381] Time since start: 45702.74s, 	Step: 51034, 	{'train/ctc_loss': Array(0.18265964, dtype=float32), 'train/wer': 0.06571008054223444, 'validation/ctc_loss': Array(0.35426068, dtype=float32), 'validation/wer': 0.10270238979633185, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.1948839, dtype=float32), 'test/wer': 0.06398147583937602, 'test/num_examples': 2472, 'score': 41842.95369029045, 'total_duration': 45702.74022102356, 'accumulated_submission_time': 41842.95369029045, 'accumulated_eval_time': 3857.23179769516, 'accumulated_logging_time': 1.5439732074737549}
I1004 13:59:24.490024 140266021414656 logging_writer.py:48] [51034] accumulated_eval_time=3857.231798, accumulated_logging_time=1.543973, accumulated_submission_time=41842.953690, global_step=51034, preemption_count=0, score=41842.953690, test/ctc_loss=0.19488389790058136, test/num_examples=2472, test/wer=0.063981, total_duration=45702.740221, train/ctc_loss=0.18265964090824127, train/wer=0.065710, validation/ctc_loss=0.3542606830596924, validation/num_examples=5348, validation/wer=0.102702
I1004 14:05:52.546331 140266021414656 logging_writer.py:48] [51500] global_step=51500, grad_norm=0.971893310546875, loss=1.057815670967102
I1004 14:12:30.755079 140266013021952 logging_writer.py:48] [52000] global_step=52000, grad_norm=1.064016580581665, loss=1.0728535652160645
I1004 14:19:57.166031 140266021414656 logging_writer.py:48] [52500] global_step=52500, grad_norm=2.1446139812469482, loss=1.0654146671295166
I1004 14:23:25.132550 140439319918400 spec.py:321] Evaluating on the training split.
I1004 14:24:17.586251 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 14:25:08.910463 140439319918400 spec.py:349] Evaluating on the test split.
I1004 14:25:34.494671 140439319918400 submission_runner.py:381] Time since start: 47272.79s, 	Step: 52768, 	{'train/ctc_loss': Array(0.15694164, dtype=float32), 'train/wer': 0.056782554543892805, 'validation/ctc_loss': Array(0.34340855, dtype=float32), 'validation/wer': 0.09990448533029744, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.18794857, dtype=float32), 'test/wer': 0.06199094103548433, 'test/num_examples': 2472, 'score': 43283.55116724968, 'total_duration': 47272.79087114334, 'accumulated_submission_time': 43283.55116724968, 'accumulated_eval_time': 3986.5886833667755, 'accumulated_logging_time': 1.603459358215332}
I1004 14:25:34.528595 140266021414656 logging_writer.py:48] [52768] accumulated_eval_time=3986.588683, accumulated_logging_time=1.603459, accumulated_submission_time=43283.551167, global_step=52768, preemption_count=0, score=43283.551167, test/ctc_loss=0.1879485696554184, test/num_examples=2472, test/wer=0.061991, total_duration=47272.790871, train/ctc_loss=0.15694163739681244, train/wer=0.056783, validation/ctc_loss=0.3434085547924042, validation/num_examples=5348, validation/wer=0.099904
I1004 14:28:30.838800 140266013021952 logging_writer.py:48] [53000] global_step=53000, grad_norm=1.11021089553833, loss=1.073337435722351
I1004 14:35:47.717848 140266021414656 logging_writer.py:48] [53500] global_step=53500, grad_norm=1.1576539278030396, loss=1.0347375869750977
I1004 14:42:21.112850 140266021414656 logging_writer.py:48] [54000] global_step=54000, grad_norm=1.10637366771698, loss=1.0549324750900269
I1004 14:49:35.226203 140439319918400 spec.py:321] Evaluating on the training split.
I1004 14:50:27.854783 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 14:51:18.293000 140439319918400 spec.py:349] Evaluating on the test split.
I1004 14:51:43.543777 140439319918400 submission_runner.py:381] Time since start: 48841.84s, 	Step: 54491, 	{'train/ctc_loss': Array(0.15021142, dtype=float32), 'train/wer': 0.05489862116100196, 'validation/ctc_loss': Array(0.33082718, dtype=float32), 'validation/wer': 0.09602601086358768, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.18216777, dtype=float32), 'test/wer': 0.05943168200190929, 'test/num_examples': 2472, 'score': 44724.20486450195, 'total_duration': 48841.83933830261, 'accumulated_submission_time': 44724.20486450195, 'accumulated_eval_time': 4114.900277376175, 'accumulated_logging_time': 1.6514270305633545}
I1004 14:51:43.581204 140266021414656 logging_writer.py:48] [54491] accumulated_eval_time=4114.900277, accumulated_logging_time=1.651427, accumulated_submission_time=44724.204865, global_step=54491, preemption_count=0, score=44724.204865, test/ctc_loss=0.18216776847839355, test/num_examples=2472, test/wer=0.059432, total_duration=48841.839338, train/ctc_loss=0.1502114236354828, train/wer=0.054899, validation/ctc_loss=0.33082717657089233, validation/num_examples=5348, validation/wer=0.096026
I1004 14:51:51.220326 140266013021952 logging_writer.py:48] [54500] global_step=54500, grad_norm=1.1752694845199585, loss=1.011852502822876
I1004 14:58:20.370946 140266021414656 logging_writer.py:48] [55000] global_step=55000, grad_norm=1.086513638496399, loss=1.0236576795578003
I1004 15:05:39.608460 140266013021952 logging_writer.py:48] [55500] global_step=55500, grad_norm=0.9851910471916199, loss=1.023249626159668
I1004 15:12:21.877341 140266021414656 logging_writer.py:48] [56000] global_step=56000, grad_norm=1.077291488647461, loss=1.0692548751831055
I1004 15:15:44.107339 140439319918400 spec.py:321] Evaluating on the training split.
I1004 15:16:36.272611 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 15:17:26.908523 140439319918400 spec.py:349] Evaluating on the test split.
I1004 15:17:52.567893 140439319918400 submission_runner.py:381] Time since start: 50410.86s, 	Step: 56235, 	{'train/ctc_loss': Array(0.1433295, dtype=float32), 'train/wer': 0.05157211870255349, 'validation/ctc_loss': Array(0.3238474, dtype=float32), 'validation/wer': 0.09356578452276433, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.17634395, dtype=float32), 'test/wer': 0.057827067211017, 'test/num_examples': 2472, 'score': 46164.685124874115, 'total_duration': 50410.864480257034, 'accumulated_submission_time': 46164.685124874115, 'accumulated_eval_time': 4243.355900526047, 'accumulated_logging_time': 1.704345703125}
I1004 15:17:52.602099 140266021414656 logging_writer.py:48] [56235] accumulated_eval_time=4243.355901, accumulated_logging_time=1.704346, accumulated_submission_time=46164.685125, global_step=56235, preemption_count=0, score=46164.685125, test/ctc_loss=0.17634394764900208, test/num_examples=2472, test/wer=0.057827, total_duration=50410.864480, train/ctc_loss=0.14332950115203857, train/wer=0.051572, validation/ctc_loss=0.3238474130630493, validation/num_examples=5348, validation/wer=0.093566
I1004 15:21:17.785124 140266013021952 logging_writer.py:48] [56500] global_step=56500, grad_norm=1.5749680995941162, loss=1.0420809984207153
I1004 15:28:00.187206 140266021414656 logging_writer.py:48] [57000] global_step=57000, grad_norm=1.3708611726760864, loss=1.017011284828186
I1004 15:35:20.586250 140266013021952 logging_writer.py:48] [57500] global_step=57500, grad_norm=1.0787886381149292, loss=1.0450363159179688
I1004 15:41:52.846455 140439319918400 spec.py:321] Evaluating on the training split.
I1004 15:42:43.549257 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 15:43:33.510533 140439319918400 spec.py:349] Evaluating on the test split.
I1004 15:43:59.601322 140439319918400 submission_runner.py:381] Time since start: 51977.90s, 	Step: 57985, 	{'train/ctc_loss': Array(0.14901261, dtype=float32), 'train/wer': 0.05411902063802754, 'validation/ctc_loss': Array(0.31982562, dtype=float32), 'validation/wer': 0.09237908711130836, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.17486139, dtype=float32), 'test/wer': 0.05707553876464973, 'test/num_examples': 2472, 'score': 47604.885159254074, 'total_duration': 51977.89715075493, 'accumulated_submission_time': 47604.885159254074, 'accumulated_eval_time': 4370.105190992355, 'accumulated_logging_time': 1.7530903816223145}
I1004 15:43:59.644156 140265366054656 logging_writer.py:48] [57985] accumulated_eval_time=4370.105191, accumulated_logging_time=1.753090, accumulated_submission_time=47604.885159, global_step=57985, preemption_count=0, score=47604.885159, test/ctc_loss=0.1748613864183426, test/num_examples=2472, test/wer=0.057076, total_duration=51977.897151, train/ctc_loss=0.14901261031627655, train/wer=0.054119, validation/ctc_loss=0.3198256194591522, validation/num_examples=5348, validation/wer=0.092379
I1004 15:44:11.886515 140265357661952 logging_writer.py:48] [58000] global_step=58000, grad_norm=2.664238214492798, loss=0.9841976761817932
I1004 15:51:03.543964 140265366054656 logging_writer.py:48] [58500] global_step=58500, grad_norm=1.0722154378890991, loss=1.059827446937561
I1004 15:57:50.001477 140265366054656 logging_writer.py:48] [59000] global_step=59000, grad_norm=1.0802242755889893, loss=0.9672567844390869
I1004 16:05:03.375823 140265357661952 logging_writer.py:48] [59500] global_step=59500, grad_norm=1.3126996755599976, loss=0.9846973419189453
I1004 16:07:59.613226 140439319918400 spec.py:321] Evaluating on the training split.
I1004 16:08:51.713214 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 16:09:42.528029 140439319918400 spec.py:349] Evaluating on the test split.
I1004 16:10:08.012983 140439319918400 submission_runner.py:381] Time since start: 53546.31s, 	Step: 59702, 	{'train/ctc_loss': Array(0.15881209, dtype=float32), 'train/wer': 0.05639355688909703, 'validation/ctc_loss': Array(0.31867227, dtype=float32), 'validation/wer': 0.09176161853949387, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.17428093, dtype=float32), 'test/wer': 0.05683179980907115, 'test/num_examples': 2472, 'score': 49044.80552101135, 'total_duration': 53546.30901789665, 'accumulated_submission_time': 49044.80552101135, 'accumulated_eval_time': 4498.499442100525, 'accumulated_logging_time': 1.8150460720062256}
I1004 16:10:08.053387 140266605094656 logging_writer.py:48] [59702] accumulated_eval_time=4498.499442, accumulated_logging_time=1.815046, accumulated_submission_time=49044.805521, global_step=59702, preemption_count=0, score=49044.805521, test/ctc_loss=0.17428092658519745, test/num_examples=2472, test/wer=0.056832, total_duration=53546.309018, train/ctc_loss=0.15881209075450897, train/wer=0.056394, validation/ctc_loss=0.3186722695827484, validation/num_examples=5348, validation/wer=0.091762
I1004 16:13:57.346400 140439319918400 spec.py:321] Evaluating on the training split.
I1004 16:14:48.667984 140439319918400 spec.py:333] Evaluating on the validation split.
I1004 16:15:32.435095 140439319918400 spec.py:349] Evaluating on the test split.
I1004 16:15:54.808006 140439319918400 submission_runner.py:381] Time since start: 53893.11s, 	Step: 60000, 	{'train/ctc_loss': Array(0.13875638, dtype=float32), 'train/wer': 0.050709529894411194, 'validation/ctc_loss': Array(0.3186282, dtype=float32), 'validation/wer': 0.09189668978957828, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.17427395, dtype=float32), 'test/wer': 0.05677086507017651, 'test/num_examples': 2472, 'score': 49274.07704639435, 'total_duration': 53893.10707640648, 'accumulated_submission_time': 49274.07704639435, 'accumulated_eval_time': 4615.958689928055, 'accumulated_logging_time': 1.8708252906799316}
I1004 16:15:54.835062 140265734694656 logging_writer.py:48] [60000] accumulated_eval_time=4615.958690, accumulated_logging_time=1.870825, accumulated_submission_time=49274.077046, global_step=60000, preemption_count=0, score=49274.077046, test/ctc_loss=0.17427395284175873, test/num_examples=2472, test/wer=0.056771, total_duration=53893.107076, train/ctc_loss=0.1387563794851303, train/wer=0.050710, validation/ctc_loss=0.318628191947937, validation/num_examples=5348, validation/wer=0.091897
I1004 16:15:54.856870 140265726301952 logging_writer.py:48] [60000] global_step=60000, preemption_count=0, score=49274.077046
I1004 16:15:55.231538 140439319918400 checkpoints.py:490] Saving checkpoint at step: 60000
I1004 16:15:56.694887 140439319918400 checkpoints.py:422] Saved checkpoint at /experiment_runs/targets_check_conformer/adamw_run_0/librispeech_conformer_jax/trial_1/checkpoint_60000
I1004 16:15:56.728696 140439319918400 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/targets_check_conformer/adamw_run_0/librispeech_conformer_jax/trial_1/checkpoint_60000.
I1004 16:15:58.212783 140439319918400 submission_runner.py:549] Tuning trial 1/1
I1004 16:15:58.213012 140439319918400 submission_runner.py:550] Hyperparameters: Hyperparameters(learning_rate=0.002106913873888147, beta1=0.8231189937738506, beta2=0.8774571227688758, warmup_steps=1199, weight_decay=0.27590534177690645)
I1004 16:15:58.232598 140439319918400 submission_runner.py:551] Metrics: {'eval_results': [(1, {'train/ctc_loss': Array(31.98603, dtype=float32), 'train/wer': 1.3190138058846803, 'validation/ctc_loss': Array(31.149433, dtype=float32), 'validation/wer': 1.0245154318903222, 'validation/num_examples': 5348, 'test/ctc_loss': Array(31.20991, dtype=float32), 'test/wer': 1.0714967603030487, 'test/num_examples': 2472, 'score': 75.39593124389648, 'total_duration': 240.96851873397827, 'accumulated_submission_time': 75.39593124389648, 'accumulated_eval_time': 165.57253074645996, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (1788, {'train/ctc_loss': Array(2.1337428, dtype=float32), 'train/wer': 0.5123066466190191, 'validation/ctc_loss': Array(2.652203, dtype=float32), 'validation/wer': 0.5496917481114145, 'validation/num_examples': 5348, 'test/ctc_loss': Array(2.2688458, dtype=float32), 'test/wer': 0.5073426360368046, 'test/num_examples': 2472, 'score': 1516.0885436534882, 'total_duration': 1803.5193746089935, 'accumulated_submission_time': 1516.0885436534882, 'accumulated_eval_time': 287.36010932922363, 'accumulated_logging_time': 0.040886878967285156, 'global_step': 1788, 'preemption_count': 0}), (3618, {'train/ctc_loss': Array(0.6710612, dtype=float32), 'train/wer': 0.22796793010681085, 'validation/ctc_loss': Array(0.99554235, dtype=float32), 'validation/wer': 0.28647647348261923, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.70161444, dtype=float32), 'test/wer': 0.2290130603457031, 'test/num_examples': 2472, 'score': 2956.459987640381, 'total_duration': 3367.879745721817, 'accumulated_submission_time': 2956.459987640381, 'accumulated_eval_time': 411.2596890926361, 'accumulated_logging_time': 0.09616494178771973, 'global_step': 3618, 'preemption_count': 0}), (5438, {'train/ctc_loss': Array(0.49043533, dtype=float32), 'train/wer': 0.17396988050244847, 'validation/ctc_loss': Array(0.83833593, dtype=float32), 'validation/wer': 0.24725757122596456, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.55463874, dtype=float32), 'test/wer': 0.18579001888976907, 'test/num_examples': 2472, 'score': 4396.973568677902, 'total_duration': 4933.6836478710175, 'accumulated_submission_time': 4396.973568677902, 'accumulated_eval_time': 536.4664764404297, 'accumulated_logging_time': 0.14515447616577148, 'global_step': 5438, 'preemption_count': 0}), (7225, {'train/ctc_loss': Array(0.46202254, dtype=float32), 'train/wer': 0.16068342950496917, 'validation/ctc_loss': Array(0.77811944, dtype=float32), 'validation/wer': 0.22934133469690976, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.50803596, dtype=float32), 'test/wer': 0.16759084353990208, 'test/num_examples': 2472, 'score': 5837.2188131809235, 'total_duration': 6498.44083237648, 'accumulated_submission_time': 5837.2188131809235, 'accumulated_eval_time': 660.8961136341095, 'accumulated_logging_time': 0.19434285163879395, 'global_step': 7225, 'preemption_count': 0}), (9037, {'train/ctc_loss': Array(0.45497754, dtype=float32), 'train/wer': 0.15755398029963688, 'validation/ctc_loss': Array(0.7485645, dtype=float32), 'validation/wer': 0.22010824995899622, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.50134647, dtype=float32), 'test/wer': 0.16523470030264253, 'test/num_examples': 2472, 'score': 7277.350239515305, 'total_duration': 8063.447151422501, 'accumulated_submission_time': 7277.350239515305, 'accumulated_eval_time': 785.6813886165619, 'accumulated_logging_time': 0.24946308135986328, 'global_step': 9037, 'preemption_count': 0}), (10834, {'train/ctc_loss': Array(0.4864511, dtype=float32), 'train/wer': 0.168785442595665, 'validation/ctc_loss': Array(0.76815295, dtype=float32), 'validation/wer': 0.22873351407152986, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.49692217, dtype=float32), 'test/wer': 0.16553937399711577, 'test/num_examples': 2472, 'score': 8717.935256958008, 'total_duration': 9628.919127464294, 'accumulated_submission_time': 8717.935256958008, 'accumulated_eval_time': 910.4851367473602, 'accumulated_logging_time': 0.2971150875091553, 'global_step': 10834, 'preemption_count': 0}), (12611, {'train/ctc_loss': Array(0.4464734, dtype=float32), 'train/wer': 0.15742985982600557, 'validation/ctc_loss': Array(0.7385711, dtype=float32), 'validation/wer': 0.22081255004872213, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.47573552, dtype=float32), 'test/wer': 0.15889748745759957, 'test/num_examples': 2472, 'score': 10157.961879253387, 'total_duration': 11196.050883769989, 'accumulated_submission_time': 10157.961879253387, 'accumulated_eval_time': 1037.5094816684723, 'accumulated_logging_time': 0.3439316749572754, 'global_step': 12611, 'preemption_count': 0}), (14375, {'train/ctc_loss': Array(0.423981, dtype=float32), 'train/wer': 0.15203203411425154, 'validation/ctc_loss': Array(0.7461639, dtype=float32), 'validation/wer': 0.22219220638887013, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.4849085, dtype=float32), 'test/wer': 0.16312229602096154, 'test/num_examples': 2472, 'score': 11597.919181585312, 'total_duration': 12763.976046800613, 'accumulated_submission_time': 11597.919181585312, 'accumulated_eval_time': 1165.3976945877075, 'accumulated_logging_time': 0.38990259170532227, 'global_step': 14375, 'preemption_count': 0}), (16142, {'train/ctc_loss': Array(0.38078287, dtype=float32), 'train/wer': 0.13283041352563454, 'validation/ctc_loss': Array(0.701938, dtype=float32), 'validation/wer': 0.20639851807542764, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.4447674, dtype=float32), 'test/wer': 0.14754331444356428, 'test/num_examples': 2472, 'score': 13038.33169579506, 'total_duration': 14330.466711997986, 'accumulated_submission_time': 13038.33169579506, 'accumulated_eval_time': 1291.3872356414795, 'accumulated_logging_time': 0.4437692165374756, 'global_step': 16142, 'preemption_count': 0}), (17930, {'train/ctc_loss': Array(0.38881645, dtype=float32), 'train/wer': 0.13868941957558173, 'validation/ctc_loss': Array(0.6963872, dtype=float32), 'validation/wer': 0.206195911200301, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.44702426, dtype=float32), 'test/wer': 0.14904637133629883, 'test/num_examples': 2472, 'score': 14478.592161655426, 'total_duration': 15896.458851337433, 'accumulated_submission_time': 14478.592161655426, 'accumulated_eval_time': 1417.025891304016, 'accumulated_logging_time': 0.5001053810119629, 'global_step': 17930, 'preemption_count': 0}), (19675, {'train/ctc_loss': Array(0.3790502, dtype=float32), 'train/wer': 0.13150532800973055, 'validation/ctc_loss': Array(0.66619724, dtype=float32), 'validation/wer': 0.19507182896120562, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.41767335, dtype=float32), 'test/wer': 0.13956086364836592, 'test/num_examples': 2472, 'score': 15918.993396997452, 'total_duration': 17464.947844028473, 'accumulated_submission_time': 15918.993396997452, 'accumulated_eval_time': 1545.021859884262, 'accumulated_logging_time': 0.5574085712432861, 'global_step': 19675, 'preemption_count': 0}), (21427, {'train/ctc_loss': Array(0.39123425, dtype=float32), 'train/wer': 0.13665022291397366, 'validation/ctc_loss': Array(0.674069, dtype=float32), 'validation/wer': 0.19815917182027806, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.41924185, dtype=float32), 'test/wer': 0.14104360896146895, 'test/num_examples': 2472, 'score': 17359.441693544388, 'total_duration': 19032.884077072144, 'accumulated_submission_time': 17359.441693544388, 'accumulated_eval_time': 1672.4268674850464, 'accumulated_logging_time': 0.6066875457763672, 'global_step': 21427, 'preemption_count': 0}), (23198, {'train/ctc_loss': Array(0.37585106, dtype=float32), 'train/wer': 0.1322203930445519, 'validation/ctc_loss': Array(0.6593281, dtype=float32), 'validation/wer': 0.1934702698530618, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.40895495, dtype=float32), 'test/wer': 0.13720472041110637, 'test/num_examples': 2472, 'score': 18799.712696313858, 'total_duration': 20604.11959052086, 'accumulated_submission_time': 18799.712696313858, 'accumulated_eval_time': 1803.3026480674744, 'accumulated_logging_time': 0.6593880653381348, 'global_step': 23198, 'preemption_count': 0}), (24963, {'train/ctc_loss': Array(0.3455431, dtype=float32), 'train/wer': 0.12042882479625015, 'validation/ctc_loss': Array(0.634761, dtype=float32), 'validation/wer': 0.18502831672278555, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.39881578, dtype=float32), 'test/wer': 0.13174090549021997, 'test/num_examples': 2472, 'score': 20239.93368458748, 'total_duration': 22172.456852912903, 'accumulated_submission_time': 20239.93368458748, 'accumulated_eval_time': 1931.3317387104034, 'accumulated_logging_time': 0.7098081111907959, 'global_step': 24963, 'preemption_count': 0}), (26710, {'train/ctc_loss': Array(0.31516305, dtype=float32), 'train/wer': 0.1125955293565299, 'validation/ctc_loss': Array(0.5985893, dtype=float32), 'validation/wer': 0.17722312805719304, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.37163034, dtype=float32), 'test/wer': 0.12467247577844129, 'test/num_examples': 2472, 'score': 21680.36767578125, 'total_duration': 23741.31293654442, 'accumulated_submission_time': 21680.36767578125, 'accumulated_eval_time': 2059.6636905670166, 'accumulated_logging_time': 0.7654232978820801, 'global_step': 26710, 'preemption_count': 0}), (28456, {'train/ctc_loss': Array(0.2942566, dtype=float32), 'train/wer': 0.10323613341379345, 'validation/ctc_loss': Array(0.5838246, dtype=float32), 'validation/wer': 0.1707686518924447, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.35414937, dtype=float32), 'test/wer': 0.1167915828814007, 'test/num_examples': 2472, 'score': 23120.666944503784, 'total_duration': 25310.901830673218, 'accumulated_submission_time': 23120.666944503784, 'accumulated_eval_time': 2188.8698608875275, 'accumulated_logging_time': 0.814436674118042, 'global_step': 28456, 'preemption_count': 0}), (30217, {'train/ctc_loss': Array(0.3031742, dtype=float32), 'train/wer': 0.10695636158779684, 'validation/ctc_loss': Array(0.5573894, dtype=float32), 'validation/wer': 0.16575171974645198, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.341485, dtype=float32), 'test/wer': 0.11498385229419292, 'test/num_examples': 2472, 'score': 24560.585616350174, 'total_duration': 26879.02878499031, 'accumulated_submission_time': 24560.585616350174, 'accumulated_eval_time': 2316.9757130146027, 'accumulated_logging_time': 0.8803038597106934, 'global_step': 30217, 'preemption_count': 0}), (31944, {'train/ctc_loss': Array(0.2831307, dtype=float32), 'train/wer': 0.09695657599878459, 'validation/ctc_loss': Array(0.5510053, dtype=float32), 'validation/wer': 0.16162239867244257, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.3258699, dtype=float32), 'test/wer': 0.10698108991936303, 'test/num_examples': 2472, 'score': 26001.12089252472, 'total_duration': 28447.315212726593, 'accumulated_submission_time': 26001.12089252472, 'accumulated_eval_time': 2444.637258052826, 'accumulated_logging_time': 0.934779167175293, 'global_step': 31944, 'preemption_count': 0}), (33700, {'train/ctc_loss': Array(0.27834785, dtype=float32), 'train/wer': 0.09709301429606151, 'validation/ctc_loss': Array(0.52099866, dtype=float32), 'validation/wer': 0.15428031143571092, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.3104823, dtype=float32), 'test/wer': 0.10503117827473443, 'test/num_examples': 2472, 'score': 27441.136357545853, 'total_duration': 30016.147325992584, 'accumulated_submission_time': 27441.136357545853, 'accumulated_eval_time': 2573.3625144958496, 'accumulated_logging_time': 0.9903042316436768, 'global_step': 33700, 'preemption_count': 0}), (35470, {'train/ctc_loss': Array(0.27073327, dtype=float32), 'train/wer': 0.09125398297047008, 'validation/ctc_loss': Array(0.50969666, dtype=float32), 'validation/wer': 0.14986155196866346, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.30261588, dtype=float32), 'test/wer': 0.10153758657810819, 'test/num_examples': 2472, 'score': 28881.243389606476, 'total_duration': 31585.95036506653, 'accumulated_submission_time': 28881.243389606476, 'accumulated_eval_time': 2702.9735271930695, 'accumulated_logging_time': 1.038757562637329, 'global_step': 35470, 'preemption_count': 0}), (37184, {'train/ctc_loss': Array(0.20574616, dtype=float32), 'train/wer': 0.07377796910714103, 'validation/ctc_loss': Array(0.4880934, dtype=float32), 'validation/wer': 0.14304045383940028, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.28866056, dtype=float32), 'test/wer': 0.09611439481648487, 'test/num_examples': 2472, 'score': 30321.89643239975, 'total_duration': 33155.71012830734, 'accumulated_submission_time': 30321.89643239975, 'accumulated_eval_time': 2831.9898529052734, 'accumulated_logging_time': 1.09462308883667, 'global_step': 37184, 'preemption_count': 0}), (38921, {'train/ctc_loss': Array(0.22578067, dtype=float32), 'train/wer': 0.08017254123460962, 'validation/ctc_loss': Array(0.47240302, dtype=float32), 'validation/wer': 0.1403969165163195, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.2732842, dtype=float32), 'test/wer': 0.0928645420754372, 'test/num_examples': 2472, 'score': 31762.3391726017, 'total_duration': 34724.89362120628, 'accumulated_submission_time': 31762.3391726017, 'accumulated_eval_time': 2960.637261867523, 'accumulated_logging_time': 1.1521766185760498, 'global_step': 38921, 'preemption_count': 0}), (40676, {'train/ctc_loss': Array(0.26900163, dtype=float32), 'train/wer': 0.09557232199519426, 'validation/ctc_loss': Array(0.44807506, dtype=float32), 'validation/wer': 0.1335179307084487, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.26067665, dtype=float32), 'test/wer': 0.08870066825096988, 'test/num_examples': 2472, 'score': 33202.350559711456, 'total_duration': 36293.79698777199, 'accumulated_submission_time': 33202.350559711456, 'accumulated_eval_time': 3089.434543609619, 'accumulated_logging_time': 1.2108683586120605, 'global_step': 40676, 'preemption_count': 0}), (42405, {'train/ctc_loss': Array(0.2662538, dtype=float32), 'train/wer': 0.09314022105397558, 'validation/ctc_loss': Array(0.43428874, dtype=float32), 'validation/wer': 0.1272564134723924, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.24629119, dtype=float32), 'test/wer': 0.08376495440050373, 'test/num_examples': 2472, 'score': 34642.995950460434, 'total_duration': 37862.372670173645, 'accumulated_submission_time': 34642.995950460434, 'accumulated_eval_time': 3217.2839591503143, 'accumulated_logging_time': 1.2571029663085938, 'global_step': 42405, 'preemption_count': 0}), (44123, {'train/ctc_loss': Array(0.28787172, dtype=float32), 'train/wer': 0.10207018385385286, 'validation/ctc_loss': Array(0.40810177, dtype=float32), 'validation/wer': 0.12124574284363573, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.23438783, dtype=float32), 'test/wer': 0.07645278573314647, 'test/num_examples': 2472, 'score': 36082.93872523308, 'total_duration': 39429.58925819397, 'accumulated_submission_time': 36082.93872523308, 'accumulated_eval_time': 3344.4672725200653, 'accumulated_logging_time': 1.3135323524475098, 'global_step': 44123, 'preemption_count': 0}), (45855, {'train/ctc_loss': Array(0.24147134, dtype=float32), 'train/wer': 0.08287361126647787, 'validation/ctc_loss': Array(0.39788356, dtype=float32), 'validation/wer': 0.11674979980511148, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.2260457, dtype=float32), 'test/wer': 0.07505128673856966, 'test/num_examples': 2472, 'score': 37522.90286588669, 'total_duration': 40995.897117614746, 'accumulated_submission_time': 37522.90286588669, 'accumulated_eval_time': 3470.726508140564, 'accumulated_logging_time': 1.362656593322754, 'global_step': 45855, 'preemption_count': 0}), (47574, {'train/ctc_loss': Array(0.2142926, dtype=float32), 'train/wer': 0.0779230178259272, 'validation/ctc_loss': Array(0.37880367, dtype=float32), 'validation/wer': 0.1113565977481693, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.21749084, dtype=float32), 'test/wer': 0.07129364450673328, 'test/num_examples': 2472, 'score': 38962.84694170952, 'total_duration': 42563.63844156265, 'accumulated_submission_time': 38962.84694170952, 'accumulated_eval_time': 3598.4093978405, 'accumulated_logging_time': 1.4419493675231934, 'global_step': 47574, 'preemption_count': 0}), (49300, {'train/ctc_loss': Array(0.1722954, dtype=float32), 'train/wer': 0.062186646945589404, 'validation/ctc_loss': Array(0.3584863, dtype=float32), 'validation/wer': 0.1050757846192438, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.20170058, dtype=float32), 'test/wer': 0.06733288647858143, 'test/num_examples': 2472, 'score': 40403.02093362808, 'total_duration': 44132.87708950043, 'accumulated_submission_time': 40403.02093362808, 'accumulated_eval_time': 3727.3926265239716, 'accumulated_logging_time': 1.489212989807129, 'global_step': 49300, 'preemption_count': 0}), (51034, {'train/ctc_loss': Array(0.18265964, dtype=float32), 'train/wer': 0.06571008054223444, 'validation/ctc_loss': Array(0.35426068, dtype=float32), 'validation/wer': 0.10270238979633185, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.1948839, dtype=float32), 'test/wer': 0.06398147583937602, 'test/num_examples': 2472, 'score': 41842.95369029045, 'total_duration': 45702.74022102356, 'accumulated_submission_time': 41842.95369029045, 'accumulated_eval_time': 3857.23179769516, 'accumulated_logging_time': 1.5439732074737549, 'global_step': 51034, 'preemption_count': 0}), (52768, {'train/ctc_loss': Array(0.15694164, dtype=float32), 'train/wer': 0.056782554543892805, 'validation/ctc_loss': Array(0.34340855, dtype=float32), 'validation/wer': 0.09990448533029744, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.18794857, dtype=float32), 'test/wer': 0.06199094103548433, 'test/num_examples': 2472, 'score': 43283.55116724968, 'total_duration': 47272.79087114334, 'accumulated_submission_time': 43283.55116724968, 'accumulated_eval_time': 3986.5886833667755, 'accumulated_logging_time': 1.603459358215332, 'global_step': 52768, 'preemption_count': 0}), (54491, {'train/ctc_loss': Array(0.15021142, dtype=float32), 'train/wer': 0.05489862116100196, 'validation/ctc_loss': Array(0.33082718, dtype=float32), 'validation/wer': 0.09602601086358768, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.18216777, dtype=float32), 'test/wer': 0.05943168200190929, 'test/num_examples': 2472, 'score': 44724.20486450195, 'total_duration': 48841.83933830261, 'accumulated_submission_time': 44724.20486450195, 'accumulated_eval_time': 4114.900277376175, 'accumulated_logging_time': 1.6514270305633545, 'global_step': 54491, 'preemption_count': 0}), (56235, {'train/ctc_loss': Array(0.1433295, dtype=float32), 'train/wer': 0.05157211870255349, 'validation/ctc_loss': Array(0.3238474, dtype=float32), 'validation/wer': 0.09356578452276433, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.17634395, dtype=float32), 'test/wer': 0.057827067211017, 'test/num_examples': 2472, 'score': 46164.685124874115, 'total_duration': 50410.864480257034, 'accumulated_submission_time': 46164.685124874115, 'accumulated_eval_time': 4243.355900526047, 'accumulated_logging_time': 1.704345703125, 'global_step': 56235, 'preemption_count': 0}), (57985, {'train/ctc_loss': Array(0.14901261, dtype=float32), 'train/wer': 0.05411902063802754, 'validation/ctc_loss': Array(0.31982562, dtype=float32), 'validation/wer': 0.09237908711130836, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.17486139, dtype=float32), 'test/wer': 0.05707553876464973, 'test/num_examples': 2472, 'score': 47604.885159254074, 'total_duration': 51977.89715075493, 'accumulated_submission_time': 47604.885159254074, 'accumulated_eval_time': 4370.105190992355, 'accumulated_logging_time': 1.7530903816223145, 'global_step': 57985, 'preemption_count': 0}), (59702, {'train/ctc_loss': Array(0.15881209, dtype=float32), 'train/wer': 0.05639355688909703, 'validation/ctc_loss': Array(0.31867227, dtype=float32), 'validation/wer': 0.09176161853949387, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.17428093, dtype=float32), 'test/wer': 0.05683179980907115, 'test/num_examples': 2472, 'score': 49044.80552101135, 'total_duration': 53546.30901789665, 'accumulated_submission_time': 49044.80552101135, 'accumulated_eval_time': 4498.499442100525, 'accumulated_logging_time': 1.8150460720062256, 'global_step': 59702, 'preemption_count': 0}), (60000, {'train/ctc_loss': Array(0.13875638, dtype=float32), 'train/wer': 0.050709529894411194, 'validation/ctc_loss': Array(0.3186282, dtype=float32), 'validation/wer': 0.09189668978957828, 'validation/num_examples': 5348, 'test/ctc_loss': Array(0.17427395, dtype=float32), 'test/wer': 0.05677086507017651, 'test/num_examples': 2472, 'score': 49274.07704639435, 'total_duration': 53893.10707640648, 'accumulated_submission_time': 49274.07704639435, 'accumulated_eval_time': 4615.958689928055, 'accumulated_logging_time': 1.8708252906799316, 'global_step': 60000, 'preemption_count': 0})], 'global_step': 60000}
I1004 16:15:58.232818 140439319918400 submission_runner.py:552] Timing: 49274.07704639435
I1004 16:15:58.232878 140439319918400 submission_runner.py:554] Total number of evals: 36
I1004 16:15:58.232931 140439319918400 submission_runner.py:555] ====================
I1004 16:15:58.236602 140439319918400 submission_runner.py:625] Final librispeech_conformer score: 49274.07704639435
