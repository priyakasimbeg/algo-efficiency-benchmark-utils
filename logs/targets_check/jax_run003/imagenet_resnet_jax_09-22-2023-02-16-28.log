python3 submission_runner.py --framework=jax --workload=imagenet_resnet --submission_path=reference_algorithms/target_setting_algorithms/jax_momentum.py --tuning_search_space=reference_algorithms/target_setting_algorithms/imagenet_resnet/tuning_search_space.json --data_dir=/data/imagenet/jax --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=targets_check_jax_run_03/momentum_run_0 --overwrite=true --save_checkpoints=false --max_global_steps=140000 --imagenet_v2_data_dir=/data/imagenet/jax 2>&1 | tee -a /logs/imagenet_resnet_jax_09-22-2023-02-16-28.log
2023-09-22 02:16:34.083839: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
I0922 02:16:52.123711 139860156245824 logger_utils.py:76] Creating experiment directory at /experiment_runs/targets_check_jax_run_03/momentum_run_0/imagenet_resnet_jax.
I0922 02:16:53.138201 139860156245824 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Host Interpreter CUDA
I0922 02:16:53.138856 139860156245824 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0922 02:16:53.139027 139860156245824 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0922 02:16:53.145690 139860156245824 submission_runner.py:500] Using RNG seed 2930868076
I0922 02:16:59.552142 139860156245824 submission_runner.py:509] --- Tuning run 1/1 ---
I0922 02:16:59.552358 139860156245824 submission_runner.py:514] Creating tuning directory at /experiment_runs/targets_check_jax_run_03/momentum_run_0/imagenet_resnet_jax/trial_1.
I0922 02:16:59.552536 139860156245824 logger_utils.py:92] Saving hparams to /experiment_runs/targets_check_jax_run_03/momentum_run_0/imagenet_resnet_jax/trial_1/hparams.json.
I0922 02:16:59.736392 139860156245824 submission_runner.py:185] Initializing dataset.
I0922 02:16:59.752745 139860156245824 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0922 02:16:59.763159 139860156245824 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0922 02:17:00.155663 139860156245824 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0922 02:17:01.359850 139860156245824 submission_runner.py:192] Initializing model.
I0922 02:17:12.153807 139860156245824 submission_runner.py:226] Initializing optimizer.
I0922 02:17:13.698139 139860156245824 submission_runner.py:233] Initializing metrics bundle.
I0922 02:17:13.698354 139860156245824 submission_runner.py:251] Initializing checkpoint and logger.
I0922 02:17:13.699463 139860156245824 checkpoints.py:915] Found no checkpoint files in /experiment_runs/targets_check_jax_run_03/momentum_run_0/imagenet_resnet_jax/trial_1 with prefix checkpoint_
I0922 02:17:14.644696 139860156245824 submission_runner.py:272] Saving meta data to /experiment_runs/targets_check_jax_run_03/momentum_run_0/imagenet_resnet_jax/trial_1/meta_data_0.json.
I0922 02:17:14.646810 139860156245824 submission_runner.py:275] Saving flags to /experiment_runs/targets_check_jax_run_03/momentum_run_0/imagenet_resnet_jax/trial_1/flags_0.json.
I0922 02:17:14.656886 139860156245824 submission_runner.py:285] Starting training loop.
2023-09-22 02:18:13.986705: E external/xla/xla/service/rendezvous.cc:31] This thread has been waiting for 10 seconds and may be stuck:
2023-09-22 02:18:16.899456: E external/xla/xla/service/rendezvous.cc:36] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.
I0922 02:18:18.470180 139694843094784 logging_writer.py:48] [0] global_step=0, grad_norm=0.537109375, loss=6.93135929107666
I0922 02:18:18.485571 139860156245824 spec.py:320] Evaluating on the training split.
I0922 02:18:19.466688 139860156245824 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0922 02:18:19.475952 139860156245824 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0922 02:18:19.561091 139860156245824 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0922 02:18:32.681550 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 02:18:34.263315 139860156245824 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0922 02:18:34.288334 139860156245824 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0922 02:18:34.369200 139860156245824 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0922 02:18:54.169063 139860156245824 spec.py:348] Evaluating on the test split.
I0922 02:18:54.977383 139860156245824 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0922 02:18:54.983700 139860156245824 dataset_builder.py:528] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0922 02:18:55.022846 139860156245824 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0922 02:19:05.783060 139860156245824 submission_runner.py:376] Time since start: 111.13s, 	Step: 1, 	{'train/accuracy': 0.0010762116871774197, 'train/loss': 6.912233829498291, 'validation/accuracy': 0.0009599999757483602, 'validation/loss': 6.911919593811035, 'validation/num_examples': 50000, 'test/accuracy': 0.0012000000569969416, 'test/loss': 6.911700248718262, 'test/num_examples': 10000, 'score': 63.82860493659973, 'total_duration': 111.1261203289032, 'accumulated_submission_time': 63.82860493659973, 'accumulated_eval_time': 47.297425746917725, 'accumulated_logging_time': 0}
I0922 02:19:05.802360 139665206138624 logging_writer.py:48] [1] accumulated_eval_time=47.297426, accumulated_logging_time=0, accumulated_submission_time=63.828605, global_step=1, preemption_count=0, score=63.828605, test/accuracy=0.001200, test/loss=6.911700, test/num_examples=10000, total_duration=111.126120, train/accuracy=0.001076, train/loss=6.912234, validation/accuracy=0.000960, validation/loss=6.911920, validation/num_examples=50000
I0922 02:19:06.154465 139665214531328 logging_writer.py:48] [1] global_step=1, grad_norm=0.5332960486412048, loss=6.9299468994140625
I0922 02:19:06.490597 139665206138624 logging_writer.py:48] [2] global_step=2, grad_norm=0.5404877662658691, loss=6.941740989685059
I0922 02:19:06.828963 139665214531328 logging_writer.py:48] [3] global_step=3, grad_norm=0.5409358739852905, loss=6.926423072814941
I0922 02:19:07.164510 139665206138624 logging_writer.py:48] [4] global_step=4, grad_norm=0.5472427606582642, loss=6.933229923248291
I0922 02:19:07.506374 139665214531328 logging_writer.py:48] [5] global_step=5, grad_norm=0.5466651320457458, loss=6.925314426422119
I0922 02:19:07.842832 139665206138624 logging_writer.py:48] [6] global_step=6, grad_norm=0.5371838212013245, loss=6.927729606628418
I0922 02:19:08.176136 139665214531328 logging_writer.py:48] [7] global_step=7, grad_norm=0.5356852412223816, loss=6.9230122566223145
I0922 02:19:08.512094 139665206138624 logging_writer.py:48] [8] global_step=8, grad_norm=0.5650603771209717, loss=6.929141044616699
I0922 02:19:08.848935 139665214531328 logging_writer.py:48] [9] global_step=9, grad_norm=0.5235918164253235, loss=6.916780948638916
I0922 02:19:09.193436 139665206138624 logging_writer.py:48] [10] global_step=10, grad_norm=0.5354770421981812, loss=6.932034492492676
I0922 02:19:09.531077 139665214531328 logging_writer.py:48] [11] global_step=11, grad_norm=0.5279668569564819, loss=6.92030143737793
I0922 02:19:09.864696 139665206138624 logging_writer.py:48] [12] global_step=12, grad_norm=0.5211200714111328, loss=6.926229000091553
I0922 02:19:10.201764 139665214531328 logging_writer.py:48] [13] global_step=13, grad_norm=0.5193662643432617, loss=6.924947261810303
I0922 02:19:10.540715 139665206138624 logging_writer.py:48] [14] global_step=14, grad_norm=0.5475108027458191, loss=6.918437957763672
I0922 02:19:10.880959 139665214531328 logging_writer.py:48] [15] global_step=15, grad_norm=0.5277956128120422, loss=6.914479732513428
I0922 02:19:11.218830 139665206138624 logging_writer.py:48] [16] global_step=16, grad_norm=0.5202715992927551, loss=6.919206619262695
I0922 02:19:11.555728 139665214531328 logging_writer.py:48] [17] global_step=17, grad_norm=0.5430466532707214, loss=6.919698238372803
I0922 02:19:11.890959 139665206138624 logging_writer.py:48] [18] global_step=18, grad_norm=0.5340162515640259, loss=6.914528846740723
I0922 02:19:12.233727 139665214531328 logging_writer.py:48] [19] global_step=19, grad_norm=0.5337220430374146, loss=6.910435199737549
I0922 02:19:12.575185 139665206138624 logging_writer.py:48] [20] global_step=20, grad_norm=0.5291640162467957, loss=6.91507625579834
I0922 02:19:12.917615 139665214531328 logging_writer.py:48] [21] global_step=21, grad_norm=0.510276734828949, loss=6.904376029968262
I0922 02:19:13.267720 139665206138624 logging_writer.py:48] [22] global_step=22, grad_norm=0.5534095764160156, loss=6.9088969230651855
I0922 02:19:13.607350 139665214531328 logging_writer.py:48] [23] global_step=23, grad_norm=0.5381202697753906, loss=6.905401229858398
I0922 02:19:13.947434 139665206138624 logging_writer.py:48] [24] global_step=24, grad_norm=0.5322266221046448, loss=6.9000749588012695
I0922 02:19:14.286186 139665214531328 logging_writer.py:48] [25] global_step=25, grad_norm=0.5400676131248474, loss=6.903077125549316
I0922 02:19:14.635520 139665206138624 logging_writer.py:48] [26] global_step=26, grad_norm=0.5189253687858582, loss=6.90770959854126
I0922 02:19:14.971888 139665214531328 logging_writer.py:48] [27] global_step=27, grad_norm=0.5321738719940186, loss=6.895535945892334
I0922 02:19:15.323658 139665206138624 logging_writer.py:48] [28] global_step=28, grad_norm=0.5166559219360352, loss=6.894428730010986
I0922 02:19:15.665572 139665214531328 logging_writer.py:48] [29] global_step=29, grad_norm=0.5168112516403198, loss=6.901882171630859
I0922 02:19:16.018625 139665206138624 logging_writer.py:48] [30] global_step=30, grad_norm=0.5289319157600403, loss=6.89932918548584
I0922 02:19:16.357628 139665214531328 logging_writer.py:48] [31] global_step=31, grad_norm=0.5290796160697937, loss=6.896938800811768
I0922 02:19:16.697328 139665206138624 logging_writer.py:48] [32] global_step=32, grad_norm=0.5429427623748779, loss=6.900054454803467
I0922 02:19:17.035363 139665214531328 logging_writer.py:48] [33] global_step=33, grad_norm=0.5383846163749695, loss=6.8861284255981445
I0922 02:19:17.375874 139665206138624 logging_writer.py:48] [34] global_step=34, grad_norm=0.5279848575592041, loss=6.896953105926514
I0922 02:19:17.711029 139665214531328 logging_writer.py:48] [35] global_step=35, grad_norm=0.5475547313690186, loss=6.889384746551514
I0922 02:19:18.053461 139665206138624 logging_writer.py:48] [36] global_step=36, grad_norm=0.5372287034988403, loss=6.8741936683654785
I0922 02:19:18.393423 139665214531328 logging_writer.py:48] [37] global_step=37, grad_norm=0.5465522408485413, loss=6.883206367492676
I0922 02:19:18.734710 139665206138624 logging_writer.py:48] [38] global_step=38, grad_norm=0.5317039489746094, loss=6.877649307250977
I0922 02:19:19.080691 139665214531328 logging_writer.py:48] [39] global_step=39, grad_norm=0.5367622971534729, loss=6.883035659790039
I0922 02:19:19.418619 139665206138624 logging_writer.py:48] [40] global_step=40, grad_norm=0.5352882146835327, loss=6.882846832275391
I0922 02:19:19.760174 139665214531328 logging_writer.py:48] [41] global_step=41, grad_norm=0.5260694622993469, loss=6.878476142883301
I0922 02:19:20.108955 139665206138624 logging_writer.py:48] [42] global_step=42, grad_norm=0.5368743538856506, loss=6.868908882141113
I0922 02:19:20.445844 139665214531328 logging_writer.py:48] [43] global_step=43, grad_norm=0.5408934950828552, loss=6.863737106323242
I0922 02:19:20.787564 139665206138624 logging_writer.py:48] [44] global_step=44, grad_norm=0.5372625589370728, loss=6.873647212982178
I0922 02:19:21.130294 139665214531328 logging_writer.py:48] [45] global_step=45, grad_norm=0.5250115394592285, loss=6.867151737213135
I0922 02:19:21.469187 139665206138624 logging_writer.py:48] [46] global_step=46, grad_norm=0.5300800204277039, loss=6.867387294769287
I0922 02:19:21.810782 139665214531328 logging_writer.py:48] [47] global_step=47, grad_norm=0.5386210083961487, loss=6.861905574798584
I0922 02:19:22.150334 139665206138624 logging_writer.py:48] [48] global_step=48, grad_norm=0.5238739848136902, loss=6.855444431304932
I0922 02:19:22.489246 139665214531328 logging_writer.py:48] [49] global_step=49, grad_norm=0.536466658115387, loss=6.852854251861572
I0922 02:19:22.829498 139665206138624 logging_writer.py:48] [50] global_step=50, grad_norm=0.5307713747024536, loss=6.860612392425537
I0922 02:19:23.167742 139665214531328 logging_writer.py:48] [51] global_step=51, grad_norm=0.5458608269691467, loss=6.856706619262695
I0922 02:19:23.507354 139665206138624 logging_writer.py:48] [52] global_step=52, grad_norm=0.5364167094230652, loss=6.84255838394165
I0922 02:19:23.847549 139665214531328 logging_writer.py:48] [53] global_step=53, grad_norm=0.5525902509689331, loss=6.842037200927734
I0922 02:19:24.187729 139665206138624 logging_writer.py:48] [54] global_step=54, grad_norm=0.5386407971382141, loss=6.828768730163574
I0922 02:19:24.526946 139665214531328 logging_writer.py:48] [55] global_step=55, grad_norm=0.552625834941864, loss=6.84365701675415
I0922 02:19:24.870105 139665206138624 logging_writer.py:48] [56] global_step=56, grad_norm=0.5417839288711548, loss=6.842596054077148
I0922 02:19:25.211896 139665214531328 logging_writer.py:48] [57] global_step=57, grad_norm=0.5534533262252808, loss=6.826157093048096
I0922 02:19:25.564985 139665206138624 logging_writer.py:48] [58] global_step=58, grad_norm=0.5451290011405945, loss=6.832233428955078
I0922 02:19:25.906074 139665214531328 logging_writer.py:48] [59] global_step=59, grad_norm=0.5559934377670288, loss=6.8353271484375
I0922 02:19:26.242240 139665206138624 logging_writer.py:48] [60] global_step=60, grad_norm=0.5554491281509399, loss=6.822957992553711
I0922 02:19:26.582600 139665214531328 logging_writer.py:48] [61] global_step=61, grad_norm=0.5517433881759644, loss=6.807202339172363
I0922 02:19:26.926000 139665206138624 logging_writer.py:48] [62] global_step=62, grad_norm=0.5478125214576721, loss=6.8291168212890625
I0922 02:19:27.269322 139665214531328 logging_writer.py:48] [63] global_step=63, grad_norm=0.556845486164093, loss=6.822293281555176
I0922 02:19:27.612813 139665206138624 logging_writer.py:48] [64] global_step=64, grad_norm=0.5613805055618286, loss=6.8185601234436035
I0922 02:19:27.954179 139665214531328 logging_writer.py:48] [65] global_step=65, grad_norm=0.5734397768974304, loss=6.813981056213379
I0922 02:19:28.293767 139665206138624 logging_writer.py:48] [66] global_step=66, grad_norm=0.5707480311393738, loss=6.816362380981445
I0922 02:19:28.631342 139665214531328 logging_writer.py:48] [67] global_step=67, grad_norm=0.5518597960472107, loss=6.8151960372924805
I0922 02:19:28.971544 139665206138624 logging_writer.py:48] [68] global_step=68, grad_norm=0.5544971823692322, loss=6.785253047943115
I0922 02:19:29.308097 139665214531328 logging_writer.py:48] [69] global_step=69, grad_norm=0.5724858045578003, loss=6.788722515106201
I0922 02:19:29.644732 139665206138624 logging_writer.py:48] [70] global_step=70, grad_norm=0.5806716084480286, loss=6.802171230316162
I0922 02:19:29.981136 139665214531328 logging_writer.py:48] [71] global_step=71, grad_norm=0.5663958191871643, loss=6.779338836669922
I0922 02:19:30.318559 139665206138624 logging_writer.py:48] [72] global_step=72, grad_norm=0.573596179485321, loss=6.774381637573242
I0922 02:19:30.651953 139665214531328 logging_writer.py:48] [73] global_step=73, grad_norm=0.5637413263320923, loss=6.7739715576171875
I0922 02:19:30.993477 139665206138624 logging_writer.py:48] [74] global_step=74, grad_norm=0.5886464715003967, loss=6.77883768081665
I0922 02:19:31.336275 139665214531328 logging_writer.py:48] [75] global_step=75, grad_norm=0.5729111433029175, loss=6.772089958190918
I0922 02:19:31.675300 139665206138624 logging_writer.py:48] [76] global_step=76, grad_norm=0.5819228887557983, loss=6.787029266357422
I0922 02:19:32.012803 139665214531328 logging_writer.py:48] [77] global_step=77, grad_norm=0.6104819178581238, loss=6.7853264808654785
I0922 02:19:32.354122 139665206138624 logging_writer.py:48] [78] global_step=78, grad_norm=0.5820018649101257, loss=6.768108367919922
I0922 02:19:32.694478 139665214531328 logging_writer.py:48] [79] global_step=79, grad_norm=0.6141409873962402, loss=6.77360725402832
I0922 02:19:33.047869 139665206138624 logging_writer.py:48] [80] global_step=80, grad_norm=0.5921594500541687, loss=6.752407550811768
I0922 02:19:33.387082 139665214531328 logging_writer.py:48] [81] global_step=81, grad_norm=0.5820584893226624, loss=6.731908798217773
I0922 02:19:33.727360 139665206138624 logging_writer.py:48] [82] global_step=82, grad_norm=0.6051756143569946, loss=6.737958908081055
I0922 02:19:34.065803 139665214531328 logging_writer.py:48] [83] global_step=83, grad_norm=0.5840923190116882, loss=6.717936038970947
I0922 02:19:34.409648 139665206138624 logging_writer.py:48] [84] global_step=84, grad_norm=0.6003739237785339, loss=6.716670513153076
I0922 02:19:34.749880 139665214531328 logging_writer.py:48] [85] global_step=85, grad_norm=0.6050819158554077, loss=6.7265777587890625
I0922 02:19:35.090429 139665206138624 logging_writer.py:48] [86] global_step=86, grad_norm=0.6013485789299011, loss=6.737328052520752
I0922 02:19:35.431168 139665214531328 logging_writer.py:48] [87] global_step=87, grad_norm=0.6033627986907959, loss=6.734517574310303
I0922 02:19:35.767765 139665206138624 logging_writer.py:48] [88] global_step=88, grad_norm=0.6122233271598816, loss=6.712181568145752
I0922 02:19:36.106047 139665214531328 logging_writer.py:48] [89] global_step=89, grad_norm=0.584632158279419, loss=6.740074634552002
I0922 02:19:36.444031 139665206138624 logging_writer.py:48] [90] global_step=90, grad_norm=0.6191073656082153, loss=6.731237411499023
I0922 02:19:36.788964 139665214531328 logging_writer.py:48] [91] global_step=91, grad_norm=0.6080610156059265, loss=6.722024440765381
I0922 02:19:37.128278 139665206138624 logging_writer.py:48] [92] global_step=92, grad_norm=0.6153712868690491, loss=6.731483459472656
I0922 02:19:37.467905 139665214531328 logging_writer.py:48] [93] global_step=93, grad_norm=0.6220614910125732, loss=6.742156982421875
I0922 02:19:37.815823 139665206138624 logging_writer.py:48] [94] global_step=94, grad_norm=0.5893393754959106, loss=6.726300239562988
I0922 02:19:38.154518 139665214531328 logging_writer.py:48] [95] global_step=95, grad_norm=0.598603367805481, loss=6.7068095207214355
I0922 02:19:38.500253 139665206138624 logging_writer.py:48] [96] global_step=96, grad_norm=0.6130816340446472, loss=6.723642826080322
I0922 02:19:38.847668 139665214531328 logging_writer.py:48] [97] global_step=97, grad_norm=0.6167166829109192, loss=6.720266819000244
I0922 02:19:39.188981 139665206138624 logging_writer.py:48] [98] global_step=98, grad_norm=0.6147202253341675, loss=6.701395511627197
I0922 02:19:39.526614 139665214531328 logging_writer.py:48] [99] global_step=99, grad_norm=0.5932380557060242, loss=6.715245246887207
I0922 02:19:39.867171 139665206138624 logging_writer.py:48] [100] global_step=100, grad_norm=0.606461226940155, loss=6.746123313903809
I0922 02:21:54.910660 139665214531328 logging_writer.py:48] [500] global_step=500, grad_norm=0.4673129916191101, loss=6.183332920074463
I0922 02:24:43.689232 139665206138624 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.5203275084495544, loss=5.578949451446533
I0922 02:27:32.310708 139665214531328 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.42734870314598083, loss=5.0869245529174805
I0922 02:27:36.107029 139860156245824 spec.py:320] Evaluating on the training split.
I0922 02:27:43.305138 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 02:27:51.541551 139860156245824 spec.py:348] Evaluating on the test split.
I0922 02:27:53.895407 139860156245824 submission_runner.py:376] Time since start: 639.24s, 	Step: 1513, 	{'train/accuracy': 0.1953125, 'train/loss': 4.250689506530762, 'validation/accuracy': 0.17737999558448792, 'validation/loss': 4.378722190856934, 'validation/num_examples': 50000, 'test/accuracy': 0.1331000030040741, 'test/loss': 4.767331600189209, 'test/num_examples': 10000, 'score': 574.1017343997955, 'total_duration': 639.2384521961212, 'accumulated_submission_time': 574.1017343997955, 'accumulated_eval_time': 65.08575344085693, 'accumulated_logging_time': 0.028851747512817383}
I0922 02:27:53.913686 139665415857920 logging_writer.py:48] [1513] accumulated_eval_time=65.085753, accumulated_logging_time=0.028852, accumulated_submission_time=574.101734, global_step=1513, preemption_count=0, score=574.101734, test/accuracy=0.133100, test/loss=4.767332, test/num_examples=10000, total_duration=639.238452, train/accuracy=0.195312, train/loss=4.250690, validation/accuracy=0.177380, validation/loss=4.378722, validation/num_examples=50000
I0922 02:30:38.394061 139665424250624 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.3660770356655121, loss=4.8440399169921875
I0922 02:33:26.892980 139665415857920 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.33582204580307007, loss=4.457951068878174
I0922 02:36:15.414743 139665424250624 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.32605835795402527, loss=4.278512954711914
I0922 02:36:23.933049 139860156245824 spec.py:320] Evaluating on the training split.
I0922 02:36:31.384940 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 02:36:39.647096 139860156245824 spec.py:348] Evaluating on the test split.
I0922 02:36:41.992665 139860156245824 submission_runner.py:376] Time since start: 1167.34s, 	Step: 3027, 	{'train/accuracy': 0.3854830861091614, 'train/loss': 3.0441174507141113, 'validation/accuracy': 0.36032000184059143, 'validation/loss': 3.1795692443847656, 'validation/num_examples': 50000, 'test/accuracy': 0.2768000066280365, 'test/loss': 3.753525972366333, 'test/num_examples': 10000, 'score': 1084.0880839824677, 'total_duration': 1167.3357067108154, 'accumulated_submission_time': 1084.0880839824677, 'accumulated_eval_time': 83.1453173160553, 'accumulated_logging_time': 0.05786466598510742}
I0922 02:36:42.010022 139695111497472 logging_writer.py:48] [3027] accumulated_eval_time=83.145317, accumulated_logging_time=0.057865, accumulated_submission_time=1084.088084, global_step=3027, preemption_count=0, score=1084.088084, test/accuracy=0.276800, test/loss=3.753526, test/num_examples=10000, total_duration=1167.335707, train/accuracy=0.385483, train/loss=3.044117, validation/accuracy=0.360320, validation/loss=3.179569, validation/num_examples=50000
I0922 02:39:21.738276 139695119890176 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.304695725440979, loss=4.270542621612549
I0922 02:42:10.096202 139695111497472 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.2913009524345398, loss=4.142014503479004
I0922 02:44:58.463727 139695119890176 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.28086569905281067, loss=4.120832920074463
I0922 02:45:12.017146 139860156245824 spec.py:320] Evaluating on the training split.
I0922 02:45:19.429260 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 02:45:27.494910 139860156245824 spec.py:348] Evaluating on the test split.
I0922 02:45:29.851670 139860156245824 submission_runner.py:376] Time since start: 1695.19s, 	Step: 4542, 	{'train/accuracy': 0.44557157158851624, 'train/loss': 2.750640392303467, 'validation/accuracy': 0.41711997985839844, 'validation/loss': 2.892887830734253, 'validation/num_examples': 50000, 'test/accuracy': 0.313400000333786, 'test/loss': 3.5260419845581055, 'test/num_examples': 10000, 'score': 1594.0628130435944, 'total_duration': 1695.194725036621, 'accumulated_submission_time': 1594.0628130435944, 'accumulated_eval_time': 100.979816198349, 'accumulated_logging_time': 0.08539056777954102}
I0922 02:45:29.869780 139694994065152 logging_writer.py:48] [4542] accumulated_eval_time=100.979816, accumulated_logging_time=0.085391, accumulated_submission_time=1594.062813, global_step=4542, preemption_count=0, score=1594.062813, test/accuracy=0.313400, test/loss=3.526042, test/num_examples=10000, total_duration=1695.194725, train/accuracy=0.445572, train/loss=2.750640, validation/accuracy=0.417120, validation/loss=2.892888, validation/num_examples=50000
I0922 02:48:04.343005 139695002457856 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.25761717557907104, loss=4.006893634796143
I0922 02:50:52.783866 139694994065152 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.26251021027565, loss=3.991364002227783
I0922 02:53:41.190120 139695002457856 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.25395500659942627, loss=3.8813021183013916
I0922 02:54:00.152168 139860156245824 spec.py:320] Evaluating on the training split.
I0922 02:54:07.543376 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 02:54:15.843073 139860156245824 spec.py:348] Evaluating on the test split.
I0922 02:54:18.242800 139860156245824 submission_runner.py:376] Time since start: 2223.59s, 	Step: 6058, 	{'train/accuracy': 0.4934430718421936, 'train/loss': 2.4900131225585938, 'validation/accuracy': 0.46459999680519104, 'validation/loss': 2.642608880996704, 'validation/num_examples': 50000, 'test/accuracy': 0.35120001435279846, 'test/loss': 3.2795279026031494, 'test/num_examples': 10000, 'score': 2104.3116278648376, 'total_duration': 2223.5858500003815, 'accumulated_submission_time': 2104.3116278648376, 'accumulated_eval_time': 119.07040405273438, 'accumulated_logging_time': 0.11498904228210449}
I0922 02:54:18.260529 139694994065152 logging_writer.py:48] [6058] accumulated_eval_time=119.070404, accumulated_logging_time=0.114989, accumulated_submission_time=2104.311628, global_step=6058, preemption_count=0, score=2104.311628, test/accuracy=0.351200, test/loss=3.279528, test/num_examples=10000, total_duration=2223.585850, train/accuracy=0.493443, train/loss=2.490013, validation/accuracy=0.464600, validation/loss=2.642609, validation/num_examples=50000
I0922 02:56:47.395876 139695103104768 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.2444130778312683, loss=3.9609313011169434
I0922 02:59:35.777504 139694994065152 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.24503953754901886, loss=3.8970072269439697
I0922 03:02:24.209701 139695103104768 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.24762171506881714, loss=3.9344396591186523
I0922 03:02:48.557453 139860156245824 spec.py:320] Evaluating on the training split.
I0922 03:02:55.763235 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 03:03:03.994701 139860156245824 spec.py:348] Evaluating on the test split.
I0922 03:03:06.343260 139860156245824 submission_runner.py:376] Time since start: 2751.69s, 	Step: 7574, 	{'train/accuracy': 0.4878627061843872, 'train/loss': 2.394216775894165, 'validation/accuracy': 0.46469998359680176, 'validation/loss': 2.541215181350708, 'validation/num_examples': 50000, 'test/accuracy': 0.35850000381469727, 'test/loss': 3.163653612136841, 'test/num_examples': 10000, 'score': 2614.577480316162, 'total_duration': 2751.686309337616, 'accumulated_submission_time': 2614.577480316162, 'accumulated_eval_time': 136.8561680316925, 'accumulated_logging_time': 0.14209389686584473}
I0922 03:03:06.361442 139695027635968 logging_writer.py:48] [7574] accumulated_eval_time=136.856168, accumulated_logging_time=0.142094, accumulated_submission_time=2614.577480, global_step=7574, preemption_count=0, score=2614.577480, test/accuracy=0.358500, test/loss=3.163654, test/num_examples=10000, total_duration=2751.686309, train/accuracy=0.487863, train/loss=2.394217, validation/accuracy=0.464700, validation/loss=2.541215, validation/num_examples=50000
I0922 03:05:30.181064 139695128282880 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.23623338341712952, loss=3.8022117614746094
I0922 03:08:18.638231 139695027635968 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.2404605597257614, loss=3.8431081771850586
I0922 03:11:07.012866 139695128282880 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.24200439453125, loss=3.8403048515319824
I0922 03:11:36.378474 139860156245824 spec.py:320] Evaluating on the training split.
I0922 03:11:43.860162 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 03:11:52.158200 139860156245824 spec.py:348] Evaluating on the test split.
I0922 03:11:54.495271 139860156245824 submission_runner.py:376] Time since start: 3279.84s, 	Step: 9089, 	{'train/accuracy': 0.5937898755073547, 'train/loss': 1.994570016860962, 'validation/accuracy': 0.5184400081634521, 'validation/loss': 2.3491361141204834, 'validation/num_examples': 50000, 'test/accuracy': 0.40130001306533813, 'test/loss': 2.987217426300049, 'test/num_examples': 10000, 'score': 3124.5621304512024, 'total_duration': 3279.838321208954, 'accumulated_submission_time': 3124.5621304512024, 'accumulated_eval_time': 154.9729254245758, 'accumulated_logging_time': 0.17090845108032227}
I0922 03:11:54.513540 139695103104768 logging_writer.py:48] [9089] accumulated_eval_time=154.972925, accumulated_logging_time=0.170908, accumulated_submission_time=3124.562130, global_step=9089, preemption_count=0, score=3124.562130, test/accuracy=0.401300, test/loss=2.987217, test/num_examples=10000, total_duration=3279.838321, train/accuracy=0.593790, train/loss=1.994570, validation/accuracy=0.518440, validation/loss=2.349136, validation/num_examples=50000
I0922 03:14:13.336895 139695111497472 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.2360214740037918, loss=3.8297343254089355
I0922 03:17:01.684399 139695103104768 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.24112164974212646, loss=3.7627735137939453
I0922 03:19:50.080285 139695111497472 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.23935744166374207, loss=3.7464938163757324
I0922 03:20:24.806937 139860156245824 spec.py:320] Evaluating on the training split.
I0922 03:20:32.276997 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 03:20:40.788489 139860156245824 spec.py:348] Evaluating on the test split.
I0922 03:20:43.140290 139860156245824 submission_runner.py:376] Time since start: 3808.48s, 	Step: 10605, 	{'train/accuracy': 0.5725645422935486, 'train/loss': 2.060797691345215, 'validation/accuracy': 0.5168799757957458, 'validation/loss': 2.3233985900878906, 'validation/num_examples': 50000, 'test/accuracy': 0.3961000144481659, 'test/loss': 2.9845314025878906, 'test/num_examples': 10000, 'score': 3634.8241727352142, 'total_duration': 3808.483343601227, 'accumulated_submission_time': 3634.8241727352142, 'accumulated_eval_time': 173.30623936653137, 'accumulated_logging_time': 0.1988847255706787}
I0922 03:20:43.159681 139695010850560 logging_writer.py:48] [10605] accumulated_eval_time=173.306239, accumulated_logging_time=0.198885, accumulated_submission_time=3634.824173, global_step=10605, preemption_count=0, score=3634.824173, test/accuracy=0.396100, test/loss=2.984531, test/num_examples=10000, total_duration=3808.483344, train/accuracy=0.572565, train/loss=2.060798, validation/accuracy=0.516880, validation/loss=2.323399, validation/num_examples=50000
I0922 03:22:56.559022 139695019243264 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.2388836145401001, loss=3.7876718044281006
I0922 03:25:44.881546 139695010850560 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.2353736162185669, loss=3.71708083152771
I0922 03:28:33.359690 139695019243264 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.23495420813560486, loss=3.710355758666992
I0922 03:29:13.212811 139860156245824 spec.py:320] Evaluating on the training split.
I0922 03:29:20.540498 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 03:29:29.050934 139860156245824 spec.py:348] Evaluating on the test split.
I0922 03:29:31.439535 139860156245824 submission_runner.py:376] Time since start: 4336.78s, 	Step: 12120, 	{'train/accuracy': 0.5725446343421936, 'train/loss': 2.088163137435913, 'validation/accuracy': 0.5295799970626831, 'validation/loss': 2.301417589187622, 'validation/num_examples': 50000, 'test/accuracy': 0.4052000045776367, 'test/loss': 2.976471424102783, 'test/num_examples': 10000, 'score': 4144.845808506012, 'total_duration': 4336.782471656799, 'accumulated_submission_time': 4144.845808506012, 'accumulated_eval_time': 191.53280925750732, 'accumulated_logging_time': 0.22790145874023438}
I0922 03:29:31.458577 139694994065152 logging_writer.py:48] [12120] accumulated_eval_time=191.532809, accumulated_logging_time=0.227901, accumulated_submission_time=4144.845809, global_step=12120, preemption_count=0, score=4144.845809, test/accuracy=0.405200, test/loss=2.976471, test/num_examples=10000, total_duration=4336.782472, train/accuracy=0.572545, train/loss=2.088163, validation/accuracy=0.529580, validation/loss=2.301418, validation/num_examples=50000
I0922 03:31:39.695523 139695002457856 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.25243160128593445, loss=3.6923952102661133
I0922 03:34:27.944028 139694994065152 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.2545066177845001, loss=3.663698434829712
I0922 03:37:16.389588 139695002457856 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.24395152926445007, loss=3.736361265182495
I0922 03:38:01.519639 139860156245824 spec.py:320] Evaluating on the training split.
I0922 03:38:08.869287 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 03:38:17.273918 139860156245824 spec.py:348] Evaluating on the test split.
I0922 03:38:19.625889 139860156245824 submission_runner.py:376] Time since start: 4864.97s, 	Step: 13636, 	{'train/accuracy': 0.561922013759613, 'train/loss': 2.0995981693267822, 'validation/accuracy': 0.5209800004959106, 'validation/loss': 2.287593126296997, 'validation/num_examples': 50000, 'test/accuracy': 0.4050000309944153, 'test/loss': 2.9458823204040527, 'test/num_examples': 10000, 'score': 4654.8745040893555, 'total_duration': 4864.968941926956, 'accumulated_submission_time': 4654.8745040893555, 'accumulated_eval_time': 209.63903427124023, 'accumulated_logging_time': 0.2571892738342285}
I0922 03:38:19.651754 139695002457856 logging_writer.py:48] [13636] accumulated_eval_time=209.639034, accumulated_logging_time=0.257189, accumulated_submission_time=4654.874504, global_step=13636, preemption_count=0, score=4654.874504, test/accuracy=0.405000, test/loss=2.945882, test/num_examples=10000, total_duration=4864.968942, train/accuracy=0.561922, train/loss=2.099598, validation/accuracy=0.520980, validation/loss=2.287593, validation/num_examples=50000
I0922 03:40:22.653342 139695111497472 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.25055015087127686, loss=3.6849265098571777
I0922 03:43:11.130771 139695002457856 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.23886436223983765, loss=3.6408798694610596
I0922 03:45:59.606525 139695111497472 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.24253258109092712, loss=3.745573043823242
I0922 03:46:49.885586 139860156245824 spec.py:320] Evaluating on the training split.
I0922 03:46:57.121024 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 03:47:05.505293 139860156245824 spec.py:348] Evaluating on the test split.
I0922 03:47:07.839840 139860156245824 submission_runner.py:376] Time since start: 5393.18s, 	Step: 15151, 	{'train/accuracy': 0.5607661008834839, 'train/loss': 2.173295259475708, 'validation/accuracy': 0.5255399942398071, 'validation/loss': 2.345304250717163, 'validation/num_examples': 50000, 'test/accuracy': 0.40950003266334534, 'test/loss': 3.0255024433135986, 'test/num_examples': 10000, 'score': 5165.076518774033, 'total_duration': 5393.182889699936, 'accumulated_submission_time': 5165.076518774033, 'accumulated_eval_time': 227.59325218200684, 'accumulated_logging_time': 0.2931509017944336}
I0922 03:47:07.859633 139694994065152 logging_writer.py:48] [15151] accumulated_eval_time=227.593252, accumulated_logging_time=0.293151, accumulated_submission_time=5165.076519, global_step=15151, preemption_count=0, score=5165.076519, test/accuracy=0.409500, test/loss=3.025502, test/num_examples=10000, total_duration=5393.182890, train/accuracy=0.560766, train/loss=2.173295, validation/accuracy=0.525540, validation/loss=2.345304, validation/num_examples=50000
I0922 03:49:05.816235 139695002457856 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.24513058364391327, loss=3.624505043029785
I0922 03:51:54.160636 139694994065152 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.2525622546672821, loss=3.6250712871551514
I0922 03:54:42.463304 139695002457856 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.24958357214927673, loss=3.656290292739868
I0922 03:55:38.167970 139860156245824 spec.py:320] Evaluating on the training split.
I0922 03:55:45.713920 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 03:55:53.818780 139860156245824 spec.py:348] Evaluating on the test split.
I0922 03:55:56.198247 139860156245824 submission_runner.py:376] Time since start: 5921.54s, 	Step: 16667, 	{'train/accuracy': 0.5772281289100647, 'train/loss': 2.0155012607574463, 'validation/accuracy': 0.542739987373352, 'validation/loss': 2.1865999698638916, 'validation/num_examples': 50000, 'test/accuracy': 0.42110002040863037, 'test/loss': 2.873884439468384, 'test/num_examples': 10000, 'score': 5675.350479841232, 'total_duration': 5921.541299819946, 'accumulated_submission_time': 5675.350479841232, 'accumulated_eval_time': 245.62349653244019, 'accumulated_logging_time': 0.32523465156555176}
I0922 03:55:56.229724 139695010850560 logging_writer.py:48] [16667] accumulated_eval_time=245.623497, accumulated_logging_time=0.325235, accumulated_submission_time=5675.350480, global_step=16667, preemption_count=0, score=5675.350480, test/accuracy=0.421100, test/loss=2.873884, test/num_examples=10000, total_duration=5921.541300, train/accuracy=0.577228, train/loss=2.015501, validation/accuracy=0.542740, validation/loss=2.186600, validation/num_examples=50000
I0922 03:57:48.603914 139695119890176 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.24937961995601654, loss=3.667402744293213
I0922 04:00:37.034218 139695010850560 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.2442348152399063, loss=3.6477200984954834
I0922 04:03:25.440372 139695119890176 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.2484206259250641, loss=3.592195510864258
I0922 04:04:26.509780 139860156245824 spec.py:320] Evaluating on the training split.
I0922 04:04:33.829785 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 04:04:42.133758 139860156245824 spec.py:348] Evaluating on the test split.
I0922 04:04:44.511814 139860156245824 submission_runner.py:376] Time since start: 6449.85s, 	Step: 18183, 	{'train/accuracy': 0.6164700388908386, 'train/loss': 1.8166255950927734, 'validation/accuracy': 0.5374599695205688, 'validation/loss': 2.1936559677124023, 'validation/num_examples': 50000, 'test/accuracy': 0.42830002307891846, 'test/loss': 2.824901819229126, 'test/num_examples': 10000, 'score': 6185.598520517349, 'total_duration': 6449.854868412018, 'accumulated_submission_time': 6185.598520517349, 'accumulated_eval_time': 263.62550163269043, 'accumulated_logging_time': 0.36657214164733887}
I0922 04:04:44.533262 139694994065152 logging_writer.py:48] [18183] accumulated_eval_time=263.625502, accumulated_logging_time=0.366572, accumulated_submission_time=6185.598521, global_step=18183, preemption_count=0, score=6185.598521, test/accuracy=0.428300, test/loss=2.824902, test/num_examples=10000, total_duration=6449.854868, train/accuracy=0.616470, train/loss=1.816626, validation/accuracy=0.537460, validation/loss=2.193656, validation/num_examples=50000
I0922 04:06:31.589073 139695002457856 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.2527046501636505, loss=3.639880418777466
I0922 04:09:19.886496 139694994065152 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.2603418827056885, loss=3.6154699325561523
I0922 04:12:08.249220 139695002457856 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.26638713479042053, loss=3.640279531478882
I0922 04:13:14.712892 139860156245824 spec.py:320] Evaluating on the training split.
I0922 04:13:22.127537 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 04:13:30.339588 139860156245824 spec.py:348] Evaluating on the test split.
I0922 04:13:32.696894 139860156245824 submission_runner.py:376] Time since start: 6978.04s, 	Step: 19699, 	{'train/accuracy': 0.6040537357330322, 'train/loss': 1.8572139739990234, 'validation/accuracy': 0.54721999168396, 'validation/loss': 2.1430695056915283, 'validation/num_examples': 50000, 'test/accuracy': 0.42500001192092896, 'test/loss': 2.8068933486938477, 'test/num_examples': 10000, 'score': 6695.745776891708, 'total_duration': 6978.039947986603, 'accumulated_submission_time': 6695.745776891708, 'accumulated_eval_time': 281.6094694137573, 'accumulated_logging_time': 0.3982985019683838}
I0922 04:13:32.716302 139695002457856 logging_writer.py:48] [19699] accumulated_eval_time=281.609469, accumulated_logging_time=0.398299, accumulated_submission_time=6695.745777, global_step=19699, preemption_count=0, score=6695.745777, test/accuracy=0.425000, test/loss=2.806893, test/num_examples=10000, total_duration=6978.039948, train/accuracy=0.604054, train/loss=1.857214, validation/accuracy=0.547220, validation/loss=2.143070, validation/num_examples=50000
I0922 04:15:14.399456 139695010850560 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.25010499358177185, loss=3.5855512619018555
I0922 04:18:02.719383 139695002457856 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.24418452382087708, loss=3.5547609329223633
I0922 04:20:51.049315 139695010850560 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.2640964686870575, loss=3.6136796474456787
I0922 04:22:02.853061 139860156245824 spec.py:320] Evaluating on the training split.
I0922 04:22:10.501853 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 04:22:18.870888 139860156245824 spec.py:348] Evaluating on the test split.
I0922 04:22:21.195092 139860156245824 submission_runner.py:376] Time since start: 7506.54s, 	Step: 21215, 	{'train/accuracy': 0.6070830821990967, 'train/loss': 1.8662636280059814, 'validation/accuracy': 0.5557399988174438, 'validation/loss': 2.107875347137451, 'validation/num_examples': 50000, 'test/accuracy': 0.43380001187324524, 'test/loss': 2.7795403003692627, 'test/num_examples': 10000, 'score': 7205.85010433197, 'total_duration': 7506.538147687912, 'accumulated_submission_time': 7205.85010433197, 'accumulated_eval_time': 299.95147609710693, 'accumulated_logging_time': 0.42829036712646484}
I0922 04:22:21.217627 139694994065152 logging_writer.py:48] [21215] accumulated_eval_time=299.951476, accumulated_logging_time=0.428290, accumulated_submission_time=7205.850104, global_step=21215, preemption_count=0, score=7205.850104, test/accuracy=0.433800, test/loss=2.779540, test/num_examples=10000, total_duration=7506.538148, train/accuracy=0.607083, train/loss=1.866264, validation/accuracy=0.555740, validation/loss=2.107875, validation/num_examples=50000
I0922 04:23:57.514200 139695002457856 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.2630632519721985, loss=3.57889461517334
I0922 04:26:45.907836 139694994065152 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.2558261752128601, loss=3.648192882537842
I0922 04:29:34.368963 139695002457856 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.2539771795272827, loss=3.650722026824951
I0922 04:30:51.499114 139860156245824 spec.py:320] Evaluating on the training split.
I0922 04:30:59.057538 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 04:31:11.528862 139860156245824 spec.py:348] Evaluating on the test split.
I0922 04:31:13.861357 139860156245824 submission_runner.py:376] Time since start: 8039.20s, 	Step: 22731, 	{'train/accuracy': 0.6033760905265808, 'train/loss': 1.921431064605713, 'validation/accuracy': 0.5582799911499023, 'validation/loss': 2.1212737560272217, 'validation/num_examples': 50000, 'test/accuracy': 0.4434000253677368, 'test/loss': 2.7690272331237793, 'test/num_examples': 10000, 'score': 7716.098157405853, 'total_duration': 8039.20441031456, 'accumulated_submission_time': 7716.098157405853, 'accumulated_eval_time': 322.3136878013611, 'accumulated_logging_time': 0.46224427223205566}
I0922 04:31:13.882284 139695002457856 logging_writer.py:48] [22731] accumulated_eval_time=322.313688, accumulated_logging_time=0.462244, accumulated_submission_time=7716.098157, global_step=22731, preemption_count=0, score=7716.098157, test/accuracy=0.443400, test/loss=2.769027, test/num_examples=10000, total_duration=8039.204410, train/accuracy=0.603376, train/loss=1.921431, validation/accuracy=0.558280, validation/loss=2.121274, validation/num_examples=50000
I0922 04:32:44.857041 139695111497472 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.25409722328186035, loss=3.578967332839966
I0922 04:35:33.191293 139695002457856 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.2620818316936493, loss=3.6161015033721924
I0922 04:38:21.586597 139695111497472 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.2551341950893402, loss=3.6091043949127197
I0922 04:39:44.196996 139860156245824 spec.py:320] Evaluating on the training split.
I0922 04:39:51.911127 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 04:40:01.286929 139860156245824 spec.py:348] Evaluating on the test split.
I0922 04:40:03.658544 139860156245824 submission_runner.py:376] Time since start: 8569.00s, 	Step: 24247, 	{'train/accuracy': 0.6059072017669678, 'train/loss': 1.8381973505020142, 'validation/accuracy': 0.5631799697875977, 'validation/loss': 2.0456507205963135, 'validation/num_examples': 50000, 'test/accuracy': 0.43810001015663147, 'test/loss': 2.73285174369812, 'test/num_examples': 10000, 'score': 8226.381306648254, 'total_duration': 8569.001594305038, 'accumulated_submission_time': 8226.381306648254, 'accumulated_eval_time': 341.7752058506012, 'accumulated_logging_time': 0.4927811622619629}
I0922 04:40:03.687069 139695019243264 logging_writer.py:48] [24247] accumulated_eval_time=341.775206, accumulated_logging_time=0.492781, accumulated_submission_time=8226.381307, global_step=24247, preemption_count=0, score=8226.381307, test/accuracy=0.438100, test/loss=2.732852, test/num_examples=10000, total_duration=8569.001594, train/accuracy=0.605907, train/loss=1.838197, validation/accuracy=0.563180, validation/loss=2.045651, validation/num_examples=50000
I0922 04:41:29.221593 139695027635968 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.2530219256877899, loss=3.5498695373535156
I0922 04:44:17.552294 139695019243264 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.2506568431854248, loss=3.5372090339660645
I0922 04:47:05.950265 139695027635968 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.25161898136138916, loss=3.488940715789795
I0922 04:48:33.948749 139860156245824 spec.py:320] Evaluating on the training split.
I0922 04:48:41.684619 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 04:48:51.791074 139860156245824 spec.py:348] Evaluating on the test split.
I0922 04:48:54.102123 139860156245824 submission_runner.py:376] Time since start: 9099.45s, 	Step: 25763, 	{'train/accuracy': 0.5989516973495483, 'train/loss': 1.9136871099472046, 'validation/accuracy': 0.5589799880981445, 'validation/loss': 2.093651294708252, 'validation/num_examples': 50000, 'test/accuracy': 0.43700000643730164, 'test/loss': 2.7729973793029785, 'test/num_examples': 10000, 'score': 8736.60784649849, 'total_duration': 9099.445104598999, 'accumulated_submission_time': 8736.60784649849, 'accumulated_eval_time': 361.92847990989685, 'accumulated_logging_time': 0.5344793796539307}
I0922 04:48:54.123305 139695019243264 logging_writer.py:48] [25763] accumulated_eval_time=361.928480, accumulated_logging_time=0.534479, accumulated_submission_time=8736.607846, global_step=25763, preemption_count=0, score=8736.607846, test/accuracy=0.437000, test/loss=2.772997, test/num_examples=10000, total_duration=9099.445105, train/accuracy=0.598952, train/loss=1.913687, validation/accuracy=0.558980, validation/loss=2.093651, validation/num_examples=50000
I0922 04:50:14.262242 139695027635968 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.25035393238067627, loss=3.521360158920288
I0922 04:53:02.520190 139695019243264 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.2533421814441681, loss=3.523070812225342
I0922 04:55:50.829901 139695027635968 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.2514823079109192, loss=3.5381155014038086
I0922 04:57:24.166325 139860156245824 spec.py:320] Evaluating on the training split.
I0922 04:57:32.291970 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 04:57:42.714519 139860156245824 spec.py:348] Evaluating on the test split.
I0922 04:57:45.177061 139860156245824 submission_runner.py:376] Time since start: 9630.52s, 	Step: 27279, 	{'train/accuracy': 0.6574457883834839, 'train/loss': 1.647836446762085, 'validation/accuracy': 0.5787799954414368, 'validation/loss': 2.012053966522217, 'validation/num_examples': 50000, 'test/accuracy': 0.458700031042099, 'test/loss': 2.6441469192504883, 'test/num_examples': 10000, 'score': 9246.617577314377, 'total_duration': 9630.520079612732, 'accumulated_submission_time': 9246.617577314377, 'accumulated_eval_time': 382.93916296958923, 'accumulated_logging_time': 0.567162036895752}
I0922 04:57:45.199061 139695019243264 logging_writer.py:48] [27279] accumulated_eval_time=382.939163, accumulated_logging_time=0.567162, accumulated_submission_time=9246.617577, global_step=27279, preemption_count=0, score=9246.617577, test/accuracy=0.458700, test/loss=2.644147, test/num_examples=10000, total_duration=9630.520080, train/accuracy=0.657446, train/loss=1.647836, validation/accuracy=0.578780, validation/loss=2.012054, validation/num_examples=50000
I0922 04:58:59.841230 139695103104768 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.24556532502174377, loss=3.4618778228759766
I0922 05:01:48.261262 139695019243264 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.2609524130821228, loss=3.4757680892944336
I0922 05:04:36.464543 139695103104768 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.24610334634780884, loss=3.4072132110595703
I0922 05:06:15.281255 139860156245824 spec.py:320] Evaluating on the training split.
I0922 05:06:23.303421 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 05:06:33.364177 139860156245824 spec.py:348] Evaluating on the test split.
I0922 05:06:35.682224 139860156245824 submission_runner.py:376] Time since start: 10161.03s, 	Step: 28795, 	{'train/accuracy': 0.6138193607330322, 'train/loss': 1.835744857788086, 'validation/accuracy': 0.5630199909210205, 'validation/loss': 2.0825109481811523, 'validation/num_examples': 50000, 'test/accuracy': 0.44460001587867737, 'test/loss': 2.743582248687744, 'test/num_examples': 10000, 'score': 9756.666748046875, 'total_duration': 10161.025271654129, 'accumulated_submission_time': 9756.666748046875, 'accumulated_eval_time': 403.340101480484, 'accumulated_logging_time': 0.6002480983734131}
I0922 05:06:35.703313 139695019243264 logging_writer.py:48] [28795] accumulated_eval_time=403.340101, accumulated_logging_time=0.600248, accumulated_submission_time=9756.666748, global_step=28795, preemption_count=0, score=9756.666748, test/accuracy=0.444600, test/loss=2.743582, test/num_examples=10000, total_duration=10161.025272, train/accuracy=0.613819, train/loss=1.835745, validation/accuracy=0.563020, validation/loss=2.082511, validation/num_examples=50000
I0922 05:07:45.024571 139695027635968 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.2649392783641815, loss=3.577345371246338
I0922 05:10:33.375067 139695019243264 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.25859642028808594, loss=3.494969129562378
I0922 05:13:21.756375 139695027635968 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.2591465413570404, loss=3.428056478500366
I0922 05:15:05.809146 139860156245824 spec.py:320] Evaluating on the training split.
I0922 05:15:14.093059 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 05:15:24.786319 139860156245824 spec.py:348] Evaluating on the test split.
I0922 05:15:27.110257 139860156245824 submission_runner.py:376] Time since start: 10692.45s, 	Step: 30311, 	{'train/accuracy': 0.6407445669174194, 'train/loss': 1.7555533647537231, 'validation/accuracy': 0.5862199664115906, 'validation/loss': 1.996310830116272, 'validation/num_examples': 50000, 'test/accuracy': 0.4561000168323517, 'test/loss': 2.664827823638916, 'test/num_examples': 10000, 'score': 10266.739155769348, 'total_duration': 10692.453307390213, 'accumulated_submission_time': 10266.739155769348, 'accumulated_eval_time': 424.641179561615, 'accumulated_logging_time': 0.6327004432678223}
I0922 05:15:27.132304 139695002457856 logging_writer.py:48] [30311] accumulated_eval_time=424.641180, accumulated_logging_time=0.632700, accumulated_submission_time=10266.739156, global_step=30311, preemption_count=0, score=10266.739156, test/accuracy=0.456100, test/loss=2.664828, test/num_examples=10000, total_duration=10692.453307, train/accuracy=0.640745, train/loss=1.755553, validation/accuracy=0.586220, validation/loss=1.996311, validation/num_examples=50000
I0922 05:16:31.088616 139695010850560 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.2543216645717621, loss=3.474597454071045
I0922 05:19:19.356237 139695002457856 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.25875207781791687, loss=3.476217746734619
I0922 05:22:07.717392 139695010850560 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.2574065923690796, loss=3.4527370929718018
I0922 05:23:57.218682 139860156245824 spec.py:320] Evaluating on the training split.
I0922 05:24:05.631481 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 05:24:16.103660 139860156245824 spec.py:348] Evaluating on the test split.
I0922 05:24:18.401229 139860156245824 submission_runner.py:376] Time since start: 11223.74s, 	Step: 31827, 	{'train/accuracy': 0.6068040132522583, 'train/loss': 1.8650717735290527, 'validation/accuracy': 0.5614399909973145, 'validation/loss': 2.0938620567321777, 'validation/num_examples': 50000, 'test/accuracy': 0.4488000273704529, 'test/loss': 2.717355489730835, 'test/num_examples': 10000, 'score': 10776.79148197174, 'total_duration': 11223.744272947311, 'accumulated_submission_time': 10776.79148197174, 'accumulated_eval_time': 445.8237051963806, 'accumulated_logging_time': 0.666865348815918}
I0922 05:24:18.423246 139694994065152 logging_writer.py:48] [31827] accumulated_eval_time=445.823705, accumulated_logging_time=0.666865, accumulated_submission_time=10776.791482, global_step=31827, preemption_count=0, score=10776.791482, test/accuracy=0.448800, test/loss=2.717355, test/num_examples=10000, total_duration=11223.744273, train/accuracy=0.606804, train/loss=1.865072, validation/accuracy=0.561440, validation/loss=2.093862, validation/num_examples=50000
I0922 05:25:17.059536 139695002457856 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.2591579854488373, loss=3.518198013305664
I0922 05:28:05.357218 139694994065152 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.26122236251831055, loss=3.445971727371216
I0922 05:30:53.822247 139695002457856 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.2703922688961029, loss=3.5580735206604004
I0922 05:32:48.437150 139860156245824 spec.py:320] Evaluating on the training split.
I0922 05:32:57.018812 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 05:33:07.540239 139860156245824 spec.py:348] Evaluating on the test split.
I0922 05:33:09.925691 139860156245824 submission_runner.py:376] Time since start: 11755.27s, 	Step: 33342, 	{'train/accuracy': 0.6131018400192261, 'train/loss': 1.890493392944336, 'validation/accuracy': 0.571399986743927, 'validation/loss': 2.0862486362457275, 'validation/num_examples': 50000, 'test/accuracy': 0.4457000195980072, 'test/loss': 2.766350030899048, 'test/num_examples': 10000, 'score': 11286.773390769958, 'total_duration': 11755.268727779388, 'accumulated_submission_time': 11286.773390769958, 'accumulated_eval_time': 467.31220626831055, 'accumulated_logging_time': 0.6990752220153809}
I0922 05:33:09.948429 139695010850560 logging_writer.py:48] [33342] accumulated_eval_time=467.312206, accumulated_logging_time=0.699075, accumulated_submission_time=11286.773391, global_step=33342, preemption_count=0, score=11286.773391, test/accuracy=0.445700, test/loss=2.766350, test/num_examples=10000, total_duration=11755.268728, train/accuracy=0.613102, train/loss=1.890493, validation/accuracy=0.571400, validation/loss=2.086249, validation/num_examples=50000
I0922 05:34:03.422652 139695019243264 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.2621799409389496, loss=3.4738481044769287
I0922 05:36:51.653742 139695010850560 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.2639196217060089, loss=3.5451128482818604
I0922 05:39:39.984763 139695019243264 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.26218369603157043, loss=3.4697158336639404
I0922 05:41:40.136091 139860156245824 spec.py:320] Evaluating on the training split.
I0922 05:41:48.950892 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 05:41:59.710515 139860156245824 spec.py:348] Evaluating on the test split.
I0922 05:42:02.070435 139860156245824 submission_runner.py:376] Time since start: 12287.41s, 	Step: 34859, 	{'train/accuracy': 0.6300023794174194, 'train/loss': 1.8194433450698853, 'validation/accuracy': 0.5906800031661987, 'validation/loss': 2.012418031692505, 'validation/num_examples': 50000, 'test/accuracy': 0.46310001611709595, 'test/loss': 2.6821506023406982, 'test/num_examples': 10000, 'score': 11796.92868757248, 'total_duration': 12287.413486480713, 'accumulated_submission_time': 11796.92868757248, 'accumulated_eval_time': 489.24654841423035, 'accumulated_logging_time': 0.732133150100708}
I0922 05:42:02.092161 139695119890176 logging_writer.py:48] [34859] accumulated_eval_time=489.246548, accumulated_logging_time=0.732133, accumulated_submission_time=11796.928688, global_step=34859, preemption_count=0, score=11796.928688, test/accuracy=0.463100, test/loss=2.682151, test/num_examples=10000, total_duration=12287.413486, train/accuracy=0.630002, train/loss=1.819443, validation/accuracy=0.590680, validation/loss=2.012418, validation/num_examples=50000
I0922 05:42:49.955346 139695128282880 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.26747626066207886, loss=3.4961469173431396
I0922 05:45:38.255526 139695119890176 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.26244649291038513, loss=3.497314214706421
I0922 05:48:26.513137 139695128282880 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.2598540186882019, loss=3.495804786682129
I0922 05:50:32.267404 139860156245824 spec.py:320] Evaluating on the training split.
I0922 05:50:41.065067 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 05:50:51.804901 139860156245824 spec.py:348] Evaluating on the test split.
I0922 05:50:54.151075 139860156245824 submission_runner.py:376] Time since start: 12819.49s, 	Step: 36375, 	{'train/accuracy': 0.642578125, 'train/loss': 1.7200690507888794, 'validation/accuracy': 0.5697199702262878, 'validation/loss': 2.0555689334869385, 'validation/num_examples': 50000, 'test/accuracy': 0.44760000705718994, 'test/loss': 2.7521586418151855, 'test/num_examples': 10000, 'score': 12307.070878267288, 'total_duration': 12819.494129180908, 'accumulated_submission_time': 12307.070878267288, 'accumulated_eval_time': 511.1301953792572, 'accumulated_logging_time': 0.7648098468780518}
I0922 05:50:54.173532 139694994065152 logging_writer.py:48] [36375] accumulated_eval_time=511.130195, accumulated_logging_time=0.764810, accumulated_submission_time=12307.070878, global_step=36375, preemption_count=0, score=12307.070878, test/accuracy=0.447600, test/loss=2.752159, test/num_examples=10000, total_duration=12819.494129, train/accuracy=0.642578, train/loss=1.720069, validation/accuracy=0.569720, validation/loss=2.055569, validation/num_examples=50000
I0922 05:51:36.535702 139695002457856 logging_writer.py:48] [36500] global_step=36500, grad_norm=0.2725842595100403, loss=3.5562260150909424
I0922 05:54:24.899132 139694994065152 logging_writer.py:48] [37000] global_step=37000, grad_norm=0.26285237073898315, loss=3.447462797164917
I0922 05:57:13.239198 139695002457856 logging_writer.py:48] [37500] global_step=37500, grad_norm=0.2670508623123169, loss=3.5106372833251953
I0922 05:59:24.337436 139860156245824 spec.py:320] Evaluating on the training split.
I0922 05:59:32.510759 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 05:59:42.841140 139860156245824 spec.py:348] Evaluating on the test split.
I0922 05:59:45.187047 139860156245824 submission_runner.py:376] Time since start: 13350.53s, 	Step: 37891, 	{'train/accuracy': 0.6353635191917419, 'train/loss': 1.7260973453521729, 'validation/accuracy': 0.5757399797439575, 'validation/loss': 2.009341239929199, 'validation/num_examples': 50000, 'test/accuracy': 0.4529000222682953, 'test/loss': 2.693175792694092, 'test/num_examples': 10000, 'score': 12817.198693037033, 'total_duration': 13350.530089378357, 'accumulated_submission_time': 12817.198693037033, 'accumulated_eval_time': 531.9797699451447, 'accumulated_logging_time': 0.801306962966919}
I0922 05:59:45.208289 139695111497472 logging_writer.py:48] [37891] accumulated_eval_time=531.979770, accumulated_logging_time=0.801307, accumulated_submission_time=12817.198693, global_step=37891, preemption_count=0, score=12817.198693, test/accuracy=0.452900, test/loss=2.693176, test/num_examples=10000, total_duration=13350.530089, train/accuracy=0.635364, train/loss=1.726097, validation/accuracy=0.575740, validation/loss=2.009341, validation/num_examples=50000
I0922 06:00:22.238831 139695119890176 logging_writer.py:48] [38000] global_step=38000, grad_norm=0.268122136592865, loss=3.434720993041992
I0922 06:03:10.580658 139695111497472 logging_writer.py:48] [38500] global_step=38500, grad_norm=0.2682720422744751, loss=3.4517855644226074
I0922 06:05:58.805136 139695119890176 logging_writer.py:48] [39000] global_step=39000, grad_norm=0.2765069603919983, loss=3.407440185546875
I0922 06:08:15.242614 139860156245824 spec.py:320] Evaluating on the training split.
I0922 06:08:23.380206 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 06:08:33.775790 139860156245824 spec.py:348] Evaluating on the test split.
I0922 06:08:36.131024 139860156245824 submission_runner.py:376] Time since start: 13881.47s, 	Step: 39407, 	{'train/accuracy': 0.6371970772743225, 'train/loss': 1.74796462059021, 'validation/accuracy': 0.5947200059890747, 'validation/loss': 1.970801830291748, 'validation/num_examples': 50000, 'test/accuracy': 0.46790000796318054, 'test/loss': 2.6150336265563965, 'test/num_examples': 10000, 'score': 13327.200963020325, 'total_duration': 13881.474056243896, 'accumulated_submission_time': 13327.200963020325, 'accumulated_eval_time': 552.8681490421295, 'accumulated_logging_time': 0.8328936100006104}
I0922 06:08:36.155405 139695010850560 logging_writer.py:48] [39407] accumulated_eval_time=552.868149, accumulated_logging_time=0.832894, accumulated_submission_time=13327.200963, global_step=39407, preemption_count=0, score=13327.200963, test/accuracy=0.467900, test/loss=2.615034, test/num_examples=10000, total_duration=13881.474056, train/accuracy=0.637197, train/loss=1.747965, validation/accuracy=0.594720, validation/loss=1.970802, validation/num_examples=50000
I0922 06:09:07.760093 139695019243264 logging_writer.py:48] [39500] global_step=39500, grad_norm=0.26628684997558594, loss=3.438408136367798
I0922 06:11:56.073757 139695010850560 logging_writer.py:48] [40000] global_step=40000, grad_norm=0.27268821001052856, loss=3.5340473651885986
I0922 06:14:44.345562 139695019243264 logging_writer.py:48] [40500] global_step=40500, grad_norm=0.2676874101161957, loss=3.4026012420654297
I0922 06:17:06.248985 139860156245824 spec.py:320] Evaluating on the training split.
I0922 06:17:14.364016 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 06:17:24.710290 139860156245824 spec.py:348] Evaluating on the test split.
I0922 06:17:27.076205 139860156245824 submission_runner.py:376] Time since start: 14412.42s, 	Step: 40923, 	{'train/accuracy': 0.6496930718421936, 'train/loss': 1.7041078805923462, 'validation/accuracy': 0.6017199754714966, 'validation/loss': 1.9247353076934814, 'validation/num_examples': 50000, 'test/accuracy': 0.4832000136375427, 'test/loss': 2.584318161010742, 'test/num_examples': 10000, 'score': 13837.261239528656, 'total_duration': 14412.419258594513, 'accumulated_submission_time': 13837.261239528656, 'accumulated_eval_time': 573.6953444480896, 'accumulated_logging_time': 0.8687067031860352}
I0922 06:17:27.098549 139695002457856 logging_writer.py:48] [40923] accumulated_eval_time=573.695344, accumulated_logging_time=0.868707, accumulated_submission_time=13837.261240, global_step=40923, preemption_count=0, score=13837.261240, test/accuracy=0.483200, test/loss=2.584318, test/num_examples=10000, total_duration=14412.419259, train/accuracy=0.649693, train/loss=1.704108, validation/accuracy=0.601720, validation/loss=1.924735, validation/num_examples=50000
I0922 06:17:53.383823 139695111497472 logging_writer.py:48] [41000] global_step=41000, grad_norm=0.26105624437332153, loss=3.4573490619659424
I0922 06:20:41.629184 139695002457856 logging_writer.py:48] [41500] global_step=41500, grad_norm=0.27961379289627075, loss=3.4410150051116943
I0922 06:23:29.941127 139695111497472 logging_writer.py:48] [42000] global_step=42000, grad_norm=0.27203938364982605, loss=3.4637370109558105
I0922 06:25:57.150395 139860156245824 spec.py:320] Evaluating on the training split.
I0922 06:26:05.373156 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 06:26:15.717644 139860156245824 spec.py:348] Evaluating on the test split.
I0922 06:26:18.073924 139860156245824 submission_runner.py:376] Time since start: 14943.42s, 	Step: 42439, 	{'train/accuracy': 0.6416812539100647, 'train/loss': 1.7094223499298096, 'validation/accuracy': 0.5963599681854248, 'validation/loss': 1.9188870191574097, 'validation/num_examples': 50000, 'test/accuracy': 0.47140002250671387, 'test/loss': 2.558954954147339, 'test/num_examples': 10000, 'score': 14347.27698802948, 'total_duration': 14943.416975975037, 'accumulated_submission_time': 14347.27698802948, 'accumulated_eval_time': 594.6188504695892, 'accumulated_logging_time': 0.9051849842071533}
I0922 06:26:18.095313 139695010850560 logging_writer.py:48] [42439] accumulated_eval_time=594.618850, accumulated_logging_time=0.905185, accumulated_submission_time=14347.276988, global_step=42439, preemption_count=0, score=14347.276988, test/accuracy=0.471400, test/loss=2.558955, test/num_examples=10000, total_duration=14943.416976, train/accuracy=0.641681, train/loss=1.709422, validation/accuracy=0.596360, validation/loss=1.918887, validation/num_examples=50000
I0922 06:26:39.000641 139695019243264 logging_writer.py:48] [42500] global_step=42500, grad_norm=0.2690980136394501, loss=3.435554027557373
I0922 06:29:27.154311 139695010850560 logging_writer.py:48] [43000] global_step=43000, grad_norm=0.27048259973526, loss=3.367072343826294
I0922 06:32:15.479097 139695019243264 logging_writer.py:48] [43500] global_step=43500, grad_norm=0.27150073647499084, loss=3.391481399536133
I0922 06:34:48.332592 139860156245824 spec.py:320] Evaluating on the training split.
I0922 06:34:56.426438 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 06:35:06.945465 139860156245824 spec.py:348] Evaluating on the test split.
I0922 06:35:09.362766 139860156245824 submission_runner.py:376] Time since start: 15474.71s, 	Step: 43956, 	{'train/accuracy': 0.650789201259613, 'train/loss': 1.6602976322174072, 'validation/accuracy': 0.6007599830627441, 'validation/loss': 1.9025561809539795, 'validation/num_examples': 50000, 'test/accuracy': 0.4764000177383423, 'test/loss': 2.577639102935791, 'test/num_examples': 10000, 'score': 14857.481169223785, 'total_duration': 15474.705823421478, 'accumulated_submission_time': 14857.481169223785, 'accumulated_eval_time': 615.6490051746368, 'accumulated_logging_time': 0.9379069805145264}
I0922 06:35:09.384633 139695002457856 logging_writer.py:48] [43956] accumulated_eval_time=615.649005, accumulated_logging_time=0.937907, accumulated_submission_time=14857.481169, global_step=43956, preemption_count=0, score=14857.481169, test/accuracy=0.476400, test/loss=2.577639, test/num_examples=10000, total_duration=15474.705823, train/accuracy=0.650789, train/loss=1.660298, validation/accuracy=0.600760, validation/loss=1.902556, validation/num_examples=50000
I0922 06:35:24.509370 139695010850560 logging_writer.py:48] [44000] global_step=44000, grad_norm=0.299095094203949, loss=3.4838380813598633
I0922 06:38:12.886126 139695002457856 logging_writer.py:48] [44500] global_step=44500, grad_norm=0.2753465175628662, loss=3.352116584777832
I0922 06:41:01.210241 139695010850560 logging_writer.py:48] [45000] global_step=45000, grad_norm=0.2745493948459625, loss=3.4072065353393555
I0922 06:43:39.519955 139860156245824 spec.py:320] Evaluating on the training split.
I0922 06:43:47.612511 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 06:43:58.295484 139860156245824 spec.py:348] Evaluating on the test split.
I0922 06:44:00.747827 139860156245824 submission_runner.py:376] Time since start: 16006.09s, 	Step: 45472, 	{'train/accuracy': 0.6668327450752258, 'train/loss': 1.613439917564392, 'validation/accuracy': 0.6021599769592285, 'validation/loss': 1.9118386507034302, 'validation/num_examples': 50000, 'test/accuracy': 0.4829000234603882, 'test/loss': 2.553234100341797, 'test/num_examples': 10000, 'score': 15367.582799911499, 'total_duration': 16006.090864181519, 'accumulated_submission_time': 15367.582799911499, 'accumulated_eval_time': 636.876837015152, 'accumulated_logging_time': 0.9713876247406006}
I0922 06:44:00.770833 139695027635968 logging_writer.py:48] [45472] accumulated_eval_time=636.876837, accumulated_logging_time=0.971388, accumulated_submission_time=15367.582800, global_step=45472, preemption_count=0, score=15367.582800, test/accuracy=0.482900, test/loss=2.553234, test/num_examples=10000, total_duration=16006.090864, train/accuracy=0.666833, train/loss=1.613440, validation/accuracy=0.602160, validation/loss=1.911839, validation/num_examples=50000
I0922 06:44:10.544160 139695103104768 logging_writer.py:48] [45500] global_step=45500, grad_norm=0.2708096504211426, loss=3.364004373550415
I0922 06:46:58.759485 139695027635968 logging_writer.py:48] [46000] global_step=46000, grad_norm=0.2785819172859192, loss=3.446249008178711
I0922 06:49:47.092593 139695103104768 logging_writer.py:48] [46500] global_step=46500, grad_norm=0.28705132007598877, loss=3.42985463142395
I0922 06:52:30.901445 139860156245824 spec.py:320] Evaluating on the training split.
I0922 06:52:39.063039 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 06:52:49.632106 139860156245824 spec.py:348] Evaluating on the test split.
I0922 06:52:52.046632 139860156245824 submission_runner.py:376] Time since start: 16537.39s, 	Step: 46988, 	{'train/accuracy': 0.6500916481018066, 'train/loss': 1.6953728199005127, 'validation/accuracy': 0.5959799885749817, 'validation/loss': 1.9494109153747559, 'validation/num_examples': 50000, 'test/accuracy': 0.48110002279281616, 'test/loss': 2.5915913581848145, 'test/num_examples': 10000, 'score': 15877.68100309372, 'total_duration': 16537.389682769775, 'accumulated_submission_time': 15877.68100309372, 'accumulated_eval_time': 658.0219976902008, 'accumulated_logging_time': 1.0049190521240234}
I0922 06:52:52.070318 139695027635968 logging_writer.py:48] [46988] accumulated_eval_time=658.021998, accumulated_logging_time=1.004919, accumulated_submission_time=15877.681003, global_step=46988, preemption_count=0, score=15877.681003, test/accuracy=0.481100, test/loss=2.591591, test/num_examples=10000, total_duration=16537.389683, train/accuracy=0.650092, train/loss=1.695373, validation/accuracy=0.595980, validation/loss=1.949411, validation/num_examples=50000
I0922 06:52:56.450918 139695103104768 logging_writer.py:48] [47000] global_step=47000, grad_norm=0.2875623404979706, loss=3.4735841751098633
I0922 06:55:44.768486 139695027635968 logging_writer.py:48] [47500] global_step=47500, grad_norm=0.2674235999584198, loss=3.373816728591919
I0922 06:58:33.024544 139695103104768 logging_writer.py:48] [48000] global_step=48000, grad_norm=0.26947012543678284, loss=3.3106656074523926
I0922 07:01:21.237119 139695027635968 logging_writer.py:48] [48500] global_step=48500, grad_norm=0.2719684839248657, loss=3.3626487255096436
I0922 07:01:22.334329 139860156245824 spec.py:320] Evaluating on the training split.
I0922 07:01:30.412986 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 07:01:41.107244 139860156245824 spec.py:348] Evaluating on the test split.
I0922 07:01:43.473887 139860156245824 submission_runner.py:376] Time since start: 17068.82s, 	Step: 48505, 	{'train/accuracy': 0.6456273794174194, 'train/loss': 1.7268511056900024, 'validation/accuracy': 0.5936399698257446, 'validation/loss': 1.9696390628814697, 'validation/num_examples': 50000, 'test/accuracy': 0.4723000228404999, 'test/loss': 2.627419948577881, 'test/num_examples': 10000, 'score': 16387.911521673203, 'total_duration': 17068.8169362545, 'accumulated_submission_time': 16387.911521673203, 'accumulated_eval_time': 679.1615083217621, 'accumulated_logging_time': 1.0399305820465088}
I0922 07:01:43.495379 139695002457856 logging_writer.py:48] [48505] accumulated_eval_time=679.161508, accumulated_logging_time=1.039931, accumulated_submission_time=16387.911522, global_step=48505, preemption_count=0, score=16387.911522, test/accuracy=0.472300, test/loss=2.627420, test/num_examples=10000, total_duration=17068.816936, train/accuracy=0.645627, train/loss=1.726851, validation/accuracy=0.593640, validation/loss=1.969639, validation/num_examples=50000
I0922 07:04:30.395650 139695010850560 logging_writer.py:48] [49000] global_step=49000, grad_norm=0.2761135697364807, loss=3.4050934314727783
I0922 07:07:18.675331 139695002457856 logging_writer.py:48] [49500] global_step=49500, grad_norm=0.2773599326610565, loss=3.4057135581970215
I0922 07:10:06.945479 139695010850560 logging_writer.py:48] [50000] global_step=50000, grad_norm=0.28487929701805115, loss=3.3912088871002197
I0922 07:10:13.760935 139860156245824 spec.py:320] Evaluating on the training split.
I0922 07:10:21.839924 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 07:10:32.430805 139860156245824 spec.py:348] Evaluating on the test split.
I0922 07:10:34.769285 139860156245824 submission_runner.py:376] Time since start: 17600.11s, 	Step: 50022, 	{'train/accuracy': 0.6594387888908386, 'train/loss': 1.6280325651168823, 'validation/accuracy': 0.6092999577522278, 'validation/loss': 1.862957239151001, 'validation/num_examples': 50000, 'test/accuracy': 0.4816000163555145, 'test/loss': 2.53275203704834, 'test/num_examples': 10000, 'score': 16898.143622159958, 'total_duration': 17600.112322092056, 'accumulated_submission_time': 16898.143622159958, 'accumulated_eval_time': 700.1698007583618, 'accumulated_logging_time': 1.0731310844421387}
I0922 07:10:34.790757 139695111497472 logging_writer.py:48] [50022] accumulated_eval_time=700.169801, accumulated_logging_time=1.073131, accumulated_submission_time=16898.143622, global_step=50022, preemption_count=0, score=16898.143622, test/accuracy=0.481600, test/loss=2.532752, test/num_examples=10000, total_duration=17600.112322, train/accuracy=0.659439, train/loss=1.628033, validation/accuracy=0.609300, validation/loss=1.862957, validation/num_examples=50000
I0922 07:13:16.051460 139695119890176 logging_writer.py:48] [50500] global_step=50500, grad_norm=0.27517932653427124, loss=3.3347599506378174
I0922 07:16:04.271373 139695111497472 logging_writer.py:48] [51000] global_step=51000, grad_norm=0.2839376628398895, loss=3.3223447799682617
I0922 07:18:52.576262 139695119890176 logging_writer.py:48] [51500] global_step=51500, grad_norm=0.27970340847969055, loss=3.4170358180999756
I0922 07:19:04.789314 139860156245824 spec.py:320] Evaluating on the training split.
I0922 07:19:12.880655 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 07:19:23.506458 139860156245824 spec.py:348] Evaluating on the test split.
I0922 07:19:25.859278 139860156245824 submission_runner.py:376] Time since start: 18131.20s, 	Step: 51538, 	{'train/accuracy': 0.6144570708274841, 'train/loss': 1.873496651649475, 'validation/accuracy': 0.5712199807167053, 'validation/loss': 2.0673816204071045, 'validation/num_examples': 50000, 'test/accuracy': 0.4492000341415405, 'test/loss': 2.7472054958343506, 'test/num_examples': 10000, 'score': 17408.110887765884, 'total_duration': 18131.202320098877, 'accumulated_submission_time': 17408.110887765884, 'accumulated_eval_time': 721.2397112846375, 'accumulated_logging_time': 1.1039350032806396}
I0922 07:19:25.880580 139695019243264 logging_writer.py:48] [51538] accumulated_eval_time=721.239711, accumulated_logging_time=1.103935, accumulated_submission_time=17408.110888, global_step=51538, preemption_count=0, score=17408.110888, test/accuracy=0.449200, test/loss=2.747205, test/num_examples=10000, total_duration=18131.202320, train/accuracy=0.614457, train/loss=1.873497, validation/accuracy=0.571220, validation/loss=2.067382, validation/num_examples=50000
I0922 07:22:01.661767 139695027635968 logging_writer.py:48] [52000] global_step=52000, grad_norm=0.2862965166568756, loss=3.3623485565185547
I0922 07:24:50.061768 139695019243264 logging_writer.py:48] [52500] global_step=52500, grad_norm=0.27791717648506165, loss=3.3627471923828125
I0922 07:27:38.291843 139695027635968 logging_writer.py:48] [53000] global_step=53000, grad_norm=0.27683600783348083, loss=3.3725779056549072
I0922 07:27:55.919924 139860156245824 spec.py:320] Evaluating on the training split.
I0922 07:28:03.973398 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 07:28:14.558633 139860156245824 spec.py:348] Evaluating on the test split.
I0922 07:28:16.883674 139860156245824 submission_runner.py:376] Time since start: 18662.23s, 	Step: 53054, 	{'train/accuracy': 0.7102598547935486, 'train/loss': 1.4080713987350464, 'validation/accuracy': 0.6158199906349182, 'validation/loss': 1.8065959215164185, 'validation/num_examples': 50000, 'test/accuracy': 0.49560001492500305, 'test/loss': 2.449063777923584, 'test/num_examples': 10000, 'score': 17918.118888378143, 'total_duration': 18662.226732492447, 'accumulated_submission_time': 17918.118888378143, 'accumulated_eval_time': 742.203426361084, 'accumulated_logging_time': 1.1347317695617676}
I0922 07:28:16.904541 139695002457856 logging_writer.py:48] [53054] accumulated_eval_time=742.203426, accumulated_logging_time=1.134732, accumulated_submission_time=17918.118888, global_step=53054, preemption_count=0, score=17918.118888, test/accuracy=0.495600, test/loss=2.449064, test/num_examples=10000, total_duration=18662.226732, train/accuracy=0.710260, train/loss=1.408071, validation/accuracy=0.615820, validation/loss=1.806596, validation/num_examples=50000
I0922 07:30:47.445988 139695010850560 logging_writer.py:48] [53500] global_step=53500, grad_norm=0.28786253929138184, loss=3.3963825702667236
I0922 07:33:35.758866 139695002457856 logging_writer.py:48] [54000] global_step=54000, grad_norm=0.27505257725715637, loss=3.3773159980773926
I0922 07:36:24.036571 139695010850560 logging_writer.py:48] [54500] global_step=54500, grad_norm=0.2974752187728882, loss=3.4845621585845947
I0922 07:36:46.997345 139860156245824 spec.py:320] Evaluating on the training split.
I0922 07:36:55.025086 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 07:37:05.691599 139860156245824 spec.py:348] Evaluating on the test split.
I0922 07:37:08.039152 139860156245824 submission_runner.py:376] Time since start: 19193.38s, 	Step: 54570, 	{'train/accuracy': 0.6874402165412903, 'train/loss': 1.5018043518066406, 'validation/accuracy': 0.6191399693489075, 'validation/loss': 1.8059743642807007, 'validation/num_examples': 50000, 'test/accuracy': 0.4978000223636627, 'test/loss': 2.4517621994018555, 'test/num_examples': 10000, 'score': 18428.1802213192, 'total_duration': 19193.382207393646, 'accumulated_submission_time': 18428.1802213192, 'accumulated_eval_time': 763.2452006340027, 'accumulated_logging_time': 1.1650416851043701}
I0922 07:37:08.060584 139695002457856 logging_writer.py:48] [54570] accumulated_eval_time=763.245201, accumulated_logging_time=1.165042, accumulated_submission_time=18428.180221, global_step=54570, preemption_count=0, score=18428.180221, test/accuracy=0.497800, test/loss=2.451762, test/num_examples=10000, total_duration=19193.382207, train/accuracy=0.687440, train/loss=1.501804, validation/accuracy=0.619140, validation/loss=1.805974, validation/num_examples=50000
I0922 07:39:33.148458 139695010850560 logging_writer.py:48] [55000] global_step=55000, grad_norm=0.2846870720386505, loss=3.334047794342041
I0922 07:42:21.426163 139695002457856 logging_writer.py:48] [55500] global_step=55500, grad_norm=0.2770892381668091, loss=3.3566393852233887
I0922 07:45:09.699672 139695010850560 logging_writer.py:48] [56000] global_step=56000, grad_norm=0.2900329828262329, loss=3.4043097496032715
I0922 07:45:38.363254 139860156245824 spec.py:320] Evaluating on the training split.
I0922 07:45:46.421648 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 07:45:57.005506 139860156245824 spec.py:348] Evaluating on the test split.
I0922 07:45:59.343872 139860156245824 submission_runner.py:376] Time since start: 19724.69s, 	Step: 56087, 	{'train/accuracy': 0.6672911047935486, 'train/loss': 1.6243317127227783, 'validation/accuracy': 0.6116799712181091, 'validation/loss': 1.8813596963882446, 'validation/num_examples': 50000, 'test/accuracy': 0.4905000329017639, 'test/loss': 2.5239357948303223, 'test/num_examples': 10000, 'score': 18938.45142197609, 'total_duration': 19724.686930656433, 'accumulated_submission_time': 18938.45142197609, 'accumulated_eval_time': 784.2257878780365, 'accumulated_logging_time': 1.1962223052978516}
I0922 07:45:59.370926 139694994065152 logging_writer.py:48] [56087] accumulated_eval_time=784.225788, accumulated_logging_time=1.196222, accumulated_submission_time=18938.451422, global_step=56087, preemption_count=0, score=18938.451422, test/accuracy=0.490500, test/loss=2.523936, test/num_examples=10000, total_duration=19724.686931, train/accuracy=0.667291, train/loss=1.624332, validation/accuracy=0.611680, validation/loss=1.881360, validation/num_examples=50000
I0922 07:48:18.785131 139695002457856 logging_writer.py:48] [56500] global_step=56500, grad_norm=0.28968432545661926, loss=3.393871545791626
I0922 07:51:07.096425 139694994065152 logging_writer.py:48] [57000] global_step=57000, grad_norm=0.2930130362510681, loss=3.2748525142669678
I0922 07:53:55.359182 139695002457856 logging_writer.py:48] [57500] global_step=57500, grad_norm=0.2845706641674042, loss=3.354886770248413
I0922 07:54:29.406462 139860156245824 spec.py:320] Evaluating on the training split.
I0922 07:54:37.397800 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 07:54:48.136537 139860156245824 spec.py:348] Evaluating on the test split.
I0922 07:54:50.486405 139860156245824 submission_runner.py:376] Time since start: 20255.83s, 	Step: 57603, 	{'train/accuracy': 0.6643016338348389, 'train/loss': 1.6511489152908325, 'validation/accuracy': 0.6108599901199341, 'validation/loss': 1.9003981351852417, 'validation/num_examples': 50000, 'test/accuracy': 0.47470003366470337, 'test/loss': 2.563464641571045, 'test/num_examples': 10000, 'score': 19448.453800678253, 'total_duration': 20255.829459428787, 'accumulated_submission_time': 19448.453800678253, 'accumulated_eval_time': 805.3057129383087, 'accumulated_logging_time': 1.2348315715789795}
I0922 07:54:50.509095 139695002457856 logging_writer.py:48] [57603] accumulated_eval_time=805.305713, accumulated_logging_time=1.234832, accumulated_submission_time=19448.453801, global_step=57603, preemption_count=0, score=19448.453801, test/accuracy=0.474700, test/loss=2.563465, test/num_examples=10000, total_duration=20255.829459, train/accuracy=0.664302, train/loss=1.651149, validation/accuracy=0.610860, validation/loss=1.900398, validation/num_examples=50000
I0922 07:57:04.393134 139695010850560 logging_writer.py:48] [58000] global_step=58000, grad_norm=0.3004332184791565, loss=3.405535936355591
I0922 07:59:52.606335 139695002457856 logging_writer.py:48] [58500] global_step=58500, grad_norm=0.29936814308166504, loss=3.3898935317993164
I0922 08:02:40.927611 139695010850560 logging_writer.py:48] [59000] global_step=59000, grad_norm=0.2910768687725067, loss=3.31539249420166
I0922 08:03:20.740723 139860156245824 spec.py:320] Evaluating on the training split.
I0922 08:03:28.780488 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 08:03:39.585508 139860156245824 spec.py:348] Evaluating on the test split.
I0922 08:03:41.900039 139860156245824 submission_runner.py:376] Time since start: 20787.24s, 	Step: 59120, 	{'train/accuracy': 0.6592593789100647, 'train/loss': 1.6350799798965454, 'validation/accuracy': 0.6084799766540527, 'validation/loss': 1.8722097873687744, 'validation/num_examples': 50000, 'test/accuracy': 0.48260003328323364, 'test/loss': 2.5308773517608643, 'test/num_examples': 10000, 'score': 19958.65367460251, 'total_duration': 20787.243068933487, 'accumulated_submission_time': 19958.65367460251, 'accumulated_eval_time': 826.4649696350098, 'accumulated_logging_time': 1.2671937942504883}
I0922 08:03:41.922986 139695002457856 logging_writer.py:48] [59120] accumulated_eval_time=826.464970, accumulated_logging_time=1.267194, accumulated_submission_time=19958.653675, global_step=59120, preemption_count=0, score=19958.653675, test/accuracy=0.482600, test/loss=2.530877, test/num_examples=10000, total_duration=20787.243069, train/accuracy=0.659259, train/loss=1.635080, validation/accuracy=0.608480, validation/loss=1.872210, validation/num_examples=50000
I0922 08:05:50.164195 139695111497472 logging_writer.py:48] [59500] global_step=59500, grad_norm=0.2873624265193939, loss=3.3463211059570312
I0922 08:08:38.398765 139695002457856 logging_writer.py:48] [60000] global_step=60000, grad_norm=0.2992362678050995, loss=3.3673768043518066
I0922 08:11:26.741532 139695111497472 logging_writer.py:48] [60500] global_step=60500, grad_norm=0.28945544362068176, loss=3.3251280784606934
I0922 08:12:11.957366 139860156245824 spec.py:320] Evaluating on the training split.
I0922 08:12:19.938020 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 08:12:30.585114 139860156245824 spec.py:348] Evaluating on the test split.
I0922 08:12:32.947625 139860156245824 submission_runner.py:376] Time since start: 21318.29s, 	Step: 60636, 	{'train/accuracy': 0.6764788031578064, 'train/loss': 1.5421534776687622, 'validation/accuracy': 0.6281999945640564, 'validation/loss': 1.7692667245864868, 'validation/num_examples': 50000, 'test/accuracy': 0.5008000135421753, 'test/loss': 2.421143054962158, 'test/num_examples': 10000, 'score': 20468.65588068962, 'total_duration': 21318.2906563282, 'accumulated_submission_time': 20468.65588068962, 'accumulated_eval_time': 847.4551708698273, 'accumulated_logging_time': 1.300093650817871}
I0922 08:12:32.970473 139695019243264 logging_writer.py:48] [60636] accumulated_eval_time=847.455171, accumulated_logging_time=1.300094, accumulated_submission_time=20468.655881, global_step=60636, preemption_count=0, score=20468.655881, test/accuracy=0.500800, test/loss=2.421143, test/num_examples=10000, total_duration=21318.290656, train/accuracy=0.676479, train/loss=1.542153, validation/accuracy=0.628200, validation/loss=1.769267, validation/num_examples=50000
I0922 08:14:35.736146 139695027635968 logging_writer.py:48] [61000] global_step=61000, grad_norm=0.28516238927841187, loss=3.3104429244995117
I0922 08:17:23.987589 139695019243264 logging_writer.py:48] [61500] global_step=61500, grad_norm=0.27967020869255066, loss=3.2830147743225098
I0922 08:20:12.295964 139695027635968 logging_writer.py:48] [62000] global_step=62000, grad_norm=0.29099801182746887, loss=3.2993526458740234
I0922 08:21:03.232714 139860156245824 spec.py:320] Evaluating on the training split.
I0922 08:21:11.153392 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 08:21:21.875503 139860156245824 spec.py:348] Evaluating on the test split.
I0922 08:21:24.269418 139860156245824 submission_runner.py:376] Time since start: 21849.61s, 	Step: 62153, 	{'train/accuracy': 0.7169563174247742, 'train/loss': 1.3769701719284058, 'validation/accuracy': 0.6265999674797058, 'validation/loss': 1.764554500579834, 'validation/num_examples': 50000, 'test/accuracy': 0.492900013923645, 'test/loss': 2.4501240253448486, 'test/num_examples': 10000, 'score': 20978.883363485336, 'total_duration': 21849.612474679947, 'accumulated_submission_time': 20978.883363485336, 'accumulated_eval_time': 868.4918429851532, 'accumulated_logging_time': 1.3359174728393555}
I0922 08:21:24.292433 139694994065152 logging_writer.py:48] [62153] accumulated_eval_time=868.491843, accumulated_logging_time=1.335917, accumulated_submission_time=20978.883363, global_step=62153, preemption_count=0, score=20978.883363, test/accuracy=0.492900, test/loss=2.450124, test/num_examples=10000, total_duration=21849.612475, train/accuracy=0.716956, train/loss=1.376970, validation/accuracy=0.626600, validation/loss=1.764555, validation/num_examples=50000
I0922 08:23:21.384779 139695002457856 logging_writer.py:48] [62500] global_step=62500, grad_norm=0.29539772868156433, loss=3.2773962020874023
I0922 08:26:09.624425 139694994065152 logging_writer.py:48] [63000] global_step=63000, grad_norm=0.293172150850296, loss=3.3558075428009033
I0922 08:28:57.945657 139695002457856 logging_writer.py:48] [63500] global_step=63500, grad_norm=0.3089028298854828, loss=3.4143950939178467
I0922 08:29:54.543036 139860156245824 spec.py:320] Evaluating on the training split.
I0922 08:30:02.494209 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 08:30:13.206739 139860156245824 spec.py:348] Evaluating on the test split.
I0922 08:30:15.570558 139860156245824 submission_runner.py:376] Time since start: 22380.91s, 	Step: 63670, 	{'train/accuracy': 0.6825574040412903, 'train/loss': 1.5605289936065674, 'validation/accuracy': 0.6123600006103516, 'validation/loss': 1.8629093170166016, 'validation/num_examples': 50000, 'test/accuracy': 0.4869000315666199, 'test/loss': 2.5212059020996094, 'test/num_examples': 10000, 'score': 21489.101444244385, 'total_duration': 22380.913610696793, 'accumulated_submission_time': 21489.101444244385, 'accumulated_eval_time': 889.519335269928, 'accumulated_logging_time': 1.3693304061889648}
I0922 08:30:15.596430 139695002457856 logging_writer.py:48] [63670] accumulated_eval_time=889.519335, accumulated_logging_time=1.369330, accumulated_submission_time=21489.101444, global_step=63670, preemption_count=0, score=21489.101444, test/accuracy=0.486900, test/loss=2.521206, test/num_examples=10000, total_duration=22380.913611, train/accuracy=0.682557, train/loss=1.560529, validation/accuracy=0.612360, validation/loss=1.862909, validation/num_examples=50000
I0922 08:32:06.893361 139695103104768 logging_writer.py:48] [64000] global_step=64000, grad_norm=0.29983022809028625, loss=3.3168692588806152
I0922 08:34:55.170144 139695002457856 logging_writer.py:48] [64500] global_step=64500, grad_norm=0.2886057198047638, loss=3.3792765140533447
I0922 08:37:43.409431 139695103104768 logging_writer.py:48] [65000] global_step=65000, grad_norm=0.30201074481010437, loss=3.3279120922088623
I0922 08:38:45.708699 139860156245824 spec.py:320] Evaluating on the training split.
I0922 08:38:53.653329 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 08:39:04.374020 139860156245824 spec.py:348] Evaluating on the test split.
I0922 08:39:06.700541 139860156245824 submission_runner.py:376] Time since start: 22912.04s, 	Step: 65187, 	{'train/accuracy': 0.6810227632522583, 'train/loss': 1.5294525623321533, 'validation/accuracy': 0.619219958782196, 'validation/loss': 1.80784010887146, 'validation/num_examples': 50000, 'test/accuracy': 0.4823000133037567, 'test/loss': 2.4801368713378906, 'test/num_examples': 10000, 'score': 21999.18106484413, 'total_duration': 22912.043599128723, 'accumulated_submission_time': 21999.18106484413, 'accumulated_eval_time': 910.511146068573, 'accumulated_logging_time': 1.4059362411499023}
I0922 08:39:06.722256 139695010850560 logging_writer.py:48] [65187] accumulated_eval_time=910.511146, accumulated_logging_time=1.405936, accumulated_submission_time=21999.181065, global_step=65187, preemption_count=0, score=21999.181065, test/accuracy=0.482300, test/loss=2.480137, test/num_examples=10000, total_duration=22912.043599, train/accuracy=0.681023, train/loss=1.529453, validation/accuracy=0.619220, validation/loss=1.807840, validation/num_examples=50000
I0922 08:40:52.322522 139695019243264 logging_writer.py:48] [65500] global_step=65500, grad_norm=0.289893239736557, loss=3.283635139465332
I0922 08:43:40.547122 139695010850560 logging_writer.py:48] [66000] global_step=66000, grad_norm=0.30817711353302, loss=3.3534722328186035
I0922 08:46:28.830991 139695019243264 logging_writer.py:48] [66500] global_step=66500, grad_norm=0.3033820390701294, loss=3.2922370433807373
I0922 08:47:36.937113 139860156245824 spec.py:320] Evaluating on the training split.
I0922 08:47:44.794783 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 08:47:55.506685 139860156245824 spec.py:348] Evaluating on the test split.
I0922 08:47:57.894514 139860156245824 submission_runner.py:376] Time since start: 23443.24s, 	Step: 66704, 	{'train/accuracy': 0.68753981590271, 'train/loss': 1.4932862520217896, 'validation/accuracy': 0.6326199769973755, 'validation/loss': 1.7415614128112793, 'validation/num_examples': 50000, 'test/accuracy': 0.5020000338554382, 'test/loss': 2.4340665340423584, 'test/num_examples': 10000, 'score': 22509.363567352295, 'total_duration': 23443.237510442734, 'accumulated_submission_time': 22509.363567352295, 'accumulated_eval_time': 931.4684584140778, 'accumulated_logging_time': 1.4373843669891357}
I0922 08:47:57.931022 139695010850560 logging_writer.py:48] [66704] accumulated_eval_time=931.468458, accumulated_logging_time=1.437384, accumulated_submission_time=22509.363567, global_step=66704, preemption_count=0, score=22509.363567, test/accuracy=0.502000, test/loss=2.434067, test/num_examples=10000, total_duration=23443.237510, train/accuracy=0.687540, train/loss=1.493286, validation/accuracy=0.632620, validation/loss=1.741561, validation/num_examples=50000
I0922 08:49:37.934348 139695103104768 logging_writer.py:48] [67000] global_step=67000, grad_norm=0.3112807869911194, loss=3.274117946624756
I0922 08:52:26.270508 139695010850560 logging_writer.py:48] [67500] global_step=67500, grad_norm=0.3032156825065613, loss=3.249506711959839
I0922 08:55:14.510672 139695103104768 logging_writer.py:48] [68000] global_step=68000, grad_norm=0.3022601306438446, loss=3.3313465118408203
I0922 08:56:27.969537 139860156245824 spec.py:320] Evaluating on the training split.
I0922 08:56:36.081423 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 08:56:46.877274 139860156245824 spec.py:348] Evaluating on the test split.
I0922 08:56:49.220860 139860156245824 submission_runner.py:376] Time since start: 23974.56s, 	Step: 68220, 	{'train/accuracy': 0.688496470451355, 'train/loss': 1.5721735954284668, 'validation/accuracy': 0.6291399598121643, 'validation/loss': 1.828994631767273, 'validation/num_examples': 50000, 'test/accuracy': 0.5041000247001648, 'test/loss': 2.4818732738494873, 'test/num_examples': 10000, 'score': 23019.36590528488, 'total_duration': 23974.563906669617, 'accumulated_submission_time': 23019.36590528488, 'accumulated_eval_time': 952.7197403907776, 'accumulated_logging_time': 1.4881384372711182}
I0922 08:56:49.244407 139695019243264 logging_writer.py:48] [68220] accumulated_eval_time=952.719740, accumulated_logging_time=1.488138, accumulated_submission_time=23019.365905, global_step=68220, preemption_count=0, score=23019.365905, test/accuracy=0.504100, test/loss=2.481873, test/num_examples=10000, total_duration=23974.563907, train/accuracy=0.688496, train/loss=1.572174, validation/accuracy=0.629140, validation/loss=1.828995, validation/num_examples=50000
I0922 08:58:23.758270 139695027635968 logging_writer.py:48] [68500] global_step=68500, grad_norm=0.30594250559806824, loss=3.2909440994262695
I0922 09:01:12.150378 139695019243264 logging_writer.py:48] [69000] global_step=69000, grad_norm=0.30048203468322754, loss=3.2731783390045166
I0922 09:04:00.492702 139695027635968 logging_writer.py:48] [69500] global_step=69500, grad_norm=0.30361518263816833, loss=3.260941505432129
I0922 09:05:19.342823 139860156245824 spec.py:320] Evaluating on the training split.
I0922 09:05:27.285130 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 09:05:38.131138 139860156245824 spec.py:348] Evaluating on the test split.
I0922 09:05:40.483902 139860156245824 submission_runner.py:376] Time since start: 24505.83s, 	Step: 69736, 	{'train/accuracy': 0.6886360049247742, 'train/loss': 1.5390214920043945, 'validation/accuracy': 0.630620002746582, 'validation/loss': 1.7868869304656982, 'validation/num_examples': 50000, 'test/accuracy': 0.5041000247001648, 'test/loss': 2.4390032291412354, 'test/num_examples': 10000, 'score': 23529.431270599365, 'total_duration': 24505.82695055008, 'accumulated_submission_time': 23529.431270599365, 'accumulated_eval_time': 973.8607857227325, 'accumulated_logging_time': 1.5223145484924316}
I0922 09:05:40.506494 139695010850560 logging_writer.py:48] [69736] accumulated_eval_time=973.860786, accumulated_logging_time=1.522315, accumulated_submission_time=23529.431271, global_step=69736, preemption_count=0, score=23529.431271, test/accuracy=0.504100, test/loss=2.439003, test/num_examples=10000, total_duration=24505.826951, train/accuracy=0.688636, train/loss=1.539021, validation/accuracy=0.630620, validation/loss=1.786887, validation/num_examples=50000
I0922 09:07:09.598842 139695019243264 logging_writer.py:48] [70000] global_step=70000, grad_norm=0.3038524091243744, loss=3.255425453186035
I0922 09:09:57.878059 139695010850560 logging_writer.py:48] [70500] global_step=70500, grad_norm=0.3047172427177429, loss=3.2893738746643066
I0922 09:12:46.157352 139695019243264 logging_writer.py:48] [71000] global_step=71000, grad_norm=0.31170976161956787, loss=3.2106800079345703
I0922 09:14:10.742771 139860156245824 spec.py:320] Evaluating on the training split.
I0922 09:14:18.691904 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 09:14:29.459809 139860156245824 spec.py:348] Evaluating on the test split.
I0922 09:14:31.790583 139860156245824 submission_runner.py:376] Time since start: 25037.13s, 	Step: 71253, 	{'train/accuracy': 0.7182317972183228, 'train/loss': 1.427201271057129, 'validation/accuracy': 0.6324399709701538, 'validation/loss': 1.809969186782837, 'validation/num_examples': 50000, 'test/accuracy': 0.5151000022888184, 'test/loss': 2.4297642707824707, 'test/num_examples': 10000, 'score': 24039.632776498795, 'total_duration': 25037.13354253769, 'accumulated_submission_time': 24039.632776498795, 'accumulated_eval_time': 994.9084758758545, 'accumulated_logging_time': 1.5572876930236816}
I0922 09:14:31.818749 139695103104768 logging_writer.py:48] [71253] accumulated_eval_time=994.908476, accumulated_logging_time=1.557288, accumulated_submission_time=24039.632776, global_step=71253, preemption_count=0, score=24039.632776, test/accuracy=0.515100, test/loss=2.429764, test/num_examples=10000, total_duration=25037.133543, train/accuracy=0.718232, train/loss=1.427201, validation/accuracy=0.632440, validation/loss=1.809969, validation/num_examples=50000
I0922 09:15:55.273930 139695111497472 logging_writer.py:48] [71500] global_step=71500, grad_norm=0.3111810088157654, loss=3.2814383506774902
I0922 09:18:43.443487 139695103104768 logging_writer.py:48] [72000] global_step=72000, grad_norm=0.30737268924713135, loss=3.281172513961792
I0922 09:21:31.589585 139695111497472 logging_writer.py:48] [72500] global_step=72500, grad_norm=0.30474111437797546, loss=3.150161027908325
I0922 09:23:01.945896 139860156245824 spec.py:320] Evaluating on the training split.
I0922 09:23:09.845762 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 09:23:20.701377 139860156245824 spec.py:348] Evaluating on the test split.
I0922 09:23:23.046007 139860156245824 submission_runner.py:376] Time since start: 25568.39s, 	Step: 72770, 	{'train/accuracy': 0.7115553021430969, 'train/loss': 1.3792685270309448, 'validation/accuracy': 0.6410199999809265, 'validation/loss': 1.695258378982544, 'validation/num_examples': 50000, 'test/accuracy': 0.513200044631958, 'test/loss': 2.351789951324463, 'test/num_examples': 10000, 'score': 24549.726781845093, 'total_duration': 25568.389043092728, 'accumulated_submission_time': 24549.726781845093, 'accumulated_eval_time': 1016.0085372924805, 'accumulated_logging_time': 1.5963807106018066}
I0922 09:23:23.069506 139695010850560 logging_writer.py:48] [72770] accumulated_eval_time=1016.008537, accumulated_logging_time=1.596381, accumulated_submission_time=24549.726782, global_step=72770, preemption_count=0, score=24549.726782, test/accuracy=0.513200, test/loss=2.351790, test/num_examples=10000, total_duration=25568.389043, train/accuracy=0.711555, train/loss=1.379269, validation/accuracy=0.641020, validation/loss=1.695258, validation/num_examples=50000
I0922 09:24:40.809317 139695019243264 logging_writer.py:48] [73000] global_step=73000, grad_norm=0.315459281206131, loss=3.3804118633270264
I0922 09:27:29.116168 139695010850560 logging_writer.py:48] [73500] global_step=73500, grad_norm=0.3116065263748169, loss=3.2069895267486572
I0922 09:30:17.422245 139695019243264 logging_writer.py:48] [74000] global_step=74000, grad_norm=0.3052782118320465, loss=3.2421131134033203
I0922 09:31:53.098926 139860156245824 spec.py:320] Evaluating on the training split.
I0922 09:32:01.027716 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 09:32:11.878749 139860156245824 spec.py:348] Evaluating on the test split.
I0922 09:32:14.265084 139860156245824 submission_runner.py:376] Time since start: 26099.61s, 	Step: 74286, 	{'train/accuracy': 0.7029256820678711, 'train/loss': 1.4456677436828613, 'validation/accuracy': 0.640500009059906, 'validation/loss': 1.7377138137817383, 'validation/num_examples': 50000, 'test/accuracy': 0.5188000202178955, 'test/loss': 2.3861923217773438, 'test/num_examples': 10000, 'score': 25059.723529815674, 'total_duration': 26099.608132362366, 'accumulated_submission_time': 25059.723529815674, 'accumulated_eval_time': 1037.1746661663055, 'accumulated_logging_time': 1.6305997371673584}
I0922 09:32:14.292394 139695111497472 logging_writer.py:48] [74286] accumulated_eval_time=1037.174666, accumulated_logging_time=1.630600, accumulated_submission_time=25059.723530, global_step=74286, preemption_count=0, score=25059.723530, test/accuracy=0.518800, test/loss=2.386192, test/num_examples=10000, total_duration=26099.608132, train/accuracy=0.702926, train/loss=1.445668, validation/accuracy=0.640500, validation/loss=1.737714, validation/num_examples=50000
I0922 09:33:26.680955 139695119890176 logging_writer.py:48] [74500] global_step=74500, grad_norm=0.3034502863883972, loss=3.183523178100586
I0922 09:36:15.012922 139695111497472 logging_writer.py:48] [75000] global_step=75000, grad_norm=0.3251660168170929, loss=3.2074122428894043
I0922 09:39:03.357888 139695119890176 logging_writer.py:48] [75500] global_step=75500, grad_norm=0.3233720064163208, loss=3.3084163665771484
I0922 09:40:44.418052 139860156245824 spec.py:320] Evaluating on the training split.
I0922 09:40:52.673579 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 09:41:03.520580 139860156245824 spec.py:348] Evaluating on the test split.
I0922 09:41:05.849290 139860156245824 submission_runner.py:376] Time since start: 26631.19s, 	Step: 75802, 	{'train/accuracy': 0.7102000713348389, 'train/loss': 1.412864089012146, 'validation/accuracy': 0.6520999670028687, 'validation/loss': 1.6886405944824219, 'validation/num_examples': 50000, 'test/accuracy': 0.5288000106811523, 'test/loss': 2.310685873031616, 'test/num_examples': 10000, 'score': 25569.817949295044, 'total_duration': 26631.19234609604, 'accumulated_submission_time': 25569.817949295044, 'accumulated_eval_time': 1058.6058802604675, 'accumulated_logging_time': 1.6673941612243652}
I0922 09:41:05.873474 139695019243264 logging_writer.py:48] [75802] accumulated_eval_time=1058.605880, accumulated_logging_time=1.667394, accumulated_submission_time=25569.817949, global_step=75802, preemption_count=0, score=25569.817949, test/accuracy=0.528800, test/loss=2.310686, test/num_examples=10000, total_duration=26631.192346, train/accuracy=0.710200, train/loss=1.412864, validation/accuracy=0.652100, validation/loss=1.688641, validation/num_examples=50000
I0922 09:42:12.753615 139695128282880 logging_writer.py:48] [76000] global_step=76000, grad_norm=0.3198067545890808, loss=3.241088390350342
I0922 09:45:01.014955 139695019243264 logging_writer.py:48] [76500] global_step=76500, grad_norm=0.3212328553199768, loss=3.3295392990112305
I0922 09:47:49.287744 139695128282880 logging_writer.py:48] [77000] global_step=77000, grad_norm=0.30666640400886536, loss=3.2039122581481934
I0922 09:49:36.144629 139860156245824 spec.py:320] Evaluating on the training split.
I0922 09:49:44.030603 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 09:49:54.933882 139860156245824 spec.py:348] Evaluating on the test split.
I0922 09:49:57.305974 139860156245824 submission_runner.py:376] Time since start: 27162.65s, 	Step: 77319, 	{'train/accuracy': 0.7073301672935486, 'train/loss': 1.4102189540863037, 'validation/accuracy': 0.6480000019073486, 'validation/loss': 1.6826646327972412, 'validation/num_examples': 50000, 'test/accuracy': 0.5267000198364258, 'test/loss': 2.3053231239318848, 'test/num_examples': 10000, 'score': 26080.056000471115, 'total_duration': 27162.649018526077, 'accumulated_submission_time': 26080.056000471115, 'accumulated_eval_time': 1079.767193555832, 'accumulated_logging_time': 1.702972173690796}
I0922 09:49:57.332038 139695010850560 logging_writer.py:48] [77319] accumulated_eval_time=1079.767194, accumulated_logging_time=1.702972, accumulated_submission_time=26080.056000, global_step=77319, preemption_count=0, score=26080.056000, test/accuracy=0.526700, test/loss=2.305323, test/num_examples=10000, total_duration=27162.649019, train/accuracy=0.707330, train/loss=1.410219, validation/accuracy=0.648000, validation/loss=1.682665, validation/num_examples=50000
I0922 09:50:58.528376 139695019243264 logging_writer.py:48] [77500] global_step=77500, grad_norm=0.3213898241519928, loss=3.193169593811035
I0922 09:53:46.794071 139695010850560 logging_writer.py:48] [78000] global_step=78000, grad_norm=0.32621562480926514, loss=3.2508649826049805
I0922 09:56:35.116174 139695019243264 logging_writer.py:48] [78500] global_step=78500, grad_norm=0.31904855370521545, loss=3.1823205947875977
I0922 09:58:27.406450 139860156245824 spec.py:320] Evaluating on the training split.
I0922 09:58:35.325835 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 09:58:46.138189 139860156245824 spec.py:348] Evaluating on the test split.
I0922 09:58:48.461930 139860156245824 submission_runner.py:376] Time since start: 27693.80s, 	Step: 78835, 	{'train/accuracy': 0.7140266299247742, 'train/loss': 1.3672490119934082, 'validation/accuracy': 0.6593799591064453, 'validation/loss': 1.6180670261383057, 'validation/num_examples': 50000, 'test/accuracy': 0.526199996471405, 'test/loss': 2.2728631496429443, 'test/num_examples': 10000, 'score': 26590.094386577606, 'total_duration': 27693.804987430573, 'accumulated_submission_time': 26590.094386577606, 'accumulated_eval_time': 1100.8226518630981, 'accumulated_logging_time': 1.7432873249053955}
I0922 09:58:48.486383 139694994065152 logging_writer.py:48] [78835] accumulated_eval_time=1100.822652, accumulated_logging_time=1.743287, accumulated_submission_time=26590.094387, global_step=78835, preemption_count=0, score=26590.094387, test/accuracy=0.526200, test/loss=2.272863, test/num_examples=10000, total_duration=27693.804987, train/accuracy=0.714027, train/loss=1.367249, validation/accuracy=0.659380, validation/loss=1.618067, validation/num_examples=50000
I0922 09:59:44.382172 139695002457856 logging_writer.py:48] [79000] global_step=79000, grad_norm=0.31662002205848694, loss=3.256692409515381
I0922 10:02:32.647403 139694994065152 logging_writer.py:48] [79500] global_step=79500, grad_norm=0.3142378330230713, loss=3.2014694213867188
I0922 10:05:20.920408 139695002457856 logging_writer.py:48] [80000] global_step=80000, grad_norm=0.3285529613494873, loss=3.2042548656463623
I0922 10:07:18.774708 139860156245824 spec.py:320] Evaluating on the training split.
I0922 10:07:26.649384 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 10:07:37.393432 139860156245824 spec.py:348] Evaluating on the test split.
I0922 10:07:39.727983 139860156245824 submission_runner.py:376] Time since start: 28225.07s, 	Step: 80352, 	{'train/accuracy': 0.7406130433082581, 'train/loss': 1.279111385345459, 'validation/accuracy': 0.6530999541282654, 'validation/loss': 1.657724142074585, 'validation/num_examples': 50000, 'test/accuracy': 0.5210000276565552, 'test/loss': 2.3075954914093018, 'test/num_examples': 10000, 'score': 27100.350009202957, 'total_duration': 28225.071019411087, 'accumulated_submission_time': 27100.350009202957, 'accumulated_eval_time': 1121.775886774063, 'accumulated_logging_time': 1.7788922786712646}
I0922 10:07:39.755838 139695027635968 logging_writer.py:48] [80352] accumulated_eval_time=1121.775887, accumulated_logging_time=1.778892, accumulated_submission_time=27100.350009, global_step=80352, preemption_count=0, score=27100.350009, test/accuracy=0.521000, test/loss=2.307595, test/num_examples=10000, total_duration=28225.071019, train/accuracy=0.740613, train/loss=1.279111, validation/accuracy=0.653100, validation/loss=1.657724, validation/num_examples=50000
I0922 10:08:29.907019 139695103104768 logging_writer.py:48] [80500] global_step=80500, grad_norm=0.3127211034297943, loss=3.1813366413116455
I0922 10:11:18.120187 139695027635968 logging_writer.py:48] [81000] global_step=81000, grad_norm=0.3194415867328644, loss=3.1751708984375
I0922 10:14:06.457814 139695103104768 logging_writer.py:48] [81500] global_step=81500, grad_norm=0.3208530843257904, loss=3.182535171508789
I0922 10:16:10.017844 139860156245824 spec.py:320] Evaluating on the training split.
I0922 10:16:17.944820 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 10:16:28.691260 139860156245824 spec.py:348] Evaluating on the test split.
I0922 10:16:31.020042 139860156245824 submission_runner.py:376] Time since start: 28756.36s, 	Step: 81869, 	{'train/accuracy': 0.7288145422935486, 'train/loss': 1.2826402187347412, 'validation/accuracy': 0.6582199931144714, 'validation/loss': 1.6013671159744263, 'validation/num_examples': 50000, 'test/accuracy': 0.5338000059127808, 'test/loss': 2.242861032485962, 'test/num_examples': 10000, 'score': 27610.579571962357, 'total_duration': 28756.363080263138, 'accumulated_submission_time': 27610.579571962357, 'accumulated_eval_time': 1142.778047800064, 'accumulated_logging_time': 1.8174490928649902}
I0922 10:16:31.045155 139694994065152 logging_writer.py:48] [81869] accumulated_eval_time=1142.778048, accumulated_logging_time=1.817449, accumulated_submission_time=27610.579572, global_step=81869, preemption_count=0, score=27610.579572, test/accuracy=0.533800, test/loss=2.242861, test/num_examples=10000, total_duration=28756.363080, train/accuracy=0.728815, train/loss=1.282640, validation/accuracy=0.658220, validation/loss=1.601367, validation/num_examples=50000
I0922 10:17:15.473464 139695002457856 logging_writer.py:48] [82000] global_step=82000, grad_norm=0.3298383057117462, loss=3.180994749069214
I0922 10:20:03.737936 139694994065152 logging_writer.py:48] [82500] global_step=82500, grad_norm=0.32465529441833496, loss=3.2328009605407715
I0922 10:22:52.075717 139695002457856 logging_writer.py:48] [83000] global_step=83000, grad_norm=0.3334799110889435, loss=3.209130048751831
I0922 10:25:01.181826 139860156245824 spec.py:320] Evaluating on the training split.
I0922 10:25:09.129785 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 10:25:19.867001 139860156245824 spec.py:348] Evaluating on the test split.
I0922 10:25:22.216874 139860156245824 submission_runner.py:376] Time since start: 29287.56s, 	Step: 83385, 	{'train/accuracy': 0.7245894074440002, 'train/loss': 1.3006478548049927, 'validation/accuracy': 0.6580199599266052, 'validation/loss': 1.6023612022399902, 'validation/num_examples': 50000, 'test/accuracy': 0.5317000150680542, 'test/loss': 2.2491512298583984, 'test/num_examples': 10000, 'score': 28120.682774066925, 'total_duration': 29287.559913635254, 'accumulated_submission_time': 28120.682774066925, 'accumulated_eval_time': 1163.8130753040314, 'accumulated_logging_time': 1.852884292602539}
I0922 10:25:22.241607 139694994065152 logging_writer.py:48] [83385] accumulated_eval_time=1163.813075, accumulated_logging_time=1.852884, accumulated_submission_time=28120.682774, global_step=83385, preemption_count=0, score=28120.682774, test/accuracy=0.531700, test/loss=2.249151, test/num_examples=10000, total_duration=29287.559914, train/accuracy=0.724589, train/loss=1.300648, validation/accuracy=0.658020, validation/loss=1.602361, validation/num_examples=50000
I0922 10:26:01.277632 139695103104768 logging_writer.py:48] [83500] global_step=83500, grad_norm=0.3249285817146301, loss=3.150028944015503
I0922 10:28:49.567064 139694994065152 logging_writer.py:48] [84000] global_step=84000, grad_norm=0.32621240615844727, loss=3.153731107711792
I0922 10:31:37.888354 139695103104768 logging_writer.py:48] [84500] global_step=84500, grad_norm=0.3356046676635742, loss=3.1707024574279785
I0922 10:33:52.307442 139860156245824 spec.py:320] Evaluating on the training split.
I0922 10:34:00.193455 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 10:34:11.201581 139860156245824 spec.py:348] Evaluating on the test split.
I0922 10:34:13.557593 139860156245824 submission_runner.py:376] Time since start: 29818.90s, 	Step: 84901, 	{'train/accuracy': 0.7145248651504517, 'train/loss': 1.413529634475708, 'validation/accuracy': 0.652999997138977, 'validation/loss': 1.6855382919311523, 'validation/num_examples': 50000, 'test/accuracy': 0.532200038433075, 'test/loss': 2.3317573070526123, 'test/num_examples': 10000, 'score': 28630.714267253876, 'total_duration': 29818.900638580322, 'accumulated_submission_time': 28630.714267253876, 'accumulated_eval_time': 1185.0631976127625, 'accumulated_logging_time': 1.8902060985565186}
I0922 10:34:13.582503 139694994065152 logging_writer.py:48] [84901] accumulated_eval_time=1185.063198, accumulated_logging_time=1.890206, accumulated_submission_time=28630.714267, global_step=84901, preemption_count=0, score=28630.714267, test/accuracy=0.532200, test/loss=2.331757, test/num_examples=10000, total_duration=29818.900639, train/accuracy=0.714525, train/loss=1.413530, validation/accuracy=0.653000, validation/loss=1.685538, validation/num_examples=50000
I0922 10:34:47.206355 139695019243264 logging_writer.py:48] [85000] global_step=85000, grad_norm=0.3471229672431946, loss=3.1608293056488037
I0922 10:37:35.424766 139694994065152 logging_writer.py:48] [85500] global_step=85500, grad_norm=0.3400489389896393, loss=3.160046100616455
I0922 10:40:23.617592 139695019243264 logging_writer.py:48] [86000] global_step=86000, grad_norm=0.35079288482666016, loss=3.1900532245635986
I0922 10:42:43.704468 139860156245824 spec.py:320] Evaluating on the training split.
I0922 10:42:51.555497 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 10:43:02.315416 139860156245824 spec.py:348] Evaluating on the test split.
I0922 10:43:04.666715 139860156245824 submission_runner.py:376] Time since start: 30350.01s, 	Step: 86418, 	{'train/accuracy': 0.7151626348495483, 'train/loss': 1.3861089944839478, 'validation/accuracy': 0.6556000113487244, 'validation/loss': 1.6581337451934814, 'validation/num_examples': 50000, 'test/accuracy': 0.5254999995231628, 'test/loss': 2.2960801124572754, 'test/num_examples': 10000, 'score': 29140.8011367321, 'total_duration': 30350.00976872444, 'accumulated_submission_time': 29140.8011367321, 'accumulated_eval_time': 1206.0254278182983, 'accumulated_logging_time': 1.9280359745025635}
I0922 10:43:04.695899 139695010850560 logging_writer.py:48] [86418] accumulated_eval_time=1206.025428, accumulated_logging_time=1.928036, accumulated_submission_time=29140.801137, global_step=86418, preemption_count=0, score=29140.801137, test/accuracy=0.525500, test/loss=2.296080, test/num_examples=10000, total_duration=30350.009769, train/accuracy=0.715163, train/loss=1.386109, validation/accuracy=0.655600, validation/loss=1.658134, validation/num_examples=50000
I0922 10:43:32.668973 139695019243264 logging_writer.py:48] [86500] global_step=86500, grad_norm=0.3285018801689148, loss=3.0820393562316895
I0922 10:46:20.898118 139695010850560 logging_writer.py:48] [87000] global_step=87000, grad_norm=0.34466031193733215, loss=3.177824020385742
I0922 10:49:09.258548 139695019243264 logging_writer.py:48] [87500] global_step=87500, grad_norm=0.3474264442920685, loss=3.170194625854492
I0922 10:51:34.777073 139860156245824 spec.py:320] Evaluating on the training split.
I0922 10:51:42.583700 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 10:51:53.472599 139860156245824 spec.py:348] Evaluating on the test split.
I0922 10:51:55.858600 139860156245824 submission_runner.py:376] Time since start: 30881.20s, 	Step: 87934, 	{'train/accuracy': 0.7551618218421936, 'train/loss': 1.2336071729660034, 'validation/accuracy': 0.6692799925804138, 'validation/loss': 1.5880743265151978, 'validation/num_examples': 50000, 'test/accuracy': 0.541100025177002, 'test/loss': 2.2302114963531494, 'test/num_examples': 10000, 'score': 29650.8491563797, 'total_duration': 30881.201652526855, 'accumulated_submission_time': 29650.8491563797, 'accumulated_eval_time': 1227.1069343090057, 'accumulated_logging_time': 1.9682741165161133}
I0922 10:51:55.882969 139695010850560 logging_writer.py:48] [87934] accumulated_eval_time=1227.106934, accumulated_logging_time=1.968274, accumulated_submission_time=29650.849156, global_step=87934, preemption_count=0, score=29650.849156, test/accuracy=0.541100, test/loss=2.230211, test/num_examples=10000, total_duration=30881.201653, train/accuracy=0.755162, train/loss=1.233607, validation/accuracy=0.669280, validation/loss=1.588074, validation/num_examples=50000
I0922 10:52:18.419210 139695111497472 logging_writer.py:48] [88000] global_step=88000, grad_norm=0.35335832834243774, loss=3.197981357574463
I0922 10:55:06.746746 139695010850560 logging_writer.py:48] [88500] global_step=88500, grad_norm=0.3564215302467346, loss=3.1234378814697266
I0922 10:57:54.890726 139695111497472 logging_writer.py:48] [89000] global_step=89000, grad_norm=0.3404565155506134, loss=3.0852749347686768
I0922 11:00:26.086256 139860156245824 spec.py:320] Evaluating on the training split.
I0922 11:00:33.972169 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 11:00:44.818331 139860156245824 spec.py:348] Evaluating on the test split.
I0922 11:00:47.183575 139860156245824 submission_runner.py:376] Time since start: 31412.53s, 	Step: 89451, 	{'train/accuracy': 0.7440210580825806, 'train/loss': 1.2593581676483154, 'validation/accuracy': 0.6637399792671204, 'validation/loss': 1.6099960803985596, 'validation/num_examples': 50000, 'test/accuracy': 0.5376999974250793, 'test/loss': 2.2556798458099365, 'test/num_examples': 10000, 'score': 30161.020138025284, 'total_duration': 31412.526627779007, 'accumulated_submission_time': 30161.020138025284, 'accumulated_eval_time': 1248.2042262554169, 'accumulated_logging_time': 2.0027639865875244}
I0922 11:00:47.210895 139695019243264 logging_writer.py:48] [89451] accumulated_eval_time=1248.204226, accumulated_logging_time=2.002764, accumulated_submission_time=30161.020138, global_step=89451, preemption_count=0, score=30161.020138, test/accuracy=0.537700, test/loss=2.255680, test/num_examples=10000, total_duration=31412.526628, train/accuracy=0.744021, train/loss=1.259358, validation/accuracy=0.663740, validation/loss=1.609996, validation/num_examples=50000
I0922 11:01:04.028146 139695027635968 logging_writer.py:48] [89500] global_step=89500, grad_norm=0.3424694538116455, loss=3.110020875930786
I0922 11:03:52.221734 139695019243264 logging_writer.py:48] [90000] global_step=90000, grad_norm=0.3382469713687897, loss=3.1454617977142334
I0922 11:06:40.441068 139695027635968 logging_writer.py:48] [90500] global_step=90500, grad_norm=0.34675347805023193, loss=3.163844108581543
I0922 11:09:17.480841 139860156245824 spec.py:320] Evaluating on the training split.
I0922 11:09:25.389828 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 11:09:36.170094 139860156245824 spec.py:348] Evaluating on the test split.
I0922 11:09:38.540524 139860156245824 submission_runner.py:376] Time since start: 31943.88s, 	Step: 90968, 	{'train/accuracy': 0.7412906289100647, 'train/loss': 1.3247534036636353, 'validation/accuracy': 0.6657800078392029, 'validation/loss': 1.6556074619293213, 'validation/num_examples': 50000, 'test/accuracy': 0.5378000140190125, 'test/loss': 2.2956035137176514, 'test/num_examples': 10000, 'score': 30671.257370471954, 'total_duration': 31943.883566617966, 'accumulated_submission_time': 30671.257370471954, 'accumulated_eval_time': 1269.2638757228851, 'accumulated_logging_time': 2.0408270359039307}
I0922 11:09:38.567976 139695002457856 logging_writer.py:48] [90968] accumulated_eval_time=1269.263876, accumulated_logging_time=2.040827, accumulated_submission_time=30671.257370, global_step=90968, preemption_count=0, score=30671.257370, test/accuracy=0.537800, test/loss=2.295604, test/num_examples=10000, total_duration=31943.883567, train/accuracy=0.741291, train/loss=1.324753, validation/accuracy=0.665780, validation/loss=1.655607, validation/num_examples=50000
I0922 11:09:49.673610 139695010850560 logging_writer.py:48] [91000] global_step=91000, grad_norm=0.3378336727619171, loss=3.1353602409362793
I0922 11:12:37.993491 139695002457856 logging_writer.py:48] [91500] global_step=91500, grad_norm=0.3434804677963257, loss=3.106139898300171
I0922 11:15:45.792768 139695010850560 logging_writer.py:48] [92000] global_step=92000, grad_norm=0.3549070954322815, loss=3.1199865341186523
I0922 11:18:08.874296 139860156245824 spec.py:320] Evaluating on the training split.
I0922 11:18:16.651846 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 11:18:27.602197 139860156245824 spec.py:348] Evaluating on the test split.
I0922 11:18:29.967836 139860156245824 submission_runner.py:376] Time since start: 32475.31s, 	Step: 92414, 	{'train/accuracy': 0.75589919090271, 'train/loss': 1.1579933166503906, 'validation/accuracy': 0.6836999654769897, 'validation/loss': 1.4863077402114868, 'validation/num_examples': 50000, 'test/accuracy': 0.555400013923645, 'test/loss': 2.1091015338897705, 'test/num_examples': 10000, 'score': 31181.531277656555, 'total_duration': 32475.31089401245, 'accumulated_submission_time': 31181.531277656555, 'accumulated_eval_time': 1290.3574063777924, 'accumulated_logging_time': 2.0792813301086426}
I0922 11:18:29.993032 139695103104768 logging_writer.py:48] [92414] accumulated_eval_time=1290.357406, accumulated_logging_time=2.079281, accumulated_submission_time=31181.531278, global_step=92414, preemption_count=0, score=31181.531278, test/accuracy=0.555400, test/loss=2.109102, test/num_examples=10000, total_duration=32475.310894, train/accuracy=0.755899, train/loss=1.157993, validation/accuracy=0.683700, validation/loss=1.486308, validation/num_examples=50000
I0922 11:18:59.282372 139695111497472 logging_writer.py:48] [92500] global_step=92500, grad_norm=0.36085614562034607, loss=3.099689483642578
I0922 11:21:47.436110 139695103104768 logging_writer.py:48] [93000] global_step=93000, grad_norm=0.34331098198890686, loss=3.046717643737793
I0922 11:24:35.682698 139695111497472 logging_writer.py:48] [93500] global_step=93500, grad_norm=0.34997808933258057, loss=3.1127068996429443
I0922 11:27:00.226773 139860156245824 spec.py:320] Evaluating on the training split.
I0922 11:27:08.088682 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 11:27:18.806984 139860156245824 spec.py:348] Evaluating on the test split.
I0922 11:27:21.210820 139860156245824 submission_runner.py:376] Time since start: 33006.55s, 	Step: 93931, 	{'train/accuracy': 0.7458944320678711, 'train/loss': 1.2392172813415527, 'validation/accuracy': 0.6752399802207947, 'validation/loss': 1.5416216850280762, 'validation/num_examples': 50000, 'test/accuracy': 0.5484000444412231, 'test/loss': 2.184175729751587, 'test/num_examples': 10000, 'score': 31691.732520103455, 'total_duration': 33006.55387425423, 'accumulated_submission_time': 31691.732520103455, 'accumulated_eval_time': 1311.3414387702942, 'accumulated_logging_time': 2.1146469116210938}
I0922 11:27:21.236881 139695002457856 logging_writer.py:48] [93931] accumulated_eval_time=1311.341439, accumulated_logging_time=2.114647, accumulated_submission_time=31691.732520, global_step=93931, preemption_count=0, score=31691.732520, test/accuracy=0.548400, test/loss=2.184176, test/num_examples=10000, total_duration=33006.553874, train/accuracy=0.745894, train/loss=1.239217, validation/accuracy=0.675240, validation/loss=1.541622, validation/num_examples=50000
I0922 11:27:44.753658 139695010850560 logging_writer.py:48] [94000] global_step=94000, grad_norm=0.35688820481300354, loss=3.0954811573028564
I0922 11:30:32.994626 139695002457856 logging_writer.py:48] [94500] global_step=94500, grad_norm=0.37291014194488525, loss=3.1540515422821045
I0922 11:33:21.303064 139695010850560 logging_writer.py:48] [95000] global_step=95000, grad_norm=0.3565273880958557, loss=3.0784387588500977
I0922 11:35:51.417777 139860156245824 spec.py:320] Evaluating on the training split.
I0922 11:35:59.171035 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 11:36:10.025879 139860156245824 spec.py:348] Evaluating on the test split.
I0922 11:36:12.370424 139860156245824 submission_runner.py:376] Time since start: 33537.71s, 	Step: 95448, 	{'train/accuracy': 0.7518335580825806, 'train/loss': 1.2238816022872925, 'validation/accuracy': 0.6846199631690979, 'validation/loss': 1.514003038406372, 'validation/num_examples': 50000, 'test/accuracy': 0.5603000521659851, 'test/loss': 2.1432273387908936, 'test/num_examples': 10000, 'score': 32201.880815029144, 'total_duration': 33537.71345996857, 'accumulated_submission_time': 32201.880815029144, 'accumulated_eval_time': 1332.2940497398376, 'accumulated_logging_time': 2.1513895988464355}
I0922 11:36:12.405378 139695119890176 logging_writer.py:48] [95448] accumulated_eval_time=1332.294050, accumulated_logging_time=2.151390, accumulated_submission_time=32201.880815, global_step=95448, preemption_count=0, score=32201.880815, test/accuracy=0.560300, test/loss=2.143227, test/num_examples=10000, total_duration=33537.713460, train/accuracy=0.751834, train/loss=1.223882, validation/accuracy=0.684620, validation/loss=1.514003, validation/num_examples=50000
I0922 11:36:30.272288 139695128282880 logging_writer.py:48] [95500] global_step=95500, grad_norm=0.36237606406211853, loss=3.0554237365722656
I0922 11:39:18.575574 139695119890176 logging_writer.py:48] [96000] global_step=96000, grad_norm=0.36224979162216187, loss=3.039173126220703
I0922 11:42:06.954165 139695128282880 logging_writer.py:48] [96500] global_step=96500, grad_norm=0.38897112011909485, loss=3.1279184818267822
I0922 11:44:42.666741 139860156245824 spec.py:320] Evaluating on the training split.
I0922 11:44:50.482321 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 11:45:01.283921 139860156245824 spec.py:348] Evaluating on the test split.
I0922 11:45:03.692245 139860156245824 submission_runner.py:376] Time since start: 34069.04s, 	Step: 96964, 	{'train/accuracy': 0.7579918503761292, 'train/loss': 1.195346713066101, 'validation/accuracy': 0.6843000054359436, 'validation/loss': 1.5134482383728027, 'validation/num_examples': 50000, 'test/accuracy': 0.5520000457763672, 'test/loss': 2.152961254119873, 'test/num_examples': 10000, 'score': 32712.109286546707, 'total_duration': 34069.0353000164, 'accumulated_submission_time': 32712.109286546707, 'accumulated_eval_time': 1353.319528579712, 'accumulated_logging_time': 2.1969006061553955}
I0922 11:45:03.718028 139695010850560 logging_writer.py:48] [96964] accumulated_eval_time=1353.319529, accumulated_logging_time=2.196901, accumulated_submission_time=32712.109287, global_step=96964, preemption_count=0, score=32712.109287, test/accuracy=0.552000, test/loss=2.152961, test/num_examples=10000, total_duration=34069.035300, train/accuracy=0.757992, train/loss=1.195347, validation/accuracy=0.684300, validation/loss=1.513448, validation/num_examples=50000
I0922 11:45:16.183039 139695019243264 logging_writer.py:48] [97000] global_step=97000, grad_norm=0.37729403376579285, loss=3.109745502471924
I0922 11:48:04.329383 139695010850560 logging_writer.py:48] [97500] global_step=97500, grad_norm=0.3683171570301056, loss=3.0534369945526123
I0922 11:50:52.530863 139695019243264 logging_writer.py:48] [98000] global_step=98000, grad_norm=0.3733269274234772, loss=3.0977816581726074
I0922 11:53:33.694569 139860156245824 spec.py:320] Evaluating on the training split.
I0922 11:53:41.470099 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 11:53:52.358393 139860156245824 spec.py:348] Evaluating on the test split.
I0922 11:53:54.683045 139860156245824 submission_runner.py:376] Time since start: 34600.03s, 	Step: 98480, 	{'train/accuracy': 0.7780413031578064, 'train/loss': 1.0820232629776, 'validation/accuracy': 0.6803999543190002, 'validation/loss': 1.4932386875152588, 'validation/num_examples': 50000, 'test/accuracy': 0.5489000082015991, 'test/loss': 2.1461191177368164, 'test/num_examples': 10000, 'score': 33222.051538944244, 'total_duration': 34600.02610182762, 'accumulated_submission_time': 33222.051538944244, 'accumulated_eval_time': 1374.3079960346222, 'accumulated_logging_time': 2.234945058822632}
I0922 11:53:54.709266 139695119890176 logging_writer.py:48] [98480] accumulated_eval_time=1374.307996, accumulated_logging_time=2.234945, accumulated_submission_time=33222.051539, global_step=98480, preemption_count=0, score=33222.051539, test/accuracy=0.548900, test/loss=2.146119, test/num_examples=10000, total_duration=34600.026102, train/accuracy=0.778041, train/loss=1.082023, validation/accuracy=0.680400, validation/loss=1.493239, validation/num_examples=50000
I0922 11:54:01.783751 139695128282880 logging_writer.py:48] [98500] global_step=98500, grad_norm=0.3744821548461914, loss=3.0455868244171143
I0922 11:56:50.038060 139695119890176 logging_writer.py:48] [99000] global_step=99000, grad_norm=0.37727391719818115, loss=3.0233073234558105
I0922 11:59:38.383992 139695128282880 logging_writer.py:48] [99500] global_step=99500, grad_norm=0.35705918073654175, loss=3.0444259643554688
I0922 12:02:25.008686 139860156245824 spec.py:320] Evaluating on the training split.
I0922 12:02:32.744433 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 12:02:43.668889 139860156245824 spec.py:348] Evaluating on the test split.
I0922 12:02:46.036462 139860156245824 submission_runner.py:376] Time since start: 35131.38s, 	Step: 99997, 	{'train/accuracy': 0.7504384517669678, 'train/loss': 1.1970044374465942, 'validation/accuracy': 0.6700999736785889, 'validation/loss': 1.5616356134414673, 'validation/num_examples': 50000, 'test/accuracy': 0.5401000380516052, 'test/loss': 2.2250664234161377, 'test/num_examples': 10000, 'score': 33732.31796813011, 'total_duration': 35131.379509449005, 'accumulated_submission_time': 33732.31796813011, 'accumulated_eval_time': 1395.3357439041138, 'accumulated_logging_time': 2.272613286972046}
I0922 12:02:46.066389 139694994065152 logging_writer.py:48] [99997] accumulated_eval_time=1395.335744, accumulated_logging_time=2.272613, accumulated_submission_time=33732.317968, global_step=99997, preemption_count=0, score=33732.317968, test/accuracy=0.540100, test/loss=2.225066, test/num_examples=10000, total_duration=35131.379509, train/accuracy=0.750438, train/loss=1.197004, validation/accuracy=0.670100, validation/loss=1.561636, validation/num_examples=50000
I0922 12:02:47.424462 139695002457856 logging_writer.py:48] [100000] global_step=100000, grad_norm=0.36224398016929626, loss=2.9723713397979736
I0922 12:05:35.598232 139694994065152 logging_writer.py:48] [100500] global_step=100500, grad_norm=0.3734777271747589, loss=2.988680362701416
I0922 12:08:23.956152 139695002457856 logging_writer.py:48] [101000] global_step=101000, grad_norm=0.3811061382293701, loss=3.113577127456665
I0922 12:11:12.127882 139694994065152 logging_writer.py:48] [101500] global_step=101500, grad_norm=0.3855360746383667, loss=2.9974679946899414
I0922 12:11:16.253561 139860156245824 spec.py:320] Evaluating on the training split.
I0922 12:11:24.031488 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 12:11:34.860851 139860156245824 spec.py:348] Evaluating on the test split.
I0922 12:11:37.198306 139860156245824 submission_runner.py:376] Time since start: 35662.54s, 	Step: 101514, 	{'train/accuracy': 0.7671595811843872, 'train/loss': 1.150720477104187, 'validation/accuracy': 0.6864799857139587, 'validation/loss': 1.505958080291748, 'validation/num_examples': 50000, 'test/accuracy': 0.5595000386238098, 'test/loss': 2.15362286567688, 'test/num_examples': 10000, 'score': 34242.47125029564, 'total_duration': 35662.541338682175, 'accumulated_submission_time': 34242.47125029564, 'accumulated_eval_time': 1416.2804539203644, 'accumulated_logging_time': 2.314411163330078}
I0922 12:11:37.223531 139695027635968 logging_writer.py:48] [101514] accumulated_eval_time=1416.280454, accumulated_logging_time=2.314411, accumulated_submission_time=34242.471250, global_step=101514, preemption_count=0, score=34242.471250, test/accuracy=0.559500, test/loss=2.153623, test/num_examples=10000, total_duration=35662.541339, train/accuracy=0.767160, train/loss=1.150720, validation/accuracy=0.686480, validation/loss=1.505958, validation/num_examples=50000
I0922 12:14:21.198881 139695103104768 logging_writer.py:48] [102000] global_step=102000, grad_norm=0.37843284010887146, loss=3.009821891784668
I0922 12:17:09.509573 139695027635968 logging_writer.py:48] [102500] global_step=102500, grad_norm=0.40568631887435913, loss=3.0113143920898438
I0922 12:19:57.885859 139695103104768 logging_writer.py:48] [103000] global_step=103000, grad_norm=0.4002610743045807, loss=2.9975485801696777
I0922 12:20:07.437203 139860156245824 spec.py:320] Evaluating on the training split.
I0922 12:20:15.123714 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 12:20:26.001198 139860156245824 spec.py:348] Evaluating on the test split.
I0922 12:20:28.384420 139860156245824 submission_runner.py:376] Time since start: 36193.73s, 	Step: 103030, 	{'train/accuracy': 0.77054762840271, 'train/loss': 1.1376694440841675, 'validation/accuracy': 0.6933199763298035, 'validation/loss': 1.4701316356658936, 'validation/num_examples': 50000, 'test/accuracy': 0.567300021648407, 'test/loss': 2.0971527099609375, 'test/num_examples': 10000, 'score': 34752.649332761765, 'total_duration': 36193.727472782135, 'accumulated_submission_time': 34752.649332761765, 'accumulated_eval_time': 1437.2276270389557, 'accumulated_logging_time': 2.352879047393799}
I0922 12:20:28.409468 139695010850560 logging_writer.py:48] [103030] accumulated_eval_time=1437.227627, accumulated_logging_time=2.352879, accumulated_submission_time=34752.649333, global_step=103030, preemption_count=0, score=34752.649333, test/accuracy=0.567300, test/loss=2.097153, test/num_examples=10000, total_duration=36193.727473, train/accuracy=0.770548, train/loss=1.137669, validation/accuracy=0.693320, validation/loss=1.470132, validation/num_examples=50000
I0922 12:23:06.908107 139695019243264 logging_writer.py:48] [103500] global_step=103500, grad_norm=0.4042918086051941, loss=3.04193115234375
I0922 12:25:55.098044 139695010850560 logging_writer.py:48] [104000] global_step=104000, grad_norm=0.38788700103759766, loss=2.976088523864746
I0922 12:28:43.308312 139695019243264 logging_writer.py:48] [104500] global_step=104500, grad_norm=0.39513394236564636, loss=3.0290255546569824
I0922 12:28:58.554435 139860156245824 spec.py:320] Evaluating on the training split.
I0922 12:29:06.325759 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 12:29:17.146253 139860156245824 spec.py:348] Evaluating on the test split.
I0922 12:29:19.519344 139860156245824 submission_runner.py:376] Time since start: 36724.86s, 	Step: 104547, 	{'train/accuracy': 0.7765864133834839, 'train/loss': 1.103898048400879, 'validation/accuracy': 0.7011599540710449, 'validation/loss': 1.4242255687713623, 'validation/num_examples': 50000, 'test/accuracy': 0.5662000179290771, 'test/loss': 2.0970206260681152, 'test/num_examples': 10000, 'score': 35262.76320910454, 'total_duration': 36724.862387657166, 'accumulated_submission_time': 35262.76320910454, 'accumulated_eval_time': 1458.1924831867218, 'accumulated_logging_time': 2.3874409198760986}
I0922 12:29:19.544929 139695002457856 logging_writer.py:48] [104547] accumulated_eval_time=1458.192483, accumulated_logging_time=2.387441, accumulated_submission_time=35262.763209, global_step=104547, preemption_count=0, score=35262.763209, test/accuracy=0.566200, test/loss=2.097021, test/num_examples=10000, total_duration=36724.862388, train/accuracy=0.776586, train/loss=1.103898, validation/accuracy=0.701160, validation/loss=1.424226, validation/num_examples=50000
I0922 12:31:52.448515 139695010850560 logging_writer.py:48] [105000] global_step=105000, grad_norm=0.39788389205932617, loss=3.051504135131836
I0922 12:34:40.757902 139695002457856 logging_writer.py:48] [105500] global_step=105500, grad_norm=0.3981741964817047, loss=2.9839179515838623
I0922 12:37:29.118743 139695010850560 logging_writer.py:48] [106000] global_step=106000, grad_norm=0.38291195034980774, loss=2.8815174102783203
I0922 12:37:49.756270 139860156245824 spec.py:320] Evaluating on the training split.
I0922 12:37:57.500089 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 12:38:08.455563 139860156245824 spec.py:348] Evaluating on the test split.
I0922 12:38:10.834642 139860156245824 submission_runner.py:376] Time since start: 37256.18s, 	Step: 106063, 	{'train/accuracy': 0.8157286047935486, 'train/loss': 0.9369745850563049, 'validation/accuracy': 0.6983199715614319, 'validation/loss': 1.4204775094985962, 'validation/num_examples': 50000, 'test/accuracy': 0.5768000483512878, 'test/loss': 2.0396924018859863, 'test/num_examples': 10000, 'score': 35772.9427614212, 'total_duration': 37256.17768883705, 'accumulated_submission_time': 35772.9427614212, 'accumulated_eval_time': 1479.2708055973053, 'accumulated_logging_time': 2.4226765632629395}
I0922 12:38:10.863697 139695019243264 logging_writer.py:48] [106063] accumulated_eval_time=1479.270806, accumulated_logging_time=2.422677, accumulated_submission_time=35772.942761, global_step=106063, preemption_count=0, score=35772.942761, test/accuracy=0.576800, test/loss=2.039692, test/num_examples=10000, total_duration=37256.177689, train/accuracy=0.815729, train/loss=0.936975, validation/accuracy=0.698320, validation/loss=1.420478, validation/num_examples=50000
I0922 12:40:38.241080 139695027635968 logging_writer.py:48] [106500] global_step=106500, grad_norm=0.39315226674079895, loss=2.967430591583252
I0922 12:43:26.569910 139695019243264 logging_writer.py:48] [107000] global_step=107000, grad_norm=0.4011478126049042, loss=2.9437856674194336
I0922 12:46:14.823060 139695027635968 logging_writer.py:48] [107500] global_step=107500, grad_norm=0.40217670798301697, loss=2.9511048793792725
I0922 12:46:41.117107 139860156245824 spec.py:320] Evaluating on the training split.
I0922 12:46:48.858374 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 12:46:59.675420 139860156245824 spec.py:348] Evaluating on the test split.
I0922 12:47:02.022134 139860156245824 submission_runner.py:376] Time since start: 37787.37s, 	Step: 107580, 	{'train/accuracy': 0.8015385866165161, 'train/loss': 0.990227997303009, 'validation/accuracy': 0.699999988079071, 'validation/loss': 1.4165207147598267, 'validation/num_examples': 50000, 'test/accuracy': 0.5751000046730042, 'test/loss': 2.0457937717437744, 'test/num_examples': 10000, 'score': 36283.16487336159, 'total_duration': 37787.36519193649, 'accumulated_submission_time': 36283.16487336159, 'accumulated_eval_time': 1500.1757967472076, 'accumulated_logging_time': 2.4612035751342773}
I0922 12:47:02.048717 139695111497472 logging_writer.py:48] [107580] accumulated_eval_time=1500.175797, accumulated_logging_time=2.461204, accumulated_submission_time=36283.164873, global_step=107580, preemption_count=0, score=36283.164873, test/accuracy=0.575100, test/loss=2.045794, test/num_examples=10000, total_duration=37787.365192, train/accuracy=0.801539, train/loss=0.990228, validation/accuracy=0.700000, validation/loss=1.416521, validation/num_examples=50000
I0922 12:49:23.692329 139695119890176 logging_writer.py:48] [108000] global_step=108000, grad_norm=0.40008336305618286, loss=2.927460193634033
I0922 12:52:11.981861 139695111497472 logging_writer.py:48] [108500] global_step=108500, grad_norm=0.40903595089912415, loss=2.9166030883789062
I0922 12:55:00.365329 139695119890176 logging_writer.py:48] [109000] global_step=109000, grad_norm=0.40723639726638794, loss=2.984360694885254
I0922 12:55:32.076000 139860156245824 spec.py:320] Evaluating on the training split.
I0922 12:55:39.833823 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 12:55:50.674993 139860156245824 spec.py:348] Evaluating on the test split.
I0922 12:55:53.040975 139860156245824 submission_runner.py:376] Time since start: 38318.38s, 	Step: 109096, 	{'train/accuracy': 0.7924306392669678, 'train/loss': 1.057602047920227, 'validation/accuracy': 0.7021200060844421, 'validation/loss': 1.448128581047058, 'validation/num_examples': 50000, 'test/accuracy': 0.5692000389099121, 'test/loss': 2.0861339569091797, 'test/num_examples': 10000, 'score': 36793.15953063965, 'total_duration': 38318.38403010368, 'accumulated_submission_time': 36793.15953063965, 'accumulated_eval_time': 1521.1407353878021, 'accumulated_logging_time': 2.4985454082489014}
I0922 12:55:53.066786 139695019243264 logging_writer.py:48] [109096] accumulated_eval_time=1521.140735, accumulated_logging_time=2.498545, accumulated_submission_time=36793.159531, global_step=109096, preemption_count=0, score=36793.159531, test/accuracy=0.569200, test/loss=2.086134, test/num_examples=10000, total_duration=38318.384030, train/accuracy=0.792431, train/loss=1.057602, validation/accuracy=0.702120, validation/loss=1.448129, validation/num_examples=50000
I0922 12:58:09.343668 139695027635968 logging_writer.py:48] [109500] global_step=109500, grad_norm=0.4305116832256317, loss=2.961195945739746
I0922 13:00:57.599798 139695019243264 logging_writer.py:48] [110000] global_step=110000, grad_norm=0.4172350764274597, loss=2.9423515796661377
I0922 13:03:45.818978 139695027635968 logging_writer.py:48] [110500] global_step=110500, grad_norm=0.41181015968322754, loss=2.909681558609009
I0922 13:04:23.233308 139860156245824 spec.py:320] Evaluating on the training split.
I0922 13:04:30.927458 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 13:04:41.859235 139860156245824 spec.py:348] Evaluating on the test split.
I0922 13:04:44.204404 139860156245824 submission_runner.py:376] Time since start: 38849.55s, 	Step: 110613, 	{'train/accuracy': 0.8116430044174194, 'train/loss': 0.9804893732070923, 'validation/accuracy': 0.7160999774932861, 'validation/loss': 1.375800609588623, 'validation/num_examples': 50000, 'test/accuracy': 0.5887000560760498, 'test/loss': 1.993880033493042, 'test/num_examples': 10000, 'score': 37303.294801950455, 'total_duration': 38849.54740905762, 'accumulated_submission_time': 37303.294801950455, 'accumulated_eval_time': 1542.1117451190948, 'accumulated_logging_time': 2.5335915088653564}
I0922 13:04:44.231873 139694994065152 logging_writer.py:48] [110613] accumulated_eval_time=1542.111745, accumulated_logging_time=2.533592, accumulated_submission_time=37303.294802, global_step=110613, preemption_count=0, score=37303.294802, test/accuracy=0.588700, test/loss=1.993880, test/num_examples=10000, total_duration=38849.547409, train/accuracy=0.811643, train/loss=0.980489, validation/accuracy=0.716100, validation/loss=1.375801, validation/num_examples=50000
I0922 13:06:54.843603 139695002457856 logging_writer.py:48] [111000] global_step=111000, grad_norm=0.4145013988018036, loss=2.9426937103271484
I0922 13:09:43.142621 139694994065152 logging_writer.py:48] [111500] global_step=111500, grad_norm=0.40487590432167053, loss=2.8157052993774414
I0922 13:12:31.453664 139695002457856 logging_writer.py:48] [112000] global_step=112000, grad_norm=0.428107887506485, loss=2.8629987239837646
I0922 13:13:14.291142 139860156245824 spec.py:320] Evaluating on the training split.
I0922 13:13:21.996573 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 13:13:32.929086 139860156245824 spec.py:348] Evaluating on the test split.
I0922 13:13:35.245185 139860156245824 submission_runner.py:376] Time since start: 39380.59s, 	Step: 112129, 	{'train/accuracy': 0.8158681392669678, 'train/loss': 0.9373319149017334, 'validation/accuracy': 0.72079998254776, 'validation/loss': 1.3203343152999878, 'validation/num_examples': 50000, 'test/accuracy': 0.5950000286102295, 'test/loss': 1.956536054611206, 'test/num_examples': 10000, 'score': 37813.322672367096, 'total_duration': 39380.58823919296, 'accumulated_submission_time': 37813.322672367096, 'accumulated_eval_time': 1563.0657584667206, 'accumulated_logging_time': 2.570284605026245}
I0922 13:13:35.271191 139695002457856 logging_writer.py:48] [112129] accumulated_eval_time=1563.065758, accumulated_logging_time=2.570285, accumulated_submission_time=37813.322672, global_step=112129, preemption_count=0, score=37813.322672, test/accuracy=0.595000, test/loss=1.956536, test/num_examples=10000, total_duration=39380.588239, train/accuracy=0.815868, train/loss=0.937332, validation/accuracy=0.720800, validation/loss=1.320334, validation/num_examples=50000
I0922 13:15:40.446581 139695010850560 logging_writer.py:48] [112500] global_step=112500, grad_norm=0.41734740138053894, loss=2.8832406997680664
I0922 13:18:28.733171 139695002457856 logging_writer.py:48] [113000] global_step=113000, grad_norm=0.4331689774990082, loss=2.8942651748657227
I0922 13:21:17.094303 139695010850560 logging_writer.py:48] [113500] global_step=113500, grad_norm=0.4434668719768524, loss=2.883545398712158
I0922 13:22:05.337402 139860156245824 spec.py:320] Evaluating on the training split.
I0922 13:22:13.058102 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 13:22:23.884987 139860156245824 spec.py:348] Evaluating on the test split.
I0922 13:22:26.220037 139860156245824 submission_runner.py:376] Time since start: 39911.56s, 	Step: 113645, 	{'train/accuracy': 0.8153699040412903, 'train/loss': 0.9452801942825317, 'validation/accuracy': 0.7195000052452087, 'validation/loss': 1.3459440469741821, 'validation/num_examples': 50000, 'test/accuracy': 0.5991000533103943, 'test/loss': 1.9470158815383911, 'test/num_examples': 10000, 'score': 38323.35699033737, 'total_duration': 39911.563091278076, 'accumulated_submission_time': 38323.35699033737, 'accumulated_eval_time': 1583.9483547210693, 'accumulated_logging_time': 2.6063740253448486}
I0922 13:22:26.245726 139695119890176 logging_writer.py:48] [113645] accumulated_eval_time=1583.948355, accumulated_logging_time=2.606374, accumulated_submission_time=38323.356990, global_step=113645, preemption_count=0, score=38323.356990, test/accuracy=0.599100, test/loss=1.947016, test/num_examples=10000, total_duration=39911.563091, train/accuracy=0.815370, train/loss=0.945280, validation/accuracy=0.719500, validation/loss=1.345944, validation/num_examples=50000
I0922 13:24:25.995222 139695128282880 logging_writer.py:48] [114000] global_step=114000, grad_norm=0.41931742429733276, loss=2.8089537620544434
I0922 13:27:14.359957 139695119890176 logging_writer.py:48] [114500] global_step=114500, grad_norm=0.4341851472854614, loss=2.831777572631836
I0922 13:30:02.630355 139695128282880 logging_writer.py:48] [115000] global_step=115000, grad_norm=0.4458910822868347, loss=2.8577933311462402
I0922 13:30:56.505445 139860156245824 spec.py:320] Evaluating on the training split.
I0922 13:31:04.257061 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 13:31:15.097988 139860156245824 spec.py:348] Evaluating on the test split.
I0922 13:31:17.376874 139860156245824 submission_runner.py:376] Time since start: 40442.72s, 	Step: 115162, 	{'train/accuracy': 0.8506855964660645, 'train/loss': 0.7918691635131836, 'validation/accuracy': 0.7225799560546875, 'validation/loss': 1.3202199935913086, 'validation/num_examples': 50000, 'test/accuracy': 0.6046000123023987, 'test/loss': 1.9181276559829712, 'test/num_examples': 10000, 'score': 38833.585057258606, 'total_duration': 40442.71990823746, 'accumulated_submission_time': 38833.585057258606, 'accumulated_eval_time': 1604.8197665214539, 'accumulated_logging_time': 2.641450881958008}
I0922 13:31:17.401880 139695010850560 logging_writer.py:48] [115162] accumulated_eval_time=1604.819767, accumulated_logging_time=2.641451, accumulated_submission_time=38833.585057, global_step=115162, preemption_count=0, score=38833.585057, test/accuracy=0.604600, test/loss=1.918128, test/num_examples=10000, total_duration=40442.719908, train/accuracy=0.850686, train/loss=0.791869, validation/accuracy=0.722580, validation/loss=1.320220, validation/num_examples=50000
I0922 13:33:11.561498 139695019243264 logging_writer.py:48] [115500] global_step=115500, grad_norm=0.45372244715690613, loss=2.8746771812438965
I0922 13:35:59.884711 139695010850560 logging_writer.py:48] [116000] global_step=116000, grad_norm=0.45949459075927734, loss=2.8391976356506348
I0922 13:38:48.105041 139695019243264 logging_writer.py:48] [116500] global_step=116500, grad_norm=0.456575483083725, loss=2.748798370361328
I0922 13:39:47.710379 139860156245824 spec.py:320] Evaluating on the training split.
I0922 13:39:55.529533 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 13:40:06.362959 139860156245824 spec.py:348] Evaluating on the test split.
I0922 13:40:08.707926 139860156245824 submission_runner.py:376] Time since start: 40974.05s, 	Step: 116679, 	{'train/accuracy': 0.8448461294174194, 'train/loss': 0.8080134987831116, 'validation/accuracy': 0.7315799593925476, 'validation/loss': 1.2733973264694214, 'validation/num_examples': 50000, 'test/accuracy': 0.6075000166893005, 'test/loss': 1.8885676860809326, 'test/num_examples': 10000, 'score': 39343.86174798012, 'total_duration': 40974.05097866058, 'accumulated_submission_time': 39343.86174798012, 'accumulated_eval_time': 1625.817280292511, 'accumulated_logging_time': 2.676112651824951}
I0922 13:40:08.735561 139695111497472 logging_writer.py:48] [116679] accumulated_eval_time=1625.817280, accumulated_logging_time=2.676113, accumulated_submission_time=39343.861748, global_step=116679, preemption_count=0, score=39343.861748, test/accuracy=0.607500, test/loss=1.888568, test/num_examples=10000, total_duration=40974.050979, train/accuracy=0.844846, train/loss=0.808013, validation/accuracy=0.731580, validation/loss=1.273397, validation/num_examples=50000
I0922 13:41:57.062474 139695119890176 logging_writer.py:48] [117000] global_step=117000, grad_norm=0.46781298518180847, loss=2.7853496074676514
I0922 13:44:45.335692 139695111497472 logging_writer.py:48] [117500] global_step=117500, grad_norm=0.45527103543281555, loss=2.732095718383789
I0922 13:47:33.657916 139695119890176 logging_writer.py:48] [118000] global_step=118000, grad_norm=0.4629472494125366, loss=2.7531635761260986
I0922 13:48:38.737691 139860156245824 spec.py:320] Evaluating on the training split.
I0922 13:48:46.394442 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 13:48:57.213061 139860156245824 spec.py:348] Evaluating on the test split.
I0922 13:49:00.165944 139860156245824 submission_runner.py:376] Time since start: 41505.51s, 	Step: 118195, 	{'train/accuracy': 0.8509048223495483, 'train/loss': 0.8078310489654541, 'validation/accuracy': 0.7376199960708618, 'validation/loss': 1.2678614854812622, 'validation/num_examples': 50000, 'test/accuracy': 0.6170000433921814, 'test/loss': 1.8626408576965332, 'test/num_examples': 10000, 'score': 39853.830624341965, 'total_duration': 41505.509009838104, 'accumulated_submission_time': 39853.830624341965, 'accumulated_eval_time': 1647.2455101013184, 'accumulated_logging_time': 2.7148563861846924}
I0922 13:49:00.187371 139695019243264 logging_writer.py:48] [118195] accumulated_eval_time=1647.245510, accumulated_logging_time=2.714856, accumulated_submission_time=39853.830624, global_step=118195, preemption_count=0, score=39853.830624, test/accuracy=0.617000, test/loss=1.862641, test/num_examples=10000, total_duration=41505.509010, train/accuracy=0.850905, train/loss=0.807831, validation/accuracy=0.737620, validation/loss=1.267861, validation/num_examples=50000
I0922 13:50:43.190203 139695027635968 logging_writer.py:48] [118500] global_step=118500, grad_norm=0.44948384165763855, loss=2.7708957195281982
I0922 13:53:31.495556 139695019243264 logging_writer.py:48] [119000] global_step=119000, grad_norm=0.4645913243293762, loss=2.8006255626678467
I0922 13:56:19.790028 139695027635968 logging_writer.py:48] [119500] global_step=119500, grad_norm=0.4732317626476288, loss=2.713559865951538
I0922 13:57:30.253629 139860156245824 spec.py:320] Evaluating on the training split.
I0922 13:57:37.989624 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 13:57:48.848376 139860156245824 spec.py:348] Evaluating on the test split.
I0922 13:57:51.184867 139860156245824 submission_runner.py:376] Time since start: 42036.53s, 	Step: 119711, 	{'train/accuracy': 0.851980984210968, 'train/loss': 0.8017945289611816, 'validation/accuracy': 0.743939995765686, 'validation/loss': 1.2531801462173462, 'validation/num_examples': 50000, 'test/accuracy': 0.6211000084877014, 'test/loss': 1.8467514514923096, 'test/num_examples': 10000, 'score': 40363.865280628204, 'total_duration': 42036.52791571617, 'accumulated_submission_time': 40363.865280628204, 'accumulated_eval_time': 1668.1767156124115, 'accumulated_logging_time': 2.7459404468536377}
I0922 13:57:51.211233 139695010850560 logging_writer.py:48] [119711] accumulated_eval_time=1668.176716, accumulated_logging_time=2.745940, accumulated_submission_time=40363.865281, global_step=119711, preemption_count=0, score=40363.865281, test/accuracy=0.621100, test/loss=1.846751, test/num_examples=10000, total_duration=42036.527916, train/accuracy=0.851981, train/loss=0.801795, validation/accuracy=0.743940, validation/loss=1.253180, validation/num_examples=50000
I0922 13:59:28.751295 139695019243264 logging_writer.py:48] [120000] global_step=120000, grad_norm=0.4863750636577606, loss=2.746298313140869
I0922 14:02:16.999966 139695010850560 logging_writer.py:48] [120500] global_step=120500, grad_norm=0.49786457419395447, loss=2.7949604988098145
I0922 14:05:05.234894 139695019243264 logging_writer.py:48] [121000] global_step=121000, grad_norm=0.5024818778038025, loss=2.727783679962158
I0922 14:06:21.400939 139860156245824 spec.py:320] Evaluating on the training split.
I0922 14:06:29.110521 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 14:06:39.934713 139860156245824 spec.py:348] Evaluating on the test split.
I0922 14:06:42.298877 139860156245824 submission_runner.py:376] Time since start: 42567.64s, 	Step: 121228, 	{'train/accuracy': 0.8600326776504517, 'train/loss': 0.760419487953186, 'validation/accuracy': 0.746999979019165, 'validation/loss': 1.2122291326522827, 'validation/num_examples': 50000, 'test/accuracy': 0.6303000450134277, 'test/loss': 1.8107094764709473, 'test/num_examples': 10000, 'score': 40874.023218393326, 'total_duration': 42567.6419274807, 'accumulated_submission_time': 40874.023218393326, 'accumulated_eval_time': 1689.0746266841888, 'accumulated_logging_time': 2.78195858001709}
I0922 14:06:42.324671 139695103104768 logging_writer.py:48] [121228] accumulated_eval_time=1689.074627, accumulated_logging_time=2.781959, accumulated_submission_time=40874.023218, global_step=121228, preemption_count=0, score=40874.023218, test/accuracy=0.630300, test/loss=1.810709, test/num_examples=10000, total_duration=42567.641927, train/accuracy=0.860033, train/loss=0.760419, validation/accuracy=0.747000, validation/loss=1.212229, validation/num_examples=50000
I0922 14:08:14.184952 139695119890176 logging_writer.py:48] [121500] global_step=121500, grad_norm=0.4739172160625458, loss=2.6523056030273438
I0922 14:11:02.412118 139695103104768 logging_writer.py:48] [122000] global_step=122000, grad_norm=0.4959179759025574, loss=2.6937432289123535
I0922 14:13:50.696455 139695119890176 logging_writer.py:48] [122500] global_step=122500, grad_norm=0.5233604311943054, loss=2.764500379562378
I0922 14:15:12.603813 139860156245824 spec.py:320] Evaluating on the training split.
I0922 14:15:20.342246 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 14:15:31.315787 139860156245824 spec.py:348] Evaluating on the test split.
I0922 14:15:33.731977 139860156245824 submission_runner.py:376] Time since start: 43099.07s, 	Step: 122745, 	{'train/accuracy': 0.8763352632522583, 'train/loss': 0.706902027130127, 'validation/accuracy': 0.7577399611473083, 'validation/loss': 1.1869767904281616, 'validation/num_examples': 50000, 'test/accuracy': 0.6366000175476074, 'test/loss': 1.7874842882156372, 'test/num_examples': 10000, 'score': 41384.26992273331, 'total_duration': 43099.07498002052, 'accumulated_submission_time': 41384.26992273331, 'accumulated_eval_time': 1710.2027170658112, 'accumulated_logging_time': 2.8178248405456543}
I0922 14:15:33.757855 139694994065152 logging_writer.py:48] [122745] accumulated_eval_time=1710.202717, accumulated_logging_time=2.817825, accumulated_submission_time=41384.269923, global_step=122745, preemption_count=0, score=41384.269923, test/accuracy=0.636600, test/loss=1.787484, test/num_examples=10000, total_duration=43099.074980, train/accuracy=0.876335, train/loss=0.706902, validation/accuracy=0.757740, validation/loss=1.186977, validation/num_examples=50000
I0922 14:16:59.934286 139695002457856 logging_writer.py:48] [123000] global_step=123000, grad_norm=0.5021028518676758, loss=2.6923577785491943
I0922 14:19:48.212533 139694994065152 logging_writer.py:48] [123500] global_step=123500, grad_norm=0.4957360327243805, loss=2.718137741088867
I0922 14:22:36.399009 139695002457856 logging_writer.py:48] [124000] global_step=124000, grad_norm=0.5020326972007751, loss=2.652066469192505
I0922 14:24:03.902147 139860156245824 spec.py:320] Evaluating on the training split.
I0922 14:24:11.666417 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 14:24:22.513501 139860156245824 spec.py:348] Evaluating on the test split.
I0922 14:24:24.868704 139860156245824 submission_runner.py:376] Time since start: 43630.21s, 	Step: 124262, 	{'train/accuracy': 0.8968231678009033, 'train/loss': 0.621975302696228, 'validation/accuracy': 0.7638999819755554, 'validation/loss': 1.1538081169128418, 'validation/num_examples': 50000, 'test/accuracy': 0.6439000368118286, 'test/loss': 1.7414237260818481, 'test/num_examples': 10000, 'score': 41894.382313251495, 'total_duration': 43630.21175980568, 'accumulated_submission_time': 41894.382313251495, 'accumulated_eval_time': 1731.169250011444, 'accumulated_logging_time': 2.85366153717041}
I0922 14:24:24.895471 139695111497472 logging_writer.py:48] [124262] accumulated_eval_time=1731.169250, accumulated_logging_time=2.853662, accumulated_submission_time=41894.382313, global_step=124262, preemption_count=0, score=41894.382313, test/accuracy=0.643900, test/loss=1.741424, test/num_examples=10000, total_duration=43630.211760, train/accuracy=0.896823, train/loss=0.621975, validation/accuracy=0.763900, validation/loss=1.153808, validation/num_examples=50000
I0922 14:25:45.341793 139695119890176 logging_writer.py:48] [124500] global_step=124500, grad_norm=0.5162554979324341, loss=2.6894774436950684
I0922 14:28:33.509979 139695111497472 logging_writer.py:48] [125000] global_step=125000, grad_norm=0.5169031023979187, loss=2.6673166751861572
I0922 14:31:21.747339 139695119890176 logging_writer.py:48] [125500] global_step=125500, grad_norm=0.5202654004096985, loss=2.6962790489196777
I0922 14:32:55.063068 139860156245824 spec.py:320] Evaluating on the training split.
I0922 14:33:02.752099 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 14:33:13.696105 139860156245824 spec.py:348] Evaluating on the test split.
I0922 14:33:16.086627 139860156245824 submission_runner.py:376] Time since start: 44161.43s, 	Step: 125779, 	{'train/accuracy': 0.9035195708274841, 'train/loss': 0.6033666729927063, 'validation/accuracy': 0.7686600089073181, 'validation/loss': 1.1359121799468994, 'validation/num_examples': 50000, 'test/accuracy': 0.6485000252723694, 'test/loss': 1.7149373292922974, 'test/num_examples': 10000, 'score': 42404.51796746254, 'total_duration': 44161.42968297005, 'accumulated_submission_time': 42404.51796746254, 'accumulated_eval_time': 1752.1927847862244, 'accumulated_logging_time': 2.890361785888672}
I0922 14:33:16.115750 139695002457856 logging_writer.py:48] [125779] accumulated_eval_time=1752.192785, accumulated_logging_time=2.890362, accumulated_submission_time=42404.517967, global_step=125779, preemption_count=0, score=42404.517967, test/accuracy=0.648500, test/loss=1.714937, test/num_examples=10000, total_duration=44161.429683, train/accuracy=0.903520, train/loss=0.603367, validation/accuracy=0.768660, validation/loss=1.135912, validation/num_examples=50000
I0922 14:34:30.834344 139695010850560 logging_writer.py:48] [126000] global_step=126000, grad_norm=0.5136191248893738, loss=2.6425092220306396
I0922 14:37:19.054996 139695002457856 logging_writer.py:48] [126500] global_step=126500, grad_norm=0.49416664242744446, loss=2.633976459503174
I0922 14:40:07.300811 139695010850560 logging_writer.py:48] [127000] global_step=127000, grad_norm=0.5213608145713806, loss=2.628065586090088
I0922 14:41:46.315765 139860156245824 spec.py:320] Evaluating on the training split.
I0922 14:41:53.970600 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 14:42:04.863081 139860156245824 spec.py:348] Evaluating on the test split.
I0922 14:42:07.222269 139860156245824 submission_runner.py:376] Time since start: 44692.57s, 	Step: 127296, 	{'train/accuracy': 0.9037986397743225, 'train/loss': 0.6011214256286621, 'validation/accuracy': 0.772059977054596, 'validation/loss': 1.1232010126113892, 'validation/num_examples': 50000, 'test/accuracy': 0.6530000567436218, 'test/loss': 1.7030549049377441, 'test/num_examples': 10000, 'score': 42914.685732364655, 'total_duration': 44692.565321445465, 'accumulated_submission_time': 42914.685732364655, 'accumulated_eval_time': 1773.099259853363, 'accumulated_logging_time': 2.929689645767212}
I0922 14:42:07.249055 139695119890176 logging_writer.py:48] [127296] accumulated_eval_time=1773.099260, accumulated_logging_time=2.929690, accumulated_submission_time=42914.685732, global_step=127296, preemption_count=0, score=42914.685732, test/accuracy=0.653000, test/loss=1.703055, test/num_examples=10000, total_duration=44692.565321, train/accuracy=0.903799, train/loss=0.601121, validation/accuracy=0.772060, validation/loss=1.123201, validation/num_examples=50000
I0922 14:43:16.196188 139695128282880 logging_writer.py:48] [127500] global_step=127500, grad_norm=0.4955539107322693, loss=2.5567879676818848
I0922 14:46:04.374992 139695119890176 logging_writer.py:48] [128000] global_step=128000, grad_norm=0.4911099970340729, loss=2.595285177230835
I0922 14:48:52.783396 139695128282880 logging_writer.py:48] [128500] global_step=128500, grad_norm=0.49097463488578796, loss=2.5632922649383545
I0922 14:50:37.502999 139860156245824 spec.py:320] Evaluating on the training split.
I0922 14:50:45.421406 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 14:50:56.078167 139860156245824 spec.py:348] Evaluating on the test split.
I0922 14:50:58.450695 139860156245824 submission_runner.py:376] Time since start: 45223.79s, 	Step: 128813, 	{'train/accuracy': 0.9054726958274841, 'train/loss': 0.5933184623718262, 'validation/accuracy': 0.7722199559211731, 'validation/loss': 1.1196633577346802, 'validation/num_examples': 50000, 'test/accuracy': 0.6549000144004822, 'test/loss': 1.6986366510391235, 'test/num_examples': 10000, 'score': 43424.90678334236, 'total_duration': 45223.79325962067, 'accumulated_submission_time': 43424.90678334236, 'accumulated_eval_time': 1794.0464432239532, 'accumulated_logging_time': 2.967623710632324}
I0922 14:50:58.477439 139694994065152 logging_writer.py:48] [128813] accumulated_eval_time=1794.046443, accumulated_logging_time=2.967624, accumulated_submission_time=43424.906783, global_step=128813, preemption_count=0, score=43424.906783, test/accuracy=0.654900, test/loss=1.698637, test/num_examples=10000, total_duration=45223.793260, train/accuracy=0.905473, train/loss=0.593318, validation/accuracy=0.772220, validation/loss=1.119663, validation/num_examples=50000
I0922 14:52:01.784801 139695002457856 logging_writer.py:48] [129000] global_step=129000, grad_norm=0.51382976770401, loss=2.606639862060547
I0922 14:54:50.002864 139694994065152 logging_writer.py:48] [129500] global_step=129500, grad_norm=0.5335409641265869, loss=2.6782448291778564
I0922 14:57:38.212941 139695002457856 logging_writer.py:48] [130000] global_step=130000, grad_norm=0.4971310794353485, loss=2.574058771133423
I0922 14:59:28.726058 139860156245824 spec.py:320] Evaluating on the training split.
I0922 14:59:36.678364 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 14:59:47.515585 139860156245824 spec.py:348] Evaluating on the test split.
I0922 14:59:49.877684 139860156245824 submission_runner.py:376] Time since start: 45755.22s, 	Step: 130330, 	{'train/accuracy': 0.90433669090271, 'train/loss': 0.5941982865333557, 'validation/accuracy': 0.7730399966239929, 'validation/loss': 1.1208032369613647, 'validation/num_examples': 50000, 'test/accuracy': 0.6545000076293945, 'test/loss': 1.6990039348602295, 'test/num_examples': 10000, 'score': 43935.1196911335, 'total_duration': 45755.22074198723, 'accumulated_submission_time': 43935.1196911335, 'accumulated_eval_time': 1815.1980483531952, 'accumulated_logging_time': 3.007782459259033}
I0922 14:59:49.904620 139695111497472 logging_writer.py:48] [130330] accumulated_eval_time=1815.198048, accumulated_logging_time=3.007782, accumulated_submission_time=43935.119691, global_step=130330, preemption_count=0, score=43935.119691, test/accuracy=0.654500, test/loss=1.699004, test/num_examples=10000, total_duration=45755.220742, train/accuracy=0.904337, train/loss=0.594198, validation/accuracy=0.773040, validation/loss=1.120803, validation/num_examples=50000
I0922 15:00:47.416389 139695119890176 logging_writer.py:48] [130500] global_step=130500, grad_norm=0.523895800113678, loss=2.596750259399414
I0922 15:03:35.663610 139695111497472 logging_writer.py:48] [131000] global_step=131000, grad_norm=0.5025109052658081, loss=2.5442757606506348
I0922 15:06:23.802313 139695119890176 logging_writer.py:48] [131500] global_step=131500, grad_norm=0.4901115596294403, loss=2.5410428047180176
I0922 15:08:19.973057 139860156245824 spec.py:320] Evaluating on the training split.
I0922 15:08:27.595357 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 15:08:38.460160 139860156245824 spec.py:348] Evaluating on the test split.
I0922 15:08:40.793148 139860156245824 submission_runner.py:376] Time since start: 46286.14s, 	Step: 131847, 	{'train/accuracy': 0.9038584232330322, 'train/loss': 0.5937583446502686, 'validation/accuracy': 0.7728399634361267, 'validation/loss': 1.1189135313034058, 'validation/num_examples': 50000, 'test/accuracy': 0.655500054359436, 'test/loss': 1.6975986957550049, 'test/num_examples': 10000, 'score': 44445.155653715134, 'total_duration': 46286.13620018959, 'accumulated_submission_time': 44445.155653715134, 'accumulated_eval_time': 1836.0181152820587, 'accumulated_logging_time': 3.044888973236084}
I0922 15:08:40.821736 139694994065152 logging_writer.py:48] [131847] accumulated_eval_time=1836.018115, accumulated_logging_time=3.044889, accumulated_submission_time=44445.155654, global_step=131847, preemption_count=0, score=44445.155654, test/accuracy=0.655500, test/loss=1.697599, test/num_examples=10000, total_duration=46286.136200, train/accuracy=0.903858, train/loss=0.593758, validation/accuracy=0.772840, validation/loss=1.118914, validation/num_examples=50000
I0922 15:09:32.648880 139695002457856 logging_writer.py:48] [132000] global_step=132000, grad_norm=0.5203520059585571, loss=2.6161677837371826
I0922 15:12:20.904638 139694994065152 logging_writer.py:48] [132500] global_step=132500, grad_norm=0.5014755129814148, loss=2.55346417427063
I0922 15:15:09.077685 139695002457856 logging_writer.py:48] [133000] global_step=133000, grad_norm=0.5035229325294495, loss=2.6005971431732178
I0922 15:17:11.052579 139860156245824 spec.py:320] Evaluating on the training split.
I0922 15:17:18.728417 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 15:17:29.516715 139860156245824 spec.py:348] Evaluating on the test split.
I0922 15:17:31.884770 139860156245824 submission_runner.py:376] Time since start: 46817.23s, 	Step: 133364, 	{'train/accuracy': 0.9064293503761292, 'train/loss': 0.5917299389839172, 'validation/accuracy': 0.773099958896637, 'validation/loss': 1.1213818788528442, 'validation/num_examples': 50000, 'test/accuracy': 0.657200038433075, 'test/loss': 1.7016446590423584, 'test/num_examples': 10000, 'score': 44955.35348391533, 'total_duration': 46817.22782421112, 'accumulated_submission_time': 44955.35348391533, 'accumulated_eval_time': 1856.8502929210663, 'accumulated_logging_time': 3.084364175796509}
I0922 15:17:31.912952 139695002457856 logging_writer.py:48] [133364] accumulated_eval_time=1856.850293, accumulated_logging_time=3.084364, accumulated_submission_time=44955.353484, global_step=133364, preemption_count=0, score=44955.353484, test/accuracy=0.657200, test/loss=1.701645, test/num_examples=10000, total_duration=46817.227824, train/accuracy=0.906429, train/loss=0.591730, validation/accuracy=0.773100, validation/loss=1.121382, validation/num_examples=50000
I0922 15:18:18.002958 139695010850560 logging_writer.py:48] [133500] global_step=133500, grad_norm=0.4889397919178009, loss=2.587672472000122
I0922 15:21:06.350225 139695002457856 logging_writer.py:48] [134000] global_step=134000, grad_norm=0.4949145019054413, loss=2.5660557746887207
I0922 15:23:54.725269 139695010850560 logging_writer.py:48] [134500] global_step=134500, grad_norm=0.5042547583580017, loss=2.611323595046997
I0922 15:26:02.172110 139860156245824 spec.py:320] Evaluating on the training split.
I0922 15:26:09.812829 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 15:26:20.699033 139860156245824 spec.py:348] Evaluating on the test split.
I0922 15:26:23.039289 139860156245824 submission_runner.py:376] Time since start: 47348.38s, 	Step: 134880, 	{'train/accuracy': 0.9071468114852905, 'train/loss': 0.591973602771759, 'validation/accuracy': 0.7734400033950806, 'validation/loss': 1.119201421737671, 'validation/num_examples': 50000, 'test/accuracy': 0.6568000316619873, 'test/loss': 1.6979857683181763, 'test/num_examples': 10000, 'score': 45465.58112287521, 'total_duration': 47348.38234257698, 'accumulated_submission_time': 45465.58112287521, 'accumulated_eval_time': 1877.7174632549286, 'accumulated_logging_time': 3.122377634048462}
I0922 15:26:23.068185 139694994065152 logging_writer.py:48] [134880] accumulated_eval_time=1877.717463, accumulated_logging_time=3.122378, accumulated_submission_time=45465.581123, global_step=134880, preemption_count=0, score=45465.581123, test/accuracy=0.656800, test/loss=1.697986, test/num_examples=10000, total_duration=47348.382343, train/accuracy=0.907147, train/loss=0.591974, validation/accuracy=0.773440, validation/loss=1.119201, validation/num_examples=50000
I0922 15:27:03.774833 139695103104768 logging_writer.py:48] [135000] global_step=135000, grad_norm=0.5072618722915649, loss=2.5448853969573975
I0922 15:29:51.977303 139694994065152 logging_writer.py:48] [135500] global_step=135500, grad_norm=0.5152120590209961, loss=2.5919415950775146
I0922 15:32:40.386421 139695103104768 logging_writer.py:48] [136000] global_step=136000, grad_norm=0.5242469310760498, loss=2.6233620643615723
I0922 15:34:53.048555 139860156245824 spec.py:320] Evaluating on the training split.
I0922 15:35:00.726755 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 15:35:11.636395 139860156245824 spec.py:348] Evaluating on the test split.
I0922 15:35:14.010590 139860156245824 submission_runner.py:376] Time since start: 47879.35s, 	Step: 136396, 	{'train/accuracy': 0.9083226919174194, 'train/loss': 0.5861381888389587, 'validation/accuracy': 0.7735599875450134, 'validation/loss': 1.121933102607727, 'validation/num_examples': 50000, 'test/accuracy': 0.6571000218391418, 'test/loss': 1.6998858451843262, 'test/num_examples': 10000, 'score': 45975.52750468254, 'total_duration': 47879.35364127159, 'accumulated_submission_time': 45975.52750468254, 'accumulated_eval_time': 1898.679480791092, 'accumulated_logging_time': 3.1631991863250732}
I0922 15:35:14.041403 139695019243264 logging_writer.py:48] [136396] accumulated_eval_time=1898.679481, accumulated_logging_time=3.163199, accumulated_submission_time=45975.527505, global_step=136396, preemption_count=0, score=45975.527505, test/accuracy=0.657100, test/loss=1.699886, test/num_examples=10000, total_duration=47879.353641, train/accuracy=0.908323, train/loss=0.586138, validation/accuracy=0.773560, validation/loss=1.121933, validation/num_examples=50000
I0922 15:35:49.396366 139695027635968 logging_writer.py:48] [136500] global_step=136500, grad_norm=0.4896862208843231, loss=2.5458641052246094
I0922 15:38:37.591676 139695019243264 logging_writer.py:48] [137000] global_step=137000, grad_norm=0.5015257000923157, loss=2.5868053436279297
I0922 15:41:25.880674 139695027635968 logging_writer.py:48] [137500] global_step=137500, grad_norm=0.5086358785629272, loss=2.5754480361938477
I0922 15:43:44.332447 139860156245824 spec.py:320] Evaluating on the training split.
I0922 15:43:52.012404 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 15:44:02.865737 139860156245824 spec.py:348] Evaluating on the test split.
I0922 15:44:05.249717 139860156245824 submission_runner.py:376] Time since start: 48410.59s, 	Step: 137913, 	{'train/accuracy': 0.9076849222183228, 'train/loss': 0.5908622145652771, 'validation/accuracy': 0.7728999853134155, 'validation/loss': 1.1200032234191895, 'validation/num_examples': 50000, 'test/accuracy': 0.656000018119812, 'test/loss': 1.69845712184906, 'test/num_examples': 10000, 'score': 46485.78516316414, 'total_duration': 48410.5927529335, 'accumulated_submission_time': 46485.78516316414, 'accumulated_eval_time': 1919.5967102050781, 'accumulated_logging_time': 3.2052040100097656}
I0922 15:44:05.281047 139695010850560 logging_writer.py:48] [137913] accumulated_eval_time=1919.596710, accumulated_logging_time=3.205204, accumulated_submission_time=46485.785163, global_step=137913, preemption_count=0, score=46485.785163, test/accuracy=0.656000, test/loss=1.698457, test/num_examples=10000, total_duration=48410.592753, train/accuracy=0.907685, train/loss=0.590862, validation/accuracy=0.772900, validation/loss=1.120003, validation/num_examples=50000
I0922 15:44:34.860213 139695103104768 logging_writer.py:48] [138000] global_step=138000, grad_norm=0.5236344337463379, loss=2.6338374614715576
I0922 15:47:23.259851 139695010850560 logging_writer.py:48] [138500] global_step=138500, grad_norm=0.5033134818077087, loss=2.590672731399536
I0922 15:50:11.531808 139695103104768 logging_writer.py:48] [139000] global_step=139000, grad_norm=0.5349866151809692, loss=2.595449924468994
I0922 15:52:35.347096 139860156245824 spec.py:320] Evaluating on the training split.
I0922 15:52:42.990180 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 15:52:53.883996 139860156245824 spec.py:348] Evaluating on the test split.
I0922 15:52:56.206309 139860156245824 submission_runner.py:376] Time since start: 48941.55s, 	Step: 139429, 	{'train/accuracy': 0.9047552347183228, 'train/loss': 0.5942578911781311, 'validation/accuracy': 0.7739399671554565, 'validation/loss': 1.1209300756454468, 'validation/num_examples': 50000, 'test/accuracy': 0.657200038433075, 'test/loss': 1.6977221965789795, 'test/num_examples': 10000, 'score': 46995.818197488785, 'total_duration': 48941.54935002327, 'accumulated_submission_time': 46995.818197488785, 'accumulated_eval_time': 1940.455887556076, 'accumulated_logging_time': 3.247645139694214}
I0922 15:52:56.235791 139694994065152 logging_writer.py:48] [139429] accumulated_eval_time=1940.455888, accumulated_logging_time=3.247645, accumulated_submission_time=46995.818197, global_step=139429, preemption_count=0, score=46995.818197, test/accuracy=0.657200, test/loss=1.697722, test/num_examples=10000, total_duration=48941.549350, train/accuracy=0.904755, train/loss=0.594258, validation/accuracy=0.773940, validation/loss=1.120930, validation/num_examples=50000
I0922 15:53:20.453840 139695019243264 logging_writer.py:48] [139500] global_step=139500, grad_norm=0.5061149001121521, loss=2.594393253326416
I0922 15:56:08.247658 139860156245824 spec.py:320] Evaluating on the training split.
I0922 15:56:15.763937 139860156245824 spec.py:332] Evaluating on the validation split.
I0922 15:56:26.627184 139860156245824 spec.py:348] Evaluating on the test split.
I0922 15:56:28.944361 139860156245824 submission_runner.py:376] Time since start: 49154.29s, 	Step: 140000, 	{'train/accuracy': 0.9080436825752258, 'train/loss': 0.5800074934959412, 'validation/accuracy': 0.7743600010871887, 'validation/loss': 1.117522954940796, 'validation/num_examples': 50000, 'test/accuracy': 0.6568000316619873, 'test/loss': 1.6970562934875488, 'test/num_examples': 10000, 'score': 47187.81134438515, 'total_duration': 49154.28737163544, 'accumulated_submission_time': 47187.81134438515, 'accumulated_eval_time': 1961.1525249481201, 'accumulated_logging_time': 3.287461757659912}
I0922 15:56:28.972028 139695010850560 logging_writer.py:48] [140000] accumulated_eval_time=1961.152525, accumulated_logging_time=3.287462, accumulated_submission_time=47187.811344, global_step=140000, preemption_count=0, score=47187.811344, test/accuracy=0.656800, test/loss=1.697056, test/num_examples=10000, total_duration=49154.287372, train/accuracy=0.908044, train/loss=0.580007, validation/accuracy=0.774360, validation/loss=1.117523, validation/num_examples=50000
I0922 15:56:28.996930 139695019243264 logging_writer.py:48] [140000] global_step=140000, preemption_count=0, score=47187.811344
I0922 15:56:29.272994 139860156245824 checkpoints.py:490] Saving checkpoint at step: 140000
I0922 15:56:30.147701 139860156245824 checkpoints.py:422] Saved checkpoint at /experiment_runs/targets_check_jax_run_03/momentum_run_0/imagenet_resnet_jax/trial_1/checkpoint_140000
I0922 15:56:30.167726 139860156245824 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/targets_check_jax_run_03/momentum_run_0/imagenet_resnet_jax/trial_1/checkpoint_140000.
I0922 15:56:31.023868 139860156245824 submission_runner.py:540] Tuning trial 1/1
I0922 15:56:31.024158 139860156245824 submission_runner.py:541] Hyperparameters: Hyperparameters(learning_rate=4.131896390902391, beta1=0.9274758113254791, beta2=0.9978504782314613, warmup_steps=6999, decay_steps_factor=0.9007765761611038, end_factor=0.001, weight_decay=5.6687777311501786e-06, label_smoothing=0.2)
I0922 15:56:31.026478 139860156245824 submission_runner.py:542] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0010762116871774197, 'train/loss': 6.912233829498291, 'validation/accuracy': 0.0009599999757483602, 'validation/loss': 6.911919593811035, 'validation/num_examples': 50000, 'test/accuracy': 0.0012000000569969416, 'test/loss': 6.911700248718262, 'test/num_examples': 10000, 'score': 63.82860493659973, 'total_duration': 111.1261203289032, 'accumulated_submission_time': 63.82860493659973, 'accumulated_eval_time': 47.297425746917725, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (1513, {'train/accuracy': 0.1953125, 'train/loss': 4.250689506530762, 'validation/accuracy': 0.17737999558448792, 'validation/loss': 4.378722190856934, 'validation/num_examples': 50000, 'test/accuracy': 0.1331000030040741, 'test/loss': 4.767331600189209, 'test/num_examples': 10000, 'score': 574.1017343997955, 'total_duration': 639.2384521961212, 'accumulated_submission_time': 574.1017343997955, 'accumulated_eval_time': 65.08575344085693, 'accumulated_logging_time': 0.028851747512817383, 'global_step': 1513, 'preemption_count': 0}), (3027, {'train/accuracy': 0.3854830861091614, 'train/loss': 3.0441174507141113, 'validation/accuracy': 0.36032000184059143, 'validation/loss': 3.1795692443847656, 'validation/num_examples': 50000, 'test/accuracy': 0.2768000066280365, 'test/loss': 3.753525972366333, 'test/num_examples': 10000, 'score': 1084.0880839824677, 'total_duration': 1167.3357067108154, 'accumulated_submission_time': 1084.0880839824677, 'accumulated_eval_time': 83.1453173160553, 'accumulated_logging_time': 0.05786466598510742, 'global_step': 3027, 'preemption_count': 0}), (4542, {'train/accuracy': 0.44557157158851624, 'train/loss': 2.750640392303467, 'validation/accuracy': 0.41711997985839844, 'validation/loss': 2.892887830734253, 'validation/num_examples': 50000, 'test/accuracy': 0.313400000333786, 'test/loss': 3.5260419845581055, 'test/num_examples': 10000, 'score': 1594.0628130435944, 'total_duration': 1695.194725036621, 'accumulated_submission_time': 1594.0628130435944, 'accumulated_eval_time': 100.979816198349, 'accumulated_logging_time': 0.08539056777954102, 'global_step': 4542, 'preemption_count': 0}), (6058, {'train/accuracy': 0.4934430718421936, 'train/loss': 2.4900131225585938, 'validation/accuracy': 0.46459999680519104, 'validation/loss': 2.642608880996704, 'validation/num_examples': 50000, 'test/accuracy': 0.35120001435279846, 'test/loss': 3.2795279026031494, 'test/num_examples': 10000, 'score': 2104.3116278648376, 'total_duration': 2223.5858500003815, 'accumulated_submission_time': 2104.3116278648376, 'accumulated_eval_time': 119.07040405273438, 'accumulated_logging_time': 0.11498904228210449, 'global_step': 6058, 'preemption_count': 0}), (7574, {'train/accuracy': 0.4878627061843872, 'train/loss': 2.394216775894165, 'validation/accuracy': 0.46469998359680176, 'validation/loss': 2.541215181350708, 'validation/num_examples': 50000, 'test/accuracy': 0.35850000381469727, 'test/loss': 3.163653612136841, 'test/num_examples': 10000, 'score': 2614.577480316162, 'total_duration': 2751.686309337616, 'accumulated_submission_time': 2614.577480316162, 'accumulated_eval_time': 136.8561680316925, 'accumulated_logging_time': 0.14209389686584473, 'global_step': 7574, 'preemption_count': 0}), (9089, {'train/accuracy': 0.5937898755073547, 'train/loss': 1.994570016860962, 'validation/accuracy': 0.5184400081634521, 'validation/loss': 2.3491361141204834, 'validation/num_examples': 50000, 'test/accuracy': 0.40130001306533813, 'test/loss': 2.987217426300049, 'test/num_examples': 10000, 'score': 3124.5621304512024, 'total_duration': 3279.838321208954, 'accumulated_submission_time': 3124.5621304512024, 'accumulated_eval_time': 154.9729254245758, 'accumulated_logging_time': 0.17090845108032227, 'global_step': 9089, 'preemption_count': 0}), (10605, {'train/accuracy': 0.5725645422935486, 'train/loss': 2.060797691345215, 'validation/accuracy': 0.5168799757957458, 'validation/loss': 2.3233985900878906, 'validation/num_examples': 50000, 'test/accuracy': 0.3961000144481659, 'test/loss': 2.9845314025878906, 'test/num_examples': 10000, 'score': 3634.8241727352142, 'total_duration': 3808.483343601227, 'accumulated_submission_time': 3634.8241727352142, 'accumulated_eval_time': 173.30623936653137, 'accumulated_logging_time': 0.1988847255706787, 'global_step': 10605, 'preemption_count': 0}), (12120, {'train/accuracy': 0.5725446343421936, 'train/loss': 2.088163137435913, 'validation/accuracy': 0.5295799970626831, 'validation/loss': 2.301417589187622, 'validation/num_examples': 50000, 'test/accuracy': 0.4052000045776367, 'test/loss': 2.976471424102783, 'test/num_examples': 10000, 'score': 4144.845808506012, 'total_duration': 4336.782471656799, 'accumulated_submission_time': 4144.845808506012, 'accumulated_eval_time': 191.53280925750732, 'accumulated_logging_time': 0.22790145874023438, 'global_step': 12120, 'preemption_count': 0}), (13636, {'train/accuracy': 0.561922013759613, 'train/loss': 2.0995981693267822, 'validation/accuracy': 0.5209800004959106, 'validation/loss': 2.287593126296997, 'validation/num_examples': 50000, 'test/accuracy': 0.4050000309944153, 'test/loss': 2.9458823204040527, 'test/num_examples': 10000, 'score': 4654.8745040893555, 'total_duration': 4864.968941926956, 'accumulated_submission_time': 4654.8745040893555, 'accumulated_eval_time': 209.63903427124023, 'accumulated_logging_time': 0.2571892738342285, 'global_step': 13636, 'preemption_count': 0}), (15151, {'train/accuracy': 0.5607661008834839, 'train/loss': 2.173295259475708, 'validation/accuracy': 0.5255399942398071, 'validation/loss': 2.345304250717163, 'validation/num_examples': 50000, 'test/accuracy': 0.40950003266334534, 'test/loss': 3.0255024433135986, 'test/num_examples': 10000, 'score': 5165.076518774033, 'total_duration': 5393.182889699936, 'accumulated_submission_time': 5165.076518774033, 'accumulated_eval_time': 227.59325218200684, 'accumulated_logging_time': 0.2931509017944336, 'global_step': 15151, 'preemption_count': 0}), (16667, {'train/accuracy': 0.5772281289100647, 'train/loss': 2.0155012607574463, 'validation/accuracy': 0.542739987373352, 'validation/loss': 2.1865999698638916, 'validation/num_examples': 50000, 'test/accuracy': 0.42110002040863037, 'test/loss': 2.873884439468384, 'test/num_examples': 10000, 'score': 5675.350479841232, 'total_duration': 5921.541299819946, 'accumulated_submission_time': 5675.350479841232, 'accumulated_eval_time': 245.62349653244019, 'accumulated_logging_time': 0.32523465156555176, 'global_step': 16667, 'preemption_count': 0}), (18183, {'train/accuracy': 0.6164700388908386, 'train/loss': 1.8166255950927734, 'validation/accuracy': 0.5374599695205688, 'validation/loss': 2.1936559677124023, 'validation/num_examples': 50000, 'test/accuracy': 0.42830002307891846, 'test/loss': 2.824901819229126, 'test/num_examples': 10000, 'score': 6185.598520517349, 'total_duration': 6449.854868412018, 'accumulated_submission_time': 6185.598520517349, 'accumulated_eval_time': 263.62550163269043, 'accumulated_logging_time': 0.36657214164733887, 'global_step': 18183, 'preemption_count': 0}), (19699, {'train/accuracy': 0.6040537357330322, 'train/loss': 1.8572139739990234, 'validation/accuracy': 0.54721999168396, 'validation/loss': 2.1430695056915283, 'validation/num_examples': 50000, 'test/accuracy': 0.42500001192092896, 'test/loss': 2.8068933486938477, 'test/num_examples': 10000, 'score': 6695.745776891708, 'total_duration': 6978.039947986603, 'accumulated_submission_time': 6695.745776891708, 'accumulated_eval_time': 281.6094694137573, 'accumulated_logging_time': 0.3982985019683838, 'global_step': 19699, 'preemption_count': 0}), (21215, {'train/accuracy': 0.6070830821990967, 'train/loss': 1.8662636280059814, 'validation/accuracy': 0.5557399988174438, 'validation/loss': 2.107875347137451, 'validation/num_examples': 50000, 'test/accuracy': 0.43380001187324524, 'test/loss': 2.7795403003692627, 'test/num_examples': 10000, 'score': 7205.85010433197, 'total_duration': 7506.538147687912, 'accumulated_submission_time': 7205.85010433197, 'accumulated_eval_time': 299.95147609710693, 'accumulated_logging_time': 0.42829036712646484, 'global_step': 21215, 'preemption_count': 0}), (22731, {'train/accuracy': 0.6033760905265808, 'train/loss': 1.921431064605713, 'validation/accuracy': 0.5582799911499023, 'validation/loss': 2.1212737560272217, 'validation/num_examples': 50000, 'test/accuracy': 0.4434000253677368, 'test/loss': 2.7690272331237793, 'test/num_examples': 10000, 'score': 7716.098157405853, 'total_duration': 8039.20441031456, 'accumulated_submission_time': 7716.098157405853, 'accumulated_eval_time': 322.3136878013611, 'accumulated_logging_time': 0.46224427223205566, 'global_step': 22731, 'preemption_count': 0}), (24247, {'train/accuracy': 0.6059072017669678, 'train/loss': 1.8381973505020142, 'validation/accuracy': 0.5631799697875977, 'validation/loss': 2.0456507205963135, 'validation/num_examples': 50000, 'test/accuracy': 0.43810001015663147, 'test/loss': 2.73285174369812, 'test/num_examples': 10000, 'score': 8226.381306648254, 'total_duration': 8569.001594305038, 'accumulated_submission_time': 8226.381306648254, 'accumulated_eval_time': 341.7752058506012, 'accumulated_logging_time': 0.4927811622619629, 'global_step': 24247, 'preemption_count': 0}), (25763, {'train/accuracy': 0.5989516973495483, 'train/loss': 1.9136871099472046, 'validation/accuracy': 0.5589799880981445, 'validation/loss': 2.093651294708252, 'validation/num_examples': 50000, 'test/accuracy': 0.43700000643730164, 'test/loss': 2.7729973793029785, 'test/num_examples': 10000, 'score': 8736.60784649849, 'total_duration': 9099.445104598999, 'accumulated_submission_time': 8736.60784649849, 'accumulated_eval_time': 361.92847990989685, 'accumulated_logging_time': 0.5344793796539307, 'global_step': 25763, 'preemption_count': 0}), (27279, {'train/accuracy': 0.6574457883834839, 'train/loss': 1.647836446762085, 'validation/accuracy': 0.5787799954414368, 'validation/loss': 2.012053966522217, 'validation/num_examples': 50000, 'test/accuracy': 0.458700031042099, 'test/loss': 2.6441469192504883, 'test/num_examples': 10000, 'score': 9246.617577314377, 'total_duration': 9630.520079612732, 'accumulated_submission_time': 9246.617577314377, 'accumulated_eval_time': 382.93916296958923, 'accumulated_logging_time': 0.567162036895752, 'global_step': 27279, 'preemption_count': 0}), (28795, {'train/accuracy': 0.6138193607330322, 'train/loss': 1.835744857788086, 'validation/accuracy': 0.5630199909210205, 'validation/loss': 2.0825109481811523, 'validation/num_examples': 50000, 'test/accuracy': 0.44460001587867737, 'test/loss': 2.743582248687744, 'test/num_examples': 10000, 'score': 9756.666748046875, 'total_duration': 10161.025271654129, 'accumulated_submission_time': 9756.666748046875, 'accumulated_eval_time': 403.340101480484, 'accumulated_logging_time': 0.6002480983734131, 'global_step': 28795, 'preemption_count': 0}), (30311, {'train/accuracy': 0.6407445669174194, 'train/loss': 1.7555533647537231, 'validation/accuracy': 0.5862199664115906, 'validation/loss': 1.996310830116272, 'validation/num_examples': 50000, 'test/accuracy': 0.4561000168323517, 'test/loss': 2.664827823638916, 'test/num_examples': 10000, 'score': 10266.739155769348, 'total_duration': 10692.453307390213, 'accumulated_submission_time': 10266.739155769348, 'accumulated_eval_time': 424.641179561615, 'accumulated_logging_time': 0.6327004432678223, 'global_step': 30311, 'preemption_count': 0}), (31827, {'train/accuracy': 0.6068040132522583, 'train/loss': 1.8650717735290527, 'validation/accuracy': 0.5614399909973145, 'validation/loss': 2.0938620567321777, 'validation/num_examples': 50000, 'test/accuracy': 0.4488000273704529, 'test/loss': 2.717355489730835, 'test/num_examples': 10000, 'score': 10776.79148197174, 'total_duration': 11223.744272947311, 'accumulated_submission_time': 10776.79148197174, 'accumulated_eval_time': 445.8237051963806, 'accumulated_logging_time': 0.666865348815918, 'global_step': 31827, 'preemption_count': 0}), (33342, {'train/accuracy': 0.6131018400192261, 'train/loss': 1.890493392944336, 'validation/accuracy': 0.571399986743927, 'validation/loss': 2.0862486362457275, 'validation/num_examples': 50000, 'test/accuracy': 0.4457000195980072, 'test/loss': 2.766350030899048, 'test/num_examples': 10000, 'score': 11286.773390769958, 'total_duration': 11755.268727779388, 'accumulated_submission_time': 11286.773390769958, 'accumulated_eval_time': 467.31220626831055, 'accumulated_logging_time': 0.6990752220153809, 'global_step': 33342, 'preemption_count': 0}), (34859, {'train/accuracy': 0.6300023794174194, 'train/loss': 1.8194433450698853, 'validation/accuracy': 0.5906800031661987, 'validation/loss': 2.012418031692505, 'validation/num_examples': 50000, 'test/accuracy': 0.46310001611709595, 'test/loss': 2.6821506023406982, 'test/num_examples': 10000, 'score': 11796.92868757248, 'total_duration': 12287.413486480713, 'accumulated_submission_time': 11796.92868757248, 'accumulated_eval_time': 489.24654841423035, 'accumulated_logging_time': 0.732133150100708, 'global_step': 34859, 'preemption_count': 0}), (36375, {'train/accuracy': 0.642578125, 'train/loss': 1.7200690507888794, 'validation/accuracy': 0.5697199702262878, 'validation/loss': 2.0555689334869385, 'validation/num_examples': 50000, 'test/accuracy': 0.44760000705718994, 'test/loss': 2.7521586418151855, 'test/num_examples': 10000, 'score': 12307.070878267288, 'total_duration': 12819.494129180908, 'accumulated_submission_time': 12307.070878267288, 'accumulated_eval_time': 511.1301953792572, 'accumulated_logging_time': 0.7648098468780518, 'global_step': 36375, 'preemption_count': 0}), (37891, {'train/accuracy': 0.6353635191917419, 'train/loss': 1.7260973453521729, 'validation/accuracy': 0.5757399797439575, 'validation/loss': 2.009341239929199, 'validation/num_examples': 50000, 'test/accuracy': 0.4529000222682953, 'test/loss': 2.693175792694092, 'test/num_examples': 10000, 'score': 12817.198693037033, 'total_duration': 13350.530089378357, 'accumulated_submission_time': 12817.198693037033, 'accumulated_eval_time': 531.9797699451447, 'accumulated_logging_time': 0.801306962966919, 'global_step': 37891, 'preemption_count': 0}), (39407, {'train/accuracy': 0.6371970772743225, 'train/loss': 1.74796462059021, 'validation/accuracy': 0.5947200059890747, 'validation/loss': 1.970801830291748, 'validation/num_examples': 50000, 'test/accuracy': 0.46790000796318054, 'test/loss': 2.6150336265563965, 'test/num_examples': 10000, 'score': 13327.200963020325, 'total_duration': 13881.474056243896, 'accumulated_submission_time': 13327.200963020325, 'accumulated_eval_time': 552.8681490421295, 'accumulated_logging_time': 0.8328936100006104, 'global_step': 39407, 'preemption_count': 0}), (40923, {'train/accuracy': 0.6496930718421936, 'train/loss': 1.7041078805923462, 'validation/accuracy': 0.6017199754714966, 'validation/loss': 1.9247353076934814, 'validation/num_examples': 50000, 'test/accuracy': 0.4832000136375427, 'test/loss': 2.584318161010742, 'test/num_examples': 10000, 'score': 13837.261239528656, 'total_duration': 14412.419258594513, 'accumulated_submission_time': 13837.261239528656, 'accumulated_eval_time': 573.6953444480896, 'accumulated_logging_time': 0.8687067031860352, 'global_step': 40923, 'preemption_count': 0}), (42439, {'train/accuracy': 0.6416812539100647, 'train/loss': 1.7094223499298096, 'validation/accuracy': 0.5963599681854248, 'validation/loss': 1.9188870191574097, 'validation/num_examples': 50000, 'test/accuracy': 0.47140002250671387, 'test/loss': 2.558954954147339, 'test/num_examples': 10000, 'score': 14347.27698802948, 'total_duration': 14943.416975975037, 'accumulated_submission_time': 14347.27698802948, 'accumulated_eval_time': 594.6188504695892, 'accumulated_logging_time': 0.9051849842071533, 'global_step': 42439, 'preemption_count': 0}), (43956, {'train/accuracy': 0.650789201259613, 'train/loss': 1.6602976322174072, 'validation/accuracy': 0.6007599830627441, 'validation/loss': 1.9025561809539795, 'validation/num_examples': 50000, 'test/accuracy': 0.4764000177383423, 'test/loss': 2.577639102935791, 'test/num_examples': 10000, 'score': 14857.481169223785, 'total_duration': 15474.705823421478, 'accumulated_submission_time': 14857.481169223785, 'accumulated_eval_time': 615.6490051746368, 'accumulated_logging_time': 0.9379069805145264, 'global_step': 43956, 'preemption_count': 0}), (45472, {'train/accuracy': 0.6668327450752258, 'train/loss': 1.613439917564392, 'validation/accuracy': 0.6021599769592285, 'validation/loss': 1.9118386507034302, 'validation/num_examples': 50000, 'test/accuracy': 0.4829000234603882, 'test/loss': 2.553234100341797, 'test/num_examples': 10000, 'score': 15367.582799911499, 'total_duration': 16006.090864181519, 'accumulated_submission_time': 15367.582799911499, 'accumulated_eval_time': 636.876837015152, 'accumulated_logging_time': 0.9713876247406006, 'global_step': 45472, 'preemption_count': 0}), (46988, {'train/accuracy': 0.6500916481018066, 'train/loss': 1.6953728199005127, 'validation/accuracy': 0.5959799885749817, 'validation/loss': 1.9494109153747559, 'validation/num_examples': 50000, 'test/accuracy': 0.48110002279281616, 'test/loss': 2.5915913581848145, 'test/num_examples': 10000, 'score': 15877.68100309372, 'total_duration': 16537.389682769775, 'accumulated_submission_time': 15877.68100309372, 'accumulated_eval_time': 658.0219976902008, 'accumulated_logging_time': 1.0049190521240234, 'global_step': 46988, 'preemption_count': 0}), (48505, {'train/accuracy': 0.6456273794174194, 'train/loss': 1.7268511056900024, 'validation/accuracy': 0.5936399698257446, 'validation/loss': 1.9696390628814697, 'validation/num_examples': 50000, 'test/accuracy': 0.4723000228404999, 'test/loss': 2.627419948577881, 'test/num_examples': 10000, 'score': 16387.911521673203, 'total_duration': 17068.8169362545, 'accumulated_submission_time': 16387.911521673203, 'accumulated_eval_time': 679.1615083217621, 'accumulated_logging_time': 1.0399305820465088, 'global_step': 48505, 'preemption_count': 0}), (50022, {'train/accuracy': 0.6594387888908386, 'train/loss': 1.6280325651168823, 'validation/accuracy': 0.6092999577522278, 'validation/loss': 1.862957239151001, 'validation/num_examples': 50000, 'test/accuracy': 0.4816000163555145, 'test/loss': 2.53275203704834, 'test/num_examples': 10000, 'score': 16898.143622159958, 'total_duration': 17600.112322092056, 'accumulated_submission_time': 16898.143622159958, 'accumulated_eval_time': 700.1698007583618, 'accumulated_logging_time': 1.0731310844421387, 'global_step': 50022, 'preemption_count': 0}), (51538, {'train/accuracy': 0.6144570708274841, 'train/loss': 1.873496651649475, 'validation/accuracy': 0.5712199807167053, 'validation/loss': 2.0673816204071045, 'validation/num_examples': 50000, 'test/accuracy': 0.4492000341415405, 'test/loss': 2.7472054958343506, 'test/num_examples': 10000, 'score': 17408.110887765884, 'total_duration': 18131.202320098877, 'accumulated_submission_time': 17408.110887765884, 'accumulated_eval_time': 721.2397112846375, 'accumulated_logging_time': 1.1039350032806396, 'global_step': 51538, 'preemption_count': 0}), (53054, {'train/accuracy': 0.7102598547935486, 'train/loss': 1.4080713987350464, 'validation/accuracy': 0.6158199906349182, 'validation/loss': 1.8065959215164185, 'validation/num_examples': 50000, 'test/accuracy': 0.49560001492500305, 'test/loss': 2.449063777923584, 'test/num_examples': 10000, 'score': 17918.118888378143, 'total_duration': 18662.226732492447, 'accumulated_submission_time': 17918.118888378143, 'accumulated_eval_time': 742.203426361084, 'accumulated_logging_time': 1.1347317695617676, 'global_step': 53054, 'preemption_count': 0}), (54570, {'train/accuracy': 0.6874402165412903, 'train/loss': 1.5018043518066406, 'validation/accuracy': 0.6191399693489075, 'validation/loss': 1.8059743642807007, 'validation/num_examples': 50000, 'test/accuracy': 0.4978000223636627, 'test/loss': 2.4517621994018555, 'test/num_examples': 10000, 'score': 18428.1802213192, 'total_duration': 19193.382207393646, 'accumulated_submission_time': 18428.1802213192, 'accumulated_eval_time': 763.2452006340027, 'accumulated_logging_time': 1.1650416851043701, 'global_step': 54570, 'preemption_count': 0}), (56087, {'train/accuracy': 0.6672911047935486, 'train/loss': 1.6243317127227783, 'validation/accuracy': 0.6116799712181091, 'validation/loss': 1.8813596963882446, 'validation/num_examples': 50000, 'test/accuracy': 0.4905000329017639, 'test/loss': 2.5239357948303223, 'test/num_examples': 10000, 'score': 18938.45142197609, 'total_duration': 19724.686930656433, 'accumulated_submission_time': 18938.45142197609, 'accumulated_eval_time': 784.2257878780365, 'accumulated_logging_time': 1.1962223052978516, 'global_step': 56087, 'preemption_count': 0}), (57603, {'train/accuracy': 0.6643016338348389, 'train/loss': 1.6511489152908325, 'validation/accuracy': 0.6108599901199341, 'validation/loss': 1.9003981351852417, 'validation/num_examples': 50000, 'test/accuracy': 0.47470003366470337, 'test/loss': 2.563464641571045, 'test/num_examples': 10000, 'score': 19448.453800678253, 'total_duration': 20255.829459428787, 'accumulated_submission_time': 19448.453800678253, 'accumulated_eval_time': 805.3057129383087, 'accumulated_logging_time': 1.2348315715789795, 'global_step': 57603, 'preemption_count': 0}), (59120, {'train/accuracy': 0.6592593789100647, 'train/loss': 1.6350799798965454, 'validation/accuracy': 0.6084799766540527, 'validation/loss': 1.8722097873687744, 'validation/num_examples': 50000, 'test/accuracy': 0.48260003328323364, 'test/loss': 2.5308773517608643, 'test/num_examples': 10000, 'score': 19958.65367460251, 'total_duration': 20787.243068933487, 'accumulated_submission_time': 19958.65367460251, 'accumulated_eval_time': 826.4649696350098, 'accumulated_logging_time': 1.2671937942504883, 'global_step': 59120, 'preemption_count': 0}), (60636, {'train/accuracy': 0.6764788031578064, 'train/loss': 1.5421534776687622, 'validation/accuracy': 0.6281999945640564, 'validation/loss': 1.7692667245864868, 'validation/num_examples': 50000, 'test/accuracy': 0.5008000135421753, 'test/loss': 2.421143054962158, 'test/num_examples': 10000, 'score': 20468.65588068962, 'total_duration': 21318.2906563282, 'accumulated_submission_time': 20468.65588068962, 'accumulated_eval_time': 847.4551708698273, 'accumulated_logging_time': 1.300093650817871, 'global_step': 60636, 'preemption_count': 0}), (62153, {'train/accuracy': 0.7169563174247742, 'train/loss': 1.3769701719284058, 'validation/accuracy': 0.6265999674797058, 'validation/loss': 1.764554500579834, 'validation/num_examples': 50000, 'test/accuracy': 0.492900013923645, 'test/loss': 2.4501240253448486, 'test/num_examples': 10000, 'score': 20978.883363485336, 'total_duration': 21849.612474679947, 'accumulated_submission_time': 20978.883363485336, 'accumulated_eval_time': 868.4918429851532, 'accumulated_logging_time': 1.3359174728393555, 'global_step': 62153, 'preemption_count': 0}), (63670, {'train/accuracy': 0.6825574040412903, 'train/loss': 1.5605289936065674, 'validation/accuracy': 0.6123600006103516, 'validation/loss': 1.8629093170166016, 'validation/num_examples': 50000, 'test/accuracy': 0.4869000315666199, 'test/loss': 2.5212059020996094, 'test/num_examples': 10000, 'score': 21489.101444244385, 'total_duration': 22380.913610696793, 'accumulated_submission_time': 21489.101444244385, 'accumulated_eval_time': 889.519335269928, 'accumulated_logging_time': 1.3693304061889648, 'global_step': 63670, 'preemption_count': 0}), (65187, {'train/accuracy': 0.6810227632522583, 'train/loss': 1.5294525623321533, 'validation/accuracy': 0.619219958782196, 'validation/loss': 1.80784010887146, 'validation/num_examples': 50000, 'test/accuracy': 0.4823000133037567, 'test/loss': 2.4801368713378906, 'test/num_examples': 10000, 'score': 21999.18106484413, 'total_duration': 22912.043599128723, 'accumulated_submission_time': 21999.18106484413, 'accumulated_eval_time': 910.511146068573, 'accumulated_logging_time': 1.4059362411499023, 'global_step': 65187, 'preemption_count': 0}), (66704, {'train/accuracy': 0.68753981590271, 'train/loss': 1.4932862520217896, 'validation/accuracy': 0.6326199769973755, 'validation/loss': 1.7415614128112793, 'validation/num_examples': 50000, 'test/accuracy': 0.5020000338554382, 'test/loss': 2.4340665340423584, 'test/num_examples': 10000, 'score': 22509.363567352295, 'total_duration': 23443.237510442734, 'accumulated_submission_time': 22509.363567352295, 'accumulated_eval_time': 931.4684584140778, 'accumulated_logging_time': 1.4373843669891357, 'global_step': 66704, 'preemption_count': 0}), (68220, {'train/accuracy': 0.688496470451355, 'train/loss': 1.5721735954284668, 'validation/accuracy': 0.6291399598121643, 'validation/loss': 1.828994631767273, 'validation/num_examples': 50000, 'test/accuracy': 0.5041000247001648, 'test/loss': 2.4818732738494873, 'test/num_examples': 10000, 'score': 23019.36590528488, 'total_duration': 23974.563906669617, 'accumulated_submission_time': 23019.36590528488, 'accumulated_eval_time': 952.7197403907776, 'accumulated_logging_time': 1.4881384372711182, 'global_step': 68220, 'preemption_count': 0}), (69736, {'train/accuracy': 0.6886360049247742, 'train/loss': 1.5390214920043945, 'validation/accuracy': 0.630620002746582, 'validation/loss': 1.7868869304656982, 'validation/num_examples': 50000, 'test/accuracy': 0.5041000247001648, 'test/loss': 2.4390032291412354, 'test/num_examples': 10000, 'score': 23529.431270599365, 'total_duration': 24505.82695055008, 'accumulated_submission_time': 23529.431270599365, 'accumulated_eval_time': 973.8607857227325, 'accumulated_logging_time': 1.5223145484924316, 'global_step': 69736, 'preemption_count': 0}), (71253, {'train/accuracy': 0.7182317972183228, 'train/loss': 1.427201271057129, 'validation/accuracy': 0.6324399709701538, 'validation/loss': 1.809969186782837, 'validation/num_examples': 50000, 'test/accuracy': 0.5151000022888184, 'test/loss': 2.4297642707824707, 'test/num_examples': 10000, 'score': 24039.632776498795, 'total_duration': 25037.13354253769, 'accumulated_submission_time': 24039.632776498795, 'accumulated_eval_time': 994.9084758758545, 'accumulated_logging_time': 1.5572876930236816, 'global_step': 71253, 'preemption_count': 0}), (72770, {'train/accuracy': 0.7115553021430969, 'train/loss': 1.3792685270309448, 'validation/accuracy': 0.6410199999809265, 'validation/loss': 1.695258378982544, 'validation/num_examples': 50000, 'test/accuracy': 0.513200044631958, 'test/loss': 2.351789951324463, 'test/num_examples': 10000, 'score': 24549.726781845093, 'total_duration': 25568.389043092728, 'accumulated_submission_time': 24549.726781845093, 'accumulated_eval_time': 1016.0085372924805, 'accumulated_logging_time': 1.5963807106018066, 'global_step': 72770, 'preemption_count': 0}), (74286, {'train/accuracy': 0.7029256820678711, 'train/loss': 1.4456677436828613, 'validation/accuracy': 0.640500009059906, 'validation/loss': 1.7377138137817383, 'validation/num_examples': 50000, 'test/accuracy': 0.5188000202178955, 'test/loss': 2.3861923217773438, 'test/num_examples': 10000, 'score': 25059.723529815674, 'total_duration': 26099.608132362366, 'accumulated_submission_time': 25059.723529815674, 'accumulated_eval_time': 1037.1746661663055, 'accumulated_logging_time': 1.6305997371673584, 'global_step': 74286, 'preemption_count': 0}), (75802, {'train/accuracy': 0.7102000713348389, 'train/loss': 1.412864089012146, 'validation/accuracy': 0.6520999670028687, 'validation/loss': 1.6886405944824219, 'validation/num_examples': 50000, 'test/accuracy': 0.5288000106811523, 'test/loss': 2.310685873031616, 'test/num_examples': 10000, 'score': 25569.817949295044, 'total_duration': 26631.19234609604, 'accumulated_submission_time': 25569.817949295044, 'accumulated_eval_time': 1058.6058802604675, 'accumulated_logging_time': 1.6673941612243652, 'global_step': 75802, 'preemption_count': 0}), (77319, {'train/accuracy': 0.7073301672935486, 'train/loss': 1.4102189540863037, 'validation/accuracy': 0.6480000019073486, 'validation/loss': 1.6826646327972412, 'validation/num_examples': 50000, 'test/accuracy': 0.5267000198364258, 'test/loss': 2.3053231239318848, 'test/num_examples': 10000, 'score': 26080.056000471115, 'total_duration': 27162.649018526077, 'accumulated_submission_time': 26080.056000471115, 'accumulated_eval_time': 1079.767193555832, 'accumulated_logging_time': 1.702972173690796, 'global_step': 77319, 'preemption_count': 0}), (78835, {'train/accuracy': 0.7140266299247742, 'train/loss': 1.3672490119934082, 'validation/accuracy': 0.6593799591064453, 'validation/loss': 1.6180670261383057, 'validation/num_examples': 50000, 'test/accuracy': 0.526199996471405, 'test/loss': 2.2728631496429443, 'test/num_examples': 10000, 'score': 26590.094386577606, 'total_duration': 27693.804987430573, 'accumulated_submission_time': 26590.094386577606, 'accumulated_eval_time': 1100.8226518630981, 'accumulated_logging_time': 1.7432873249053955, 'global_step': 78835, 'preemption_count': 0}), (80352, {'train/accuracy': 0.7406130433082581, 'train/loss': 1.279111385345459, 'validation/accuracy': 0.6530999541282654, 'validation/loss': 1.657724142074585, 'validation/num_examples': 50000, 'test/accuracy': 0.5210000276565552, 'test/loss': 2.3075954914093018, 'test/num_examples': 10000, 'score': 27100.350009202957, 'total_duration': 28225.071019411087, 'accumulated_submission_time': 27100.350009202957, 'accumulated_eval_time': 1121.775886774063, 'accumulated_logging_time': 1.7788922786712646, 'global_step': 80352, 'preemption_count': 0}), (81869, {'train/accuracy': 0.7288145422935486, 'train/loss': 1.2826402187347412, 'validation/accuracy': 0.6582199931144714, 'validation/loss': 1.6013671159744263, 'validation/num_examples': 50000, 'test/accuracy': 0.5338000059127808, 'test/loss': 2.242861032485962, 'test/num_examples': 10000, 'score': 27610.579571962357, 'total_duration': 28756.363080263138, 'accumulated_submission_time': 27610.579571962357, 'accumulated_eval_time': 1142.778047800064, 'accumulated_logging_time': 1.8174490928649902, 'global_step': 81869, 'preemption_count': 0}), (83385, {'train/accuracy': 0.7245894074440002, 'train/loss': 1.3006478548049927, 'validation/accuracy': 0.6580199599266052, 'validation/loss': 1.6023612022399902, 'validation/num_examples': 50000, 'test/accuracy': 0.5317000150680542, 'test/loss': 2.2491512298583984, 'test/num_examples': 10000, 'score': 28120.682774066925, 'total_duration': 29287.559913635254, 'accumulated_submission_time': 28120.682774066925, 'accumulated_eval_time': 1163.8130753040314, 'accumulated_logging_time': 1.852884292602539, 'global_step': 83385, 'preemption_count': 0}), (84901, {'train/accuracy': 0.7145248651504517, 'train/loss': 1.413529634475708, 'validation/accuracy': 0.652999997138977, 'validation/loss': 1.6855382919311523, 'validation/num_examples': 50000, 'test/accuracy': 0.532200038433075, 'test/loss': 2.3317573070526123, 'test/num_examples': 10000, 'score': 28630.714267253876, 'total_duration': 29818.900638580322, 'accumulated_submission_time': 28630.714267253876, 'accumulated_eval_time': 1185.0631976127625, 'accumulated_logging_time': 1.8902060985565186, 'global_step': 84901, 'preemption_count': 0}), (86418, {'train/accuracy': 0.7151626348495483, 'train/loss': 1.3861089944839478, 'validation/accuracy': 0.6556000113487244, 'validation/loss': 1.6581337451934814, 'validation/num_examples': 50000, 'test/accuracy': 0.5254999995231628, 'test/loss': 2.2960801124572754, 'test/num_examples': 10000, 'score': 29140.8011367321, 'total_duration': 30350.00976872444, 'accumulated_submission_time': 29140.8011367321, 'accumulated_eval_time': 1206.0254278182983, 'accumulated_logging_time': 1.9280359745025635, 'global_step': 86418, 'preemption_count': 0}), (87934, {'train/accuracy': 0.7551618218421936, 'train/loss': 1.2336071729660034, 'validation/accuracy': 0.6692799925804138, 'validation/loss': 1.5880743265151978, 'validation/num_examples': 50000, 'test/accuracy': 0.541100025177002, 'test/loss': 2.2302114963531494, 'test/num_examples': 10000, 'score': 29650.8491563797, 'total_duration': 30881.201652526855, 'accumulated_submission_time': 29650.8491563797, 'accumulated_eval_time': 1227.1069343090057, 'accumulated_logging_time': 1.9682741165161133, 'global_step': 87934, 'preemption_count': 0}), (89451, {'train/accuracy': 0.7440210580825806, 'train/loss': 1.2593581676483154, 'validation/accuracy': 0.6637399792671204, 'validation/loss': 1.6099960803985596, 'validation/num_examples': 50000, 'test/accuracy': 0.5376999974250793, 'test/loss': 2.2556798458099365, 'test/num_examples': 10000, 'score': 30161.020138025284, 'total_duration': 31412.526627779007, 'accumulated_submission_time': 30161.020138025284, 'accumulated_eval_time': 1248.2042262554169, 'accumulated_logging_time': 2.0027639865875244, 'global_step': 89451, 'preemption_count': 0}), (90968, {'train/accuracy': 0.7412906289100647, 'train/loss': 1.3247534036636353, 'validation/accuracy': 0.6657800078392029, 'validation/loss': 1.6556074619293213, 'validation/num_examples': 50000, 'test/accuracy': 0.5378000140190125, 'test/loss': 2.2956035137176514, 'test/num_examples': 10000, 'score': 30671.257370471954, 'total_duration': 31943.883566617966, 'accumulated_submission_time': 30671.257370471954, 'accumulated_eval_time': 1269.2638757228851, 'accumulated_logging_time': 2.0408270359039307, 'global_step': 90968, 'preemption_count': 0}), (92414, {'train/accuracy': 0.75589919090271, 'train/loss': 1.1579933166503906, 'validation/accuracy': 0.6836999654769897, 'validation/loss': 1.4863077402114868, 'validation/num_examples': 50000, 'test/accuracy': 0.555400013923645, 'test/loss': 2.1091015338897705, 'test/num_examples': 10000, 'score': 31181.531277656555, 'total_duration': 32475.31089401245, 'accumulated_submission_time': 31181.531277656555, 'accumulated_eval_time': 1290.3574063777924, 'accumulated_logging_time': 2.0792813301086426, 'global_step': 92414, 'preemption_count': 0}), (93931, {'train/accuracy': 0.7458944320678711, 'train/loss': 1.2392172813415527, 'validation/accuracy': 0.6752399802207947, 'validation/loss': 1.5416216850280762, 'validation/num_examples': 50000, 'test/accuracy': 0.5484000444412231, 'test/loss': 2.184175729751587, 'test/num_examples': 10000, 'score': 31691.732520103455, 'total_duration': 33006.55387425423, 'accumulated_submission_time': 31691.732520103455, 'accumulated_eval_time': 1311.3414387702942, 'accumulated_logging_time': 2.1146469116210938, 'global_step': 93931, 'preemption_count': 0}), (95448, {'train/accuracy': 0.7518335580825806, 'train/loss': 1.2238816022872925, 'validation/accuracy': 0.6846199631690979, 'validation/loss': 1.514003038406372, 'validation/num_examples': 50000, 'test/accuracy': 0.5603000521659851, 'test/loss': 2.1432273387908936, 'test/num_examples': 10000, 'score': 32201.880815029144, 'total_duration': 33537.71345996857, 'accumulated_submission_time': 32201.880815029144, 'accumulated_eval_time': 1332.2940497398376, 'accumulated_logging_time': 2.1513895988464355, 'global_step': 95448, 'preemption_count': 0}), (96964, {'train/accuracy': 0.7579918503761292, 'train/loss': 1.195346713066101, 'validation/accuracy': 0.6843000054359436, 'validation/loss': 1.5134482383728027, 'validation/num_examples': 50000, 'test/accuracy': 0.5520000457763672, 'test/loss': 2.152961254119873, 'test/num_examples': 10000, 'score': 32712.109286546707, 'total_duration': 34069.0353000164, 'accumulated_submission_time': 32712.109286546707, 'accumulated_eval_time': 1353.319528579712, 'accumulated_logging_time': 2.1969006061553955, 'global_step': 96964, 'preemption_count': 0}), (98480, {'train/accuracy': 0.7780413031578064, 'train/loss': 1.0820232629776, 'validation/accuracy': 0.6803999543190002, 'validation/loss': 1.4932386875152588, 'validation/num_examples': 50000, 'test/accuracy': 0.5489000082015991, 'test/loss': 2.1461191177368164, 'test/num_examples': 10000, 'score': 33222.051538944244, 'total_duration': 34600.02610182762, 'accumulated_submission_time': 33222.051538944244, 'accumulated_eval_time': 1374.3079960346222, 'accumulated_logging_time': 2.234945058822632, 'global_step': 98480, 'preemption_count': 0}), (99997, {'train/accuracy': 0.7504384517669678, 'train/loss': 1.1970044374465942, 'validation/accuracy': 0.6700999736785889, 'validation/loss': 1.5616356134414673, 'validation/num_examples': 50000, 'test/accuracy': 0.5401000380516052, 'test/loss': 2.2250664234161377, 'test/num_examples': 10000, 'score': 33732.31796813011, 'total_duration': 35131.379509449005, 'accumulated_submission_time': 33732.31796813011, 'accumulated_eval_time': 1395.3357439041138, 'accumulated_logging_time': 2.272613286972046, 'global_step': 99997, 'preemption_count': 0}), (101514, {'train/accuracy': 0.7671595811843872, 'train/loss': 1.150720477104187, 'validation/accuracy': 0.6864799857139587, 'validation/loss': 1.505958080291748, 'validation/num_examples': 50000, 'test/accuracy': 0.5595000386238098, 'test/loss': 2.15362286567688, 'test/num_examples': 10000, 'score': 34242.47125029564, 'total_duration': 35662.541338682175, 'accumulated_submission_time': 34242.47125029564, 'accumulated_eval_time': 1416.2804539203644, 'accumulated_logging_time': 2.314411163330078, 'global_step': 101514, 'preemption_count': 0}), (103030, {'train/accuracy': 0.77054762840271, 'train/loss': 1.1376694440841675, 'validation/accuracy': 0.6933199763298035, 'validation/loss': 1.4701316356658936, 'validation/num_examples': 50000, 'test/accuracy': 0.567300021648407, 'test/loss': 2.0971527099609375, 'test/num_examples': 10000, 'score': 34752.649332761765, 'total_duration': 36193.727472782135, 'accumulated_submission_time': 34752.649332761765, 'accumulated_eval_time': 1437.2276270389557, 'accumulated_logging_time': 2.352879047393799, 'global_step': 103030, 'preemption_count': 0}), (104547, {'train/accuracy': 0.7765864133834839, 'train/loss': 1.103898048400879, 'validation/accuracy': 0.7011599540710449, 'validation/loss': 1.4242255687713623, 'validation/num_examples': 50000, 'test/accuracy': 0.5662000179290771, 'test/loss': 2.0970206260681152, 'test/num_examples': 10000, 'score': 35262.76320910454, 'total_duration': 36724.862387657166, 'accumulated_submission_time': 35262.76320910454, 'accumulated_eval_time': 1458.1924831867218, 'accumulated_logging_time': 2.3874409198760986, 'global_step': 104547, 'preemption_count': 0}), (106063, {'train/accuracy': 0.8157286047935486, 'train/loss': 0.9369745850563049, 'validation/accuracy': 0.6983199715614319, 'validation/loss': 1.4204775094985962, 'validation/num_examples': 50000, 'test/accuracy': 0.5768000483512878, 'test/loss': 2.0396924018859863, 'test/num_examples': 10000, 'score': 35772.9427614212, 'total_duration': 37256.17768883705, 'accumulated_submission_time': 35772.9427614212, 'accumulated_eval_time': 1479.2708055973053, 'accumulated_logging_time': 2.4226765632629395, 'global_step': 106063, 'preemption_count': 0}), (107580, {'train/accuracy': 0.8015385866165161, 'train/loss': 0.990227997303009, 'validation/accuracy': 0.699999988079071, 'validation/loss': 1.4165207147598267, 'validation/num_examples': 50000, 'test/accuracy': 0.5751000046730042, 'test/loss': 2.0457937717437744, 'test/num_examples': 10000, 'score': 36283.16487336159, 'total_duration': 37787.36519193649, 'accumulated_submission_time': 36283.16487336159, 'accumulated_eval_time': 1500.1757967472076, 'accumulated_logging_time': 2.4612035751342773, 'global_step': 107580, 'preemption_count': 0}), (109096, {'train/accuracy': 0.7924306392669678, 'train/loss': 1.057602047920227, 'validation/accuracy': 0.7021200060844421, 'validation/loss': 1.448128581047058, 'validation/num_examples': 50000, 'test/accuracy': 0.5692000389099121, 'test/loss': 2.0861339569091797, 'test/num_examples': 10000, 'score': 36793.15953063965, 'total_duration': 38318.38403010368, 'accumulated_submission_time': 36793.15953063965, 'accumulated_eval_time': 1521.1407353878021, 'accumulated_logging_time': 2.4985454082489014, 'global_step': 109096, 'preemption_count': 0}), (110613, {'train/accuracy': 0.8116430044174194, 'train/loss': 0.9804893732070923, 'validation/accuracy': 0.7160999774932861, 'validation/loss': 1.375800609588623, 'validation/num_examples': 50000, 'test/accuracy': 0.5887000560760498, 'test/loss': 1.993880033493042, 'test/num_examples': 10000, 'score': 37303.294801950455, 'total_duration': 38849.54740905762, 'accumulated_submission_time': 37303.294801950455, 'accumulated_eval_time': 1542.1117451190948, 'accumulated_logging_time': 2.5335915088653564, 'global_step': 110613, 'preemption_count': 0}), (112129, {'train/accuracy': 0.8158681392669678, 'train/loss': 0.9373319149017334, 'validation/accuracy': 0.72079998254776, 'validation/loss': 1.3203343152999878, 'validation/num_examples': 50000, 'test/accuracy': 0.5950000286102295, 'test/loss': 1.956536054611206, 'test/num_examples': 10000, 'score': 37813.322672367096, 'total_duration': 39380.58823919296, 'accumulated_submission_time': 37813.322672367096, 'accumulated_eval_time': 1563.0657584667206, 'accumulated_logging_time': 2.570284605026245, 'global_step': 112129, 'preemption_count': 0}), (113645, {'train/accuracy': 0.8153699040412903, 'train/loss': 0.9452801942825317, 'validation/accuracy': 0.7195000052452087, 'validation/loss': 1.3459440469741821, 'validation/num_examples': 50000, 'test/accuracy': 0.5991000533103943, 'test/loss': 1.9470158815383911, 'test/num_examples': 10000, 'score': 38323.35699033737, 'total_duration': 39911.563091278076, 'accumulated_submission_time': 38323.35699033737, 'accumulated_eval_time': 1583.9483547210693, 'accumulated_logging_time': 2.6063740253448486, 'global_step': 113645, 'preemption_count': 0}), (115162, {'train/accuracy': 0.8506855964660645, 'train/loss': 0.7918691635131836, 'validation/accuracy': 0.7225799560546875, 'validation/loss': 1.3202199935913086, 'validation/num_examples': 50000, 'test/accuracy': 0.6046000123023987, 'test/loss': 1.9181276559829712, 'test/num_examples': 10000, 'score': 38833.585057258606, 'total_duration': 40442.71990823746, 'accumulated_submission_time': 38833.585057258606, 'accumulated_eval_time': 1604.8197665214539, 'accumulated_logging_time': 2.641450881958008, 'global_step': 115162, 'preemption_count': 0}), (116679, {'train/accuracy': 0.8448461294174194, 'train/loss': 0.8080134987831116, 'validation/accuracy': 0.7315799593925476, 'validation/loss': 1.2733973264694214, 'validation/num_examples': 50000, 'test/accuracy': 0.6075000166893005, 'test/loss': 1.8885676860809326, 'test/num_examples': 10000, 'score': 39343.86174798012, 'total_duration': 40974.05097866058, 'accumulated_submission_time': 39343.86174798012, 'accumulated_eval_time': 1625.817280292511, 'accumulated_logging_time': 2.676112651824951, 'global_step': 116679, 'preemption_count': 0}), (118195, {'train/accuracy': 0.8509048223495483, 'train/loss': 0.8078310489654541, 'validation/accuracy': 0.7376199960708618, 'validation/loss': 1.2678614854812622, 'validation/num_examples': 50000, 'test/accuracy': 0.6170000433921814, 'test/loss': 1.8626408576965332, 'test/num_examples': 10000, 'score': 39853.830624341965, 'total_duration': 41505.509009838104, 'accumulated_submission_time': 39853.830624341965, 'accumulated_eval_time': 1647.2455101013184, 'accumulated_logging_time': 2.7148563861846924, 'global_step': 118195, 'preemption_count': 0}), (119711, {'train/accuracy': 0.851980984210968, 'train/loss': 0.8017945289611816, 'validation/accuracy': 0.743939995765686, 'validation/loss': 1.2531801462173462, 'validation/num_examples': 50000, 'test/accuracy': 0.6211000084877014, 'test/loss': 1.8467514514923096, 'test/num_examples': 10000, 'score': 40363.865280628204, 'total_duration': 42036.52791571617, 'accumulated_submission_time': 40363.865280628204, 'accumulated_eval_time': 1668.1767156124115, 'accumulated_logging_time': 2.7459404468536377, 'global_step': 119711, 'preemption_count': 0}), (121228, {'train/accuracy': 0.8600326776504517, 'train/loss': 0.760419487953186, 'validation/accuracy': 0.746999979019165, 'validation/loss': 1.2122291326522827, 'validation/num_examples': 50000, 'test/accuracy': 0.6303000450134277, 'test/loss': 1.8107094764709473, 'test/num_examples': 10000, 'score': 40874.023218393326, 'total_duration': 42567.6419274807, 'accumulated_submission_time': 40874.023218393326, 'accumulated_eval_time': 1689.0746266841888, 'accumulated_logging_time': 2.78195858001709, 'global_step': 121228, 'preemption_count': 0}), (122745, {'train/accuracy': 0.8763352632522583, 'train/loss': 0.706902027130127, 'validation/accuracy': 0.7577399611473083, 'validation/loss': 1.1869767904281616, 'validation/num_examples': 50000, 'test/accuracy': 0.6366000175476074, 'test/loss': 1.7874842882156372, 'test/num_examples': 10000, 'score': 41384.26992273331, 'total_duration': 43099.07498002052, 'accumulated_submission_time': 41384.26992273331, 'accumulated_eval_time': 1710.2027170658112, 'accumulated_logging_time': 2.8178248405456543, 'global_step': 122745, 'preemption_count': 0}), (124262, {'train/accuracy': 0.8968231678009033, 'train/loss': 0.621975302696228, 'validation/accuracy': 0.7638999819755554, 'validation/loss': 1.1538081169128418, 'validation/num_examples': 50000, 'test/accuracy': 0.6439000368118286, 'test/loss': 1.7414237260818481, 'test/num_examples': 10000, 'score': 41894.382313251495, 'total_duration': 43630.21175980568, 'accumulated_submission_time': 41894.382313251495, 'accumulated_eval_time': 1731.169250011444, 'accumulated_logging_time': 2.85366153717041, 'global_step': 124262, 'preemption_count': 0}), (125779, {'train/accuracy': 0.9035195708274841, 'train/loss': 0.6033666729927063, 'validation/accuracy': 0.7686600089073181, 'validation/loss': 1.1359121799468994, 'validation/num_examples': 50000, 'test/accuracy': 0.6485000252723694, 'test/loss': 1.7149373292922974, 'test/num_examples': 10000, 'score': 42404.51796746254, 'total_duration': 44161.42968297005, 'accumulated_submission_time': 42404.51796746254, 'accumulated_eval_time': 1752.1927847862244, 'accumulated_logging_time': 2.890361785888672, 'global_step': 125779, 'preemption_count': 0}), (127296, {'train/accuracy': 0.9037986397743225, 'train/loss': 0.6011214256286621, 'validation/accuracy': 0.772059977054596, 'validation/loss': 1.1232010126113892, 'validation/num_examples': 50000, 'test/accuracy': 0.6530000567436218, 'test/loss': 1.7030549049377441, 'test/num_examples': 10000, 'score': 42914.685732364655, 'total_duration': 44692.565321445465, 'accumulated_submission_time': 42914.685732364655, 'accumulated_eval_time': 1773.099259853363, 'accumulated_logging_time': 2.929689645767212, 'global_step': 127296, 'preemption_count': 0}), (128813, {'train/accuracy': 0.9054726958274841, 'train/loss': 0.5933184623718262, 'validation/accuracy': 0.7722199559211731, 'validation/loss': 1.1196633577346802, 'validation/num_examples': 50000, 'test/accuracy': 0.6549000144004822, 'test/loss': 1.6986366510391235, 'test/num_examples': 10000, 'score': 43424.90678334236, 'total_duration': 45223.79325962067, 'accumulated_submission_time': 43424.90678334236, 'accumulated_eval_time': 1794.0464432239532, 'accumulated_logging_time': 2.967623710632324, 'global_step': 128813, 'preemption_count': 0}), (130330, {'train/accuracy': 0.90433669090271, 'train/loss': 0.5941982865333557, 'validation/accuracy': 0.7730399966239929, 'validation/loss': 1.1208032369613647, 'validation/num_examples': 50000, 'test/accuracy': 0.6545000076293945, 'test/loss': 1.6990039348602295, 'test/num_examples': 10000, 'score': 43935.1196911335, 'total_duration': 45755.22074198723, 'accumulated_submission_time': 43935.1196911335, 'accumulated_eval_time': 1815.1980483531952, 'accumulated_logging_time': 3.007782459259033, 'global_step': 130330, 'preemption_count': 0}), (131847, {'train/accuracy': 0.9038584232330322, 'train/loss': 0.5937583446502686, 'validation/accuracy': 0.7728399634361267, 'validation/loss': 1.1189135313034058, 'validation/num_examples': 50000, 'test/accuracy': 0.655500054359436, 'test/loss': 1.6975986957550049, 'test/num_examples': 10000, 'score': 44445.155653715134, 'total_duration': 46286.13620018959, 'accumulated_submission_time': 44445.155653715134, 'accumulated_eval_time': 1836.0181152820587, 'accumulated_logging_time': 3.044888973236084, 'global_step': 131847, 'preemption_count': 0}), (133364, {'train/accuracy': 0.9064293503761292, 'train/loss': 0.5917299389839172, 'validation/accuracy': 0.773099958896637, 'validation/loss': 1.1213818788528442, 'validation/num_examples': 50000, 'test/accuracy': 0.657200038433075, 'test/loss': 1.7016446590423584, 'test/num_examples': 10000, 'score': 44955.35348391533, 'total_duration': 46817.22782421112, 'accumulated_submission_time': 44955.35348391533, 'accumulated_eval_time': 1856.8502929210663, 'accumulated_logging_time': 3.084364175796509, 'global_step': 133364, 'preemption_count': 0}), (134880, {'train/accuracy': 0.9071468114852905, 'train/loss': 0.591973602771759, 'validation/accuracy': 0.7734400033950806, 'validation/loss': 1.119201421737671, 'validation/num_examples': 50000, 'test/accuracy': 0.6568000316619873, 'test/loss': 1.6979857683181763, 'test/num_examples': 10000, 'score': 45465.58112287521, 'total_duration': 47348.38234257698, 'accumulated_submission_time': 45465.58112287521, 'accumulated_eval_time': 1877.7174632549286, 'accumulated_logging_time': 3.122377634048462, 'global_step': 134880, 'preemption_count': 0}), (136396, {'train/accuracy': 0.9083226919174194, 'train/loss': 0.5861381888389587, 'validation/accuracy': 0.7735599875450134, 'validation/loss': 1.121933102607727, 'validation/num_examples': 50000, 'test/accuracy': 0.6571000218391418, 'test/loss': 1.6998858451843262, 'test/num_examples': 10000, 'score': 45975.52750468254, 'total_duration': 47879.35364127159, 'accumulated_submission_time': 45975.52750468254, 'accumulated_eval_time': 1898.679480791092, 'accumulated_logging_time': 3.1631991863250732, 'global_step': 136396, 'preemption_count': 0}), (137913, {'train/accuracy': 0.9076849222183228, 'train/loss': 0.5908622145652771, 'validation/accuracy': 0.7728999853134155, 'validation/loss': 1.1200032234191895, 'validation/num_examples': 50000, 'test/accuracy': 0.656000018119812, 'test/loss': 1.69845712184906, 'test/num_examples': 10000, 'score': 46485.78516316414, 'total_duration': 48410.5927529335, 'accumulated_submission_time': 46485.78516316414, 'accumulated_eval_time': 1919.5967102050781, 'accumulated_logging_time': 3.2052040100097656, 'global_step': 137913, 'preemption_count': 0}), (139429, {'train/accuracy': 0.9047552347183228, 'train/loss': 0.5942578911781311, 'validation/accuracy': 0.7739399671554565, 'validation/loss': 1.1209300756454468, 'validation/num_examples': 50000, 'test/accuracy': 0.657200038433075, 'test/loss': 1.6977221965789795, 'test/num_examples': 10000, 'score': 46995.818197488785, 'total_duration': 48941.54935002327, 'accumulated_submission_time': 46995.818197488785, 'accumulated_eval_time': 1940.455887556076, 'accumulated_logging_time': 3.247645139694214, 'global_step': 139429, 'preemption_count': 0}), (140000, {'train/accuracy': 0.9080436825752258, 'train/loss': 0.5800074934959412, 'validation/accuracy': 0.7743600010871887, 'validation/loss': 1.117522954940796, 'validation/num_examples': 50000, 'test/accuracy': 0.6568000316619873, 'test/loss': 1.6970562934875488, 'test/num_examples': 10000, 'score': 47187.81134438515, 'total_duration': 49154.28737163544, 'accumulated_submission_time': 47187.81134438515, 'accumulated_eval_time': 1961.1525249481201, 'accumulated_logging_time': 3.287461757659912, 'global_step': 140000, 'preemption_count': 0})], 'global_step': 140000}
I0922 15:56:31.026633 139860156245824 submission_runner.py:543] Timing: 47187.81134438515
I0922 15:56:31.026688 139860156245824 submission_runner.py:545] Total number of evals: 94
I0922 15:56:31.026731 139860156245824 submission_runner.py:546] ====================
I0922 15:56:31.026992 139860156245824 submission_runner.py:614] Final imagenet_resnet score: 47187.81134438515
