python3 submission_runner.py --framework=jax --workload=imagenet_resnet --submission_path=reference_algorithms/target_setting_algorithms/jax_momentum.py --tuning_search_space=reference_algorithms/target_setting_algorithms/imagenet_resnet/tuning_search_space.json --data_dir=/data/imagenet/jax --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=targets_check_jax_run_02/momentum_run_0 --overwrite=true --save_checkpoints=false --max_global_steps=140000 --imagenet_v2_data_dir=/data/imagenet/jax 2>&1 | tee -a /logs/imagenet_resnet_jax_09-21-2023-00-19-45.log
2023-09-21 00:19:50.998335: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
I0921 00:20:09.735180 140613218989888 logger_utils.py:76] Creating experiment directory at /experiment_runs/targets_check_jax_run_02/momentum_run_0/imagenet_resnet_jax.
I0921 00:20:10.708833 140613218989888 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter Host
I0921 00:20:10.709493 140613218989888 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0921 00:20:10.709633 140613218989888 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0921 00:20:10.716217 140613218989888 submission_runner.py:500] Using RNG seed 2868085080
I0921 00:20:16.673250 140613218989888 submission_runner.py:509] --- Tuning run 1/1 ---
I0921 00:20:16.673491 140613218989888 submission_runner.py:514] Creating tuning directory at /experiment_runs/targets_check_jax_run_02/momentum_run_0/imagenet_resnet_jax/trial_1.
I0921 00:20:16.673681 140613218989888 logger_utils.py:92] Saving hparams to /experiment_runs/targets_check_jax_run_02/momentum_run_0/imagenet_resnet_jax/trial_1/hparams.json.
I0921 00:20:16.861978 140613218989888 submission_runner.py:185] Initializing dataset.
I0921 00:20:16.882066 140613218989888 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0921 00:20:16.894484 140613218989888 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0921 00:20:17.288301 140613218989888 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0921 00:20:18.499287 140613218989888 submission_runner.py:192] Initializing model.
I0921 00:20:29.148238 140613218989888 submission_runner.py:226] Initializing optimizer.
I0921 00:20:30.720594 140613218989888 submission_runner.py:233] Initializing metrics bundle.
I0921 00:20:30.720793 140613218989888 submission_runner.py:251] Initializing checkpoint and logger.
I0921 00:20:30.721968 140613218989888 checkpoints.py:915] Found no checkpoint files in /experiment_runs/targets_check_jax_run_02/momentum_run_0/imagenet_resnet_jax/trial_1 with prefix checkpoint_
I0921 00:20:31.659768 140613218989888 submission_runner.py:272] Saving meta data to /experiment_runs/targets_check_jax_run_02/momentum_run_0/imagenet_resnet_jax/trial_1/meta_data_0.json.
I0921 00:20:31.661572 140613218989888 submission_runner.py:275] Saving flags to /experiment_runs/targets_check_jax_run_02/momentum_run_0/imagenet_resnet_jax/trial_1/flags_0.json.
I0921 00:20:31.671262 140613218989888 submission_runner.py:285] Starting training loop.
2023-09-21 00:21:30.975249: E external/xla/xla/service/rendezvous.cc:31] This thread has been waiting for 10 seconds and may be stuck:
2023-09-21 00:21:33.515913: E external/xla/xla/service/rendezvous.cc:36] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.
I0921 00:21:35.081089 140447192176384 logging_writer.py:48] [0] global_step=0, grad_norm=0.5563316941261292, loss=6.930698394775391
I0921 00:21:35.097946 140613218989888 spec.py:320] Evaluating on the training split.
I0921 00:21:36.059638 140613218989888 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0921 00:21:36.068844 140613218989888 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0921 00:21:36.153556 140613218989888 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0921 00:21:49.118548 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 00:21:50.367825 140613218989888 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0921 00:21:50.385855 140613218989888 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0921 00:21:50.460115 140613218989888 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0921 00:22:10.469817 140613218989888 spec.py:348] Evaluating on the test split.
I0921 00:22:11.316871 140613218989888 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0921 00:22:11.324807 140613218989888 dataset_builder.py:528] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0921 00:22:11.375193 140613218989888 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0921 00:22:22.153873 140613218989888 submission_runner.py:376] Time since start: 110.48s, 	Step: 1, 	{'train/accuracy': 0.0010363520123064518, 'train/loss': 6.91220760345459, 'validation/accuracy': 0.0008999999845400453, 'validation/loss': 6.911862373352051, 'validation/num_examples': 50000, 'test/accuracy': 0.0010999999940395355, 'test/loss': 6.912576198577881, 'test/num_examples': 10000, 'score': 63.42658305168152, 'total_duration': 110.48254609107971, 'accumulated_submission_time': 63.42658305168152, 'accumulated_eval_time': 47.05587124824524, 'accumulated_logging_time': 0}
I0921 00:22:22.174788 140418243094272 logging_writer.py:48] [1] accumulated_eval_time=47.055871, accumulated_logging_time=0, accumulated_submission_time=63.426583, global_step=1, preemption_count=0, score=63.426583, test/accuracy=0.001100, test/loss=6.912576, test/num_examples=10000, total_duration=110.482546, train/accuracy=0.001036, train/loss=6.912208, validation/accuracy=0.000900, validation/loss=6.911862, validation/num_examples=50000
I0921 00:22:22.527171 140418251486976 logging_writer.py:48] [1] global_step=1, grad_norm=0.5420605540275574, loss=6.933406352996826
I0921 00:22:22.859939 140418243094272 logging_writer.py:48] [2] global_step=2, grad_norm=0.5260661840438843, loss=6.920904159545898
I0921 00:22:23.196085 140418251486976 logging_writer.py:48] [3] global_step=3, grad_norm=0.5464506149291992, loss=6.9261956214904785
I0921 00:22:23.531192 140418243094272 logging_writer.py:48] [4] global_step=4, grad_norm=0.5484023094177246, loss=6.93790340423584
I0921 00:22:23.867565 140418251486976 logging_writer.py:48] [5] global_step=5, grad_norm=0.5328207612037659, loss=6.92358922958374
I0921 00:22:24.202884 140418243094272 logging_writer.py:48] [6] global_step=6, grad_norm=0.5356621742248535, loss=6.922907829284668
I0921 00:22:24.539721 140418251486976 logging_writer.py:48] [7] global_step=7, grad_norm=0.5241442918777466, loss=6.924181938171387
I0921 00:22:24.877330 140418243094272 logging_writer.py:48] [8] global_step=8, grad_norm=0.5379922389984131, loss=6.929767608642578
I0921 00:22:25.220749 140418251486976 logging_writer.py:48] [9] global_step=9, grad_norm=0.5440324544906616, loss=6.935551643371582
I0921 00:22:25.555198 140418243094272 logging_writer.py:48] [10] global_step=10, grad_norm=0.5453055500984192, loss=6.91994047164917
I0921 00:22:25.889153 140418251486976 logging_writer.py:48] [11] global_step=11, grad_norm=0.545007050037384, loss=6.925210952758789
I0921 00:22:26.228777 140418243094272 logging_writer.py:48] [12] global_step=12, grad_norm=0.5399075746536255, loss=6.923259258270264
I0921 00:22:26.566261 140418251486976 logging_writer.py:48] [13] global_step=13, grad_norm=0.5362339019775391, loss=6.927305221557617
I0921 00:22:26.903254 140418243094272 logging_writer.py:48] [14] global_step=14, grad_norm=0.5303665995597839, loss=6.930929660797119
I0921 00:22:27.246932 140418251486976 logging_writer.py:48] [15] global_step=15, grad_norm=0.5729291439056396, loss=6.925494194030762
I0921 00:22:27.591136 140418243094272 logging_writer.py:48] [16] global_step=16, grad_norm=0.526073694229126, loss=6.908718585968018
I0921 00:22:27.941050 140418251486976 logging_writer.py:48] [17] global_step=17, grad_norm=0.5327125191688538, loss=6.909692764282227
I0921 00:22:28.278806 140418243094272 logging_writer.py:48] [18] global_step=18, grad_norm=0.5395603179931641, loss=6.921718120574951
I0921 00:22:28.613723 140418251486976 logging_writer.py:48] [19] global_step=19, grad_norm=0.5324004888534546, loss=6.908438205718994
I0921 00:22:28.968558 140418243094272 logging_writer.py:48] [20] global_step=20, grad_norm=0.5474923253059387, loss=6.916072368621826
I0921 00:22:29.309651 140418251486976 logging_writer.py:48] [21] global_step=21, grad_norm=0.5257435441017151, loss=6.904871940612793
I0921 00:22:29.650537 140418243094272 logging_writer.py:48] [22] global_step=22, grad_norm=0.5382184386253357, loss=6.9110846519470215
I0921 00:22:29.993143 140418251486976 logging_writer.py:48] [23] global_step=23, grad_norm=0.5306285619735718, loss=6.900088310241699
I0921 00:22:30.347195 140418243094272 logging_writer.py:48] [24] global_step=24, grad_norm=0.5403220653533936, loss=6.901258945465088
I0921 00:22:30.690356 140418251486976 logging_writer.py:48] [25] global_step=25, grad_norm=0.5359060168266296, loss=6.904452323913574
I0921 00:22:31.046880 140418243094272 logging_writer.py:48] [26] global_step=26, grad_norm=0.5291658639907837, loss=6.904052257537842
I0921 00:22:31.389918 140418251486976 logging_writer.py:48] [27] global_step=27, grad_norm=0.516372561454773, loss=6.906612396240234
I0921 00:22:31.728214 140418243094272 logging_writer.py:48] [28] global_step=28, grad_norm=0.5344109535217285, loss=6.894718647003174
I0921 00:22:32.068162 140418251486976 logging_writer.py:48] [29] global_step=29, grad_norm=0.5430341958999634, loss=6.899886608123779
I0921 00:22:32.411850 140418243094272 logging_writer.py:48] [30] global_step=30, grad_norm=0.5105817914009094, loss=6.893848419189453
I0921 00:22:32.754318 140418251486976 logging_writer.py:48] [31] global_step=31, grad_norm=0.550148606300354, loss=6.900583267211914
I0921 00:22:33.095219 140418243094272 logging_writer.py:48] [32] global_step=32, grad_norm=0.5422645807266235, loss=6.895782470703125
I0921 00:22:33.432960 140418251486976 logging_writer.py:48] [33] global_step=33, grad_norm=0.5443384647369385, loss=6.889247894287109
I0921 00:22:33.774331 140418243094272 logging_writer.py:48] [34] global_step=34, grad_norm=0.5298402309417725, loss=6.886694431304932
I0921 00:22:34.120302 140418251486976 logging_writer.py:48] [35] global_step=35, grad_norm=0.5340990424156189, loss=6.884541034698486
I0921 00:22:34.467897 140418243094272 logging_writer.py:48] [36] global_step=36, grad_norm=0.5227813720703125, loss=6.880038261413574
I0921 00:22:34.809798 140418251486976 logging_writer.py:48] [37] global_step=37, grad_norm=0.5355860590934753, loss=6.883771896362305
I0921 00:22:35.149573 140418243094272 logging_writer.py:48] [38] global_step=38, grad_norm=0.5215061902999878, loss=6.882721900939941
I0921 00:22:35.501405 140418251486976 logging_writer.py:48] [39] global_step=39, grad_norm=0.531731367111206, loss=6.887913703918457
I0921 00:22:35.843542 140418243094272 logging_writer.py:48] [40] global_step=40, grad_norm=0.5409425497055054, loss=6.876843452453613
I0921 00:22:36.182853 140418251486976 logging_writer.py:48] [41] global_step=41, grad_norm=0.5213497877120972, loss=6.878006935119629
I0921 00:22:36.517890 140418243094272 logging_writer.py:48] [42] global_step=42, grad_norm=0.5274547934532166, loss=6.869867324829102
I0921 00:22:36.855195 140418251486976 logging_writer.py:48] [43] global_step=43, grad_norm=0.5281503796577454, loss=6.875378131866455
I0921 00:22:37.191245 140418243094272 logging_writer.py:48] [44] global_step=44, grad_norm=0.5216000080108643, loss=6.865767955780029
I0921 00:22:37.525752 140418251486976 logging_writer.py:48] [45] global_step=45, grad_norm=0.5404658913612366, loss=6.850439071655273
I0921 00:22:37.872150 140418243094272 logging_writer.py:48] [46] global_step=46, grad_norm=0.5410371422767639, loss=6.864529609680176
I0921 00:22:38.209126 140418251486976 logging_writer.py:48] [47] global_step=47, grad_norm=0.5504673719406128, loss=6.879603385925293
I0921 00:22:38.548875 140418243094272 logging_writer.py:48] [48] global_step=48, grad_norm=0.5396199822425842, loss=6.863391399383545
I0921 00:22:38.890231 140418251486976 logging_writer.py:48] [49] global_step=49, grad_norm=0.5435841679573059, loss=6.864748001098633
I0921 00:22:39.242315 140418243094272 logging_writer.py:48] [50] global_step=50, grad_norm=0.5585485100746155, loss=6.858393669128418
I0921 00:22:39.591765 140418251486976 logging_writer.py:48] [51] global_step=51, grad_norm=0.5348204970359802, loss=6.848065376281738
I0921 00:22:39.932864 140418243094272 logging_writer.py:48] [52] global_step=52, grad_norm=0.5406157374382019, loss=6.852054119110107
I0921 00:22:40.273753 140418251486976 logging_writer.py:48] [53] global_step=53, grad_norm=0.5509515404701233, loss=6.842803955078125
I0921 00:22:40.612690 140418243094272 logging_writer.py:48] [54] global_step=54, grad_norm=0.5407646894454956, loss=6.846693992614746
I0921 00:22:40.948826 140418251486976 logging_writer.py:48] [55] global_step=55, grad_norm=0.555444598197937, loss=6.848784446716309
I0921 00:22:41.288641 140418243094272 logging_writer.py:48] [56] global_step=56, grad_norm=0.5728210806846619, loss=6.851871490478516
I0921 00:22:41.638159 140418251486976 logging_writer.py:48] [57] global_step=57, grad_norm=0.5335817337036133, loss=6.835646629333496
I0921 00:22:41.975519 140418243094272 logging_writer.py:48] [58] global_step=58, grad_norm=0.5529950857162476, loss=6.826654434204102
I0921 00:22:42.321946 140418251486976 logging_writer.py:48] [59] global_step=59, grad_norm=0.5485995411872864, loss=6.840174198150635
I0921 00:22:42.662489 140418243094272 logging_writer.py:48] [60] global_step=60, grad_norm=0.5468389391899109, loss=6.8351030349731445
I0921 00:22:43.006064 140418251486976 logging_writer.py:48] [61] global_step=61, grad_norm=0.5704689621925354, loss=6.833099365234375
I0921 00:22:43.344350 140418243094272 logging_writer.py:48] [62] global_step=62, grad_norm=0.5679489970207214, loss=6.825336933135986
I0921 00:22:43.693350 140418251486976 logging_writer.py:48] [63] global_step=63, grad_norm=0.5538339614868164, loss=6.833106517791748
I0921 00:22:44.033038 140418243094272 logging_writer.py:48] [64] global_step=64, grad_norm=0.5582337379455566, loss=6.8091535568237305
I0921 00:22:44.372975 140418251486976 logging_writer.py:48] [65] global_step=65, grad_norm=0.5758341550827026, loss=6.8253655433654785
I0921 00:22:44.716077 140418243094272 logging_writer.py:48] [66] global_step=66, grad_norm=0.5711483955383301, loss=6.806366443634033
I0921 00:22:45.062947 140418251486976 logging_writer.py:48] [67] global_step=67, grad_norm=0.5521509647369385, loss=6.812082290649414
I0921 00:22:45.402397 140418243094272 logging_writer.py:48] [68] global_step=68, grad_norm=0.5620955228805542, loss=6.794568061828613
I0921 00:22:45.746651 140418251486976 logging_writer.py:48] [69] global_step=69, grad_norm=0.5637133717536926, loss=6.800246238708496
I0921 00:22:46.085104 140418243094272 logging_writer.py:48] [70] global_step=70, grad_norm=0.5619961023330688, loss=6.787999629974365
I0921 00:22:46.431588 140418251486976 logging_writer.py:48] [71] global_step=71, grad_norm=0.5779818892478943, loss=6.799094200134277
I0921 00:22:46.773201 140418243094272 logging_writer.py:48] [72] global_step=72, grad_norm=0.5825289487838745, loss=6.781582832336426
I0921 00:22:47.112571 140418251486976 logging_writer.py:48] [73] global_step=73, grad_norm=0.5764539241790771, loss=6.796877861022949
I0921 00:22:47.453755 140418243094272 logging_writer.py:48] [74] global_step=74, grad_norm=0.578093945980072, loss=6.777802467346191
I0921 00:22:47.796815 140418251486976 logging_writer.py:48] [75] global_step=75, grad_norm=0.5712320804595947, loss=6.775622367858887
I0921 00:22:48.141317 140418243094272 logging_writer.py:48] [76] global_step=76, grad_norm=0.5773877501487732, loss=6.783332824707031
I0921 00:22:48.481290 140418251486976 logging_writer.py:48] [77] global_step=77, grad_norm=0.5760298371315002, loss=6.752143859863281
I0921 00:22:48.820757 140418243094272 logging_writer.py:48] [78] global_step=78, grad_norm=0.5969334244728088, loss=6.749870777130127
I0921 00:22:49.158512 140418251486976 logging_writer.py:48] [79] global_step=79, grad_norm=0.5794575810432434, loss=6.759387969970703
I0921 00:22:49.500027 140418243094272 logging_writer.py:48] [80] global_step=80, grad_norm=0.5872409343719482, loss=6.7585930824279785
I0921 00:22:49.844705 140418251486976 logging_writer.py:48] [81] global_step=81, grad_norm=0.6004892587661743, loss=6.78303337097168
I0921 00:22:50.183116 140418243094272 logging_writer.py:48] [82] global_step=82, grad_norm=0.6275739669799805, loss=6.762884140014648
I0921 00:22:50.523545 140418251486976 logging_writer.py:48] [83] global_step=83, grad_norm=0.6109288334846497, loss=6.728975772857666
I0921 00:22:50.865908 140418243094272 logging_writer.py:48] [84] global_step=84, grad_norm=0.6190110445022583, loss=6.7517781257629395
I0921 00:22:51.203657 140418251486976 logging_writer.py:48] [85] global_step=85, grad_norm=0.6175463795661926, loss=6.7372260093688965
I0921 00:22:51.543606 140418243094272 logging_writer.py:48] [86] global_step=86, grad_norm=0.5765413045883179, loss=6.73630428314209
I0921 00:22:51.885964 140418251486976 logging_writer.py:48] [87] global_step=87, grad_norm=0.5791665315628052, loss=6.745651721954346
I0921 00:22:52.230283 140418243094272 logging_writer.py:48] [88] global_step=88, grad_norm=0.6035159826278687, loss=6.748033046722412
I0921 00:22:52.571691 140418251486976 logging_writer.py:48] [89] global_step=89, grad_norm=0.6092205047607422, loss=6.734974384307861
I0921 00:22:52.913871 140418243094272 logging_writer.py:48] [90] global_step=90, grad_norm=0.6077076196670532, loss=6.7030744552612305
I0921 00:22:53.254054 140418251486976 logging_writer.py:48] [91] global_step=91, grad_norm=0.6060813069343567, loss=6.7412028312683105
I0921 00:22:53.594008 140418243094272 logging_writer.py:48] [92] global_step=92, grad_norm=0.5926579236984253, loss=6.693047523498535
I0921 00:22:53.935324 140418251486976 logging_writer.py:48] [93] global_step=93, grad_norm=0.6106031537055969, loss=6.6970343589782715
I0921 00:22:54.272243 140418243094272 logging_writer.py:48] [94] global_step=94, grad_norm=0.6134994029998779, loss=6.687639236450195
I0921 00:22:54.611601 140418251486976 logging_writer.py:48] [95] global_step=95, grad_norm=0.618302583694458, loss=6.7133002281188965
I0921 00:22:54.951177 140418243094272 logging_writer.py:48] [96] global_step=96, grad_norm=0.6046845316886902, loss=6.696984767913818
I0921 00:22:55.299771 140418251486976 logging_writer.py:48] [97] global_step=97, grad_norm=0.6258026361465454, loss=6.720874309539795
I0921 00:22:55.638313 140418243094272 logging_writer.py:48] [98] global_step=98, grad_norm=0.6217877864837646, loss=6.7295403480529785
I0921 00:22:55.980515 140418251486976 logging_writer.py:48] [99] global_step=99, grad_norm=0.6344262957572937, loss=6.692075729370117
I0921 00:22:56.321408 140418243094272 logging_writer.py:48] [100] global_step=100, grad_norm=0.6347963809967041, loss=6.671544551849365
I0921 00:25:11.196948 140418251486976 logging_writer.py:48] [500] global_step=500, grad_norm=0.5042558312416077, loss=6.208642959594727
I0921 00:27:59.956098 140418243094272 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.5514674186706543, loss=5.593202590942383
I0921 00:30:48.574975 140418251486976 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.4075099527835846, loss=5.109992504119873
I0921 00:30:52.377985 140613218989888 spec.py:320] Evaluating on the training split.
I0921 00:30:59.548800 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 00:31:07.757919 140613218989888 spec.py:348] Evaluating on the test split.
I0921 00:31:10.121309 140613218989888 submission_runner.py:376] Time since start: 638.45s, 	Step: 1513, 	{'train/accuracy': 0.18600526452064514, 'train/loss': 4.260481357574463, 'validation/accuracy': 0.1713399887084961, 'validation/loss': 4.391124725341797, 'validation/num_examples': 50000, 'test/accuracy': 0.12350000441074371, 'test/loss': 4.809715270996094, 'test/num_examples': 10000, 'score': 573.5950057506561, 'total_duration': 638.4499394893646, 'accumulated_submission_time': 573.5950057506561, 'accumulated_eval_time': 64.79911708831787, 'accumulated_logging_time': 0.031407833099365234}
I0921 00:31:10.140980 140418364692224 logging_writer.py:48] [1513] accumulated_eval_time=64.799117, accumulated_logging_time=0.031408, accumulated_submission_time=573.595006, global_step=1513, preemption_count=0, score=573.595006, test/accuracy=0.123500, test/loss=4.809715, test/num_examples=10000, total_duration=638.449939, train/accuracy=0.186005, train/loss=4.260481, validation/accuracy=0.171340, validation/loss=4.391125, validation/num_examples=50000
I0921 00:33:54.644410 140418373084928 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.3806363344192505, loss=4.7896528244018555
I0921 00:36:42.953112 140418364692224 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.35272830724716187, loss=4.564854145050049
I0921 00:39:31.301899 140418373084928 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.31165966391563416, loss=4.432936668395996
I0921 00:39:40.149292 140613218989888 spec.py:320] Evaluating on the training split.
I0921 00:39:47.546655 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 00:39:55.754276 140613218989888 spec.py:348] Evaluating on the test split.
I0921 00:39:58.046115 140613218989888 submission_runner.py:376] Time since start: 1166.37s, 	Step: 3028, 	{'train/accuracy': 0.3601522445678711, 'train/loss': 3.1906676292419434, 'validation/accuracy': 0.32725998759269714, 'validation/loss': 3.360729217529297, 'validation/num_examples': 50000, 'test/accuracy': 0.24540001153945923, 'test/loss': 3.9212749004364014, 'test/num_examples': 10000, 'score': 1083.5686395168304, 'total_duration': 1166.3747670650482, 'accumulated_submission_time': 1083.5686395168304, 'accumulated_eval_time': 82.69588994979858, 'accumulated_logging_time': 0.06120419502258301}
I0921 00:39:58.064004 140448249149184 logging_writer.py:48] [3028] accumulated_eval_time=82.695890, accumulated_logging_time=0.061204, accumulated_submission_time=1083.568640, global_step=3028, preemption_count=0, score=1083.568640, test/accuracy=0.245400, test/loss=3.921275, test/num_examples=10000, total_duration=1166.374767, train/accuracy=0.360152, train/loss=3.190668, validation/accuracy=0.327260, validation/loss=3.360729, validation/num_examples=50000
I0921 00:42:37.303425 140448333010688 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.3038787841796875, loss=4.22756290435791
I0921 00:45:25.542026 140448249149184 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.30508655309677124, loss=4.16455078125
I0921 00:48:13.803800 140448333010688 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.28565269708633423, loss=4.055211544036865
I0921 00:48:28.366229 140613218989888 spec.py:320] Evaluating on the training split.
I0921 00:48:35.549952 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 00:48:43.858578 140613218989888 spec.py:348] Evaluating on the test split.
I0921 00:48:46.165224 140613218989888 submission_runner.py:376] Time since start: 1694.49s, 	Step: 4545, 	{'train/accuracy': 0.4586256146430969, 'train/loss': 2.605865478515625, 'validation/accuracy': 0.42941999435424805, 'validation/loss': 2.7456960678100586, 'validation/num_examples': 50000, 'test/accuracy': 0.32360002398490906, 'test/loss': 3.4065797328948975, 'test/num_examples': 10000, 'score': 1593.8365013599396, 'total_duration': 1694.4938836097717, 'accumulated_submission_time': 1593.8365013599396, 'accumulated_eval_time': 100.49484872817993, 'accumulated_logging_time': 0.08878755569458008}
I0921 00:48:46.183137 140447024387840 logging_writer.py:48] [4545] accumulated_eval_time=100.494849, accumulated_logging_time=0.088788, accumulated_submission_time=1593.836501, global_step=4545, preemption_count=0, score=1593.836501, test/accuracy=0.323600, test/loss=3.406580, test/num_examples=10000, total_duration=1694.493884, train/accuracy=0.458626, train/loss=2.605865, validation/accuracy=0.429420, validation/loss=2.745696, validation/num_examples=50000
I0921 00:51:19.656101 140447032780544 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.27122944593429565, loss=4.037111282348633
I0921 00:54:07.897336 140447024387840 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.2634727954864502, loss=3.959780216217041
I0921 00:56:56.140579 140447032780544 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.2609141170978546, loss=4.0406718254089355
I0921 00:57:16.437479 140613218989888 spec.py:320] Evaluating on the training split.
I0921 00:57:23.665191 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 00:57:31.804307 140613218989888 spec.py:348] Evaluating on the test split.
I0921 00:57:34.164487 140613218989888 submission_runner.py:376] Time since start: 2222.49s, 	Step: 6062, 	{'train/accuracy': 0.48810186982154846, 'train/loss': 2.485229730606079, 'validation/accuracy': 0.46181997656822205, 'validation/loss': 2.6277108192443848, 'validation/num_examples': 50000, 'test/accuracy': 0.34790000319480896, 'test/loss': 3.319991111755371, 'test/num_examples': 10000, 'score': 2104.052232503891, 'total_duration': 2222.4931490421295, 'accumulated_submission_time': 2104.052232503891, 'accumulated_eval_time': 118.22181153297424, 'accumulated_logging_time': 0.12106847763061523}
I0921 00:57:34.183365 140447049565952 logging_writer.py:48] [6062] accumulated_eval_time=118.221812, accumulated_logging_time=0.121068, accumulated_submission_time=2104.052233, global_step=6062, preemption_count=0, score=2104.052233, test/accuracy=0.347900, test/loss=3.319991, test/num_examples=10000, total_duration=2222.493149, train/accuracy=0.488102, train/loss=2.485230, validation/accuracy=0.461820, validation/loss=2.627711, validation/num_examples=50000
I0921 01:00:01.908302 140447779387136 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.2556852698326111, loss=3.930469512939453
I0921 01:02:50.148778 140447049565952 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.24974983930587769, loss=4.024763584136963
I0921 01:05:38.383815 140447779387136 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.24227069318294525, loss=3.845379590988159
I0921 01:06:04.393211 140613218989888 spec.py:320] Evaluating on the training split.
I0921 01:06:11.660765 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 01:06:19.940271 140613218989888 spec.py:348] Evaluating on the test split.
I0921 01:06:22.303537 140613218989888 submission_runner.py:376] Time since start: 2750.63s, 	Step: 7579, 	{'train/accuracy': 0.47576528787612915, 'train/loss': 2.582186222076416, 'validation/accuracy': 0.44533997774124146, 'validation/loss': 2.7355730533599854, 'validation/num_examples': 50000, 'test/accuracy': 0.35110002756118774, 'test/loss': 3.3165767192840576, 'test/num_examples': 10000, 'score': 2614.2272295951843, 'total_duration': 2750.6316063404083, 'accumulated_submission_time': 2614.2272295951843, 'accumulated_eval_time': 136.13150453567505, 'accumulated_logging_time': 0.15039396286010742}
I0921 01:06:22.321308 140447032780544 logging_writer.py:48] [7579] accumulated_eval_time=136.131505, accumulated_logging_time=0.150394, accumulated_submission_time=2614.227230, global_step=7579, preemption_count=0, score=2614.227230, test/accuracy=0.351100, test/loss=3.316577, test/num_examples=10000, total_duration=2750.631606, train/accuracy=0.475765, train/loss=2.582186, validation/accuracy=0.445340, validation/loss=2.735573, validation/num_examples=50000
I0921 01:08:44.346693 140447041173248 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.2451358437538147, loss=3.8136916160583496
I0921 01:11:32.563067 140447032780544 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.23239603638648987, loss=3.8574984073638916
I0921 01:14:20.812728 140447041173248 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.24617044627666473, loss=3.829106330871582
I0921 01:14:52.520741 140613218989888 spec.py:320] Evaluating on the training split.
I0921 01:15:00.000604 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 01:15:08.337190 140613218989888 spec.py:348] Evaluating on the test split.
I0921 01:15:10.662297 140613218989888 submission_runner.py:376] Time since start: 3278.99s, 	Step: 9096, 	{'train/accuracy': 0.5944674611091614, 'train/loss': 1.9870927333831787, 'validation/accuracy': 0.5116599798202515, 'validation/loss': 2.362605333328247, 'validation/num_examples': 50000, 'test/accuracy': 0.39650002121925354, 'test/loss': 3.0199806690216064, 'test/num_examples': 10000, 'score': 3124.392338991165, 'total_duration': 3278.990958213806, 'accumulated_submission_time': 3124.392338991165, 'accumulated_eval_time': 154.27301621437073, 'accumulated_logging_time': 0.17804622650146484}
I0921 01:15:10.680286 140447015995136 logging_writer.py:48] [9096] accumulated_eval_time=154.273016, accumulated_logging_time=0.178046, accumulated_submission_time=3124.392339, global_step=9096, preemption_count=0, score=3124.392339, test/accuracy=0.396500, test/loss=3.019981, test/num_examples=10000, total_duration=3278.990958, train/accuracy=0.594467, train/loss=1.987093, validation/accuracy=0.511660, validation/loss=2.362605, validation/num_examples=50000
I0921 01:17:28.031490 140447024387840 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.24008247256278992, loss=3.834031105041504
I0921 01:20:16.257504 140447015995136 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.24792325496673584, loss=3.783202886581421
I0921 01:23:04.499977 140447024387840 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.24050012230873108, loss=3.746365785598755
I0921 01:23:40.906207 140613218989888 spec.py:320] Evaluating on the training split.
I0921 01:23:48.227600 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 01:23:56.687904 140613218989888 spec.py:348] Evaluating on the test split.
I0921 01:23:58.992567 140613218989888 submission_runner.py:376] Time since start: 3807.32s, 	Step: 10610, 	{'train/accuracy': 0.5423110723495483, 'train/loss': 2.207017421722412, 'validation/accuracy': 0.49041998386383057, 'validation/loss': 2.4853177070617676, 'validation/num_examples': 50000, 'test/accuracy': 0.3785000145435333, 'test/loss': 3.1514739990234375, 'test/num_examples': 10000, 'score': 3634.58509683609, 'total_duration': 3807.321106672287, 'accumulated_submission_time': 3634.58509683609, 'accumulated_eval_time': 172.35921263694763, 'accumulated_logging_time': 0.20548152923583984}
I0921 01:23:59.016076 140446286206720 logging_writer.py:48] [10610] accumulated_eval_time=172.359213, accumulated_logging_time=0.205482, accumulated_submission_time=3634.585097, global_step=10610, preemption_count=0, score=3634.585097, test/accuracy=0.378500, test/loss=3.151474, test/num_examples=10000, total_duration=3807.321107, train/accuracy=0.542311, train/loss=2.207017, validation/accuracy=0.490420, validation/loss=2.485318, validation/num_examples=50000
I0921 01:26:10.604931 140446294599424 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.23614098131656647, loss=3.7370500564575195
I0921 01:28:58.811371 140446286206720 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.24319392442703247, loss=3.722095489501953
I0921 01:31:47.032308 140446294599424 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.24179726839065552, loss=3.729423761367798
I0921 01:32:29.183159 140613218989888 spec.py:320] Evaluating on the training split.
I0921 01:32:36.507846 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 01:32:44.861637 140613218989888 spec.py:348] Evaluating on the test split.
I0921 01:32:47.212877 140613218989888 submission_runner.py:376] Time since start: 4335.54s, 	Step: 12127, 	{'train/accuracy': 0.5005381107330322, 'train/loss': 2.4511353969573975, 'validation/accuracy': 0.46271997690200806, 'validation/loss': 2.652254343032837, 'validation/num_examples': 50000, 'test/accuracy': 0.3573000133037567, 'test/loss': 3.3161263465881348, 'test/num_examples': 10000, 'score': 4144.716547966003, 'total_duration': 4335.541543960571, 'accumulated_submission_time': 4144.716547966003, 'accumulated_eval_time': 190.38888955116272, 'accumulated_logging_time': 0.2405107021331787}
I0921 01:32:47.235641 140447779387136 logging_writer.py:48] [12127] accumulated_eval_time=190.388890, accumulated_logging_time=0.240511, accumulated_submission_time=4144.716548, global_step=12127, preemption_count=0, score=4144.716548, test/accuracy=0.357300, test/loss=3.316126, test/num_examples=10000, total_duration=4335.541544, train/accuracy=0.500538, train/loss=2.451135, validation/accuracy=0.462720, validation/loss=2.652254, validation/num_examples=50000
I0921 01:34:53.028174 140447863248640 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.23860231041908264, loss=3.6773197650909424
I0921 01:37:41.279981 140447779387136 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.2449754923582077, loss=3.5909342765808105
I0921 01:40:29.443243 140447863248640 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.25106528401374817, loss=3.7281041145324707
I0921 01:41:17.325871 140613218989888 spec.py:320] Evaluating on the training split.
I0921 01:41:24.613720 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 01:41:32.899383 140613218989888 spec.py:348] Evaluating on the test split.
I0921 01:41:35.223679 140613218989888 submission_runner.py:376] Time since start: 4863.55s, 	Step: 13644, 	{'train/accuracy': 0.5743383169174194, 'train/loss': 2.007390022277832, 'validation/accuracy': 0.5335999727249146, 'validation/loss': 2.203630208969116, 'validation/num_examples': 50000, 'test/accuracy': 0.4118000268936157, 'test/loss': 2.903945207595825, 'test/num_examples': 10000, 'score': 4654.771801948547, 'total_duration': 4863.552335500717, 'accumulated_submission_time': 4654.771801948547, 'accumulated_eval_time': 208.28665924072266, 'accumulated_logging_time': 0.2745518684387207}
I0921 01:41:35.246109 140447024387840 logging_writer.py:48] [13644] accumulated_eval_time=208.286659, accumulated_logging_time=0.274552, accumulated_submission_time=4654.771802, global_step=13644, preemption_count=0, score=4654.771802, test/accuracy=0.411800, test/loss=2.903945, test/num_examples=10000, total_duration=4863.552336, train/accuracy=0.574338, train/loss=2.007390, validation/accuracy=0.533600, validation/loss=2.203630, validation/num_examples=50000
I0921 01:43:35.366709 140447032780544 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.24735087156295776, loss=3.724680185317993
I0921 01:46:23.590822 140447024387840 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.24553704261779785, loss=3.660844087600708
I0921 01:49:11.789602 140447032780544 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.25224098563194275, loss=3.623711585998535
I0921 01:50:05.376214 140613218989888 spec.py:320] Evaluating on the training split.
I0921 01:50:12.567801 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 01:50:20.783966 140613218989888 spec.py:348] Evaluating on the test split.
I0921 01:50:23.122530 140613218989888 submission_runner.py:376] Time since start: 5391.45s, 	Step: 15161, 	{'train/accuracy': 0.5954639315605164, 'train/loss': 1.9491528272628784, 'validation/accuracy': 0.553820013999939, 'validation/loss': 2.149799108505249, 'validation/num_examples': 50000, 'test/accuracy': 0.4392000138759613, 'test/loss': 2.7913265228271484, 'test/num_examples': 10000, 'score': 5164.86758518219, 'total_duration': 5391.45116686821, 'accumulated_submission_time': 5164.86758518219, 'accumulated_eval_time': 226.0329098701477, 'accumulated_logging_time': 0.3073427677154541}
I0921 01:50:23.146136 140447024387840 logging_writer.py:48] [15161] accumulated_eval_time=226.032910, accumulated_logging_time=0.307343, accumulated_submission_time=5164.867585, global_step=15161, preemption_count=0, score=5164.867585, test/accuracy=0.439200, test/loss=2.791327, test/num_examples=10000, total_duration=5391.451167, train/accuracy=0.595464, train/loss=1.949153, validation/accuracy=0.553820, validation/loss=2.149799, validation/num_examples=50000
I0921 01:52:17.551829 140447032780544 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.24098245799541473, loss=3.655078172683716
I0921 01:55:05.779758 140447024387840 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.25130021572113037, loss=3.624303102493286
I0921 01:57:53.988114 140447032780544 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.24644650518894196, loss=3.5778446197509766
I0921 01:58:53.293681 140613218989888 spec.py:320] Evaluating on the training split.
I0921 01:59:00.605164 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 01:59:09.040352 140613218989888 spec.py:348] Evaluating on the test split.
I0921 01:59:11.368568 140613218989888 submission_runner.py:376] Time since start: 5919.70s, 	Step: 16678, 	{'train/accuracy': 0.5875518321990967, 'train/loss': 1.9690172672271729, 'validation/accuracy': 0.5499599575996399, 'validation/loss': 2.139955520629883, 'validation/num_examples': 50000, 'test/accuracy': 0.43390002846717834, 'test/loss': 2.793609142303467, 'test/num_examples': 10000, 'score': 5674.9813821315765, 'total_duration': 5919.697226047516, 'accumulated_submission_time': 5674.9813821315765, 'accumulated_eval_time': 244.10775351524353, 'accumulated_logging_time': 0.3408012390136719}
I0921 01:59:11.392028 140447024387840 logging_writer.py:48] [16678] accumulated_eval_time=244.107754, accumulated_logging_time=0.340801, accumulated_submission_time=5674.981382, global_step=16678, preemption_count=0, score=5674.981382, test/accuracy=0.433900, test/loss=2.793609, test/num_examples=10000, total_duration=5919.697226, train/accuracy=0.587552, train/loss=1.969017, validation/accuracy=0.549960, validation/loss=2.139956, validation/num_examples=50000
I0921 02:00:59.970884 140447049565952 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.24538832902908325, loss=3.629940986633301
I0921 02:03:48.223615 140447024387840 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.25370028614997864, loss=3.6591367721557617
I0921 02:06:36.464946 140447049565952 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.26106879115104675, loss=3.674131393432617
I0921 02:07:41.488224 140613218989888 spec.py:320] Evaluating on the training split.
I0921 02:07:48.690984 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 02:07:57.088721 140613218989888 spec.py:348] Evaluating on the test split.
I0921 02:07:59.442689 140613218989888 submission_runner.py:376] Time since start: 6447.77s, 	Step: 18195, 	{'train/accuracy': 0.6247608065605164, 'train/loss': 1.8786145448684692, 'validation/accuracy': 0.5376799702644348, 'validation/loss': 2.266126871109009, 'validation/num_examples': 50000, 'test/accuracy': 0.42260003089904785, 'test/loss': 2.922790050506592, 'test/num_examples': 10000, 'score': 6185.04268860817, 'total_duration': 6447.771356105804, 'accumulated_submission_time': 6185.04268860817, 'accumulated_eval_time': 262.06218433380127, 'accumulated_logging_time': 0.37500429153442383}
I0921 02:07:59.463916 140447015995136 logging_writer.py:48] [18195] accumulated_eval_time=262.062184, accumulated_logging_time=0.375004, accumulated_submission_time=6185.042689, global_step=18195, preemption_count=0, score=6185.042689, test/accuracy=0.422600, test/loss=2.922790, test/num_examples=10000, total_duration=6447.771356, train/accuracy=0.624761, train/loss=1.878615, validation/accuracy=0.537680, validation/loss=2.266127, validation/num_examples=50000
I0921 02:09:42.470232 140447024387840 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.24451804161071777, loss=3.5526416301727295
I0921 02:12:30.717925 140447015995136 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.2481989562511444, loss=3.587430953979492
I0921 02:15:18.918022 140447024387840 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.2506865859031677, loss=3.596221446990967
I0921 02:16:29.689324 140613218989888 spec.py:320] Evaluating on the training split.
I0921 02:16:36.991729 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 02:16:45.357817 140613218989888 spec.py:348] Evaluating on the test split.
I0921 02:16:47.706606 140613218989888 submission_runner.py:376] Time since start: 6976.04s, 	Step: 19712, 	{'train/accuracy': 0.5977559089660645, 'train/loss': 1.9386297464370728, 'validation/accuracy': 0.5434799790382385, 'validation/loss': 2.188788652420044, 'validation/num_examples': 50000, 'test/accuracy': 0.4252000153064728, 'test/loss': 2.8603928089141846, 'test/num_examples': 10000, 'score': 6695.234313488007, 'total_duration': 6976.035272598267, 'accumulated_submission_time': 6695.234313488007, 'accumulated_eval_time': 280.07943201065063, 'accumulated_logging_time': 0.4057941436767578}
I0921 02:16:47.730466 140447779387136 logging_writer.py:48] [19712] accumulated_eval_time=280.079432, accumulated_logging_time=0.405794, accumulated_submission_time=6695.234313, global_step=19712, preemption_count=0, score=6695.234313, test/accuracy=0.425200, test/loss=2.860393, test/num_examples=10000, total_duration=6976.035273, train/accuracy=0.597756, train/loss=1.938630, validation/accuracy=0.543480, validation/loss=2.188789, validation/num_examples=50000
I0921 02:18:24.782765 140447863248640 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.24682658910751343, loss=3.6224541664123535
I0921 02:21:13.031011 140447779387136 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.2591841220855713, loss=3.624427318572998
I0921 02:24:01.250216 140447863248640 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.25418490171432495, loss=3.5869903564453125
I0921 02:25:18.032541 140613218989888 spec.py:320] Evaluating on the training split.
I0921 02:25:25.593675 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 02:25:34.000665 140613218989888 spec.py:348] Evaluating on the test split.
I0921 02:25:36.314419 140613218989888 submission_runner.py:376] Time since start: 7504.64s, 	Step: 21230, 	{'train/accuracy': 0.6077407598495483, 'train/loss': 1.855846881866455, 'validation/accuracy': 0.5599799752235413, 'validation/loss': 2.086848497390747, 'validation/num_examples': 50000, 'test/accuracy': 0.43540000915527344, 'test/loss': 2.770585536956787, 'test/num_examples': 10000, 'score': 7205.501652479172, 'total_duration': 7504.6430513858795, 'accumulated_submission_time': 7205.501652479172, 'accumulated_eval_time': 298.3612427711487, 'accumulated_logging_time': 0.4401130676269531}
I0921 02:25:36.334583 140447041173248 logging_writer.py:48] [21230] accumulated_eval_time=298.361243, accumulated_logging_time=0.440113, accumulated_submission_time=7205.501652, global_step=21230, preemption_count=0, score=7205.501652, test/accuracy=0.435400, test/loss=2.770586, test/num_examples=10000, total_duration=7504.643051, train/accuracy=0.607741, train/loss=1.855847, validation/accuracy=0.559980, validation/loss=2.086848, validation/num_examples=50000
I0921 02:27:07.576111 140447049565952 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.256495863199234, loss=3.532569169998169
I0921 02:29:55.808378 140447041173248 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.24122141301631927, loss=3.5524044036865234
I0921 02:32:43.995138 140447049565952 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.25316184759140015, loss=3.6180198192596436
I0921 02:34:06.546397 140613218989888 spec.py:320] Evaluating on the training split.
I0921 02:34:13.939955 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 02:34:22.718519 140613218989888 spec.py:348] Evaluating on the test split.
I0921 02:34:25.044336 140613218989888 submission_runner.py:376] Time since start: 8033.37s, 	Step: 22747, 	{'train/accuracy': 0.6139987111091614, 'train/loss': 1.8695482015609741, 'validation/accuracy': 0.5684399604797363, 'validation/loss': 2.0831968784332275, 'validation/num_examples': 50000, 'test/accuracy': 0.44530001282691956, 'test/loss': 2.759314775466919, 'test/num_examples': 10000, 'score': 7715.679613113403, 'total_duration': 8033.372991323471, 'accumulated_submission_time': 7715.679613113403, 'accumulated_eval_time': 316.85913920402527, 'accumulated_logging_time': 0.4701504707336426}
I0921 02:34:25.065743 140447015995136 logging_writer.py:48] [22747] accumulated_eval_time=316.859139, accumulated_logging_time=0.470150, accumulated_submission_time=7715.679613, global_step=22747, preemption_count=0, score=7715.679613, test/accuracy=0.445300, test/loss=2.759315, test/num_examples=10000, total_duration=8033.372991, train/accuracy=0.613999, train/loss=1.869548, validation/accuracy=0.568440, validation/loss=2.083197, validation/num_examples=50000
I0921 02:35:50.567719 140447024387840 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.2510257959365845, loss=3.5873568058013916
I0921 02:38:38.770678 140447015995136 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.2566208839416504, loss=3.5669844150543213
I0921 02:41:27.053056 140447024387840 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.2549512982368469, loss=3.559889793395996
I0921 02:42:55.264502 140613218989888 spec.py:320] Evaluating on the training split.
I0921 02:43:02.675987 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 02:43:11.947868 140613218989888 spec.py:348] Evaluating on the test split.
I0921 02:43:14.245646 140613218989888 submission_runner.py:376] Time since start: 8562.57s, 	Step: 24264, 	{'train/accuracy': 0.6081792116165161, 'train/loss': 1.874230146408081, 'validation/accuracy': 0.5652199983596802, 'validation/loss': 2.0674972534179688, 'validation/num_examples': 50000, 'test/accuracy': 0.4410000145435333, 'test/loss': 2.752103567123413, 'test/num_examples': 10000, 'score': 8225.844413280487, 'total_duration': 8562.574270963669, 'accumulated_submission_time': 8225.844413280487, 'accumulated_eval_time': 335.8402123451233, 'accumulated_logging_time': 0.5013852119445801}
I0921 02:43:14.274154 140447779387136 logging_writer.py:48] [24264] accumulated_eval_time=335.840212, accumulated_logging_time=0.501385, accumulated_submission_time=8225.844413, global_step=24264, preemption_count=0, score=8225.844413, test/accuracy=0.441000, test/loss=2.752104, test/num_examples=10000, total_duration=8562.574271, train/accuracy=0.608179, train/loss=1.874230, validation/accuracy=0.565220, validation/loss=2.067497, validation/num_examples=50000
I0921 02:44:33.988071 140447863248640 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.2518448829650879, loss=3.5719375610351562
I0921 02:47:22.239974 140447779387136 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.2529640793800354, loss=3.6013526916503906
I0921 02:50:10.429875 140447863248640 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.25942525267601013, loss=3.565854549407959
I0921 02:51:44.382581 140613218989888 spec.py:320] Evaluating on the training split.
I0921 02:51:52.069531 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 02:52:01.834412 140613218989888 spec.py:348] Evaluating on the test split.
I0921 02:52:04.171637 140613218989888 submission_runner.py:376] Time since start: 9092.50s, 	Step: 25781, 	{'train/accuracy': 0.6123445630073547, 'train/loss': 1.9537458419799805, 'validation/accuracy': 0.5752599835395813, 'validation/loss': 2.1266887187957764, 'validation/num_examples': 50000, 'test/accuracy': 0.4538000226020813, 'test/loss': 2.7576181888580322, 'test/num_examples': 10000, 'score': 8735.915976524353, 'total_duration': 9092.500293016434, 'accumulated_submission_time': 8735.915976524353, 'accumulated_eval_time': 355.6292459964752, 'accumulated_logging_time': 0.5426211357116699}
I0921 02:52:04.192681 140446172940032 logging_writer.py:48] [25781] accumulated_eval_time=355.629246, accumulated_logging_time=0.542621, accumulated_submission_time=8735.915977, global_step=25781, preemption_count=0, score=8735.915977, test/accuracy=0.453800, test/loss=2.757618, test/num_examples=10000, total_duration=9092.500293, train/accuracy=0.612345, train/loss=1.953746, validation/accuracy=0.575260, validation/loss=2.126689, validation/num_examples=50000
I0921 02:53:18.236688 140447015995136 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.25302135944366455, loss=3.4216156005859375
I0921 02:56:06.517173 140446172940032 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.26071223616600037, loss=3.609100818634033
I0921 02:58:54.732280 140447015995136 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.25446823239326477, loss=3.5250332355499268
I0921 03:00:34.412553 140613218989888 spec.py:320] Evaluating on the training split.
I0921 03:00:42.656034 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 03:00:51.899640 140613218989888 spec.py:348] Evaluating on the test split.
I0921 03:00:54.273888 140613218989888 submission_runner.py:376] Time since start: 9622.60s, 	Step: 27298, 	{'train/accuracy': 0.6115074753761292, 'train/loss': 1.9302557706832886, 'validation/accuracy': 0.5424000024795532, 'validation/loss': 2.234837532043457, 'validation/num_examples': 50000, 'test/accuracy': 0.42350003123283386, 'test/loss': 2.889622449874878, 'test/num_examples': 10000, 'score': 9246.095047950745, 'total_duration': 9622.60255765915, 'accumulated_submission_time': 9246.095047950745, 'accumulated_eval_time': 375.49055767059326, 'accumulated_logging_time': 0.580510139465332}
I0921 03:00:54.297256 140446156154624 logging_writer.py:48] [27298] accumulated_eval_time=375.490558, accumulated_logging_time=0.580510, accumulated_submission_time=9246.095048, global_step=27298, preemption_count=0, score=9246.095048, test/accuracy=0.423500, test/loss=2.889622, test/num_examples=10000, total_duration=9622.602558, train/accuracy=0.611507, train/loss=1.930256, validation/accuracy=0.542400, validation/loss=2.234838, validation/num_examples=50000
I0921 03:02:02.533462 140446164547328 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.25627413392066956, loss=3.545409679412842
I0921 03:04:50.766978 140446156154624 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.25784832239151, loss=3.468512535095215
I0921 03:07:38.929777 140446164547328 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.2584353983402252, loss=3.598162889480591
I0921 03:09:24.369995 140613218989888 spec.py:320] Evaluating on the training split.
I0921 03:09:32.775738 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 03:09:41.923140 140613218989888 spec.py:348] Evaluating on the test split.
I0921 03:09:44.276199 140613218989888 submission_runner.py:376] Time since start: 10152.60s, 	Step: 28815, 	{'train/accuracy': 0.6237643361091614, 'train/loss': 1.7441202402114868, 'validation/accuracy': 0.5724200010299683, 'validation/loss': 2.0058789253234863, 'validation/num_examples': 50000, 'test/accuracy': 0.451200008392334, 'test/loss': 2.706669330596924, 'test/num_examples': 10000, 'score': 9756.131294965744, 'total_duration': 10152.604863405228, 'accumulated_submission_time': 9756.131294965744, 'accumulated_eval_time': 395.3967297077179, 'accumulated_logging_time': 0.6164669990539551}
I0921 03:09:44.299115 140446172940032 logging_writer.py:48] [28815] accumulated_eval_time=395.396730, accumulated_logging_time=0.616467, accumulated_submission_time=9756.131295, global_step=28815, preemption_count=0, score=9756.131295, test/accuracy=0.451200, test/loss=2.706669, test/num_examples=10000, total_duration=10152.604863, train/accuracy=0.623764, train/loss=1.744120, validation/accuracy=0.572420, validation/loss=2.005879, validation/num_examples=50000
I0921 03:10:46.795971 140446235883264 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.26336729526519775, loss=3.5657148361206055
I0921 03:13:34.998556 140446172940032 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.2535018026828766, loss=3.543797254562378
I0921 03:16:23.208297 140446235883264 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.2551552951335907, loss=3.498737335205078
I0921 03:18:14.611014 140613218989888 spec.py:320] Evaluating on the training split.
I0921 03:18:23.059371 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 03:18:32.738929 140613218989888 spec.py:348] Evaluating on the test split.
I0921 03:18:35.039256 140613218989888 submission_runner.py:376] Time since start: 10683.37s, 	Step: 30333, 	{'train/accuracy': 0.6113081574440002, 'train/loss': 1.8609651327133179, 'validation/accuracy': 0.5625999569892883, 'validation/loss': 2.10093092918396, 'validation/num_examples': 50000, 'test/accuracy': 0.4407000243663788, 'test/loss': 2.759889841079712, 'test/num_examples': 10000, 'score': 10266.407609701157, 'total_duration': 10683.367906332016, 'accumulated_submission_time': 10266.407609701157, 'accumulated_eval_time': 415.82493329048157, 'accumulated_logging_time': 0.6509401798248291}
I0921 03:18:35.063984 140446164547328 logging_writer.py:48] [30333] accumulated_eval_time=415.824933, accumulated_logging_time=0.650940, accumulated_submission_time=10266.407610, global_step=30333, preemption_count=0, score=10266.407610, test/accuracy=0.440700, test/loss=2.759890, test/num_examples=10000, total_duration=10683.367906, train/accuracy=0.611308, train/loss=1.860965, validation/accuracy=0.562600, validation/loss=2.100931, validation/num_examples=50000
I0921 03:19:31.456906 140446172940032 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.24881777167320251, loss=3.4470808506011963
I0921 03:22:19.632178 140446164547328 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.2629178762435913, loss=3.5084547996520996
I0921 03:25:07.878744 140446172940032 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.2572888731956482, loss=3.4721903800964355
I0921 03:27:05.367255 140613218989888 spec.py:320] Evaluating on the training split.
I0921 03:27:13.485548 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 03:27:24.375568 140613218989888 spec.py:348] Evaluating on the test split.
I0921 03:27:26.708881 140613218989888 submission_runner.py:376] Time since start: 11215.04s, 	Step: 31851, 	{'train/accuracy': 0.6287069320678711, 'train/loss': 1.7984288930892944, 'validation/accuracy': 0.5835599899291992, 'validation/loss': 2.004408359527588, 'validation/num_examples': 50000, 'test/accuracy': 0.4619000256061554, 'test/loss': 2.658885955810547, 'test/num_examples': 10000, 'score': 10776.673121452332, 'total_duration': 11215.037534236908, 'accumulated_submission_time': 10776.673121452332, 'accumulated_eval_time': 437.1665277481079, 'accumulated_logging_time': 0.6895773410797119}
I0921 03:27:26.731076 140446172940032 logging_writer.py:48] [31851] accumulated_eval_time=437.166528, accumulated_logging_time=0.689577, accumulated_submission_time=10776.673121, global_step=31851, preemption_count=0, score=10776.673121, test/accuracy=0.461900, test/loss=2.658886, test/num_examples=10000, total_duration=11215.037534, train/accuracy=0.628707, train/loss=1.798429, validation/accuracy=0.583560, validation/loss=2.004408, validation/num_examples=50000
I0921 03:28:17.212290 140446999209728 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.26164519786834717, loss=3.4416959285736084
I0921 03:31:05.393659 140446172940032 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.2524358332157135, loss=3.531680107116699
I0921 03:33:53.691964 140446999209728 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.26137620210647583, loss=3.4998488426208496
I0921 03:35:56.909530 140613218989888 spec.py:320] Evaluating on the training split.
I0921 03:36:05.048379 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 03:36:16.014722 140613218989888 spec.py:348] Evaluating on the test split.
I0921 03:36:18.366879 140613218989888 submission_runner.py:376] Time since start: 11746.70s, 	Step: 33368, 	{'train/accuracy': 0.6348652839660645, 'train/loss': 1.734724521636963, 'validation/accuracy': 0.5921399593353271, 'validation/loss': 1.9456363916397095, 'validation/num_examples': 50000, 'test/accuracy': 0.467600017786026, 'test/loss': 2.6168863773345947, 'test/num_examples': 10000, 'score': 11286.81523323059, 'total_duration': 11746.69552898407, 'accumulated_submission_time': 11286.81523323059, 'accumulated_eval_time': 458.6238343715668, 'accumulated_logging_time': 0.7243063449859619}
I0921 03:36:18.390976 140446235883264 logging_writer.py:48] [33368] accumulated_eval_time=458.623834, accumulated_logging_time=0.724306, accumulated_submission_time=11286.815233, global_step=33368, preemption_count=0, score=11286.815233, test/accuracy=0.467600, test/loss=2.616886, test/num_examples=10000, total_duration=11746.695529, train/accuracy=0.634865, train/loss=1.734725, validation/accuracy=0.592140, validation/loss=1.945636, validation/num_examples=50000
I0921 03:37:03.137525 140446990817024 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.25260141491889954, loss=3.4956870079040527
I0921 03:39:51.386585 140446235883264 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.26410698890686035, loss=3.5480058193206787
I0921 03:42:39.615689 140446990817024 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.26054060459136963, loss=3.4449305534362793
I0921 03:44:48.546613 140613218989888 spec.py:320] Evaluating on the training split.
I0921 03:44:56.858464 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 03:45:07.521529 140613218989888 spec.py:348] Evaluating on the test split.
I0921 03:45:09.816840 140613218989888 submission_runner.py:376] Time since start: 12278.15s, 	Step: 34885, 	{'train/accuracy': 0.6336296200752258, 'train/loss': 1.7741262912750244, 'validation/accuracy': 0.5887399911880493, 'validation/loss': 1.9872188568115234, 'validation/num_examples': 50000, 'test/accuracy': 0.4678000211715698, 'test/loss': 2.6356329917907715, 'test/num_examples': 10000, 'score': 11796.935238361359, 'total_duration': 12278.145491838455, 'accumulated_submission_time': 11796.935238361359, 'accumulated_eval_time': 479.8940281867981, 'accumulated_logging_time': 0.7600452899932861}
I0921 03:45:09.839940 140446164547328 logging_writer.py:48] [34885] accumulated_eval_time=479.894028, accumulated_logging_time=0.760045, accumulated_submission_time=11796.935238, global_step=34885, preemption_count=0, score=11796.935238, test/accuracy=0.467800, test/loss=2.635633, test/num_examples=10000, total_duration=12278.145492, train/accuracy=0.633630, train/loss=1.774126, validation/accuracy=0.588740, validation/loss=1.987219, validation/num_examples=50000
I0921 03:45:48.831445 140446172940032 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.2650487720966339, loss=3.503054618835449
I0921 03:48:36.996094 140446164547328 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.27145132422447205, loss=3.4929068088531494
I0921 03:51:25.227833 140446172940032 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.26860958337783813, loss=3.4793612957000732
I0921 03:53:39.897036 140613218989888 spec.py:320] Evaluating on the training split.
I0921 03:53:48.312742 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 03:53:59.646556 140613218989888 spec.py:348] Evaluating on the test split.
I0921 03:54:01.997812 140613218989888 submission_runner.py:376] Time since start: 12810.33s, 	Step: 36402, 	{'train/accuracy': 0.626395046710968, 'train/loss': 1.8138104677200317, 'validation/accuracy': 0.5559599995613098, 'validation/loss': 2.1397645473480225, 'validation/num_examples': 50000, 'test/accuracy': 0.4309000074863434, 'test/loss': 2.829883337020874, 'test/num_examples': 10000, 'score': 12306.953290224075, 'total_duration': 12810.326432228088, 'accumulated_submission_time': 12306.953290224075, 'accumulated_eval_time': 501.99473237991333, 'accumulated_logging_time': 0.798119068145752}
I0921 03:54:02.024839 140447007602432 logging_writer.py:48] [36402] accumulated_eval_time=501.994732, accumulated_logging_time=0.798119, accumulated_submission_time=12306.953290, global_step=36402, preemption_count=0, score=12306.953290, test/accuracy=0.430900, test/loss=2.829883, test/num_examples=10000, total_duration=12810.326432, train/accuracy=0.626395, train/loss=1.813810, validation/accuracy=0.555960, validation/loss=2.139765, validation/num_examples=50000
I0921 03:54:35.256846 140447015995136 logging_writer.py:48] [36500] global_step=36500, grad_norm=0.25962033867836, loss=3.4080138206481934
I0921 03:57:23.499152 140447007602432 logging_writer.py:48] [37000] global_step=37000, grad_norm=0.25501933693885803, loss=3.4367384910583496
I0921 04:00:11.727494 140447015995136 logging_writer.py:48] [37500] global_step=37500, grad_norm=0.26930350065231323, loss=3.4481050968170166
I0921 04:02:32.117751 140613218989888 spec.py:320] Evaluating on the training split.
I0921 04:02:39.925334 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 04:02:50.616281 140613218989888 spec.py:348] Evaluating on the test split.
I0921 04:02:52.970042 140613218989888 submission_runner.py:376] Time since start: 13341.30s, 	Step: 37919, 	{'train/accuracy': 0.6433154940605164, 'train/loss': 1.6928578615188599, 'validation/accuracy': 0.5925999879837036, 'validation/loss': 1.9268696308135986, 'validation/num_examples': 50000, 'test/accuracy': 0.46950003504753113, 'test/loss': 2.6046764850616455, 'test/num_examples': 10000, 'score': 12817.005209684372, 'total_duration': 13341.298707485199, 'accumulated_submission_time': 12817.005209684372, 'accumulated_eval_time': 522.8470289707184, 'accumulated_logging_time': 0.8420491218566895}
I0921 04:02:52.996940 140446164547328 logging_writer.py:48] [37919] accumulated_eval_time=522.847029, accumulated_logging_time=0.842049, accumulated_submission_time=12817.005210, global_step=37919, preemption_count=0, score=12817.005210, test/accuracy=0.469500, test/loss=2.604676, test/num_examples=10000, total_duration=13341.298707, train/accuracy=0.643315, train/loss=1.692858, validation/accuracy=0.592600, validation/loss=1.926870, validation/num_examples=50000
I0921 04:03:20.588320 140446172940032 logging_writer.py:48] [38000] global_step=38000, grad_norm=0.2725718915462494, loss=3.496595621109009
I0921 04:06:08.779010 140446164547328 logging_writer.py:48] [38500] global_step=38500, grad_norm=0.26926445960998535, loss=3.4659976959228516
I0921 04:08:56.984247 140446172940032 logging_writer.py:48] [39000] global_step=39000, grad_norm=0.2639209032058716, loss=3.3988025188446045
I0921 04:11:23.097336 140613218989888 spec.py:320] Evaluating on the training split.
I0921 04:11:30.908039 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 04:11:41.612260 140613218989888 spec.py:348] Evaluating on the test split.
I0921 04:11:43.982722 140613218989888 submission_runner.py:376] Time since start: 13872.31s, 	Step: 39436, 	{'train/accuracy': 0.6396284699440002, 'train/loss': 1.716475009918213, 'validation/accuracy': 0.5875799655914307, 'validation/loss': 1.9562627077102661, 'validation/num_examples': 50000, 'test/accuracy': 0.4643000364303589, 'test/loss': 2.620577573776245, 'test/num_examples': 10000, 'score': 13327.070336341858, 'total_duration': 13872.311385631561, 'accumulated_submission_time': 13327.070336341858, 'accumulated_eval_time': 543.7323985099792, 'accumulated_logging_time': 0.880258321762085}
I0921 04:11:44.005907 140447007602432 logging_writer.py:48] [39436] accumulated_eval_time=543.732399, accumulated_logging_time=0.880258, accumulated_submission_time=13327.070336, global_step=39436, preemption_count=0, score=13327.070336, test/accuracy=0.464300, test/loss=2.620578, test/num_examples=10000, total_duration=13872.311386, train/accuracy=0.639628, train/loss=1.716475, validation/accuracy=0.587580, validation/loss=1.956263, validation/num_examples=50000
I0921 04:12:05.838758 140447015995136 logging_writer.py:48] [39500] global_step=39500, grad_norm=0.27740058302879333, loss=3.5073463916778564
I0921 04:14:54.035757 140447007602432 logging_writer.py:48] [40000] global_step=40000, grad_norm=0.2610066533088684, loss=3.4112541675567627
I0921 04:17:42.244771 140447015995136 logging_writer.py:48] [40500] global_step=40500, grad_norm=0.2668895721435547, loss=3.5139267444610596
I0921 04:20:14.027777 140613218989888 spec.py:320] Evaluating on the training split.
I0921 04:20:21.809153 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 04:20:32.422441 140613218989888 spec.py:348] Evaluating on the test split.
I0921 04:20:34.768039 140613218989888 submission_runner.py:376] Time since start: 14403.10s, 	Step: 40953, 	{'train/accuracy': 0.6538384556770325, 'train/loss': 1.6342676877975464, 'validation/accuracy': 0.60725998878479, 'validation/loss': 1.849616527557373, 'validation/num_examples': 50000, 'test/accuracy': 0.4861000180244446, 'test/loss': 2.4979519844055176, 'test/num_examples': 10000, 'score': 13837.057256937027, 'total_duration': 14403.096657276154, 'accumulated_submission_time': 13837.057256937027, 'accumulated_eval_time': 564.4725894927979, 'accumulated_logging_time': 0.9146661758422852}
I0921 04:20:34.791298 140445296359168 logging_writer.py:48] [40953] accumulated_eval_time=564.472589, accumulated_logging_time=0.914666, accumulated_submission_time=13837.057257, global_step=40953, preemption_count=0, score=13837.057257, test/accuracy=0.486100, test/loss=2.497952, test/num_examples=10000, total_duration=14403.096657, train/accuracy=0.653838, train/loss=1.634268, validation/accuracy=0.607260, validation/loss=1.849617, validation/num_examples=50000
I0921 04:20:50.897495 140446164547328 logging_writer.py:48] [41000] global_step=41000, grad_norm=0.2816266417503357, loss=3.459035873413086
I0921 04:23:39.027611 140445296359168 logging_writer.py:48] [41500] global_step=41500, grad_norm=0.2581859827041626, loss=3.3764171600341797
I0921 04:26:27.271572 140446164547328 logging_writer.py:48] [42000] global_step=42000, grad_norm=0.2640301585197449, loss=3.364698886871338
I0921 04:29:04.800788 140613218989888 spec.py:320] Evaluating on the training split.
I0921 04:29:12.557384 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 04:29:23.429107 140613218989888 spec.py:348] Evaluating on the test split.
I0921 04:29:25.786012 140613218989888 submission_runner.py:376] Time since start: 14934.11s, 	Step: 42470, 	{'train/accuracy': 0.6361008882522583, 'train/loss': 1.7833523750305176, 'validation/accuracy': 0.58815997838974, 'validation/loss': 1.9896317720413208, 'validation/num_examples': 50000, 'test/accuracy': 0.4710000157356262, 'test/loss': 2.617781162261963, 'test/num_examples': 10000, 'score': 14347.031331300735, 'total_duration': 14934.114666461945, 'accumulated_submission_time': 14347.031331300735, 'accumulated_eval_time': 585.4577765464783, 'accumulated_logging_time': 0.9492604732513428}
I0921 04:29:25.808585 140447007602432 logging_writer.py:48] [42470] accumulated_eval_time=585.457777, accumulated_logging_time=0.949260, accumulated_submission_time=14347.031331, global_step=42470, preemption_count=0, score=14347.031331, test/accuracy=0.471000, test/loss=2.617781, test/num_examples=10000, total_duration=14934.114666, train/accuracy=0.636101, train/loss=1.783352, validation/accuracy=0.588160, validation/loss=1.989632, validation/num_examples=50000
I0921 04:29:36.264025 140447015995136 logging_writer.py:48] [42500] global_step=42500, grad_norm=0.2831982672214508, loss=3.3923373222351074
I0921 04:32:24.544844 140447007602432 logging_writer.py:48] [43000] global_step=43000, grad_norm=0.2796322703361511, loss=3.366219997406006
I0921 04:35:12.733362 140447015995136 logging_writer.py:48] [43500] global_step=43500, grad_norm=0.27542412281036377, loss=3.4325199127197266
I0921 04:37:55.985962 140613218989888 spec.py:320] Evaluating on the training split.
I0921 04:38:03.778863 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 04:38:14.475990 140613218989888 spec.py:348] Evaluating on the test split.
I0921 04:38:16.799128 140613218989888 submission_runner.py:376] Time since start: 15465.13s, 	Step: 43987, 	{'train/accuracy': 0.6603754758834839, 'train/loss': 1.683393120765686, 'validation/accuracy': 0.5868399739265442, 'validation/loss': 1.9995726346969604, 'validation/num_examples': 50000, 'test/accuracy': 0.4644000232219696, 'test/loss': 2.663170337677002, 'test/num_examples': 10000, 'score': 14857.173608064651, 'total_duration': 15465.127775907516, 'accumulated_submission_time': 14857.173608064651, 'accumulated_eval_time': 606.2709102630615, 'accumulated_logging_time': 0.9829974174499512}
I0921 04:38:16.824100 140446164547328 logging_writer.py:48] [43987] accumulated_eval_time=606.270910, accumulated_logging_time=0.982997, accumulated_submission_time=14857.173608, global_step=43987, preemption_count=0, score=14857.173608, test/accuracy=0.464400, test/loss=2.663170, test/num_examples=10000, total_duration=15465.127776, train/accuracy=0.660375, train/loss=1.683393, validation/accuracy=0.586840, validation/loss=1.999573, validation/num_examples=50000
I0921 04:38:21.563185 140446172940032 logging_writer.py:48] [44000] global_step=44000, grad_norm=0.27409183979034424, loss=3.4121816158294678
I0921 04:41:09.838575 140446164547328 logging_writer.py:48] [44500] global_step=44500, grad_norm=0.28121086955070496, loss=3.455754280090332
I0921 04:43:58.050793 140446172940032 logging_writer.py:48] [45000] global_step=45000, grad_norm=0.270701140165329, loss=3.351362705230713
I0921 04:46:46.251924 140446164547328 logging_writer.py:48] [45500] global_step=45500, grad_norm=0.279691219329834, loss=3.4768624305725098
I0921 04:46:47.017276 140613218989888 spec.py:320] Evaluating on the training split.
I0921 04:46:54.852403 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 04:47:05.821036 140613218989888 spec.py:348] Evaluating on the test split.
I0921 04:47:08.157641 140613218989888 submission_runner.py:376] Time since start: 15996.49s, 	Step: 45504, 	{'train/accuracy': 0.6693239808082581, 'train/loss': 1.5423797369003296, 'validation/accuracy': 0.602400004863739, 'validation/loss': 1.847364068031311, 'validation/num_examples': 50000, 'test/accuracy': 0.47930002212524414, 'test/loss': 2.4985201358795166, 'test/num_examples': 10000, 'score': 15367.331311702728, 'total_duration': 15996.48631119728, 'accumulated_submission_time': 15367.331311702728, 'accumulated_eval_time': 627.4112348556519, 'accumulated_logging_time': 1.019683837890625}
I0921 04:47:08.180625 140445296359168 logging_writer.py:48] [45504] accumulated_eval_time=627.411235, accumulated_logging_time=1.019684, accumulated_submission_time=15367.331312, global_step=45504, preemption_count=0, score=15367.331312, test/accuracy=0.479300, test/loss=2.498520, test/num_examples=10000, total_duration=15996.486311, train/accuracy=0.669324, train/loss=1.542380, validation/accuracy=0.602400, validation/loss=1.847364, validation/num_examples=50000
I0921 04:49:55.421217 140446990817024 logging_writer.py:48] [46000] global_step=46000, grad_norm=0.2757216691970825, loss=3.452299118041992
I0921 04:52:43.598672 140445296359168 logging_writer.py:48] [46500] global_step=46500, grad_norm=0.2759018838405609, loss=3.4298534393310547
I0921 04:55:31.764968 140446990817024 logging_writer.py:48] [47000] global_step=47000, grad_norm=0.2694472372531891, loss=3.3451650142669678
I0921 04:55:38.253005 140613218989888 spec.py:320] Evaluating on the training split.
I0921 04:55:45.979211 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 04:55:56.806773 140613218989888 spec.py:348] Evaluating on the test split.
I0921 04:55:59.224821 140613218989888 submission_runner.py:376] Time since start: 16527.55s, 	Step: 47021, 	{'train/accuracy': 0.6635642647743225, 'train/loss': 1.6628048419952393, 'validation/accuracy': 0.6050999760627747, 'validation/loss': 1.9179195165634155, 'validation/num_examples': 50000, 'test/accuracy': 0.48000001907348633, 'test/loss': 2.580186128616333, 'test/num_examples': 10000, 'score': 15877.369775295258, 'total_duration': 16527.553474664688, 'accumulated_submission_time': 15877.369775295258, 'accumulated_eval_time': 648.3829953670502, 'accumulated_logging_time': 1.052889347076416}
I0921 04:55:59.252076 140446172940032 logging_writer.py:48] [47021] accumulated_eval_time=648.382995, accumulated_logging_time=1.052889, accumulated_submission_time=15877.369775, global_step=47021, preemption_count=0, score=15877.369775, test/accuracy=0.480000, test/loss=2.580186, test/num_examples=10000, total_duration=16527.553475, train/accuracy=0.663564, train/loss=1.662805, validation/accuracy=0.605100, validation/loss=1.917920, validation/num_examples=50000
I0921 04:58:40.813332 140446235883264 logging_writer.py:48] [47500] global_step=47500, grad_norm=0.2803840637207031, loss=3.4154212474823
I0921 05:01:29.040706 140446172940032 logging_writer.py:48] [48000] global_step=48000, grad_norm=0.27742621302604675, loss=3.3830552101135254
I0921 05:04:17.243184 140446235883264 logging_writer.py:48] [48500] global_step=48500, grad_norm=0.2750622034072876, loss=3.3872151374816895
I0921 05:04:29.453550 140613218989888 spec.py:320] Evaluating on the training split.
I0921 05:04:37.153259 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 05:04:48.238067 140613218989888 spec.py:348] Evaluating on the test split.
I0921 05:04:50.566950 140613218989888 submission_runner.py:376] Time since start: 17058.90s, 	Step: 48538, 	{'train/accuracy': 0.6535395383834839, 'train/loss': 1.6473050117492676, 'validation/accuracy': 0.6027399897575378, 'validation/loss': 1.8904958963394165, 'validation/num_examples': 50000, 'test/accuracy': 0.48190003633499146, 'test/loss': 2.5572152137756348, 'test/num_examples': 10000, 'score': 16387.537207603455, 'total_duration': 17058.895617485046, 'accumulated_submission_time': 16387.537207603455, 'accumulated_eval_time': 669.4963607788086, 'accumulated_logging_time': 1.0904269218444824}
I0921 05:04:50.590234 140446164547328 logging_writer.py:48] [48538] accumulated_eval_time=669.496361, accumulated_logging_time=1.090427, accumulated_submission_time=16387.537208, global_step=48538, preemption_count=0, score=16387.537208, test/accuracy=0.481900, test/loss=2.557215, test/num_examples=10000, total_duration=17058.895617, train/accuracy=0.653540, train/loss=1.647305, validation/accuracy=0.602740, validation/loss=1.890496, validation/num_examples=50000
I0921 05:07:26.429808 140446172940032 logging_writer.py:48] [49000] global_step=49000, grad_norm=0.265555739402771, loss=3.3919894695281982
I0921 05:10:14.616362 140446164547328 logging_writer.py:48] [49500] global_step=49500, grad_norm=0.26544609665870667, loss=3.3425965309143066
I0921 05:13:02.785994 140446172940032 logging_writer.py:48] [50000] global_step=50000, grad_norm=0.2757532596588135, loss=3.353980302810669
I0921 05:13:20.700974 140613218989888 spec.py:320] Evaluating on the training split.
I0921 05:13:28.397866 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 05:13:39.631180 140613218989888 spec.py:348] Evaluating on the test split.
I0921 05:13:42.042884 140613218989888 submission_runner.py:376] Time since start: 17590.37s, 	Step: 50055, 	{'train/accuracy': 0.6315369606018066, 'train/loss': 1.7543830871582031, 'validation/accuracy': 0.5855000019073486, 'validation/loss': 1.9698681831359863, 'validation/num_examples': 50000, 'test/accuracy': 0.46540001034736633, 'test/loss': 2.6308541297912598, 'test/num_examples': 10000, 'score': 16897.61312365532, 'total_duration': 17590.371537685394, 'accumulated_submission_time': 16897.61312365532, 'accumulated_eval_time': 690.8382194042206, 'accumulated_logging_time': 1.1248712539672852}
I0921 05:13:42.066548 140446999209728 logging_writer.py:48] [50055] accumulated_eval_time=690.838219, accumulated_logging_time=1.124871, accumulated_submission_time=16897.613124, global_step=50055, preemption_count=0, score=16897.613124, test/accuracy=0.465400, test/loss=2.630854, test/num_examples=10000, total_duration=17590.371538, train/accuracy=0.631537, train/loss=1.754383, validation/accuracy=0.585500, validation/loss=1.969868, validation/num_examples=50000
I0921 05:16:12.833392 140447007602432 logging_writer.py:48] [50500] global_step=50500, grad_norm=0.28035011887550354, loss=3.3730878829956055
I0921 05:19:01.090641 140446999209728 logging_writer.py:48] [51000] global_step=51000, grad_norm=0.2782667279243469, loss=3.3737239837646484
I0921 05:21:49.321046 140447007602432 logging_writer.py:48] [51500] global_step=51500, grad_norm=0.2745909094810486, loss=3.4009077548980713
I0921 05:22:12.276165 140613218989888 spec.py:320] Evaluating on the training split.
I0921 05:22:19.958303 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 05:22:31.096951 140613218989888 spec.py:348] Evaluating on the test split.
I0921 05:22:33.437849 140613218989888 submission_runner.py:376] Time since start: 18121.77s, 	Step: 51570, 	{'train/accuracy': 0.6583824753761292, 'train/loss': 1.6394034624099731, 'validation/accuracy': 0.612500011920929, 'validation/loss': 1.8568693399429321, 'validation/num_examples': 50000, 'test/accuracy': 0.4863000214099884, 'test/loss': 2.5079689025878906, 'test/num_examples': 10000, 'score': 17407.788469791412, 'total_duration': 18121.76651597023, 'accumulated_submission_time': 17407.788469791412, 'accumulated_eval_time': 711.9998610019684, 'accumulated_logging_time': 1.1591193675994873}
I0921 05:22:33.460363 140446164547328 logging_writer.py:48] [51570] accumulated_eval_time=711.999861, accumulated_logging_time=1.159119, accumulated_submission_time=17407.788470, global_step=51570, preemption_count=0, score=17407.788470, test/accuracy=0.486300, test/loss=2.507969, test/num_examples=10000, total_duration=18121.766516, train/accuracy=0.658382, train/loss=1.639403, validation/accuracy=0.612500, validation/loss=1.856869, validation/num_examples=50000
I0921 05:24:58.544108 140446172940032 logging_writer.py:48] [52000] global_step=52000, grad_norm=0.28585389256477356, loss=3.4247636795043945
I0921 05:27:46.728706 140446164547328 logging_writer.py:48] [52500] global_step=52500, grad_norm=0.27921003103256226, loss=3.346771717071533
I0921 05:30:34.972976 140446172940032 logging_writer.py:48] [53000] global_step=53000, grad_norm=0.27579590678215027, loss=3.346510410308838
I0921 05:31:03.669055 140613218989888 spec.py:320] Evaluating on the training split.
I0921 05:31:11.380328 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 05:31:22.337344 140613218989888 spec.py:348] Evaluating on the test split.
I0921 05:31:24.625773 140613218989888 submission_runner.py:376] Time since start: 18652.95s, 	Step: 53087, 	{'train/accuracy': 0.6985012888908386, 'train/loss': 1.4924120903015137, 'validation/accuracy': 0.6067799925804138, 'validation/loss': 1.900179147720337, 'validation/num_examples': 50000, 'test/accuracy': 0.47860002517700195, 'test/loss': 2.5549025535583496, 'test/num_examples': 10000, 'score': 17917.96275138855, 'total_duration': 18652.954436063766, 'accumulated_submission_time': 17917.96275138855, 'accumulated_eval_time': 732.9565396308899, 'accumulated_logging_time': 1.1921696662902832}
I0921 05:31:24.647572 140446999209728 logging_writer.py:48] [53087] accumulated_eval_time=732.956540, accumulated_logging_time=1.192170, accumulated_submission_time=17917.962751, global_step=53087, preemption_count=0, score=17917.962751, test/accuracy=0.478600, test/loss=2.554903, test/num_examples=10000, total_duration=18652.954436, train/accuracy=0.698501, train/loss=1.492412, validation/accuracy=0.606780, validation/loss=1.900179, validation/num_examples=50000
I0921 05:33:43.991871 140447007602432 logging_writer.py:48] [53500] global_step=53500, grad_norm=0.2890051007270813, loss=3.372877836227417
I0921 05:36:32.252555 140446999209728 logging_writer.py:48] [54000] global_step=54000, grad_norm=0.28226855397224426, loss=3.317448377609253
I0921 05:39:20.487738 140447007602432 logging_writer.py:48] [54500] global_step=54500, grad_norm=0.27954402565956116, loss=3.41664981842041
I0921 05:39:54.911549 140613218989888 spec.py:320] Evaluating on the training split.
I0921 05:40:02.577513 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 05:40:13.716264 140613218989888 spec.py:348] Evaluating on the test split.
I0921 05:40:16.037556 140613218989888 submission_runner.py:376] Time since start: 19184.37s, 	Step: 54604, 	{'train/accuracy': 0.6769570708274841, 'train/loss': 1.5328868627548218, 'validation/accuracy': 0.6092000007629395, 'validation/loss': 1.8308618068695068, 'validation/num_examples': 50000, 'test/accuracy': 0.4880000352859497, 'test/loss': 2.482255697250366, 'test/num_examples': 10000, 'score': 18428.192138671875, 'total_duration': 19184.366216659546, 'accumulated_submission_time': 18428.192138671875, 'accumulated_eval_time': 754.0825002193451, 'accumulated_logging_time': 1.2245855331420898}
I0921 05:40:16.060981 140446164547328 logging_writer.py:48] [54604] accumulated_eval_time=754.082500, accumulated_logging_time=1.224586, accumulated_submission_time=18428.192139, global_step=54604, preemption_count=0, score=18428.192139, test/accuracy=0.488000, test/loss=2.482256, test/num_examples=10000, total_duration=19184.366217, train/accuracy=0.676957, train/loss=1.532887, validation/accuracy=0.609200, validation/loss=1.830862, validation/num_examples=50000
I0921 05:42:29.699049 140446172940032 logging_writer.py:48] [55000] global_step=55000, grad_norm=0.2783483862876892, loss=3.347151517868042
I0921 05:45:17.878122 140446164547328 logging_writer.py:48] [55500] global_step=55500, grad_norm=0.2840574383735657, loss=3.3021340370178223
I0921 05:48:06.079110 140446172940032 logging_writer.py:48] [56000] global_step=56000, grad_norm=0.2819906175136566, loss=3.327214002609253
I0921 05:48:46.200410 140613218989888 spec.py:320] Evaluating on the training split.
I0921 05:48:53.947111 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 05:49:04.816114 140613218989888 spec.py:348] Evaluating on the test split.
I0921 05:49:07.239929 140613218989888 submission_runner.py:376] Time since start: 19715.57s, 	Step: 56121, 	{'train/accuracy': 0.6670519709587097, 'train/loss': 1.6260281801223755, 'validation/accuracy': 0.6095600128173828, 'validation/loss': 1.8815218210220337, 'validation/num_examples': 50000, 'test/accuracy': 0.49010002613067627, 'test/loss': 2.5206735134124756, 'test/num_examples': 10000, 'score': 18938.29710006714, 'total_duration': 19715.568593502045, 'accumulated_submission_time': 18938.29710006714, 'accumulated_eval_time': 775.1219809055328, 'accumulated_logging_time': 1.2585887908935547}
I0921 05:49:07.264626 140447007602432 logging_writer.py:48] [56121] accumulated_eval_time=775.121981, accumulated_logging_time=1.258589, accumulated_submission_time=18938.297100, global_step=56121, preemption_count=0, score=18938.297100, test/accuracy=0.490100, test/loss=2.520674, test/num_examples=10000, total_duration=19715.568594, train/accuracy=0.667052, train/loss=1.626028, validation/accuracy=0.609560, validation/loss=1.881522, validation/num_examples=50000
I0921 05:51:15.090614 140447015995136 logging_writer.py:48] [56500] global_step=56500, grad_norm=0.2811731994152069, loss=3.3515684604644775
I0921 05:54:03.331718 140447007602432 logging_writer.py:48] [57000] global_step=57000, grad_norm=0.29461637139320374, loss=3.4178149700164795
I0921 05:56:51.564385 140447015995136 logging_writer.py:48] [57500] global_step=57500, grad_norm=0.2912415564060211, loss=3.3654696941375732
I0921 05:57:37.407003 140613218989888 spec.py:320] Evaluating on the training split.
I0921 05:57:44.982372 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 05:57:55.931300 140613218989888 spec.py:348] Evaluating on the test split.
I0921 05:57:58.248207 140613218989888 submission_runner.py:376] Time since start: 20246.58s, 	Step: 57638, 	{'train/accuracy': 0.6732102632522583, 'train/loss': 1.5738229751586914, 'validation/accuracy': 0.6189599633216858, 'validation/loss': 1.8145744800567627, 'validation/num_examples': 50000, 'test/accuracy': 0.49160003662109375, 'test/loss': 2.4750869274139404, 'test/num_examples': 10000, 'score': 19448.404630184174, 'total_duration': 20246.57687520981, 'accumulated_submission_time': 19448.404630184174, 'accumulated_eval_time': 795.9631505012512, 'accumulated_logging_time': 1.2943003177642822}
I0921 05:57:58.275953 140446235883264 logging_writer.py:48] [57638] accumulated_eval_time=795.963151, accumulated_logging_time=1.294300, accumulated_submission_time=19448.404630, global_step=57638, preemption_count=0, score=19448.404630, test/accuracy=0.491600, test/loss=2.475087, test/num_examples=10000, total_duration=20246.576875, train/accuracy=0.673210, train/loss=1.573823, validation/accuracy=0.618960, validation/loss=1.814574, validation/num_examples=50000
I0921 06:00:00.380168 140446990817024 logging_writer.py:48] [58000] global_step=58000, grad_norm=0.28995630145072937, loss=3.3700716495513916
I0921 06:02:48.645628 140446235883264 logging_writer.py:48] [58500] global_step=58500, grad_norm=0.28819283843040466, loss=3.3309102058410645
I0921 06:05:36.850187 140446990817024 logging_writer.py:48] [59000] global_step=59000, grad_norm=0.28479650616645813, loss=3.2958836555480957
I0921 06:06:28.405031 140613218989888 spec.py:320] Evaluating on the training split.
I0921 06:06:36.055622 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 06:06:47.211917 140613218989888 spec.py:348] Evaluating on the test split.
I0921 06:06:49.551775 140613218989888 submission_runner.py:376] Time since start: 20777.88s, 	Step: 59155, 	{'train/accuracy': 0.6637834906578064, 'train/loss': 1.649034857749939, 'validation/accuracy': 0.6145399808883667, 'validation/loss': 1.870615839958191, 'validation/num_examples': 50000, 'test/accuracy': 0.48590001463890076, 'test/loss': 2.557185173034668, 'test/num_examples': 10000, 'score': 19958.498077392578, 'total_duration': 20777.880433559418, 'accumulated_submission_time': 19958.498077392578, 'accumulated_eval_time': 817.1098523139954, 'accumulated_logging_time': 1.3336970806121826}
I0921 06:06:49.574862 140446235883264 logging_writer.py:48] [59155] accumulated_eval_time=817.109852, accumulated_logging_time=1.333697, accumulated_submission_time=19958.498077, global_step=59155, preemption_count=0, score=19958.498077, test/accuracy=0.485900, test/loss=2.557185, test/num_examples=10000, total_duration=20777.880434, train/accuracy=0.663783, train/loss=1.649035, validation/accuracy=0.614540, validation/loss=1.870616, validation/num_examples=50000
I0921 06:08:46.043436 140447015995136 logging_writer.py:48] [59500] global_step=59500, grad_norm=0.2885890305042267, loss=3.2470951080322266
I0921 06:11:34.177875 140446235883264 logging_writer.py:48] [60000] global_step=60000, grad_norm=0.3002873957157135, loss=3.3100972175598145
I0921 06:14:22.440598 140447015995136 logging_writer.py:48] [60500] global_step=60500, grad_norm=0.2885667681694031, loss=3.372809410095215
I0921 06:15:19.746584 140613218989888 spec.py:320] Evaluating on the training split.
I0921 06:15:27.274455 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 06:15:38.217955 140613218989888 spec.py:348] Evaluating on the test split.
I0921 06:15:40.611252 140613218989888 submission_runner.py:376] Time since start: 21308.94s, 	Step: 60672, 	{'train/accuracy': 0.6783123016357422, 'train/loss': 1.5390408039093018, 'validation/accuracy': 0.6280999779701233, 'validation/loss': 1.7732737064361572, 'validation/num_examples': 50000, 'test/accuracy': 0.49480003118515015, 'test/loss': 2.4399282932281494, 'test/num_examples': 10000, 'score': 20468.633964538574, 'total_duration': 21308.93989467621, 'accumulated_submission_time': 20468.633964538574, 'accumulated_eval_time': 837.9744617938995, 'accumulated_logging_time': 1.368260383605957}
I0921 06:15:40.637354 140446990817024 logging_writer.py:48] [60672] accumulated_eval_time=837.974462, accumulated_logging_time=1.368260, accumulated_submission_time=20468.633965, global_step=60672, preemption_count=0, score=20468.633965, test/accuracy=0.494800, test/loss=2.439928, test/num_examples=10000, total_duration=21308.939895, train/accuracy=0.678312, train/loss=1.539041, validation/accuracy=0.628100, validation/loss=1.773274, validation/num_examples=50000
I0921 06:17:31.340826 140446999209728 logging_writer.py:48] [61000] global_step=61000, grad_norm=0.28782394528388977, loss=3.326049566268921
I0921 06:20:19.543298 140446990817024 logging_writer.py:48] [61500] global_step=61500, grad_norm=0.3022942841053009, loss=3.312729835510254
I0921 06:23:07.790120 140446999209728 logging_writer.py:48] [62000] global_step=62000, grad_norm=0.2860648036003113, loss=3.260842800140381
I0921 06:24:10.831698 140613218989888 spec.py:320] Evaluating on the training split.
I0921 06:24:18.338245 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 06:24:29.380640 140613218989888 spec.py:348] Evaluating on the test split.
I0921 06:24:31.728744 140613218989888 submission_runner.py:376] Time since start: 21840.06s, 	Step: 62189, 	{'train/accuracy': 0.7044802308082581, 'train/loss': 1.5039805173873901, 'validation/accuracy': 0.621239960193634, 'validation/loss': 1.8661829233169556, 'validation/num_examples': 50000, 'test/accuracy': 0.49310001730918884, 'test/loss': 2.5342471599578857, 'test/num_examples': 10000, 'score': 20978.793485164642, 'total_duration': 21840.057413101196, 'accumulated_submission_time': 20978.793485164642, 'accumulated_eval_time': 858.8714756965637, 'accumulated_logging_time': 1.4050464630126953}
I0921 06:24:31.752136 140446164547328 logging_writer.py:48] [62189] accumulated_eval_time=858.871476, accumulated_logging_time=1.405046, accumulated_submission_time=20978.793485, global_step=62189, preemption_count=0, score=20978.793485, test/accuracy=0.493100, test/loss=2.534247, test/num_examples=10000, total_duration=21840.057413, train/accuracy=0.704480, train/loss=1.503981, validation/accuracy=0.621240, validation/loss=1.866183, validation/num_examples=50000
I0921 06:26:16.728850 140446172940032 logging_writer.py:48] [62500] global_step=62500, grad_norm=0.28951820731163025, loss=3.337864637374878
I0921 06:29:04.910271 140446164547328 logging_writer.py:48] [63000] global_step=63000, grad_norm=0.29774415493011475, loss=3.3408803939819336
I0921 06:31:53.136713 140446172940032 logging_writer.py:48] [63500] global_step=63500, grad_norm=0.2938619554042816, loss=3.3406717777252197
I0921 06:33:01.855350 140613218989888 spec.py:320] Evaluating on the training split.
I0921 06:33:09.382605 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 06:33:20.511942 140613218989888 spec.py:348] Evaluating on the test split.
I0921 06:33:22.850305 140613218989888 submission_runner.py:376] Time since start: 22371.18s, 	Step: 63706, 	{'train/accuracy': 0.7075693607330322, 'train/loss': 1.3596501350402832, 'validation/accuracy': 0.6421799659729004, 'validation/loss': 1.655147910118103, 'validation/num_examples': 50000, 'test/accuracy': 0.5166000127792358, 'test/loss': 2.3244237899780273, 'test/num_examples': 10000, 'score': 21488.862284183502, 'total_duration': 22371.17894911766, 'accumulated_submission_time': 21488.862284183502, 'accumulated_eval_time': 879.8663790225983, 'accumulated_logging_time': 1.43892240524292}
I0921 06:33:22.877290 140445296359168 logging_writer.py:48] [63706] accumulated_eval_time=879.866379, accumulated_logging_time=1.438922, accumulated_submission_time=21488.862284, global_step=63706, preemption_count=0, score=21488.862284, test/accuracy=0.516600, test/loss=2.324424, test/num_examples=10000, total_duration=22371.178949, train/accuracy=0.707569, train/loss=1.359650, validation/accuracy=0.642180, validation/loss=1.655148, validation/num_examples=50000
I0921 06:35:02.163726 140446164547328 logging_writer.py:48] [64000] global_step=64000, grad_norm=0.30391278862953186, loss=3.2978405952453613
I0921 06:37:50.431350 140445296359168 logging_writer.py:48] [64500] global_step=64500, grad_norm=0.3022354245185852, loss=3.2860958576202393
I0921 06:40:38.585767 140446164547328 logging_writer.py:48] [65000] global_step=65000, grad_norm=0.29313504695892334, loss=3.2968504428863525
I0921 06:41:53.017270 140613218989888 spec.py:320] Evaluating on the training split.
I0921 06:42:00.624356 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 06:42:11.772216 140613218989888 spec.py:348] Evaluating on the test split.
I0921 06:42:14.136307 140613218989888 submission_runner.py:376] Time since start: 22902.46s, 	Step: 65223, 	{'train/accuracy': 0.6975446343421936, 'train/loss': 1.467308759689331, 'validation/accuracy': 0.6388199925422668, 'validation/loss': 1.7396818399429321, 'validation/num_examples': 50000, 'test/accuracy': 0.5074000358581543, 'test/loss': 2.387864112854004, 'test/num_examples': 10000, 'score': 21998.965037345886, 'total_duration': 22902.464923620224, 'accumulated_submission_time': 21998.965037345886, 'accumulated_eval_time': 900.9853439331055, 'accumulated_logging_time': 1.4791550636291504}
I0921 06:42:14.172369 140447015995136 logging_writer.py:48] [65223] accumulated_eval_time=900.985344, accumulated_logging_time=1.479155, accumulated_submission_time=21998.965037, global_step=65223, preemption_count=0, score=21998.965037, test/accuracy=0.507400, test/loss=2.387864, test/num_examples=10000, total_duration=22902.464924, train/accuracy=0.697545, train/loss=1.467309, validation/accuracy=0.638820, validation/loss=1.739682, validation/num_examples=50000
I0921 06:43:47.723803 140447024387840 logging_writer.py:48] [65500] global_step=65500, grad_norm=0.29977720975875854, loss=3.2608728408813477
I0921 06:46:35.963961 140447015995136 logging_writer.py:48] [66000] global_step=66000, grad_norm=0.29978567361831665, loss=3.239881753921509
I0921 06:49:24.191442 140447024387840 logging_writer.py:48] [66500] global_step=66500, grad_norm=0.29908421635627747, loss=3.2750349044799805
I0921 06:50:44.331607 140613218989888 spec.py:320] Evaluating on the training split.
I0921 06:50:51.880987 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 06:51:02.999997 140613218989888 spec.py:348] Evaluating on the test split.
I0921 06:51:05.330594 140613218989888 submission_runner.py:376] Time since start: 23433.66s, 	Step: 66740, 	{'train/accuracy': 0.6934191584587097, 'train/loss': 1.4384207725524902, 'validation/accuracy': 0.6387999653816223, 'validation/loss': 1.6868369579315186, 'validation/num_examples': 50000, 'test/accuracy': 0.5131000280380249, 'test/loss': 2.3482666015625, 'test/num_examples': 10000, 'score': 22509.085248470306, 'total_duration': 23433.65925884247, 'accumulated_submission_time': 22509.085248470306, 'accumulated_eval_time': 921.984296798706, 'accumulated_logging_time': 1.5302343368530273}
I0921 06:51:05.355323 140446990817024 logging_writer.py:48] [66740] accumulated_eval_time=921.984297, accumulated_logging_time=1.530234, accumulated_submission_time=22509.085248, global_step=66740, preemption_count=0, score=22509.085248, test/accuracy=0.513100, test/loss=2.348267, test/num_examples=10000, total_duration=23433.659259, train/accuracy=0.693419, train/loss=1.438421, validation/accuracy=0.638800, validation/loss=1.686837, validation/num_examples=50000
I0921 06:52:33.217015 140447024387840 logging_writer.py:48] [67000] global_step=67000, grad_norm=0.29019370675086975, loss=3.227076530456543
I0921 06:55:21.426472 140446990817024 logging_writer.py:48] [67500] global_step=67500, grad_norm=0.29840388894081116, loss=3.260289192199707
I0921 06:58:09.594270 140447024387840 logging_writer.py:48] [68000] global_step=68000, grad_norm=0.298308789730072, loss=3.3615424633026123
I0921 06:59:35.500152 140613218989888 spec.py:320] Evaluating on the training split.
I0921 06:59:43.037429 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 06:59:54.188831 140613218989888 spec.py:348] Evaluating on the test split.
I0921 06:59:56.579750 140613218989888 submission_runner.py:376] Time since start: 23964.91s, 	Step: 68257, 	{'train/accuracy': 0.70023512840271, 'train/loss': 1.4438289403915405, 'validation/accuracy': 0.6456199884414673, 'validation/loss': 1.679024338722229, 'validation/num_examples': 50000, 'test/accuracy': 0.513200044631958, 'test/loss': 2.3601062297821045, 'test/num_examples': 10000, 'score': 23019.195251703262, 'total_duration': 23964.908405542374, 'accumulated_submission_time': 23019.195251703262, 'accumulated_eval_time': 943.0638625621796, 'accumulated_logging_time': 1.5661993026733398}
I0921 06:59:56.603991 140445296359168 logging_writer.py:48] [68257] accumulated_eval_time=943.063863, accumulated_logging_time=1.566199, accumulated_submission_time=23019.195252, global_step=68257, preemption_count=0, score=23019.195252, test/accuracy=0.513200, test/loss=2.360106, test/num_examples=10000, total_duration=23964.908406, train/accuracy=0.700235, train/loss=1.443829, validation/accuracy=0.645620, validation/loss=1.679024, validation/num_examples=50000
I0921 07:01:18.585032 140446164547328 logging_writer.py:48] [68500] global_step=68500, grad_norm=0.29664862155914307, loss=3.2988085746765137
I0921 07:04:06.835777 140445296359168 logging_writer.py:48] [69000] global_step=69000, grad_norm=0.30303236842155457, loss=3.304629325866699
I0921 07:06:55.046910 140446164547328 logging_writer.py:48] [69500] global_step=69500, grad_norm=0.29908400774002075, loss=3.237154722213745
I0921 07:08:26.657636 140613218989888 spec.py:320] Evaluating on the training split.
I0921 07:08:34.177960 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 07:08:45.244745 140613218989888 spec.py:348] Evaluating on the test split.
I0921 07:08:47.551920 140613218989888 submission_runner.py:376] Time since start: 24495.88s, 	Step: 69774, 	{'train/accuracy': 0.7023277878761292, 'train/loss': 1.4531011581420898, 'validation/accuracy': 0.6444599628448486, 'validation/loss': 1.700484275817871, 'validation/num_examples': 50000, 'test/accuracy': 0.5200999975204468, 'test/loss': 2.3464748859405518, 'test/num_examples': 10000, 'score': 23529.21361875534, 'total_duration': 24495.880565404892, 'accumulated_submission_time': 23529.21361875534, 'accumulated_eval_time': 963.9580943584442, 'accumulated_logging_time': 1.6017961502075195}
I0921 07:08:47.579053 140446164547328 logging_writer.py:48] [69774] accumulated_eval_time=963.958094, accumulated_logging_time=1.601796, accumulated_submission_time=23529.213619, global_step=69774, preemption_count=0, score=23529.213619, test/accuracy=0.520100, test/loss=2.346475, test/num_examples=10000, total_duration=24495.880565, train/accuracy=0.702328, train/loss=1.453101, validation/accuracy=0.644460, validation/loss=1.700484, validation/num_examples=50000
I0921 07:10:03.855802 140446172940032 logging_writer.py:48] [70000] global_step=70000, grad_norm=0.3161986470222473, loss=3.241736650466919
I0921 07:12:52.074629 140446164547328 logging_writer.py:48] [70500] global_step=70500, grad_norm=0.3098622262477875, loss=3.3053581714630127
I0921 07:15:40.312952 140446172940032 logging_writer.py:48] [71000] global_step=71000, grad_norm=0.30896854400634766, loss=3.3104801177978516
I0921 07:17:17.609351 140613218989888 spec.py:320] Evaluating on the training split.
I0921 07:17:25.179093 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 07:17:36.317469 140613218989888 spec.py:348] Evaluating on the test split.
I0921 07:17:38.676195 140613218989888 submission_runner.py:376] Time since start: 25027.00s, 	Step: 71291, 	{'train/accuracy': 0.7182317972183228, 'train/loss': 1.3463919162750244, 'validation/accuracy': 0.6370999813079834, 'validation/loss': 1.7067084312438965, 'validation/num_examples': 50000, 'test/accuracy': 0.510200023651123, 'test/loss': 2.352832794189453, 'test/num_examples': 10000, 'score': 24039.209142446518, 'total_duration': 25027.00485777855, 'accumulated_submission_time': 24039.209142446518, 'accumulated_eval_time': 985.0249061584473, 'accumulated_logging_time': 1.639897346496582}
I0921 07:17:38.700945 140446990817024 logging_writer.py:48] [71291] accumulated_eval_time=985.024906, accumulated_logging_time=1.639897, accumulated_submission_time=24039.209142, global_step=71291, preemption_count=0, score=24039.209142, test/accuracy=0.510200, test/loss=2.352833, test/num_examples=10000, total_duration=25027.004858, train/accuracy=0.718232, train/loss=1.346392, validation/accuracy=0.637100, validation/loss=1.706708, validation/num_examples=50000
I0921 07:18:49.281254 140446999209728 logging_writer.py:48] [71500] global_step=71500, grad_norm=0.3175073266029358, loss=3.2749814987182617
I0921 07:21:37.583526 140446990817024 logging_writer.py:48] [72000] global_step=72000, grad_norm=0.310181587934494, loss=3.267758369445801
I0921 07:24:25.818325 140446999209728 logging_writer.py:48] [72500] global_step=72500, grad_norm=0.31111687421798706, loss=3.1818084716796875
I0921 07:26:08.883806 140613218989888 spec.py:320] Evaluating on the training split.
I0921 07:26:16.369123 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 07:26:27.561810 140613218989888 spec.py:348] Evaluating on the test split.
I0921 07:26:29.884756 140613218989888 submission_runner.py:376] Time since start: 25558.21s, 	Step: 72808, 	{'train/accuracy': 0.6951131820678711, 'train/loss': 1.522586703300476, 'validation/accuracy': 0.6317799687385559, 'validation/loss': 1.8127872943878174, 'validation/num_examples': 50000, 'test/accuracy': 0.5080000162124634, 'test/loss': 2.457387685775757, 'test/num_examples': 10000, 'score': 24549.357794046402, 'total_duration': 25558.21341776848, 'accumulated_submission_time': 24549.357794046402, 'accumulated_eval_time': 1006.0258257389069, 'accumulated_logging_time': 1.675201177597046}
I0921 07:26:29.911746 140446999209728 logging_writer.py:48] [72808] accumulated_eval_time=1006.025826, accumulated_logging_time=1.675201, accumulated_submission_time=24549.357794, global_step=72808, preemption_count=0, score=24549.357794, test/accuracy=0.508000, test/loss=2.457388, test/num_examples=10000, total_duration=25558.213418, train/accuracy=0.695113, train/loss=1.522587, validation/accuracy=0.631780, validation/loss=1.812787, validation/num_examples=50000
I0921 07:27:34.814437 140447007602432 logging_writer.py:48] [73000] global_step=73000, grad_norm=0.30802270770072937, loss=3.219512462615967
I0921 07:30:23.037467 140446999209728 logging_writer.py:48] [73500] global_step=73500, grad_norm=0.31015729904174805, loss=3.2096831798553467
I0921 07:33:11.236968 140447007602432 logging_writer.py:48] [74000] global_step=74000, grad_norm=0.30689364671707153, loss=3.2776408195495605
I0921 07:35:00.001005 140613218989888 spec.py:320] Evaluating on the training split.
I0921 07:35:07.599009 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 07:35:18.727284 140613218989888 spec.py:348] Evaluating on the test split.
I0921 07:35:21.080391 140613218989888 submission_runner.py:376] Time since start: 26089.41s, 	Step: 74325, 	{'train/accuracy': 0.7155811190605164, 'train/loss': 1.414952278137207, 'validation/accuracy': 0.6520599722862244, 'validation/loss': 1.7008613348007202, 'validation/num_examples': 50000, 'test/accuracy': 0.5311000347137451, 'test/loss': 2.307309627532959, 'test/num_examples': 10000, 'score': 25059.411647558212, 'total_duration': 26089.40896821022, 'accumulated_submission_time': 25059.411647558212, 'accumulated_eval_time': 1027.105108499527, 'accumulated_logging_time': 1.7139711380004883}
I0921 07:35:21.105920 140445296359168 logging_writer.py:48] [74325] accumulated_eval_time=1027.105108, accumulated_logging_time=1.713971, accumulated_submission_time=25059.411648, global_step=74325, preemption_count=0, score=25059.411648, test/accuracy=0.531100, test/loss=2.307310, test/num_examples=10000, total_duration=26089.408968, train/accuracy=0.715581, train/loss=1.414952, validation/accuracy=0.652060, validation/loss=1.700861, validation/num_examples=50000
I0921 07:36:20.312360 140446164547328 logging_writer.py:48] [74500] global_step=74500, grad_norm=0.3050025403499603, loss=3.200157880783081
I0921 07:39:08.616985 140445296359168 logging_writer.py:48] [75000] global_step=75000, grad_norm=0.3211391866207123, loss=3.2516210079193115
I0921 07:41:56.874293 140446164547328 logging_writer.py:48] [75500] global_step=75500, grad_norm=0.31732413172721863, loss=3.203551769256592
I0921 07:43:51.352138 140613218989888 spec.py:320] Evaluating on the training split.
I0921 07:43:59.320125 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 07:44:10.667434 140613218989888 spec.py:348] Evaluating on the test split.
I0921 07:44:13.035244 140613218989888 submission_runner.py:376] Time since start: 26621.36s, 	Step: 75842, 	{'train/accuracy': 0.6940768361091614, 'train/loss': 1.5050263404846191, 'validation/accuracy': 0.6295599937438965, 'validation/loss': 1.7738419771194458, 'validation/num_examples': 50000, 'test/accuracy': 0.5039000511169434, 'test/loss': 2.4370033740997314, 'test/num_examples': 10000, 'score': 25569.62277650833, 'total_duration': 26621.363907575607, 'accumulated_submission_time': 25569.62277650833, 'accumulated_eval_time': 1048.7881875038147, 'accumulated_logging_time': 1.750809907913208}
I0921 07:44:13.059964 140446172940032 logging_writer.py:48] [75842] accumulated_eval_time=1048.788188, accumulated_logging_time=1.750810, accumulated_submission_time=25569.622777, global_step=75842, preemption_count=0, score=25569.622777, test/accuracy=0.503900, test/loss=2.437003, test/num_examples=10000, total_duration=26621.363908, train/accuracy=0.694077, train/loss=1.505026, validation/accuracy=0.629560, validation/loss=1.773842, validation/num_examples=50000
I0921 07:45:06.576822 140446999209728 logging_writer.py:48] [76000] global_step=76000, grad_norm=0.31574976444244385, loss=3.2234461307525635
I0921 07:47:54.797944 140446172940032 logging_writer.py:48] [76500] global_step=76500, grad_norm=0.31703075766563416, loss=3.2374963760375977
I0921 07:50:43.049509 140446999209728 logging_writer.py:48] [77000] global_step=77000, grad_norm=0.3119738698005676, loss=3.285325050354004
I0921 07:52:43.265610 140613218989888 spec.py:320] Evaluating on the training split.
I0921 07:52:50.797230 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 07:53:01.978990 140613218989888 spec.py:348] Evaluating on the test split.
I0921 07:53:04.318727 140613218989888 submission_runner.py:376] Time since start: 27152.65s, 	Step: 77359, 	{'train/accuracy': 0.6878786683082581, 'train/loss': 1.5141419172286987, 'validation/accuracy': 0.633899986743927, 'validation/loss': 1.7614827156066895, 'validation/num_examples': 50000, 'test/accuracy': 0.5118000507354736, 'test/loss': 2.4090476036071777, 'test/num_examples': 10000, 'score': 26079.792610406876, 'total_duration': 27152.647390842438, 'accumulated_submission_time': 26079.792610406876, 'accumulated_eval_time': 1069.8412821292877, 'accumulated_logging_time': 1.7873945236206055}
I0921 07:53:04.345024 140446990817024 logging_writer.py:48] [77359] accumulated_eval_time=1069.841282, accumulated_logging_time=1.787395, accumulated_submission_time=26079.792610, global_step=77359, preemption_count=0, score=26079.792610, test/accuracy=0.511800, test/loss=2.409048, test/num_examples=10000, total_duration=27152.647391, train/accuracy=0.687879, train/loss=1.514142, validation/accuracy=0.633900, validation/loss=1.761483, validation/num_examples=50000
I0921 07:53:52.112257 140447024387840 logging_writer.py:48] [77500] global_step=77500, grad_norm=0.3231295049190521, loss=3.2520060539245605
I0921 07:56:40.307389 140446990817024 logging_writer.py:48] [78000] global_step=78000, grad_norm=0.31555038690567017, loss=3.2111353874206543
I0921 07:59:28.506576 140447024387840 logging_writer.py:48] [78500] global_step=78500, grad_norm=0.3159649074077606, loss=3.156517267227173
I0921 08:01:34.494039 140613218989888 spec.py:320] Evaluating on the training split.
I0921 08:01:42.000144 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 08:01:53.073753 140613218989888 spec.py:348] Evaluating on the test split.
I0921 08:01:55.389433 140613218989888 submission_runner.py:376] Time since start: 27683.72s, 	Step: 78876, 	{'train/accuracy': 0.7185506820678711, 'train/loss': 1.389367699623108, 'validation/accuracy': 0.6455199718475342, 'validation/loss': 1.6985089778900146, 'validation/num_examples': 50000, 'test/accuracy': 0.5169000029563904, 'test/loss': 2.3687965869903564, 'test/num_examples': 10000, 'score': 26589.906127929688, 'total_duration': 27683.71810078621, 'accumulated_submission_time': 26589.906127929688, 'accumulated_eval_time': 1090.7366514205933, 'accumulated_logging_time': 1.8254246711730957}
I0921 08:01:55.426938 140446172940032 logging_writer.py:48] [78876] accumulated_eval_time=1090.736651, accumulated_logging_time=1.825425, accumulated_submission_time=26589.906128, global_step=78876, preemption_count=0, score=26589.906128, test/accuracy=0.516900, test/loss=2.368797, test/num_examples=10000, total_duration=27683.718101, train/accuracy=0.718551, train/loss=1.389368, validation/accuracy=0.645520, validation/loss=1.698509, validation/num_examples=50000
I0921 08:02:37.447359 140446235883264 logging_writer.py:48] [79000] global_step=79000, grad_norm=0.3157334625720978, loss=3.156890392303467
I0921 08:05:25.659842 140446172940032 logging_writer.py:48] [79500] global_step=79500, grad_norm=0.323335736989975, loss=3.164780616760254
I0921 08:08:13.867301 140446235883264 logging_writer.py:48] [80000] global_step=80000, grad_norm=0.34294700622558594, loss=3.201962471008301
I0921 08:10:25.513401 140613218989888 spec.py:320] Evaluating on the training split.
I0921 08:10:33.027243 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 08:10:44.067776 140613218989888 spec.py:348] Evaluating on the test split.
I0921 08:10:46.429344 140613218989888 submission_runner.py:376] Time since start: 28214.76s, 	Step: 80393, 	{'train/accuracy': 0.7281369566917419, 'train/loss': 1.3253265619277954, 'validation/accuracy': 0.6444199681282043, 'validation/loss': 1.6741849184036255, 'validation/num_examples': 50000, 'test/accuracy': 0.515500009059906, 'test/loss': 2.3491342067718506, 'test/num_examples': 10000, 'score': 27099.957800865173, 'total_duration': 28214.758013486862, 'accumulated_submission_time': 27099.957800865173, 'accumulated_eval_time': 1111.6525723934174, 'accumulated_logging_time': 1.8742599487304688}
I0921 08:10:46.455063 140445296359168 logging_writer.py:48] [80393] accumulated_eval_time=1111.652572, accumulated_logging_time=1.874260, accumulated_submission_time=27099.957801, global_step=80393, preemption_count=0, score=27099.957801, test/accuracy=0.515500, test/loss=2.349134, test/num_examples=10000, total_duration=28214.758013, train/accuracy=0.728137, train/loss=1.325327, validation/accuracy=0.644420, validation/loss=1.674185, validation/num_examples=50000
I0921 08:11:22.704368 140446164547328 logging_writer.py:48] [80500] global_step=80500, grad_norm=0.32505977153778076, loss=3.188847780227661
I0921 08:14:10.983292 140445296359168 logging_writer.py:48] [81000] global_step=81000, grad_norm=0.32656335830688477, loss=3.2111270427703857
I0921 08:16:59.267845 140446164547328 logging_writer.py:48] [81500] global_step=81500, grad_norm=0.3166333734989166, loss=3.1346349716186523
I0921 08:19:16.695253 140613218989888 spec.py:320] Evaluating on the training split.
I0921 08:19:24.173698 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 08:19:35.352536 140613218989888 spec.py:348] Evaluating on the test split.
I0921 08:19:37.679126 140613218989888 submission_runner.py:376] Time since start: 28746.01s, 	Step: 81910, 	{'train/accuracy': 0.7171356678009033, 'train/loss': 1.3880951404571533, 'validation/accuracy': 0.6470400094985962, 'validation/loss': 1.6899938583374023, 'validation/num_examples': 50000, 'test/accuracy': 0.5190000534057617, 'test/loss': 2.3436319828033447, 'test/num_examples': 10000, 'score': 27610.161732196808, 'total_duration': 28746.007794857025, 'accumulated_submission_time': 27610.161732196808, 'accumulated_eval_time': 1132.6364245414734, 'accumulated_logging_time': 1.9125375747680664}
I0921 08:19:37.709728 140447015995136 logging_writer.py:48] [81910] accumulated_eval_time=1132.636425, accumulated_logging_time=1.912538, accumulated_submission_time=27610.161732, global_step=81910, preemption_count=0, score=27610.161732, test/accuracy=0.519000, test/loss=2.343632, test/num_examples=10000, total_duration=28746.007795, train/accuracy=0.717136, train/loss=1.388095, validation/accuracy=0.647040, validation/loss=1.689994, validation/num_examples=50000
I0921 08:20:08.312760 140447024387840 logging_writer.py:48] [82000] global_step=82000, grad_norm=0.33525553345680237, loss=3.219813585281372
I0921 08:22:56.562716 140447015995136 logging_writer.py:48] [82500] global_step=82500, grad_norm=0.32667526602745056, loss=3.246901035308838
I0921 08:25:44.778086 140447024387840 logging_writer.py:48] [83000] global_step=83000, grad_norm=0.33255642652511597, loss=3.1909518241882324
I0921 08:28:07.875312 140613218989888 spec.py:320] Evaluating on the training split.
I0921 08:28:15.338463 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 08:28:26.523952 140613218989888 spec.py:348] Evaluating on the test split.
I0921 08:28:28.850168 140613218989888 submission_runner.py:376] Time since start: 29277.18s, 	Step: 83427, 	{'train/accuracy': 0.71488356590271, 'train/loss': 1.3625293970108032, 'validation/accuracy': 0.6510199904441833, 'validation/loss': 1.6441048383712769, 'validation/num_examples': 50000, 'test/accuracy': 0.5236999988555908, 'test/loss': 2.316115617752075, 'test/num_examples': 10000, 'score': 28120.290773630142, 'total_duration': 29277.178822040558, 'accumulated_submission_time': 28120.290773630142, 'accumulated_eval_time': 1153.6112608909607, 'accumulated_logging_time': 1.9558968544006348}
I0921 08:28:28.879640 140446172940032 logging_writer.py:48] [83427] accumulated_eval_time=1153.611261, accumulated_logging_time=1.955897, accumulated_submission_time=28120.290774, global_step=83427, preemption_count=0, score=28120.290774, test/accuracy=0.523700, test/loss=2.316116, test/num_examples=10000, total_duration=29277.178822, train/accuracy=0.714884, train/loss=1.362529, validation/accuracy=0.651020, validation/loss=1.644105, validation/num_examples=50000
I0921 08:28:53.763953 140446235883264 logging_writer.py:48] [83500] global_step=83500, grad_norm=0.34970906376838684, loss=3.212470769882202
I0921 08:31:41.925204 140446172940032 logging_writer.py:48] [84000] global_step=84000, grad_norm=0.33615216612815857, loss=3.1805777549743652
I0921 08:34:30.162265 140446235883264 logging_writer.py:48] [84500] global_step=84500, grad_norm=0.3368687033653259, loss=3.2006983757019043
I0921 08:36:58.932652 140613218989888 spec.py:320] Evaluating on the training split.
I0921 08:37:06.406169 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 08:37:17.643057 140613218989888 spec.py:348] Evaluating on the test split.
I0921 08:37:20.034476 140613218989888 submission_runner.py:376] Time since start: 29808.36s, 	Step: 84944, 	{'train/accuracy': 0.7269212007522583, 'train/loss': 1.3108192682266235, 'validation/accuracy': 0.6607599854469299, 'validation/loss': 1.599299669265747, 'validation/num_examples': 50000, 'test/accuracy': 0.5332000255584717, 'test/loss': 2.2441816329956055, 'test/num_examples': 10000, 'score': 28630.306353330612, 'total_duration': 29808.363132476807, 'accumulated_submission_time': 28630.306353330612, 'accumulated_eval_time': 1174.7130620479584, 'accumulated_logging_time': 1.9988429546356201}
I0921 08:37:20.060782 140447015995136 logging_writer.py:48] [84944] accumulated_eval_time=1174.713062, accumulated_logging_time=1.998843, accumulated_submission_time=28630.306353, global_step=84944, preemption_count=0, score=28630.306353, test/accuracy=0.533200, test/loss=2.244182, test/num_examples=10000, total_duration=29808.363132, train/accuracy=0.726921, train/loss=1.310819, validation/accuracy=0.660760, validation/loss=1.599300, validation/num_examples=50000
I0921 08:37:39.206335 140447024387840 logging_writer.py:48] [85000] global_step=85000, grad_norm=0.32567310333251953, loss=3.1423819065093994
I0921 08:40:27.233355 140447015995136 logging_writer.py:48] [85500] global_step=85500, grad_norm=0.3251207172870636, loss=3.1417198181152344
I0921 08:43:15.534064 140447024387840 logging_writer.py:48] [86000] global_step=86000, grad_norm=0.3439444303512573, loss=3.163228750228882
I0921 08:45:50.081471 140613218989888 spec.py:320] Evaluating on the training split.
I0921 08:45:57.539205 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 08:46:08.788528 140613218989888 spec.py:348] Evaluating on the test split.
I0921 08:46:11.108452 140613218989888 submission_runner.py:376] Time since start: 30339.44s, 	Step: 86461, 	{'train/accuracy': 0.7081672549247742, 'train/loss': 1.4201782941818237, 'validation/accuracy': 0.6499399542808533, 'validation/loss': 1.683957576751709, 'validation/num_examples': 50000, 'test/accuracy': 0.5160000324249268, 'test/loss': 2.3554069995880127, 'test/num_examples': 10000, 'score': 29140.289971590042, 'total_duration': 30339.43712091446, 'accumulated_submission_time': 29140.289971590042, 'accumulated_eval_time': 1195.7400197982788, 'accumulated_logging_time': 2.0383377075195312}
I0921 08:46:11.141426 140446164547328 logging_writer.py:48] [86461] accumulated_eval_time=1195.740020, accumulated_logging_time=2.038338, accumulated_submission_time=29140.289972, global_step=86461, preemption_count=0, score=29140.289972, test/accuracy=0.516000, test/loss=2.355407, test/num_examples=10000, total_duration=30339.437121, train/accuracy=0.708167, train/loss=1.420178, validation/accuracy=0.649940, validation/loss=1.683958, validation/num_examples=50000
I0921 08:46:24.610500 140446172940032 logging_writer.py:48] [86500] global_step=86500, grad_norm=0.33857035636901855, loss=3.1456027030944824
I0921 08:49:12.793569 140446164547328 logging_writer.py:48] [87000] global_step=87000, grad_norm=0.32007959485054016, loss=3.0516042709350586
I0921 08:52:01.030270 140446172940032 logging_writer.py:48] [87500] global_step=87500, grad_norm=0.3292735517024994, loss=3.040863037109375
I0921 08:54:41.299274 140613218989888 spec.py:320] Evaluating on the training split.
I0921 08:54:48.752566 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 08:54:59.771929 140613218989888 spec.py:348] Evaluating on the test split.
I0921 08:55:02.100608 140613218989888 submission_runner.py:376] Time since start: 30870.43s, 	Step: 87978, 	{'train/accuracy': 0.7741948366165161, 'train/loss': 1.1025867462158203, 'validation/accuracy': 0.6649999618530273, 'validation/loss': 1.576514482498169, 'validation/num_examples': 50000, 'test/accuracy': 0.544700026512146, 'test/loss': 2.20332407951355, 'test/num_examples': 10000, 'score': 29650.408900499344, 'total_duration': 30870.429267644882, 'accumulated_submission_time': 29650.408900499344, 'accumulated_eval_time': 1216.5413224697113, 'accumulated_logging_time': 2.0864293575286865}
I0921 08:55:02.128017 140446164547328 logging_writer.py:48] [87978] accumulated_eval_time=1216.541322, accumulated_logging_time=2.086429, accumulated_submission_time=29650.408900, global_step=87978, preemption_count=0, score=29650.408900, test/accuracy=0.544700, test/loss=2.203324, test/num_examples=10000, total_duration=30870.429268, train/accuracy=0.774195, train/loss=1.102587, validation/accuracy=0.665000, validation/loss=1.576514, validation/num_examples=50000
I0921 08:55:09.863342 140446172940032 logging_writer.py:48] [88000] global_step=88000, grad_norm=0.3453966975212097, loss=3.197694778442383
I0921 08:57:58.138592 140446164547328 logging_writer.py:48] [88500] global_step=88500, grad_norm=0.3436453640460968, loss=3.1441779136657715
I0921 09:00:46.372009 140446172940032 logging_writer.py:48] [89000] global_step=89000, grad_norm=0.3536754548549652, loss=3.142423391342163
I0921 09:03:32.281226 140613218989888 spec.py:320] Evaluating on the training split.
I0921 09:03:39.737737 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 09:03:50.885243 140613218989888 spec.py:348] Evaluating on the test split.
I0921 09:03:53.225356 140613218989888 submission_runner.py:376] Time since start: 31401.55s, 	Step: 89403, 	{'train/accuracy': 0.760164201259613, 'train/loss': 1.2321293354034424, 'validation/accuracy': 0.6697799563407898, 'validation/loss': 1.6143219470977783, 'validation/num_examples': 50000, 'test/accuracy': 0.5444000363349915, 'test/loss': 2.2412638664245605, 'test/num_examples': 10000, 'score': 30160.527873277664, 'total_duration': 31401.554005622864, 'accumulated_submission_time': 30160.527873277664, 'accumulated_eval_time': 1237.485412120819, 'accumulated_logging_time': 2.125343084335327}
I0921 09:03:53.256861 140446172940032 logging_writer.py:48] [89403] accumulated_eval_time=1237.485412, accumulated_logging_time=2.125343, accumulated_submission_time=30160.527873, global_step=89403, preemption_count=0, score=30160.527873, test/accuracy=0.544400, test/loss=2.241264, test/num_examples=10000, total_duration=31401.554006, train/accuracy=0.760164, train/loss=1.232129, validation/accuracy=0.669780, validation/loss=1.614322, validation/num_examples=50000
I0921 09:04:26.206912 140446990817024 logging_writer.py:48] [89500] global_step=89500, grad_norm=0.34256935119628906, loss=3.135265827178955
I0921 09:07:14.502468 140446172940032 logging_writer.py:48] [90000] global_step=90000, grad_norm=0.35209783911705017, loss=3.1239633560180664
I0921 09:10:02.727080 140446990817024 logging_writer.py:48] [90500] global_step=90500, grad_norm=0.3473758101463318, loss=3.1047375202178955
I0921 09:12:23.445142 140613218989888 spec.py:320] Evaluating on the training split.
I0921 09:12:30.978272 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 09:12:41.920020 140613218989888 spec.py:348] Evaluating on the test split.
I0921 09:12:44.276143 140613218989888 submission_runner.py:376] Time since start: 31932.60s, 	Step: 90920, 	{'train/accuracy': 0.7546834945678711, 'train/loss': 1.1807116270065308, 'validation/accuracy': 0.6760199666023254, 'validation/loss': 1.5265799760818481, 'validation/num_examples': 50000, 'test/accuracy': 0.5505000352859497, 'test/loss': 2.1591992378234863, 'test/num_examples': 10000, 'score': 30670.68004131317, 'total_duration': 31932.60477924347, 'accumulated_submission_time': 30670.68004131317, 'accumulated_eval_time': 1258.3163604736328, 'accumulated_logging_time': 2.1692705154418945}
I0921 09:12:44.303136 140445296359168 logging_writer.py:48] [90920] accumulated_eval_time=1258.316360, accumulated_logging_time=2.169271, accumulated_submission_time=30670.680041, global_step=90920, preemption_count=0, score=30670.680041, test/accuracy=0.550500, test/loss=2.159199, test/num_examples=10000, total_duration=31932.604779, train/accuracy=0.754683, train/loss=1.180712, validation/accuracy=0.676020, validation/loss=1.526580, validation/num_examples=50000
I0921 09:13:11.591736 140446235883264 logging_writer.py:48] [91000] global_step=91000, grad_norm=0.3555426597595215, loss=3.125296115875244
I0921 09:15:59.816602 140445296359168 logging_writer.py:48] [91500] global_step=91500, grad_norm=0.3410206735134125, loss=3.1417269706726074
I0921 09:18:48.070654 140446235883264 logging_writer.py:48] [92000] global_step=92000, grad_norm=0.34430474042892456, loss=3.0981717109680176
I0921 09:21:14.554724 140613218989888 spec.py:320] Evaluating on the training split.
I0921 09:21:21.979541 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 09:21:32.993553 140613218989888 spec.py:348] Evaluating on the test split.
I0921 09:21:35.703116 140613218989888 submission_runner.py:376] Time since start: 32464.03s, 	Step: 92437, 	{'train/accuracy': 0.7476283311843872, 'train/loss': 1.2200695276260376, 'validation/accuracy': 0.669219970703125, 'validation/loss': 1.546072006225586, 'validation/num_examples': 50000, 'test/accuracy': 0.5409000515937805, 'test/loss': 2.1896841526031494, 'test/num_examples': 10000, 'score': 31180.89601111412, 'total_duration': 32464.031769752502, 'accumulated_submission_time': 31180.89601111412, 'accumulated_eval_time': 1279.46471118927, 'accumulated_logging_time': 2.2080471515655518}
I0921 09:21:35.731663 140445296359168 logging_writer.py:48] [92437] accumulated_eval_time=1279.464711, accumulated_logging_time=2.208047, accumulated_submission_time=31180.896011, global_step=92437, preemption_count=0, score=31180.896011, test/accuracy=0.540900, test/loss=2.189684, test/num_examples=10000, total_duration=32464.031770, train/accuracy=0.747628, train/loss=1.220070, validation/accuracy=0.669220, validation/loss=1.546072, validation/num_examples=50000
I0921 09:21:57.300982 140446164547328 logging_writer.py:48] [92500] global_step=92500, grad_norm=0.34960782527923584, loss=3.060140371322632
I0921 09:24:45.568302 140445296359168 logging_writer.py:48] [93000] global_step=93000, grad_norm=0.343671977519989, loss=3.116586923599243
I0921 09:27:33.781403 140446164547328 logging_writer.py:48] [93500] global_step=93500, grad_norm=0.373569130897522, loss=3.1454033851623535
I0921 09:30:05.938716 140613218989888 spec.py:320] Evaluating on the training split.
I0921 09:30:13.403859 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 09:30:24.430454 140613218989888 spec.py:348] Evaluating on the test split.
I0921 09:30:26.771758 140613218989888 submission_runner.py:376] Time since start: 32995.10s, 	Step: 93954, 	{'train/accuracy': 0.7428451776504517, 'train/loss': 1.2713103294372559, 'validation/accuracy': 0.6768400073051453, 'validation/loss': 1.5632636547088623, 'validation/num_examples': 50000, 'test/accuracy': 0.5412000417709351, 'test/loss': 2.229316234588623, 'test/num_examples': 10000, 'score': 31691.067200660706, 'total_duration': 32995.10042333603, 'accumulated_submission_time': 31691.067200660706, 'accumulated_eval_time': 1300.2977285385132, 'accumulated_logging_time': 2.2484145164489746}
I0921 09:30:26.798610 140446999209728 logging_writer.py:48] [93954] accumulated_eval_time=1300.297729, accumulated_logging_time=2.248415, accumulated_submission_time=31691.067201, global_step=93954, preemption_count=0, score=31691.067201, test/accuracy=0.541200, test/loss=2.229316, test/num_examples=10000, total_duration=32995.100423, train/accuracy=0.742845, train/loss=1.271310, validation/accuracy=0.676840, validation/loss=1.563264, validation/num_examples=50000
I0921 09:30:42.635402 140447007602432 logging_writer.py:48] [94000] global_step=94000, grad_norm=0.3464675545692444, loss=3.03672194480896
I0921 09:33:30.954166 140446999209728 logging_writer.py:48] [94500] global_step=94500, grad_norm=0.3505924940109253, loss=3.0507311820983887
I0921 09:36:19.230703 140447007602432 logging_writer.py:48] [95000] global_step=95000, grad_norm=0.3565899431705475, loss=3.1192448139190674
I0921 09:38:56.803625 140613218989888 spec.py:320] Evaluating on the training split.
I0921 09:39:04.257690 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 09:39:15.379351 140613218989888 spec.py:348] Evaluating on the test split.
I0921 09:39:17.704334 140613218989888 submission_runner.py:376] Time since start: 33526.03s, 	Step: 95470, 	{'train/accuracy': 0.7487842440605164, 'train/loss': 1.2690248489379883, 'validation/accuracy': 0.6800400018692017, 'validation/loss': 1.5611140727996826, 'validation/num_examples': 50000, 'test/accuracy': 0.5588000416755676, 'test/loss': 2.176574945449829, 'test/num_examples': 10000, 'score': 32201.036960601807, 'total_duration': 33526.03298687935, 'accumulated_submission_time': 32201.036960601807, 'accumulated_eval_time': 1321.1983988285065, 'accumulated_logging_time': 2.2867887020111084}
I0921 09:39:17.734750 140446164547328 logging_writer.py:48] [95470] accumulated_eval_time=1321.198399, accumulated_logging_time=2.286789, accumulated_submission_time=32201.036961, global_step=95470, preemption_count=0, score=32201.036961, test/accuracy=0.558800, test/loss=2.176575, test/num_examples=10000, total_duration=33526.032987, train/accuracy=0.748784, train/loss=1.269025, validation/accuracy=0.680040, validation/loss=1.561114, validation/num_examples=50000
I0921 09:39:28.168320 140446172940032 logging_writer.py:48] [95500] global_step=95500, grad_norm=0.3620976507663727, loss=3.085495710372925
I0921 09:42:16.413638 140446164547328 logging_writer.py:48] [96000] global_step=96000, grad_norm=0.37209898233413696, loss=3.0467305183410645
I0921 09:45:04.616245 140446172940032 logging_writer.py:48] [96500] global_step=96500, grad_norm=0.37305280566215515, loss=3.119359016418457
I0921 09:47:47.803508 140613218989888 spec.py:320] Evaluating on the training split.
I0921 09:47:55.225508 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 09:48:06.293908 140613218989888 spec.py:348] Evaluating on the test split.
I0921 09:48:08.712818 140613218989888 submission_runner.py:376] Time since start: 34057.04s, 	Step: 96987, 	{'train/accuracy': 0.7792569994926453, 'train/loss': 1.127251386642456, 'validation/accuracy': 0.6884999871253967, 'validation/loss': 1.5091551542282104, 'validation/num_examples': 50000, 'test/accuracy': 0.5596000552177429, 'test/loss': 2.1477794647216797, 'test/num_examples': 10000, 'score': 32711.069343805313, 'total_duration': 34057.04123091698, 'accumulated_submission_time': 32711.069343805313, 'accumulated_eval_time': 1342.107433795929, 'accumulated_logging_time': 2.329782009124756}
I0921 09:48:08.739846 140446164547328 logging_writer.py:48] [96987] accumulated_eval_time=1342.107434, accumulated_logging_time=2.329782, accumulated_submission_time=32711.069344, global_step=96987, preemption_count=0, score=32711.069344, test/accuracy=0.559600, test/loss=2.147779, test/num_examples=10000, total_duration=34057.041231, train/accuracy=0.779257, train/loss=1.127251, validation/accuracy=0.688500, validation/loss=1.509155, validation/num_examples=50000
I0921 09:48:13.450699 140447007602432 logging_writer.py:48] [97000] global_step=97000, grad_norm=0.3646641671657562, loss=3.0083160400390625
I0921 09:51:01.600339 140446164547328 logging_writer.py:48] [97500] global_step=97500, grad_norm=0.3605125844478607, loss=3.024428606033325
I0921 09:53:49.825552 140447007602432 logging_writer.py:48] [98000] global_step=98000, grad_norm=0.35687315464019775, loss=3.094769239425659
I0921 09:56:38.107287 140446164547328 logging_writer.py:48] [98500] global_step=98500, grad_norm=0.3683936595916748, loss=3.0112524032592773
I0921 09:56:38.869921 140613218989888 spec.py:320] Evaluating on the training split.
I0921 09:56:46.338411 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 09:56:57.448777 140613218989888 spec.py:348] Evaluating on the test split.
I0921 09:56:59.788494 140613218989888 submission_runner.py:376] Time since start: 34588.12s, 	Step: 98504, 	{'train/accuracy': 0.7738958597183228, 'train/loss': 1.1183806657791138, 'validation/accuracy': 0.6839399933815002, 'validation/loss': 1.509204387664795, 'validation/num_examples': 50000, 'test/accuracy': 0.5569000244140625, 'test/loss': 2.1492249965667725, 'test/num_examples': 10000, 'score': 33221.164717674255, 'total_duration': 34588.117144823074, 'accumulated_submission_time': 33221.164717674255, 'accumulated_eval_time': 1363.0259428024292, 'accumulated_logging_time': 2.367922306060791}
I0921 09:56:59.813994 140446164547328 logging_writer.py:48] [98504] accumulated_eval_time=1363.025943, accumulated_logging_time=2.367922, accumulated_submission_time=33221.164718, global_step=98504, preemption_count=0, score=33221.164718, test/accuracy=0.556900, test/loss=2.149225, test/num_examples=10000, total_duration=34588.117145, train/accuracy=0.773896, train/loss=1.118381, validation/accuracy=0.683940, validation/loss=1.509204, validation/num_examples=50000
I0921 09:59:47.000283 140446172940032 logging_writer.py:48] [99000] global_step=99000, grad_norm=0.3800124228000641, loss=3.0920605659484863
I0921 10:02:35.243020 140446164547328 logging_writer.py:48] [99500] global_step=99500, grad_norm=0.38363340497016907, loss=3.0461697578430176
I0921 10:05:23.480744 140446172940032 logging_writer.py:48] [100000] global_step=100000, grad_norm=0.377422034740448, loss=3.0927839279174805
I0921 10:05:29.954877 140613218989888 spec.py:320] Evaluating on the training split.
I0921 10:05:37.358138 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 10:05:48.540894 140613218989888 spec.py:348] Evaluating on the test split.
I0921 10:05:50.902192 140613218989888 submission_runner.py:376] Time since start: 35119.23s, 	Step: 100021, 	{'train/accuracy': 0.7620376348495483, 'train/loss': 1.1442164182662964, 'validation/accuracy': 0.6807000041007996, 'validation/loss': 1.5029559135437012, 'validation/num_examples': 50000, 'test/accuracy': 0.5522000193595886, 'test/loss': 2.168475389480591, 'test/num_examples': 10000, 'score': 33731.27061343193, 'total_duration': 35119.230862379074, 'accumulated_submission_time': 33731.27061343193, 'accumulated_eval_time': 1383.9732139110565, 'accumulated_logging_time': 2.404984712600708}
I0921 10:05:50.929698 140446999209728 logging_writer.py:48] [100021] accumulated_eval_time=1383.973214, accumulated_logging_time=2.404985, accumulated_submission_time=33731.270613, global_step=100021, preemption_count=0, score=33731.270613, test/accuracy=0.552200, test/loss=2.168475, test/num_examples=10000, total_duration=35119.230862, train/accuracy=0.762038, train/loss=1.144216, validation/accuracy=0.680700, validation/loss=1.502956, validation/num_examples=50000
I0921 10:08:32.476649 140447007602432 logging_writer.py:48] [100500] global_step=100500, grad_norm=0.3758077621459961, loss=2.9949703216552734
I0921 10:11:20.689700 140446999209728 logging_writer.py:48] [101000] global_step=101000, grad_norm=0.3793098032474518, loss=3.050997734069824
I0921 10:14:08.894496 140447007602432 logging_writer.py:48] [101500] global_step=101500, grad_norm=0.3717975616455078, loss=2.959080696105957
I0921 10:14:21.091220 140613218989888 spec.py:320] Evaluating on the training split.
I0921 10:14:28.550128 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 10:14:39.751766 140613218989888 spec.py:348] Evaluating on the test split.
I0921 10:14:42.128398 140613218989888 submission_runner.py:376] Time since start: 35650.46s, 	Step: 101538, 	{'train/accuracy': 0.7798150181770325, 'train/loss': 1.1336147785186768, 'validation/accuracy': 0.6987199783325195, 'validation/loss': 1.472100019454956, 'validation/num_examples': 50000, 'test/accuracy': 0.5708000063896179, 'test/loss': 2.1115829944610596, 'test/num_examples': 10000, 'score': 34241.39809155464, 'total_duration': 35650.45706796646, 'accumulated_submission_time': 34241.39809155464, 'accumulated_eval_time': 1405.0103640556335, 'accumulated_logging_time': 2.443260669708252}
I0921 10:14:42.153305 140446235883264 logging_writer.py:48] [101538] accumulated_eval_time=1405.010364, accumulated_logging_time=2.443261, accumulated_submission_time=34241.398092, global_step=101538, preemption_count=0, score=34241.398092, test/accuracy=0.570800, test/loss=2.111583, test/num_examples=10000, total_duration=35650.457068, train/accuracy=0.779815, train/loss=1.133615, validation/accuracy=0.698720, validation/loss=1.472100, validation/num_examples=50000
I0921 10:17:17.878833 140446990817024 logging_writer.py:48] [102000] global_step=102000, grad_norm=0.39287298917770386, loss=3.051133394241333
I0921 10:20:06.121839 140446235883264 logging_writer.py:48] [102500] global_step=102500, grad_norm=0.38337644934654236, loss=3.0331339836120605
I0921 10:22:54.382205 140446990817024 logging_writer.py:48] [103000] global_step=103000, grad_norm=0.3788679242134094, loss=2.9811577796936035
I0921 10:23:12.298741 140613218989888 spec.py:320] Evaluating on the training split.
I0921 10:23:19.763996 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 10:23:30.865255 140613218989888 spec.py:348] Evaluating on the test split.
I0921 10:23:33.171298 140613218989888 submission_runner.py:376] Time since start: 36181.50s, 	Step: 103055, 	{'train/accuracy': 0.7728396058082581, 'train/loss': 1.1437686681747437, 'validation/accuracy': 0.6934599876403809, 'validation/loss': 1.4837627410888672, 'validation/num_examples': 50000, 'test/accuracy': 0.5624000430107117, 'test/loss': 2.120307445526123, 'test/num_examples': 10000, 'score': 34751.50690150261, 'total_duration': 36181.49987959862, 'accumulated_submission_time': 34751.50690150261, 'accumulated_eval_time': 1425.882792711258, 'accumulated_logging_time': 2.4810028076171875}
I0921 10:23:33.197398 140446172940032 logging_writer.py:48] [103055] accumulated_eval_time=1425.882793, accumulated_logging_time=2.481003, accumulated_submission_time=34751.506902, global_step=103055, preemption_count=0, score=34751.506902, test/accuracy=0.562400, test/loss=2.120307, test/num_examples=10000, total_duration=36181.499880, train/accuracy=0.772840, train/loss=1.143769, validation/accuracy=0.693460, validation/loss=1.483763, validation/num_examples=50000
I0921 10:26:03.188477 140446235883264 logging_writer.py:48] [103500] global_step=103500, grad_norm=0.3861703872680664, loss=2.9690024852752686
I0921 10:28:51.391952 140446172940032 logging_writer.py:48] [104000] global_step=104000, grad_norm=0.40048888325691223, loss=3.025723934173584
I0921 10:31:39.601140 140446235883264 logging_writer.py:48] [104500] global_step=104500, grad_norm=0.386339008808136, loss=2.9280190467834473
I0921 10:32:03.249214 140613218989888 spec.py:320] Evaluating on the training split.
I0921 10:32:10.631930 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 10:32:21.726193 140613218989888 spec.py:348] Evaluating on the test split.
I0921 10:32:24.067853 140613218989888 submission_runner.py:376] Time since start: 36712.40s, 	Step: 104572, 	{'train/accuracy': 0.7798548936843872, 'train/loss': 1.084933876991272, 'validation/accuracy': 0.705299973487854, 'validation/loss': 1.4098957777023315, 'validation/num_examples': 50000, 'test/accuracy': 0.581000030040741, 'test/loss': 2.0294301509857178, 'test/num_examples': 10000, 'score': 35261.52269268036, 'total_duration': 36712.39652299881, 'accumulated_submission_time': 35261.52269268036, 'accumulated_eval_time': 1446.7013919353485, 'accumulated_logging_time': 2.5192880630493164}
I0921 10:32:24.094298 140447015995136 logging_writer.py:48] [104572] accumulated_eval_time=1446.701392, accumulated_logging_time=2.519288, accumulated_submission_time=35261.522693, global_step=104572, preemption_count=0, score=35261.522693, test/accuracy=0.581000, test/loss=2.029430, test/num_examples=10000, total_duration=36712.396523, train/accuracy=0.779855, train/loss=1.084934, validation/accuracy=0.705300, validation/loss=1.409896, validation/num_examples=50000
I0921 10:34:48.431109 140447024387840 logging_writer.py:48] [105000] global_step=105000, grad_norm=0.4060470759868622, loss=2.9858591556549072
I0921 10:37:36.661369 140447015995136 logging_writer.py:48] [105500] global_step=105500, grad_norm=0.39890459179878235, loss=3.0030879974365234
I0921 10:40:24.867876 140447024387840 logging_writer.py:48] [106000] global_step=106000, grad_norm=0.4240477383136749, loss=2.995701313018799
I0921 10:40:54.240874 140613218989888 spec.py:320] Evaluating on the training split.
I0921 10:41:01.626211 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 10:41:12.669197 140613218989888 spec.py:348] Evaluating on the test split.
I0921 10:41:15.002205 140613218989888 submission_runner.py:376] Time since start: 37243.33s, 	Step: 106089, 	{'train/accuracy': 0.8142538070678711, 'train/loss': 0.9820297360420227, 'validation/accuracy': 0.6957399845123291, 'validation/loss': 1.4702575206756592, 'validation/num_examples': 50000, 'test/accuracy': 0.5756000280380249, 'test/loss': 2.088582992553711, 'test/num_examples': 10000, 'score': 35771.63497543335, 'total_duration': 37243.33074903488, 'accumulated_submission_time': 35771.63497543335, 'accumulated_eval_time': 1467.462560892105, 'accumulated_logging_time': 2.5562973022460938}
I0921 10:41:15.032886 140446172940032 logging_writer.py:48] [106089] accumulated_eval_time=1467.462561, accumulated_logging_time=2.556297, accumulated_submission_time=35771.634975, global_step=106089, preemption_count=0, score=35771.634975, test/accuracy=0.575600, test/loss=2.088583, test/num_examples=10000, total_duration=37243.330749, train/accuracy=0.814254, train/loss=0.982030, validation/accuracy=0.695740, validation/loss=1.470258, validation/num_examples=50000
I0921 10:43:33.690989 140446235883264 logging_writer.py:48] [106500] global_step=106500, grad_norm=0.40322357416152954, loss=2.9726619720458984
I0921 10:46:21.922564 140446172940032 logging_writer.py:48] [107000] global_step=107000, grad_norm=0.3911997377872467, loss=2.921370029449463
I0921 10:49:10.155867 140446235883264 logging_writer.py:48] [107500] global_step=107500, grad_norm=0.38709285855293274, loss=2.9123241901397705
I0921 10:49:45.236669 140613218989888 spec.py:320] Evaluating on the training split.
I0921 10:49:52.902787 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 10:50:03.899013 140613218989888 spec.py:348] Evaluating on the test split.
I0921 10:50:06.217132 140613218989888 submission_runner.py:376] Time since start: 37774.55s, 	Step: 107606, 	{'train/accuracy': 0.8084143400192261, 'train/loss': 0.9889046549797058, 'validation/accuracy': 0.7097199559211731, 'validation/loss': 1.3914456367492676, 'validation/num_examples': 50000, 'test/accuracy': 0.5845000147819519, 'test/loss': 1.998412013053894, 'test/num_examples': 10000, 'score': 36281.79980945587, 'total_duration': 37774.54580140114, 'accumulated_submission_time': 36281.79980945587, 'accumulated_eval_time': 1488.4429895877838, 'accumulated_logging_time': 2.602069854736328}
I0921 10:50:06.243654 140445296359168 logging_writer.py:48] [107606] accumulated_eval_time=1488.442990, accumulated_logging_time=2.602070, accumulated_submission_time=36281.799809, global_step=107606, preemption_count=0, score=36281.799809, test/accuracy=0.584500, test/loss=1.998412, test/num_examples=10000, total_duration=37774.545801, train/accuracy=0.808414, train/loss=0.988905, validation/accuracy=0.709720, validation/loss=1.391446, validation/num_examples=50000
I0921 10:52:19.172899 140446999209728 logging_writer.py:48] [108000] global_step=108000, grad_norm=0.40735170245170593, loss=2.948378801345825
I0921 10:55:07.388005 140445296359168 logging_writer.py:48] [108500] global_step=108500, grad_norm=0.419050395488739, loss=3.0022168159484863
I0921 10:57:55.623634 140446999209728 logging_writer.py:48] [109000] global_step=109000, grad_norm=0.4153014123439789, loss=2.908865451812744
I0921 10:58:36.414880 140613218989888 spec.py:320] Evaluating on the training split.
I0921 10:58:43.863310 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 10:58:54.986638 140613218989888 spec.py:348] Evaluating on the test split.
I0921 10:58:57.271487 140613218989888 submission_runner.py:376] Time since start: 38305.60s, 	Step: 109123, 	{'train/accuracy': 0.7987882494926453, 'train/loss': 1.0279736518859863, 'validation/accuracy': 0.7055000066757202, 'validation/loss': 1.4219591617584229, 'validation/num_examples': 50000, 'test/accuracy': 0.5830000042915344, 'test/loss': 2.031740188598633, 'test/num_examples': 10000, 'score': 36791.936692237854, 'total_duration': 38305.600130319595, 'accumulated_submission_time': 36791.936692237854, 'accumulated_eval_time': 1509.299532175064, 'accumulated_logging_time': 2.639185667037964}
I0921 10:58:57.307051 140447007602432 logging_writer.py:48] [109123] accumulated_eval_time=1509.299532, accumulated_logging_time=2.639186, accumulated_submission_time=36791.936692, global_step=109123, preemption_count=0, score=36791.936692, test/accuracy=0.583000, test/loss=2.031740, test/num_examples=10000, total_duration=38305.600130, train/accuracy=0.798788, train/loss=1.027974, validation/accuracy=0.705500, validation/loss=1.421959, validation/num_examples=50000
I0921 11:01:04.447762 140447015995136 logging_writer.py:48] [109500] global_step=109500, grad_norm=0.4376038908958435, loss=3.0099098682403564
I0921 11:03:52.654789 140447007602432 logging_writer.py:48] [110000] global_step=110000, grad_norm=0.41477492451667786, loss=2.9301986694335938
I0921 11:06:40.881814 140447015995136 logging_writer.py:48] [110500] global_step=110500, grad_norm=0.4073322117328644, loss=2.8961386680603027
I0921 11:07:27.433652 140613218989888 spec.py:320] Evaluating on the training split.
I0921 11:07:34.850595 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 11:07:45.895401 140613218989888 spec.py:348] Evaluating on the test split.
I0921 11:07:48.229644 140613218989888 submission_runner.py:376] Time since start: 38836.56s, 	Step: 110640, 	{'train/accuracy': 0.8102080225944519, 'train/loss': 0.9365128874778748, 'validation/accuracy': 0.7159799933433533, 'validation/loss': 1.3339099884033203, 'validation/num_examples': 50000, 'test/accuracy': 0.5889000296592712, 'test/loss': 1.9741050004959106, 'test/num_examples': 10000, 'score': 37302.028915166855, 'total_duration': 38836.55831408501, 'accumulated_submission_time': 37302.028915166855, 'accumulated_eval_time': 1530.0955040454865, 'accumulated_logging_time': 2.6852407455444336}
I0921 11:07:48.255660 140446164547328 logging_writer.py:48] [110640] accumulated_eval_time=1530.095504, accumulated_logging_time=2.685241, accumulated_submission_time=37302.028915, global_step=110640, preemption_count=0, score=37302.028915, test/accuracy=0.588900, test/loss=1.974105, test/num_examples=10000, total_duration=38836.558314, train/accuracy=0.810208, train/loss=0.936513, validation/accuracy=0.715980, validation/loss=1.333910, validation/num_examples=50000
I0921 11:09:49.548920 140446172940032 logging_writer.py:48] [111000] global_step=111000, grad_norm=0.42300331592559814, loss=2.9151418209075928
I0921 11:12:37.784697 140446164547328 logging_writer.py:48] [111500] global_step=111500, grad_norm=0.4200751483440399, loss=2.832430839538574
I0921 11:15:26.049387 140446172940032 logging_writer.py:48] [112000] global_step=112000, grad_norm=0.40150323510169983, loss=2.825309991836548
I0921 11:16:18.320088 140613218989888 spec.py:320] Evaluating on the training split.
I0921 11:16:25.726504 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 11:16:36.641371 140613218989888 spec.py:348] Evaluating on the test split.
I0921 11:16:38.998124 140613218989888 submission_runner.py:376] Time since start: 39367.33s, 	Step: 112157, 	{'train/accuracy': 0.8016581535339355, 'train/loss': 1.010259747505188, 'validation/accuracy': 0.7116000056266785, 'validation/loss': 1.3901562690734863, 'validation/num_examples': 50000, 'test/accuracy': 0.5875000357627869, 'test/loss': 2.0190460681915283, 'test/num_examples': 10000, 'score': 37812.05665755272, 'total_duration': 39367.32677149773, 'accumulated_submission_time': 37812.05665755272, 'accumulated_eval_time': 1550.7734966278076, 'accumulated_logging_time': 2.724013090133667}
I0921 11:16:39.035213 140446164547328 logging_writer.py:48] [112157] accumulated_eval_time=1550.773497, accumulated_logging_time=2.724013, accumulated_submission_time=37812.056658, global_step=112157, preemption_count=0, score=37812.056658, test/accuracy=0.587500, test/loss=2.019046, test/num_examples=10000, total_duration=39367.326771, train/accuracy=0.801658, train/loss=1.010260, validation/accuracy=0.711600, validation/loss=1.390156, validation/num_examples=50000
I0921 11:18:34.788689 140446172940032 logging_writer.py:48] [112500] global_step=112500, grad_norm=0.4555036723613739, loss=2.971369743347168
I0921 11:21:23.017826 140446164547328 logging_writer.py:48] [113000] global_step=113000, grad_norm=0.4386817216873169, loss=2.94100022315979
I0921 11:24:11.232714 140446172940032 logging_writer.py:48] [113500] global_step=113500, grad_norm=0.4251370131969452, loss=2.850231170654297
I0921 11:25:09.185428 140613218989888 spec.py:320] Evaluating on the training split.
I0921 11:25:16.568897 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 11:25:27.772550 140613218989888 spec.py:348] Evaluating on the test split.
I0921 11:25:30.100831 140613218989888 submission_runner.py:376] Time since start: 39898.43s, 	Step: 113674, 	{'train/accuracy': 0.8226243257522583, 'train/loss': 0.9075947999954224, 'validation/accuracy': 0.7247599959373474, 'validation/loss': 1.3018537759780884, 'validation/num_examples': 50000, 'test/accuracy': 0.6044000387191772, 'test/loss': 1.9077553749084473, 'test/num_examples': 10000, 'score': 38322.17178297043, 'total_duration': 39898.42949771881, 'accumulated_submission_time': 38322.17178297043, 'accumulated_eval_time': 1571.6888778209686, 'accumulated_logging_time': 2.7724108695983887}
I0921 11:25:30.127835 140446164547328 logging_writer.py:48] [113674] accumulated_eval_time=1571.688878, accumulated_logging_time=2.772411, accumulated_submission_time=38322.171783, global_step=113674, preemption_count=0, score=38322.171783, test/accuracy=0.604400, test/loss=1.907755, test/num_examples=10000, total_duration=39898.429498, train/accuracy=0.822624, train/loss=0.907595, validation/accuracy=0.724760, validation/loss=1.301854, validation/num_examples=50000
I0921 11:27:20.137410 140446990817024 logging_writer.py:48] [114000] global_step=114000, grad_norm=0.439495712518692, loss=2.854207992553711
I0921 11:30:08.412706 140446164547328 logging_writer.py:48] [114500] global_step=114500, grad_norm=0.439163476228714, loss=2.8301994800567627
I0921 11:32:56.617580 140446990817024 logging_writer.py:48] [115000] global_step=115000, grad_norm=0.46541091799736023, loss=2.8605544567108154
I0921 11:34:00.265231 140613218989888 spec.py:320] Evaluating on the training split.
I0921 11:34:07.764834 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 11:34:18.826209 140613218989888 spec.py:348] Evaluating on the test split.
I0921 11:34:21.179024 140613218989888 submission_runner.py:376] Time since start: 40429.51s, 	Step: 115191, 	{'train/accuracy': 0.8444873690605164, 'train/loss': 0.816093921661377, 'validation/accuracy': 0.7221999764442444, 'validation/loss': 1.3223457336425781, 'validation/num_examples': 50000, 'test/accuracy': 0.5949000120162964, 'test/loss': 1.955386757850647, 'test/num_examples': 10000, 'score': 38832.27325510979, 'total_duration': 40429.50769138336, 'accumulated_submission_time': 38832.27325510979, 'accumulated_eval_time': 1592.6026391983032, 'accumulated_logging_time': 2.8115036487579346}
I0921 11:34:21.206783 140446172940032 logging_writer.py:48] [115191] accumulated_eval_time=1592.602639, accumulated_logging_time=2.811504, accumulated_submission_time=38832.273255, global_step=115191, preemption_count=0, score=38832.273255, test/accuracy=0.594900, test/loss=1.955387, test/num_examples=10000, total_duration=40429.507691, train/accuracy=0.844487, train/loss=0.816094, validation/accuracy=0.722200, validation/loss=1.322346, validation/num_examples=50000
I0921 11:36:05.464175 140446235883264 logging_writer.py:48] [115500] global_step=115500, grad_norm=0.44423046708106995, loss=2.813657283782959
I0921 11:38:53.664579 140446172940032 logging_writer.py:48] [116000] global_step=116000, grad_norm=0.4563106894493103, loss=2.839176893234253
I0921 11:41:41.902931 140446235883264 logging_writer.py:48] [116500] global_step=116500, grad_norm=0.4576534628868103, loss=2.819610118865967
I0921 11:42:51.261462 140613218989888 spec.py:320] Evaluating on the training split.
I0921 11:42:58.750078 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 11:43:09.573594 140613218989888 spec.py:348] Evaluating on the test split.
I0921 11:43:11.941916 140613218989888 submission_runner.py:376] Time since start: 40960.27s, 	Step: 116708, 	{'train/accuracy': 0.8449656963348389, 'train/loss': 0.8320600986480713, 'validation/accuracy': 0.7335399985313416, 'validation/loss': 1.2946419715881348, 'validation/num_examples': 50000, 'test/accuracy': 0.6045000553131104, 'test/loss': 1.9058303833007812, 'test/num_examples': 10000, 'score': 39342.29028558731, 'total_duration': 40960.27058124542, 'accumulated_submission_time': 39342.29028558731, 'accumulated_eval_time': 1613.283058643341, 'accumulated_logging_time': 2.853027105331421}
I0921 11:43:11.969014 140447007602432 logging_writer.py:48] [116708] accumulated_eval_time=1613.283059, accumulated_logging_time=2.853027, accumulated_submission_time=39342.290286, global_step=116708, preemption_count=0, score=39342.290286, test/accuracy=0.604500, test/loss=1.905830, test/num_examples=10000, total_duration=40960.270581, train/accuracy=0.844966, train/loss=0.832060, validation/accuracy=0.733540, validation/loss=1.294642, validation/num_examples=50000
I0921 11:44:50.507589 140447015995136 logging_writer.py:48] [117000] global_step=117000, grad_norm=0.44735467433929443, loss=2.7930169105529785
I0921 11:47:38.697360 140447007602432 logging_writer.py:48] [117500] global_step=117500, grad_norm=0.4723086953163147, loss=2.8099725246429443
I0921 11:50:26.867938 140447015995136 logging_writer.py:48] [118000] global_step=118000, grad_norm=0.4435904622077942, loss=2.7936789989471436
I0921 11:51:41.973230 140613218989888 spec.py:320] Evaluating on the training split.
I0921 11:51:49.403145 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 11:52:00.418040 140613218989888 spec.py:348] Evaluating on the test split.
I0921 11:52:02.753342 140613218989888 submission_runner.py:376] Time since start: 41491.08s, 	Step: 118225, 	{'train/accuracy': 0.8530173897743225, 'train/loss': 0.795059084892273, 'validation/accuracy': 0.7384399771690369, 'validation/loss': 1.2515661716461182, 'validation/num_examples': 50000, 'test/accuracy': 0.6126000285148621, 'test/loss': 1.862630009651184, 'test/num_examples': 10000, 'score': 39852.26021718979, 'total_duration': 41491.08199930191, 'accumulated_submission_time': 39852.26021718979, 'accumulated_eval_time': 1634.0631339550018, 'accumulated_logging_time': 2.8905999660491943}
I0921 11:52:02.780467 140446164547328 logging_writer.py:48] [118225] accumulated_eval_time=1634.063134, accumulated_logging_time=2.890600, accumulated_submission_time=39852.260217, global_step=118225, preemption_count=0, score=39852.260217, test/accuracy=0.612600, test/loss=1.862630, test/num_examples=10000, total_duration=41491.081999, train/accuracy=0.853017, train/loss=0.795059, validation/accuracy=0.738440, validation/loss=1.251566, validation/num_examples=50000
I0921 11:53:35.515049 140446172940032 logging_writer.py:48] [118500] global_step=118500, grad_norm=0.4721122682094574, loss=2.805293321609497
I0921 11:56:23.712467 140446164547328 logging_writer.py:48] [119000] global_step=119000, grad_norm=0.5054395198822021, loss=2.8253746032714844
I0921 11:59:11.994188 140446172940032 logging_writer.py:48] [119500] global_step=119500, grad_norm=0.47474104166030884, loss=2.7224984169006348
I0921 12:00:32.821279 140613218989888 spec.py:320] Evaluating on the training split.
I0921 12:00:40.154464 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 12:00:51.335937 140613218989888 spec.py:348] Evaluating on the test split.
I0921 12:00:53.710134 140613218989888 submission_runner.py:376] Time since start: 42022.04s, 	Step: 119742, 	{'train/accuracy': 0.8602120280265808, 'train/loss': 0.7721146941184998, 'validation/accuracy': 0.7487399578094482, 'validation/loss': 1.2245062589645386, 'validation/num_examples': 50000, 'test/accuracy': 0.6221000552177429, 'test/loss': 1.824009895324707, 'test/num_examples': 10000, 'score': 40362.266666173935, 'total_duration': 42022.038808345795, 'accumulated_submission_time': 40362.266666173935, 'accumulated_eval_time': 1654.951964378357, 'accumulated_logging_time': 2.9282946586608887}
I0921 12:00:53.737088 140447015995136 logging_writer.py:48] [119742] accumulated_eval_time=1654.951964, accumulated_logging_time=2.928295, accumulated_submission_time=40362.266666, global_step=119742, preemption_count=0, score=40362.266666, test/accuracy=0.622100, test/loss=1.824010, test/num_examples=10000, total_duration=42022.038808, train/accuracy=0.860212, train/loss=0.772115, validation/accuracy=0.748740, validation/loss=1.224506, validation/num_examples=50000
I0921 12:02:20.726820 140447024387840 logging_writer.py:48] [120000] global_step=120000, grad_norm=0.46144768595695496, loss=2.7243752479553223
I0921 12:05:08.922381 140447015995136 logging_writer.py:48] [120500] global_step=120500, grad_norm=0.45606303215026855, loss=2.726940155029297
I0921 12:07:57.146197 140447024387840 logging_writer.py:48] [121000] global_step=121000, grad_norm=0.477328360080719, loss=2.7445383071899414
I0921 12:09:24.045356 140613218989888 spec.py:320] Evaluating on the training split.
I0921 12:09:31.446467 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 12:09:42.576467 140613218989888 spec.py:348] Evaluating on the test split.
I0921 12:09:44.877758 140613218989888 submission_runner.py:376] Time since start: 42553.21s, 	Step: 121260, 	{'train/accuracy': 0.8625637292861938, 'train/loss': 0.7528239488601685, 'validation/accuracy': 0.7497400045394897, 'validation/loss': 1.2097290754318237, 'validation/num_examples': 50000, 'test/accuracy': 0.6291000247001648, 'test/loss': 1.8062241077423096, 'test/num_examples': 10000, 'score': 40872.539221048355, 'total_duration': 42553.2064037323, 'accumulated_submission_time': 40872.539221048355, 'accumulated_eval_time': 1675.7843565940857, 'accumulated_logging_time': 2.9671173095703125}
I0921 12:09:44.905281 140446172940032 logging_writer.py:48] [121260] accumulated_eval_time=1675.784357, accumulated_logging_time=2.967117, accumulated_submission_time=40872.539221, global_step=121260, preemption_count=0, score=40872.539221, test/accuracy=0.629100, test/loss=1.806224, test/num_examples=10000, total_duration=42553.206404, train/accuracy=0.862564, train/loss=0.752824, validation/accuracy=0.749740, validation/loss=1.209729, validation/num_examples=50000
I0921 12:11:06.013838 140446235883264 logging_writer.py:48] [121500] global_step=121500, grad_norm=0.5014413595199585, loss=2.719942092895508
I0921 12:13:54.251407 140446172940032 logging_writer.py:48] [122000] global_step=122000, grad_norm=0.4988298714160919, loss=2.7533340454101562
I0921 12:16:42.483973 140446235883264 logging_writer.py:48] [122500] global_step=122500, grad_norm=0.4802260100841522, loss=2.7410387992858887
I0921 12:18:15.067255 140613218989888 spec.py:320] Evaluating on the training split.
I0921 12:18:22.686345 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 12:18:34.021543 140613218989888 spec.py:348] Evaluating on the test split.
I0921 12:18:36.352809 140613218989888 submission_runner.py:376] Time since start: 43084.68s, 	Step: 122777, 	{'train/accuracy': 0.8712930083274841, 'train/loss': 0.7350925207138062, 'validation/accuracy': 0.755079984664917, 'validation/loss': 1.2087671756744385, 'validation/num_examples': 50000, 'test/accuracy': 0.6279000043869019, 'test/loss': 1.8225747346878052, 'test/num_examples': 10000, 'score': 41382.66648173332, 'total_duration': 43084.681473493576, 'accumulated_submission_time': 41382.66648173332, 'accumulated_eval_time': 1697.069876909256, 'accumulated_logging_time': 3.0055551528930664}
I0921 12:18:36.384244 140446164547328 logging_writer.py:48] [122777] accumulated_eval_time=1697.069877, accumulated_logging_time=3.005555, accumulated_submission_time=41382.666482, global_step=122777, preemption_count=0, score=41382.666482, test/accuracy=0.627900, test/loss=1.822575, test/num_examples=10000, total_duration=43084.681473, train/accuracy=0.871293, train/loss=0.735093, validation/accuracy=0.755080, validation/loss=1.208767, validation/num_examples=50000
I0921 12:19:51.721850 140446172940032 logging_writer.py:48] [123000] global_step=123000, grad_norm=0.5123284459114075, loss=2.6670193672180176
I0921 12:22:39.985218 140446164547328 logging_writer.py:48] [123500] global_step=123500, grad_norm=0.49787676334381104, loss=2.721726417541504
I0921 12:25:28.178071 140446172940032 logging_writer.py:48] [124000] global_step=124000, grad_norm=0.4980223774909973, loss=2.636090040206909
I0921 12:27:06.527858 140613218989888 spec.py:320] Evaluating on the training split.
I0921 12:27:13.949364 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 12:27:25.022971 140613218989888 spec.py:348] Evaluating on the test split.
I0921 12:27:27.364357 140613218989888 submission_runner.py:376] Time since start: 43615.69s, 	Step: 124294, 	{'train/accuracy': 0.8966438174247742, 'train/loss': 0.6295205950737, 'validation/accuracy': 0.7619999647140503, 'validation/loss': 1.1587510108947754, 'validation/num_examples': 50000, 'test/accuracy': 0.638200044631958, 'test/loss': 1.7649061679840088, 'test/num_examples': 10000, 'score': 41892.77513337135, 'total_duration': 43615.692863702774, 'accumulated_submission_time': 41892.77513337135, 'accumulated_eval_time': 1717.9061884880066, 'accumulated_logging_time': 3.0478503704071045}
I0921 12:27:27.392621 140446172940032 logging_writer.py:48] [124294] accumulated_eval_time=1717.906188, accumulated_logging_time=3.047850, accumulated_submission_time=41892.775133, global_step=124294, preemption_count=0, score=41892.775133, test/accuracy=0.638200, test/loss=1.764906, test/num_examples=10000, total_duration=43615.692864, train/accuracy=0.896644, train/loss=0.629521, validation/accuracy=0.762000, validation/loss=1.158751, validation/num_examples=50000
I0921 12:28:37.050604 140446235883264 logging_writer.py:48] [124500] global_step=124500, grad_norm=0.4940033257007599, loss=2.627864122390747
I0921 12:31:25.290827 140446172940032 logging_writer.py:48] [125000] global_step=125000, grad_norm=0.524196207523346, loss=2.6773743629455566
I0921 12:34:13.525868 140446235883264 logging_writer.py:48] [125500] global_step=125500, grad_norm=0.529374897480011, loss=2.7231619358062744
I0921 12:35:57.567438 140613218989888 spec.py:320] Evaluating on the training split.
I0921 12:36:05.023649 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 12:36:15.846383 140613218989888 spec.py:348] Evaluating on the test split.
I0921 12:36:18.143808 140613218989888 submission_runner.py:376] Time since start: 44146.47s, 	Step: 125811, 	{'train/accuracy': 0.9040776491165161, 'train/loss': 0.600990355014801, 'validation/accuracy': 0.7697799801826477, 'validation/loss': 1.1348940134048462, 'validation/num_examples': 50000, 'test/accuracy': 0.6457000374794006, 'test/loss': 1.7272042036056519, 'test/num_examples': 10000, 'score': 42402.91263651848, 'total_duration': 44146.47246336937, 'accumulated_submission_time': 42402.91263651848, 'accumulated_eval_time': 1738.482519865036, 'accumulated_logging_time': 3.0896189212799072}
I0921 12:36:18.171232 140446164547328 logging_writer.py:48] [125811] accumulated_eval_time=1738.482520, accumulated_logging_time=3.089619, accumulated_submission_time=42402.912637, global_step=125811, preemption_count=0, score=42402.912637, test/accuracy=0.645700, test/loss=1.727204, test/num_examples=10000, total_duration=44146.472463, train/accuracy=0.904078, train/loss=0.600990, validation/accuracy=0.769780, validation/loss=1.134894, validation/num_examples=50000
I0921 12:37:21.948217 140446990817024 logging_writer.py:48] [126000] global_step=126000, grad_norm=0.49362578988075256, loss=2.58986234664917
I0921 12:40:10.133454 140446164547328 logging_writer.py:48] [126500] global_step=126500, grad_norm=0.5131782293319702, loss=2.622692823410034
I0921 12:42:58.349354 140446990817024 logging_writer.py:48] [127000] global_step=127000, grad_norm=0.4985995292663574, loss=2.590228796005249
I0921 12:44:48.465519 140613218989888 spec.py:320] Evaluating on the training split.
I0921 12:44:55.752629 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 12:45:06.755289 140613218989888 spec.py:348] Evaluating on the test split.
I0921 12:45:09.073571 140613218989888 submission_runner.py:376] Time since start: 44677.40s, 	Step: 127329, 	{'train/accuracy': 0.9037786722183228, 'train/loss': 0.5991418957710266, 'validation/accuracy': 0.7731399536132812, 'validation/loss': 1.1176573038101196, 'validation/num_examples': 50000, 'test/accuracy': 0.6514000296592712, 'test/loss': 1.7044885158538818, 'test/num_examples': 10000, 'score': 42913.17221546173, 'total_duration': 44677.40223860741, 'accumulated_submission_time': 42913.17221546173, 'accumulated_eval_time': 1759.0905449390411, 'accumulated_logging_time': 3.127929210662842}
I0921 12:45:09.101562 140446235883264 logging_writer.py:48] [127329] accumulated_eval_time=1759.090545, accumulated_logging_time=3.127929, accumulated_submission_time=42913.172215, global_step=127329, preemption_count=0, score=42913.172215, test/accuracy=0.651400, test/loss=1.704489, test/num_examples=10000, total_duration=44677.402239, train/accuracy=0.903779, train/loss=0.599142, validation/accuracy=0.773140, validation/loss=1.117657, validation/num_examples=50000
I0921 12:46:07.038818 140446999209728 logging_writer.py:48] [127500] global_step=127500, grad_norm=0.4914441406726837, loss=2.542541027069092
I0921 12:48:55.276893 140446235883264 logging_writer.py:48] [128000] global_step=128000, grad_norm=0.5121180415153503, loss=2.6166558265686035
I0921 12:51:43.483208 140446999209728 logging_writer.py:48] [128500] global_step=128500, grad_norm=0.5157044529914856, loss=2.6048004627227783
I0921 12:53:39.261154 140613218989888 spec.py:320] Evaluating on the training split.
I0921 12:53:46.759632 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 12:53:57.568526 140613218989888 spec.py:348] Evaluating on the test split.
I0921 12:53:59.890571 140613218989888 submission_runner.py:376] Time since start: 45208.22s, 	Step: 128846, 	{'train/accuracy': 0.9041772484779358, 'train/loss': 0.5988971590995789, 'validation/accuracy': 0.7734000086784363, 'validation/loss': 1.1173559427261353, 'validation/num_examples': 50000, 'test/accuracy': 0.6503000259399414, 'test/loss': 1.7053135633468628, 'test/num_examples': 10000, 'score': 43423.294951438904, 'total_duration': 45208.21922135353, 'accumulated_submission_time': 43423.294951438904, 'accumulated_eval_time': 1779.719927072525, 'accumulated_logging_time': 3.1692354679107666}
I0921 12:53:59.924060 140446990817024 logging_writer.py:48] [128846] accumulated_eval_time=1779.719927, accumulated_logging_time=3.169235, accumulated_submission_time=43423.294951, global_step=128846, preemption_count=0, score=43423.294951, test/accuracy=0.650300, test/loss=1.705314, test/num_examples=10000, total_duration=45208.219221, train/accuracy=0.904177, train/loss=0.598897, validation/accuracy=0.773400, validation/loss=1.117356, validation/num_examples=50000
I0921 12:54:52.039238 140447015995136 logging_writer.py:48] [129000] global_step=129000, grad_norm=0.5106645822525024, loss=2.6038098335266113
I0921 12:57:40.032587 140446990817024 logging_writer.py:48] [129500] global_step=129500, grad_norm=0.5019254684448242, loss=2.5738179683685303
I0921 13:00:28.269305 140447015995136 logging_writer.py:48] [130000] global_step=130000, grad_norm=0.5092782974243164, loss=2.593531370162964
I0921 13:02:30.119980 140613218989888 spec.py:320] Evaluating on the training split.
I0921 13:02:37.503903 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 13:02:48.441857 140613218989888 spec.py:348] Evaluating on the test split.
I0921 13:02:50.778425 140613218989888 submission_runner.py:376] Time since start: 45739.11s, 	Step: 130364, 	{'train/accuracy': 0.9042171239852905, 'train/loss': 0.5978606939315796, 'validation/accuracy': 0.7737999558448792, 'validation/loss': 1.1178109645843506, 'validation/num_examples': 50000, 'test/accuracy': 0.6497000455856323, 'test/loss': 1.7077109813690186, 'test/num_examples': 10000, 'score': 43933.45530128479, 'total_duration': 45739.10709118843, 'accumulated_submission_time': 43933.45530128479, 'accumulated_eval_time': 1800.3783478736877, 'accumulated_logging_time': 3.214592933654785}
I0921 13:02:50.807492 140446172940032 logging_writer.py:48] [130364] accumulated_eval_time=1800.378348, accumulated_logging_time=3.214593, accumulated_submission_time=43933.455301, global_step=130364, preemption_count=0, score=43933.455301, test/accuracy=0.649700, test/loss=1.707711, test/num_examples=10000, total_duration=45739.107091, train/accuracy=0.904217, train/loss=0.597861, validation/accuracy=0.773800, validation/loss=1.117811, validation/num_examples=50000
I0921 13:03:36.936337 140446235883264 logging_writer.py:48] [130500] global_step=130500, grad_norm=0.5072513222694397, loss=2.5599114894866943
I0921 13:06:25.160799 140446172940032 logging_writer.py:48] [131000] global_step=131000, grad_norm=0.5198997259140015, loss=2.608139753341675
I0921 13:09:13.385572 140446235883264 logging_writer.py:48] [131500] global_step=131500, grad_norm=0.5022709369659424, loss=2.546698808670044
I0921 13:11:20.994343 140613218989888 spec.py:320] Evaluating on the training split.
I0921 13:11:28.301138 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 13:11:39.310699 140613218989888 spec.py:348] Evaluating on the test split.
I0921 13:11:41.654966 140613218989888 submission_runner.py:376] Time since start: 46269.98s, 	Step: 131881, 	{'train/accuracy': 0.9047752022743225, 'train/loss': 0.596454918384552, 'validation/accuracy': 0.7737599611282349, 'validation/loss': 1.1194186210632324, 'validation/num_examples': 50000, 'test/accuracy': 0.6518000364303589, 'test/loss': 1.706139326095581, 'test/num_examples': 10000, 'score': 44443.60584616661, 'total_duration': 46269.98361802101, 'accumulated_submission_time': 44443.60584616661, 'accumulated_eval_time': 1821.038932800293, 'accumulated_logging_time': 3.2563745975494385}
I0921 13:11:41.693323 140446164547328 logging_writer.py:48] [131881] accumulated_eval_time=1821.038933, accumulated_logging_time=3.256375, accumulated_submission_time=44443.605846, global_step=131881, preemption_count=0, score=44443.605846, test/accuracy=0.651800, test/loss=1.706139, test/num_examples=10000, total_duration=46269.983618, train/accuracy=0.904775, train/loss=0.596455, validation/accuracy=0.773760, validation/loss=1.119419, validation/num_examples=50000
I0921 13:12:22.075694 140447007602432 logging_writer.py:48] [132000] global_step=132000, grad_norm=0.5130009651184082, loss=2.6078286170959473
I0921 13:15:10.348581 140446164547328 logging_writer.py:48] [132500] global_step=132500, grad_norm=0.5096624493598938, loss=2.544175386428833
I0921 13:17:58.672967 140447007602432 logging_writer.py:48] [133000] global_step=133000, grad_norm=0.5292454957962036, loss=2.6137123107910156
I0921 13:20:11.692404 140613218989888 spec.py:320] Evaluating on the training split.
I0921 13:20:18.954839 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 13:20:29.982927 140613218989888 spec.py:348] Evaluating on the test split.
I0921 13:20:32.312407 140613218989888 submission_runner.py:376] Time since start: 46800.64s, 	Step: 133397, 	{'train/accuracy': 0.9069873690605164, 'train/loss': 0.5902242064476013, 'validation/accuracy': 0.7743600010871887, 'validation/loss': 1.1142349243164062, 'validation/num_examples': 50000, 'test/accuracy': 0.6517000198364258, 'test/loss': 1.7023909091949463, 'test/num_examples': 10000, 'score': 44953.56882548332, 'total_duration': 46800.64102816582, 'accumulated_submission_time': 44953.56882548332, 'accumulated_eval_time': 1841.6588699817657, 'accumulated_logging_time': 3.307283401489258}
I0921 13:20:32.342415 140446235883264 logging_writer.py:48] [133397] accumulated_eval_time=1841.658870, accumulated_logging_time=3.307283, accumulated_submission_time=44953.568825, global_step=133397, preemption_count=0, score=44953.568825, test/accuracy=0.651700, test/loss=1.702391, test/num_examples=10000, total_duration=46800.641028, train/accuracy=0.906987, train/loss=0.590224, validation/accuracy=0.774360, validation/loss=1.114235, validation/num_examples=50000
I0921 13:21:07.361112 140446990817024 logging_writer.py:48] [133500] global_step=133500, grad_norm=0.491967111825943, loss=2.551879405975342
I0921 13:23:55.557769 140446235883264 logging_writer.py:48] [134000] global_step=134000, grad_norm=0.49737784266471863, loss=2.5554609298706055
I0921 13:26:43.744883 140446990817024 logging_writer.py:48] [134500] global_step=134500, grad_norm=0.5038657784461975, loss=2.55993390083313
I0921 13:29:02.415999 140613218989888 spec.py:320] Evaluating on the training split.
I0921 13:29:09.785510 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 13:29:20.875192 140613218989888 spec.py:348] Evaluating on the test split.
I0921 13:29:23.216546 140613218989888 submission_runner.py:376] Time since start: 47331.54s, 	Step: 134914, 	{'train/accuracy': 0.9077845811843872, 'train/loss': 0.5867584943771362, 'validation/accuracy': 0.7740599513053894, 'validation/loss': 1.1166901588439941, 'validation/num_examples': 50000, 'test/accuracy': 0.650600016117096, 'test/loss': 1.704883098602295, 'test/num_examples': 10000, 'score': 45463.606588840485, 'total_duration': 47331.54493737221, 'accumulated_submission_time': 45463.606588840485, 'accumulated_eval_time': 1862.45911693573, 'accumulated_logging_time': 3.349576950073242}
I0921 13:29:23.244864 140447007602432 logging_writer.py:48] [134914] accumulated_eval_time=1862.459117, accumulated_logging_time=3.349577, accumulated_submission_time=45463.606589, global_step=134914, preemption_count=0, score=45463.606589, test/accuracy=0.650600, test/loss=1.704883, test/num_examples=10000, total_duration=47331.544937, train/accuracy=0.907785, train/loss=0.586758, validation/accuracy=0.774060, validation/loss=1.116690, validation/num_examples=50000
I0921 13:29:52.531560 140447015995136 logging_writer.py:48] [135000] global_step=135000, grad_norm=0.5038214921951294, loss=2.5682919025421143
I0921 13:32:40.771243 140447007602432 logging_writer.py:48] [135500] global_step=135500, grad_norm=0.4998209774494171, loss=2.5635039806365967
I0921 13:35:29.033824 140447015995136 logging_writer.py:48] [136000] global_step=136000, grad_norm=0.5346813797950745, loss=2.5982794761657715
I0921 13:37:53.429741 140613218989888 spec.py:320] Evaluating on the training split.
I0921 13:38:00.813452 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 13:38:11.845486 140613218989888 spec.py:348] Evaluating on the test split.
I0921 13:38:14.207064 140613218989888 submission_runner.py:376] Time since start: 47862.54s, 	Step: 136431, 	{'train/accuracy': 0.9085220098495483, 'train/loss': 0.5823172330856323, 'validation/accuracy': 0.7741599678993225, 'validation/loss': 1.11417818069458, 'validation/num_examples': 50000, 'test/accuracy': 0.6508000493049622, 'test/loss': 1.7033154964447021, 'test/num_examples': 10000, 'score': 45973.756283283234, 'total_duration': 47862.535675525665, 'accumulated_submission_time': 45973.756283283234, 'accumulated_eval_time': 1883.2363646030426, 'accumulated_logging_time': 3.389491081237793}
I0921 13:38:14.251925 140445296359168 logging_writer.py:48] [136431] accumulated_eval_time=1883.236365, accumulated_logging_time=3.389491, accumulated_submission_time=45973.756283, global_step=136431, preemption_count=0, score=45973.756283, test/accuracy=0.650800, test/loss=1.703315, test/num_examples=10000, total_duration=47862.535676, train/accuracy=0.908522, train/loss=0.582317, validation/accuracy=0.774160, validation/loss=1.114178, validation/num_examples=50000
I0921 13:38:37.859861 140446164547328 logging_writer.py:48] [136500] global_step=136500, grad_norm=0.4955670237541199, loss=2.5540125370025635
I0921 13:41:26.086287 140445296359168 logging_writer.py:48] [137000] global_step=137000, grad_norm=0.5089892745018005, loss=2.5911262035369873
I0921 13:44:14.296378 140446164547328 logging_writer.py:48] [137500] global_step=137500, grad_norm=0.5266187191009521, loss=2.6204895973205566
I0921 13:46:44.450705 140613218989888 spec.py:320] Evaluating on the training split.
I0921 13:46:51.699654 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 13:47:02.837374 140613218989888 spec.py:348] Evaluating on the test split.
I0921 13:47:05.154085 140613218989888 submission_runner.py:376] Time since start: 48393.48s, 	Step: 137948, 	{'train/accuracy': 0.9083625674247742, 'train/loss': 0.5867701172828674, 'validation/accuracy': 0.7748199701309204, 'validation/loss': 1.1123692989349365, 'validation/num_examples': 50000, 'test/accuracy': 0.6527000069618225, 'test/loss': 1.7015321254730225, 'test/num_examples': 10000, 'score': 46483.91411471367, 'total_duration': 48393.48275065422, 'accumulated_submission_time': 46483.91411471367, 'accumulated_eval_time': 1903.939735174179, 'accumulated_logging_time': 3.4515347480773926}
I0921 13:47:05.183202 140446999209728 logging_writer.py:48] [137948] accumulated_eval_time=1903.939735, accumulated_logging_time=3.451535, accumulated_submission_time=46483.914115, global_step=137948, preemption_count=0, score=46483.914115, test/accuracy=0.652700, test/loss=1.701532, test/num_examples=10000, total_duration=48393.482751, train/accuracy=0.908363, train/loss=0.586770, validation/accuracy=0.774820, validation/loss=1.112369, validation/num_examples=50000
I0921 13:47:22.979122 140447007602432 logging_writer.py:48] [138000] global_step=138000, grad_norm=0.5181692242622375, loss=2.6144001483917236
I0921 13:50:11.154399 140446999209728 logging_writer.py:48] [138500] global_step=138500, grad_norm=0.5204424858093262, loss=2.5774080753326416
I0921 13:52:59.338557 140447007602432 logging_writer.py:48] [139000] global_step=139000, grad_norm=0.5090790390968323, loss=2.6189193725585938
I0921 13:55:35.230334 140613218989888 spec.py:320] Evaluating on the training split.
I0921 13:55:42.543727 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 13:55:53.539571 140613218989888 spec.py:348] Evaluating on the test split.
I0921 13:55:55.854072 140613218989888 submission_runner.py:376] Time since start: 48924.18s, 	Step: 139465, 	{'train/accuracy': 0.9058314561843872, 'train/loss': 0.589944064617157, 'validation/accuracy': 0.7748199701309204, 'validation/loss': 1.1144973039627075, 'validation/num_examples': 50000, 'test/accuracy': 0.6518000364303589, 'test/loss': 1.702471375465393, 'test/num_examples': 10000, 'score': 46993.92519116402, 'total_duration': 48924.18271780014, 'accumulated_submission_time': 46993.92519116402, 'accumulated_eval_time': 1924.5634286403656, 'accumulated_logging_time': 3.4931278228759766}
I0921 13:55:55.883570 140446172940032 logging_writer.py:48] [139465] accumulated_eval_time=1924.563429, accumulated_logging_time=3.493128, accumulated_submission_time=46993.925191, global_step=139465, preemption_count=0, score=46993.925191, test/accuracy=0.651800, test/loss=1.702471, test/num_examples=10000, total_duration=48924.182718, train/accuracy=0.905831, train/loss=0.589944, validation/accuracy=0.774820, validation/loss=1.114497, validation/num_examples=50000
I0921 13:56:08.022682 140446235883264 logging_writer.py:48] [139500] global_step=139500, grad_norm=0.5096421837806702, loss=2.5551557540893555
I0921 13:58:55.684282 140613218989888 spec.py:320] Evaluating on the training split.
I0921 13:59:02.879670 140613218989888 spec.py:332] Evaluating on the validation split.
I0921 13:59:14.032296 140613218989888 spec.py:348] Evaluating on the test split.
I0921 13:59:16.658773 140613218989888 submission_runner.py:376] Time since start: 49124.99s, 	Step: 140000, 	{'train/accuracy': 0.9089205861091614, 'train/loss': 0.5751429796218872, 'validation/accuracy': 0.7743399739265442, 'validation/loss': 1.1133061647415161, 'validation/num_examples': 50000, 'test/accuracy': 0.6511000394821167, 'test/loss': 1.7018169164657593, 'test/num_examples': 10000, 'score': 47173.7046084404, 'total_duration': 49124.98744869232, 'accumulated_submission_time': 47173.7046084404, 'accumulated_eval_time': 1945.5379238128662, 'accumulated_logging_time': 3.5352821350097656}
I0921 13:59:16.683372 140446164547328 logging_writer.py:48] [140000] accumulated_eval_time=1945.537924, accumulated_logging_time=3.535282, accumulated_submission_time=47173.704608, global_step=140000, preemption_count=0, score=47173.704608, test/accuracy=0.651100, test/loss=1.701817, test/num_examples=10000, total_duration=49124.987449, train/accuracy=0.908921, train/loss=0.575143, validation/accuracy=0.774340, validation/loss=1.113306, validation/num_examples=50000
I0921 13:59:16.705051 140446172940032 logging_writer.py:48] [140000] global_step=140000, preemption_count=0, score=47173.704608
I0921 13:59:16.913259 140613218989888 checkpoints.py:490] Saving checkpoint at step: 140000
I0921 13:59:17.640264 140613218989888 checkpoints.py:422] Saved checkpoint at /experiment_runs/targets_check_jax_run_02/momentum_run_0/imagenet_resnet_jax/trial_1/checkpoint_140000
I0921 13:59:17.657586 140613218989888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/targets_check_jax_run_02/momentum_run_0/imagenet_resnet_jax/trial_1/checkpoint_140000.
I0921 13:59:18.419122 140613218989888 submission_runner.py:540] Tuning trial 1/1
I0921 13:59:18.419376 140613218989888 submission_runner.py:541] Hyperparameters: Hyperparameters(learning_rate=4.131896390902391, beta1=0.9274758113254791, beta2=0.9978504782314613, warmup_steps=6999, decay_steps_factor=0.9007765761611038, end_factor=0.001, weight_decay=5.6687777311501786e-06, label_smoothing=0.2)
I0921 13:59:18.422807 140613218989888 submission_runner.py:542] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0010363520123064518, 'train/loss': 6.91220760345459, 'validation/accuracy': 0.0008999999845400453, 'validation/loss': 6.911862373352051, 'validation/num_examples': 50000, 'test/accuracy': 0.0010999999940395355, 'test/loss': 6.912576198577881, 'test/num_examples': 10000, 'score': 63.42658305168152, 'total_duration': 110.48254609107971, 'accumulated_submission_time': 63.42658305168152, 'accumulated_eval_time': 47.05587124824524, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (1513, {'train/accuracy': 0.18600526452064514, 'train/loss': 4.260481357574463, 'validation/accuracy': 0.1713399887084961, 'validation/loss': 4.391124725341797, 'validation/num_examples': 50000, 'test/accuracy': 0.12350000441074371, 'test/loss': 4.809715270996094, 'test/num_examples': 10000, 'score': 573.5950057506561, 'total_duration': 638.4499394893646, 'accumulated_submission_time': 573.5950057506561, 'accumulated_eval_time': 64.79911708831787, 'accumulated_logging_time': 0.031407833099365234, 'global_step': 1513, 'preemption_count': 0}), (3028, {'train/accuracy': 0.3601522445678711, 'train/loss': 3.1906676292419434, 'validation/accuracy': 0.32725998759269714, 'validation/loss': 3.360729217529297, 'validation/num_examples': 50000, 'test/accuracy': 0.24540001153945923, 'test/loss': 3.9212749004364014, 'test/num_examples': 10000, 'score': 1083.5686395168304, 'total_duration': 1166.3747670650482, 'accumulated_submission_time': 1083.5686395168304, 'accumulated_eval_time': 82.69588994979858, 'accumulated_logging_time': 0.06120419502258301, 'global_step': 3028, 'preemption_count': 0}), (4545, {'train/accuracy': 0.4586256146430969, 'train/loss': 2.605865478515625, 'validation/accuracy': 0.42941999435424805, 'validation/loss': 2.7456960678100586, 'validation/num_examples': 50000, 'test/accuracy': 0.32360002398490906, 'test/loss': 3.4065797328948975, 'test/num_examples': 10000, 'score': 1593.8365013599396, 'total_duration': 1694.4938836097717, 'accumulated_submission_time': 1593.8365013599396, 'accumulated_eval_time': 100.49484872817993, 'accumulated_logging_time': 0.08878755569458008, 'global_step': 4545, 'preemption_count': 0}), (6062, {'train/accuracy': 0.48810186982154846, 'train/loss': 2.485229730606079, 'validation/accuracy': 0.46181997656822205, 'validation/loss': 2.6277108192443848, 'validation/num_examples': 50000, 'test/accuracy': 0.34790000319480896, 'test/loss': 3.319991111755371, 'test/num_examples': 10000, 'score': 2104.052232503891, 'total_duration': 2222.4931490421295, 'accumulated_submission_time': 2104.052232503891, 'accumulated_eval_time': 118.22181153297424, 'accumulated_logging_time': 0.12106847763061523, 'global_step': 6062, 'preemption_count': 0}), (7579, {'train/accuracy': 0.47576528787612915, 'train/loss': 2.582186222076416, 'validation/accuracy': 0.44533997774124146, 'validation/loss': 2.7355730533599854, 'validation/num_examples': 50000, 'test/accuracy': 0.35110002756118774, 'test/loss': 3.3165767192840576, 'test/num_examples': 10000, 'score': 2614.2272295951843, 'total_duration': 2750.6316063404083, 'accumulated_submission_time': 2614.2272295951843, 'accumulated_eval_time': 136.13150453567505, 'accumulated_logging_time': 0.15039396286010742, 'global_step': 7579, 'preemption_count': 0}), (9096, {'train/accuracy': 0.5944674611091614, 'train/loss': 1.9870927333831787, 'validation/accuracy': 0.5116599798202515, 'validation/loss': 2.362605333328247, 'validation/num_examples': 50000, 'test/accuracy': 0.39650002121925354, 'test/loss': 3.0199806690216064, 'test/num_examples': 10000, 'score': 3124.392338991165, 'total_duration': 3278.990958213806, 'accumulated_submission_time': 3124.392338991165, 'accumulated_eval_time': 154.27301621437073, 'accumulated_logging_time': 0.17804622650146484, 'global_step': 9096, 'preemption_count': 0}), (10610, {'train/accuracy': 0.5423110723495483, 'train/loss': 2.207017421722412, 'validation/accuracy': 0.49041998386383057, 'validation/loss': 2.4853177070617676, 'validation/num_examples': 50000, 'test/accuracy': 0.3785000145435333, 'test/loss': 3.1514739990234375, 'test/num_examples': 10000, 'score': 3634.58509683609, 'total_duration': 3807.321106672287, 'accumulated_submission_time': 3634.58509683609, 'accumulated_eval_time': 172.35921263694763, 'accumulated_logging_time': 0.20548152923583984, 'global_step': 10610, 'preemption_count': 0}), (12127, {'train/accuracy': 0.5005381107330322, 'train/loss': 2.4511353969573975, 'validation/accuracy': 0.46271997690200806, 'validation/loss': 2.652254343032837, 'validation/num_examples': 50000, 'test/accuracy': 0.3573000133037567, 'test/loss': 3.3161263465881348, 'test/num_examples': 10000, 'score': 4144.716547966003, 'total_duration': 4335.541543960571, 'accumulated_submission_time': 4144.716547966003, 'accumulated_eval_time': 190.38888955116272, 'accumulated_logging_time': 0.2405107021331787, 'global_step': 12127, 'preemption_count': 0}), (13644, {'train/accuracy': 0.5743383169174194, 'train/loss': 2.007390022277832, 'validation/accuracy': 0.5335999727249146, 'validation/loss': 2.203630208969116, 'validation/num_examples': 50000, 'test/accuracy': 0.4118000268936157, 'test/loss': 2.903945207595825, 'test/num_examples': 10000, 'score': 4654.771801948547, 'total_duration': 4863.552335500717, 'accumulated_submission_time': 4654.771801948547, 'accumulated_eval_time': 208.28665924072266, 'accumulated_logging_time': 0.2745518684387207, 'global_step': 13644, 'preemption_count': 0}), (15161, {'train/accuracy': 0.5954639315605164, 'train/loss': 1.9491528272628784, 'validation/accuracy': 0.553820013999939, 'validation/loss': 2.149799108505249, 'validation/num_examples': 50000, 'test/accuracy': 0.4392000138759613, 'test/loss': 2.7913265228271484, 'test/num_examples': 10000, 'score': 5164.86758518219, 'total_duration': 5391.45116686821, 'accumulated_submission_time': 5164.86758518219, 'accumulated_eval_time': 226.0329098701477, 'accumulated_logging_time': 0.3073427677154541, 'global_step': 15161, 'preemption_count': 0}), (16678, {'train/accuracy': 0.5875518321990967, 'train/loss': 1.9690172672271729, 'validation/accuracy': 0.5499599575996399, 'validation/loss': 2.139955520629883, 'validation/num_examples': 50000, 'test/accuracy': 0.43390002846717834, 'test/loss': 2.793609142303467, 'test/num_examples': 10000, 'score': 5674.9813821315765, 'total_duration': 5919.697226047516, 'accumulated_submission_time': 5674.9813821315765, 'accumulated_eval_time': 244.10775351524353, 'accumulated_logging_time': 0.3408012390136719, 'global_step': 16678, 'preemption_count': 0}), (18195, {'train/accuracy': 0.6247608065605164, 'train/loss': 1.8786145448684692, 'validation/accuracy': 0.5376799702644348, 'validation/loss': 2.266126871109009, 'validation/num_examples': 50000, 'test/accuracy': 0.42260003089904785, 'test/loss': 2.922790050506592, 'test/num_examples': 10000, 'score': 6185.04268860817, 'total_duration': 6447.771356105804, 'accumulated_submission_time': 6185.04268860817, 'accumulated_eval_time': 262.06218433380127, 'accumulated_logging_time': 0.37500429153442383, 'global_step': 18195, 'preemption_count': 0}), (19712, {'train/accuracy': 0.5977559089660645, 'train/loss': 1.9386297464370728, 'validation/accuracy': 0.5434799790382385, 'validation/loss': 2.188788652420044, 'validation/num_examples': 50000, 'test/accuracy': 0.4252000153064728, 'test/loss': 2.8603928089141846, 'test/num_examples': 10000, 'score': 6695.234313488007, 'total_duration': 6976.035272598267, 'accumulated_submission_time': 6695.234313488007, 'accumulated_eval_time': 280.07943201065063, 'accumulated_logging_time': 0.4057941436767578, 'global_step': 19712, 'preemption_count': 0}), (21230, {'train/accuracy': 0.6077407598495483, 'train/loss': 1.855846881866455, 'validation/accuracy': 0.5599799752235413, 'validation/loss': 2.086848497390747, 'validation/num_examples': 50000, 'test/accuracy': 0.43540000915527344, 'test/loss': 2.770585536956787, 'test/num_examples': 10000, 'score': 7205.501652479172, 'total_duration': 7504.6430513858795, 'accumulated_submission_time': 7205.501652479172, 'accumulated_eval_time': 298.3612427711487, 'accumulated_logging_time': 0.4401130676269531, 'global_step': 21230, 'preemption_count': 0}), (22747, {'train/accuracy': 0.6139987111091614, 'train/loss': 1.8695482015609741, 'validation/accuracy': 0.5684399604797363, 'validation/loss': 2.0831968784332275, 'validation/num_examples': 50000, 'test/accuracy': 0.44530001282691956, 'test/loss': 2.759314775466919, 'test/num_examples': 10000, 'score': 7715.679613113403, 'total_duration': 8033.372991323471, 'accumulated_submission_time': 7715.679613113403, 'accumulated_eval_time': 316.85913920402527, 'accumulated_logging_time': 0.4701504707336426, 'global_step': 22747, 'preemption_count': 0}), (24264, {'train/accuracy': 0.6081792116165161, 'train/loss': 1.874230146408081, 'validation/accuracy': 0.5652199983596802, 'validation/loss': 2.0674972534179688, 'validation/num_examples': 50000, 'test/accuracy': 0.4410000145435333, 'test/loss': 2.752103567123413, 'test/num_examples': 10000, 'score': 8225.844413280487, 'total_duration': 8562.574270963669, 'accumulated_submission_time': 8225.844413280487, 'accumulated_eval_time': 335.8402123451233, 'accumulated_logging_time': 0.5013852119445801, 'global_step': 24264, 'preemption_count': 0}), (25781, {'train/accuracy': 0.6123445630073547, 'train/loss': 1.9537458419799805, 'validation/accuracy': 0.5752599835395813, 'validation/loss': 2.1266887187957764, 'validation/num_examples': 50000, 'test/accuracy': 0.4538000226020813, 'test/loss': 2.7576181888580322, 'test/num_examples': 10000, 'score': 8735.915976524353, 'total_duration': 9092.500293016434, 'accumulated_submission_time': 8735.915976524353, 'accumulated_eval_time': 355.6292459964752, 'accumulated_logging_time': 0.5426211357116699, 'global_step': 25781, 'preemption_count': 0}), (27298, {'train/accuracy': 0.6115074753761292, 'train/loss': 1.9302557706832886, 'validation/accuracy': 0.5424000024795532, 'validation/loss': 2.234837532043457, 'validation/num_examples': 50000, 'test/accuracy': 0.42350003123283386, 'test/loss': 2.889622449874878, 'test/num_examples': 10000, 'score': 9246.095047950745, 'total_duration': 9622.60255765915, 'accumulated_submission_time': 9246.095047950745, 'accumulated_eval_time': 375.49055767059326, 'accumulated_logging_time': 0.580510139465332, 'global_step': 27298, 'preemption_count': 0}), (28815, {'train/accuracy': 0.6237643361091614, 'train/loss': 1.7441202402114868, 'validation/accuracy': 0.5724200010299683, 'validation/loss': 2.0058789253234863, 'validation/num_examples': 50000, 'test/accuracy': 0.451200008392334, 'test/loss': 2.706669330596924, 'test/num_examples': 10000, 'score': 9756.131294965744, 'total_duration': 10152.604863405228, 'accumulated_submission_time': 9756.131294965744, 'accumulated_eval_time': 395.3967297077179, 'accumulated_logging_time': 0.6164669990539551, 'global_step': 28815, 'preemption_count': 0}), (30333, {'train/accuracy': 0.6113081574440002, 'train/loss': 1.8609651327133179, 'validation/accuracy': 0.5625999569892883, 'validation/loss': 2.10093092918396, 'validation/num_examples': 50000, 'test/accuracy': 0.4407000243663788, 'test/loss': 2.759889841079712, 'test/num_examples': 10000, 'score': 10266.407609701157, 'total_duration': 10683.367906332016, 'accumulated_submission_time': 10266.407609701157, 'accumulated_eval_time': 415.82493329048157, 'accumulated_logging_time': 0.6509401798248291, 'global_step': 30333, 'preemption_count': 0}), (31851, {'train/accuracy': 0.6287069320678711, 'train/loss': 1.7984288930892944, 'validation/accuracy': 0.5835599899291992, 'validation/loss': 2.004408359527588, 'validation/num_examples': 50000, 'test/accuracy': 0.4619000256061554, 'test/loss': 2.658885955810547, 'test/num_examples': 10000, 'score': 10776.673121452332, 'total_duration': 11215.037534236908, 'accumulated_submission_time': 10776.673121452332, 'accumulated_eval_time': 437.1665277481079, 'accumulated_logging_time': 0.6895773410797119, 'global_step': 31851, 'preemption_count': 0}), (33368, {'train/accuracy': 0.6348652839660645, 'train/loss': 1.734724521636963, 'validation/accuracy': 0.5921399593353271, 'validation/loss': 1.9456363916397095, 'validation/num_examples': 50000, 'test/accuracy': 0.467600017786026, 'test/loss': 2.6168863773345947, 'test/num_examples': 10000, 'score': 11286.81523323059, 'total_duration': 11746.69552898407, 'accumulated_submission_time': 11286.81523323059, 'accumulated_eval_time': 458.6238343715668, 'accumulated_logging_time': 0.7243063449859619, 'global_step': 33368, 'preemption_count': 0}), (34885, {'train/accuracy': 0.6336296200752258, 'train/loss': 1.7741262912750244, 'validation/accuracy': 0.5887399911880493, 'validation/loss': 1.9872188568115234, 'validation/num_examples': 50000, 'test/accuracy': 0.4678000211715698, 'test/loss': 2.6356329917907715, 'test/num_examples': 10000, 'score': 11796.935238361359, 'total_duration': 12278.145491838455, 'accumulated_submission_time': 11796.935238361359, 'accumulated_eval_time': 479.8940281867981, 'accumulated_logging_time': 0.7600452899932861, 'global_step': 34885, 'preemption_count': 0}), (36402, {'train/accuracy': 0.626395046710968, 'train/loss': 1.8138104677200317, 'validation/accuracy': 0.5559599995613098, 'validation/loss': 2.1397645473480225, 'validation/num_examples': 50000, 'test/accuracy': 0.4309000074863434, 'test/loss': 2.829883337020874, 'test/num_examples': 10000, 'score': 12306.953290224075, 'total_duration': 12810.326432228088, 'accumulated_submission_time': 12306.953290224075, 'accumulated_eval_time': 501.99473237991333, 'accumulated_logging_time': 0.798119068145752, 'global_step': 36402, 'preemption_count': 0}), (37919, {'train/accuracy': 0.6433154940605164, 'train/loss': 1.6928578615188599, 'validation/accuracy': 0.5925999879837036, 'validation/loss': 1.9268696308135986, 'validation/num_examples': 50000, 'test/accuracy': 0.46950003504753113, 'test/loss': 2.6046764850616455, 'test/num_examples': 10000, 'score': 12817.005209684372, 'total_duration': 13341.298707485199, 'accumulated_submission_time': 12817.005209684372, 'accumulated_eval_time': 522.8470289707184, 'accumulated_logging_time': 0.8420491218566895, 'global_step': 37919, 'preemption_count': 0}), (39436, {'train/accuracy': 0.6396284699440002, 'train/loss': 1.716475009918213, 'validation/accuracy': 0.5875799655914307, 'validation/loss': 1.9562627077102661, 'validation/num_examples': 50000, 'test/accuracy': 0.4643000364303589, 'test/loss': 2.620577573776245, 'test/num_examples': 10000, 'score': 13327.070336341858, 'total_duration': 13872.311385631561, 'accumulated_submission_time': 13327.070336341858, 'accumulated_eval_time': 543.7323985099792, 'accumulated_logging_time': 0.880258321762085, 'global_step': 39436, 'preemption_count': 0}), (40953, {'train/accuracy': 0.6538384556770325, 'train/loss': 1.6342676877975464, 'validation/accuracy': 0.60725998878479, 'validation/loss': 1.849616527557373, 'validation/num_examples': 50000, 'test/accuracy': 0.4861000180244446, 'test/loss': 2.4979519844055176, 'test/num_examples': 10000, 'score': 13837.057256937027, 'total_duration': 14403.096657276154, 'accumulated_submission_time': 13837.057256937027, 'accumulated_eval_time': 564.4725894927979, 'accumulated_logging_time': 0.9146661758422852, 'global_step': 40953, 'preemption_count': 0}), (42470, {'train/accuracy': 0.6361008882522583, 'train/loss': 1.7833523750305176, 'validation/accuracy': 0.58815997838974, 'validation/loss': 1.9896317720413208, 'validation/num_examples': 50000, 'test/accuracy': 0.4710000157356262, 'test/loss': 2.617781162261963, 'test/num_examples': 10000, 'score': 14347.031331300735, 'total_duration': 14934.114666461945, 'accumulated_submission_time': 14347.031331300735, 'accumulated_eval_time': 585.4577765464783, 'accumulated_logging_time': 0.9492604732513428, 'global_step': 42470, 'preemption_count': 0}), (43987, {'train/accuracy': 0.6603754758834839, 'train/loss': 1.683393120765686, 'validation/accuracy': 0.5868399739265442, 'validation/loss': 1.9995726346969604, 'validation/num_examples': 50000, 'test/accuracy': 0.4644000232219696, 'test/loss': 2.663170337677002, 'test/num_examples': 10000, 'score': 14857.173608064651, 'total_duration': 15465.127775907516, 'accumulated_submission_time': 14857.173608064651, 'accumulated_eval_time': 606.2709102630615, 'accumulated_logging_time': 0.9829974174499512, 'global_step': 43987, 'preemption_count': 0}), (45504, {'train/accuracy': 0.6693239808082581, 'train/loss': 1.5423797369003296, 'validation/accuracy': 0.602400004863739, 'validation/loss': 1.847364068031311, 'validation/num_examples': 50000, 'test/accuracy': 0.47930002212524414, 'test/loss': 2.4985201358795166, 'test/num_examples': 10000, 'score': 15367.331311702728, 'total_duration': 15996.48631119728, 'accumulated_submission_time': 15367.331311702728, 'accumulated_eval_time': 627.4112348556519, 'accumulated_logging_time': 1.019683837890625, 'global_step': 45504, 'preemption_count': 0}), (47021, {'train/accuracy': 0.6635642647743225, 'train/loss': 1.6628048419952393, 'validation/accuracy': 0.6050999760627747, 'validation/loss': 1.9179195165634155, 'validation/num_examples': 50000, 'test/accuracy': 0.48000001907348633, 'test/loss': 2.580186128616333, 'test/num_examples': 10000, 'score': 15877.369775295258, 'total_duration': 16527.553474664688, 'accumulated_submission_time': 15877.369775295258, 'accumulated_eval_time': 648.3829953670502, 'accumulated_logging_time': 1.052889347076416, 'global_step': 47021, 'preemption_count': 0}), (48538, {'train/accuracy': 0.6535395383834839, 'train/loss': 1.6473050117492676, 'validation/accuracy': 0.6027399897575378, 'validation/loss': 1.8904958963394165, 'validation/num_examples': 50000, 'test/accuracy': 0.48190003633499146, 'test/loss': 2.5572152137756348, 'test/num_examples': 10000, 'score': 16387.537207603455, 'total_duration': 17058.895617485046, 'accumulated_submission_time': 16387.537207603455, 'accumulated_eval_time': 669.4963607788086, 'accumulated_logging_time': 1.0904269218444824, 'global_step': 48538, 'preemption_count': 0}), (50055, {'train/accuracy': 0.6315369606018066, 'train/loss': 1.7543830871582031, 'validation/accuracy': 0.5855000019073486, 'validation/loss': 1.9698681831359863, 'validation/num_examples': 50000, 'test/accuracy': 0.46540001034736633, 'test/loss': 2.6308541297912598, 'test/num_examples': 10000, 'score': 16897.61312365532, 'total_duration': 17590.371537685394, 'accumulated_submission_time': 16897.61312365532, 'accumulated_eval_time': 690.8382194042206, 'accumulated_logging_time': 1.1248712539672852, 'global_step': 50055, 'preemption_count': 0}), (51570, {'train/accuracy': 0.6583824753761292, 'train/loss': 1.6394034624099731, 'validation/accuracy': 0.612500011920929, 'validation/loss': 1.8568693399429321, 'validation/num_examples': 50000, 'test/accuracy': 0.4863000214099884, 'test/loss': 2.5079689025878906, 'test/num_examples': 10000, 'score': 17407.788469791412, 'total_duration': 18121.76651597023, 'accumulated_submission_time': 17407.788469791412, 'accumulated_eval_time': 711.9998610019684, 'accumulated_logging_time': 1.1591193675994873, 'global_step': 51570, 'preemption_count': 0}), (53087, {'train/accuracy': 0.6985012888908386, 'train/loss': 1.4924120903015137, 'validation/accuracy': 0.6067799925804138, 'validation/loss': 1.900179147720337, 'validation/num_examples': 50000, 'test/accuracy': 0.47860002517700195, 'test/loss': 2.5549025535583496, 'test/num_examples': 10000, 'score': 17917.96275138855, 'total_duration': 18652.954436063766, 'accumulated_submission_time': 17917.96275138855, 'accumulated_eval_time': 732.9565396308899, 'accumulated_logging_time': 1.1921696662902832, 'global_step': 53087, 'preemption_count': 0}), (54604, {'train/accuracy': 0.6769570708274841, 'train/loss': 1.5328868627548218, 'validation/accuracy': 0.6092000007629395, 'validation/loss': 1.8308618068695068, 'validation/num_examples': 50000, 'test/accuracy': 0.4880000352859497, 'test/loss': 2.482255697250366, 'test/num_examples': 10000, 'score': 18428.192138671875, 'total_duration': 19184.366216659546, 'accumulated_submission_time': 18428.192138671875, 'accumulated_eval_time': 754.0825002193451, 'accumulated_logging_time': 1.2245855331420898, 'global_step': 54604, 'preemption_count': 0}), (56121, {'train/accuracy': 0.6670519709587097, 'train/loss': 1.6260281801223755, 'validation/accuracy': 0.6095600128173828, 'validation/loss': 1.8815218210220337, 'validation/num_examples': 50000, 'test/accuracy': 0.49010002613067627, 'test/loss': 2.5206735134124756, 'test/num_examples': 10000, 'score': 18938.29710006714, 'total_duration': 19715.568593502045, 'accumulated_submission_time': 18938.29710006714, 'accumulated_eval_time': 775.1219809055328, 'accumulated_logging_time': 1.2585887908935547, 'global_step': 56121, 'preemption_count': 0}), (57638, {'train/accuracy': 0.6732102632522583, 'train/loss': 1.5738229751586914, 'validation/accuracy': 0.6189599633216858, 'validation/loss': 1.8145744800567627, 'validation/num_examples': 50000, 'test/accuracy': 0.49160003662109375, 'test/loss': 2.4750869274139404, 'test/num_examples': 10000, 'score': 19448.404630184174, 'total_duration': 20246.57687520981, 'accumulated_submission_time': 19448.404630184174, 'accumulated_eval_time': 795.9631505012512, 'accumulated_logging_time': 1.2943003177642822, 'global_step': 57638, 'preemption_count': 0}), (59155, {'train/accuracy': 0.6637834906578064, 'train/loss': 1.649034857749939, 'validation/accuracy': 0.6145399808883667, 'validation/loss': 1.870615839958191, 'validation/num_examples': 50000, 'test/accuracy': 0.48590001463890076, 'test/loss': 2.557185173034668, 'test/num_examples': 10000, 'score': 19958.498077392578, 'total_duration': 20777.880433559418, 'accumulated_submission_time': 19958.498077392578, 'accumulated_eval_time': 817.1098523139954, 'accumulated_logging_time': 1.3336970806121826, 'global_step': 59155, 'preemption_count': 0}), (60672, {'train/accuracy': 0.6783123016357422, 'train/loss': 1.5390408039093018, 'validation/accuracy': 0.6280999779701233, 'validation/loss': 1.7732737064361572, 'validation/num_examples': 50000, 'test/accuracy': 0.49480003118515015, 'test/loss': 2.4399282932281494, 'test/num_examples': 10000, 'score': 20468.633964538574, 'total_duration': 21308.93989467621, 'accumulated_submission_time': 20468.633964538574, 'accumulated_eval_time': 837.9744617938995, 'accumulated_logging_time': 1.368260383605957, 'global_step': 60672, 'preemption_count': 0}), (62189, {'train/accuracy': 0.7044802308082581, 'train/loss': 1.5039805173873901, 'validation/accuracy': 0.621239960193634, 'validation/loss': 1.8661829233169556, 'validation/num_examples': 50000, 'test/accuracy': 0.49310001730918884, 'test/loss': 2.5342471599578857, 'test/num_examples': 10000, 'score': 20978.793485164642, 'total_duration': 21840.057413101196, 'accumulated_submission_time': 20978.793485164642, 'accumulated_eval_time': 858.8714756965637, 'accumulated_logging_time': 1.4050464630126953, 'global_step': 62189, 'preemption_count': 0}), (63706, {'train/accuracy': 0.7075693607330322, 'train/loss': 1.3596501350402832, 'validation/accuracy': 0.6421799659729004, 'validation/loss': 1.655147910118103, 'validation/num_examples': 50000, 'test/accuracy': 0.5166000127792358, 'test/loss': 2.3244237899780273, 'test/num_examples': 10000, 'score': 21488.862284183502, 'total_duration': 22371.17894911766, 'accumulated_submission_time': 21488.862284183502, 'accumulated_eval_time': 879.8663790225983, 'accumulated_logging_time': 1.43892240524292, 'global_step': 63706, 'preemption_count': 0}), (65223, {'train/accuracy': 0.6975446343421936, 'train/loss': 1.467308759689331, 'validation/accuracy': 0.6388199925422668, 'validation/loss': 1.7396818399429321, 'validation/num_examples': 50000, 'test/accuracy': 0.5074000358581543, 'test/loss': 2.387864112854004, 'test/num_examples': 10000, 'score': 21998.965037345886, 'total_duration': 22902.464923620224, 'accumulated_submission_time': 21998.965037345886, 'accumulated_eval_time': 900.9853439331055, 'accumulated_logging_time': 1.4791550636291504, 'global_step': 65223, 'preemption_count': 0}), (66740, {'train/accuracy': 0.6934191584587097, 'train/loss': 1.4384207725524902, 'validation/accuracy': 0.6387999653816223, 'validation/loss': 1.6868369579315186, 'validation/num_examples': 50000, 'test/accuracy': 0.5131000280380249, 'test/loss': 2.3482666015625, 'test/num_examples': 10000, 'score': 22509.085248470306, 'total_duration': 23433.65925884247, 'accumulated_submission_time': 22509.085248470306, 'accumulated_eval_time': 921.984296798706, 'accumulated_logging_time': 1.5302343368530273, 'global_step': 66740, 'preemption_count': 0}), (68257, {'train/accuracy': 0.70023512840271, 'train/loss': 1.4438289403915405, 'validation/accuracy': 0.6456199884414673, 'validation/loss': 1.679024338722229, 'validation/num_examples': 50000, 'test/accuracy': 0.513200044631958, 'test/loss': 2.3601062297821045, 'test/num_examples': 10000, 'score': 23019.195251703262, 'total_duration': 23964.908405542374, 'accumulated_submission_time': 23019.195251703262, 'accumulated_eval_time': 943.0638625621796, 'accumulated_logging_time': 1.5661993026733398, 'global_step': 68257, 'preemption_count': 0}), (69774, {'train/accuracy': 0.7023277878761292, 'train/loss': 1.4531011581420898, 'validation/accuracy': 0.6444599628448486, 'validation/loss': 1.700484275817871, 'validation/num_examples': 50000, 'test/accuracy': 0.5200999975204468, 'test/loss': 2.3464748859405518, 'test/num_examples': 10000, 'score': 23529.21361875534, 'total_duration': 24495.880565404892, 'accumulated_submission_time': 23529.21361875534, 'accumulated_eval_time': 963.9580943584442, 'accumulated_logging_time': 1.6017961502075195, 'global_step': 69774, 'preemption_count': 0}), (71291, {'train/accuracy': 0.7182317972183228, 'train/loss': 1.3463919162750244, 'validation/accuracy': 0.6370999813079834, 'validation/loss': 1.7067084312438965, 'validation/num_examples': 50000, 'test/accuracy': 0.510200023651123, 'test/loss': 2.352832794189453, 'test/num_examples': 10000, 'score': 24039.209142446518, 'total_duration': 25027.00485777855, 'accumulated_submission_time': 24039.209142446518, 'accumulated_eval_time': 985.0249061584473, 'accumulated_logging_time': 1.639897346496582, 'global_step': 71291, 'preemption_count': 0}), (72808, {'train/accuracy': 0.6951131820678711, 'train/loss': 1.522586703300476, 'validation/accuracy': 0.6317799687385559, 'validation/loss': 1.8127872943878174, 'validation/num_examples': 50000, 'test/accuracy': 0.5080000162124634, 'test/loss': 2.457387685775757, 'test/num_examples': 10000, 'score': 24549.357794046402, 'total_duration': 25558.21341776848, 'accumulated_submission_time': 24549.357794046402, 'accumulated_eval_time': 1006.0258257389069, 'accumulated_logging_time': 1.675201177597046, 'global_step': 72808, 'preemption_count': 0}), (74325, {'train/accuracy': 0.7155811190605164, 'train/loss': 1.414952278137207, 'validation/accuracy': 0.6520599722862244, 'validation/loss': 1.7008613348007202, 'validation/num_examples': 50000, 'test/accuracy': 0.5311000347137451, 'test/loss': 2.307309627532959, 'test/num_examples': 10000, 'score': 25059.411647558212, 'total_duration': 26089.40896821022, 'accumulated_submission_time': 25059.411647558212, 'accumulated_eval_time': 1027.105108499527, 'accumulated_logging_time': 1.7139711380004883, 'global_step': 74325, 'preemption_count': 0}), (75842, {'train/accuracy': 0.6940768361091614, 'train/loss': 1.5050263404846191, 'validation/accuracy': 0.6295599937438965, 'validation/loss': 1.7738419771194458, 'validation/num_examples': 50000, 'test/accuracy': 0.5039000511169434, 'test/loss': 2.4370033740997314, 'test/num_examples': 10000, 'score': 25569.62277650833, 'total_duration': 26621.363907575607, 'accumulated_submission_time': 25569.62277650833, 'accumulated_eval_time': 1048.7881875038147, 'accumulated_logging_time': 1.750809907913208, 'global_step': 75842, 'preemption_count': 0}), (77359, {'train/accuracy': 0.6878786683082581, 'train/loss': 1.5141419172286987, 'validation/accuracy': 0.633899986743927, 'validation/loss': 1.7614827156066895, 'validation/num_examples': 50000, 'test/accuracy': 0.5118000507354736, 'test/loss': 2.4090476036071777, 'test/num_examples': 10000, 'score': 26079.792610406876, 'total_duration': 27152.647390842438, 'accumulated_submission_time': 26079.792610406876, 'accumulated_eval_time': 1069.8412821292877, 'accumulated_logging_time': 1.7873945236206055, 'global_step': 77359, 'preemption_count': 0}), (78876, {'train/accuracy': 0.7185506820678711, 'train/loss': 1.389367699623108, 'validation/accuracy': 0.6455199718475342, 'validation/loss': 1.6985089778900146, 'validation/num_examples': 50000, 'test/accuracy': 0.5169000029563904, 'test/loss': 2.3687965869903564, 'test/num_examples': 10000, 'score': 26589.906127929688, 'total_duration': 27683.71810078621, 'accumulated_submission_time': 26589.906127929688, 'accumulated_eval_time': 1090.7366514205933, 'accumulated_logging_time': 1.8254246711730957, 'global_step': 78876, 'preemption_count': 0}), (80393, {'train/accuracy': 0.7281369566917419, 'train/loss': 1.3253265619277954, 'validation/accuracy': 0.6444199681282043, 'validation/loss': 1.6741849184036255, 'validation/num_examples': 50000, 'test/accuracy': 0.515500009059906, 'test/loss': 2.3491342067718506, 'test/num_examples': 10000, 'score': 27099.957800865173, 'total_duration': 28214.758013486862, 'accumulated_submission_time': 27099.957800865173, 'accumulated_eval_time': 1111.6525723934174, 'accumulated_logging_time': 1.8742599487304688, 'global_step': 80393, 'preemption_count': 0}), (81910, {'train/accuracy': 0.7171356678009033, 'train/loss': 1.3880951404571533, 'validation/accuracy': 0.6470400094985962, 'validation/loss': 1.6899938583374023, 'validation/num_examples': 50000, 'test/accuracy': 0.5190000534057617, 'test/loss': 2.3436319828033447, 'test/num_examples': 10000, 'score': 27610.161732196808, 'total_duration': 28746.007794857025, 'accumulated_submission_time': 27610.161732196808, 'accumulated_eval_time': 1132.6364245414734, 'accumulated_logging_time': 1.9125375747680664, 'global_step': 81910, 'preemption_count': 0}), (83427, {'train/accuracy': 0.71488356590271, 'train/loss': 1.3625293970108032, 'validation/accuracy': 0.6510199904441833, 'validation/loss': 1.6441048383712769, 'validation/num_examples': 50000, 'test/accuracy': 0.5236999988555908, 'test/loss': 2.316115617752075, 'test/num_examples': 10000, 'score': 28120.290773630142, 'total_duration': 29277.178822040558, 'accumulated_submission_time': 28120.290773630142, 'accumulated_eval_time': 1153.6112608909607, 'accumulated_logging_time': 1.9558968544006348, 'global_step': 83427, 'preemption_count': 0}), (84944, {'train/accuracy': 0.7269212007522583, 'train/loss': 1.3108192682266235, 'validation/accuracy': 0.6607599854469299, 'validation/loss': 1.599299669265747, 'validation/num_examples': 50000, 'test/accuracy': 0.5332000255584717, 'test/loss': 2.2441816329956055, 'test/num_examples': 10000, 'score': 28630.306353330612, 'total_duration': 29808.363132476807, 'accumulated_submission_time': 28630.306353330612, 'accumulated_eval_time': 1174.7130620479584, 'accumulated_logging_time': 1.9988429546356201, 'global_step': 84944, 'preemption_count': 0}), (86461, {'train/accuracy': 0.7081672549247742, 'train/loss': 1.4201782941818237, 'validation/accuracy': 0.6499399542808533, 'validation/loss': 1.683957576751709, 'validation/num_examples': 50000, 'test/accuracy': 0.5160000324249268, 'test/loss': 2.3554069995880127, 'test/num_examples': 10000, 'score': 29140.289971590042, 'total_duration': 30339.43712091446, 'accumulated_submission_time': 29140.289971590042, 'accumulated_eval_time': 1195.7400197982788, 'accumulated_logging_time': 2.0383377075195312, 'global_step': 86461, 'preemption_count': 0}), (87978, {'train/accuracy': 0.7741948366165161, 'train/loss': 1.1025867462158203, 'validation/accuracy': 0.6649999618530273, 'validation/loss': 1.576514482498169, 'validation/num_examples': 50000, 'test/accuracy': 0.544700026512146, 'test/loss': 2.20332407951355, 'test/num_examples': 10000, 'score': 29650.408900499344, 'total_duration': 30870.429267644882, 'accumulated_submission_time': 29650.408900499344, 'accumulated_eval_time': 1216.5413224697113, 'accumulated_logging_time': 2.0864293575286865, 'global_step': 87978, 'preemption_count': 0}), (89403, {'train/accuracy': 0.760164201259613, 'train/loss': 1.2321293354034424, 'validation/accuracy': 0.6697799563407898, 'validation/loss': 1.6143219470977783, 'validation/num_examples': 50000, 'test/accuracy': 0.5444000363349915, 'test/loss': 2.2412638664245605, 'test/num_examples': 10000, 'score': 30160.527873277664, 'total_duration': 31401.554005622864, 'accumulated_submission_time': 30160.527873277664, 'accumulated_eval_time': 1237.485412120819, 'accumulated_logging_time': 2.125343084335327, 'global_step': 89403, 'preemption_count': 0}), (90920, {'train/accuracy': 0.7546834945678711, 'train/loss': 1.1807116270065308, 'validation/accuracy': 0.6760199666023254, 'validation/loss': 1.5265799760818481, 'validation/num_examples': 50000, 'test/accuracy': 0.5505000352859497, 'test/loss': 2.1591992378234863, 'test/num_examples': 10000, 'score': 30670.68004131317, 'total_duration': 31932.60477924347, 'accumulated_submission_time': 30670.68004131317, 'accumulated_eval_time': 1258.3163604736328, 'accumulated_logging_time': 2.1692705154418945, 'global_step': 90920, 'preemption_count': 0}), (92437, {'train/accuracy': 0.7476283311843872, 'train/loss': 1.2200695276260376, 'validation/accuracy': 0.669219970703125, 'validation/loss': 1.546072006225586, 'validation/num_examples': 50000, 'test/accuracy': 0.5409000515937805, 'test/loss': 2.1896841526031494, 'test/num_examples': 10000, 'score': 31180.89601111412, 'total_duration': 32464.031769752502, 'accumulated_submission_time': 31180.89601111412, 'accumulated_eval_time': 1279.46471118927, 'accumulated_logging_time': 2.2080471515655518, 'global_step': 92437, 'preemption_count': 0}), (93954, {'train/accuracy': 0.7428451776504517, 'train/loss': 1.2713103294372559, 'validation/accuracy': 0.6768400073051453, 'validation/loss': 1.5632636547088623, 'validation/num_examples': 50000, 'test/accuracy': 0.5412000417709351, 'test/loss': 2.229316234588623, 'test/num_examples': 10000, 'score': 31691.067200660706, 'total_duration': 32995.10042333603, 'accumulated_submission_time': 31691.067200660706, 'accumulated_eval_time': 1300.2977285385132, 'accumulated_logging_time': 2.2484145164489746, 'global_step': 93954, 'preemption_count': 0}), (95470, {'train/accuracy': 0.7487842440605164, 'train/loss': 1.2690248489379883, 'validation/accuracy': 0.6800400018692017, 'validation/loss': 1.5611140727996826, 'validation/num_examples': 50000, 'test/accuracy': 0.5588000416755676, 'test/loss': 2.176574945449829, 'test/num_examples': 10000, 'score': 32201.036960601807, 'total_duration': 33526.03298687935, 'accumulated_submission_time': 32201.036960601807, 'accumulated_eval_time': 1321.1983988285065, 'accumulated_logging_time': 2.2867887020111084, 'global_step': 95470, 'preemption_count': 0}), (96987, {'train/accuracy': 0.7792569994926453, 'train/loss': 1.127251386642456, 'validation/accuracy': 0.6884999871253967, 'validation/loss': 1.5091551542282104, 'validation/num_examples': 50000, 'test/accuracy': 0.5596000552177429, 'test/loss': 2.1477794647216797, 'test/num_examples': 10000, 'score': 32711.069343805313, 'total_duration': 34057.04123091698, 'accumulated_submission_time': 32711.069343805313, 'accumulated_eval_time': 1342.107433795929, 'accumulated_logging_time': 2.329782009124756, 'global_step': 96987, 'preemption_count': 0}), (98504, {'train/accuracy': 0.7738958597183228, 'train/loss': 1.1183806657791138, 'validation/accuracy': 0.6839399933815002, 'validation/loss': 1.509204387664795, 'validation/num_examples': 50000, 'test/accuracy': 0.5569000244140625, 'test/loss': 2.1492249965667725, 'test/num_examples': 10000, 'score': 33221.164717674255, 'total_duration': 34588.117144823074, 'accumulated_submission_time': 33221.164717674255, 'accumulated_eval_time': 1363.0259428024292, 'accumulated_logging_time': 2.367922306060791, 'global_step': 98504, 'preemption_count': 0}), (100021, {'train/accuracy': 0.7620376348495483, 'train/loss': 1.1442164182662964, 'validation/accuracy': 0.6807000041007996, 'validation/loss': 1.5029559135437012, 'validation/num_examples': 50000, 'test/accuracy': 0.5522000193595886, 'test/loss': 2.168475389480591, 'test/num_examples': 10000, 'score': 33731.27061343193, 'total_duration': 35119.230862379074, 'accumulated_submission_time': 33731.27061343193, 'accumulated_eval_time': 1383.9732139110565, 'accumulated_logging_time': 2.404984712600708, 'global_step': 100021, 'preemption_count': 0}), (101538, {'train/accuracy': 0.7798150181770325, 'train/loss': 1.1336147785186768, 'validation/accuracy': 0.6987199783325195, 'validation/loss': 1.472100019454956, 'validation/num_examples': 50000, 'test/accuracy': 0.5708000063896179, 'test/loss': 2.1115829944610596, 'test/num_examples': 10000, 'score': 34241.39809155464, 'total_duration': 35650.45706796646, 'accumulated_submission_time': 34241.39809155464, 'accumulated_eval_time': 1405.0103640556335, 'accumulated_logging_time': 2.443260669708252, 'global_step': 101538, 'preemption_count': 0}), (103055, {'train/accuracy': 0.7728396058082581, 'train/loss': 1.1437686681747437, 'validation/accuracy': 0.6934599876403809, 'validation/loss': 1.4837627410888672, 'validation/num_examples': 50000, 'test/accuracy': 0.5624000430107117, 'test/loss': 2.120307445526123, 'test/num_examples': 10000, 'score': 34751.50690150261, 'total_duration': 36181.49987959862, 'accumulated_submission_time': 34751.50690150261, 'accumulated_eval_time': 1425.882792711258, 'accumulated_logging_time': 2.4810028076171875, 'global_step': 103055, 'preemption_count': 0}), (104572, {'train/accuracy': 0.7798548936843872, 'train/loss': 1.084933876991272, 'validation/accuracy': 0.705299973487854, 'validation/loss': 1.4098957777023315, 'validation/num_examples': 50000, 'test/accuracy': 0.581000030040741, 'test/loss': 2.0294301509857178, 'test/num_examples': 10000, 'score': 35261.52269268036, 'total_duration': 36712.39652299881, 'accumulated_submission_time': 35261.52269268036, 'accumulated_eval_time': 1446.7013919353485, 'accumulated_logging_time': 2.5192880630493164, 'global_step': 104572, 'preemption_count': 0}), (106089, {'train/accuracy': 0.8142538070678711, 'train/loss': 0.9820297360420227, 'validation/accuracy': 0.6957399845123291, 'validation/loss': 1.4702575206756592, 'validation/num_examples': 50000, 'test/accuracy': 0.5756000280380249, 'test/loss': 2.088582992553711, 'test/num_examples': 10000, 'score': 35771.63497543335, 'total_duration': 37243.33074903488, 'accumulated_submission_time': 35771.63497543335, 'accumulated_eval_time': 1467.462560892105, 'accumulated_logging_time': 2.5562973022460938, 'global_step': 106089, 'preemption_count': 0}), (107606, {'train/accuracy': 0.8084143400192261, 'train/loss': 0.9889046549797058, 'validation/accuracy': 0.7097199559211731, 'validation/loss': 1.3914456367492676, 'validation/num_examples': 50000, 'test/accuracy': 0.5845000147819519, 'test/loss': 1.998412013053894, 'test/num_examples': 10000, 'score': 36281.79980945587, 'total_duration': 37774.54580140114, 'accumulated_submission_time': 36281.79980945587, 'accumulated_eval_time': 1488.4429895877838, 'accumulated_logging_time': 2.602069854736328, 'global_step': 107606, 'preemption_count': 0}), (109123, {'train/accuracy': 0.7987882494926453, 'train/loss': 1.0279736518859863, 'validation/accuracy': 0.7055000066757202, 'validation/loss': 1.4219591617584229, 'validation/num_examples': 50000, 'test/accuracy': 0.5830000042915344, 'test/loss': 2.031740188598633, 'test/num_examples': 10000, 'score': 36791.936692237854, 'total_duration': 38305.600130319595, 'accumulated_submission_time': 36791.936692237854, 'accumulated_eval_time': 1509.299532175064, 'accumulated_logging_time': 2.639185667037964, 'global_step': 109123, 'preemption_count': 0}), (110640, {'train/accuracy': 0.8102080225944519, 'train/loss': 0.9365128874778748, 'validation/accuracy': 0.7159799933433533, 'validation/loss': 1.3339099884033203, 'validation/num_examples': 50000, 'test/accuracy': 0.5889000296592712, 'test/loss': 1.9741050004959106, 'test/num_examples': 10000, 'score': 37302.028915166855, 'total_duration': 38836.55831408501, 'accumulated_submission_time': 37302.028915166855, 'accumulated_eval_time': 1530.0955040454865, 'accumulated_logging_time': 2.6852407455444336, 'global_step': 110640, 'preemption_count': 0}), (112157, {'train/accuracy': 0.8016581535339355, 'train/loss': 1.010259747505188, 'validation/accuracy': 0.7116000056266785, 'validation/loss': 1.3901562690734863, 'validation/num_examples': 50000, 'test/accuracy': 0.5875000357627869, 'test/loss': 2.0190460681915283, 'test/num_examples': 10000, 'score': 37812.05665755272, 'total_duration': 39367.32677149773, 'accumulated_submission_time': 37812.05665755272, 'accumulated_eval_time': 1550.7734966278076, 'accumulated_logging_time': 2.724013090133667, 'global_step': 112157, 'preemption_count': 0}), (113674, {'train/accuracy': 0.8226243257522583, 'train/loss': 0.9075947999954224, 'validation/accuracy': 0.7247599959373474, 'validation/loss': 1.3018537759780884, 'validation/num_examples': 50000, 'test/accuracy': 0.6044000387191772, 'test/loss': 1.9077553749084473, 'test/num_examples': 10000, 'score': 38322.17178297043, 'total_duration': 39898.42949771881, 'accumulated_submission_time': 38322.17178297043, 'accumulated_eval_time': 1571.6888778209686, 'accumulated_logging_time': 2.7724108695983887, 'global_step': 113674, 'preemption_count': 0}), (115191, {'train/accuracy': 0.8444873690605164, 'train/loss': 0.816093921661377, 'validation/accuracy': 0.7221999764442444, 'validation/loss': 1.3223457336425781, 'validation/num_examples': 50000, 'test/accuracy': 0.5949000120162964, 'test/loss': 1.955386757850647, 'test/num_examples': 10000, 'score': 38832.27325510979, 'total_duration': 40429.50769138336, 'accumulated_submission_time': 38832.27325510979, 'accumulated_eval_time': 1592.6026391983032, 'accumulated_logging_time': 2.8115036487579346, 'global_step': 115191, 'preemption_count': 0}), (116708, {'train/accuracy': 0.8449656963348389, 'train/loss': 0.8320600986480713, 'validation/accuracy': 0.7335399985313416, 'validation/loss': 1.2946419715881348, 'validation/num_examples': 50000, 'test/accuracy': 0.6045000553131104, 'test/loss': 1.9058303833007812, 'test/num_examples': 10000, 'score': 39342.29028558731, 'total_duration': 40960.27058124542, 'accumulated_submission_time': 39342.29028558731, 'accumulated_eval_time': 1613.283058643341, 'accumulated_logging_time': 2.853027105331421, 'global_step': 116708, 'preemption_count': 0}), (118225, {'train/accuracy': 0.8530173897743225, 'train/loss': 0.795059084892273, 'validation/accuracy': 0.7384399771690369, 'validation/loss': 1.2515661716461182, 'validation/num_examples': 50000, 'test/accuracy': 0.6126000285148621, 'test/loss': 1.862630009651184, 'test/num_examples': 10000, 'score': 39852.26021718979, 'total_duration': 41491.08199930191, 'accumulated_submission_time': 39852.26021718979, 'accumulated_eval_time': 1634.0631339550018, 'accumulated_logging_time': 2.8905999660491943, 'global_step': 118225, 'preemption_count': 0}), (119742, {'train/accuracy': 0.8602120280265808, 'train/loss': 0.7721146941184998, 'validation/accuracy': 0.7487399578094482, 'validation/loss': 1.2245062589645386, 'validation/num_examples': 50000, 'test/accuracy': 0.6221000552177429, 'test/loss': 1.824009895324707, 'test/num_examples': 10000, 'score': 40362.266666173935, 'total_duration': 42022.038808345795, 'accumulated_submission_time': 40362.266666173935, 'accumulated_eval_time': 1654.951964378357, 'accumulated_logging_time': 2.9282946586608887, 'global_step': 119742, 'preemption_count': 0}), (121260, {'train/accuracy': 0.8625637292861938, 'train/loss': 0.7528239488601685, 'validation/accuracy': 0.7497400045394897, 'validation/loss': 1.2097290754318237, 'validation/num_examples': 50000, 'test/accuracy': 0.6291000247001648, 'test/loss': 1.8062241077423096, 'test/num_examples': 10000, 'score': 40872.539221048355, 'total_duration': 42553.2064037323, 'accumulated_submission_time': 40872.539221048355, 'accumulated_eval_time': 1675.7843565940857, 'accumulated_logging_time': 2.9671173095703125, 'global_step': 121260, 'preemption_count': 0}), (122777, {'train/accuracy': 0.8712930083274841, 'train/loss': 0.7350925207138062, 'validation/accuracy': 0.755079984664917, 'validation/loss': 1.2087671756744385, 'validation/num_examples': 50000, 'test/accuracy': 0.6279000043869019, 'test/loss': 1.8225747346878052, 'test/num_examples': 10000, 'score': 41382.66648173332, 'total_duration': 43084.681473493576, 'accumulated_submission_time': 41382.66648173332, 'accumulated_eval_time': 1697.069876909256, 'accumulated_logging_time': 3.0055551528930664, 'global_step': 122777, 'preemption_count': 0}), (124294, {'train/accuracy': 0.8966438174247742, 'train/loss': 0.6295205950737, 'validation/accuracy': 0.7619999647140503, 'validation/loss': 1.1587510108947754, 'validation/num_examples': 50000, 'test/accuracy': 0.638200044631958, 'test/loss': 1.7649061679840088, 'test/num_examples': 10000, 'score': 41892.77513337135, 'total_duration': 43615.692863702774, 'accumulated_submission_time': 41892.77513337135, 'accumulated_eval_time': 1717.9061884880066, 'accumulated_logging_time': 3.0478503704071045, 'global_step': 124294, 'preemption_count': 0}), (125811, {'train/accuracy': 0.9040776491165161, 'train/loss': 0.600990355014801, 'validation/accuracy': 0.7697799801826477, 'validation/loss': 1.1348940134048462, 'validation/num_examples': 50000, 'test/accuracy': 0.6457000374794006, 'test/loss': 1.7272042036056519, 'test/num_examples': 10000, 'score': 42402.91263651848, 'total_duration': 44146.47246336937, 'accumulated_submission_time': 42402.91263651848, 'accumulated_eval_time': 1738.482519865036, 'accumulated_logging_time': 3.0896189212799072, 'global_step': 125811, 'preemption_count': 0}), (127329, {'train/accuracy': 0.9037786722183228, 'train/loss': 0.5991418957710266, 'validation/accuracy': 0.7731399536132812, 'validation/loss': 1.1176573038101196, 'validation/num_examples': 50000, 'test/accuracy': 0.6514000296592712, 'test/loss': 1.7044885158538818, 'test/num_examples': 10000, 'score': 42913.17221546173, 'total_duration': 44677.40223860741, 'accumulated_submission_time': 42913.17221546173, 'accumulated_eval_time': 1759.0905449390411, 'accumulated_logging_time': 3.127929210662842, 'global_step': 127329, 'preemption_count': 0}), (128846, {'train/accuracy': 0.9041772484779358, 'train/loss': 0.5988971590995789, 'validation/accuracy': 0.7734000086784363, 'validation/loss': 1.1173559427261353, 'validation/num_examples': 50000, 'test/accuracy': 0.6503000259399414, 'test/loss': 1.7053135633468628, 'test/num_examples': 10000, 'score': 43423.294951438904, 'total_duration': 45208.21922135353, 'accumulated_submission_time': 43423.294951438904, 'accumulated_eval_time': 1779.719927072525, 'accumulated_logging_time': 3.1692354679107666, 'global_step': 128846, 'preemption_count': 0}), (130364, {'train/accuracy': 0.9042171239852905, 'train/loss': 0.5978606939315796, 'validation/accuracy': 0.7737999558448792, 'validation/loss': 1.1178109645843506, 'validation/num_examples': 50000, 'test/accuracy': 0.6497000455856323, 'test/loss': 1.7077109813690186, 'test/num_examples': 10000, 'score': 43933.45530128479, 'total_duration': 45739.10709118843, 'accumulated_submission_time': 43933.45530128479, 'accumulated_eval_time': 1800.3783478736877, 'accumulated_logging_time': 3.214592933654785, 'global_step': 130364, 'preemption_count': 0}), (131881, {'train/accuracy': 0.9047752022743225, 'train/loss': 0.596454918384552, 'validation/accuracy': 0.7737599611282349, 'validation/loss': 1.1194186210632324, 'validation/num_examples': 50000, 'test/accuracy': 0.6518000364303589, 'test/loss': 1.706139326095581, 'test/num_examples': 10000, 'score': 44443.60584616661, 'total_duration': 46269.98361802101, 'accumulated_submission_time': 44443.60584616661, 'accumulated_eval_time': 1821.038932800293, 'accumulated_logging_time': 3.2563745975494385, 'global_step': 131881, 'preemption_count': 0}), (133397, {'train/accuracy': 0.9069873690605164, 'train/loss': 0.5902242064476013, 'validation/accuracy': 0.7743600010871887, 'validation/loss': 1.1142349243164062, 'validation/num_examples': 50000, 'test/accuracy': 0.6517000198364258, 'test/loss': 1.7023909091949463, 'test/num_examples': 10000, 'score': 44953.56882548332, 'total_duration': 46800.64102816582, 'accumulated_submission_time': 44953.56882548332, 'accumulated_eval_time': 1841.6588699817657, 'accumulated_logging_time': 3.307283401489258, 'global_step': 133397, 'preemption_count': 0}), (134914, {'train/accuracy': 0.9077845811843872, 'train/loss': 0.5867584943771362, 'validation/accuracy': 0.7740599513053894, 'validation/loss': 1.1166901588439941, 'validation/num_examples': 50000, 'test/accuracy': 0.650600016117096, 'test/loss': 1.704883098602295, 'test/num_examples': 10000, 'score': 45463.606588840485, 'total_duration': 47331.54493737221, 'accumulated_submission_time': 45463.606588840485, 'accumulated_eval_time': 1862.45911693573, 'accumulated_logging_time': 3.349576950073242, 'global_step': 134914, 'preemption_count': 0}), (136431, {'train/accuracy': 0.9085220098495483, 'train/loss': 0.5823172330856323, 'validation/accuracy': 0.7741599678993225, 'validation/loss': 1.11417818069458, 'validation/num_examples': 50000, 'test/accuracy': 0.6508000493049622, 'test/loss': 1.7033154964447021, 'test/num_examples': 10000, 'score': 45973.756283283234, 'total_duration': 47862.535675525665, 'accumulated_submission_time': 45973.756283283234, 'accumulated_eval_time': 1883.2363646030426, 'accumulated_logging_time': 3.389491081237793, 'global_step': 136431, 'preemption_count': 0}), (137948, {'train/accuracy': 0.9083625674247742, 'train/loss': 0.5867701172828674, 'validation/accuracy': 0.7748199701309204, 'validation/loss': 1.1123692989349365, 'validation/num_examples': 50000, 'test/accuracy': 0.6527000069618225, 'test/loss': 1.7015321254730225, 'test/num_examples': 10000, 'score': 46483.91411471367, 'total_duration': 48393.48275065422, 'accumulated_submission_time': 46483.91411471367, 'accumulated_eval_time': 1903.939735174179, 'accumulated_logging_time': 3.4515347480773926, 'global_step': 137948, 'preemption_count': 0}), (139465, {'train/accuracy': 0.9058314561843872, 'train/loss': 0.589944064617157, 'validation/accuracy': 0.7748199701309204, 'validation/loss': 1.1144973039627075, 'validation/num_examples': 50000, 'test/accuracy': 0.6518000364303589, 'test/loss': 1.702471375465393, 'test/num_examples': 10000, 'score': 46993.92519116402, 'total_duration': 48924.18271780014, 'accumulated_submission_time': 46993.92519116402, 'accumulated_eval_time': 1924.5634286403656, 'accumulated_logging_time': 3.4931278228759766, 'global_step': 139465, 'preemption_count': 0}), (140000, {'train/accuracy': 0.9089205861091614, 'train/loss': 0.5751429796218872, 'validation/accuracy': 0.7743399739265442, 'validation/loss': 1.1133061647415161, 'validation/num_examples': 50000, 'test/accuracy': 0.6511000394821167, 'test/loss': 1.7018169164657593, 'test/num_examples': 10000, 'score': 47173.7046084404, 'total_duration': 49124.98744869232, 'accumulated_submission_time': 47173.7046084404, 'accumulated_eval_time': 1945.5379238128662, 'accumulated_logging_time': 3.5352821350097656, 'global_step': 140000, 'preemption_count': 0})], 'global_step': 140000}
I0921 13:59:18.422999 140613218989888 submission_runner.py:543] Timing: 47173.7046084404
I0921 13:59:18.423056 140613218989888 submission_runner.py:545] Total number of evals: 94
I0921 13:59:18.423099 140613218989888 submission_runner.py:546] ====================
I0921 13:59:18.423358 140613218989888 submission_runner.py:614] Final imagenet_resnet score: 47173.7046084404
