python3 submission_runner.py --framework=jax --workload=imagenet_resnet --submission_path=reference_algorithms/target_setting_algorithms/jax_momentum.py --tuning_search_space=reference_algorithms/target_setting_algorithms/imagenet_resnet/tuning_search_space.json --data_dir=/data/imagenet/jax --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=targets_check_jax_run_01/momentum_run_0 --overwrite=true --save_checkpoints=false --max_global_steps=140000 --imagenet_v2_data_dir=/data/imagenet/jax 2>&1 | tee -a /logs/imagenet_resnet_jax_09-18-2023-21-56-30.log
2023-09-18 21:56:35.714315: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
I0918 21:56:55.157577 140245097760576 logger_utils.py:76] Creating experiment directory at /experiment_runs/targets_check_jax_run_01/momentum_run_0/imagenet_resnet_jax.
I0918 21:56:56.160453 140245097760576 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter Host
I0918 21:56:56.161284 140245097760576 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0918 21:56:56.161425 140245097760576 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0918 21:56:56.167919 140245097760576 submission_runner.py:500] Using RNG seed 1497662247
I0918 21:57:02.167587 140245097760576 submission_runner.py:509] --- Tuning run 1/1 ---
I0918 21:57:02.167813 140245097760576 submission_runner.py:514] Creating tuning directory at /experiment_runs/targets_check_jax_run_01/momentum_run_0/imagenet_resnet_jax/trial_1.
I0918 21:57:02.167992 140245097760576 logger_utils.py:92] Saving hparams to /experiment_runs/targets_check_jax_run_01/momentum_run_0/imagenet_resnet_jax/trial_1/hparams.json.
I0918 21:57:02.352966 140245097760576 submission_runner.py:185] Initializing dataset.
I0918 21:57:02.376805 140245097760576 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0918 21:57:02.387336 140245097760576 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0918 21:57:02.776822 140245097760576 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0918 21:57:03.974661 140245097760576 submission_runner.py:192] Initializing model.
I0918 21:57:14.850217 140245097760576 submission_runner.py:226] Initializing optimizer.
I0918 21:57:16.415026 140245097760576 submission_runner.py:233] Initializing metrics bundle.
I0918 21:57:16.415236 140245097760576 submission_runner.py:251] Initializing checkpoint and logger.
I0918 21:57:16.416383 140245097760576 checkpoints.py:915] Found no checkpoint files in /experiment_runs/targets_check_jax_run_01/momentum_run_0/imagenet_resnet_jax/trial_1 with prefix checkpoint_
I0918 21:57:17.344566 140245097760576 submission_runner.py:272] Saving meta data to /experiment_runs/targets_check_jax_run_01/momentum_run_0/imagenet_resnet_jax/trial_1/meta_data_0.json.
I0918 21:57:17.346478 140245097760576 submission_runner.py:275] Saving flags to /experiment_runs/targets_check_jax_run_01/momentum_run_0/imagenet_resnet_jax/trial_1/flags_0.json.
I0918 21:57:17.355725 140245097760576 submission_runner.py:285] Starting training loop.
2023-09-18 21:58:17.779537: E external/xla/xla/service/rendezvous.cc:31] This thread has been waiting for 10 seconds and may be stuck:
2023-09-18 21:58:20.542905: E external/xla/xla/service/rendezvous.cc:36] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.
I0918 21:58:22.142515 140079183951616 logging_writer.py:48] [0] global_step=0, grad_norm=0.540239691734314, loss=6.935049057006836
I0918 21:58:22.162006 140245097760576 spec.py:320] Evaluating on the training split.
I0918 21:58:23.163855 140245097760576 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0918 21:58:23.174458 140245097760576 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0918 21:58:23.265866 140245097760576 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0918 21:58:36.558065 140245097760576 spec.py:332] Evaluating on the validation split.
I0918 21:58:37.801761 140245097760576 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0918 21:58:37.832764 140245097760576 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0918 21:58:37.895825 140245097760576 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0918 21:58:58.060387 140245097760576 spec.py:348] Evaluating on the test split.
I0918 21:58:58.880962 140245097760576 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0918 21:58:58.886100 140245097760576 dataset_builder.py:528] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0918 21:58:58.926051 140245097760576 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0918 21:59:09.856637 140245097760576 submission_runner.py:376] Time since start: 112.50s, 	Step: 1, 	{'train/accuracy': 0.0009167729294858873, 'train/loss': 6.912160873413086, 'validation/accuracy': 0.00107999995816499, 'validation/loss': 6.9129462242126465, 'validation/num_examples': 50000, 'test/accuracy': 0.0009000000427477062, 'test/loss': 6.912593364715576, 'test/num_examples': 10000, 'score': 64.80615377426147, 'total_duration': 112.50085163116455, 'accumulated_submission_time': 64.80615377426147, 'accumulated_eval_time': 47.69458341598511, 'accumulated_logging_time': 0}
I0918 21:59:09.879401 140051728017152 logging_writer.py:48] [1] accumulated_eval_time=47.694583, accumulated_logging_time=0, accumulated_submission_time=64.806154, global_step=1, preemption_count=0, score=64.806154, test/accuracy=0.000900, test/loss=6.912593, test/num_examples=10000, total_duration=112.500852, train/accuracy=0.000917, train/loss=6.912161, validation/accuracy=0.001080, validation/loss=6.912946, validation/num_examples=50000
I0918 21:59:10.232641 140051736409856 logging_writer.py:48] [1] global_step=1, grad_norm=0.537957489490509, loss=6.939721584320068
I0918 21:59:10.574777 140051728017152 logging_writer.py:48] [2] global_step=2, grad_norm=0.5566927790641785, loss=6.927579402923584
I0918 21:59:10.921761 140051736409856 logging_writer.py:48] [3] global_step=3, grad_norm=0.546130895614624, loss=6.931467533111572
I0918 21:59:11.265642 140051728017152 logging_writer.py:48] [4] global_step=4, grad_norm=0.5375412106513977, loss=6.928398132324219
I0918 21:59:11.607906 140051736409856 logging_writer.py:48] [5] global_step=5, grad_norm=0.5330464839935303, loss=6.919754505157471
I0918 21:59:11.943125 140051728017152 logging_writer.py:48] [6] global_step=6, grad_norm=0.542557954788208, loss=6.913405895233154
I0918 21:59:12.286510 140051736409856 logging_writer.py:48] [7] global_step=7, grad_norm=0.5327475070953369, loss=6.935346603393555
I0918 21:59:12.637643 140051728017152 logging_writer.py:48] [8] global_step=8, grad_norm=0.5338653922080994, loss=6.920569896697998
I0918 21:59:12.971779 140051736409856 logging_writer.py:48] [9] global_step=9, grad_norm=0.53280109167099, loss=6.923961639404297
I0918 21:59:13.317754 140051728017152 logging_writer.py:48] [10] global_step=10, grad_norm=0.5518768429756165, loss=6.921321868896484
I0918 21:59:13.665272 140051736409856 logging_writer.py:48] [11] global_step=11, grad_norm=0.537388026714325, loss=6.928396224975586
I0918 21:59:14.014029 140051728017152 logging_writer.py:48] [12] global_step=12, grad_norm=0.5421220064163208, loss=6.9235148429870605
I0918 21:59:14.359143 140051736409856 logging_writer.py:48] [13] global_step=13, grad_norm=0.5439914464950562, loss=6.915210247039795
I0918 21:59:14.711538 140051728017152 logging_writer.py:48] [14] global_step=14, grad_norm=0.5337656736373901, loss=6.932853698730469
I0918 21:59:15.057103 140051736409856 logging_writer.py:48] [15] global_step=15, grad_norm=0.5305963754653931, loss=6.910370349884033
I0918 21:59:15.402705 140051728017152 logging_writer.py:48] [16] global_step=16, grad_norm=0.5377213954925537, loss=6.913823127746582
I0918 21:59:15.751060 140051736409856 logging_writer.py:48] [17] global_step=17, grad_norm=0.5287356972694397, loss=6.911647319793701
I0918 21:59:16.104856 140051728017152 logging_writer.py:48] [18] global_step=18, grad_norm=0.5333185791969299, loss=6.915579319000244
I0918 21:59:16.455623 140051736409856 logging_writer.py:48] [19] global_step=19, grad_norm=0.5345672965049744, loss=6.912100315093994
I0918 21:59:16.811008 140051728017152 logging_writer.py:48] [20] global_step=20, grad_norm=0.546558141708374, loss=6.912709712982178
I0918 21:59:17.152222 140051736409856 logging_writer.py:48] [21] global_step=21, grad_norm=0.5509396195411682, loss=6.912834167480469
I0918 21:59:17.503935 140051728017152 logging_writer.py:48] [22] global_step=22, grad_norm=0.5471112132072449, loss=6.911868572235107
I0918 21:59:17.858096 140051736409856 logging_writer.py:48] [23] global_step=23, grad_norm=0.5348207354545593, loss=6.905935764312744
I0918 21:59:18.207865 140051728017152 logging_writer.py:48] [24] global_step=24, grad_norm=0.5242552161216736, loss=6.906692981719971
I0918 21:59:18.544747 140051736409856 logging_writer.py:48] [25] global_step=25, grad_norm=0.5257474184036255, loss=6.90167236328125
I0918 21:59:18.901803 140051728017152 logging_writer.py:48] [26] global_step=26, grad_norm=0.5192806720733643, loss=6.895348072052002
I0918 21:59:19.250618 140051736409856 logging_writer.py:48] [27] global_step=27, grad_norm=0.5364306569099426, loss=6.9006242752075195
I0918 21:59:19.602731 140051728017152 logging_writer.py:48] [28] global_step=28, grad_norm=0.5231704711914062, loss=6.900488376617432
I0918 21:59:19.951797 140051736409856 logging_writer.py:48] [29] global_step=29, grad_norm=0.5263739228248596, loss=6.900284767150879
I0918 21:59:20.305117 140051728017152 logging_writer.py:48] [30] global_step=30, grad_norm=0.5375543236732483, loss=6.901355743408203
I0918 21:59:20.657937 140051736409856 logging_writer.py:48] [31] global_step=31, grad_norm=0.5328873991966248, loss=6.89595890045166
I0918 21:59:21.009935 140051728017152 logging_writer.py:48] [32] global_step=32, grad_norm=0.5304853320121765, loss=6.887637138366699
I0918 21:59:21.357319 140051736409856 logging_writer.py:48] [33] global_step=33, grad_norm=0.5351240038871765, loss=6.890926361083984
I0918 21:59:21.706057 140051728017152 logging_writer.py:48] [34] global_step=34, grad_norm=0.5412804484367371, loss=6.8893818855285645
I0918 21:59:22.060202 140051736409856 logging_writer.py:48] [35] global_step=35, grad_norm=0.5404163002967834, loss=6.895193576812744
I0918 21:59:22.413890 140051728017152 logging_writer.py:48] [36] global_step=36, grad_norm=0.5307564735412598, loss=6.875616550445557
I0918 21:59:22.766036 140051736409856 logging_writer.py:48] [37] global_step=37, grad_norm=0.5408303737640381, loss=6.887465476989746
I0918 21:59:23.120168 140051728017152 logging_writer.py:48] [38] global_step=38, grad_norm=0.5406891107559204, loss=6.885532379150391
I0918 21:59:23.460273 140051736409856 logging_writer.py:48] [39] global_step=39, grad_norm=0.5566048622131348, loss=6.88167667388916
I0918 21:59:23.797096 140051728017152 logging_writer.py:48] [40] global_step=40, grad_norm=0.5427637100219727, loss=6.872408390045166
I0918 21:59:24.147178 140051736409856 logging_writer.py:48] [41] global_step=41, grad_norm=0.5367428064346313, loss=6.86783504486084
I0918 21:59:24.496494 140051728017152 logging_writer.py:48] [42] global_step=42, grad_norm=0.5224602222442627, loss=6.8742218017578125
I0918 21:59:24.844194 140051736409856 logging_writer.py:48] [43] global_step=43, grad_norm=0.554151177406311, loss=6.879422664642334
I0918 21:59:25.194461 140051728017152 logging_writer.py:48] [44] global_step=44, grad_norm=0.5350071787834167, loss=6.866204261779785
I0918 21:59:25.541064 140051736409856 logging_writer.py:48] [45] global_step=45, grad_norm=0.5288429856300354, loss=6.87493371963501
I0918 21:59:25.889819 140051728017152 logging_writer.py:48] [46] global_step=46, grad_norm=0.5547736883163452, loss=6.864381313323975
I0918 21:59:26.232620 140051736409856 logging_writer.py:48] [47] global_step=47, grad_norm=0.5395237803459167, loss=6.863713264465332
I0918 21:59:26.569977 140051728017152 logging_writer.py:48] [48] global_step=48, grad_norm=0.5515335202217102, loss=6.851443767547607
I0918 21:59:26.925964 140051736409856 logging_writer.py:48] [49] global_step=49, grad_norm=0.5592793822288513, loss=6.850809097290039
I0918 21:59:27.280738 140051728017152 logging_writer.py:48] [50] global_step=50, grad_norm=0.547350287437439, loss=6.853680610656738
I0918 21:59:27.627819 140051736409856 logging_writer.py:48] [51] global_step=51, grad_norm=0.5378409028053284, loss=6.867073059082031
I0918 21:59:27.973172 140051728017152 logging_writer.py:48] [52] global_step=52, grad_norm=0.5657081007957458, loss=6.848219871520996
I0918 21:59:28.323404 140051736409856 logging_writer.py:48] [53] global_step=53, grad_norm=0.5449942946434021, loss=6.852821350097656
I0918 21:59:28.659894 140051728017152 logging_writer.py:48] [54] global_step=54, grad_norm=0.5622574090957642, loss=6.835149765014648
I0918 21:59:29.005384 140051736409856 logging_writer.py:48] [55] global_step=55, grad_norm=0.55568528175354, loss=6.831630706787109
I0918 21:59:29.354437 140051728017152 logging_writer.py:48] [56] global_step=56, grad_norm=0.5520581007003784, loss=6.826972007751465
I0918 21:59:29.701667 140051736409856 logging_writer.py:48] [57] global_step=57, grad_norm=0.5682461261749268, loss=6.833032131195068
I0918 21:59:30.055157 140051728017152 logging_writer.py:48] [58] global_step=58, grad_norm=0.5392029285430908, loss=6.8253679275512695
I0918 21:59:30.402139 140051736409856 logging_writer.py:48] [59] global_step=59, grad_norm=0.5562225580215454, loss=6.823646068572998
I0918 21:59:30.748260 140051728017152 logging_writer.py:48] [60] global_step=60, grad_norm=0.5531567931175232, loss=6.82377815246582
I0918 21:59:31.101642 140051736409856 logging_writer.py:48] [61] global_step=61, grad_norm=0.5937596559524536, loss=6.817296028137207
I0918 21:59:31.450673 140051728017152 logging_writer.py:48] [62] global_step=62, grad_norm=0.547265350818634, loss=6.80377197265625
I0918 21:59:31.801862 140051736409856 logging_writer.py:48] [63] global_step=63, grad_norm=0.5740444660186768, loss=6.8124213218688965
I0918 21:59:32.139091 140051728017152 logging_writer.py:48] [64] global_step=64, grad_norm=0.5575976371765137, loss=6.800612926483154
I0918 21:59:32.489204 140051736409856 logging_writer.py:48] [65] global_step=65, grad_norm=0.5845440030097961, loss=6.810207843780518
I0918 21:59:32.841072 140051728017152 logging_writer.py:48] [66] global_step=66, grad_norm=0.5794809460639954, loss=6.798935413360596
I0918 21:59:33.195268 140051736409856 logging_writer.py:48] [67] global_step=67, grad_norm=0.5659559965133667, loss=6.787827014923096
I0918 21:59:33.543199 140051728017152 logging_writer.py:48] [68] global_step=68, grad_norm=0.5727720856666565, loss=6.786640167236328
I0918 21:59:33.898070 140051736409856 logging_writer.py:48] [69] global_step=69, grad_norm=0.5726144909858704, loss=6.7696404457092285
I0918 21:59:34.241304 140051728017152 logging_writer.py:48] [70] global_step=70, grad_norm=0.591446042060852, loss=6.787134170532227
I0918 21:59:34.585303 140051736409856 logging_writer.py:48] [71] global_step=71, grad_norm=0.574658989906311, loss=6.7761054039001465
I0918 21:59:34.923647 140051728017152 logging_writer.py:48] [72] global_step=72, grad_norm=0.5763656497001648, loss=6.770443916320801
I0918 21:59:35.270460 140051736409856 logging_writer.py:48] [73] global_step=73, grad_norm=0.599402129650116, loss=6.777858734130859
I0918 21:59:35.617994 140051728017152 logging_writer.py:48] [74] global_step=74, grad_norm=0.5969821214675903, loss=6.759809494018555
I0918 21:59:35.966331 140051736409856 logging_writer.py:48] [75] global_step=75, grad_norm=0.5846912264823914, loss=6.738851547241211
I0918 21:59:36.315372 140051728017152 logging_writer.py:48] [76] global_step=76, grad_norm=0.5828906893730164, loss=6.779227256774902
I0918 21:59:36.669971 140051736409856 logging_writer.py:48] [77] global_step=77, grad_norm=0.5930161476135254, loss=6.7450690269470215
I0918 21:59:37.020042 140051728017152 logging_writer.py:48] [78] global_step=78, grad_norm=0.6095826029777527, loss=6.77144718170166
I0918 21:59:37.369503 140051736409856 logging_writer.py:48] [79] global_step=79, grad_norm=0.5995645523071289, loss=6.7487711906433105
I0918 21:59:37.718018 140051728017152 logging_writer.py:48] [80] global_step=80, grad_norm=0.6054137945175171, loss=6.752806663513184
I0918 21:59:38.062475 140051736409856 logging_writer.py:48] [81] global_step=81, grad_norm=0.6347129344940186, loss=6.745769500732422
I0918 21:59:38.417183 140051728017152 logging_writer.py:48] [82] global_step=82, grad_norm=0.5979660153388977, loss=6.719090461730957
I0918 21:59:38.767258 140051736409856 logging_writer.py:48] [83] global_step=83, grad_norm=0.6053669452667236, loss=6.749204158782959
I0918 21:59:39.114748 140051728017152 logging_writer.py:48] [84] global_step=84, grad_norm=0.6097270846366882, loss=6.737092018127441
I0918 21:59:39.465534 140051736409856 logging_writer.py:48] [85] global_step=85, grad_norm=0.5948668122291565, loss=6.742681980133057
I0918 21:59:39.812483 140051728017152 logging_writer.py:48] [86] global_step=86, grad_norm=0.5941188931465149, loss=6.713531494140625
I0918 21:59:40.166137 140051736409856 logging_writer.py:48] [87] global_step=87, grad_norm=0.5962377786636353, loss=6.710093975067139
I0918 21:59:40.518995 140051728017152 logging_writer.py:48] [88] global_step=88, grad_norm=0.6199076771736145, loss=6.7559661865234375
I0918 21:59:40.864592 140051736409856 logging_writer.py:48] [89] global_step=89, grad_norm=0.6192276477813721, loss=6.739351749420166
I0918 21:59:41.213782 140051728017152 logging_writer.py:48] [90] global_step=90, grad_norm=0.5989221334457397, loss=6.717360496520996
I0918 21:59:41.559516 140051736409856 logging_writer.py:48] [91] global_step=91, grad_norm=0.6076995134353638, loss=6.7317986488342285
I0918 21:59:41.915435 140051728017152 logging_writer.py:48] [92] global_step=92, grad_norm=0.6201198101043701, loss=6.715114593505859
I0918 21:59:42.262703 140051736409856 logging_writer.py:48] [93] global_step=93, grad_norm=0.631504237651825, loss=6.701854228973389
I0918 21:59:42.611839 140051728017152 logging_writer.py:48] [94] global_step=94, grad_norm=0.6088209748268127, loss=6.713550567626953
I0918 21:59:42.961501 140051736409856 logging_writer.py:48] [95] global_step=95, grad_norm=0.6104635000228882, loss=6.699885368347168
I0918 21:59:43.315124 140051728017152 logging_writer.py:48] [96] global_step=96, grad_norm=0.5923188328742981, loss=6.686607837677002
I0918 21:59:43.669540 140051736409856 logging_writer.py:48] [97] global_step=97, grad_norm=0.6426099538803101, loss=6.683309555053711
I0918 21:59:44.023718 140051728017152 logging_writer.py:48] [98] global_step=98, grad_norm=0.6186212301254272, loss=6.670659065246582
I0918 21:59:44.373087 140051736409856 logging_writer.py:48] [99] global_step=99, grad_norm=0.6127018332481384, loss=6.665423393249512
I0918 21:59:44.724274 140051728017152 logging_writer.py:48] [100] global_step=100, grad_norm=0.6094993352890015, loss=6.676359176635742
I0918 22:01:59.707630 140051736409856 logging_writer.py:48] [500] global_step=500, grad_norm=0.46156033873558044, loss=6.164167881011963
I0918 22:04:48.345090 140051728017152 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.4720613658428192, loss=5.615428447723389
I0918 22:07:36.789477 140051736409856 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.44794443249702454, loss=5.1679368019104
I0918 22:07:39.916512 140245097760576 spec.py:320] Evaluating on the training split.
I0918 22:07:47.348739 140245097760576 spec.py:332] Evaluating on the validation split.
I0918 22:07:55.468968 140245097760576 spec.py:348] Evaluating on the test split.
I0918 22:07:57.743440 140245097760576 submission_runner.py:376] Time since start: 640.39s, 	Step: 1511, 	{'train/accuracy': 0.1892538219690323, 'train/loss': 4.242469787597656, 'validation/accuracy': 0.17117999494075775, 'validation/loss': 4.365173816680908, 'validation/num_examples': 50000, 'test/accuracy': 0.1291000097990036, 'test/loss': 4.756425857543945, 'test/num_examples': 10000, 'score': 574.8116409778595, 'total_duration': 640.3876354694366, 'accumulated_submission_time': 574.8116409778595, 'accumulated_eval_time': 65.52145624160767, 'accumulated_logging_time': 0.032228708267211914}
I0918 22:07:57.761517 140051879020288 logging_writer.py:48] [1511] accumulated_eval_time=65.521456, accumulated_logging_time=0.032229, accumulated_submission_time=574.811641, global_step=1511, preemption_count=0, score=574.811641, test/accuracy=0.129100, test/loss=4.756426, test/num_examples=10000, total_duration=640.387635, train/accuracy=0.189254, train/loss=4.242470, validation/accuracy=0.171180, validation/loss=4.365174, validation/num_examples=50000
I0918 22:10:42.774367 140051887412992 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.37116220593452454, loss=4.800940036773682
I0918 22:13:31.205044 140051879020288 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.3448173999786377, loss=4.502073764801025
I0918 22:16:19.626541 140051887412992 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.31043004989624023, loss=4.290902137756348
I0918 22:16:27.801487 140245097760576 spec.py:320] Evaluating on the training split.
I0918 22:16:35.513915 140245097760576 spec.py:332] Evaluating on the validation split.
I0918 22:16:43.807088 140245097760576 spec.py:348] Evaluating on the test split.
I0918 22:16:46.196463 140245097760576 submission_runner.py:376] Time since start: 1168.84s, 	Step: 3026, 	{'train/accuracy': 0.38362962007522583, 'train/loss': 3.044987440109253, 'validation/accuracy': 0.35221999883651733, 'validation/loss': 3.208611249923706, 'validation/num_examples': 50000, 'test/accuracy': 0.2648000121116638, 'test/loss': 3.803739309310913, 'test/num_examples': 10000, 'score': 1084.818897485733, 'total_duration': 1168.8404161930084, 'accumulated_submission_time': 1084.818897485733, 'accumulated_eval_time': 83.91613936424255, 'accumulated_logging_time': 0.06050562858581543}
I0918 22:16:46.214598 140080475789056 logging_writer.py:48] [3026] accumulated_eval_time=83.916139, accumulated_logging_time=0.060506, accumulated_submission_time=1084.818897, global_step=3026, preemption_count=0, score=1084.818897, test/accuracy=0.264800, test/loss=3.803739, test/num_examples=10000, total_duration=1168.840416, train/accuracy=0.383630, train/loss=3.044987, validation/accuracy=0.352220, validation/loss=3.208611, validation/num_examples=50000
I0918 22:19:26.104581 140080484181760 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.3050544559955597, loss=4.289724349975586
I0918 22:22:14.428314 140080475789056 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.2858978807926178, loss=4.150920391082764
I0918 22:25:02.682537 140080484181760 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.2826956808567047, loss=4.079341411590576
I0918 22:25:16.226367 140245097760576 spec.py:320] Evaluating on the training split.
I0918 22:25:23.608380 140245097760576 spec.py:332] Evaluating on the validation split.
I0918 22:25:32.137775 140245097760576 spec.py:348] Evaluating on the test split.
I0918 22:25:34.484184 140245097760576 submission_runner.py:376] Time since start: 1697.13s, 	Step: 4542, 	{'train/accuracy': 0.4262595474720001, 'train/loss': 2.840193033218384, 'validation/accuracy': 0.3979399800300598, 'validation/loss': 2.9878180027008057, 'validation/num_examples': 50000, 'test/accuracy': 0.2981000244617462, 'test/loss': 3.595538854598999, 'test/num_examples': 10000, 'score': 1594.7971105575562, 'total_duration': 1697.1283793449402, 'accumulated_submission_time': 1594.7971105575562, 'accumulated_eval_time': 102.17391872406006, 'accumulated_logging_time': 0.09000849723815918}
I0918 22:25:34.501937 140080467396352 logging_writer.py:48] [4542] accumulated_eval_time=102.173919, accumulated_logging_time=0.090008, accumulated_submission_time=1594.797111, global_step=4542, preemption_count=0, score=1594.797111, test/accuracy=0.298100, test/loss=3.595539, test/num_examples=10000, total_duration=1697.128379, train/accuracy=0.426260, train/loss=2.840193, validation/accuracy=0.397940, validation/loss=2.987818, validation/num_examples=50000
I0918 22:28:08.986500 140080651937536 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.2769806683063507, loss=4.020443439483643
I0918 22:30:57.247220 140080467396352 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.26367682218551636, loss=3.9636330604553223
I0918 22:33:45.456740 140080651937536 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.25553882122039795, loss=3.9955973625183105
I0918 22:34:04.727105 140245097760576 spec.py:320] Evaluating on the training split.
I0918 22:34:12.123036 140245097760576 spec.py:332] Evaluating on the validation split.
I0918 22:34:20.417112 140245097760576 spec.py:348] Evaluating on the test split.
I0918 22:34:22.820603 140245097760576 submission_runner.py:376] Time since start: 2225.46s, 	Step: 6059, 	{'train/accuracy': 0.5079719424247742, 'train/loss': 2.401481866836548, 'validation/accuracy': 0.4783399999141693, 'validation/loss': 2.5446739196777344, 'validation/num_examples': 50000, 'test/accuracy': 0.36730000376701355, 'test/loss': 3.2133424282073975, 'test/num_examples': 10000, 'score': 2104.9897060394287, 'total_duration': 2225.463969707489, 'accumulated_submission_time': 2104.9897060394287, 'accumulated_eval_time': 120.26653456687927, 'accumulated_logging_time': 0.11799263954162598}
I0918 22:34:22.838940 140080459003648 logging_writer.py:48] [6059] accumulated_eval_time=120.266535, accumulated_logging_time=0.117993, accumulated_submission_time=2104.989706, global_step=6059, preemption_count=0, score=2104.989706, test/accuracy=0.367300, test/loss=3.213342, test/num_examples=10000, total_duration=2225.463970, train/accuracy=0.507972, train/loss=2.401482, validation/accuracy=0.478340, validation/loss=2.544674, validation/num_examples=50000
I0918 22:36:51.641390 140080475789056 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.25589537620544434, loss=3.9748668670654297
I0918 22:39:39.834718 140080459003648 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.24100622534751892, loss=3.9211809635162354
I0918 22:42:28.028271 140080475789056 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.24363121390342712, loss=3.85188889503479
I0918 22:42:53.017943 140245097760576 spec.py:320] Evaluating on the training split.
I0918 22:43:00.536076 140245097760576 spec.py:332] Evaluating on the validation split.
I0918 22:43:08.908346 140245097760576 spec.py:348] Evaluating on the test split.
I0918 22:43:11.320298 140245097760576 submission_runner.py:376] Time since start: 2753.96s, 	Step: 7576, 	{'train/accuracy': 0.5211654901504517, 'train/loss': 2.3125686645507812, 'validation/accuracy': 0.4885199964046478, 'validation/loss': 2.4631083011627197, 'validation/num_examples': 50000, 'test/accuracy': 0.37960001826286316, 'test/loss': 3.142300844192505, 'test/num_examples': 10000, 'score': 2615.1366531848907, 'total_duration': 2753.9645006656647, 'accumulated_submission_time': 2615.1366531848907, 'accumulated_eval_time': 138.56886315345764, 'accumulated_logging_time': 0.14600682258605957}
I0918 22:43:11.338615 140080467396352 logging_writer.py:48] [7576] accumulated_eval_time=138.568863, accumulated_logging_time=0.146007, accumulated_submission_time=2615.136653, global_step=7576, preemption_count=0, score=2615.136653, test/accuracy=0.379600, test/loss=3.142301, test/num_examples=10000, total_duration=2753.964501, train/accuracy=0.521165, train/loss=2.312569, validation/accuracy=0.488520, validation/loss=2.463108, validation/num_examples=50000
I0918 22:45:34.405838 140080643544832 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.24075838923454285, loss=3.8157148361206055
I0918 22:48:22.639674 140080467396352 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.2416161298751831, loss=3.834956645965576
I0918 22:51:10.846396 140080643544832 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.24080783128738403, loss=3.891982316970825
I0918 22:51:41.538650 140245097760576 spec.py:320] Evaluating on the training split.
I0918 22:51:49.034225 140245097760576 spec.py:332] Evaluating on the validation split.
I0918 22:51:57.399171 140245097760576 spec.py:348] Evaluating on the test split.
I0918 22:51:59.750854 140245097760576 submission_runner.py:376] Time since start: 3282.40s, 	Step: 9093, 	{'train/accuracy': 0.5986328125, 'train/loss': 1.9171991348266602, 'validation/accuracy': 0.5203199982643127, 'validation/loss': 2.2843058109283447, 'validation/num_examples': 50000, 'test/accuracy': 0.4017000198364258, 'test/loss': 2.9574360847473145, 'test/num_examples': 10000, 'score': 3125.3041179180145, 'total_duration': 3282.39505815506, 'accumulated_submission_time': 3125.3041179180145, 'accumulated_eval_time': 156.78103804588318, 'accumulated_logging_time': 0.17435216903686523}
I0918 22:51:59.769212 140080459003648 logging_writer.py:48] [9093] accumulated_eval_time=156.781038, accumulated_logging_time=0.174352, accumulated_submission_time=3125.304118, global_step=9093, preemption_count=0, score=3125.304118, test/accuracy=0.401700, test/loss=2.957436, test/num_examples=10000, total_duration=3282.395058, train/accuracy=0.598633, train/loss=1.917199, validation/accuracy=0.520320, validation/loss=2.284306, validation/num_examples=50000
I0918 22:54:17.016503 140080475789056 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.2417319118976593, loss=3.7834088802337646
I0918 22:57:05.236913 140080459003648 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.2367546558380127, loss=3.7786917686462402
I0918 22:59:53.460466 140080475789056 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.23711854219436646, loss=3.762446641921997
I0918 23:00:29.843172 140245097760576 spec.py:320] Evaluating on the training split.
I0918 23:00:37.467519 140245097760576 spec.py:332] Evaluating on the validation split.
I0918 23:00:45.962256 140245097760576 spec.py:348] Evaluating on the test split.
I0918 23:00:48.328564 140245097760576 submission_runner.py:376] Time since start: 3810.97s, 	Step: 10610, 	{'train/accuracy': 0.5328643321990967, 'train/loss': 2.2464993000030518, 'validation/accuracy': 0.48135998845100403, 'validation/loss': 2.5128233432769775, 'validation/num_examples': 50000, 'test/accuracy': 0.3797000050544739, 'test/loss': 3.102165460586548, 'test/num_examples': 10000, 'score': 3635.3449680805206, 'total_duration': 3810.9727642536163, 'accumulated_submission_time': 3635.3449680805206, 'accumulated_eval_time': 175.2663881778717, 'accumulated_logging_time': 0.20341968536376953}
I0918 23:00:48.349245 140080249284352 logging_writer.py:48] [10610] accumulated_eval_time=175.266388, accumulated_logging_time=0.203420, accumulated_submission_time=3635.344968, global_step=10610, preemption_count=0, score=3635.344968, test/accuracy=0.379700, test/loss=3.102165, test/num_examples=10000, total_duration=3810.972764, train/accuracy=0.532864, train/loss=2.246499, validation/accuracy=0.481360, validation/loss=2.512823, validation/num_examples=50000
I0918 23:02:59.936265 140080257677056 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.23706525564193726, loss=3.7336502075195312
I0918 23:05:48.135613 140080249284352 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.2351362258195877, loss=3.7256224155426025
I0918 23:08:36.350561 140080257677056 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.2514578700065613, loss=3.6975438594818115
I0918 23:09:18.488682 140245097760576 spec.py:320] Evaluating on the training split.
I0918 23:09:26.048413 140245097760576 spec.py:332] Evaluating on the validation split.
I0918 23:09:34.708118 140245097760576 spec.py:348] Evaluating on the test split.
I0918 23:09:37.068768 140245097760576 submission_runner.py:376] Time since start: 4339.71s, 	Step: 12127, 	{'train/accuracy': 0.5541692972183228, 'train/loss': 2.180311679840088, 'validation/accuracy': 0.5069400072097778, 'validation/loss': 2.392803192138672, 'validation/num_examples': 50000, 'test/accuracy': 0.39420002698898315, 'test/loss': 3.0181732177734375, 'test/num_examples': 10000, 'score': 4145.451757669449, 'total_duration': 4339.712961912155, 'accumulated_submission_time': 4145.451757669449, 'accumulated_eval_time': 193.84642934799194, 'accumulated_logging_time': 0.23447585105895996}
I0918 23:09:37.096188 140080442218240 logging_writer.py:48] [12127] accumulated_eval_time=193.846429, accumulated_logging_time=0.234476, accumulated_submission_time=4145.451758, global_step=12127, preemption_count=0, score=4145.451758, test/accuracy=0.394200, test/loss=3.018173, test/num_examples=10000, total_duration=4339.712962, train/accuracy=0.554169, train/loss=2.180312, validation/accuracy=0.506940, validation/loss=2.392803, validation/num_examples=50000
I0918 23:11:42.940322 140080450610944 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.25638774037361145, loss=3.7417962551116943
I0918 23:14:31.225519 140080442218240 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.2420119345188141, loss=3.6038661003112793
I0918 23:17:19.410639 140080450610944 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.2406453788280487, loss=3.619415521621704
I0918 23:18:07.263685 140245097760576 spec.py:320] Evaluating on the training split.
I0918 23:18:14.757606 140245097760576 spec.py:332] Evaluating on the validation split.
I0918 23:18:23.473869 140245097760576 spec.py:348] Evaluating on the test split.
I0918 23:18:25.832725 140245097760576 submission_runner.py:376] Time since start: 4868.48s, 	Step: 13644, 	{'train/accuracy': 0.5454201102256775, 'train/loss': 2.18947434425354, 'validation/accuracy': 0.5059599876403809, 'validation/loss': 2.383917808532715, 'validation/num_examples': 50000, 'test/accuracy': 0.39330002665519714, 'test/loss': 3.0202107429504395, 'test/num_examples': 10000, 'score': 4655.583962917328, 'total_duration': 4868.476912498474, 'accumulated_submission_time': 4655.583962917328, 'accumulated_eval_time': 212.41541361808777, 'accumulated_logging_time': 0.2749812602996826}
I0918 23:18:25.852576 140080257677056 logging_writer.py:48] [13644] accumulated_eval_time=212.415414, accumulated_logging_time=0.274981, accumulated_submission_time=4655.583963, global_step=13644, preemption_count=0, score=4655.583963, test/accuracy=0.393300, test/loss=3.020211, test/num_examples=10000, total_duration=4868.476912, train/accuracy=0.545420, train/loss=2.189474, validation/accuracy=0.505960, validation/loss=2.383918, validation/num_examples=50000
I0918 23:20:25.893839 140080266069760 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.24486416578292847, loss=3.722256660461426
I0918 23:23:14.109590 140080257677056 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.253394216299057, loss=3.7281205654144287
I0918 23:26:02.308566 140080266069760 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.2523905038833618, loss=3.701465368270874
I0918 23:26:55.918486 140245097760576 spec.py:320] Evaluating on the training split.
I0918 23:27:04.328714 140245097760576 spec.py:332] Evaluating on the validation split.
I0918 23:27:12.940852 140245097760576 spec.py:348] Evaluating on the test split.
I0918 23:27:15.313172 140245097760576 submission_runner.py:376] Time since start: 5397.96s, 	Step: 15161, 	{'train/accuracy': 0.5900430083274841, 'train/loss': 1.940801739692688, 'validation/accuracy': 0.5483199954032898, 'validation/loss': 2.1355481147766113, 'validation/num_examples': 50000, 'test/accuracy': 0.4303000271320343, 'test/loss': 2.7870802879333496, 'test/num_examples': 10000, 'score': 5165.618021726608, 'total_duration': 5397.9573802948, 'accumulated_submission_time': 5165.618021726608, 'accumulated_eval_time': 231.81007027626038, 'accumulated_logging_time': 0.3049659729003906}
I0918 23:27:15.350729 140080266069760 logging_writer.py:48] [15161] accumulated_eval_time=231.810070, accumulated_logging_time=0.304966, accumulated_submission_time=5165.618022, global_step=15161, preemption_count=0, score=5165.618022, test/accuracy=0.430300, test/loss=2.787080, test/num_examples=10000, total_duration=5397.957380, train/accuracy=0.590043, train/loss=1.940802, validation/accuracy=0.548320, validation/loss=2.135548, validation/num_examples=50000
I0918 23:29:09.736321 140080291247872 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.248631551861763, loss=3.664045572280884
I0918 23:31:57.958965 140080266069760 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.2515967786312103, loss=3.678972005844116
I0918 23:34:46.158176 140080291247872 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.24811960756778717, loss=3.550895929336548
I0918 23:35:45.441865 140245097760576 spec.py:320] Evaluating on the training split.
I0918 23:35:53.136680 140245097760576 spec.py:332] Evaluating on the validation split.
I0918 23:36:01.719853 140245097760576 spec.py:348] Evaluating on the test split.
I0918 23:36:04.064246 140245097760576 submission_runner.py:376] Time since start: 5926.71s, 	Step: 16678, 	{'train/accuracy': 0.5860371589660645, 'train/loss': 1.9944552183151245, 'validation/accuracy': 0.550059974193573, 'validation/loss': 2.1530261039733887, 'validation/num_examples': 50000, 'test/accuracy': 0.4279000163078308, 'test/loss': 2.8396711349487305, 'test/num_examples': 10000, 'score': 5675.676437139511, 'total_duration': 5926.708446502686, 'accumulated_submission_time': 5675.676437139511, 'accumulated_eval_time': 250.43241119384766, 'accumulated_logging_time': 0.3533515930175781}
I0918 23:36:04.087614 140080257677056 logging_writer.py:48] [16678] accumulated_eval_time=250.432411, accumulated_logging_time=0.353352, accumulated_submission_time=5675.676437, global_step=16678, preemption_count=0, score=5675.676437, test/accuracy=0.427900, test/loss=2.839671, test/num_examples=10000, total_duration=5926.708447, train/accuracy=0.586037, train/loss=1.994455, validation/accuracy=0.550060, validation/loss=2.153026, validation/num_examples=50000
I0918 23:37:52.832546 140080274462464 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.24842213094234467, loss=3.6571249961853027
I0918 23:40:41.044709 140080257677056 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.2402810901403427, loss=3.633235216140747
I0918 23:43:29.248854 140080274462464 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.24626941978931427, loss=3.6401214599609375
I0918 23:44:34.253064 140245097760576 spec.py:320] Evaluating on the training split.
I0918 23:44:42.882621 140245097760576 spec.py:332] Evaluating on the validation split.
I0918 23:44:51.328209 140245097760576 spec.py:348] Evaluating on the test split.
I0918 23:44:53.616991 140245097760576 submission_runner.py:376] Time since start: 6456.26s, 	Step: 18195, 	{'train/accuracy': 0.6191805005073547, 'train/loss': 1.8125768899917603, 'validation/accuracy': 0.5428199768066406, 'validation/loss': 2.1788017749786377, 'validation/num_examples': 50000, 'test/accuracy': 0.415800005197525, 'test/loss': 2.8776638507843018, 'test/num_examples': 10000, 'score': 6185.806494951248, 'total_duration': 6456.2611672878265, 'accumulated_submission_time': 6185.806494951248, 'accumulated_eval_time': 269.7962746620178, 'accumulated_logging_time': 0.38915419578552246}
I0918 23:44:53.655208 140080274462464 logging_writer.py:48] [18195] accumulated_eval_time=269.796275, accumulated_logging_time=0.389154, accumulated_submission_time=6185.806495, global_step=18195, preemption_count=0, score=6185.806495, test/accuracy=0.415800, test/loss=2.877664, test/num_examples=10000, total_duration=6456.261167, train/accuracy=0.619181, train/loss=1.812577, validation/accuracy=0.542820, validation/loss=2.178802, validation/num_examples=50000
I0918 23:46:36.631381 140080282855168 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.2505626082420349, loss=3.6870222091674805
I0918 23:49:24.831107 140080274462464 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.2552146911621094, loss=3.647801399230957
I0918 23:52:13.017815 140080282855168 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.2615339159965515, loss=3.723147392272949
I0918 23:53:23.750364 140245097760576 spec.py:320] Evaluating on the training split.
I0918 23:53:31.568997 140245097760576 spec.py:332] Evaluating on the validation split.
I0918 23:53:40.196205 140245097760576 spec.py:348] Evaluating on the test split.
I0918 23:53:42.517608 140245097760576 submission_runner.py:376] Time since start: 6985.16s, 	Step: 19712, 	{'train/accuracy': 0.6296635866165161, 'train/loss': 1.755889654159546, 'validation/accuracy': 0.5690000057220459, 'validation/loss': 2.028282880783081, 'validation/num_examples': 50000, 'test/accuracy': 0.4487000107765198, 'test/loss': 2.6749298572540283, 'test/num_examples': 10000, 'score': 6695.867879390717, 'total_duration': 6985.161635398865, 'accumulated_submission_time': 6695.867879390717, 'accumulated_eval_time': 288.56330966949463, 'accumulated_logging_time': 0.4392695426940918}
I0918 23:53:42.542144 140080249284352 logging_writer.py:48] [19712] accumulated_eval_time=288.563310, accumulated_logging_time=0.439270, accumulated_submission_time=6695.867879, global_step=19712, preemption_count=0, score=6695.867879, test/accuracy=0.448700, test/loss=2.674930, test/num_examples=10000, total_duration=6985.161635, train/accuracy=0.629664, train/loss=1.755890, validation/accuracy=0.569000, validation/loss=2.028283, validation/num_examples=50000
I0918 23:55:19.756645 140080257677056 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.2531561851501465, loss=3.5629990100860596
I0918 23:58:08.058607 140080249284352 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.24118556082248688, loss=3.577033042907715
I0919 00:00:56.225886 140080257677056 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.25539007782936096, loss=3.710142135620117
I0919 00:02:12.664367 140245097760576 spec.py:320] Evaluating on the training split.
I0919 00:02:20.963671 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 00:02:30.554243 140245097760576 spec.py:348] Evaluating on the test split.
I0919 00:02:32.969914 140245097760576 submission_runner.py:376] Time since start: 7515.61s, 	Step: 21229, 	{'train/accuracy': 0.6113680005073547, 'train/loss': 1.9071935415267944, 'validation/accuracy': 0.5615400075912476, 'validation/loss': 2.136620044708252, 'validation/num_examples': 50000, 'test/accuracy': 0.4368000328540802, 'test/loss': 2.8098642826080322, 'test/num_examples': 10000, 'score': 7205.9560983181, 'total_duration': 7515.6140875816345, 'accumulated_submission_time': 7205.9560983181, 'accumulated_eval_time': 308.8688642978668, 'accumulated_logging_time': 0.4752368927001953}
I0919 00:02:33.008499 140080257677056 logging_writer.py:48] [21229] accumulated_eval_time=308.868864, accumulated_logging_time=0.475237, accumulated_submission_time=7205.956098, global_step=21229, preemption_count=0, score=7205.956098, test/accuracy=0.436800, test/loss=2.809864, test/num_examples=10000, total_duration=7515.614088, train/accuracy=0.611368, train/loss=1.907194, validation/accuracy=0.561540, validation/loss=2.136620, validation/num_examples=50000
I0919 00:04:04.546581 140080282855168 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.2556680738925934, loss=3.65358829498291
I0919 00:06:52.827165 140080257677056 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.24866637587547302, loss=3.579869031906128
I0919 00:09:40.989492 140080282855168 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.2561415433883667, loss=3.540999412536621
I0919 00:11:03.170323 140245097760576 spec.py:320] Evaluating on the training split.
I0919 00:11:11.048342 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 00:11:20.531853 140245097760576 spec.py:348] Evaluating on the test split.
I0919 00:11:22.874132 140245097760576 submission_runner.py:376] Time since start: 8045.52s, 	Step: 22746, 	{'train/accuracy': 0.5900828838348389, 'train/loss': 2.003718614578247, 'validation/accuracy': 0.5470600128173828, 'validation/loss': 2.1998207569122314, 'validation/num_examples': 50000, 'test/accuracy': 0.4289000332355499, 'test/loss': 2.8556807041168213, 'test/num_examples': 10000, 'score': 7716.082714080811, 'total_duration': 8045.518242359161, 'accumulated_submission_time': 7716.082714080811, 'accumulated_eval_time': 328.57254815101624, 'accumulated_logging_time': 0.5265705585479736}
I0919 00:11:22.895421 140080249284352 logging_writer.py:48] [22746] accumulated_eval_time=328.572548, accumulated_logging_time=0.526571, accumulated_submission_time=7716.082714, global_step=22746, preemption_count=0, score=7716.082714, test/accuracy=0.428900, test/loss=2.855681, test/num_examples=10000, total_duration=8045.518242, train/accuracy=0.590083, train/loss=2.003719, validation/accuracy=0.547060, validation/loss=2.199821, validation/num_examples=50000
I0919 00:12:48.665729 140080274462464 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.2519179880619049, loss=3.5236072540283203
I0919 00:15:36.896762 140080249284352 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.25313320755958557, loss=3.5622899532318115
I0919 00:18:25.135203 140080274462464 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.25610610842704773, loss=3.499329090118408
I0919 00:19:52.987135 140245097760576 spec.py:320] Evaluating on the training split.
I0919 00:20:00.879484 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 00:20:10.435391 140245097760576 spec.py:348] Evaluating on the test split.
I0919 00:20:12.763148 140245097760576 submission_runner.py:376] Time since start: 8575.41s, 	Step: 24263, 	{'train/accuracy': 0.5965002775192261, 'train/loss': 1.9317721128463745, 'validation/accuracy': 0.5542600154876709, 'validation/loss': 2.1205153465270996, 'validation/num_examples': 50000, 'test/accuracy': 0.4285000264644623, 'test/loss': 2.80458927154541, 'test/num_examples': 10000, 'score': 8226.141713142395, 'total_duration': 8575.407284259796, 'accumulated_submission_time': 8226.141713142395, 'accumulated_eval_time': 348.34847712516785, 'accumulated_logging_time': 0.5582351684570312}
I0919 00:20:12.782865 140080266069760 logging_writer.py:48] [24263] accumulated_eval_time=348.348477, accumulated_logging_time=0.558235, accumulated_submission_time=8226.141713, global_step=24263, preemption_count=0, score=8226.141713, test/accuracy=0.428500, test/loss=2.804589, test/num_examples=10000, total_duration=8575.407284, train/accuracy=0.596500, train/loss=1.931772, validation/accuracy=0.554260, validation/loss=2.120515, validation/num_examples=50000
I0919 00:21:32.883288 140080282855168 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.25413334369659424, loss=3.5655453205108643
I0919 00:24:21.120984 140080266069760 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.2593158781528473, loss=3.5785157680511475
I0919 00:27:09.313635 140080282855168 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.24525098502635956, loss=3.5129997730255127
I0919 00:28:42.911194 140245097760576 spec.py:320] Evaluating on the training split.
I0919 00:28:50.908375 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 00:29:00.351155 140245097760576 spec.py:348] Evaluating on the test split.
I0919 00:29:03.432417 140245097760576 submission_runner.py:376] Time since start: 9106.08s, 	Step: 25780, 	{'train/accuracy': 0.6048309803009033, 'train/loss': 1.9325666427612305, 'validation/accuracy': 0.5648199915885925, 'validation/loss': 2.1053247451782227, 'validation/num_examples': 50000, 'test/accuracy': 0.4458000063896179, 'test/loss': 2.7545578479766846, 'test/num_examples': 10000, 'score': 8736.2371571064, 'total_duration': 9106.076616764069, 'accumulated_submission_time': 8736.2371571064, 'accumulated_eval_time': 368.86967420578003, 'accumulated_logging_time': 0.5889146327972412}
I0919 00:29:03.451916 140080442218240 logging_writer.py:48] [25780] accumulated_eval_time=368.869674, accumulated_logging_time=0.588915, accumulated_submission_time=8736.237157, global_step=25780, preemption_count=0, score=8736.237157, test/accuracy=0.445800, test/loss=2.754558, test/num_examples=10000, total_duration=9106.076617, train/accuracy=0.604831, train/loss=1.932567, validation/accuracy=0.564820, validation/loss=2.105325, validation/num_examples=50000
I0919 00:30:17.815104 140080450610944 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.2585650384426117, loss=3.6112072467803955
I0919 00:33:06.084702 140080442218240 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.25694411993026733, loss=3.603668212890625
I0919 00:35:54.279342 140080450610944 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.2586984932422638, loss=3.5615968704223633
I0919 00:37:33.585846 140245097760576 spec.py:320] Evaluating on the training split.
I0919 00:37:41.710564 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 00:37:51.949539 140245097760576 spec.py:348] Evaluating on the test split.
I0919 00:37:54.294289 140245097760576 submission_runner.py:376] Time since start: 9636.94s, 	Step: 27297, 	{'train/accuracy': 0.648457407951355, 'train/loss': 1.7073768377304077, 'validation/accuracy': 0.5740599632263184, 'validation/loss': 2.045314073562622, 'validation/num_examples': 50000, 'test/accuracy': 0.4489000141620636, 'test/loss': 2.731684684753418, 'test/num_examples': 10000, 'score': 9246.338513851166, 'total_duration': 9636.938492059708, 'accumulated_submission_time': 9246.338513851166, 'accumulated_eval_time': 389.5780885219574, 'accumulated_logging_time': 0.6190969944000244}
I0919 00:37:54.316069 140080266069760 logging_writer.py:48] [27297] accumulated_eval_time=389.578089, accumulated_logging_time=0.619097, accumulated_submission_time=9246.338514, global_step=27297, preemption_count=0, score=9246.338514, test/accuracy=0.448900, test/loss=2.731685, test/num_examples=10000, total_duration=9636.938492, train/accuracy=0.648457, train/loss=1.707377, validation/accuracy=0.574060, validation/loss=2.045314, validation/num_examples=50000
I0919 00:39:02.900834 140080274462464 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.26477304100990295, loss=3.5556864738464355
I0919 00:41:51.060607 140080266069760 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.27134862542152405, loss=3.5561728477478027
I0919 00:44:39.326669 140080274462464 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.268661767244339, loss=3.5467000007629395
I0919 00:46:24.376168 140245097760576 spec.py:320] Evaluating on the training split.
I0919 00:46:32.535331 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 00:46:42.231639 140245097760576 spec.py:348] Evaluating on the test split.
I0919 00:46:44.581800 140245097760576 submission_runner.py:376] Time since start: 10167.23s, 	Step: 28814, 	{'train/accuracy': 0.6102519035339355, 'train/loss': 1.919688105583191, 'validation/accuracy': 0.5570200085639954, 'validation/loss': 2.1826367378234863, 'validation/num_examples': 50000, 'test/accuracy': 0.43880000710487366, 'test/loss': 2.8118410110473633, 'test/num_examples': 10000, 'score': 9756.365114688873, 'total_duration': 10167.22600197792, 'accumulated_submission_time': 9756.365114688873, 'accumulated_eval_time': 409.78370451927185, 'accumulated_logging_time': 0.6514098644256592}
I0919 00:46:44.604682 140079133595392 logging_writer.py:48] [28814] accumulated_eval_time=409.783705, accumulated_logging_time=0.651410, accumulated_submission_time=9756.365115, global_step=28814, preemption_count=0, score=9756.365115, test/accuracy=0.438800, test/loss=2.811841, test/num_examples=10000, total_duration=10167.226002, train/accuracy=0.610252, train/loss=1.919688, validation/accuracy=0.557020, validation/loss=2.182637, validation/num_examples=50000
I0919 00:47:47.491552 140079141988096 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.2613731324672699, loss=3.565340518951416
I0919 00:50:35.771190 140079133595392 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.2516045868396759, loss=3.5342354774475098
I0919 00:53:23.920725 140079141988096 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.2569645941257477, loss=3.5042271614074707
I0919 00:55:14.732998 140245097760576 spec.py:320] Evaluating on the training split.
I0919 00:55:23.169877 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 00:55:34.024150 140245097760576 spec.py:348] Evaluating on the test split.
I0919 00:55:36.351127 140245097760576 submission_runner.py:376] Time since start: 10699.00s, 	Step: 30331, 	{'train/accuracy': 0.6017019748687744, 'train/loss': 1.9694526195526123, 'validation/accuracy': 0.5550999641418457, 'validation/loss': 2.1903817653656006, 'validation/num_examples': 50000, 'test/accuracy': 0.43250003457069397, 'test/loss': 2.8544583320617676, 'test/num_examples': 10000, 'score': 10266.457380771637, 'total_duration': 10698.995329380035, 'accumulated_submission_time': 10266.457380771637, 'accumulated_eval_time': 431.4018225669861, 'accumulated_logging_time': 0.6866528987884521}
I0919 00:55:36.373170 140078412199680 logging_writer.py:48] [30331] accumulated_eval_time=431.401823, accumulated_logging_time=0.686653, accumulated_submission_time=10266.457381, global_step=30331, preemption_count=0, score=10266.457381, test/accuracy=0.432500, test/loss=2.854458, test/num_examples=10000, total_duration=10698.995329, train/accuracy=0.601702, train/loss=1.969453, validation/accuracy=0.555100, validation/loss=2.190382, validation/num_examples=50000
I0919 00:56:33.491092 140079158773504 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.26855888962745667, loss=3.5986645221710205
I0919 00:59:21.716254 140078412199680 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.26509132981300354, loss=3.552147150039673
I0919 01:02:09.839443 140079158773504 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.26568758487701416, loss=3.4328675270080566
I0919 01:04:06.650763 140245097760576 spec.py:320] Evaluating on the training split.
I0919 01:04:14.936959 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 01:04:25.216504 140245097760576 spec.py:348] Evaluating on the test split.
I0919 01:04:27.570933 140245097760576 submission_runner.py:376] Time since start: 11230.22s, 	Step: 31849, 	{'train/accuracy': 0.6138990521430969, 'train/loss': 1.9323968887329102, 'validation/accuracy': 0.5714600086212158, 'validation/loss': 2.1468288898468018, 'validation/num_examples': 50000, 'test/accuracy': 0.4465000331401825, 'test/loss': 2.7963528633117676, 'test/num_examples': 10000, 'score': 10776.701550006866, 'total_duration': 11230.215115308762, 'accumulated_submission_time': 10776.701550006866, 'accumulated_eval_time': 452.32195019721985, 'accumulated_logging_time': 0.7195277214050293}
I0919 01:04:27.601397 140078395414272 logging_writer.py:48] [31849] accumulated_eval_time=452.321950, accumulated_logging_time=0.719528, accumulated_submission_time=10776.701550, global_step=31849, preemption_count=0, score=10776.701550, test/accuracy=0.446500, test/loss=2.796353, test/num_examples=10000, total_duration=11230.215115, train/accuracy=0.613899, train/loss=1.932397, validation/accuracy=0.571460, validation/loss=2.146829, validation/num_examples=50000
I0919 01:05:18.675214 140078403806976 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.2624575197696686, loss=3.433169364929199
I0919 01:08:06.857886 140078395414272 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.2773100733757019, loss=3.5274384021759033
I0919 01:10:55.028332 140078403806976 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.25925934314727783, loss=3.479710578918457
I0919 01:12:57.904276 140245097760576 spec.py:320] Evaluating on the training split.
I0919 01:13:06.336573 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 01:13:17.022635 140245097760576 spec.py:348] Evaluating on the test split.
I0919 01:13:19.387740 140245097760576 submission_runner.py:376] Time since start: 11762.03s, 	Step: 33367, 	{'train/accuracy': 0.6291453838348389, 'train/loss': 1.737581491470337, 'validation/accuracy': 0.5842999815940857, 'validation/loss': 1.9522442817687988, 'validation/num_examples': 50000, 'test/accuracy': 0.46300002932548523, 'test/loss': 2.632305145263672, 'test/num_examples': 10000, 'score': 11286.97012758255, 'total_duration': 11762.031930208206, 'accumulated_submission_time': 11286.97012758255, 'accumulated_eval_time': 473.80539107322693, 'accumulated_logging_time': 0.7617902755737305}
I0919 01:13:19.416627 140078403806976 logging_writer.py:48] [33367] accumulated_eval_time=473.805391, accumulated_logging_time=0.761790, accumulated_submission_time=11286.970128, global_step=33367, preemption_count=0, score=11286.970128, test/accuracy=0.463000, test/loss=2.632305, test/num_examples=10000, total_duration=11762.031930, train/accuracy=0.629145, train/loss=1.737581, validation/accuracy=0.584300, validation/loss=1.952244, validation/num_examples=50000
I0919 01:14:04.492772 140079888594688 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.256636381149292, loss=3.3847835063934326
I0919 01:16:52.667838 140078403806976 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.2686503529548645, loss=3.522312641143799
I0919 01:19:40.837000 140079888594688 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.2549910545349121, loss=3.452566623687744
I0919 01:21:49.430578 140245097760576 spec.py:320] Evaluating on the training split.
I0919 01:21:57.861925 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 01:22:08.911191 140245097760576 spec.py:348] Evaluating on the test split.
I0919 01:22:11.234654 140245097760576 submission_runner.py:376] Time since start: 12293.88s, 	Step: 34884, 	{'train/accuracy': 0.6321348547935486, 'train/loss': 1.7898281812667847, 'validation/accuracy': 0.5905599594116211, 'validation/loss': 1.9755117893218994, 'validation/num_examples': 50000, 'test/accuracy': 0.467600017786026, 'test/loss': 2.653351068496704, 'test/num_examples': 10000, 'score': 11796.948772668839, 'total_duration': 12293.878856658936, 'accumulated_submission_time': 11796.948772668839, 'accumulated_eval_time': 495.6094489097595, 'accumulated_logging_time': 0.8033304214477539}
I0919 01:22:11.260421 140078403806976 logging_writer.py:48] [34884] accumulated_eval_time=495.609449, accumulated_logging_time=0.803330, accumulated_submission_time=11796.948773, global_step=34884, preemption_count=0, score=11796.948773, test/accuracy=0.467600, test/loss=2.653351, test/num_examples=10000, total_duration=12293.878857, train/accuracy=0.632135, train/loss=1.789828, validation/accuracy=0.590560, validation/loss=1.975512, validation/num_examples=50000
I0919 01:22:50.655415 140078412199680 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.2627699077129364, loss=3.513706922531128
I0919 01:25:38.857045 140078403806976 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.2677716612815857, loss=3.490694522857666
I0919 01:28:27.021181 140078412199680 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.26223647594451904, loss=3.4565210342407227
I0919 01:30:41.338780 140245097760576 spec.py:320] Evaluating on the training split.
I0919 01:30:49.880909 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 01:31:00.741896 140245097760576 spec.py:348] Evaluating on the test split.
I0919 01:31:03.590406 140245097760576 submission_runner.py:376] Time since start: 12826.23s, 	Step: 36401, 	{'train/accuracy': 0.6490353941917419, 'train/loss': 1.7624365091323853, 'validation/accuracy': 0.5829399824142456, 'validation/loss': 2.069182872772217, 'validation/num_examples': 50000, 'test/accuracy': 0.4589000344276428, 'test/loss': 2.729459524154663, 'test/num_examples': 10000, 'score': 12306.99295759201, 'total_duration': 12826.234589576721, 'accumulated_submission_time': 12306.99295759201, 'accumulated_eval_time': 517.8610317707062, 'accumulated_logging_time': 0.840540885925293}
I0919 01:31:03.616062 140079888594688 logging_writer.py:48] [36401] accumulated_eval_time=517.861032, accumulated_logging_time=0.840541, accumulated_submission_time=12306.992958, global_step=36401, preemption_count=0, score=12306.992958, test/accuracy=0.458900, test/loss=2.729460, test/num_examples=10000, total_duration=12826.234590, train/accuracy=0.649035, train/loss=1.762437, validation/accuracy=0.582940, validation/loss=2.069183, validation/num_examples=50000
I0919 01:31:37.206350 140080442218240 logging_writer.py:48] [36500] global_step=36500, grad_norm=0.26184630393981934, loss=3.488227367401123
I0919 01:34:25.256488 140079888594688 logging_writer.py:48] [37000] global_step=37000, grad_norm=0.2618275284767151, loss=3.486252784729004
I0919 01:37:13.411254 140080442218240 logging_writer.py:48] [37500] global_step=37500, grad_norm=0.257697194814682, loss=3.44376277923584
I0919 01:39:33.775526 140245097760576 spec.py:320] Evaluating on the training split.
I0919 01:39:41.558793 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 01:39:52.248627 140245097760576 spec.py:348] Evaluating on the test split.
I0919 01:39:54.587508 140245097760576 submission_runner.py:376] Time since start: 13357.23s, 	Step: 37919, 	{'train/accuracy': 0.6336694955825806, 'train/loss': 1.7425209283828735, 'validation/accuracy': 0.579800009727478, 'validation/loss': 2.002507448196411, 'validation/num_examples': 50000, 'test/accuracy': 0.4490000307559967, 'test/loss': 2.7044670581817627, 'test/num_examples': 10000, 'score': 12817.115663766861, 'total_duration': 13357.231716394424, 'accumulated_submission_time': 12817.115663766861, 'accumulated_eval_time': 538.673003911972, 'accumulated_logging_time': 0.8800115585327148}
I0919 01:39:54.616648 140078412199680 logging_writer.py:48] [37919] accumulated_eval_time=538.673004, accumulated_logging_time=0.880012, accumulated_submission_time=12817.115664, global_step=37919, preemption_count=0, score=12817.115664, test/accuracy=0.449000, test/loss=2.704467, test/num_examples=10000, total_duration=13357.231716, train/accuracy=0.633669, train/loss=1.742521, validation/accuracy=0.579800, validation/loss=2.002507, validation/num_examples=50000
I0919 01:40:22.226012 140079100045056 logging_writer.py:48] [38000] global_step=38000, grad_norm=0.26343804597854614, loss=3.5246500968933105
I0919 01:43:10.463006 140078412199680 logging_writer.py:48] [38500] global_step=38500, grad_norm=0.26730436086654663, loss=3.4481799602508545
I0919 01:45:58.633410 140079100045056 logging_writer.py:48] [39000] global_step=39000, grad_norm=0.26414981484413147, loss=3.4847030639648438
I0919 01:48:24.692987 140245097760576 spec.py:320] Evaluating on the training split.
I0919 01:48:32.509499 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 01:48:43.134039 140245097760576 spec.py:348] Evaluating on the test split.
I0919 01:48:45.579774 140245097760576 submission_runner.py:376] Time since start: 13888.22s, 	Step: 39436, 	{'train/accuracy': 0.6382334232330322, 'train/loss': 1.7431460618972778, 'validation/accuracy': 0.587619960308075, 'validation/loss': 1.9530900716781616, 'validation/num_examples': 50000, 'test/accuracy': 0.4626000225543976, 'test/loss': 2.6381335258483887, 'test/num_examples': 10000, 'score': 13327.157706737518, 'total_duration': 13888.223961114883, 'accumulated_submission_time': 13327.157706737518, 'accumulated_eval_time': 559.5597512722015, 'accumulated_logging_time': 0.9208221435546875}
I0919 01:48:45.607666 140079158773504 logging_writer.py:48] [39436] accumulated_eval_time=559.559751, accumulated_logging_time=0.920822, accumulated_submission_time=13327.157707, global_step=39436, preemption_count=0, score=13327.157707, test/accuracy=0.462600, test/loss=2.638134, test/num_examples=10000, total_duration=13888.223961, train/accuracy=0.638233, train/loss=1.743146, validation/accuracy=0.587620, validation/loss=1.953090, validation/num_examples=50000
I0919 01:49:07.444315 140079888594688 logging_writer.py:48] [39500] global_step=39500, grad_norm=0.27595818042755127, loss=3.4318594932556152
I0919 01:51:55.636707 140079158773504 logging_writer.py:48] [40000] global_step=40000, grad_norm=0.26771917939186096, loss=3.535384178161621
I0919 01:54:43.791197 140079888594688 logging_writer.py:48] [40500] global_step=40500, grad_norm=0.270791232585907, loss=3.4515914916992188
I0919 01:57:15.632778 140245097760576 spec.py:320] Evaluating on the training split.
I0919 01:57:23.491635 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 01:57:34.019559 140245097760576 spec.py:348] Evaluating on the test split.
I0919 01:57:36.366828 140245097760576 submission_runner.py:376] Time since start: 14419.01s, 	Step: 40953, 	{'train/accuracy': 0.6347058415412903, 'train/loss': 1.778356909751892, 'validation/accuracy': 0.5856800079345703, 'validation/loss': 1.9926531314849854, 'validation/num_examples': 50000, 'test/accuracy': 0.4652000367641449, 'test/loss': 2.6373789310455322, 'test/num_examples': 10000, 'score': 13837.148118257523, 'total_duration': 14419.011028289795, 'accumulated_submission_time': 13837.148118257523, 'accumulated_eval_time': 580.2938213348389, 'accumulated_logging_time': 0.960615873336792}
I0919 01:57:36.389857 140078412199680 logging_writer.py:48] [40953] accumulated_eval_time=580.293821, accumulated_logging_time=0.960616, accumulated_submission_time=13837.148118, global_step=40953, preemption_count=0, score=13837.148118, test/accuracy=0.465200, test/loss=2.637379, test/num_examples=10000, total_duration=14419.011028, train/accuracy=0.634706, train/loss=1.778357, validation/accuracy=0.585680, validation/loss=1.992653, validation/num_examples=50000
I0919 01:57:52.511426 140079100045056 logging_writer.py:48] [41000] global_step=41000, grad_norm=0.2754214107990265, loss=3.4713830947875977
I0919 02:00:40.671765 140078412199680 logging_writer.py:48] [41500] global_step=41500, grad_norm=0.2676386535167694, loss=3.417041301727295
I0919 02:03:28.843675 140079100045056 logging_writer.py:48] [42000] global_step=42000, grad_norm=0.26494038105010986, loss=3.474762201309204
I0919 02:06:06.685448 140245097760576 spec.py:320] Evaluating on the training split.
I0919 02:06:14.415704 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 02:06:25.022056 140245097760576 spec.py:348] Evaluating on the test split.
I0919 02:06:27.350578 140245097760576 submission_runner.py:376] Time since start: 14949.99s, 	Step: 42471, 	{'train/accuracy': 0.6211734414100647, 'train/loss': 1.8077707290649414, 'validation/accuracy': 0.5771799683570862, 'validation/loss': 2.0112338066101074, 'validation/num_examples': 50000, 'test/accuracy': 0.4529000222682953, 'test/loss': 2.69852352142334, 'test/num_examples': 10000, 'score': 14347.40918970108, 'total_duration': 14949.99478673935, 'accumulated_submission_time': 14347.40918970108, 'accumulated_eval_time': 600.9589376449585, 'accumulated_logging_time': 0.9961771965026855}
I0919 02:06:27.373547 140078403806976 logging_writer.py:48] [42471] accumulated_eval_time=600.958938, accumulated_logging_time=0.996177, accumulated_submission_time=14347.409190, global_step=42471, preemption_count=0, score=14347.409190, test/accuracy=0.452900, test/loss=2.698524, test/num_examples=10000, total_duration=14949.994787, train/accuracy=0.621173, train/loss=1.807771, validation/accuracy=0.577180, validation/loss=2.011234, validation/num_examples=50000
I0919 02:06:37.475383 140078412199680 logging_writer.py:48] [42500] global_step=42500, grad_norm=0.2742195427417755, loss=3.474376916885376
I0919 02:09:25.695245 140078403806976 logging_writer.py:48] [43000] global_step=43000, grad_norm=0.258420467376709, loss=3.416146755218506
I0919 02:12:13.869888 140078412199680 logging_writer.py:48] [43500] global_step=43500, grad_norm=0.27440404891967773, loss=3.422668218612671
I0919 02:14:57.495119 140245097760576 spec.py:320] Evaluating on the training split.
I0919 02:15:05.206231 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 02:15:15.806499 140245097760576 spec.py:348] Evaluating on the test split.
I0919 02:15:18.219890 140245097760576 submission_runner.py:376] Time since start: 15480.86s, 	Step: 43988, 	{'train/accuracy': 0.6793287396430969, 'train/loss': 1.5328608751296997, 'validation/accuracy': 0.6055799722671509, 'validation/loss': 1.8692936897277832, 'validation/num_examples': 50000, 'test/accuracy': 0.4812000095844269, 'test/loss': 2.5292365550994873, 'test/num_examples': 10000, 'score': 14857.495784044266, 'total_duration': 15480.864092350006, 'accumulated_submission_time': 14857.495784044266, 'accumulated_eval_time': 621.6836967468262, 'accumulated_logging_time': 1.0306508541107178}
I0919 02:15:18.243514 140078403806976 logging_writer.py:48] [43988] accumulated_eval_time=621.683697, accumulated_logging_time=1.030651, accumulated_submission_time=14857.495784, global_step=43988, preemption_count=0, score=14857.495784, test/accuracy=0.481200, test/loss=2.529237, test/num_examples=10000, total_duration=15480.864092, train/accuracy=0.679329, train/loss=1.532861, validation/accuracy=0.605580, validation/loss=1.869294, validation/num_examples=50000
I0919 02:15:22.620114 140078412199680 logging_writer.py:48] [44000] global_step=44000, grad_norm=0.27338722348213196, loss=3.420553207397461
I0919 02:18:10.722158 140078403806976 logging_writer.py:48] [44500] global_step=44500, grad_norm=0.27146583795547485, loss=3.421884775161743
I0919 02:20:58.854993 140078412199680 logging_writer.py:48] [45000] global_step=45000, grad_norm=0.2655535936355591, loss=3.3648462295532227
I0919 02:23:47.058707 140078403806976 logging_writer.py:48] [45500] global_step=45500, grad_norm=0.28879016637802124, loss=3.4864039421081543
I0919 02:23:48.499288 140245097760576 spec.py:320] Evaluating on the training split.
I0919 02:23:56.196837 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 02:24:07.003927 140245097760576 spec.py:348] Evaluating on the test split.
I0919 02:24:09.366958 140245097760576 submission_runner.py:376] Time since start: 16012.01s, 	Step: 45506, 	{'train/accuracy': 0.6739675998687744, 'train/loss': 1.5494647026062012, 'validation/accuracy': 0.6106399893760681, 'validation/loss': 1.8453357219696045, 'validation/num_examples': 50000, 'test/accuracy': 0.48440003395080566, 'test/loss': 2.502803087234497, 'test/num_examples': 10000, 'score': 15367.717188358307, 'total_duration': 16012.011163949966, 'accumulated_submission_time': 15367.717188358307, 'accumulated_eval_time': 642.5513274669647, 'accumulated_logging_time': 1.0658679008483887}
I0919 02:24:09.390982 140078403806976 logging_writer.py:48] [45506] accumulated_eval_time=642.551327, accumulated_logging_time=1.065868, accumulated_submission_time=15367.717188, global_step=45506, preemption_count=0, score=15367.717188, test/accuracy=0.484400, test/loss=2.502803, test/num_examples=10000, total_duration=16012.011164, train/accuracy=0.673968, train/loss=1.549465, validation/accuracy=0.610640, validation/loss=1.845336, validation/num_examples=50000
I0919 02:26:55.914976 140080442218240 logging_writer.py:48] [46000] global_step=46000, grad_norm=0.27523478865623474, loss=3.5031065940856934
I0919 02:29:44.108945 140078403806976 logging_writer.py:48] [46500] global_step=46500, grad_norm=0.27307969331741333, loss=3.403456449508667
I0919 02:32:32.275971 140080442218240 logging_writer.py:48] [47000] global_step=47000, grad_norm=0.2762252986431122, loss=3.443758726119995
I0919 02:32:39.429405 140245097760576 spec.py:320] Evaluating on the training split.
I0919 02:32:47.151809 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 02:32:57.897860 140245097760576 spec.py:348] Evaluating on the test split.
I0919 02:33:00.240210 140245097760576 submission_runner.py:376] Time since start: 16542.88s, 	Step: 47023, 	{'train/accuracy': 0.6523237824440002, 'train/loss': 1.6569514274597168, 'validation/accuracy': 0.5984199643135071, 'validation/loss': 1.9110010862350464, 'validation/num_examples': 50000, 'test/accuracy': 0.47030001878738403, 'test/loss': 2.6157262325286865, 'test/num_examples': 10000, 'score': 15877.718472957611, 'total_duration': 16542.884393692017, 'accumulated_submission_time': 15877.718472957611, 'accumulated_eval_time': 663.3620738983154, 'accumulated_logging_time': 1.104386568069458}
I0919 02:33:00.263499 140079158773504 logging_writer.py:48] [47023] accumulated_eval_time=663.362074, accumulated_logging_time=1.104387, accumulated_submission_time=15877.718473, global_step=47023, preemption_count=0, score=15877.718473, test/accuracy=0.470300, test/loss=2.615726, test/num_examples=10000, total_duration=16542.884394, train/accuracy=0.652324, train/loss=1.656951, validation/accuracy=0.598420, validation/loss=1.911001, validation/num_examples=50000
I0919 02:35:41.106436 140079888594688 logging_writer.py:48] [47500] global_step=47500, grad_norm=0.270921528339386, loss=3.430516004562378
I0919 02:38:29.303096 140079158773504 logging_writer.py:48] [48000] global_step=48000, grad_norm=0.2856791615486145, loss=3.4030325412750244
I0919 02:41:17.565587 140079888594688 logging_writer.py:48] [48500] global_step=48500, grad_norm=0.2744177579879761, loss=3.3916943073272705
I0919 02:41:30.428321 140245097760576 spec.py:320] Evaluating on the training split.
I0919 02:41:38.108242 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 02:41:48.873071 140245097760576 spec.py:348] Evaluating on the test split.
I0919 02:41:51.223248 140245097760576 submission_runner.py:376] Time since start: 17073.87s, 	Step: 48540, 	{'train/accuracy': 0.6041135191917419, 'train/loss': 1.9337728023529053, 'validation/accuracy': 0.5577999949455261, 'validation/loss': 2.163736581802368, 'validation/num_examples': 50000, 'test/accuracy': 0.4301000237464905, 'test/loss': 2.88299822807312, 'test/num_examples': 10000, 'score': 16387.850256681442, 'total_duration': 17073.867317438126, 'accumulated_submission_time': 16387.850256681442, 'accumulated_eval_time': 684.156824350357, 'accumulated_logging_time': 1.1386842727661133}
I0919 02:41:51.247037 140078412199680 logging_writer.py:48] [48540] accumulated_eval_time=684.156824, accumulated_logging_time=1.138684, accumulated_submission_time=16387.850257, global_step=48540, preemption_count=0, score=16387.850257, test/accuracy=0.430100, test/loss=2.882998, test/num_examples=10000, total_duration=17073.867317, train/accuracy=0.604114, train/loss=1.933773, validation/accuracy=0.557800, validation/loss=2.163737, validation/num_examples=50000
I0919 02:44:26.298894 140079100045056 logging_writer.py:48] [49000] global_step=49000, grad_norm=0.28691548109054565, loss=3.3726325035095215
I0919 02:47:14.518999 140078412199680 logging_writer.py:48] [49500] global_step=49500, grad_norm=0.2780207097530365, loss=3.457357406616211
I0919 02:50:02.714312 140079100045056 logging_writer.py:48] [50000] global_step=50000, grad_norm=0.28048941493034363, loss=3.3622827529907227
I0919 02:50:21.304111 140245097760576 spec.py:320] Evaluating on the training split.
I0919 02:50:28.967437 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 02:50:39.770963 140245097760576 spec.py:348] Evaluating on the test split.
I0919 02:50:42.129171 140245097760576 submission_runner.py:376] Time since start: 17604.77s, 	Step: 50057, 	{'train/accuracy': 0.6246213316917419, 'train/loss': 1.7456004619598389, 'validation/accuracy': 0.5808199644088745, 'validation/loss': 1.96638822555542, 'validation/num_examples': 50000, 'test/accuracy': 0.45000001788139343, 'test/loss': 2.6594595909118652, 'test/num_examples': 10000, 'score': 16897.873760938644, 'total_duration': 17604.773377895355, 'accumulated_submission_time': 16897.873760938644, 'accumulated_eval_time': 704.9818737506866, 'accumulated_logging_time': 1.1735165119171143}
I0919 02:50:42.153624 140078412199680 logging_writer.py:48] [50057] accumulated_eval_time=704.981874, accumulated_logging_time=1.173517, accumulated_submission_time=16897.873761, global_step=50057, preemption_count=0, score=16897.873761, test/accuracy=0.450000, test/loss=2.659460, test/num_examples=10000, total_duration=17604.773378, train/accuracy=0.624621, train/loss=1.745600, validation/accuracy=0.580820, validation/loss=1.966388, validation/num_examples=50000
I0919 02:53:11.448817 140080442218240 logging_writer.py:48] [50500] global_step=50500, grad_norm=0.29007428884506226, loss=3.361707925796509
I0919 02:55:59.606678 140078412199680 logging_writer.py:48] [51000] global_step=51000, grad_norm=0.276695191860199, loss=3.4094655513763428
I0919 02:58:47.815948 140080442218240 logging_writer.py:48] [51500] global_step=51500, grad_norm=0.2912391126155853, loss=3.4738893508911133
I0919 02:59:12.138263 140245097760576 spec.py:320] Evaluating on the training split.
I0919 02:59:19.925649 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 02:59:30.691636 140245097760576 spec.py:348] Evaluating on the test split.
I0919 02:59:33.052640 140245097760576 submission_runner.py:376] Time since start: 18135.70s, 	Step: 51574, 	{'train/accuracy': 0.6569076776504517, 'train/loss': 1.6841869354248047, 'validation/accuracy': 0.6110599637031555, 'validation/loss': 1.8849471807479858, 'validation/num_examples': 50000, 'test/accuracy': 0.48250001668930054, 'test/loss': 2.5378668308258057, 'test/num_examples': 10000, 'score': 17407.82470226288, 'total_duration': 18135.69685125351, 'accumulated_submission_time': 17407.82470226288, 'accumulated_eval_time': 725.8962314128876, 'accumulated_logging_time': 1.2089519500732422}
I0919 02:59:33.076222 140078412199680 logging_writer.py:48] [51574] accumulated_eval_time=725.896231, accumulated_logging_time=1.208952, accumulated_submission_time=17407.824702, global_step=51574, preemption_count=0, score=17407.824702, test/accuracy=0.482500, test/loss=2.537867, test/num_examples=10000, total_duration=18135.696851, train/accuracy=0.656908, train/loss=1.684187, validation/accuracy=0.611060, validation/loss=1.884947, validation/num_examples=50000
I0919 03:01:56.648570 140079100045056 logging_writer.py:48] [52000] global_step=52000, grad_norm=0.2763637900352478, loss=3.314798355102539
I0919 03:04:44.852896 140078412199680 logging_writer.py:48] [52500] global_step=52500, grad_norm=0.2754884362220764, loss=3.3432528972625732
I0919 03:07:33.065816 140079100045056 logging_writer.py:48] [53000] global_step=53000, grad_norm=0.290548712015152, loss=3.4163732528686523
I0919 03:08:03.091312 140245097760576 spec.py:320] Evaluating on the training split.
I0919 03:08:10.699656 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 03:08:21.582921 140245097760576 spec.py:348] Evaluating on the test split.
I0919 03:08:23.881121 140245097760576 submission_runner.py:376] Time since start: 18666.53s, 	Step: 53091, 	{'train/accuracy': 0.7050581574440002, 'train/loss': 1.4129359722137451, 'validation/accuracy': 0.6082199811935425, 'validation/loss': 1.8329261541366577, 'validation/num_examples': 50000, 'test/accuracy': 0.4846000373363495, 'test/loss': 2.500943183898926, 'test/num_examples': 10000, 'score': 17917.80679678917, 'total_duration': 18666.525322437286, 'accumulated_submission_time': 17917.80679678917, 'accumulated_eval_time': 746.6859955787659, 'accumulated_logging_time': 1.2432892322540283}
I0919 03:08:23.903912 140079888594688 logging_writer.py:48] [53091] accumulated_eval_time=746.685996, accumulated_logging_time=1.243289, accumulated_submission_time=17917.806797, global_step=53091, preemption_count=0, score=17917.806797, test/accuracy=0.484600, test/loss=2.500943, test/num_examples=10000, total_duration=18666.525322, train/accuracy=0.705058, train/loss=1.412936, validation/accuracy=0.608220, validation/loss=1.832926, validation/num_examples=50000
I0919 03:10:41.884762 140080442218240 logging_writer.py:48] [53500] global_step=53500, grad_norm=0.29042109847068787, loss=3.4484214782714844
I0919 03:13:30.005072 140079888594688 logging_writer.py:48] [54000] global_step=54000, grad_norm=0.2752688229084015, loss=3.268234968185425
I0919 03:16:18.221915 140080442218240 logging_writer.py:48] [54500] global_step=54500, grad_norm=0.28977665305137634, loss=3.3364076614379883
I0919 03:16:53.955362 140245097760576 spec.py:320] Evaluating on the training split.
I0919 03:17:01.514046 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 03:17:12.669418 140245097760576 spec.py:348] Evaluating on the test split.
I0919 03:17:15.006650 140245097760576 submission_runner.py:376] Time since start: 19197.65s, 	Step: 54608, 	{'train/accuracy': 0.6829958558082581, 'train/loss': 1.494336485862732, 'validation/accuracy': 0.6208400130271912, 'validation/loss': 1.7739062309265137, 'validation/num_examples': 50000, 'test/accuracy': 0.49880000948905945, 'test/loss': 2.444182872772217, 'test/num_examples': 10000, 'score': 18427.823033094406, 'total_duration': 19197.650846481323, 'accumulated_submission_time': 18427.823033094406, 'accumulated_eval_time': 767.737245798111, 'accumulated_logging_time': 1.278395652770996}
I0919 03:17:15.029503 140079100045056 logging_writer.py:48] [54608] accumulated_eval_time=767.737246, accumulated_logging_time=1.278396, accumulated_submission_time=18427.823033, global_step=54608, preemption_count=0, score=18427.823033, test/accuracy=0.498800, test/loss=2.444183, test/num_examples=10000, total_duration=19197.650846, train/accuracy=0.682996, train/loss=1.494336, validation/accuracy=0.620840, validation/loss=1.773906, validation/num_examples=50000
I0919 03:19:27.210109 140079158773504 logging_writer.py:48] [55000] global_step=55000, grad_norm=0.28867292404174805, loss=3.364170551300049
I0919 03:22:15.373827 140079100045056 logging_writer.py:48] [55500] global_step=55500, grad_norm=0.2838882505893707, loss=3.2919809818267822
I0919 03:25:03.557980 140079158773504 logging_writer.py:48] [56000] global_step=56000, grad_norm=0.2779209613800049, loss=3.272233247756958
I0919 03:25:45.010070 140245097760576 spec.py:320] Evaluating on the training split.
I0919 03:25:52.617746 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 03:26:03.519029 140245097760576 spec.py:348] Evaluating on the test split.
I0919 03:26:05.898907 140245097760576 submission_runner.py:376] Time since start: 19728.54s, 	Step: 56125, 	{'train/accuracy': 0.6871013641357422, 'train/loss': 1.526764988899231, 'validation/accuracy': 0.6281999945640564, 'validation/loss': 1.7881439924240112, 'validation/num_examples': 50000, 'test/accuracy': 0.5010000467300415, 'test/loss': 2.445608139038086, 'test/num_examples': 10000, 'score': 18937.767692565918, 'total_duration': 19728.54311323166, 'accumulated_submission_time': 18937.767692565918, 'accumulated_eval_time': 788.6260476112366, 'accumulated_logging_time': 1.3143045902252197}
I0919 03:26:05.920969 140078395414272 logging_writer.py:48] [56125] accumulated_eval_time=788.626048, accumulated_logging_time=1.314305, accumulated_submission_time=18937.767693, global_step=56125, preemption_count=0, score=18937.767693, test/accuracy=0.501000, test/loss=2.445608, test/num_examples=10000, total_duration=19728.543113, train/accuracy=0.687101, train/loss=1.526765, validation/accuracy=0.628200, validation/loss=1.788144, validation/num_examples=50000
I0919 03:28:12.389365 140078403806976 logging_writer.py:48] [56500] global_step=56500, grad_norm=0.2919093668460846, loss=3.3638410568237305
I0919 03:31:00.582358 140078395414272 logging_writer.py:48] [57000] global_step=57000, grad_norm=0.2835463583469391, loss=3.316007375717163
I0919 03:33:48.811594 140078403806976 logging_writer.py:48] [57500] global_step=57500, grad_norm=0.29607269167900085, loss=3.4419093132019043
I0919 03:34:35.969910 140245097760576 spec.py:320] Evaluating on the training split.
I0919 03:34:43.510289 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 03:34:54.609693 140245097760576 spec.py:348] Evaluating on the test split.
I0919 03:34:56.917479 140245097760576 submission_runner.py:376] Time since start: 20259.56s, 	Step: 57642, 	{'train/accuracy': 0.6488759517669678, 'train/loss': 1.726908802986145, 'validation/accuracy': 0.5937399864196777, 'validation/loss': 1.9639030694961548, 'validation/num_examples': 50000, 'test/accuracy': 0.4668000340461731, 'test/loss': 2.6268622875213623, 'test/num_examples': 10000, 'score': 19447.78379178047, 'total_duration': 20259.561609745026, 'accumulated_submission_time': 19447.78379178047, 'accumulated_eval_time': 809.5735065937042, 'accumulated_logging_time': 1.3472275733947754}
I0919 03:34:56.941955 140078403806976 logging_writer.py:48] [57642] accumulated_eval_time=809.573507, accumulated_logging_time=1.347228, accumulated_submission_time=19447.783792, global_step=57642, preemption_count=0, score=19447.783792, test/accuracy=0.466800, test/loss=2.626862, test/num_examples=10000, total_duration=20259.561610, train/accuracy=0.648876, train/loss=1.726909, validation/accuracy=0.593740, validation/loss=1.963903, validation/num_examples=50000
I0919 03:36:57.606276 140080442218240 logging_writer.py:48] [58000] global_step=58000, grad_norm=0.28991296887397766, loss=3.316622734069824
I0919 03:39:45.862941 140078403806976 logging_writer.py:48] [58500] global_step=58500, grad_norm=0.2960127294063568, loss=3.326244831085205
I0919 03:42:34.013651 140080442218240 logging_writer.py:48] [59000] global_step=59000, grad_norm=0.28588613867759705, loss=3.3430798053741455
I0919 03:43:26.947555 140245097760576 spec.py:320] Evaluating on the training split.
I0919 03:43:34.559498 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 03:43:45.455550 140245097760576 spec.py:348] Evaluating on the test split.
I0919 03:43:47.854564 140245097760576 submission_runner.py:376] Time since start: 20790.50s, 	Step: 59159, 	{'train/accuracy': 0.6782127022743225, 'train/loss': 1.5793383121490479, 'validation/accuracy': 0.6237599849700928, 'validation/loss': 1.8233593702316284, 'validation/num_examples': 50000, 'test/accuracy': 0.49650001525878906, 'test/loss': 2.490795850753784, 'test/num_examples': 10000, 'score': 19957.75455212593, 'total_duration': 20790.498770713806, 'accumulated_submission_time': 19957.75455212593, 'accumulated_eval_time': 830.4804813861847, 'accumulated_logging_time': 1.3838343620300293}
I0919 03:43:47.883125 140078412199680 logging_writer.py:48] [59159] accumulated_eval_time=830.480481, accumulated_logging_time=1.383834, accumulated_submission_time=19957.754552, global_step=59159, preemption_count=0, score=19957.754552, test/accuracy=0.496500, test/loss=2.490796, test/num_examples=10000, total_duration=20790.498771, train/accuracy=0.678213, train/loss=1.579338, validation/accuracy=0.623760, validation/loss=1.823359, validation/num_examples=50000
I0919 03:45:42.836050 140079100045056 logging_writer.py:48] [59500] global_step=59500, grad_norm=0.29008400440216064, loss=3.2789034843444824
I0919 03:48:31.040623 140078412199680 logging_writer.py:48] [60000] global_step=60000, grad_norm=0.30321329832077026, loss=3.3364408016204834
I0919 03:51:19.290080 140079100045056 logging_writer.py:48] [60500] global_step=60500, grad_norm=0.29558265209198, loss=3.361752510070801
I0919 03:52:18.032758 140245097760576 spec.py:320] Evaluating on the training split.
I0919 03:52:25.637530 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 03:52:36.612699 140245097760576 spec.py:348] Evaluating on the test split.
I0919 03:52:38.858925 140245097760576 submission_runner.py:376] Time since start: 21321.50s, 	Step: 60676, 	{'train/accuracy': 0.641043484210968, 'train/loss': 1.7735086679458618, 'validation/accuracy': 0.5956999659538269, 'validation/loss': 1.9781285524368286, 'validation/num_examples': 50000, 'test/accuracy': 0.4766000211238861, 'test/loss': 2.61031436920166, 'test/num_examples': 10000, 'score': 20467.869895219803, 'total_duration': 21321.503106832504, 'accumulated_submission_time': 20467.869895219803, 'accumulated_eval_time': 851.3065967559814, 'accumulated_logging_time': 1.4244861602783203}
I0919 03:52:38.888999 140078412199680 logging_writer.py:48] [60676] accumulated_eval_time=851.306597, accumulated_logging_time=1.424486, accumulated_submission_time=20467.869895, global_step=60676, preemption_count=0, score=20467.869895, test/accuracy=0.476600, test/loss=2.610314, test/num_examples=10000, total_duration=21321.503107, train/accuracy=0.641043, train/loss=1.773509, validation/accuracy=0.595700, validation/loss=1.978129, validation/num_examples=50000
I0919 03:54:28.289192 140079100045056 logging_writer.py:48] [61000] global_step=61000, grad_norm=0.28613463044166565, loss=3.2924861907958984
I0919 03:57:16.468994 140078412199680 logging_writer.py:48] [61500] global_step=61500, grad_norm=0.28749880194664, loss=3.362100839614868
I0919 04:00:04.725343 140079100045056 logging_writer.py:48] [62000] global_step=62000, grad_norm=0.2850571572780609, loss=3.2332053184509277
I0919 04:01:09.050646 140245097760576 spec.py:320] Evaluating on the training split.
I0919 04:01:16.569733 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 04:01:27.375006 140245097760576 spec.py:348] Evaluating on the test split.
I0919 04:01:29.634520 140245097760576 submission_runner.py:376] Time since start: 21852.28s, 	Step: 62193, 	{'train/accuracy': 0.7098811864852905, 'train/loss': 1.430907130241394, 'validation/accuracy': 0.625499963760376, 'validation/loss': 1.817330241203308, 'validation/num_examples': 50000, 'test/accuracy': 0.5009000301361084, 'test/loss': 2.4610514640808105, 'test/num_examples': 10000, 'score': 20977.998966693878, 'total_duration': 21852.278718948364, 'accumulated_submission_time': 20977.998966693878, 'accumulated_eval_time': 871.8904156684875, 'accumulated_logging_time': 1.4668834209442139}
I0919 04:01:29.660893 140079158773504 logging_writer.py:48] [62193] accumulated_eval_time=871.890416, accumulated_logging_time=1.466883, accumulated_submission_time=20977.998967, global_step=62193, preemption_count=0, score=20977.998967, test/accuracy=0.500900, test/loss=2.461051, test/num_examples=10000, total_duration=21852.278719, train/accuracy=0.709881, train/loss=1.430907, validation/accuracy=0.625500, validation/loss=1.817330, validation/num_examples=50000
I0919 04:03:13.118016 140079888594688 logging_writer.py:48] [62500] global_step=62500, grad_norm=0.2977161705493927, loss=3.3929505348205566
I0919 04:06:01.285994 140079158773504 logging_writer.py:48] [63000] global_step=63000, grad_norm=0.29356566071510315, loss=3.299520492553711
I0919 04:08:49.522775 140079888594688 logging_writer.py:48] [63500] global_step=63500, grad_norm=0.28115639090538025, loss=3.2318122386932373
I0919 04:09:59.913049 140245097760576 spec.py:320] Evaluating on the training split.
I0919 04:10:07.429676 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 04:10:18.231789 140245097760576 spec.py:348] Evaluating on the test split.
I0919 04:10:20.497666 140245097760576 submission_runner.py:376] Time since start: 22383.14s, 	Step: 63711, 	{'train/accuracy': 0.6798469424247742, 'train/loss': 1.5500541925430298, 'validation/accuracy': 0.6165199875831604, 'validation/loss': 1.8367286920547485, 'validation/num_examples': 50000, 'test/accuracy': 0.48440003395080566, 'test/loss': 2.513198137283325, 'test/num_examples': 10000, 'score': 21488.22046637535, 'total_duration': 22383.141842603683, 'accumulated_submission_time': 21488.22046637535, 'accumulated_eval_time': 892.4749524593353, 'accumulated_logging_time': 1.5038414001464844}
I0919 04:10:20.525734 140078412199680 logging_writer.py:48] [63711] accumulated_eval_time=892.474952, accumulated_logging_time=1.503841, accumulated_submission_time=21488.220466, global_step=63711, preemption_count=0, score=21488.220466, test/accuracy=0.484400, test/loss=2.513198, test/num_examples=10000, total_duration=22383.141843, train/accuracy=0.679847, train/loss=1.550054, validation/accuracy=0.616520, validation/loss=1.836729, validation/num_examples=50000
I0919 04:11:57.951853 140079100045056 logging_writer.py:48] [64000] global_step=64000, grad_norm=0.2924432158470154, loss=3.3263840675354004
I0919 04:14:46.148444 140078412199680 logging_writer.py:48] [64500] global_step=64500, grad_norm=0.2985348105430603, loss=3.292052984237671
I0919 04:17:34.352467 140079100045056 logging_writer.py:48] [65000] global_step=65000, grad_norm=0.29269859194755554, loss=3.300006628036499
I0919 04:18:50.767417 140245097760576 spec.py:320] Evaluating on the training split.
I0919 04:18:58.250252 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 04:19:09.220335 140245097760576 spec.py:348] Evaluating on the test split.
I0919 04:19:11.486510 140245097760576 submission_runner.py:376] Time since start: 22914.13s, 	Step: 65229, 	{'train/accuracy': 0.6919044852256775, 'train/loss': 1.528098225593567, 'validation/accuracy': 0.628879964351654, 'validation/loss': 1.8035516738891602, 'validation/num_examples': 50000, 'test/accuracy': 0.49560001492500305, 'test/loss': 2.483914613723755, 'test/num_examples': 10000, 'score': 21998.431813955307, 'total_duration': 22914.130730628967, 'accumulated_submission_time': 21998.431813955307, 'accumulated_eval_time': 913.1940140724182, 'accumulated_logging_time': 1.542017936706543}
I0919 04:19:11.511344 140079888594688 logging_writer.py:48] [65229] accumulated_eval_time=913.194014, accumulated_logging_time=1.542018, accumulated_submission_time=21998.431814, global_step=65229, preemption_count=0, score=21998.431814, test/accuracy=0.495600, test/loss=2.483915, test/num_examples=10000, total_duration=22914.130731, train/accuracy=0.691904, train/loss=1.528098, validation/accuracy=0.628880, validation/loss=1.803552, validation/num_examples=50000
I0919 04:20:42.949020 140080450610944 logging_writer.py:48] [65500] global_step=65500, grad_norm=0.2978602945804596, loss=3.302245855331421
I0919 04:23:31.153798 140079888594688 logging_writer.py:48] [66000] global_step=66000, grad_norm=0.29379919171333313, loss=3.2793402671813965
I0919 04:26:19.352610 140080450610944 logging_writer.py:48] [66500] global_step=66500, grad_norm=0.3028877079486847, loss=3.330249547958374
I0919 04:27:41.539578 140245097760576 spec.py:320] Evaluating on the training split.
I0919 04:27:49.018934 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 04:27:59.926656 140245097760576 spec.py:348] Evaluating on the test split.
I0919 04:28:02.448655 140245097760576 submission_runner.py:376] Time since start: 23445.09s, 	Step: 66746, 	{'train/accuracy': 0.6633250713348389, 'train/loss': 1.610998272895813, 'validation/accuracy': 0.6083999872207642, 'validation/loss': 1.8528920412063599, 'validation/num_examples': 50000, 'test/accuracy': 0.48100003600120544, 'test/loss': 2.542644739151001, 'test/num_examples': 10000, 'score': 22508.42777967453, 'total_duration': 23445.09285068512, 'accumulated_submission_time': 22508.42777967453, 'accumulated_eval_time': 934.1030423641205, 'accumulated_logging_time': 1.5790565013885498}
I0919 04:28:02.475804 140078395414272 logging_writer.py:48] [66746] accumulated_eval_time=934.103042, accumulated_logging_time=1.579057, accumulated_submission_time=22508.427780, global_step=66746, preemption_count=0, score=22508.427780, test/accuracy=0.481000, test/loss=2.542645, test/num_examples=10000, total_duration=23445.092851, train/accuracy=0.663325, train/loss=1.610998, validation/accuracy=0.608400, validation/loss=1.852892, validation/num_examples=50000
I0919 04:29:28.181871 140078403806976 logging_writer.py:48] [67000] global_step=67000, grad_norm=0.29818961024284363, loss=3.2259371280670166
I0919 04:32:16.395975 140078395414272 logging_writer.py:48] [67500] global_step=67500, grad_norm=0.2997060716152191, loss=3.2914862632751465
I0919 04:35:04.604204 140078403806976 logging_writer.py:48] [68000] global_step=68000, grad_norm=0.3018976151943207, loss=3.242271900177002
I0919 04:36:32.499454 140245097760576 spec.py:320] Evaluating on the training split.
I0919 04:36:40.193189 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 04:36:50.944042 140245097760576 spec.py:348] Evaluating on the test split.
I0919 04:36:53.143552 140245097760576 submission_runner.py:376] Time since start: 23975.79s, 	Step: 68263, 	{'train/accuracy': 0.6818598508834839, 'train/loss': 1.5423789024353027, 'validation/accuracy': 0.6284199953079224, 'validation/loss': 1.7802072763442993, 'validation/num_examples': 50000, 'test/accuracy': 0.5039000511169434, 'test/loss': 2.4353668689727783, 'test/num_examples': 10000, 'score': 23018.41924905777, 'total_duration': 23975.78776717186, 'accumulated_submission_time': 23018.41924905777, 'accumulated_eval_time': 954.7471029758453, 'accumulated_logging_time': 1.6181974411010742}
I0919 04:36:53.167838 140080442218240 logging_writer.py:48] [68263] accumulated_eval_time=954.747103, accumulated_logging_time=1.618197, accumulated_submission_time=23018.419249, global_step=68263, preemption_count=0, score=23018.419249, test/accuracy=0.503900, test/loss=2.435367, test/num_examples=10000, total_duration=23975.787767, train/accuracy=0.681860, train/loss=1.542379, validation/accuracy=0.628420, validation/loss=1.780207, validation/num_examples=50000
I0919 04:38:13.215267 140080450610944 logging_writer.py:48] [68500] global_step=68500, grad_norm=0.3074661195278168, loss=3.2311270236968994
I0919 04:41:01.424664 140080442218240 logging_writer.py:48] [69000] global_step=69000, grad_norm=0.3029269576072693, loss=3.2606422901153564
I0919 04:43:49.638806 140080450610944 logging_writer.py:48] [69500] global_step=69500, grad_norm=0.29794928431510925, loss=3.251821517944336
I0919 04:45:23.228345 140245097760576 spec.py:320] Evaluating on the training split.
I0919 04:45:30.679344 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 04:45:41.705958 140245097760576 spec.py:348] Evaluating on the test split.
I0919 04:45:44.020313 140245097760576 submission_runner.py:376] Time since start: 24506.66s, 	Step: 69780, 	{'train/accuracy': 0.6935786008834839, 'train/loss': 1.470489501953125, 'validation/accuracy': 0.6381199955940247, 'validation/loss': 1.7132763862609863, 'validation/num_examples': 50000, 'test/accuracy': 0.5136000514030457, 'test/loss': 2.3623480796813965, 'test/num_examples': 10000, 'score': 23528.449256658554, 'total_duration': 24506.664514780045, 'accumulated_submission_time': 23528.449256658554, 'accumulated_eval_time': 975.5390205383301, 'accumulated_logging_time': 1.6528310775756836}
I0919 04:45:44.044676 140079100045056 logging_writer.py:48] [69780] accumulated_eval_time=975.539021, accumulated_logging_time=1.652831, accumulated_submission_time=23528.449257, global_step=69780, preemption_count=0, score=23528.449257, test/accuracy=0.513600, test/loss=2.362348, test/num_examples=10000, total_duration=24506.664515, train/accuracy=0.693579, train/loss=1.470490, validation/accuracy=0.638120, validation/loss=1.713276, validation/num_examples=50000
I0919 04:46:58.281739 140080459003648 logging_writer.py:48] [70000] global_step=70000, grad_norm=0.30545973777770996, loss=3.265709400177002
I0919 04:49:46.396236 140079100045056 logging_writer.py:48] [70500] global_step=70500, grad_norm=0.29813283681869507, loss=3.2840919494628906
I0919 04:52:34.617605 140080459003648 logging_writer.py:48] [71000] global_step=71000, grad_norm=0.32116472721099854, loss=3.3129560947418213
I0919 04:54:14.256536 140245097760576 spec.py:320] Evaluating on the training split.
I0919 04:54:21.720507 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 04:54:32.771756 140245097760576 spec.py:348] Evaluating on the test split.
I0919 04:54:35.044607 140245097760576 submission_runner.py:376] Time since start: 25037.69s, 	Step: 71298, 	{'train/accuracy': 0.7183513641357422, 'train/loss': 1.3737677335739136, 'validation/accuracy': 0.6387799978256226, 'validation/loss': 1.7288742065429688, 'validation/num_examples': 50000, 'test/accuracy': 0.5098000168800354, 'test/loss': 2.374168872833252, 'test/num_examples': 10000, 'score': 24038.630749225616, 'total_duration': 25037.68881034851, 'accumulated_submission_time': 24038.630749225616, 'accumulated_eval_time': 996.3270401954651, 'accumulated_logging_time': 1.6874737739562988}
I0919 04:54:35.067890 140079158773504 logging_writer.py:48] [71298] accumulated_eval_time=996.327040, accumulated_logging_time=1.687474, accumulated_submission_time=24038.630749, global_step=71298, preemption_count=0, score=24038.630749, test/accuracy=0.509800, test/loss=2.374169, test/num_examples=10000, total_duration=25037.688810, train/accuracy=0.718351, train/loss=1.373768, validation/accuracy=0.638780, validation/loss=1.728874, validation/num_examples=50000
I0919 04:55:43.206485 140079888594688 logging_writer.py:48] [71500] global_step=71500, grad_norm=0.32380396127700806, loss=3.3032169342041016
I0919 04:58:31.309673 140079158773504 logging_writer.py:48] [72000] global_step=72000, grad_norm=0.3216035068035126, loss=3.3109424114227295
I0919 05:01:19.551989 140079888594688 logging_writer.py:48] [72500] global_step=72500, grad_norm=0.3075772523880005, loss=3.2281553745269775
I0919 05:03:05.285288 140245097760576 spec.py:320] Evaluating on the training split.
I0919 05:03:12.738214 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 05:03:23.661736 140245097760576 spec.py:348] Evaluating on the test split.
I0919 05:03:25.901973 140245097760576 submission_runner.py:376] Time since start: 25568.55s, 	Step: 72816, 	{'train/accuracy': 0.7173150181770325, 'train/loss': 1.3715227842330933, 'validation/accuracy': 0.6507799625396729, 'validation/loss': 1.6766383647918701, 'validation/num_examples': 50000, 'test/accuracy': 0.5223000049591064, 'test/loss': 2.3065056800842285, 'test/num_examples': 10000, 'score': 24548.817907333374, 'total_duration': 25568.546179533005, 'accumulated_submission_time': 24548.817907333374, 'accumulated_eval_time': 1016.9436917304993, 'accumulated_logging_time': 1.7209486961364746}
I0919 05:03:25.925408 140079100045056 logging_writer.py:48] [72816] accumulated_eval_time=1016.943692, accumulated_logging_time=1.720949, accumulated_submission_time=24548.817907, global_step=72816, preemption_count=0, score=24548.817907, test/accuracy=0.522300, test/loss=2.306506, test/num_examples=10000, total_duration=25568.546180, train/accuracy=0.717315, train/loss=1.371523, validation/accuracy=0.650780, validation/loss=1.676638, validation/num_examples=50000
I0919 05:04:28.021762 140079158773504 logging_writer.py:48] [73000] global_step=73000, grad_norm=0.31874051690101624, loss=3.3318145275115967
I0919 05:07:16.212611 140079100045056 logging_writer.py:48] [73500] global_step=73500, grad_norm=0.3042697310447693, loss=3.1829233169555664
I0919 05:10:04.401527 140079158773504 logging_writer.py:48] [74000] global_step=74000, grad_norm=0.31128162145614624, loss=3.256455898284912
I0919 05:11:56.207030 140245097760576 spec.py:320] Evaluating on the training split.
I0919 05:12:03.685801 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 05:12:14.506953 140245097760576 spec.py:348] Evaluating on the test split.
I0919 05:12:16.742557 140245097760576 submission_runner.py:376] Time since start: 26099.39s, 	Step: 74334, 	{'train/accuracy': 0.7150231003761292, 'train/loss': 1.4037551879882812, 'validation/accuracy': 0.6541999578475952, 'validation/loss': 1.6802089214324951, 'validation/num_examples': 50000, 'test/accuracy': 0.5294000506401062, 'test/loss': 2.3218131065368652, 'test/num_examples': 10000, 'score': 25059.06854248047, 'total_duration': 26099.38676095009, 'accumulated_submission_time': 25059.06854248047, 'accumulated_eval_time': 1037.4791700839996, 'accumulated_logging_time': 1.7551240921020508}
I0919 05:12:16.771202 140080442218240 logging_writer.py:48] [74334] accumulated_eval_time=1037.479170, accumulated_logging_time=1.755124, accumulated_submission_time=25059.068542, global_step=74334, preemption_count=0, score=25059.068542, test/accuracy=0.529400, test/loss=2.321813, test/num_examples=10000, total_duration=26099.386761, train/accuracy=0.715023, train/loss=1.403755, validation/accuracy=0.654200, validation/loss=1.680209, validation/num_examples=50000
I0919 05:13:12.889433 140080450610944 logging_writer.py:48] [74500] global_step=74500, grad_norm=0.31363528966903687, loss=3.199885368347168
I0919 05:16:01.084629 140080442218240 logging_writer.py:48] [75000] global_step=75000, grad_norm=0.31721410155296326, loss=3.2898759841918945
I0919 05:18:49.268910 140080450610944 logging_writer.py:48] [75500] global_step=75500, grad_norm=0.324980229139328, loss=3.252699851989746
I0919 05:20:47.045653 140245097760576 spec.py:320] Evaluating on the training split.
I0919 05:20:54.992494 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 05:21:05.850394 140245097760576 spec.py:348] Evaluating on the test split.
I0919 05:21:08.145666 140245097760576 submission_runner.py:376] Time since start: 26630.79s, 	Step: 75852, 	{'train/accuracy': 0.6949537396430969, 'train/loss': 1.4483387470245361, 'validation/accuracy': 0.6391800045967102, 'validation/loss': 1.7073774337768555, 'validation/num_examples': 50000, 'test/accuracy': 0.5117000341415405, 'test/loss': 2.3859994411468506, 'test/num_examples': 10000, 'score': 25569.311100006104, 'total_duration': 26630.78979563713, 'accumulated_submission_time': 25569.311100006104, 'accumulated_eval_time': 1058.5790586471558, 'accumulated_logging_time': 1.7955327033996582}
I0919 05:21:08.174947 140078412199680 logging_writer.py:48] [75852] accumulated_eval_time=1058.579059, accumulated_logging_time=1.795533, accumulated_submission_time=25569.311100, global_step=75852, preemption_count=0, score=25569.311100, test/accuracy=0.511700, test/loss=2.385999, test/num_examples=10000, total_duration=26630.789796, train/accuracy=0.694954, train/loss=1.448339, validation/accuracy=0.639180, validation/loss=1.707377, validation/num_examples=50000
I0919 05:21:58.276620 140079100045056 logging_writer.py:48] [76000] global_step=76000, grad_norm=0.30313560366630554, loss=3.1785480976104736
I0919 05:24:46.524520 140078412199680 logging_writer.py:48] [76500] global_step=76500, grad_norm=0.32603365182876587, loss=3.3079721927642822
I0919 05:27:34.727719 140079100045056 logging_writer.py:48] [77000] global_step=77000, grad_norm=0.3166900873184204, loss=3.1431899070739746
I0919 05:29:38.248913 140245097760576 spec.py:320] Evaluating on the training split.
I0919 05:29:45.688880 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 05:29:56.633788 140245097760576 spec.py:348] Evaluating on the test split.
I0919 05:29:58.868928 140245097760576 submission_runner.py:376] Time since start: 27161.51s, 	Step: 77369, 	{'train/accuracy': 0.6845503449440002, 'train/loss': 1.5119658708572388, 'validation/accuracy': 0.6297999620437622, 'validation/loss': 1.767849326133728, 'validation/num_examples': 50000, 'test/accuracy': 0.5014000535011292, 'test/loss': 2.4139227867126465, 'test/num_examples': 10000, 'score': 26079.353837251663, 'total_duration': 27161.51313304901, 'accumulated_submission_time': 26079.353837251663, 'accumulated_eval_time': 1079.1990377902985, 'accumulated_logging_time': 1.836071252822876}
I0919 05:29:58.893751 140078395414272 logging_writer.py:48] [77369] accumulated_eval_time=1079.199038, accumulated_logging_time=1.836071, accumulated_submission_time=26079.353837, global_step=77369, preemption_count=0, score=26079.353837, test/accuracy=0.501400, test/loss=2.413923, test/num_examples=10000, total_duration=27161.513133, train/accuracy=0.684550, train/loss=1.511966, validation/accuracy=0.629800, validation/loss=1.767849, validation/num_examples=50000
I0919 05:30:43.291985 140078403806976 logging_writer.py:48] [77500] global_step=77500, grad_norm=0.3149087727069855, loss=3.2312889099121094
I0919 05:33:31.521942 140078395414272 logging_writer.py:48] [78000] global_step=78000, grad_norm=0.31635409593582153, loss=3.2744038105010986
I0919 05:36:19.696596 140078403806976 logging_writer.py:48] [78500] global_step=78500, grad_norm=0.3070444166660309, loss=3.153491973876953
I0919 05:38:28.962325 140245097760576 spec.py:320] Evaluating on the training split.
I0919 05:38:36.377429 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 05:38:47.293410 140245097760576 spec.py:348] Evaluating on the test split.
I0919 05:38:49.549872 140245097760576 submission_runner.py:376] Time since start: 27692.19s, 	Step: 78886, 	{'train/accuracy': 0.72367262840271, 'train/loss': 1.3457744121551514, 'validation/accuracy': 0.6444399952888489, 'validation/loss': 1.6890619993209839, 'validation/num_examples': 50000, 'test/accuracy': 0.5208000540733337, 'test/loss': 2.3527793884277344, 'test/num_examples': 10000, 'score': 26589.38980102539, 'total_duration': 27692.19407916069, 'accumulated_submission_time': 26589.38980102539, 'accumulated_eval_time': 1099.7865402698517, 'accumulated_logging_time': 1.873595952987671}
I0919 05:38:49.573556 140079158773504 logging_writer.py:48] [78886] accumulated_eval_time=1099.786540, accumulated_logging_time=1.873596, accumulated_submission_time=26589.389801, global_step=78886, preemption_count=0, score=26589.389801, test/accuracy=0.520800, test/loss=2.352779, test/num_examples=10000, total_duration=27692.194079, train/accuracy=0.723673, train/loss=1.345774, validation/accuracy=0.644440, validation/loss=1.689062, validation/num_examples=50000
I0919 05:39:28.206400 140079888594688 logging_writer.py:48] [79000] global_step=79000, grad_norm=0.33444517850875854, loss=3.301142692565918
I0919 05:42:16.432897 140079158773504 logging_writer.py:48] [79500] global_step=79500, grad_norm=0.30245494842529297, loss=3.131629467010498
I0919 05:45:04.627407 140079888594688 logging_writer.py:48] [80000] global_step=80000, grad_norm=0.3255270719528198, loss=3.1623032093048096
I0919 05:47:19.613981 140245097760576 spec.py:320] Evaluating on the training split.
I0919 05:47:27.054904 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 05:47:38.003624 140245097760576 spec.py:348] Evaluating on the test split.
I0919 05:47:40.257223 140245097760576 submission_runner.py:376] Time since start: 28222.90s, 	Step: 80403, 	{'train/accuracy': 0.711336076259613, 'train/loss': 1.3960850238800049, 'validation/accuracy': 0.6375600099563599, 'validation/loss': 1.7303324937820435, 'validation/num_examples': 50000, 'test/accuracy': 0.5095000267028809, 'test/loss': 2.383603811264038, 'test/num_examples': 10000, 'score': 27099.39931821823, 'total_duration': 28222.901433229446, 'accumulated_submission_time': 27099.39931821823, 'accumulated_eval_time': 1120.4297413825989, 'accumulated_logging_time': 1.9080631732940674}
I0919 05:47:40.282592 140078395414272 logging_writer.py:48] [80403] accumulated_eval_time=1120.429741, accumulated_logging_time=1.908063, accumulated_submission_time=27099.399318, global_step=80403, preemption_count=0, score=27099.399318, test/accuracy=0.509500, test/loss=2.383604, test/num_examples=10000, total_duration=28222.901433, train/accuracy=0.711336, train/loss=1.396085, validation/accuracy=0.637560, validation/loss=1.730332, validation/num_examples=50000
I0919 05:48:13.295628 140078412199680 logging_writer.py:48] [80500] global_step=80500, grad_norm=0.3138290047645569, loss=3.1838746070861816
I0919 05:51:01.467280 140078395414272 logging_writer.py:48] [81000] global_step=81000, grad_norm=0.32370588183403015, loss=3.249258041381836
I0919 05:53:49.642802 140078412199680 logging_writer.py:48] [81500] global_step=81500, grad_norm=0.3264378309249878, loss=3.212123394012451
I0919 05:56:10.345951 140245097760576 spec.py:320] Evaluating on the training split.
I0919 05:56:17.762012 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 05:56:28.633865 140245097760576 spec.py:348] Evaluating on the test split.
I0919 05:56:30.884969 140245097760576 submission_runner.py:376] Time since start: 28753.53s, 	Step: 81920, 	{'train/accuracy': 0.7154815196990967, 'train/loss': 1.3452292680740356, 'validation/accuracy': 0.6497200131416321, 'validation/loss': 1.648118495941162, 'validation/num_examples': 50000, 'test/accuracy': 0.5223000049591064, 'test/loss': 2.3020050525665283, 'test/num_examples': 10000, 'score': 27609.43206501007, 'total_duration': 28753.52916288376, 'accumulated_submission_time': 27609.43206501007, 'accumulated_eval_time': 1140.9687027931213, 'accumulated_logging_time': 1.9445154666900635}
I0919 05:56:30.909071 140080442218240 logging_writer.py:48] [81920] accumulated_eval_time=1140.968703, accumulated_logging_time=1.944515, accumulated_submission_time=27609.432065, global_step=81920, preemption_count=0, score=27609.432065, test/accuracy=0.522300, test/loss=2.302005, test/num_examples=10000, total_duration=28753.529163, train/accuracy=0.715482, train/loss=1.345229, validation/accuracy=0.649720, validation/loss=1.648118, validation/num_examples=50000
I0919 05:56:58.159038 140080450610944 logging_writer.py:48] [82000] global_step=82000, grad_norm=0.31746718287467957, loss=3.119654893875122
I0919 05:59:46.349227 140080442218240 logging_writer.py:48] [82500] global_step=82500, grad_norm=0.3305433690547943, loss=3.1782777309417725
I0919 06:02:34.494610 140080450610944 logging_writer.py:48] [83000] global_step=83000, grad_norm=0.3297470808029175, loss=3.114367961883545
I0919 06:05:00.927028 140245097760576 spec.py:320] Evaluating on the training split.
I0919 06:05:08.348919 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 06:05:19.285320 140245097760576 spec.py:348] Evaluating on the test split.
I0919 06:05:21.528307 140245097760576 submission_runner.py:376] Time since start: 29284.17s, 	Step: 83437, 	{'train/accuracy': 0.7182317972183228, 'train/loss': 1.3525248765945435, 'validation/accuracy': 0.6508600115776062, 'validation/loss': 1.6412359476089478, 'validation/num_examples': 50000, 'test/accuracy': 0.5220000147819519, 'test/loss': 2.308457612991333, 'test/num_examples': 10000, 'score': 28119.417169332504, 'total_duration': 29284.172510147095, 'accumulated_submission_time': 28119.417169332504, 'accumulated_eval_time': 1161.5699355602264, 'accumulated_logging_time': 1.9811246395111084}
I0919 06:05:21.552331 140079100045056 logging_writer.py:48] [83437] accumulated_eval_time=1161.569936, accumulated_logging_time=1.981125, accumulated_submission_time=28119.417169, global_step=83437, preemption_count=0, score=28119.417169, test/accuracy=0.522000, test/loss=2.308458, test/num_examples=10000, total_duration=29284.172510, train/accuracy=0.718232, train/loss=1.352525, validation/accuracy=0.650860, validation/loss=1.641236, validation/num_examples=50000
I0919 06:05:43.047730 140079158773504 logging_writer.py:48] [83500] global_step=83500, grad_norm=0.3317944407463074, loss=3.1755521297454834
I0919 06:08:31.054594 140079100045056 logging_writer.py:48] [84000] global_step=84000, grad_norm=0.34170547127723694, loss=3.25327205657959
I0919 06:11:19.227443 140079158773504 logging_writer.py:48] [84500] global_step=84500, grad_norm=0.33977967500686646, loss=3.140864849090576
I0919 06:13:51.647522 140245097760576 spec.py:320] Evaluating on the training split.
I0919 06:13:59.121662 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 06:14:10.065755 140245097760576 spec.py:348] Evaluating on the test split.
I0919 06:14:12.352700 140245097760576 submission_runner.py:376] Time since start: 29815.00s, 	Step: 84955, 	{'train/accuracy': 0.7302694320678711, 'train/loss': 1.3102004528045654, 'validation/accuracy': 0.6685999631881714, 'validation/loss': 1.5819252729415894, 'validation/num_examples': 50000, 'test/accuracy': 0.5442000031471252, 'test/loss': 2.22513484954834, 'test/num_examples': 10000, 'score': 28629.48138308525, 'total_duration': 29814.99689412117, 'accumulated_submission_time': 28629.48138308525, 'accumulated_eval_time': 1182.275056362152, 'accumulated_logging_time': 2.0158612728118896}
I0919 06:14:12.383230 140078412199680 logging_writer.py:48] [84955] accumulated_eval_time=1182.275056, accumulated_logging_time=2.015861, accumulated_submission_time=28629.481383, global_step=84955, preemption_count=0, score=28629.481383, test/accuracy=0.544200, test/loss=2.225135, test/num_examples=10000, total_duration=29814.996894, train/accuracy=0.730269, train/loss=1.310200, validation/accuracy=0.668600, validation/loss=1.581925, validation/num_examples=50000
I0919 06:14:27.840508 140079100045056 logging_writer.py:48] [85000] global_step=85000, grad_norm=0.3367685377597809, loss=3.209855318069458
I0919 06:17:15.956812 140078412199680 logging_writer.py:48] [85500] global_step=85500, grad_norm=0.3388993442058563, loss=3.215332269668579
I0919 06:20:04.120948 140079100045056 logging_writer.py:48] [86000] global_step=86000, grad_norm=0.339474618434906, loss=3.1496548652648926
I0919 06:22:42.639466 140245097760576 spec.py:320] Evaluating on the training split.
I0919 06:22:50.074254 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 06:23:01.163043 140245097760576 spec.py:348] Evaluating on the test split.
I0919 06:23:03.426009 140245097760576 submission_runner.py:376] Time since start: 30346.07s, 	Step: 86473, 	{'train/accuracy': 0.7212013602256775, 'train/loss': 1.3514279127120972, 'validation/accuracy': 0.6615999937057495, 'validation/loss': 1.627492904663086, 'validation/num_examples': 50000, 'test/accuracy': 0.534500002861023, 'test/loss': 2.2647857666015625, 'test/num_examples': 10000, 'score': 29139.703558683395, 'total_duration': 30346.07021546364, 'accumulated_submission_time': 29139.703558683395, 'accumulated_eval_time': 1203.0615570545197, 'accumulated_logging_time': 2.0603201389312744}
I0919 06:23:03.454735 140079888594688 logging_writer.py:48] [86473] accumulated_eval_time=1203.061557, accumulated_logging_time=2.060320, accumulated_submission_time=29139.703559, global_step=86473, preemption_count=0, score=29139.703559, test/accuracy=0.534500, test/loss=2.264786, test/num_examples=10000, total_duration=30346.070215, train/accuracy=0.721201, train/loss=1.351428, validation/accuracy=0.661600, validation/loss=1.627493, validation/num_examples=50000
I0919 06:23:12.858231 140080442218240 logging_writer.py:48] [86500] global_step=86500, grad_norm=0.3423999845981598, loss=3.124429702758789
I0919 06:26:00.947623 140079888594688 logging_writer.py:48] [87000] global_step=87000, grad_norm=0.3284043073654175, loss=3.073603630065918
I0919 06:28:49.141866 140080442218240 logging_writer.py:48] [87500] global_step=87500, grad_norm=0.3288237154483795, loss=3.143315076828003
I0919 06:31:33.682851 140245097760576 spec.py:320] Evaluating on the training split.
I0919 06:31:41.145383 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 06:31:52.064068 140245097760576 spec.py:348] Evaluating on the test split.
I0919 06:31:54.425559 140245097760576 submission_runner.py:376] Time since start: 30877.07s, 	Step: 87991, 	{'train/accuracy': 0.7641900181770325, 'train/loss': 1.1873400211334229, 'validation/accuracy': 0.6584999561309814, 'validation/loss': 1.6387598514556885, 'validation/num_examples': 50000, 'test/accuracy': 0.5294000506401062, 'test/loss': 2.2972586154937744, 'test/num_examples': 10000, 'score': 29649.899120807648, 'total_duration': 30877.069764614105, 'accumulated_submission_time': 29649.899120807648, 'accumulated_eval_time': 1223.8042414188385, 'accumulated_logging_time': 2.101274013519287}
I0919 06:31:54.450026 140078412199680 logging_writer.py:48] [87991] accumulated_eval_time=1223.804241, accumulated_logging_time=2.101274, accumulated_submission_time=29649.899121, global_step=87991, preemption_count=0, score=29649.899121, test/accuracy=0.529400, test/loss=2.297259, test/num_examples=10000, total_duration=30877.069765, train/accuracy=0.764190, train/loss=1.187340, validation/accuracy=0.658500, validation/loss=1.638760, validation/num_examples=50000
I0919 06:31:57.808296 140079100045056 logging_writer.py:48] [88000] global_step=88000, grad_norm=0.336436927318573, loss=3.1938252449035645
I0919 06:34:45.859681 140078412199680 logging_writer.py:48] [88500] global_step=88500, grad_norm=0.3606773316860199, loss=3.234370231628418
I0919 06:37:34.084030 140079100045056 logging_writer.py:48] [89000] global_step=89000, grad_norm=0.34196051955223083, loss=3.0613229274749756
I0919 06:40:22.257596 140078412199680 logging_writer.py:48] [89500] global_step=89500, grad_norm=0.3364834189414978, loss=3.051884651184082
I0919 06:40:24.712312 140245097760576 spec.py:320] Evaluating on the training split.
I0919 06:40:32.150619 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 06:40:43.011998 140245097760576 spec.py:348] Evaluating on the test split.
I0919 06:40:45.222562 140245097760576 submission_runner.py:376] Time since start: 31407.87s, 	Step: 89509, 	{'train/accuracy': 0.7386599183082581, 'train/loss': 1.3126999139785767, 'validation/accuracy': 0.6611999869346619, 'validation/loss': 1.6471408605575562, 'validation/num_examples': 50000, 'test/accuracy': 0.5315000414848328, 'test/loss': 2.3068275451660156, 'test/num_examples': 10000, 'score': 30160.129207372665, 'total_duration': 31407.866783618927, 'accumulated_submission_time': 30160.129207372665, 'accumulated_eval_time': 1244.3144550323486, 'accumulated_logging_time': 2.137824773788452}
I0919 06:40:45.246889 140080442218240 logging_writer.py:48] [89509] accumulated_eval_time=1244.314455, accumulated_logging_time=2.137825, accumulated_submission_time=30160.129207, global_step=89509, preemption_count=0, score=30160.129207, test/accuracy=0.531500, test/loss=2.306828, test/num_examples=10000, total_duration=31407.866784, train/accuracy=0.738660, train/loss=1.312700, validation/accuracy=0.661200, validation/loss=1.647141, validation/num_examples=50000
I0919 06:43:30.740758 140080450610944 logging_writer.py:48] [90000] global_step=90000, grad_norm=0.3453971743583679, loss=3.1085431575775146
I0919 06:46:18.884464 140080442218240 logging_writer.py:48] [90500] global_step=90500, grad_norm=0.33864524960517883, loss=3.0801618099212646
I0919 06:49:07.100745 140080450610944 logging_writer.py:48] [91000] global_step=91000, grad_norm=0.34189173579216003, loss=3.150252342224121
I0919 06:49:15.268249 140245097760576 spec.py:320] Evaluating on the training split.
I0919 06:49:22.761520 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 06:49:33.564484 140245097760576 spec.py:348] Evaluating on the test split.
I0919 06:49:35.844212 140245097760576 submission_runner.py:376] Time since start: 31938.49s, 	Step: 91026, 	{'train/accuracy': 0.7432238459587097, 'train/loss': 1.2964186668395996, 'validation/accuracy': 0.6706799864768982, 'validation/loss': 1.6102522611618042, 'validation/num_examples': 50000, 'test/accuracy': 0.5410000085830688, 'test/loss': 2.256373405456543, 'test/num_examples': 10000, 'score': 30670.118807554245, 'total_duration': 31938.488426685333, 'accumulated_submission_time': 30670.118807554245, 'accumulated_eval_time': 1264.890377521515, 'accumulated_logging_time': 2.173720598220825}
I0919 06:49:35.869945 140078395414272 logging_writer.py:48] [91026] accumulated_eval_time=1264.890378, accumulated_logging_time=2.173721, accumulated_submission_time=30670.118808, global_step=91026, preemption_count=0, score=30670.118808, test/accuracy=0.541000, test/loss=2.256373, test/num_examples=10000, total_duration=31938.488427, train/accuracy=0.743224, train/loss=1.296419, validation/accuracy=0.670680, validation/loss=1.610252, validation/num_examples=50000
I0919 06:52:15.684660 140078412199680 logging_writer.py:48] [91500] global_step=91500, grad_norm=0.3471275568008423, loss=3.0709121227264404
I0919 06:55:03.830003 140078395414272 logging_writer.py:48] [92000] global_step=92000, grad_norm=0.33899986743927, loss=3.0569872856140137
I0919 06:57:52.029653 140078412199680 logging_writer.py:48] [92500] global_step=92500, grad_norm=0.34539660811424255, loss=3.066709518432617
I0919 06:58:05.918608 140245097760576 spec.py:320] Evaluating on the training split.
I0919 06:58:13.347946 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 06:58:24.232588 140245097760576 spec.py:348] Evaluating on the test split.
I0919 06:58:26.498570 140245097760576 submission_runner.py:376] Time since start: 32469.14s, 	Step: 92543, 	{'train/accuracy': 0.7345144748687744, 'train/loss': 1.2694228887557983, 'validation/accuracy': 0.668720006942749, 'validation/loss': 1.5643812417984009, 'validation/num_examples': 50000, 'test/accuracy': 0.5458000302314758, 'test/loss': 2.223123073577881, 'test/num_examples': 10000, 'score': 31180.136553525925, 'total_duration': 32469.14278435707, 'accumulated_submission_time': 31180.136553525925, 'accumulated_eval_time': 1285.4702961444855, 'accumulated_logging_time': 2.210169792175293}
I0919 06:58:26.523775 140080442218240 logging_writer.py:48] [92543] accumulated_eval_time=1285.470296, accumulated_logging_time=2.210170, accumulated_submission_time=31180.136554, global_step=92543, preemption_count=0, score=31180.136554, test/accuracy=0.545800, test/loss=2.223123, test/num_examples=10000, total_duration=32469.142784, train/accuracy=0.734514, train/loss=1.269423, validation/accuracy=0.668720, validation/loss=1.564381, validation/num_examples=50000
I0919 07:01:00.482305 140080450610944 logging_writer.py:48] [93000] global_step=93000, grad_norm=0.35270652174949646, loss=3.0857133865356445
I0919 07:03:48.625421 140080442218240 logging_writer.py:48] [93500] global_step=93500, grad_norm=0.35802701115608215, loss=3.087796449661255
I0919 07:06:36.827295 140080450610944 logging_writer.py:48] [94000] global_step=94000, grad_norm=0.36267513036727905, loss=3.11515474319458
I0919 07:06:56.764477 140245097760576 spec.py:320] Evaluating on the training split.
I0919 07:07:04.155195 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 07:07:15.133206 140245097760576 spec.py:348] Evaluating on the test split.
I0919 07:07:17.417707 140245097760576 submission_runner.py:376] Time since start: 33000.06s, 	Step: 94061, 	{'train/accuracy': 0.7450374364852905, 'train/loss': 1.205109715461731, 'validation/accuracy': 0.6753199696540833, 'validation/loss': 1.5156527757644653, 'validation/num_examples': 50000, 'test/accuracy': 0.5515000224113464, 'test/loss': 2.1441524028778076, 'test/num_examples': 10000, 'score': 31690.346209049225, 'total_duration': 33000.06192779541, 'accumulated_submission_time': 31690.346209049225, 'accumulated_eval_time': 1306.1234905719757, 'accumulated_logging_time': 2.2462716102600098}
I0919 07:07:17.443049 140078412199680 logging_writer.py:48] [94061] accumulated_eval_time=1306.123491, accumulated_logging_time=2.246272, accumulated_submission_time=31690.346209, global_step=94061, preemption_count=0, score=31690.346209, test/accuracy=0.551500, test/loss=2.144152, test/num_examples=10000, total_duration=33000.061928, train/accuracy=0.745037, train/loss=1.205110, validation/accuracy=0.675320, validation/loss=1.515653, validation/num_examples=50000
I0919 07:09:45.367320 140079100045056 logging_writer.py:48] [94500] global_step=94500, grad_norm=0.3643988072872162, loss=3.0784764289855957
I0919 07:12:33.607080 140078412199680 logging_writer.py:48] [95000] global_step=95000, grad_norm=0.36191174387931824, loss=3.0558841228485107
I0919 07:15:21.812409 140079100045056 logging_writer.py:48] [95500] global_step=95500, grad_norm=0.3586524426937103, loss=3.117985248565674
I0919 07:15:47.470157 140245097760576 spec.py:320] Evaluating on the training split.
I0919 07:15:54.825881 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 07:16:05.782749 140245097760576 spec.py:348] Evaluating on the test split.
I0919 07:16:08.020312 140245097760576 submission_runner.py:376] Time since start: 33530.66s, 	Step: 95578, 	{'train/accuracy': 0.7210817933082581, 'train/loss': 1.3763164281845093, 'validation/accuracy': 0.6561399698257446, 'validation/loss': 1.6640539169311523, 'validation/num_examples': 50000, 'test/accuracy': 0.5299000144004822, 'test/loss': 2.322737455368042, 'test/num_examples': 10000, 'score': 32200.342797517776, 'total_duration': 33530.66452765465, 'accumulated_submission_time': 32200.342797517776, 'accumulated_eval_time': 1326.6736025810242, 'accumulated_logging_time': 2.282148599624634}
I0919 07:16:08.048011 140078403806976 logging_writer.py:48] [95578] accumulated_eval_time=1326.673603, accumulated_logging_time=2.282149, accumulated_submission_time=32200.342798, global_step=95578, preemption_count=0, score=32200.342798, test/accuracy=0.529900, test/loss=2.322737, test/num_examples=10000, total_duration=33530.664528, train/accuracy=0.721082, train/loss=1.376316, validation/accuracy=0.656140, validation/loss=1.664054, validation/num_examples=50000
I0919 07:18:30.314157 140080442218240 logging_writer.py:48] [96000] global_step=96000, grad_norm=0.3490920662879944, loss=3.130615234375
I0919 07:21:18.530360 140078403806976 logging_writer.py:48] [96500] global_step=96500, grad_norm=0.3687067925930023, loss=3.080756187438965
I0919 07:24:06.705946 140080442218240 logging_writer.py:48] [97000] global_step=97000, grad_norm=0.3769667148590088, loss=2.99326491355896
I0919 07:24:38.082527 140245097760576 spec.py:320] Evaluating on the training split.
I0919 07:24:45.458584 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 07:24:56.330027 140245097760576 spec.py:348] Evaluating on the test split.
I0919 07:24:58.900952 140245097760576 submission_runner.py:376] Time since start: 34061.55s, 	Step: 97095, 	{'train/accuracy': 0.7633131146430969, 'train/loss': 1.2339246273040771, 'validation/accuracy': 0.6608399748802185, 'validation/loss': 1.6570223569869995, 'validation/num_examples': 50000, 'test/accuracy': 0.527400016784668, 'test/loss': 2.335861921310425, 'test/num_examples': 10000, 'score': 32710.34723854065, 'total_duration': 34061.545172691345, 'accumulated_submission_time': 32710.34723854065, 'accumulated_eval_time': 1347.491994380951, 'accumulated_logging_time': 2.3200888633728027}
I0919 07:24:58.925572 140079888594688 logging_writer.py:48] [97095] accumulated_eval_time=1347.491994, accumulated_logging_time=2.320089, accumulated_submission_time=32710.347239, global_step=97095, preemption_count=0, score=32710.347239, test/accuracy=0.527400, test/loss=2.335862, test/num_examples=10000, total_duration=34061.545173, train/accuracy=0.763313, train/loss=1.233925, validation/accuracy=0.660840, validation/loss=1.657022, validation/num_examples=50000
I0919 07:27:15.432922 140080459003648 logging_writer.py:48] [97500] global_step=97500, grad_norm=0.3548910617828369, loss=3.0098400115966797
I0919 07:30:03.676880 140079888594688 logging_writer.py:48] [98000] global_step=98000, grad_norm=0.34819862246513367, loss=2.956653594970703
I0919 07:32:51.895428 140080459003648 logging_writer.py:48] [98500] global_step=98500, grad_norm=0.3620019555091858, loss=3.0228586196899414
I0919 07:33:29.011216 140245097760576 spec.py:320] Evaluating on the training split.
I0919 07:33:36.457226 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 07:33:47.394073 140245097760576 spec.py:348] Evaluating on the test split.
I0919 07:33:49.634549 140245097760576 submission_runner.py:376] Time since start: 34592.28s, 	Step: 98612, 	{'train/accuracy': 0.7786192297935486, 'train/loss': 1.0950895547866821, 'validation/accuracy': 0.6916599869728088, 'validation/loss': 1.4663927555084229, 'validation/num_examples': 50000, 'test/accuracy': 0.5592000484466553, 'test/loss': 2.105501174926758, 'test/num_examples': 10000, 'score': 33220.40139245987, 'total_duration': 34592.27876710892, 'accumulated_submission_time': 33220.40139245987, 'accumulated_eval_time': 1368.1152873039246, 'accumulated_logging_time': 2.356036424636841}
I0919 07:33:49.662584 140078412199680 logging_writer.py:48] [98612] accumulated_eval_time=1368.115287, accumulated_logging_time=2.356036, accumulated_submission_time=33220.401392, global_step=98612, preemption_count=0, score=33220.401392, test/accuracy=0.559200, test/loss=2.105501, test/num_examples=10000, total_duration=34592.278767, train/accuracy=0.778619, train/loss=1.095090, validation/accuracy=0.691660, validation/loss=1.466393, validation/num_examples=50000
I0919 07:36:00.462593 140079100045056 logging_writer.py:48] [99000] global_step=99000, grad_norm=0.3735103905200958, loss=2.988626003265381
I0919 07:38:48.520017 140078412199680 logging_writer.py:48] [99500] global_step=99500, grad_norm=0.3891255855560303, loss=3.0571606159210205
I0919 07:41:36.768259 140079100045056 logging_writer.py:48] [100000] global_step=100000, grad_norm=0.37370559573173523, loss=3.0379230976104736
I0919 07:42:19.915775 140245097760576 spec.py:320] Evaluating on the training split.
I0919 07:42:27.248592 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 07:42:38.161401 140245097760576 spec.py:348] Evaluating on the test split.
I0919 07:42:40.374175 140245097760576 submission_runner.py:376] Time since start: 35123.02s, 	Step: 100130, 	{'train/accuracy': 0.7604432106018066, 'train/loss': 1.180131196975708, 'validation/accuracy': 0.6843000054359436, 'validation/loss': 1.512358546257019, 'validation/num_examples': 50000, 'test/accuracy': 0.5595000386238098, 'test/loss': 2.161224365234375, 'test/num_examples': 10000, 'score': 33730.62457942963, 'total_duration': 35123.01833987236, 'accumulated_submission_time': 33730.62457942963, 'accumulated_eval_time': 1388.5735955238342, 'accumulated_logging_time': 2.3942630290985107}
I0919 07:42:40.399191 140079100045056 logging_writer.py:48] [100130] accumulated_eval_time=1388.573596, accumulated_logging_time=2.394263, accumulated_submission_time=33730.624579, global_step=100130, preemption_count=0, score=33730.624579, test/accuracy=0.559500, test/loss=2.161224, test/num_examples=10000, total_duration=35123.018340, train/accuracy=0.760443, train/loss=1.180131, validation/accuracy=0.684300, validation/loss=1.512359, validation/num_examples=50000
I0919 07:44:45.126036 140079888594688 logging_writer.py:48] [100500] global_step=100500, grad_norm=0.3910071551799774, loss=3.1329381465911865
I0919 07:47:33.362115 140079100045056 logging_writer.py:48] [101000] global_step=101000, grad_norm=0.38917431235313416, loss=3.0976686477661133
I0919 07:50:21.580481 140079888594688 logging_writer.py:48] [101500] global_step=101500, grad_norm=0.3915252685546875, loss=3.0465235710144043
I0919 07:51:10.421864 140245097760576 spec.py:320] Evaluating on the training split.
I0919 07:51:17.807446 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 07:51:28.668630 140245097760576 spec.py:348] Evaluating on the test split.
I0919 07:51:30.967300 140245097760576 submission_runner.py:376] Time since start: 35653.61s, 	Step: 101647, 	{'train/accuracy': 0.7696707248687744, 'train/loss': 1.1325535774230957, 'validation/accuracy': 0.6917200088500977, 'validation/loss': 1.4804883003234863, 'validation/num_examples': 50000, 'test/accuracy': 0.5688000321388245, 'test/loss': 2.1134915351867676, 'test/num_examples': 10000, 'score': 34240.61685299873, 'total_duration': 35653.61151719093, 'accumulated_submission_time': 34240.61685299873, 'accumulated_eval_time': 1409.118991613388, 'accumulated_logging_time': 2.4296483993530273}
I0919 07:51:30.994465 140079100045056 logging_writer.py:48] [101647] accumulated_eval_time=1409.118992, accumulated_logging_time=2.429648, accumulated_submission_time=34240.616853, global_step=101647, preemption_count=0, score=34240.616853, test/accuracy=0.568800, test/loss=2.113492, test/num_examples=10000, total_duration=35653.611517, train/accuracy=0.769671, train/loss=1.132554, validation/accuracy=0.691720, validation/loss=1.480488, validation/num_examples=50000
I0919 07:53:30.081502 140079158773504 logging_writer.py:48] [102000] global_step=102000, grad_norm=0.38966527581214905, loss=3.0185139179229736
I0919 07:56:18.325864 140079100045056 logging_writer.py:48] [102500] global_step=102500, grad_norm=0.3698348104953766, loss=2.961604595184326
I0919 07:59:06.496934 140079158773504 logging_writer.py:48] [103000] global_step=103000, grad_norm=0.36744147539138794, loss=2.9216108322143555
I0919 08:00:01.079446 140245097760576 spec.py:320] Evaluating on the training split.
I0919 08:00:08.469152 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 08:00:19.251975 140245097760576 spec.py:348] Evaluating on the test split.
I0919 08:00:21.587354 140245097760576 submission_runner.py:376] Time since start: 36184.23s, 	Step: 103164, 	{'train/accuracy': 0.7825454473495483, 'train/loss': 1.070412278175354, 'validation/accuracy': 0.705839991569519, 'validation/loss': 1.4002232551574707, 'validation/num_examples': 50000, 'test/accuracy': 0.5758000016212463, 'test/loss': 2.0226001739501953, 'test/num_examples': 10000, 'score': 34750.670857191086, 'total_duration': 36184.23157286644, 'accumulated_submission_time': 34750.670857191086, 'accumulated_eval_time': 1429.626859664917, 'accumulated_logging_time': 2.467414379119873}
I0919 08:00:21.612832 140079100045056 logging_writer.py:48] [103164] accumulated_eval_time=1429.626860, accumulated_logging_time=2.467414, accumulated_submission_time=34750.670857, global_step=103164, preemption_count=0, score=34750.670857, test/accuracy=0.575800, test/loss=2.022600, test/num_examples=10000, total_duration=36184.231573, train/accuracy=0.782545, train/loss=1.070412, validation/accuracy=0.705840, validation/loss=1.400223, validation/num_examples=50000
I0919 08:02:14.972257 140079888594688 logging_writer.py:48] [103500] global_step=103500, grad_norm=0.38564643263816833, loss=2.980762243270874
I0919 08:05:03.241925 140079100045056 logging_writer.py:48] [104000] global_step=104000, grad_norm=0.38065385818481445, loss=2.9998154640197754
I0919 08:07:51.436123 140079888594688 logging_writer.py:48] [104500] global_step=104500, grad_norm=0.3812731206417084, loss=2.978750705718994
I0919 08:08:51.748443 140245097760576 spec.py:320] Evaluating on the training split.
I0919 08:08:59.057969 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 08:09:09.932891 140245097760576 spec.py:348] Evaluating on the test split.
I0919 08:09:12.292981 140245097760576 submission_runner.py:376] Time since start: 36714.94s, 	Step: 104681, 	{'train/accuracy': 0.7799545526504517, 'train/loss': 1.0913686752319336, 'validation/accuracy': 0.7016800045967102, 'validation/loss': 1.423983097076416, 'validation/num_examples': 50000, 'test/accuracy': 0.5788000226020813, 'test/loss': 2.0614922046661377, 'test/num_examples': 10000, 'score': 35260.77351951599, 'total_duration': 36714.93715381622, 'accumulated_submission_time': 35260.77351951599, 'accumulated_eval_time': 1450.1713275909424, 'accumulated_logging_time': 2.5057055950164795}
I0919 08:09:12.319376 140078865176320 logging_writer.py:48] [104681] accumulated_eval_time=1450.171328, accumulated_logging_time=2.505706, accumulated_submission_time=35260.773520, global_step=104681, preemption_count=0, score=35260.773520, test/accuracy=0.578800, test/loss=2.061492, test/num_examples=10000, total_duration=36714.937154, train/accuracy=0.779955, train/loss=1.091369, validation/accuracy=0.701680, validation/loss=1.423983, validation/num_examples=50000
I0919 08:10:59.956456 140078873569024 logging_writer.py:48] [105000] global_step=105000, grad_norm=0.3875903785228729, loss=2.9775400161743164
I0919 08:13:48.220936 140078865176320 logging_writer.py:48] [105500] global_step=105500, grad_norm=0.4056262969970703, loss=3.052610158920288
I0919 08:16:36.405145 140078873569024 logging_writer.py:48] [106000] global_step=106000, grad_norm=0.4099402129650116, loss=2.9389846324920654
I0919 08:17:42.428535 140245097760576 spec.py:320] Evaluating on the training split.
I0919 08:17:49.771584 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 08:18:00.847202 140245097760576 spec.py:348] Evaluating on the test split.
I0919 08:18:03.397636 140245097760576 submission_runner.py:376] Time since start: 37246.04s, 	Step: 106198, 	{'train/accuracy': 0.8139548897743225, 'train/loss': 0.962578296661377, 'validation/accuracy': 0.7041999697685242, 'validation/loss': 1.4052836894989014, 'validation/num_examples': 50000, 'test/accuracy': 0.581000030040741, 'test/loss': 2.0259625911712646, 'test/num_examples': 10000, 'score': 35770.8518717289, 'total_duration': 37246.04178881645, 'accumulated_submission_time': 35770.8518717289, 'accumulated_eval_time': 1471.1403260231018, 'accumulated_logging_time': 2.54270339012146}
I0919 08:18:03.420149 140078873569024 logging_writer.py:48] [106198] accumulated_eval_time=1471.140326, accumulated_logging_time=2.542703, accumulated_submission_time=35770.851872, global_step=106198, preemption_count=0, score=35770.851872, test/accuracy=0.581000, test/loss=2.025963, test/num_examples=10000, total_duration=37246.041789, train/accuracy=0.813955, train/loss=0.962578, validation/accuracy=0.704200, validation/loss=1.405284, validation/num_examples=50000
I0919 08:19:45.137052 140078881961728 logging_writer.py:48] [106500] global_step=106500, grad_norm=0.41330522298812866, loss=3.006260395050049
I0919 08:22:33.258236 140078873569024 logging_writer.py:48] [107000] global_step=107000, grad_norm=0.40747687220573425, loss=2.9434444904327393
I0919 08:25:21.502635 140078881961728 logging_writer.py:48] [107500] global_step=107500, grad_norm=0.39789989590644836, loss=2.936612129211426
I0919 08:26:33.595874 140245097760576 spec.py:320] Evaluating on the training split.
I0919 08:26:40.900118 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 08:26:51.886014 140245097760576 spec.py:348] Evaluating on the test split.
I0919 08:26:54.108408 140245097760576 submission_runner.py:376] Time since start: 37776.75s, 	Step: 107716, 	{'train/accuracy': 0.8071388602256775, 'train/loss': 1.004296064376831, 'validation/accuracy': 0.7107200026512146, 'validation/loss': 1.4042963981628418, 'validation/num_examples': 50000, 'test/accuracy': 0.5868000388145447, 'test/loss': 2.0278871059417725, 'test/num_examples': 10000, 'score': 36280.99781918526, 'total_duration': 37776.7526242733, 'accumulated_submission_time': 36280.99781918526, 'accumulated_eval_time': 1491.6528244018555, 'accumulated_logging_time': 2.574843645095825}
I0919 08:26:54.134482 140079158773504 logging_writer.py:48] [107716] accumulated_eval_time=1491.652824, accumulated_logging_time=2.574844, accumulated_submission_time=36280.997819, global_step=107716, preemption_count=0, score=36280.997819, test/accuracy=0.586800, test/loss=2.027887, test/num_examples=10000, total_duration=37776.752624, train/accuracy=0.807139, train/loss=1.004296, validation/accuracy=0.710720, validation/loss=1.404296, validation/num_examples=50000
I0919 08:28:29.994723 140080442218240 logging_writer.py:48] [108000] global_step=108000, grad_norm=0.4119834303855896, loss=2.9625728130340576
I0919 08:31:18.183651 140079158773504 logging_writer.py:48] [108500] global_step=108500, grad_norm=0.40666213631629944, loss=2.9119715690612793
I0919 08:34:06.433385 140080442218240 logging_writer.py:48] [109000] global_step=109000, grad_norm=0.41754382848739624, loss=2.957141637802124
I0919 08:35:24.223444 140245097760576 spec.py:320] Evaluating on the training split.
I0919 08:35:31.541632 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 08:35:42.507573 140245097760576 spec.py:348] Evaluating on the test split.
I0919 08:35:44.735165 140245097760576 submission_runner.py:376] Time since start: 38307.38s, 	Step: 109233, 	{'train/accuracy': 0.8026546239852905, 'train/loss': 0.9770081639289856, 'validation/accuracy': 0.7093999981880188, 'validation/loss': 1.359559178352356, 'validation/num_examples': 50000, 'test/accuracy': 0.5829000473022461, 'test/loss': 2.013956069946289, 'test/num_examples': 10000, 'score': 36791.056072473526, 'total_duration': 38307.37937450409, 'accumulated_submission_time': 36791.056072473526, 'accumulated_eval_time': 1512.1645052433014, 'accumulated_logging_time': 2.6113500595092773}
I0919 08:35:44.760811 140078865176320 logging_writer.py:48] [109233] accumulated_eval_time=1512.164505, accumulated_logging_time=2.611350, accumulated_submission_time=36791.056072, global_step=109233, preemption_count=0, score=36791.056072, test/accuracy=0.582900, test/loss=2.013956, test/num_examples=10000, total_duration=38307.379375, train/accuracy=0.802655, train/loss=0.977008, validation/accuracy=0.709400, validation/loss=1.359559, validation/num_examples=50000
I0919 08:37:14.893096 140078873569024 logging_writer.py:48] [109500] global_step=109500, grad_norm=0.4251593053340912, loss=2.9589221477508545
I0919 08:40:03.089041 140078865176320 logging_writer.py:48] [110000] global_step=110000, grad_norm=0.4336017370223999, loss=2.9645745754241943
I0919 08:42:51.300926 140078873569024 logging_writer.py:48] [110500] global_step=110500, grad_norm=0.42862531542778015, loss=2.9695510864257812
I0919 08:44:14.849557 140245097760576 spec.py:320] Evaluating on the training split.
I0919 08:44:22.158512 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 08:44:33.182854 140245097760576 spec.py:348] Evaluating on the test split.
I0919 08:44:35.449756 140245097760576 submission_runner.py:376] Time since start: 38838.09s, 	Step: 110750, 	{'train/accuracy': 0.8110650181770325, 'train/loss': 0.9361371994018555, 'validation/accuracy': 0.7163400053977966, 'validation/loss': 1.322260856628418, 'validation/num_examples': 50000, 'test/accuracy': 0.5926000475883484, 'test/loss': 1.94412100315094, 'test/num_examples': 10000, 'score': 37301.11421895027, 'total_duration': 38838.09396600723, 'accumulated_submission_time': 37301.11421895027, 'accumulated_eval_time': 1532.7646689414978, 'accumulated_logging_time': 2.6472840309143066}
I0919 08:44:35.475533 140078865176320 logging_writer.py:48] [110750] accumulated_eval_time=1532.764669, accumulated_logging_time=2.647284, accumulated_submission_time=37301.114219, global_step=110750, preemption_count=0, score=37301.114219, test/accuracy=0.592600, test/loss=1.944121, test/num_examples=10000, total_duration=38838.093966, train/accuracy=0.811065, train/loss=0.936137, validation/accuracy=0.716340, validation/loss=1.322261, validation/num_examples=50000
I0919 08:45:59.851922 140078873569024 logging_writer.py:48] [111000] global_step=111000, grad_norm=0.4147934913635254, loss=2.8634040355682373
I0919 08:48:48.043024 140078865176320 logging_writer.py:48] [111500] global_step=111500, grad_norm=0.4424534738063812, loss=2.9503564834594727
I0919 08:51:36.260915 140078873569024 logging_writer.py:48] [112000] global_step=112000, grad_norm=0.4478333592414856, loss=2.9270670413970947
I0919 08:53:05.523314 140245097760576 spec.py:320] Evaluating on the training split.
I0919 08:53:12.858443 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 08:53:23.824949 140245097760576 spec.py:348] Evaluating on the test split.
I0919 08:53:26.111583 140245097760576 submission_runner.py:376] Time since start: 39368.76s, 	Step: 112267, 	{'train/accuracy': 0.8099489808082581, 'train/loss': 0.955118715763092, 'validation/accuracy': 0.7160800099372864, 'validation/loss': 1.3434462547302246, 'validation/num_examples': 50000, 'test/accuracy': 0.5981000065803528, 'test/loss': 1.9447907209396362, 'test/num_examples': 10000, 'score': 37811.13156104088, 'total_duration': 39368.75576210022, 'accumulated_submission_time': 37811.13156104088, 'accumulated_eval_time': 1553.3528666496277, 'accumulated_logging_time': 2.6835885047912598}
I0919 08:53:26.138383 140079888594688 logging_writer.py:48] [112267] accumulated_eval_time=1553.352867, accumulated_logging_time=2.683589, accumulated_submission_time=37811.131561, global_step=112267, preemption_count=0, score=37811.131561, test/accuracy=0.598100, test/loss=1.944791, test/num_examples=10000, total_duration=39368.755762, train/accuracy=0.809949, train/loss=0.955119, validation/accuracy=0.716080, validation/loss=1.343446, validation/num_examples=50000
I0919 08:54:44.787382 140080442218240 logging_writer.py:48] [112500] global_step=112500, grad_norm=0.424406498670578, loss=2.879335641860962
I0919 08:57:33.035656 140079888594688 logging_writer.py:48] [113000] global_step=113000, grad_norm=0.4449378252029419, loss=2.962327480316162
I0919 09:00:21.226446 140080442218240 logging_writer.py:48] [113500] global_step=113500, grad_norm=0.4459124207496643, loss=2.8955111503601074
I0919 09:01:56.156189 140245097760576 spec.py:320] Evaluating on the training split.
I0919 09:02:03.468713 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 09:02:14.406655 140245097760576 spec.py:348] Evaluating on the test split.
I0919 09:02:16.654085 140245097760576 submission_runner.py:376] Time since start: 39899.30s, 	Step: 113784, 	{'train/accuracy': 0.8325294852256775, 'train/loss': 0.8838786482810974, 'validation/accuracy': 0.7283599972724915, 'validation/loss': 1.313471794128418, 'validation/num_examples': 50000, 'test/accuracy': 0.6026000380516052, 'test/loss': 1.9423364400863647, 'test/num_examples': 10000, 'score': 38321.11910676956, 'total_duration': 39899.29828763008, 'accumulated_submission_time': 38321.11910676956, 'accumulated_eval_time': 1573.850713968277, 'accumulated_logging_time': 2.720670700073242}
I0919 09:02:16.681285 140078873569024 logging_writer.py:48] [113784] accumulated_eval_time=1573.850714, accumulated_logging_time=2.720671, accumulated_submission_time=38321.119107, global_step=113784, preemption_count=0, score=38321.119107, test/accuracy=0.602600, test/loss=1.942336, test/num_examples=10000, total_duration=39899.298288, train/accuracy=0.832529, train/loss=0.883879, validation/accuracy=0.728360, validation/loss=1.313472, validation/num_examples=50000
I0919 09:03:29.661480 140078881961728 logging_writer.py:48] [114000] global_step=114000, grad_norm=0.45026227831840515, loss=2.859248161315918
I0919 09:06:17.878052 140078873569024 logging_writer.py:48] [114500] global_step=114500, grad_norm=0.45417141914367676, loss=2.8983542919158936
I0919 09:09:06.123348 140078881961728 logging_writer.py:48] [115000] global_step=115000, grad_norm=0.45796114206314087, loss=2.8021912574768066
I0919 09:10:46.685149 140245097760576 spec.py:320] Evaluating on the training split.
I0919 09:10:54.029927 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 09:11:04.903682 140245097760576 spec.py:348] Evaluating on the test split.
I0919 09:11:07.188544 140245097760576 submission_runner.py:376] Time since start: 40429.83s, 	Step: 115301, 	{'train/accuracy': 0.8475167155265808, 'train/loss': 0.8132196664810181, 'validation/accuracy': 0.730239987373352, 'validation/loss': 1.288041353225708, 'validation/num_examples': 50000, 'test/accuracy': 0.6048000454902649, 'test/loss': 1.9094524383544922, 'test/num_examples': 10000, 'score': 38831.091960668564, 'total_duration': 40429.83276319504, 'accumulated_submission_time': 38831.091960668564, 'accumulated_eval_time': 1594.3540887832642, 'accumulated_logging_time': 2.7583861351013184}
I0919 09:11:07.216759 140079888594688 logging_writer.py:48] [115301] accumulated_eval_time=1594.354089, accumulated_logging_time=2.758386, accumulated_submission_time=38831.091961, global_step=115301, preemption_count=0, score=38831.091961, test/accuracy=0.604800, test/loss=1.909452, test/num_examples=10000, total_duration=40429.832763, train/accuracy=0.847517, train/loss=0.813220, validation/accuracy=0.730240, validation/loss=1.288041, validation/num_examples=50000
I0919 09:12:14.399069 140080442218240 logging_writer.py:48] [115500] global_step=115500, grad_norm=0.48620057106018066, loss=2.9378011226654053
I0919 09:15:02.535618 140079888594688 logging_writer.py:48] [116000] global_step=116000, grad_norm=0.44541388750076294, loss=2.7921957969665527
I0919 09:17:50.801692 140080442218240 logging_writer.py:48] [116500] global_step=116500, grad_norm=0.463121622800827, loss=2.836358070373535
I0919 09:19:37.203599 140245097760576 spec.py:320] Evaluating on the training split.
I0919 09:19:44.558416 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 09:19:55.613279 140245097760576 spec.py:348] Evaluating on the test split.
I0919 09:19:57.888348 140245097760576 submission_runner.py:376] Time since start: 40960.53s, 	Step: 116818, 	{'train/accuracy': 0.83793044090271, 'train/loss': 0.867727518081665, 'validation/accuracy': 0.7301599979400635, 'validation/loss': 1.3111166954040527, 'validation/num_examples': 50000, 'test/accuracy': 0.6048000454902649, 'test/loss': 1.946718692779541, 'test/num_examples': 10000, 'score': 39341.047543525696, 'total_duration': 40960.53256702423, 'accumulated_submission_time': 39341.047543525696, 'accumulated_eval_time': 1615.0388205051422, 'accumulated_logging_time': 2.7972633838653564}
I0919 09:19:57.916423 140078865176320 logging_writer.py:48] [116818] accumulated_eval_time=1615.038821, accumulated_logging_time=2.797263, accumulated_submission_time=39341.047544, global_step=116818, preemption_count=0, score=39341.047544, test/accuracy=0.604800, test/loss=1.946719, test/num_examples=10000, total_duration=40960.532567, train/accuracy=0.837930, train/loss=0.867728, validation/accuracy=0.730160, validation/loss=1.311117, validation/num_examples=50000
I0919 09:20:59.470844 140078873569024 logging_writer.py:48] [117000] global_step=117000, grad_norm=0.46919023990631104, loss=2.841418743133545
I0919 09:23:47.686267 140078865176320 logging_writer.py:48] [117500] global_step=117500, grad_norm=0.46206098794937134, loss=2.8365283012390137
I0919 09:26:35.876238 140078873569024 logging_writer.py:48] [118000] global_step=118000, grad_norm=0.4746492803096771, loss=2.885223388671875
I0919 09:28:27.958577 140245097760576 spec.py:320] Evaluating on the training split.
I0919 09:28:35.281818 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 09:28:46.175500 140245097760576 spec.py:348] Evaluating on the test split.
I0919 09:28:48.416571 140245097760576 submission_runner.py:376] Time since start: 41491.06s, 	Step: 118335, 	{'train/accuracy': 0.8512834906578064, 'train/loss': 0.8133650422096252, 'validation/accuracy': 0.7404599785804749, 'validation/loss': 1.2683063745498657, 'validation/num_examples': 50000, 'test/accuracy': 0.6169000267982483, 'test/loss': 1.8760502338409424, 'test/num_examples': 10000, 'score': 39851.058109760284, 'total_duration': 41491.060791015625, 'accumulated_submission_time': 39851.058109760284, 'accumulated_eval_time': 1635.4967844486237, 'accumulated_logging_time': 2.836625337600708}
I0919 09:28:48.443885 140079158773504 logging_writer.py:48] [118335] accumulated_eval_time=1635.496784, accumulated_logging_time=2.836625, accumulated_submission_time=39851.058110, global_step=118335, preemption_count=0, score=39851.058110, test/accuracy=0.616900, test/loss=1.876050, test/num_examples=10000, total_duration=41491.060791, train/accuracy=0.851283, train/loss=0.813365, validation/accuracy=0.740460, validation/loss=1.268306, validation/num_examples=50000
I0919 09:29:44.188356 140079888594688 logging_writer.py:48] [118500] global_step=118500, grad_norm=0.46269771456718445, loss=2.80605149269104
I0919 09:32:32.338357 140079158773504 logging_writer.py:48] [119000] global_step=119000, grad_norm=0.47579851746559143, loss=2.7474112510681152
I0919 09:35:20.506138 140079888594688 logging_writer.py:48] [119500] global_step=119500, grad_norm=0.4859600067138672, loss=2.7802743911743164
I0919 09:37:18.576304 140245097760576 spec.py:320] Evaluating on the training split.
I0919 09:37:25.886177 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 09:37:36.746217 140245097760576 spec.py:348] Evaluating on the test split.
I0919 09:37:38.987417 140245097760576 submission_runner.py:376] Time since start: 42021.63s, 	Step: 119853, 	{'train/accuracy': 0.8532565236091614, 'train/loss': 0.7885985970497131, 'validation/accuracy': 0.7427200078964233, 'validation/loss': 1.2393643856048584, 'validation/num_examples': 50000, 'test/accuracy': 0.6176000237464905, 'test/loss': 1.8440178632736206, 'test/num_examples': 10000, 'score': 40361.158826589584, 'total_duration': 42021.631635427475, 'accumulated_submission_time': 40361.158826589584, 'accumulated_eval_time': 1655.9078681468964, 'accumulated_logging_time': 2.875187635421753}
I0919 09:37:39.017860 140078873569024 logging_writer.py:48] [119853] accumulated_eval_time=1655.907868, accumulated_logging_time=2.875188, accumulated_submission_time=40361.158827, global_step=119853, preemption_count=0, score=40361.158827, test/accuracy=0.617600, test/loss=1.844018, test/num_examples=10000, total_duration=42021.631635, train/accuracy=0.853257, train/loss=0.788599, validation/accuracy=0.742720, validation/loss=1.239364, validation/num_examples=50000
I0919 09:38:28.756086 140078881961728 logging_writer.py:48] [120000] global_step=120000, grad_norm=0.4862726032733917, loss=2.759615421295166
I0919 09:41:16.931935 140078873569024 logging_writer.py:48] [120500] global_step=120500, grad_norm=0.47460824251174927, loss=2.698673725128174
I0919 09:44:05.106133 140078881961728 logging_writer.py:48] [121000] global_step=121000, grad_norm=0.4799600839614868, loss=2.6689646244049072
I0919 09:46:09.293129 140245097760576 spec.py:320] Evaluating on the training split.
I0919 09:46:16.574791 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 09:46:27.474034 140245097760576 spec.py:348] Evaluating on the test split.
I0919 09:46:29.767049 140245097760576 submission_runner.py:376] Time since start: 42552.41s, 	Step: 121371, 	{'train/accuracy': 0.8619858026504517, 'train/loss': 0.7477796077728271, 'validation/accuracy': 0.750059962272644, 'validation/loss': 1.2026126384735107, 'validation/num_examples': 50000, 'test/accuracy': 0.6231000423431396, 'test/loss': 1.8168764114379883, 'test/num_examples': 10000, 'score': 40871.40272784233, 'total_duration': 42552.41125202179, 'accumulated_submission_time': 40871.40272784233, 'accumulated_eval_time': 1676.3817439079285, 'accumulated_logging_time': 2.9170479774475098}
I0919 09:46:29.793745 140078881961728 logging_writer.py:48] [121371] accumulated_eval_time=1676.381744, accumulated_logging_time=2.917048, accumulated_submission_time=40871.402728, global_step=121371, preemption_count=0, score=40871.402728, test/accuracy=0.623100, test/loss=1.816876, test/num_examples=10000, total_duration=42552.411252, train/accuracy=0.861986, train/loss=0.747780, validation/accuracy=0.750060, validation/loss=1.202613, validation/num_examples=50000
I0919 09:47:13.542549 140080442218240 logging_writer.py:48] [121500] global_step=121500, grad_norm=0.48918429017066956, loss=2.7010202407836914
I0919 09:50:01.745130 140078881961728 logging_writer.py:48] [122000] global_step=122000, grad_norm=0.49627649784088135, loss=2.696950674057007
I0919 09:52:50.043477 140080442218240 logging_writer.py:48] [122500] global_step=122500, grad_norm=0.49152758717536926, loss=2.7072858810424805
I0919 09:54:59.999356 140245097760576 spec.py:320] Evaluating on the training split.
I0919 09:55:07.374325 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 09:55:18.236965 140245097760576 spec.py:348] Evaluating on the test split.
I0919 09:55:20.537668 140245097760576 submission_runner.py:376] Time since start: 43083.18s, 	Step: 122888, 	{'train/accuracy': 0.8946906924247742, 'train/loss': 0.6371654272079468, 'validation/accuracy': 0.7576000094413757, 'validation/loss': 1.182360291481018, 'validation/num_examples': 50000, 'test/accuracy': 0.6347000598907471, 'test/loss': 1.7741376161575317, 'test/num_examples': 10000, 'score': 41381.57604265213, 'total_duration': 43083.18188738823, 'accumulated_submission_time': 41381.57604265213, 'accumulated_eval_time': 1696.9200265407562, 'accumulated_logging_time': 2.955721616744995}
I0919 09:55:20.567170 140078873569024 logging_writer.py:48] [122888] accumulated_eval_time=1696.920027, accumulated_logging_time=2.955722, accumulated_submission_time=41381.576043, global_step=122888, preemption_count=0, score=41381.576043, test/accuracy=0.634700, test/loss=1.774138, test/num_examples=10000, total_duration=43083.181887, train/accuracy=0.894691, train/loss=0.637165, validation/accuracy=0.757600, validation/loss=1.182360, validation/num_examples=50000
I0919 09:55:58.596173 140079100045056 logging_writer.py:48] [123000] global_step=123000, grad_norm=0.5028195977210999, loss=2.699162721633911
I0919 09:58:46.808153 140078873569024 logging_writer.py:48] [123500] global_step=123500, grad_norm=0.5330160856246948, loss=2.712813138961792
I0919 10:01:34.986220 140079100045056 logging_writer.py:48] [124000] global_step=124000, grad_norm=0.5007813572883606, loss=2.6466569900512695
I0919 10:03:50.637794 140245097760576 spec.py:320] Evaluating on the training split.
I0919 10:03:58.052801 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 10:04:08.901360 140245097760576 spec.py:348] Evaluating on the test split.
I0919 10:04:11.144508 140245097760576 submission_runner.py:376] Time since start: 43613.79s, 	Step: 124405, 	{'train/accuracy': 0.8950892686843872, 'train/loss': 0.6363955140113831, 'validation/accuracy': 0.76419997215271, 'validation/loss': 1.1598738431930542, 'validation/num_examples': 50000, 'test/accuracy': 0.6403000354766846, 'test/loss': 1.7538734674453735, 'test/num_examples': 10000, 'score': 41891.6149725914, 'total_duration': 43613.78872227669, 'accumulated_submission_time': 41891.6149725914, 'accumulated_eval_time': 1717.4267044067383, 'accumulated_logging_time': 2.996537923812866}
I0919 10:04:11.176646 140078881961728 logging_writer.py:48] [124405] accumulated_eval_time=1717.426704, accumulated_logging_time=2.996538, accumulated_submission_time=41891.614973, global_step=124405, preemption_count=0, score=41891.614973, test/accuracy=0.640300, test/loss=1.753873, test/num_examples=10000, total_duration=43613.788722, train/accuracy=0.895089, train/loss=0.636396, validation/accuracy=0.764200, validation/loss=1.159874, validation/num_examples=50000
I0919 10:04:43.511661 140079100045056 logging_writer.py:48] [124500] global_step=124500, grad_norm=0.4933563470840454, loss=2.5984866619110107
I0919 10:07:31.728496 140078881961728 logging_writer.py:48] [125000] global_step=125000, grad_norm=0.5168254375457764, loss=2.658433437347412
I0919 10:10:19.915840 140079100045056 logging_writer.py:48] [125500] global_step=125500, grad_norm=0.5144593715667725, loss=2.6477859020233154
I0919 10:12:41.319920 140245097760576 spec.py:320] Evaluating on the training split.
I0919 10:12:48.609295 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 10:12:59.539814 140245097760576 spec.py:348] Evaluating on the test split.
I0919 10:13:01.828969 140245097760576 submission_runner.py:376] Time since start: 44144.47s, 	Step: 125922, 	{'train/accuracy': 0.9030811190605164, 'train/loss': 0.5979558229446411, 'validation/accuracy': 0.7681799530982971, 'validation/loss': 1.1289294958114624, 'validation/num_examples': 50000, 'test/accuracy': 0.6470000147819519, 'test/loss': 1.7141063213348389, 'test/num_examples': 10000, 'score': 42401.72726345062, 'total_duration': 44144.47311043739, 'accumulated_submission_time': 42401.72726345062, 'accumulated_eval_time': 1737.9356472492218, 'accumulated_logging_time': 3.039466142654419}
I0919 10:13:01.867678 140078865176320 logging_writer.py:48] [125922] accumulated_eval_time=1737.935647, accumulated_logging_time=3.039466, accumulated_submission_time=42401.727263, global_step=125922, preemption_count=0, score=42401.727263, test/accuracy=0.647000, test/loss=1.714106, test/num_examples=10000, total_duration=44144.473110, train/accuracy=0.903081, train/loss=0.597956, validation/accuracy=0.768180, validation/loss=1.128929, validation/num_examples=50000
I0919 10:13:28.437189 140079158773504 logging_writer.py:48] [126000] global_step=126000, grad_norm=0.5206568241119385, loss=2.616478443145752
I0919 10:16:16.629409 140078865176320 logging_writer.py:48] [126500] global_step=126500, grad_norm=0.5163595080375671, loss=2.659550189971924
I0919 10:19:04.762227 140079158773504 logging_writer.py:48] [127000] global_step=127000, grad_norm=0.5095486640930176, loss=2.6149706840515137
I0919 10:21:31.849870 140245097760576 spec.py:320] Evaluating on the training split.
I0919 10:21:39.122855 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 10:21:50.078324 140245097760576 spec.py:348] Evaluating on the test split.
I0919 10:21:52.331821 140245097760576 submission_runner.py:376] Time since start: 44674.98s, 	Step: 127439, 	{'train/accuracy': 0.9046157598495483, 'train/loss': 0.598039984703064, 'validation/accuracy': 0.7721199989318848, 'validation/loss': 1.123956322669983, 'validation/num_examples': 50000, 'test/accuracy': 0.6500000357627869, 'test/loss': 1.7073290348052979, 'test/num_examples': 10000, 'score': 42911.6735765934, 'total_duration': 44674.97602677345, 'accumulated_submission_time': 42911.6735765934, 'accumulated_eval_time': 1758.4175555706024, 'accumulated_logging_time': 3.093670129776001}
I0919 10:21:52.363556 140080442218240 logging_writer.py:48] [127439] accumulated_eval_time=1758.417556, accumulated_logging_time=3.093670, accumulated_submission_time=42911.673577, global_step=127439, preemption_count=0, score=42911.673577, test/accuracy=0.650000, test/loss=1.707329, test/num_examples=10000, total_duration=44674.976027, train/accuracy=0.904616, train/loss=0.598040, validation/accuracy=0.772120, validation/loss=1.123956, validation/num_examples=50000
I0919 10:22:13.222042 140080450610944 logging_writer.py:48] [127500] global_step=127500, grad_norm=0.5031535029411316, loss=2.624870538711548
I0919 10:25:01.473402 140080442218240 logging_writer.py:48] [128000] global_step=128000, grad_norm=0.49313682317733765, loss=2.633424997329712
I0919 10:27:49.702057 140080450610944 logging_writer.py:48] [128500] global_step=128500, grad_norm=0.5127902030944824, loss=2.6163570880889893
I0919 10:30:22.536988 140245097760576 spec.py:320] Evaluating on the training split.
I0919 10:30:29.941173 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 10:30:40.777719 140245097760576 spec.py:348] Evaluating on the test split.
I0919 10:30:43.061971 140245097760576 submission_runner.py:376] Time since start: 45205.71s, 	Step: 128956, 	{'train/accuracy': 0.9033800959587097, 'train/loss': 0.6007381677627563, 'validation/accuracy': 0.7731599807739258, 'validation/loss': 1.1220510005950928, 'validation/num_examples': 50000, 'test/accuracy': 0.6511000394821167, 'test/loss': 1.70318603515625, 'test/num_examples': 10000, 'score': 43421.815564394, 'total_duration': 45205.706189870834, 'accumulated_submission_time': 43421.815564394, 'accumulated_eval_time': 1778.942519903183, 'accumulated_logging_time': 3.136686086654663}
I0919 10:30:43.089890 140079100045056 logging_writer.py:48] [128956] accumulated_eval_time=1778.942520, accumulated_logging_time=3.136686, accumulated_submission_time=43421.815564, global_step=128956, preemption_count=0, score=43421.815564, test/accuracy=0.651100, test/loss=1.703186, test/num_examples=10000, total_duration=45205.706190, train/accuracy=0.903380, train/loss=0.600738, validation/accuracy=0.773160, validation/loss=1.122051, validation/num_examples=50000
I0919 10:30:58.226591 140079158773504 logging_writer.py:48] [129000] global_step=129000, grad_norm=0.5090358853340149, loss=2.5957531929016113
I0919 10:33:46.437876 140079100045056 logging_writer.py:48] [129500] global_step=129500, grad_norm=0.502230167388916, loss=2.564284086227417
I0919 10:36:34.617391 140079158773504 logging_writer.py:48] [130000] global_step=130000, grad_norm=0.515122652053833, loss=2.609029531478882
I0919 10:39:13.147508 140245097760576 spec.py:320] Evaluating on the training split.
I0919 10:39:20.467350 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 10:39:31.311825 140245097760576 spec.py:348] Evaluating on the test split.
I0919 10:39:33.590633 140245097760576 submission_runner.py:376] Time since start: 45736.23s, 	Step: 130473, 	{'train/accuracy': 0.9044563174247742, 'train/loss': 0.5953980684280396, 'validation/accuracy': 0.7731199860572815, 'validation/loss': 1.1207743883132935, 'validation/num_examples': 50000, 'test/accuracy': 0.6499000191688538, 'test/loss': 1.7032558917999268, 'test/num_examples': 10000, 'score': 43931.84219288826, 'total_duration': 45736.23483633995, 'accumulated_submission_time': 43931.84219288826, 'accumulated_eval_time': 1799.3856046199799, 'accumulated_logging_time': 3.175229787826538}
I0919 10:39:33.627016 140078881961728 logging_writer.py:48] [130473] accumulated_eval_time=1799.385605, accumulated_logging_time=3.175230, accumulated_submission_time=43931.842193, global_step=130473, preemption_count=0, score=43931.842193, test/accuracy=0.649900, test/loss=1.703256, test/num_examples=10000, total_duration=45736.234836, train/accuracy=0.904456, train/loss=0.595398, validation/accuracy=0.773120, validation/loss=1.120774, validation/num_examples=50000
I0919 10:39:43.028318 140079100045056 logging_writer.py:48] [130500] global_step=130500, grad_norm=0.5108525156974792, loss=2.594350814819336
I0919 10:42:31.200097 140078881961728 logging_writer.py:48] [131000] global_step=131000, grad_norm=0.5288354158401489, loss=2.638361930847168
I0919 10:45:19.454167 140079100045056 logging_writer.py:48] [131500] global_step=131500, grad_norm=0.482459157705307, loss=2.563478708267212
I0919 10:48:03.693558 140245097760576 spec.py:320] Evaluating on the training split.
I0919 10:48:10.994146 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 10:48:21.833275 140245097760576 spec.py:348] Evaluating on the test split.
I0919 10:48:24.122498 140245097760576 submission_runner.py:376] Time since start: 46266.77s, 	Step: 131990, 	{'train/accuracy': 0.9046157598495483, 'train/loss': 0.5978898406028748, 'validation/accuracy': 0.7736200094223022, 'validation/loss': 1.1203153133392334, 'validation/num_examples': 50000, 'test/accuracy': 0.6521000266075134, 'test/loss': 1.7020705938339233, 'test/num_examples': 10000, 'score': 44441.87713241577, 'total_duration': 46266.766699790955, 'accumulated_submission_time': 44441.87713241577, 'accumulated_eval_time': 1819.8144969940186, 'accumulated_logging_time': 3.2233197689056396}
I0919 10:48:24.150805 140080442218240 logging_writer.py:48] [131990] accumulated_eval_time=1819.814497, accumulated_logging_time=3.223320, accumulated_submission_time=44441.877132, global_step=131990, preemption_count=0, score=44441.877132, test/accuracy=0.652100, test/loss=1.702071, test/num_examples=10000, total_duration=46266.766700, train/accuracy=0.904616, train/loss=0.597890, validation/accuracy=0.773620, validation/loss=1.120315, validation/num_examples=50000
I0919 10:48:27.854789 140080450610944 logging_writer.py:48] [132000] global_step=132000, grad_norm=0.5249527096748352, loss=2.646873712539673
I0919 10:51:15.985740 140080442218240 logging_writer.py:48] [132500] global_step=132500, grad_norm=0.5221611261367798, loss=2.664731979370117
I0919 10:54:04.152578 140080450610944 logging_writer.py:48] [133000] global_step=133000, grad_norm=0.5311770439147949, loss=2.6593658924102783
I0919 10:56:52.270627 140080442218240 logging_writer.py:48] [133500] global_step=133500, grad_norm=0.5334873795509338, loss=2.595308303833008
I0919 10:56:54.373590 140245097760576 spec.py:320] Evaluating on the training split.
I0919 10:57:01.702000 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 10:57:12.540623 140245097760576 spec.py:348] Evaluating on the test split.
I0919 10:57:14.768727 140245097760576 submission_runner.py:376] Time since start: 46797.41s, 	Step: 133508, 	{'train/accuracy': 0.9060905575752258, 'train/loss': 0.5886658430099487, 'validation/accuracy': 0.7738400101661682, 'validation/loss': 1.1211588382720947, 'validation/num_examples': 50000, 'test/accuracy': 0.6526000499725342, 'test/loss': 1.703035593032837, 'test/num_examples': 10000, 'score': 44952.06863164902, 'total_duration': 46797.41291928291, 'accumulated_submission_time': 44952.06863164902, 'accumulated_eval_time': 1840.2095685005188, 'accumulated_logging_time': 3.2629220485687256}
I0919 10:57:14.799307 140078865176320 logging_writer.py:48] [133508] accumulated_eval_time=1840.209569, accumulated_logging_time=3.262922, accumulated_submission_time=44952.068632, global_step=133508, preemption_count=0, score=44952.068632, test/accuracy=0.652600, test/loss=1.703036, test/num_examples=10000, total_duration=46797.412919, train/accuracy=0.906091, train/loss=0.588666, validation/accuracy=0.773840, validation/loss=1.121159, validation/num_examples=50000
I0919 11:00:00.572407 140078873569024 logging_writer.py:48] [134000] global_step=134000, grad_norm=0.5083151459693909, loss=2.6135311126708984
I0919 11:02:48.775043 140078865176320 logging_writer.py:48] [134500] global_step=134500, grad_norm=0.49331265687942505, loss=2.5515058040618896
I0919 11:05:36.967726 140078873569024 logging_writer.py:48] [135000] global_step=135000, grad_norm=0.5290290713310242, loss=2.6156554222106934
I0919 11:05:44.794252 140245097760576 spec.py:320] Evaluating on the training split.
I0919 11:05:52.054538 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 11:06:02.921696 140245097760576 spec.py:348] Evaluating on the test split.
I0919 11:06:05.214228 140245097760576 submission_runner.py:376] Time since start: 47327.86s, 	Step: 135025, 	{'train/accuracy': 0.9071667790412903, 'train/loss': 0.5921725034713745, 'validation/accuracy': 0.7730599641799927, 'validation/loss': 1.123219609260559, 'validation/num_examples': 50000, 'test/accuracy': 0.6525000333786011, 'test/loss': 1.7038555145263672, 'test/num_examples': 10000, 'score': 45462.0313372612, 'total_duration': 47327.85843586922, 'accumulated_submission_time': 45462.0313372612, 'accumulated_eval_time': 1860.6294927597046, 'accumulated_logging_time': 3.3053972721099854}
I0919 11:06:05.243236 140079888594688 logging_writer.py:48] [135025] accumulated_eval_time=1860.629493, accumulated_logging_time=3.305397, accumulated_submission_time=45462.031337, global_step=135025, preemption_count=0, score=45462.031337, test/accuracy=0.652500, test/loss=1.703856, test/num_examples=10000, total_duration=47327.858436, train/accuracy=0.907167, train/loss=0.592173, validation/accuracy=0.773060, validation/loss=1.123220, validation/num_examples=50000
I0919 11:08:45.256572 140080442218240 logging_writer.py:48] [135500] global_step=135500, grad_norm=0.5146767497062683, loss=2.5787625312805176
I0919 11:11:33.423074 140079888594688 logging_writer.py:48] [136000] global_step=136000, grad_norm=0.5033395886421204, loss=2.5921545028686523
I0919 11:14:21.659219 140080442218240 logging_writer.py:48] [136500] global_step=136500, grad_norm=0.5481114983558655, loss=2.637019634246826
I0919 11:14:35.532853 140245097760576 spec.py:320] Evaluating on the training split.
I0919 11:14:42.814294 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 11:14:53.618477 140245097760576 spec.py:348] Evaluating on the test split.
I0919 11:14:55.887355 140245097760576 submission_runner.py:376] Time since start: 47858.53s, 	Step: 136543, 	{'train/accuracy': 0.9085020422935486, 'train/loss': 0.5905719995498657, 'validation/accuracy': 0.7737399935722351, 'validation/loss': 1.1226686239242554, 'validation/num_examples': 50000, 'test/accuracy': 0.6511000394821167, 'test/loss': 1.7019078731536865, 'test/num_examples': 10000, 'score': 45972.291091918945, 'total_duration': 47858.53156018257, 'accumulated_submission_time': 45972.291091918945, 'accumulated_eval_time': 1880.9839470386505, 'accumulated_logging_time': 3.3439760208129883}
I0919 11:14:55.913591 140079100045056 logging_writer.py:48] [136543] accumulated_eval_time=1880.983947, accumulated_logging_time=3.343976, accumulated_submission_time=45972.291092, global_step=136543, preemption_count=0, score=45972.291092, test/accuracy=0.651100, test/loss=1.701908, test/num_examples=10000, total_duration=47858.531560, train/accuracy=0.908502, train/loss=0.590572, validation/accuracy=0.773740, validation/loss=1.122669, validation/num_examples=50000
I0919 11:17:29.998179 140079158773504 logging_writer.py:48] [137000] global_step=137000, grad_norm=0.508574903011322, loss=2.607954502105713
I0919 11:20:18.211241 140079100045056 logging_writer.py:48] [137500] global_step=137500, grad_norm=0.5211389064788818, loss=2.6471827030181885
I0919 11:23:06.391987 140079158773504 logging_writer.py:48] [138000] global_step=138000, grad_norm=0.49712997674942017, loss=2.5948386192321777
I0919 11:23:25.998990 140245097760576 spec.py:320] Evaluating on the training split.
I0919 11:23:33.237384 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 11:23:44.110323 140245097760576 spec.py:348] Evaluating on the test split.
I0919 11:23:46.377680 140245097760576 submission_runner.py:376] Time since start: 48389.02s, 	Step: 138060, 	{'train/accuracy': 0.9065290093421936, 'train/loss': 0.5865035057067871, 'validation/accuracy': 0.7734400033950806, 'validation/loss': 1.1186720132827759, 'validation/num_examples': 50000, 'test/accuracy': 0.6523000597953796, 'test/loss': 1.7003748416900635, 'test/num_examples': 10000, 'score': 46482.3462703228, 'total_duration': 48389.021898031235, 'accumulated_submission_time': 46482.3462703228, 'accumulated_eval_time': 1901.362600326538, 'accumulated_logging_time': 3.3802568912506104}
I0919 11:23:46.406736 140078873569024 logging_writer.py:48] [138060] accumulated_eval_time=1901.362600, accumulated_logging_time=3.380257, accumulated_submission_time=46482.346270, global_step=138060, preemption_count=0, score=46482.346270, test/accuracy=0.652300, test/loss=1.700375, test/num_examples=10000, total_duration=48389.021898, train/accuracy=0.906529, train/loss=0.586504, validation/accuracy=0.773440, validation/loss=1.118672, validation/num_examples=50000
I0919 11:26:14.754029 140078881961728 logging_writer.py:48] [138500] global_step=138500, grad_norm=0.5331783294677734, loss=2.6348490715026855
I0919 11:29:02.964525 140078873569024 logging_writer.py:48] [139000] global_step=139000, grad_norm=0.4877510964870453, loss=2.572187900543213
I0919 11:31:51.195692 140078881961728 logging_writer.py:48] [139500] global_step=139500, grad_norm=0.522478461265564, loss=2.6055312156677246
I0919 11:32:16.522610 140245097760576 spec.py:320] Evaluating on the training split.
I0919 11:32:23.748216 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 11:32:34.557670 140245097760576 spec.py:348] Evaluating on the test split.
I0919 11:32:36.796694 140245097760576 submission_runner.py:376] Time since start: 48919.44s, 	Step: 139577, 	{'train/accuracy': 0.9042769074440002, 'train/loss': 0.5936236381530762, 'validation/accuracy': 0.7740199565887451, 'validation/loss': 1.120292067527771, 'validation/num_examples': 50000, 'test/accuracy': 0.652400016784668, 'test/loss': 1.701324701309204, 'test/num_examples': 10000, 'score': 46992.43078827858, 'total_duration': 48919.440913677216, 'accumulated_submission_time': 46992.43078827858, 'accumulated_eval_time': 1921.636647939682, 'accumulated_logging_time': 3.4203310012817383}
I0919 11:32:36.824107 140079158773504 logging_writer.py:48] [139577] accumulated_eval_time=1921.636648, accumulated_logging_time=3.420331, accumulated_submission_time=46992.430788, global_step=139577, preemption_count=0, score=46992.430788, test/accuracy=0.652400, test/loss=1.701325, test/num_examples=10000, total_duration=48919.440914, train/accuracy=0.904277, train/loss=0.593624, validation/accuracy=0.774020, validation/loss=1.120292, validation/num_examples=50000
I0919 11:34:58.878713 140245097760576 spec.py:320] Evaluating on the training split.
I0919 11:35:06.138059 140245097760576 spec.py:332] Evaluating on the validation split.
I0919 11:35:16.963593 140245097760576 spec.py:348] Evaluating on the test split.
I0919 11:35:19.237958 140245097760576 submission_runner.py:376] Time since start: 49081.88s, 	Step: 140000, 	{'train/accuracy': 0.9085817933082581, 'train/loss': 0.5802215337753296, 'validation/accuracy': 0.7741400003433228, 'validation/loss': 1.1203563213348389, 'validation/num_examples': 50000, 'test/accuracy': 0.6518000364303589, 'test/loss': 1.7017462253570557, 'test/num_examples': 10000, 'score': 47134.46629500389, 'total_duration': 49081.88216590881, 'accumulated_submission_time': 47134.46629500389, 'accumulated_eval_time': 1941.995854139328, 'accumulated_logging_time': 3.460902214050293}
I0919 11:35:19.266723 140079100045056 logging_writer.py:48] [140000] accumulated_eval_time=1941.995854, accumulated_logging_time=3.460902, accumulated_submission_time=47134.466295, global_step=140000, preemption_count=0, score=47134.466295, test/accuracy=0.651800, test/loss=1.701746, test/num_examples=10000, total_duration=49081.882166, train/accuracy=0.908582, train/loss=0.580222, validation/accuracy=0.774140, validation/loss=1.120356, validation/num_examples=50000
I0919 11:35:19.293137 140079158773504 logging_writer.py:48] [140000] global_step=140000, preemption_count=0, score=47134.466295
I0919 11:35:19.553014 140245097760576 checkpoints.py:490] Saving checkpoint at step: 140000
I0919 11:35:20.407814 140245097760576 checkpoints.py:422] Saved checkpoint at /experiment_runs/targets_check_jax_run_01/momentum_run_0/imagenet_resnet_jax/trial_1/checkpoint_140000
I0919 11:35:20.428133 140245097760576 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/targets_check_jax_run_01/momentum_run_0/imagenet_resnet_jax/trial_1/checkpoint_140000.
I0919 11:35:21.219796 140245097760576 submission_runner.py:540] Tuning trial 1/1
I0919 11:35:21.220136 140245097760576 submission_runner.py:541] Hyperparameters: Hyperparameters(learning_rate=4.131896390902391, beta1=0.9274758113254791, beta2=0.9978504782314613, warmup_steps=6999, decay_steps_factor=0.9007765761611038, end_factor=0.001, weight_decay=5.6687777311501786e-06, label_smoothing=0.2)
I0919 11:35:21.223712 140245097760576 submission_runner.py:542] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0009167729294858873, 'train/loss': 6.912160873413086, 'validation/accuracy': 0.00107999995816499, 'validation/loss': 6.9129462242126465, 'validation/num_examples': 50000, 'test/accuracy': 0.0009000000427477062, 'test/loss': 6.912593364715576, 'test/num_examples': 10000, 'score': 64.80615377426147, 'total_duration': 112.50085163116455, 'accumulated_submission_time': 64.80615377426147, 'accumulated_eval_time': 47.69458341598511, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (1511, {'train/accuracy': 0.1892538219690323, 'train/loss': 4.242469787597656, 'validation/accuracy': 0.17117999494075775, 'validation/loss': 4.365173816680908, 'validation/num_examples': 50000, 'test/accuracy': 0.1291000097990036, 'test/loss': 4.756425857543945, 'test/num_examples': 10000, 'score': 574.8116409778595, 'total_duration': 640.3876354694366, 'accumulated_submission_time': 574.8116409778595, 'accumulated_eval_time': 65.52145624160767, 'accumulated_logging_time': 0.032228708267211914, 'global_step': 1511, 'preemption_count': 0}), (3026, {'train/accuracy': 0.38362962007522583, 'train/loss': 3.044987440109253, 'validation/accuracy': 0.35221999883651733, 'validation/loss': 3.208611249923706, 'validation/num_examples': 50000, 'test/accuracy': 0.2648000121116638, 'test/loss': 3.803739309310913, 'test/num_examples': 10000, 'score': 1084.818897485733, 'total_duration': 1168.8404161930084, 'accumulated_submission_time': 1084.818897485733, 'accumulated_eval_time': 83.91613936424255, 'accumulated_logging_time': 0.06050562858581543, 'global_step': 3026, 'preemption_count': 0}), (4542, {'train/accuracy': 0.4262595474720001, 'train/loss': 2.840193033218384, 'validation/accuracy': 0.3979399800300598, 'validation/loss': 2.9878180027008057, 'validation/num_examples': 50000, 'test/accuracy': 0.2981000244617462, 'test/loss': 3.595538854598999, 'test/num_examples': 10000, 'score': 1594.7971105575562, 'total_duration': 1697.1283793449402, 'accumulated_submission_time': 1594.7971105575562, 'accumulated_eval_time': 102.17391872406006, 'accumulated_logging_time': 0.09000849723815918, 'global_step': 4542, 'preemption_count': 0}), (6059, {'train/accuracy': 0.5079719424247742, 'train/loss': 2.401481866836548, 'validation/accuracy': 0.4783399999141693, 'validation/loss': 2.5446739196777344, 'validation/num_examples': 50000, 'test/accuracy': 0.36730000376701355, 'test/loss': 3.2133424282073975, 'test/num_examples': 10000, 'score': 2104.9897060394287, 'total_duration': 2225.463969707489, 'accumulated_submission_time': 2104.9897060394287, 'accumulated_eval_time': 120.26653456687927, 'accumulated_logging_time': 0.11799263954162598, 'global_step': 6059, 'preemption_count': 0}), (7576, {'train/accuracy': 0.5211654901504517, 'train/loss': 2.3125686645507812, 'validation/accuracy': 0.4885199964046478, 'validation/loss': 2.4631083011627197, 'validation/num_examples': 50000, 'test/accuracy': 0.37960001826286316, 'test/loss': 3.142300844192505, 'test/num_examples': 10000, 'score': 2615.1366531848907, 'total_duration': 2753.9645006656647, 'accumulated_submission_time': 2615.1366531848907, 'accumulated_eval_time': 138.56886315345764, 'accumulated_logging_time': 0.14600682258605957, 'global_step': 7576, 'preemption_count': 0}), (9093, {'train/accuracy': 0.5986328125, 'train/loss': 1.9171991348266602, 'validation/accuracy': 0.5203199982643127, 'validation/loss': 2.2843058109283447, 'validation/num_examples': 50000, 'test/accuracy': 0.4017000198364258, 'test/loss': 2.9574360847473145, 'test/num_examples': 10000, 'score': 3125.3041179180145, 'total_duration': 3282.39505815506, 'accumulated_submission_time': 3125.3041179180145, 'accumulated_eval_time': 156.78103804588318, 'accumulated_logging_time': 0.17435216903686523, 'global_step': 9093, 'preemption_count': 0}), (10610, {'train/accuracy': 0.5328643321990967, 'train/loss': 2.2464993000030518, 'validation/accuracy': 0.48135998845100403, 'validation/loss': 2.5128233432769775, 'validation/num_examples': 50000, 'test/accuracy': 0.3797000050544739, 'test/loss': 3.102165460586548, 'test/num_examples': 10000, 'score': 3635.3449680805206, 'total_duration': 3810.9727642536163, 'accumulated_submission_time': 3635.3449680805206, 'accumulated_eval_time': 175.2663881778717, 'accumulated_logging_time': 0.20341968536376953, 'global_step': 10610, 'preemption_count': 0}), (12127, {'train/accuracy': 0.5541692972183228, 'train/loss': 2.180311679840088, 'validation/accuracy': 0.5069400072097778, 'validation/loss': 2.392803192138672, 'validation/num_examples': 50000, 'test/accuracy': 0.39420002698898315, 'test/loss': 3.0181732177734375, 'test/num_examples': 10000, 'score': 4145.451757669449, 'total_duration': 4339.712961912155, 'accumulated_submission_time': 4145.451757669449, 'accumulated_eval_time': 193.84642934799194, 'accumulated_logging_time': 0.23447585105895996, 'global_step': 12127, 'preemption_count': 0}), (13644, {'train/accuracy': 0.5454201102256775, 'train/loss': 2.18947434425354, 'validation/accuracy': 0.5059599876403809, 'validation/loss': 2.383917808532715, 'validation/num_examples': 50000, 'test/accuracy': 0.39330002665519714, 'test/loss': 3.0202107429504395, 'test/num_examples': 10000, 'score': 4655.583962917328, 'total_duration': 4868.476912498474, 'accumulated_submission_time': 4655.583962917328, 'accumulated_eval_time': 212.41541361808777, 'accumulated_logging_time': 0.2749812602996826, 'global_step': 13644, 'preemption_count': 0}), (15161, {'train/accuracy': 0.5900430083274841, 'train/loss': 1.940801739692688, 'validation/accuracy': 0.5483199954032898, 'validation/loss': 2.1355481147766113, 'validation/num_examples': 50000, 'test/accuracy': 0.4303000271320343, 'test/loss': 2.7870802879333496, 'test/num_examples': 10000, 'score': 5165.618021726608, 'total_duration': 5397.9573802948, 'accumulated_submission_time': 5165.618021726608, 'accumulated_eval_time': 231.81007027626038, 'accumulated_logging_time': 0.3049659729003906, 'global_step': 15161, 'preemption_count': 0}), (16678, {'train/accuracy': 0.5860371589660645, 'train/loss': 1.9944552183151245, 'validation/accuracy': 0.550059974193573, 'validation/loss': 2.1530261039733887, 'validation/num_examples': 50000, 'test/accuracy': 0.4279000163078308, 'test/loss': 2.8396711349487305, 'test/num_examples': 10000, 'score': 5675.676437139511, 'total_duration': 5926.708446502686, 'accumulated_submission_time': 5675.676437139511, 'accumulated_eval_time': 250.43241119384766, 'accumulated_logging_time': 0.3533515930175781, 'global_step': 16678, 'preemption_count': 0}), (18195, {'train/accuracy': 0.6191805005073547, 'train/loss': 1.8125768899917603, 'validation/accuracy': 0.5428199768066406, 'validation/loss': 2.1788017749786377, 'validation/num_examples': 50000, 'test/accuracy': 0.415800005197525, 'test/loss': 2.8776638507843018, 'test/num_examples': 10000, 'score': 6185.806494951248, 'total_duration': 6456.2611672878265, 'accumulated_submission_time': 6185.806494951248, 'accumulated_eval_time': 269.7962746620178, 'accumulated_logging_time': 0.38915419578552246, 'global_step': 18195, 'preemption_count': 0}), (19712, {'train/accuracy': 0.6296635866165161, 'train/loss': 1.755889654159546, 'validation/accuracy': 0.5690000057220459, 'validation/loss': 2.028282880783081, 'validation/num_examples': 50000, 'test/accuracy': 0.4487000107765198, 'test/loss': 2.6749298572540283, 'test/num_examples': 10000, 'score': 6695.867879390717, 'total_duration': 6985.161635398865, 'accumulated_submission_time': 6695.867879390717, 'accumulated_eval_time': 288.56330966949463, 'accumulated_logging_time': 0.4392695426940918, 'global_step': 19712, 'preemption_count': 0}), (21229, {'train/accuracy': 0.6113680005073547, 'train/loss': 1.9071935415267944, 'validation/accuracy': 0.5615400075912476, 'validation/loss': 2.136620044708252, 'validation/num_examples': 50000, 'test/accuracy': 0.4368000328540802, 'test/loss': 2.8098642826080322, 'test/num_examples': 10000, 'score': 7205.9560983181, 'total_duration': 7515.6140875816345, 'accumulated_submission_time': 7205.9560983181, 'accumulated_eval_time': 308.8688642978668, 'accumulated_logging_time': 0.4752368927001953, 'global_step': 21229, 'preemption_count': 0}), (22746, {'train/accuracy': 0.5900828838348389, 'train/loss': 2.003718614578247, 'validation/accuracy': 0.5470600128173828, 'validation/loss': 2.1998207569122314, 'validation/num_examples': 50000, 'test/accuracy': 0.4289000332355499, 'test/loss': 2.8556807041168213, 'test/num_examples': 10000, 'score': 7716.082714080811, 'total_duration': 8045.518242359161, 'accumulated_submission_time': 7716.082714080811, 'accumulated_eval_time': 328.57254815101624, 'accumulated_logging_time': 0.5265705585479736, 'global_step': 22746, 'preemption_count': 0}), (24263, {'train/accuracy': 0.5965002775192261, 'train/loss': 1.9317721128463745, 'validation/accuracy': 0.5542600154876709, 'validation/loss': 2.1205153465270996, 'validation/num_examples': 50000, 'test/accuracy': 0.4285000264644623, 'test/loss': 2.80458927154541, 'test/num_examples': 10000, 'score': 8226.141713142395, 'total_duration': 8575.407284259796, 'accumulated_submission_time': 8226.141713142395, 'accumulated_eval_time': 348.34847712516785, 'accumulated_logging_time': 0.5582351684570312, 'global_step': 24263, 'preemption_count': 0}), (25780, {'train/accuracy': 0.6048309803009033, 'train/loss': 1.9325666427612305, 'validation/accuracy': 0.5648199915885925, 'validation/loss': 2.1053247451782227, 'validation/num_examples': 50000, 'test/accuracy': 0.4458000063896179, 'test/loss': 2.7545578479766846, 'test/num_examples': 10000, 'score': 8736.2371571064, 'total_duration': 9106.076616764069, 'accumulated_submission_time': 8736.2371571064, 'accumulated_eval_time': 368.86967420578003, 'accumulated_logging_time': 0.5889146327972412, 'global_step': 25780, 'preemption_count': 0}), (27297, {'train/accuracy': 0.648457407951355, 'train/loss': 1.7073768377304077, 'validation/accuracy': 0.5740599632263184, 'validation/loss': 2.045314073562622, 'validation/num_examples': 50000, 'test/accuracy': 0.4489000141620636, 'test/loss': 2.731684684753418, 'test/num_examples': 10000, 'score': 9246.338513851166, 'total_duration': 9636.938492059708, 'accumulated_submission_time': 9246.338513851166, 'accumulated_eval_time': 389.5780885219574, 'accumulated_logging_time': 0.6190969944000244, 'global_step': 27297, 'preemption_count': 0}), (28814, {'train/accuracy': 0.6102519035339355, 'train/loss': 1.919688105583191, 'validation/accuracy': 0.5570200085639954, 'validation/loss': 2.1826367378234863, 'validation/num_examples': 50000, 'test/accuracy': 0.43880000710487366, 'test/loss': 2.8118410110473633, 'test/num_examples': 10000, 'score': 9756.365114688873, 'total_duration': 10167.22600197792, 'accumulated_submission_time': 9756.365114688873, 'accumulated_eval_time': 409.78370451927185, 'accumulated_logging_time': 0.6514098644256592, 'global_step': 28814, 'preemption_count': 0}), (30331, {'train/accuracy': 0.6017019748687744, 'train/loss': 1.9694526195526123, 'validation/accuracy': 0.5550999641418457, 'validation/loss': 2.1903817653656006, 'validation/num_examples': 50000, 'test/accuracy': 0.43250003457069397, 'test/loss': 2.8544583320617676, 'test/num_examples': 10000, 'score': 10266.457380771637, 'total_duration': 10698.995329380035, 'accumulated_submission_time': 10266.457380771637, 'accumulated_eval_time': 431.4018225669861, 'accumulated_logging_time': 0.6866528987884521, 'global_step': 30331, 'preemption_count': 0}), (31849, {'train/accuracy': 0.6138990521430969, 'train/loss': 1.9323968887329102, 'validation/accuracy': 0.5714600086212158, 'validation/loss': 2.1468288898468018, 'validation/num_examples': 50000, 'test/accuracy': 0.4465000331401825, 'test/loss': 2.7963528633117676, 'test/num_examples': 10000, 'score': 10776.701550006866, 'total_duration': 11230.215115308762, 'accumulated_submission_time': 10776.701550006866, 'accumulated_eval_time': 452.32195019721985, 'accumulated_logging_time': 0.7195277214050293, 'global_step': 31849, 'preemption_count': 0}), (33367, {'train/accuracy': 0.6291453838348389, 'train/loss': 1.737581491470337, 'validation/accuracy': 0.5842999815940857, 'validation/loss': 1.9522442817687988, 'validation/num_examples': 50000, 'test/accuracy': 0.46300002932548523, 'test/loss': 2.632305145263672, 'test/num_examples': 10000, 'score': 11286.97012758255, 'total_duration': 11762.031930208206, 'accumulated_submission_time': 11286.97012758255, 'accumulated_eval_time': 473.80539107322693, 'accumulated_logging_time': 0.7617902755737305, 'global_step': 33367, 'preemption_count': 0}), (34884, {'train/accuracy': 0.6321348547935486, 'train/loss': 1.7898281812667847, 'validation/accuracy': 0.5905599594116211, 'validation/loss': 1.9755117893218994, 'validation/num_examples': 50000, 'test/accuracy': 0.467600017786026, 'test/loss': 2.653351068496704, 'test/num_examples': 10000, 'score': 11796.948772668839, 'total_duration': 12293.878856658936, 'accumulated_submission_time': 11796.948772668839, 'accumulated_eval_time': 495.6094489097595, 'accumulated_logging_time': 0.8033304214477539, 'global_step': 34884, 'preemption_count': 0}), (36401, {'train/accuracy': 0.6490353941917419, 'train/loss': 1.7624365091323853, 'validation/accuracy': 0.5829399824142456, 'validation/loss': 2.069182872772217, 'validation/num_examples': 50000, 'test/accuracy': 0.4589000344276428, 'test/loss': 2.729459524154663, 'test/num_examples': 10000, 'score': 12306.99295759201, 'total_duration': 12826.234589576721, 'accumulated_submission_time': 12306.99295759201, 'accumulated_eval_time': 517.8610317707062, 'accumulated_logging_time': 0.840540885925293, 'global_step': 36401, 'preemption_count': 0}), (37919, {'train/accuracy': 0.6336694955825806, 'train/loss': 1.7425209283828735, 'validation/accuracy': 0.579800009727478, 'validation/loss': 2.002507448196411, 'validation/num_examples': 50000, 'test/accuracy': 0.4490000307559967, 'test/loss': 2.7044670581817627, 'test/num_examples': 10000, 'score': 12817.115663766861, 'total_duration': 13357.231716394424, 'accumulated_submission_time': 12817.115663766861, 'accumulated_eval_time': 538.673003911972, 'accumulated_logging_time': 0.8800115585327148, 'global_step': 37919, 'preemption_count': 0}), (39436, {'train/accuracy': 0.6382334232330322, 'train/loss': 1.7431460618972778, 'validation/accuracy': 0.587619960308075, 'validation/loss': 1.9530900716781616, 'validation/num_examples': 50000, 'test/accuracy': 0.4626000225543976, 'test/loss': 2.6381335258483887, 'test/num_examples': 10000, 'score': 13327.157706737518, 'total_duration': 13888.223961114883, 'accumulated_submission_time': 13327.157706737518, 'accumulated_eval_time': 559.5597512722015, 'accumulated_logging_time': 0.9208221435546875, 'global_step': 39436, 'preemption_count': 0}), (40953, {'train/accuracy': 0.6347058415412903, 'train/loss': 1.778356909751892, 'validation/accuracy': 0.5856800079345703, 'validation/loss': 1.9926531314849854, 'validation/num_examples': 50000, 'test/accuracy': 0.4652000367641449, 'test/loss': 2.6373789310455322, 'test/num_examples': 10000, 'score': 13837.148118257523, 'total_duration': 14419.011028289795, 'accumulated_submission_time': 13837.148118257523, 'accumulated_eval_time': 580.2938213348389, 'accumulated_logging_time': 0.960615873336792, 'global_step': 40953, 'preemption_count': 0}), (42471, {'train/accuracy': 0.6211734414100647, 'train/loss': 1.8077707290649414, 'validation/accuracy': 0.5771799683570862, 'validation/loss': 2.0112338066101074, 'validation/num_examples': 50000, 'test/accuracy': 0.4529000222682953, 'test/loss': 2.69852352142334, 'test/num_examples': 10000, 'score': 14347.40918970108, 'total_duration': 14949.99478673935, 'accumulated_submission_time': 14347.40918970108, 'accumulated_eval_time': 600.9589376449585, 'accumulated_logging_time': 0.9961771965026855, 'global_step': 42471, 'preemption_count': 0}), (43988, {'train/accuracy': 0.6793287396430969, 'train/loss': 1.5328608751296997, 'validation/accuracy': 0.6055799722671509, 'validation/loss': 1.8692936897277832, 'validation/num_examples': 50000, 'test/accuracy': 0.4812000095844269, 'test/loss': 2.5292365550994873, 'test/num_examples': 10000, 'score': 14857.495784044266, 'total_duration': 15480.864092350006, 'accumulated_submission_time': 14857.495784044266, 'accumulated_eval_time': 621.6836967468262, 'accumulated_logging_time': 1.0306508541107178, 'global_step': 43988, 'preemption_count': 0}), (45506, {'train/accuracy': 0.6739675998687744, 'train/loss': 1.5494647026062012, 'validation/accuracy': 0.6106399893760681, 'validation/loss': 1.8453357219696045, 'validation/num_examples': 50000, 'test/accuracy': 0.48440003395080566, 'test/loss': 2.502803087234497, 'test/num_examples': 10000, 'score': 15367.717188358307, 'total_duration': 16012.011163949966, 'accumulated_submission_time': 15367.717188358307, 'accumulated_eval_time': 642.5513274669647, 'accumulated_logging_time': 1.0658679008483887, 'global_step': 45506, 'preemption_count': 0}), (47023, {'train/accuracy': 0.6523237824440002, 'train/loss': 1.6569514274597168, 'validation/accuracy': 0.5984199643135071, 'validation/loss': 1.9110010862350464, 'validation/num_examples': 50000, 'test/accuracy': 0.47030001878738403, 'test/loss': 2.6157262325286865, 'test/num_examples': 10000, 'score': 15877.718472957611, 'total_duration': 16542.884393692017, 'accumulated_submission_time': 15877.718472957611, 'accumulated_eval_time': 663.3620738983154, 'accumulated_logging_time': 1.104386568069458, 'global_step': 47023, 'preemption_count': 0}), (48540, {'train/accuracy': 0.6041135191917419, 'train/loss': 1.9337728023529053, 'validation/accuracy': 0.5577999949455261, 'validation/loss': 2.163736581802368, 'validation/num_examples': 50000, 'test/accuracy': 0.4301000237464905, 'test/loss': 2.88299822807312, 'test/num_examples': 10000, 'score': 16387.850256681442, 'total_duration': 17073.867317438126, 'accumulated_submission_time': 16387.850256681442, 'accumulated_eval_time': 684.156824350357, 'accumulated_logging_time': 1.1386842727661133, 'global_step': 48540, 'preemption_count': 0}), (50057, {'train/accuracy': 0.6246213316917419, 'train/loss': 1.7456004619598389, 'validation/accuracy': 0.5808199644088745, 'validation/loss': 1.96638822555542, 'validation/num_examples': 50000, 'test/accuracy': 0.45000001788139343, 'test/loss': 2.6594595909118652, 'test/num_examples': 10000, 'score': 16897.873760938644, 'total_duration': 17604.773377895355, 'accumulated_submission_time': 16897.873760938644, 'accumulated_eval_time': 704.9818737506866, 'accumulated_logging_time': 1.1735165119171143, 'global_step': 50057, 'preemption_count': 0}), (51574, {'train/accuracy': 0.6569076776504517, 'train/loss': 1.6841869354248047, 'validation/accuracy': 0.6110599637031555, 'validation/loss': 1.8849471807479858, 'validation/num_examples': 50000, 'test/accuracy': 0.48250001668930054, 'test/loss': 2.5378668308258057, 'test/num_examples': 10000, 'score': 17407.82470226288, 'total_duration': 18135.69685125351, 'accumulated_submission_time': 17407.82470226288, 'accumulated_eval_time': 725.8962314128876, 'accumulated_logging_time': 1.2089519500732422, 'global_step': 51574, 'preemption_count': 0}), (53091, {'train/accuracy': 0.7050581574440002, 'train/loss': 1.4129359722137451, 'validation/accuracy': 0.6082199811935425, 'validation/loss': 1.8329261541366577, 'validation/num_examples': 50000, 'test/accuracy': 0.4846000373363495, 'test/loss': 2.500943183898926, 'test/num_examples': 10000, 'score': 17917.80679678917, 'total_duration': 18666.525322437286, 'accumulated_submission_time': 17917.80679678917, 'accumulated_eval_time': 746.6859955787659, 'accumulated_logging_time': 1.2432892322540283, 'global_step': 53091, 'preemption_count': 0}), (54608, {'train/accuracy': 0.6829958558082581, 'train/loss': 1.494336485862732, 'validation/accuracy': 0.6208400130271912, 'validation/loss': 1.7739062309265137, 'validation/num_examples': 50000, 'test/accuracy': 0.49880000948905945, 'test/loss': 2.444182872772217, 'test/num_examples': 10000, 'score': 18427.823033094406, 'total_duration': 19197.650846481323, 'accumulated_submission_time': 18427.823033094406, 'accumulated_eval_time': 767.737245798111, 'accumulated_logging_time': 1.278395652770996, 'global_step': 54608, 'preemption_count': 0}), (56125, {'train/accuracy': 0.6871013641357422, 'train/loss': 1.526764988899231, 'validation/accuracy': 0.6281999945640564, 'validation/loss': 1.7881439924240112, 'validation/num_examples': 50000, 'test/accuracy': 0.5010000467300415, 'test/loss': 2.445608139038086, 'test/num_examples': 10000, 'score': 18937.767692565918, 'total_duration': 19728.54311323166, 'accumulated_submission_time': 18937.767692565918, 'accumulated_eval_time': 788.6260476112366, 'accumulated_logging_time': 1.3143045902252197, 'global_step': 56125, 'preemption_count': 0}), (57642, {'train/accuracy': 0.6488759517669678, 'train/loss': 1.726908802986145, 'validation/accuracy': 0.5937399864196777, 'validation/loss': 1.9639030694961548, 'validation/num_examples': 50000, 'test/accuracy': 0.4668000340461731, 'test/loss': 2.6268622875213623, 'test/num_examples': 10000, 'score': 19447.78379178047, 'total_duration': 20259.561609745026, 'accumulated_submission_time': 19447.78379178047, 'accumulated_eval_time': 809.5735065937042, 'accumulated_logging_time': 1.3472275733947754, 'global_step': 57642, 'preemption_count': 0}), (59159, {'train/accuracy': 0.6782127022743225, 'train/loss': 1.5793383121490479, 'validation/accuracy': 0.6237599849700928, 'validation/loss': 1.8233593702316284, 'validation/num_examples': 50000, 'test/accuracy': 0.49650001525878906, 'test/loss': 2.490795850753784, 'test/num_examples': 10000, 'score': 19957.75455212593, 'total_duration': 20790.498770713806, 'accumulated_submission_time': 19957.75455212593, 'accumulated_eval_time': 830.4804813861847, 'accumulated_logging_time': 1.3838343620300293, 'global_step': 59159, 'preemption_count': 0}), (60676, {'train/accuracy': 0.641043484210968, 'train/loss': 1.7735086679458618, 'validation/accuracy': 0.5956999659538269, 'validation/loss': 1.9781285524368286, 'validation/num_examples': 50000, 'test/accuracy': 0.4766000211238861, 'test/loss': 2.61031436920166, 'test/num_examples': 10000, 'score': 20467.869895219803, 'total_duration': 21321.503106832504, 'accumulated_submission_time': 20467.869895219803, 'accumulated_eval_time': 851.3065967559814, 'accumulated_logging_time': 1.4244861602783203, 'global_step': 60676, 'preemption_count': 0}), (62193, {'train/accuracy': 0.7098811864852905, 'train/loss': 1.430907130241394, 'validation/accuracy': 0.625499963760376, 'validation/loss': 1.817330241203308, 'validation/num_examples': 50000, 'test/accuracy': 0.5009000301361084, 'test/loss': 2.4610514640808105, 'test/num_examples': 10000, 'score': 20977.998966693878, 'total_duration': 21852.278718948364, 'accumulated_submission_time': 20977.998966693878, 'accumulated_eval_time': 871.8904156684875, 'accumulated_logging_time': 1.4668834209442139, 'global_step': 62193, 'preemption_count': 0}), (63711, {'train/accuracy': 0.6798469424247742, 'train/loss': 1.5500541925430298, 'validation/accuracy': 0.6165199875831604, 'validation/loss': 1.8367286920547485, 'validation/num_examples': 50000, 'test/accuracy': 0.48440003395080566, 'test/loss': 2.513198137283325, 'test/num_examples': 10000, 'score': 21488.22046637535, 'total_duration': 22383.141842603683, 'accumulated_submission_time': 21488.22046637535, 'accumulated_eval_time': 892.4749524593353, 'accumulated_logging_time': 1.5038414001464844, 'global_step': 63711, 'preemption_count': 0}), (65229, {'train/accuracy': 0.6919044852256775, 'train/loss': 1.528098225593567, 'validation/accuracy': 0.628879964351654, 'validation/loss': 1.8035516738891602, 'validation/num_examples': 50000, 'test/accuracy': 0.49560001492500305, 'test/loss': 2.483914613723755, 'test/num_examples': 10000, 'score': 21998.431813955307, 'total_duration': 22914.130730628967, 'accumulated_submission_time': 21998.431813955307, 'accumulated_eval_time': 913.1940140724182, 'accumulated_logging_time': 1.542017936706543, 'global_step': 65229, 'preemption_count': 0}), (66746, {'train/accuracy': 0.6633250713348389, 'train/loss': 1.610998272895813, 'validation/accuracy': 0.6083999872207642, 'validation/loss': 1.8528920412063599, 'validation/num_examples': 50000, 'test/accuracy': 0.48100003600120544, 'test/loss': 2.542644739151001, 'test/num_examples': 10000, 'score': 22508.42777967453, 'total_duration': 23445.09285068512, 'accumulated_submission_time': 22508.42777967453, 'accumulated_eval_time': 934.1030423641205, 'accumulated_logging_time': 1.5790565013885498, 'global_step': 66746, 'preemption_count': 0}), (68263, {'train/accuracy': 0.6818598508834839, 'train/loss': 1.5423789024353027, 'validation/accuracy': 0.6284199953079224, 'validation/loss': 1.7802072763442993, 'validation/num_examples': 50000, 'test/accuracy': 0.5039000511169434, 'test/loss': 2.4353668689727783, 'test/num_examples': 10000, 'score': 23018.41924905777, 'total_duration': 23975.78776717186, 'accumulated_submission_time': 23018.41924905777, 'accumulated_eval_time': 954.7471029758453, 'accumulated_logging_time': 1.6181974411010742, 'global_step': 68263, 'preemption_count': 0}), (69780, {'train/accuracy': 0.6935786008834839, 'train/loss': 1.470489501953125, 'validation/accuracy': 0.6381199955940247, 'validation/loss': 1.7132763862609863, 'validation/num_examples': 50000, 'test/accuracy': 0.5136000514030457, 'test/loss': 2.3623480796813965, 'test/num_examples': 10000, 'score': 23528.449256658554, 'total_duration': 24506.664514780045, 'accumulated_submission_time': 23528.449256658554, 'accumulated_eval_time': 975.5390205383301, 'accumulated_logging_time': 1.6528310775756836, 'global_step': 69780, 'preemption_count': 0}), (71298, {'train/accuracy': 0.7183513641357422, 'train/loss': 1.3737677335739136, 'validation/accuracy': 0.6387799978256226, 'validation/loss': 1.7288742065429688, 'validation/num_examples': 50000, 'test/accuracy': 0.5098000168800354, 'test/loss': 2.374168872833252, 'test/num_examples': 10000, 'score': 24038.630749225616, 'total_duration': 25037.68881034851, 'accumulated_submission_time': 24038.630749225616, 'accumulated_eval_time': 996.3270401954651, 'accumulated_logging_time': 1.6874737739562988, 'global_step': 71298, 'preemption_count': 0}), (72816, {'train/accuracy': 0.7173150181770325, 'train/loss': 1.3715227842330933, 'validation/accuracy': 0.6507799625396729, 'validation/loss': 1.6766383647918701, 'validation/num_examples': 50000, 'test/accuracy': 0.5223000049591064, 'test/loss': 2.3065056800842285, 'test/num_examples': 10000, 'score': 24548.817907333374, 'total_duration': 25568.546179533005, 'accumulated_submission_time': 24548.817907333374, 'accumulated_eval_time': 1016.9436917304993, 'accumulated_logging_time': 1.7209486961364746, 'global_step': 72816, 'preemption_count': 0}), (74334, {'train/accuracy': 0.7150231003761292, 'train/loss': 1.4037551879882812, 'validation/accuracy': 0.6541999578475952, 'validation/loss': 1.6802089214324951, 'validation/num_examples': 50000, 'test/accuracy': 0.5294000506401062, 'test/loss': 2.3218131065368652, 'test/num_examples': 10000, 'score': 25059.06854248047, 'total_duration': 26099.38676095009, 'accumulated_submission_time': 25059.06854248047, 'accumulated_eval_time': 1037.4791700839996, 'accumulated_logging_time': 1.7551240921020508, 'global_step': 74334, 'preemption_count': 0}), (75852, {'train/accuracy': 0.6949537396430969, 'train/loss': 1.4483387470245361, 'validation/accuracy': 0.6391800045967102, 'validation/loss': 1.7073774337768555, 'validation/num_examples': 50000, 'test/accuracy': 0.5117000341415405, 'test/loss': 2.3859994411468506, 'test/num_examples': 10000, 'score': 25569.311100006104, 'total_duration': 26630.78979563713, 'accumulated_submission_time': 25569.311100006104, 'accumulated_eval_time': 1058.5790586471558, 'accumulated_logging_time': 1.7955327033996582, 'global_step': 75852, 'preemption_count': 0}), (77369, {'train/accuracy': 0.6845503449440002, 'train/loss': 1.5119658708572388, 'validation/accuracy': 0.6297999620437622, 'validation/loss': 1.767849326133728, 'validation/num_examples': 50000, 'test/accuracy': 0.5014000535011292, 'test/loss': 2.4139227867126465, 'test/num_examples': 10000, 'score': 26079.353837251663, 'total_duration': 27161.51313304901, 'accumulated_submission_time': 26079.353837251663, 'accumulated_eval_time': 1079.1990377902985, 'accumulated_logging_time': 1.836071252822876, 'global_step': 77369, 'preemption_count': 0}), (78886, {'train/accuracy': 0.72367262840271, 'train/loss': 1.3457744121551514, 'validation/accuracy': 0.6444399952888489, 'validation/loss': 1.6890619993209839, 'validation/num_examples': 50000, 'test/accuracy': 0.5208000540733337, 'test/loss': 2.3527793884277344, 'test/num_examples': 10000, 'score': 26589.38980102539, 'total_duration': 27692.19407916069, 'accumulated_submission_time': 26589.38980102539, 'accumulated_eval_time': 1099.7865402698517, 'accumulated_logging_time': 1.873595952987671, 'global_step': 78886, 'preemption_count': 0}), (80403, {'train/accuracy': 0.711336076259613, 'train/loss': 1.3960850238800049, 'validation/accuracy': 0.6375600099563599, 'validation/loss': 1.7303324937820435, 'validation/num_examples': 50000, 'test/accuracy': 0.5095000267028809, 'test/loss': 2.383603811264038, 'test/num_examples': 10000, 'score': 27099.39931821823, 'total_duration': 28222.901433229446, 'accumulated_submission_time': 27099.39931821823, 'accumulated_eval_time': 1120.4297413825989, 'accumulated_logging_time': 1.9080631732940674, 'global_step': 80403, 'preemption_count': 0}), (81920, {'train/accuracy': 0.7154815196990967, 'train/loss': 1.3452292680740356, 'validation/accuracy': 0.6497200131416321, 'validation/loss': 1.648118495941162, 'validation/num_examples': 50000, 'test/accuracy': 0.5223000049591064, 'test/loss': 2.3020050525665283, 'test/num_examples': 10000, 'score': 27609.43206501007, 'total_duration': 28753.52916288376, 'accumulated_submission_time': 27609.43206501007, 'accumulated_eval_time': 1140.9687027931213, 'accumulated_logging_time': 1.9445154666900635, 'global_step': 81920, 'preemption_count': 0}), (83437, {'train/accuracy': 0.7182317972183228, 'train/loss': 1.3525248765945435, 'validation/accuracy': 0.6508600115776062, 'validation/loss': 1.6412359476089478, 'validation/num_examples': 50000, 'test/accuracy': 0.5220000147819519, 'test/loss': 2.308457612991333, 'test/num_examples': 10000, 'score': 28119.417169332504, 'total_duration': 29284.172510147095, 'accumulated_submission_time': 28119.417169332504, 'accumulated_eval_time': 1161.5699355602264, 'accumulated_logging_time': 1.9811246395111084, 'global_step': 83437, 'preemption_count': 0}), (84955, {'train/accuracy': 0.7302694320678711, 'train/loss': 1.3102004528045654, 'validation/accuracy': 0.6685999631881714, 'validation/loss': 1.5819252729415894, 'validation/num_examples': 50000, 'test/accuracy': 0.5442000031471252, 'test/loss': 2.22513484954834, 'test/num_examples': 10000, 'score': 28629.48138308525, 'total_duration': 29814.99689412117, 'accumulated_submission_time': 28629.48138308525, 'accumulated_eval_time': 1182.275056362152, 'accumulated_logging_time': 2.0158612728118896, 'global_step': 84955, 'preemption_count': 0}), (86473, {'train/accuracy': 0.7212013602256775, 'train/loss': 1.3514279127120972, 'validation/accuracy': 0.6615999937057495, 'validation/loss': 1.627492904663086, 'validation/num_examples': 50000, 'test/accuracy': 0.534500002861023, 'test/loss': 2.2647857666015625, 'test/num_examples': 10000, 'score': 29139.703558683395, 'total_duration': 30346.07021546364, 'accumulated_submission_time': 29139.703558683395, 'accumulated_eval_time': 1203.0615570545197, 'accumulated_logging_time': 2.0603201389312744, 'global_step': 86473, 'preemption_count': 0}), (87991, {'train/accuracy': 0.7641900181770325, 'train/loss': 1.1873400211334229, 'validation/accuracy': 0.6584999561309814, 'validation/loss': 1.6387598514556885, 'validation/num_examples': 50000, 'test/accuracy': 0.5294000506401062, 'test/loss': 2.2972586154937744, 'test/num_examples': 10000, 'score': 29649.899120807648, 'total_duration': 30877.069764614105, 'accumulated_submission_time': 29649.899120807648, 'accumulated_eval_time': 1223.8042414188385, 'accumulated_logging_time': 2.101274013519287, 'global_step': 87991, 'preemption_count': 0}), (89509, {'train/accuracy': 0.7386599183082581, 'train/loss': 1.3126999139785767, 'validation/accuracy': 0.6611999869346619, 'validation/loss': 1.6471408605575562, 'validation/num_examples': 50000, 'test/accuracy': 0.5315000414848328, 'test/loss': 2.3068275451660156, 'test/num_examples': 10000, 'score': 30160.129207372665, 'total_duration': 31407.866783618927, 'accumulated_submission_time': 30160.129207372665, 'accumulated_eval_time': 1244.3144550323486, 'accumulated_logging_time': 2.137824773788452, 'global_step': 89509, 'preemption_count': 0}), (91026, {'train/accuracy': 0.7432238459587097, 'train/loss': 1.2964186668395996, 'validation/accuracy': 0.6706799864768982, 'validation/loss': 1.6102522611618042, 'validation/num_examples': 50000, 'test/accuracy': 0.5410000085830688, 'test/loss': 2.256373405456543, 'test/num_examples': 10000, 'score': 30670.118807554245, 'total_duration': 31938.488426685333, 'accumulated_submission_time': 30670.118807554245, 'accumulated_eval_time': 1264.890377521515, 'accumulated_logging_time': 2.173720598220825, 'global_step': 91026, 'preemption_count': 0}), (92543, {'train/accuracy': 0.7345144748687744, 'train/loss': 1.2694228887557983, 'validation/accuracy': 0.668720006942749, 'validation/loss': 1.5643812417984009, 'validation/num_examples': 50000, 'test/accuracy': 0.5458000302314758, 'test/loss': 2.223123073577881, 'test/num_examples': 10000, 'score': 31180.136553525925, 'total_duration': 32469.14278435707, 'accumulated_submission_time': 31180.136553525925, 'accumulated_eval_time': 1285.4702961444855, 'accumulated_logging_time': 2.210169792175293, 'global_step': 92543, 'preemption_count': 0}), (94061, {'train/accuracy': 0.7450374364852905, 'train/loss': 1.205109715461731, 'validation/accuracy': 0.6753199696540833, 'validation/loss': 1.5156527757644653, 'validation/num_examples': 50000, 'test/accuracy': 0.5515000224113464, 'test/loss': 2.1441524028778076, 'test/num_examples': 10000, 'score': 31690.346209049225, 'total_duration': 33000.06192779541, 'accumulated_submission_time': 31690.346209049225, 'accumulated_eval_time': 1306.1234905719757, 'accumulated_logging_time': 2.2462716102600098, 'global_step': 94061, 'preemption_count': 0}), (95578, {'train/accuracy': 0.7210817933082581, 'train/loss': 1.3763164281845093, 'validation/accuracy': 0.6561399698257446, 'validation/loss': 1.6640539169311523, 'validation/num_examples': 50000, 'test/accuracy': 0.5299000144004822, 'test/loss': 2.322737455368042, 'test/num_examples': 10000, 'score': 32200.342797517776, 'total_duration': 33530.66452765465, 'accumulated_submission_time': 32200.342797517776, 'accumulated_eval_time': 1326.6736025810242, 'accumulated_logging_time': 2.282148599624634, 'global_step': 95578, 'preemption_count': 0}), (97095, {'train/accuracy': 0.7633131146430969, 'train/loss': 1.2339246273040771, 'validation/accuracy': 0.6608399748802185, 'validation/loss': 1.6570223569869995, 'validation/num_examples': 50000, 'test/accuracy': 0.527400016784668, 'test/loss': 2.335861921310425, 'test/num_examples': 10000, 'score': 32710.34723854065, 'total_duration': 34061.545172691345, 'accumulated_submission_time': 32710.34723854065, 'accumulated_eval_time': 1347.491994380951, 'accumulated_logging_time': 2.3200888633728027, 'global_step': 97095, 'preemption_count': 0}), (98612, {'train/accuracy': 0.7786192297935486, 'train/loss': 1.0950895547866821, 'validation/accuracy': 0.6916599869728088, 'validation/loss': 1.4663927555084229, 'validation/num_examples': 50000, 'test/accuracy': 0.5592000484466553, 'test/loss': 2.105501174926758, 'test/num_examples': 10000, 'score': 33220.40139245987, 'total_duration': 34592.27876710892, 'accumulated_submission_time': 33220.40139245987, 'accumulated_eval_time': 1368.1152873039246, 'accumulated_logging_time': 2.356036424636841, 'global_step': 98612, 'preemption_count': 0}), (100130, {'train/accuracy': 0.7604432106018066, 'train/loss': 1.180131196975708, 'validation/accuracy': 0.6843000054359436, 'validation/loss': 1.512358546257019, 'validation/num_examples': 50000, 'test/accuracy': 0.5595000386238098, 'test/loss': 2.161224365234375, 'test/num_examples': 10000, 'score': 33730.62457942963, 'total_duration': 35123.01833987236, 'accumulated_submission_time': 33730.62457942963, 'accumulated_eval_time': 1388.5735955238342, 'accumulated_logging_time': 2.3942630290985107, 'global_step': 100130, 'preemption_count': 0}), (101647, {'train/accuracy': 0.7696707248687744, 'train/loss': 1.1325535774230957, 'validation/accuracy': 0.6917200088500977, 'validation/loss': 1.4804883003234863, 'validation/num_examples': 50000, 'test/accuracy': 0.5688000321388245, 'test/loss': 2.1134915351867676, 'test/num_examples': 10000, 'score': 34240.61685299873, 'total_duration': 35653.61151719093, 'accumulated_submission_time': 34240.61685299873, 'accumulated_eval_time': 1409.118991613388, 'accumulated_logging_time': 2.4296483993530273, 'global_step': 101647, 'preemption_count': 0}), (103164, {'train/accuracy': 0.7825454473495483, 'train/loss': 1.070412278175354, 'validation/accuracy': 0.705839991569519, 'validation/loss': 1.4002232551574707, 'validation/num_examples': 50000, 'test/accuracy': 0.5758000016212463, 'test/loss': 2.0226001739501953, 'test/num_examples': 10000, 'score': 34750.670857191086, 'total_duration': 36184.23157286644, 'accumulated_submission_time': 34750.670857191086, 'accumulated_eval_time': 1429.626859664917, 'accumulated_logging_time': 2.467414379119873, 'global_step': 103164, 'preemption_count': 0}), (104681, {'train/accuracy': 0.7799545526504517, 'train/loss': 1.0913686752319336, 'validation/accuracy': 0.7016800045967102, 'validation/loss': 1.423983097076416, 'validation/num_examples': 50000, 'test/accuracy': 0.5788000226020813, 'test/loss': 2.0614922046661377, 'test/num_examples': 10000, 'score': 35260.77351951599, 'total_duration': 36714.93715381622, 'accumulated_submission_time': 35260.77351951599, 'accumulated_eval_time': 1450.1713275909424, 'accumulated_logging_time': 2.5057055950164795, 'global_step': 104681, 'preemption_count': 0}), (106198, {'train/accuracy': 0.8139548897743225, 'train/loss': 0.962578296661377, 'validation/accuracy': 0.7041999697685242, 'validation/loss': 1.4052836894989014, 'validation/num_examples': 50000, 'test/accuracy': 0.581000030040741, 'test/loss': 2.0259625911712646, 'test/num_examples': 10000, 'score': 35770.8518717289, 'total_duration': 37246.04178881645, 'accumulated_submission_time': 35770.8518717289, 'accumulated_eval_time': 1471.1403260231018, 'accumulated_logging_time': 2.54270339012146, 'global_step': 106198, 'preemption_count': 0}), (107716, {'train/accuracy': 0.8071388602256775, 'train/loss': 1.004296064376831, 'validation/accuracy': 0.7107200026512146, 'validation/loss': 1.4042963981628418, 'validation/num_examples': 50000, 'test/accuracy': 0.5868000388145447, 'test/loss': 2.0278871059417725, 'test/num_examples': 10000, 'score': 36280.99781918526, 'total_duration': 37776.7526242733, 'accumulated_submission_time': 36280.99781918526, 'accumulated_eval_time': 1491.6528244018555, 'accumulated_logging_time': 2.574843645095825, 'global_step': 107716, 'preemption_count': 0}), (109233, {'train/accuracy': 0.8026546239852905, 'train/loss': 0.9770081639289856, 'validation/accuracy': 0.7093999981880188, 'validation/loss': 1.359559178352356, 'validation/num_examples': 50000, 'test/accuracy': 0.5829000473022461, 'test/loss': 2.013956069946289, 'test/num_examples': 10000, 'score': 36791.056072473526, 'total_duration': 38307.37937450409, 'accumulated_submission_time': 36791.056072473526, 'accumulated_eval_time': 1512.1645052433014, 'accumulated_logging_time': 2.6113500595092773, 'global_step': 109233, 'preemption_count': 0}), (110750, {'train/accuracy': 0.8110650181770325, 'train/loss': 0.9361371994018555, 'validation/accuracy': 0.7163400053977966, 'validation/loss': 1.322260856628418, 'validation/num_examples': 50000, 'test/accuracy': 0.5926000475883484, 'test/loss': 1.94412100315094, 'test/num_examples': 10000, 'score': 37301.11421895027, 'total_duration': 38838.09396600723, 'accumulated_submission_time': 37301.11421895027, 'accumulated_eval_time': 1532.7646689414978, 'accumulated_logging_time': 2.6472840309143066, 'global_step': 110750, 'preemption_count': 0}), (112267, {'train/accuracy': 0.8099489808082581, 'train/loss': 0.955118715763092, 'validation/accuracy': 0.7160800099372864, 'validation/loss': 1.3434462547302246, 'validation/num_examples': 50000, 'test/accuracy': 0.5981000065803528, 'test/loss': 1.9447907209396362, 'test/num_examples': 10000, 'score': 37811.13156104088, 'total_duration': 39368.75576210022, 'accumulated_submission_time': 37811.13156104088, 'accumulated_eval_time': 1553.3528666496277, 'accumulated_logging_time': 2.6835885047912598, 'global_step': 112267, 'preemption_count': 0}), (113784, {'train/accuracy': 0.8325294852256775, 'train/loss': 0.8838786482810974, 'validation/accuracy': 0.7283599972724915, 'validation/loss': 1.313471794128418, 'validation/num_examples': 50000, 'test/accuracy': 0.6026000380516052, 'test/loss': 1.9423364400863647, 'test/num_examples': 10000, 'score': 38321.11910676956, 'total_duration': 39899.29828763008, 'accumulated_submission_time': 38321.11910676956, 'accumulated_eval_time': 1573.850713968277, 'accumulated_logging_time': 2.720670700073242, 'global_step': 113784, 'preemption_count': 0}), (115301, {'train/accuracy': 0.8475167155265808, 'train/loss': 0.8132196664810181, 'validation/accuracy': 0.730239987373352, 'validation/loss': 1.288041353225708, 'validation/num_examples': 50000, 'test/accuracy': 0.6048000454902649, 'test/loss': 1.9094524383544922, 'test/num_examples': 10000, 'score': 38831.091960668564, 'total_duration': 40429.83276319504, 'accumulated_submission_time': 38831.091960668564, 'accumulated_eval_time': 1594.3540887832642, 'accumulated_logging_time': 2.7583861351013184, 'global_step': 115301, 'preemption_count': 0}), (116818, {'train/accuracy': 0.83793044090271, 'train/loss': 0.867727518081665, 'validation/accuracy': 0.7301599979400635, 'validation/loss': 1.3111166954040527, 'validation/num_examples': 50000, 'test/accuracy': 0.6048000454902649, 'test/loss': 1.946718692779541, 'test/num_examples': 10000, 'score': 39341.047543525696, 'total_duration': 40960.53256702423, 'accumulated_submission_time': 39341.047543525696, 'accumulated_eval_time': 1615.0388205051422, 'accumulated_logging_time': 2.7972633838653564, 'global_step': 116818, 'preemption_count': 0}), (118335, {'train/accuracy': 0.8512834906578064, 'train/loss': 0.8133650422096252, 'validation/accuracy': 0.7404599785804749, 'validation/loss': 1.2683063745498657, 'validation/num_examples': 50000, 'test/accuracy': 0.6169000267982483, 'test/loss': 1.8760502338409424, 'test/num_examples': 10000, 'score': 39851.058109760284, 'total_duration': 41491.060791015625, 'accumulated_submission_time': 39851.058109760284, 'accumulated_eval_time': 1635.4967844486237, 'accumulated_logging_time': 2.836625337600708, 'global_step': 118335, 'preemption_count': 0}), (119853, {'train/accuracy': 0.8532565236091614, 'train/loss': 0.7885985970497131, 'validation/accuracy': 0.7427200078964233, 'validation/loss': 1.2393643856048584, 'validation/num_examples': 50000, 'test/accuracy': 0.6176000237464905, 'test/loss': 1.8440178632736206, 'test/num_examples': 10000, 'score': 40361.158826589584, 'total_duration': 42021.631635427475, 'accumulated_submission_time': 40361.158826589584, 'accumulated_eval_time': 1655.9078681468964, 'accumulated_logging_time': 2.875187635421753, 'global_step': 119853, 'preemption_count': 0}), (121371, {'train/accuracy': 0.8619858026504517, 'train/loss': 0.7477796077728271, 'validation/accuracy': 0.750059962272644, 'validation/loss': 1.2026126384735107, 'validation/num_examples': 50000, 'test/accuracy': 0.6231000423431396, 'test/loss': 1.8168764114379883, 'test/num_examples': 10000, 'score': 40871.40272784233, 'total_duration': 42552.41125202179, 'accumulated_submission_time': 40871.40272784233, 'accumulated_eval_time': 1676.3817439079285, 'accumulated_logging_time': 2.9170479774475098, 'global_step': 121371, 'preemption_count': 0}), (122888, {'train/accuracy': 0.8946906924247742, 'train/loss': 0.6371654272079468, 'validation/accuracy': 0.7576000094413757, 'validation/loss': 1.182360291481018, 'validation/num_examples': 50000, 'test/accuracy': 0.6347000598907471, 'test/loss': 1.7741376161575317, 'test/num_examples': 10000, 'score': 41381.57604265213, 'total_duration': 43083.18188738823, 'accumulated_submission_time': 41381.57604265213, 'accumulated_eval_time': 1696.9200265407562, 'accumulated_logging_time': 2.955721616744995, 'global_step': 122888, 'preemption_count': 0}), (124405, {'train/accuracy': 0.8950892686843872, 'train/loss': 0.6363955140113831, 'validation/accuracy': 0.76419997215271, 'validation/loss': 1.1598738431930542, 'validation/num_examples': 50000, 'test/accuracy': 0.6403000354766846, 'test/loss': 1.7538734674453735, 'test/num_examples': 10000, 'score': 41891.6149725914, 'total_duration': 43613.78872227669, 'accumulated_submission_time': 41891.6149725914, 'accumulated_eval_time': 1717.4267044067383, 'accumulated_logging_time': 2.996537923812866, 'global_step': 124405, 'preemption_count': 0}), (125922, {'train/accuracy': 0.9030811190605164, 'train/loss': 0.5979558229446411, 'validation/accuracy': 0.7681799530982971, 'validation/loss': 1.1289294958114624, 'validation/num_examples': 50000, 'test/accuracy': 0.6470000147819519, 'test/loss': 1.7141063213348389, 'test/num_examples': 10000, 'score': 42401.72726345062, 'total_duration': 44144.47311043739, 'accumulated_submission_time': 42401.72726345062, 'accumulated_eval_time': 1737.9356472492218, 'accumulated_logging_time': 3.039466142654419, 'global_step': 125922, 'preemption_count': 0}), (127439, {'train/accuracy': 0.9046157598495483, 'train/loss': 0.598039984703064, 'validation/accuracy': 0.7721199989318848, 'validation/loss': 1.123956322669983, 'validation/num_examples': 50000, 'test/accuracy': 0.6500000357627869, 'test/loss': 1.7073290348052979, 'test/num_examples': 10000, 'score': 42911.6735765934, 'total_duration': 44674.97602677345, 'accumulated_submission_time': 42911.6735765934, 'accumulated_eval_time': 1758.4175555706024, 'accumulated_logging_time': 3.093670129776001, 'global_step': 127439, 'preemption_count': 0}), (128956, {'train/accuracy': 0.9033800959587097, 'train/loss': 0.6007381677627563, 'validation/accuracy': 0.7731599807739258, 'validation/loss': 1.1220510005950928, 'validation/num_examples': 50000, 'test/accuracy': 0.6511000394821167, 'test/loss': 1.70318603515625, 'test/num_examples': 10000, 'score': 43421.815564394, 'total_duration': 45205.706189870834, 'accumulated_submission_time': 43421.815564394, 'accumulated_eval_time': 1778.942519903183, 'accumulated_logging_time': 3.136686086654663, 'global_step': 128956, 'preemption_count': 0}), (130473, {'train/accuracy': 0.9044563174247742, 'train/loss': 0.5953980684280396, 'validation/accuracy': 0.7731199860572815, 'validation/loss': 1.1207743883132935, 'validation/num_examples': 50000, 'test/accuracy': 0.6499000191688538, 'test/loss': 1.7032558917999268, 'test/num_examples': 10000, 'score': 43931.84219288826, 'total_duration': 45736.23483633995, 'accumulated_submission_time': 43931.84219288826, 'accumulated_eval_time': 1799.3856046199799, 'accumulated_logging_time': 3.175229787826538, 'global_step': 130473, 'preemption_count': 0}), (131990, {'train/accuracy': 0.9046157598495483, 'train/loss': 0.5978898406028748, 'validation/accuracy': 0.7736200094223022, 'validation/loss': 1.1203153133392334, 'validation/num_examples': 50000, 'test/accuracy': 0.6521000266075134, 'test/loss': 1.7020705938339233, 'test/num_examples': 10000, 'score': 44441.87713241577, 'total_duration': 46266.766699790955, 'accumulated_submission_time': 44441.87713241577, 'accumulated_eval_time': 1819.8144969940186, 'accumulated_logging_time': 3.2233197689056396, 'global_step': 131990, 'preemption_count': 0}), (133508, {'train/accuracy': 0.9060905575752258, 'train/loss': 0.5886658430099487, 'validation/accuracy': 0.7738400101661682, 'validation/loss': 1.1211588382720947, 'validation/num_examples': 50000, 'test/accuracy': 0.6526000499725342, 'test/loss': 1.703035593032837, 'test/num_examples': 10000, 'score': 44952.06863164902, 'total_duration': 46797.41291928291, 'accumulated_submission_time': 44952.06863164902, 'accumulated_eval_time': 1840.2095685005188, 'accumulated_logging_time': 3.2629220485687256, 'global_step': 133508, 'preemption_count': 0}), (135025, {'train/accuracy': 0.9071667790412903, 'train/loss': 0.5921725034713745, 'validation/accuracy': 0.7730599641799927, 'validation/loss': 1.123219609260559, 'validation/num_examples': 50000, 'test/accuracy': 0.6525000333786011, 'test/loss': 1.7038555145263672, 'test/num_examples': 10000, 'score': 45462.0313372612, 'total_duration': 47327.85843586922, 'accumulated_submission_time': 45462.0313372612, 'accumulated_eval_time': 1860.6294927597046, 'accumulated_logging_time': 3.3053972721099854, 'global_step': 135025, 'preemption_count': 0}), (136543, {'train/accuracy': 0.9085020422935486, 'train/loss': 0.5905719995498657, 'validation/accuracy': 0.7737399935722351, 'validation/loss': 1.1226686239242554, 'validation/num_examples': 50000, 'test/accuracy': 0.6511000394821167, 'test/loss': 1.7019078731536865, 'test/num_examples': 10000, 'score': 45972.291091918945, 'total_duration': 47858.53156018257, 'accumulated_submission_time': 45972.291091918945, 'accumulated_eval_time': 1880.9839470386505, 'accumulated_logging_time': 3.3439760208129883, 'global_step': 136543, 'preemption_count': 0}), (138060, {'train/accuracy': 0.9065290093421936, 'train/loss': 0.5865035057067871, 'validation/accuracy': 0.7734400033950806, 'validation/loss': 1.1186720132827759, 'validation/num_examples': 50000, 'test/accuracy': 0.6523000597953796, 'test/loss': 1.7003748416900635, 'test/num_examples': 10000, 'score': 46482.3462703228, 'total_duration': 48389.021898031235, 'accumulated_submission_time': 46482.3462703228, 'accumulated_eval_time': 1901.362600326538, 'accumulated_logging_time': 3.3802568912506104, 'global_step': 138060, 'preemption_count': 0}), (139577, {'train/accuracy': 0.9042769074440002, 'train/loss': 0.5936236381530762, 'validation/accuracy': 0.7740199565887451, 'validation/loss': 1.120292067527771, 'validation/num_examples': 50000, 'test/accuracy': 0.652400016784668, 'test/loss': 1.701324701309204, 'test/num_examples': 10000, 'score': 46992.43078827858, 'total_duration': 48919.440913677216, 'accumulated_submission_time': 46992.43078827858, 'accumulated_eval_time': 1921.636647939682, 'accumulated_logging_time': 3.4203310012817383, 'global_step': 139577, 'preemption_count': 0}), (140000, {'train/accuracy': 0.9085817933082581, 'train/loss': 0.5802215337753296, 'validation/accuracy': 0.7741400003433228, 'validation/loss': 1.1203563213348389, 'validation/num_examples': 50000, 'test/accuracy': 0.6518000364303589, 'test/loss': 1.7017462253570557, 'test/num_examples': 10000, 'score': 47134.46629500389, 'total_duration': 49081.88216590881, 'accumulated_submission_time': 47134.46629500389, 'accumulated_eval_time': 1941.995854139328, 'accumulated_logging_time': 3.460902214050293, 'global_step': 140000, 'preemption_count': 0})], 'global_step': 140000}
I0919 11:35:21.223894 140245097760576 submission_runner.py:543] Timing: 47134.46629500389
I0919 11:35:21.223966 140245097760576 submission_runner.py:545] Total number of evals: 94
I0919 11:35:21.224011 140245097760576 submission_runner.py:546] ====================
I0919 11:35:21.224299 140245097760576 submission_runner.py:614] Final imagenet_resnet score: 47134.46629500389
