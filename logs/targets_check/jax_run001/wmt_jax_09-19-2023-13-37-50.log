python3 submission_runner.py --framework=jax --workload=wmt --submission_path=reference_algorithms/target_setting_algorithms/jax_nadamw.py --tuning_search_space=reference_algorithms/target_setting_algorithms/wmt/tuning_search_space.json --data_dir=/data/wmt --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=targets_check_jax_run_01/nadamw_run_0 --overwrite=true --save_checkpoints=false --max_global_steps=100000 2>&1 | tee -a /logs/wmt_jax_09-19-2023-13-37-50.log
2023-09-19 13:37:55.130119: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0919 13:38:14.596660 139893447890752 logger_utils.py:76] Creating experiment directory at /experiment_runs/targets_check_jax_run_01/nadamw_run_0/wmt_jax.
I0919 13:38:15.738289 139893447890752 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter Host CUDA
I0919 13:38:15.739023 139893447890752 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0919 13:38:15.739168 139893447890752 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0919 13:38:15.745311 139893447890752 submission_runner.py:500] Using RNG seed 3365234507
I0919 13:38:22.030560 139893447890752 submission_runner.py:509] --- Tuning run 1/1 ---
I0919 13:38:22.030793 139893447890752 submission_runner.py:514] Creating tuning directory at /experiment_runs/targets_check_jax_run_01/nadamw_run_0/wmt_jax/trial_1.
I0919 13:38:22.030980 139893447890752 logger_utils.py:92] Saving hparams to /experiment_runs/targets_check_jax_run_01/nadamw_run_0/wmt_jax/trial_1/hparams.json.
I0919 13:38:22.215804 139893447890752 submission_runner.py:185] Initializing dataset.
I0919 13:38:22.243894 139893447890752 dataset_info.py:578] Load dataset info from /data/wmt/wmt17_translate/de-en/1.0.0
I0919 13:38:22.251133 139893447890752 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0919 13:38:22.427392 139893447890752 logging_logger.py:49] Constructing tf.data.Dataset wmt17_translate for split train, from /data/wmt/wmt17_translate/de-en/1.0.0
I0919 13:38:24.458830 139893447890752 submission_runner.py:192] Initializing model.
I0919 13:38:33.444377 139893447890752 submission_runner.py:226] Initializing optimizer.
I0919 13:38:34.480347 139893447890752 submission_runner.py:233] Initializing metrics bundle.
I0919 13:38:34.480549 139893447890752 submission_runner.py:251] Initializing checkpoint and logger.
I0919 13:38:34.481715 139893447890752 checkpoints.py:915] Found no checkpoint files in /experiment_runs/targets_check_jax_run_01/nadamw_run_0/wmt_jax/trial_1 with prefix checkpoint_
I0919 13:38:34.482028 139893447890752 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0919 13:38:34.482113 139893447890752 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
I0919 13:38:35.412295 139893447890752 submission_runner.py:272] Saving meta data to /experiment_runs/targets_check_jax_run_01/nadamw_run_0/wmt_jax/trial_1/meta_data_0.json.
I0919 13:38:35.413289 139893447890752 submission_runner.py:275] Saving flags to /experiment_runs/targets_check_jax_run_01/nadamw_run_0/wmt_jax/trial_1/flags_0.json.
I0919 13:38:35.423189 139893447890752 submission_runner.py:285] Starting training loop.
I0919 13:39:20.896788 139729068615424 logging_writer.py:48] [0] global_step=0, grad_norm=4.832695484161377, loss=11.010526657104492
I0919 13:39:20.913344 139893447890752 spec.py:320] Evaluating on the training split.
I0919 13:39:20.916695 139893447890752 dataset_info.py:578] Load dataset info from /data/wmt/wmt17_translate/de-en/1.0.0
I0919 13:39:20.919538 139893447890752 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0919 13:39:20.956542 139893447890752 logging_logger.py:49] Constructing tf.data.Dataset wmt17_translate for split train, from /data/wmt/wmt17_translate/de-en/1.0.0
I0919 13:39:28.620568 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 13:44:13.363239 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 13:44:13.368162 139893447890752 dataset_info.py:578] Load dataset info from /data/wmt/wmt14_translate/de-en/1.0.0
I0919 13:44:13.371790 139893447890752 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0919 13:44:13.409096 139893447890752 logging_logger.py:49] Constructing tf.data.Dataset wmt14_translate for split validation, from /data/wmt/wmt14_translate/de-en/1.0.0
I0919 13:44:20.804235 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 13:48:58.973952 139893447890752 spec.py:348] Evaluating on the test split.
I0919 13:48:58.976693 139893447890752 dataset_info.py:578] Load dataset info from /data/wmt/wmt14_translate/de-en/1.0.0
I0919 13:48:58.979587 139893447890752 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0919 13:48:59.014970 139893447890752 logging_logger.py:49] Constructing tf.data.Dataset wmt14_translate for split test, from /data/wmt/wmt14_translate/de-en/1.0.0
I0919 13:49:05.958207 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 13:53:40.558714 139893447890752 submission_runner.py:376] Time since start: 905.14s, 	Step: 1, 	{'train/accuracy': 0.0005717618041671813, 'train/loss': 11.013775825500488, 'train/bleu': 0.0, 'validation/accuracy': 0.0004835649742744863, 'validation/loss': 11.0232572555542, 'validation/bleu': 0.0, 'validation/num_examples': 3000, 'test/accuracy': 0.0007088489946909249, 'test/loss': 11.036556243896484, 'test/bleu': 0.0, 'test/num_examples': 3003, 'score': 45.49011206626892, 'total_duration': 905.1354348659515, 'accumulated_submission_time': 45.49011206626892, 'accumulated_eval_time': 859.6452877521515, 'accumulated_logging_time': 0}
I0919 13:53:40.580221 139716895373056 logging_writer.py:48] [1] accumulated_eval_time=859.645288, accumulated_logging_time=0, accumulated_submission_time=45.490112, global_step=1, preemption_count=0, score=45.490112, test/accuracy=0.000709, test/bleu=0.000000, test/loss=11.036556, test/num_examples=3003, total_duration=905.135435, train/accuracy=0.000572, train/bleu=0.000000, train/loss=11.013776, validation/accuracy=0.000484, validation/bleu=0.000000, validation/loss=11.023257, validation/num_examples=3000
I0919 13:53:40.955426 139716903765760 logging_writer.py:48] [1] global_step=1, grad_norm=4.829944133758545, loss=11.022071838378906
I0919 13:53:41.330993 139716895373056 logging_writer.py:48] [2] global_step=2, grad_norm=4.809591293334961, loss=10.98670482635498
I0919 13:53:41.702316 139716903765760 logging_writer.py:48] [3] global_step=3, grad_norm=4.6522088050842285, loss=10.939329147338867
I0919 13:53:42.075191 139716895373056 logging_writer.py:48] [4] global_step=4, grad_norm=4.531066417694092, loss=10.86326789855957
I0919 13:53:42.446950 139716903765760 logging_writer.py:48] [5] global_step=5, grad_norm=4.352598667144775, loss=10.770099639892578
I0919 13:53:42.818982 139716895373056 logging_writer.py:48] [6] global_step=6, grad_norm=4.127171993255615, loss=10.671277046203613
I0919 13:53:43.191768 139716903765760 logging_writer.py:48] [7] global_step=7, grad_norm=3.898465871810913, loss=10.559915542602539
I0919 13:53:43.563981 139716895373056 logging_writer.py:48] [8] global_step=8, grad_norm=3.6203510761260986, loss=10.440267562866211
I0919 13:53:43.939327 139716903765760 logging_writer.py:48] [9] global_step=9, grad_norm=3.292616844177246, loss=10.32646656036377
I0919 13:53:44.313155 139716895373056 logging_writer.py:48] [10] global_step=10, grad_norm=2.98042631149292, loss=10.209486961364746
I0919 13:53:44.686238 139716903765760 logging_writer.py:48] [11] global_step=11, grad_norm=2.6871535778045654, loss=10.09712028503418
I0919 13:53:45.057769 139716895373056 logging_writer.py:48] [12] global_step=12, grad_norm=2.462153673171997, loss=9.977521896362305
I0919 13:53:45.430416 139716903765760 logging_writer.py:48] [13] global_step=13, grad_norm=2.2522647380828857, loss=9.85621452331543
I0919 13:53:45.801062 139716895373056 logging_writer.py:48] [14] global_step=14, grad_norm=2.0125346183776855, loss=9.775575637817383
I0919 13:53:46.172886 139716903765760 logging_writer.py:48] [15] global_step=15, grad_norm=1.8177847862243652, loss=9.677225112915039
I0919 13:53:46.543387 139716895373056 logging_writer.py:48] [16] global_step=16, grad_norm=1.6784682273864746, loss=9.58297061920166
I0919 13:53:46.916154 139716903765760 logging_writer.py:48] [17] global_step=17, grad_norm=1.5118120908737183, loss=9.516984939575195
I0919 13:53:47.288759 139716895373056 logging_writer.py:48] [18] global_step=18, grad_norm=1.404412031173706, loss=9.429512023925781
I0919 13:53:47.660869 139716903765760 logging_writer.py:48] [19] global_step=19, grad_norm=1.276042103767395, loss=9.383689880371094
I0919 13:53:48.033943 139716895373056 logging_writer.py:48] [20] global_step=20, grad_norm=1.1827614307403564, loss=9.3052339553833
I0919 13:53:48.405864 139716903765760 logging_writer.py:48] [21] global_step=21, grad_norm=1.0856044292449951, loss=9.213098526000977
I0919 13:53:48.782320 139716895373056 logging_writer.py:48] [22] global_step=22, grad_norm=0.9924231171607971, loss=9.170923233032227
I0919 13:53:49.153092 139716903765760 logging_writer.py:48] [23] global_step=23, grad_norm=0.9058732390403748, loss=9.142476081848145
I0919 13:53:49.525092 139716895373056 logging_writer.py:48] [24] global_step=24, grad_norm=0.8935673832893372, loss=9.037959098815918
I0919 13:53:49.899483 139716903765760 logging_writer.py:48] [25] global_step=25, grad_norm=0.7967426776885986, loss=9.03270149230957
I0919 13:53:50.274125 139716895373056 logging_writer.py:48] [26] global_step=26, grad_norm=0.7387446165084839, loss=8.98028564453125
I0919 13:53:50.648330 139716903765760 logging_writer.py:48] [27] global_step=27, grad_norm=0.6997236013412476, loss=8.96644115447998
I0919 13:53:51.019725 139716895373056 logging_writer.py:48] [28] global_step=28, grad_norm=0.6582096219062805, loss=8.936174392700195
I0919 13:53:51.391281 139716903765760 logging_writer.py:48] [29] global_step=29, grad_norm=0.6035207509994507, loss=8.869569778442383
I0919 13:53:51.762986 139716895373056 logging_writer.py:48] [30] global_step=30, grad_norm=0.5698084831237793, loss=8.817306518554688
I0919 13:53:52.134944 139716903765760 logging_writer.py:48] [31] global_step=31, grad_norm=0.5234701633453369, loss=8.80659294128418
I0919 13:53:52.507876 139716895373056 logging_writer.py:48] [32] global_step=32, grad_norm=0.495223730802536, loss=8.757509231567383
I0919 13:53:52.877106 139716903765760 logging_writer.py:48] [33] global_step=33, grad_norm=0.4573572874069214, loss=8.769536018371582
I0919 13:53:53.248288 139716895373056 logging_writer.py:48] [34] global_step=34, grad_norm=0.43360018730163574, loss=8.748031616210938
I0919 13:53:53.618349 139716903765760 logging_writer.py:48] [35] global_step=35, grad_norm=0.39921364188194275, loss=8.729448318481445
I0919 13:53:53.991416 139716895373056 logging_writer.py:48] [36] global_step=36, grad_norm=0.38012638688087463, loss=8.718056678771973
I0919 13:53:54.362008 139716903765760 logging_writer.py:48] [37] global_step=37, grad_norm=0.37450963258743286, loss=8.663930892944336
I0919 13:53:54.734719 139716895373056 logging_writer.py:48] [38] global_step=38, grad_norm=0.33793729543685913, loss=8.672853469848633
I0919 13:53:55.105818 139716903765760 logging_writer.py:48] [39] global_step=39, grad_norm=0.32449400424957275, loss=8.6764497756958
I0919 13:53:55.478490 139716895373056 logging_writer.py:48] [40] global_step=40, grad_norm=0.3053264915943146, loss=8.645401954650879
I0919 13:53:55.853265 139716903765760 logging_writer.py:48] [41] global_step=41, grad_norm=0.28595101833343506, loss=8.633733749389648
I0919 13:53:56.225254 139716895373056 logging_writer.py:48] [42] global_step=42, grad_norm=0.2682954668998718, loss=8.628908157348633
I0919 13:53:56.598844 139716903765760 logging_writer.py:48] [43] global_step=43, grad_norm=0.2714236378669739, loss=8.557352066040039
I0919 13:53:56.971330 139716895373056 logging_writer.py:48] [44] global_step=44, grad_norm=0.24911247193813324, loss=8.552152633666992
I0919 13:53:57.341556 139716903765760 logging_writer.py:48] [45] global_step=45, grad_norm=0.25452423095703125, loss=8.572823524475098
I0919 13:53:57.711742 139716895373056 logging_writer.py:48] [46] global_step=46, grad_norm=0.2246660590171814, loss=8.523086547851562
I0919 13:53:58.083400 139716903765760 logging_writer.py:48] [47] global_step=47, grad_norm=0.2290293276309967, loss=8.553152084350586
I0919 13:53:58.457545 139716895373056 logging_writer.py:48] [48] global_step=48, grad_norm=0.20878368616104126, loss=8.540547370910645
I0919 13:53:58.829524 139716903765760 logging_writer.py:48] [49] global_step=49, grad_norm=0.21084466576576233, loss=8.503317832946777
I0919 13:53:59.201246 139716895373056 logging_writer.py:48] [50] global_step=50, grad_norm=0.19826416671276093, loss=8.491518020629883
I0919 13:53:59.570785 139716903765760 logging_writer.py:48] [51] global_step=51, grad_norm=0.19715747237205505, loss=8.510637283325195
I0919 13:53:59.941752 139716895373056 logging_writer.py:48] [52] global_step=52, grad_norm=0.18083062767982483, loss=8.49329662322998
I0919 13:54:00.311993 139716903765760 logging_writer.py:48] [53] global_step=53, grad_norm=0.1951872706413269, loss=8.509987831115723
I0919 13:54:00.682049 139716895373056 logging_writer.py:48] [54] global_step=54, grad_norm=0.17684981226921082, loss=8.506264686584473
I0919 13:54:01.050583 139716903765760 logging_writer.py:48] [55] global_step=55, grad_norm=0.17768509685993195, loss=8.532796859741211
I0919 13:54:01.423183 139716895373056 logging_writer.py:48] [56] global_step=56, grad_norm=0.1743510216474533, loss=8.495979309082031
I0919 13:54:01.794410 139716903765760 logging_writer.py:48] [57] global_step=57, grad_norm=0.17252498865127563, loss=8.471809387207031
I0919 13:54:02.166743 139716895373056 logging_writer.py:48] [58] global_step=58, grad_norm=0.17190055549144745, loss=8.498480796813965
I0919 13:54:02.538027 139716903765760 logging_writer.py:48] [59] global_step=59, grad_norm=0.1863388866186142, loss=8.438926696777344
I0919 13:54:02.913139 139716895373056 logging_writer.py:48] [60] global_step=60, grad_norm=0.17203113436698914, loss=8.455737113952637
I0919 13:54:03.284929 139716903765760 logging_writer.py:48] [61] global_step=61, grad_norm=0.17178946733474731, loss=8.465336799621582
I0919 13:54:03.658263 139716895373056 logging_writer.py:48] [62] global_step=62, grad_norm=0.16901205480098724, loss=8.459539413452148
I0919 13:54:04.031090 139716903765760 logging_writer.py:48] [63] global_step=63, grad_norm=0.17059502005577087, loss=8.424274444580078
I0919 13:54:04.404711 139716895373056 logging_writer.py:48] [64] global_step=64, grad_norm=0.16625216603279114, loss=8.49231243133545
I0919 13:54:04.777496 139716903765760 logging_writer.py:48] [65] global_step=65, grad_norm=0.16921697556972504, loss=8.43645191192627
I0919 13:54:05.152542 139716895373056 logging_writer.py:48] [66] global_step=66, grad_norm=0.16971011459827423, loss=8.396842002868652
I0919 13:54:05.526090 139716903765760 logging_writer.py:48] [67] global_step=67, grad_norm=0.16279540956020355, loss=8.400856018066406
I0919 13:54:05.899263 139716895373056 logging_writer.py:48] [68] global_step=68, grad_norm=0.16768598556518555, loss=8.39405345916748
I0919 13:54:06.272673 139716903765760 logging_writer.py:48] [69] global_step=69, grad_norm=0.16323554515838623, loss=8.388762474060059
I0919 13:54:06.645948 139716895373056 logging_writer.py:48] [70] global_step=70, grad_norm=0.17121745645999908, loss=8.36768913269043
I0919 13:54:07.019769 139716903765760 logging_writer.py:48] [71] global_step=71, grad_norm=0.16058899462223053, loss=8.402409553527832
I0919 13:54:07.393745 139716895373056 logging_writer.py:48] [72] global_step=72, grad_norm=0.1656084656715393, loss=8.384739875793457
I0919 13:54:07.767364 139716903765760 logging_writer.py:48] [73] global_step=73, grad_norm=0.1596975475549698, loss=8.325275421142578
I0919 13:54:08.141405 139716895373056 logging_writer.py:48] [74] global_step=74, grad_norm=0.1618024706840515, loss=8.362518310546875
I0919 13:54:08.512004 139716903765760 logging_writer.py:48] [75] global_step=75, grad_norm=0.16924269497394562, loss=8.3391695022583
I0919 13:54:08.883373 139716895373056 logging_writer.py:48] [76] global_step=76, grad_norm=0.15580931305885315, loss=8.315329551696777
I0919 13:54:09.253214 139716903765760 logging_writer.py:48] [77] global_step=77, grad_norm=0.1594509333372116, loss=8.310619354248047
I0919 13:54:09.625195 139716895373056 logging_writer.py:48] [78] global_step=78, grad_norm=0.1526498794555664, loss=8.316283226013184
I0919 13:54:09.997687 139716903765760 logging_writer.py:48] [79] global_step=79, grad_norm=0.15931202471256256, loss=8.301329612731934
I0919 13:54:10.371421 139716895373056 logging_writer.py:48] [80] global_step=80, grad_norm=0.1507052332162857, loss=8.347702026367188
I0919 13:54:10.744681 139716903765760 logging_writer.py:48] [81] global_step=81, grad_norm=0.14424251019954681, loss=8.31180477142334
I0919 13:54:11.120230 139716895373056 logging_writer.py:48] [82] global_step=82, grad_norm=0.15405084192752838, loss=8.276998519897461
I0919 13:54:11.494253 139716903765760 logging_writer.py:48] [83] global_step=83, grad_norm=0.1589694619178772, loss=8.274739265441895
I0919 13:54:11.868819 139716895373056 logging_writer.py:48] [84] global_step=84, grad_norm=0.16574904322624207, loss=8.323301315307617
I0919 13:54:12.240729 139716903765760 logging_writer.py:48] [85] global_step=85, grad_norm=0.1540730595588684, loss=8.287134170532227
I0919 13:54:12.611640 139716895373056 logging_writer.py:48] [86] global_step=86, grad_norm=0.1663649082183838, loss=8.240574836730957
I0919 13:54:12.981997 139716903765760 logging_writer.py:48] [87] global_step=87, grad_norm=0.16204212605953217, loss=8.238828659057617
I0919 13:54:13.354530 139716895373056 logging_writer.py:48] [88] global_step=88, grad_norm=0.15835103392601013, loss=8.227150917053223
I0919 13:54:13.727117 139716903765760 logging_writer.py:48] [89] global_step=89, grad_norm=0.16923058032989502, loss=8.230534553527832
I0919 13:54:14.099861 139716895373056 logging_writer.py:48] [90] global_step=90, grad_norm=0.17010492086410522, loss=8.25466537475586
I0919 13:54:14.471084 139716903765760 logging_writer.py:48] [91] global_step=91, grad_norm=0.20242713391780853, loss=8.246634483337402
I0919 13:54:14.845027 139716895373056 logging_writer.py:48] [92] global_step=92, grad_norm=0.1585649698972702, loss=8.21975326538086
I0919 13:54:15.216662 139716903765760 logging_writer.py:48] [93] global_step=93, grad_norm=0.18139374256134033, loss=8.226872444152832
I0919 13:54:15.589559 139716895373056 logging_writer.py:48] [94] global_step=94, grad_norm=0.16012997925281525, loss=8.227466583251953
I0919 13:54:15.960200 139716903765760 logging_writer.py:48] [95] global_step=95, grad_norm=0.15826699137687683, loss=8.20461654663086
I0919 13:54:16.333950 139716895373056 logging_writer.py:48] [96] global_step=96, grad_norm=0.15918274223804474, loss=8.165860176086426
I0919 13:54:16.705157 139716903765760 logging_writer.py:48] [97] global_step=97, grad_norm=0.14917106926441193, loss=8.199243545532227
I0919 13:54:17.079242 139716895373056 logging_writer.py:48] [98] global_step=98, grad_norm=0.19103127717971802, loss=8.201574325561523
I0919 13:54:17.453196 139716903765760 logging_writer.py:48] [99] global_step=99, grad_norm=0.17152059078216553, loss=8.208992004394531
I0919 13:54:17.826241 139716895373056 logging_writer.py:48] [100] global_step=100, grad_norm=0.1832588016986847, loss=8.173714637756348
I0919 13:56:40.957951 139716903765760 logging_writer.py:48] [500] global_step=500, grad_norm=0.4879309833049774, loss=5.649004936218262
I0919 13:59:39.850693 139716895373056 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.5141639113426208, loss=4.344282627105713
I0919 14:02:38.522960 139716903765760 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.44221198558807373, loss=3.52108097076416
I0919 14:05:37.218138 139716895373056 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.3362657427787781, loss=3.10507869720459
I0919 14:07:40.878737 139893447890752 spec.py:320] Evaluating on the training split.
I0919 14:07:43.868163 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 14:10:25.347589 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 14:10:27.997394 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 14:12:57.893653 139893447890752 spec.py:348] Evaluating on the test split.
I0919 14:13:00.581984 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 14:15:21.041776 139893447890752 submission_runner.py:376] Time since start: 2205.62s, 	Step: 2348, 	{'train/accuracy': 0.5223027467727661, 'train/loss': 2.756577730178833, 'train/bleu': 22.847602082953824, 'validation/accuracy': 0.5262922644615173, 'validation/loss': 2.7263078689575195, 'validation/bleu': 19.09381751292806, 'validation/num_examples': 3000, 'test/accuracy': 0.522596001625061, 'test/loss': 2.7707769870758057, 'test/bleu': 17.304567851597227, 'test/num_examples': 3003, 'score': 885.7435092926025, 'total_duration': 2205.6185047626495, 'accumulated_submission_time': 885.7435092926025, 'accumulated_eval_time': 1319.8082892894745, 'accumulated_logging_time': 0.03294658660888672}
I0919 14:15:21.057502 139716903765760 logging_writer.py:48] [2348] accumulated_eval_time=1319.808289, accumulated_logging_time=0.032947, accumulated_submission_time=885.743509, global_step=2348, preemption_count=0, score=885.743509, test/accuracy=0.522596, test/bleu=17.304568, test/loss=2.770777, test/num_examples=3003, total_duration=2205.618505, train/accuracy=0.522303, train/bleu=22.847602, train/loss=2.756578, validation/accuracy=0.526292, validation/bleu=19.093818, validation/loss=2.726308, validation/num_examples=3000
I0919 14:16:15.734458 139716895373056 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.2866441607475281, loss=2.828752279281616
I0919 14:19:14.332790 139716903765760 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.23263706266880035, loss=2.621734857559204
I0919 14:22:12.881609 139716895373056 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.19716303050518036, loss=2.442241668701172
I0919 14:25:11.377484 139716903765760 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.18376101553440094, loss=2.4507875442504883
I0919 14:28:09.876034 139716895373056 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.16214579343795776, loss=2.3442635536193848
I0919 14:29:21.363727 139893447890752 spec.py:320] Evaluating on the training split.
I0919 14:29:24.346579 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 14:32:05.336443 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 14:32:07.973325 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 14:34:25.022604 139893447890752 spec.py:348] Evaluating on the test split.
I0919 14:34:27.718834 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 14:36:37.142006 139893447890752 submission_runner.py:376] Time since start: 3481.72s, 	Step: 4702, 	{'train/accuracy': 0.5791102647781372, 'train/loss': 2.2252321243286133, 'train/bleu': 27.499746212286194, 'validation/accuracy': 0.5956528782844543, 'validation/loss': 2.106135606765747, 'validation/bleu': 23.72745635793008, 'validation/num_examples': 3000, 'test/accuracy': 0.5980942845344543, 'test/loss': 2.089252471923828, 'test/bleu': 22.38019268071747, 'test/num_examples': 3003, 'score': 1726.006341457367, 'total_duration': 3481.7187197208405, 'accumulated_submission_time': 1726.006341457367, 'accumulated_eval_time': 1755.5865097045898, 'accumulated_logging_time': 0.05828285217285156}
I0919 14:36:37.157473 139716903765760 logging_writer.py:48] [4702] accumulated_eval_time=1755.586510, accumulated_logging_time=0.058283, accumulated_submission_time=1726.006341, global_step=4702, preemption_count=0, score=1726.006341, test/accuracy=0.598094, test/bleu=22.380193, test/loss=2.089252, test/num_examples=3003, total_duration=3481.718720, train/accuracy=0.579110, train/bleu=27.499746, train/loss=2.225232, validation/accuracy=0.595653, validation/bleu=23.727456, validation/loss=2.106136, validation/num_examples=3000
I0919 14:38:23.885036 139716895373056 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.14246051013469696, loss=2.1879615783691406
I0919 14:41:22.365123 139716903765760 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.14831571280956268, loss=2.264753580093384
I0919 14:44:20.874008 139716895373056 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.16004163026809692, loss=2.177671194076538
I0919 14:47:19.414797 139716903765760 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.1374761015176773, loss=2.094050407409668
I0919 14:50:17.843467 139716895373056 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.14703862369060516, loss=2.23248553276062
I0919 14:50:37.186649 139893447890752 spec.py:320] Evaluating on the training split.
I0919 14:50:40.167434 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 14:53:35.855138 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 14:53:38.489107 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 14:55:50.741386 139893447890752 spec.py:348] Evaluating on the test split.
I0919 14:55:53.458268 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 14:58:05.850656 139893447890752 submission_runner.py:376] Time since start: 4770.43s, 	Step: 7056, 	{'train/accuracy': 0.6083300709724426, 'train/loss': 1.986690878868103, 'train/bleu': 29.13191209704578, 'validation/accuracy': 0.6204262971878052, 'validation/loss': 1.903771162033081, 'validation/bleu': 25.60077053364534, 'validation/num_examples': 3000, 'test/accuracy': 0.6244494915008545, 'test/loss': 1.861025094985962, 'test/bleu': 24.510254880278833, 'test/num_examples': 3003, 'score': 2565.9905123710632, 'total_duration': 4770.427384853363, 'accumulated_submission_time': 2565.9905123710632, 'accumulated_eval_time': 2204.250458717346, 'accumulated_logging_time': 0.08476591110229492}
I0919 14:58:05.866346 139716903765760 logging_writer.py:48] [7056] accumulated_eval_time=2204.250459, accumulated_logging_time=0.084766, accumulated_submission_time=2565.990512, global_step=7056, preemption_count=0, score=2565.990512, test/accuracy=0.624449, test/bleu=24.510255, test/loss=1.861025, test/num_examples=3003, total_duration=4770.427385, train/accuracy=0.608330, train/bleu=29.131912, train/loss=1.986691, validation/accuracy=0.620426, validation/bleu=25.600771, validation/loss=1.903771, validation/num_examples=3000
I0919 15:00:44.748400 139716895373056 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.13400572538375854, loss=2.056119203567505
I0919 15:03:43.255194 139716903765760 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.14398136734962463, loss=2.1156885623931885
I0919 15:06:41.782203 139716895373056 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.19352154433727264, loss=2.0904688835144043
I0919 15:09:40.357123 139716903765760 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.19294360280036926, loss=2.0798351764678955
I0919 15:12:06.091464 139893447890752 spec.py:320] Evaluating on the training split.
I0919 15:12:09.068586 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 15:14:51.476543 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 15:14:54.114671 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 15:17:12.471797 139893447890752 spec.py:348] Evaluating on the test split.
I0919 15:17:15.168265 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 15:19:20.438569 139893447890752 submission_runner.py:376] Time since start: 6045.02s, 	Step: 9410, 	{'train/accuracy': 0.6192506551742554, 'train/loss': 1.9133780002593994, 'train/bleu': 29.970172083927032, 'validation/accuracy': 0.6329493522644043, 'validation/loss': 1.804319143295288, 'validation/bleu': 26.322287874286733, 'validation/num_examples': 3000, 'test/accuracy': 0.6389169692993164, 'test/loss': 1.7473876476287842, 'test/bleu': 25.383847748661594, 'test/num_examples': 3003, 'score': 3406.172182559967, 'total_duration': 6045.015289068222, 'accumulated_submission_time': 3406.172182559967, 'accumulated_eval_time': 2638.597517490387, 'accumulated_logging_time': 0.10985875129699707}
I0919 15:19:20.454269 139716895373056 logging_writer.py:48] [9410] accumulated_eval_time=2638.597517, accumulated_logging_time=0.109859, accumulated_submission_time=3406.172183, global_step=9410, preemption_count=0, score=3406.172183, test/accuracy=0.638917, test/bleu=25.383848, test/loss=1.747388, test/num_examples=3003, total_duration=6045.015289, train/accuracy=0.619251, train/bleu=29.970172, train/loss=1.913378, validation/accuracy=0.632949, validation/bleu=26.322288, validation/loss=1.804319, validation/num_examples=3000
I0919 15:19:52.973131 139716903765760 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.15036632120609283, loss=2.096148729324341
I0919 15:22:51.464411 139716895373056 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.14204977452754974, loss=2.0046846866607666
I0919 15:25:49.944263 139716903765760 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.19467684626579285, loss=1.893592357635498
I0919 15:28:48.445135 139716895373056 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.14953236281871796, loss=2.03863263130188
I0919 15:31:46.878178 139716903765760 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.2010539323091507, loss=2.01822829246521
I0919 15:33:20.504266 139893447890752 spec.py:320] Evaluating on the training split.
I0919 15:33:23.491049 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 15:35:45.492753 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 15:35:48.120980 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 15:38:06.746827 139893447890752 spec.py:348] Evaluating on the test split.
I0919 15:38:09.428860 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 15:40:13.919470 139893447890752 submission_runner.py:376] Time since start: 7298.50s, 	Step: 11764, 	{'train/accuracy': 0.620331883430481, 'train/loss': 1.8951793909072876, 'train/bleu': 29.83833860940748, 'validation/accuracy': 0.6390373110771179, 'validation/loss': 1.7426457405090332, 'validation/bleu': 26.54636428136027, 'validation/num_examples': 3000, 'test/accuracy': 0.6477950215339661, 'test/loss': 1.6812012195587158, 'test/bleu': 25.394898018748137, 'test/num_examples': 3003, 'score': 4246.178511142731, 'total_duration': 7298.496207475662, 'accumulated_submission_time': 4246.178511142731, 'accumulated_eval_time': 3052.0126888751984, 'accumulated_logging_time': 0.13535833358764648}
I0919 15:40:13.935132 139716895373056 logging_writer.py:48] [11764] accumulated_eval_time=3052.012689, accumulated_logging_time=0.135358, accumulated_submission_time=4246.178511, global_step=11764, preemption_count=0, score=4246.178511, test/accuracy=0.647795, test/bleu=25.394898, test/loss=1.681201, test/num_examples=3003, total_duration=7298.496207, train/accuracy=0.620332, train/bleu=29.838339, train/loss=1.895179, validation/accuracy=0.639037, validation/bleu=26.546364, validation/loss=1.742646, validation/num_examples=3000
I0919 15:41:38.525343 139716903765760 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.19671739637851715, loss=1.9696569442749023
I0919 15:44:36.999946 139716895373056 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.16893671452999115, loss=1.9484596252441406
I0919 15:47:35.462279 139716903765760 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.18221478164196014, loss=1.896181344985962
I0919 15:50:34.045921 139716895373056 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.17648042738437653, loss=2.031665563583374
I0919 15:53:32.507904 139716903765760 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.1995413601398468, loss=1.9120609760284424
I0919 15:54:13.972440 139893447890752 spec.py:320] Evaluating on the training split.
I0919 15:54:16.958530 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 15:57:12.283903 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 15:57:14.922746 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 15:59:42.117055 139893447890752 spec.py:348] Evaluating on the test split.
I0919 15:59:44.825691 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 16:02:01.227982 139893447890752 submission_runner.py:376] Time since start: 8605.80s, 	Step: 14118, 	{'train/accuracy': 0.6296640038490295, 'train/loss': 1.8099462985992432, 'train/bleu': 30.076540343096546, 'validation/accuracy': 0.6466999650001526, 'validation/loss': 1.6975938081741333, 'validation/bleu': 27.278604848140947, 'validation/num_examples': 3000, 'test/accuracy': 0.654093325138092, 'test/loss': 1.6343461275100708, 'test/bleu': 26.315594765409987, 'test/num_examples': 3003, 'score': 5086.171936750412, 'total_duration': 8605.804715633392, 'accumulated_submission_time': 5086.171936750412, 'accumulated_eval_time': 3519.268178462982, 'accumulated_logging_time': 0.16052460670471191}
I0919 16:02:01.244904 139716895373056 logging_writer.py:48] [14118] accumulated_eval_time=3519.268178, accumulated_logging_time=0.160525, accumulated_submission_time=5086.171937, global_step=14118, preemption_count=0, score=5086.171937, test/accuracy=0.654093, test/bleu=26.315595, test/loss=1.634346, test/num_examples=3003, total_duration=8605.804716, train/accuracy=0.629664, train/bleu=30.076540, train/loss=1.809946, validation/accuracy=0.646700, validation/bleu=27.278605, validation/loss=1.697594, validation/num_examples=3000
I0919 16:04:18.079553 139716903765760 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.1557697355747223, loss=1.9513444900512695
I0919 16:07:16.623229 139716895373056 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.24133606255054474, loss=1.8980809450149536
I0919 16:10:15.223443 139716903765760 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.21007880568504333, loss=1.9452095031738281
I0919 16:13:13.780353 139716895373056 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.17846091091632843, loss=1.9206773042678833
I0919 16:16:01.343546 139893447890752 spec.py:320] Evaluating on the training split.
I0919 16:16:04.329299 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 16:19:13.692624 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 16:19:16.321954 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 16:21:28.819099 139893447890752 spec.py:348] Evaluating on the test split.
I0919 16:21:31.513259 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 16:23:45.319220 139893447890752 submission_runner.py:376] Time since start: 9909.90s, 	Step: 16471, 	{'train/accuracy': 0.628422737121582, 'train/loss': 1.817078948020935, 'train/bleu': 30.346818653597612, 'validation/accuracy': 0.6486218571662903, 'validation/loss': 1.6729240417480469, 'validation/bleu': 27.41113805093856, 'validation/num_examples': 3000, 'test/accuracy': 0.6577188968658447, 'test/loss': 1.6027809381484985, 'test/bleu': 26.406408728211915, 'test/num_examples': 3003, 'score': 5926.226072311401, 'total_duration': 9909.895950555801, 'accumulated_submission_time': 5926.226072311401, 'accumulated_eval_time': 3983.243810892105, 'accumulated_logging_time': 0.18732285499572754}
I0919 16:23:45.335264 139716903765760 logging_writer.py:48] [16471] accumulated_eval_time=3983.243811, accumulated_logging_time=0.187323, accumulated_submission_time=5926.226072, global_step=16471, preemption_count=0, score=5926.226072, test/accuracy=0.657719, test/bleu=26.406409, test/loss=1.602781, test/num_examples=3003, total_duration=9909.895951, train/accuracy=0.628423, train/bleu=30.346819, train/loss=1.817079, validation/accuracy=0.648622, validation/bleu=27.411138, validation/loss=1.672924, validation/num_examples=3000
I0919 16:23:56.068597 139716895373056 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.22126439213752747, loss=1.8981455564498901
I0919 16:26:54.640623 139716903765760 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.21722489595413208, loss=1.8662941455841064
I0919 16:29:53.200024 139716895373056 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.19277462363243103, loss=1.9372719526290894
I0919 16:32:51.796603 139716903765760 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.188727006316185, loss=1.8916560411453247
I0919 16:35:50.316495 139716895373056 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.20967842638492584, loss=1.876338243484497
I0919 16:37:45.378625 139893447890752 spec.py:320] Evaluating on the training split.
I0919 16:37:48.359551 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 16:41:24.586269 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 16:41:27.234942 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 16:43:43.982029 139893447890752 spec.py:348] Evaluating on the test split.
I0919 16:43:46.665786 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 16:45:51.892376 139893447890752 submission_runner.py:376] Time since start: 11236.47s, 	Step: 18824, 	{'train/accuracy': 0.6679422855377197, 'train/loss': 1.536102294921875, 'train/bleu': 33.41147710430217, 'validation/accuracy': 0.6535567045211792, 'validation/loss': 1.6475372314453125, 'validation/bleu': 27.90157434961957, 'validation/num_examples': 3000, 'test/accuracy': 0.6603683829307556, 'test/loss': 1.5781642198562622, 'test/bleu': 26.770949558872914, 'test/num_examples': 3003, 'score': 6766.224604606628, 'total_duration': 11236.46910738945, 'accumulated_submission_time': 6766.224604606628, 'accumulated_eval_time': 4469.757536888123, 'accumulated_logging_time': 0.21306157112121582}
I0919 16:45:51.908429 139716903765760 logging_writer.py:48] [18824] accumulated_eval_time=4469.757537, accumulated_logging_time=0.213062, accumulated_submission_time=6766.224605, global_step=18824, preemption_count=0, score=6766.224605, test/accuracy=0.660368, test/bleu=26.770950, test/loss=1.578164, test/num_examples=3003, total_duration=11236.469107, train/accuracy=0.667942, train/bleu=33.411477, train/loss=1.536102, validation/accuracy=0.653557, validation/bleu=27.901574, validation/loss=1.647537, validation/num_examples=3000
I0919 16:46:55.065320 139716895373056 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.18105557560920715, loss=1.828194499015808
I0919 16:49:53.465911 139716903765760 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.17221835255622864, loss=1.9488093852996826
I0919 16:52:51.886750 139716895373056 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.18161071836948395, loss=1.9076305627822876
I0919 16:55:50.309585 139716903765760 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.20669230818748474, loss=1.860697627067566
I0919 16:58:48.777950 139716895373056 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.2005768120288849, loss=1.7951421737670898
I0919 16:59:52.061977 139893447890752 spec.py:320] Evaluating on the training split.
I0919 16:59:55.056349 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 17:02:54.160265 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 17:02:56.779492 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 17:05:19.546343 139893447890752 spec.py:348] Evaluating on the test split.
I0919 17:05:22.254650 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 17:07:46.139728 139893447890752 submission_runner.py:376] Time since start: 12550.72s, 	Step: 21179, 	{'train/accuracy': 0.6381531953811646, 'train/loss': 1.7443022727966309, 'train/bleu': 30.73251058386486, 'validation/accuracy': 0.6548957824707031, 'validation/loss': 1.6329565048217773, 'validation/bleu': 27.683706875417723, 'validation/num_examples': 3000, 'test/accuracy': 0.6660391688346863, 'test/loss': 1.5578665733337402, 'test/bleu': 27.463220896539916, 'test/num_examples': 3003, 'score': 7606.333317279816, 'total_duration': 12550.716458320618, 'accumulated_submission_time': 7606.333317279816, 'accumulated_eval_time': 4943.835241317749, 'accumulated_logging_time': 0.23907184600830078}
I0919 17:07:46.156017 139716903765760 logging_writer.py:48] [21179] accumulated_eval_time=4943.835241, accumulated_logging_time=0.239072, accumulated_submission_time=7606.333317, global_step=21179, preemption_count=0, score=7606.333317, test/accuracy=0.666039, test/bleu=27.463221, test/loss=1.557867, test/num_examples=3003, total_duration=12550.716458, train/accuracy=0.638153, train/bleu=30.732511, train/loss=1.744302, validation/accuracy=0.654896, validation/bleu=27.683707, validation/loss=1.632957, validation/num_examples=3000
I0919 17:09:41.172091 139716895373056 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.18498192727565765, loss=1.8506251573562622
I0919 17:12:39.716075 139716903765760 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.24293413758277893, loss=1.9137965440750122
I0919 17:15:38.298204 139716895373056 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.18185362219810486, loss=1.7977449893951416
I0919 17:18:36.842050 139716903765760 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.17545899748802185, loss=1.827406406402588
I0919 17:21:35.328688 139716895373056 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.17165043950080872, loss=1.7669461965560913
I0919 17:21:46.471394 139893447890752 spec.py:320] Evaluating on the training split.
I0919 17:21:49.458785 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 17:25:02.878228 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 17:25:05.513442 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 17:27:27.003085 139893447890752 spec.py:348] Evaluating on the test split.
I0919 17:27:29.678412 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 17:29:47.674072 139893447890752 submission_runner.py:376] Time since start: 13872.25s, 	Step: 23533, 	{'train/accuracy': 0.6357744336128235, 'train/loss': 1.762818455696106, 'train/bleu': 30.517142124662858, 'validation/accuracy': 0.6572763919830322, 'validation/loss': 1.6141091585159302, 'validation/bleu': 27.860278731603966, 'validation/num_examples': 3000, 'test/accuracy': 0.6679797768592834, 'test/loss': 1.5416169166564941, 'test/bleu': 27.46032153571663, 'test/num_examples': 3003, 'score': 8446.604129314423, 'total_duration': 13872.250803232193, 'accumulated_submission_time': 8446.604129314423, 'accumulated_eval_time': 5425.037862062454, 'accumulated_logging_time': 0.26519775390625}
I0919 17:29:47.690565 139716903765760 logging_writer.py:48] [23533] accumulated_eval_time=5425.037862, accumulated_logging_time=0.265198, accumulated_submission_time=8446.604129, global_step=23533, preemption_count=0, score=8446.604129, test/accuracy=0.667980, test/bleu=27.460322, test/loss=1.541617, test/num_examples=3003, total_duration=13872.250803, train/accuracy=0.635774, train/bleu=30.517142, train/loss=1.762818, validation/accuracy=0.657276, validation/bleu=27.860279, validation/loss=1.614109, validation/num_examples=3000
I0919 17:32:34.735829 139716895373056 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.15851660072803497, loss=1.7893037796020508
I0919 17:35:33.241960 139716903765760 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.1777980774641037, loss=1.7044649124145508
I0919 17:38:31.792799 139716895373056 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.1927928775548935, loss=1.8439290523529053
I0919 17:41:30.273486 139716903765760 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.18254780769348145, loss=1.7840410470962524
I0919 17:43:47.819039 139893447890752 spec.py:320] Evaluating on the training split.
I0919 17:43:50.798205 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 17:46:51.755681 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 17:46:54.389044 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 17:49:11.358635 139893447890752 spec.py:348] Evaluating on the test split.
I0919 17:49:14.041592 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 17:51:37.820732 139893447890752 submission_runner.py:376] Time since start: 15182.40s, 	Step: 25887, 	{'train/accuracy': 0.6444838047027588, 'train/loss': 1.6967813968658447, 'train/bleu': 31.689275246780817, 'validation/accuracy': 0.6590370535850525, 'validation/loss': 1.601287603378296, 'validation/bleu': 28.0668084718369, 'validation/num_examples': 3000, 'test/accuracy': 0.6697112321853638, 'test/loss': 1.528649926185608, 'test/bleu': 27.513607473954195, 'test/num_examples': 3003, 'score': 9286.687712907791, 'total_duration': 15182.397433280945, 'accumulated_submission_time': 9286.687712907791, 'accumulated_eval_time': 5895.039499044418, 'accumulated_logging_time': 0.2910938262939453}
I0919 17:51:37.836892 139716895373056 logging_writer.py:48] [25887] accumulated_eval_time=5895.039499, accumulated_logging_time=0.291094, accumulated_submission_time=9286.687713, global_step=25887, preemption_count=0, score=9286.687713, test/accuracy=0.669711, test/bleu=27.513607, test/loss=1.528650, test/num_examples=3003, total_duration=15182.397433, train/accuracy=0.644484, train/bleu=31.689275, train/loss=1.696781, validation/accuracy=0.659037, validation/bleu=28.066808, validation/loss=1.601288, validation/num_examples=3000
I0919 17:52:18.527452 139716903765760 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.17818664014339447, loss=1.827358603477478
I0919 17:55:16.976404 139716895373056 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.17128483951091766, loss=1.7554161548614502
I0919 17:58:15.395367 139716903765760 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.21857792139053345, loss=1.8387936353683472
I0919 18:01:13.775439 139716895373056 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.2943509817123413, loss=1.836988091468811
I0919 18:04:12.205754 139716903765760 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.2884334623813629, loss=1.792101263999939
I0919 18:05:37.917466 139893447890752 spec.py:320] Evaluating on the training split.
I0919 18:05:40.906597 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 18:09:57.073965 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 18:09:59.712791 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 18:13:16.846987 139893447890752 spec.py:348] Evaluating on the test split.
I0919 18:13:19.544608 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 18:16:55.163399 139893447890752 submission_runner.py:376] Time since start: 16699.74s, 	Step: 28242, 	{'train/accuracy': 0.6431544423103333, 'train/loss': 1.7186918258666992, 'train/bleu': 31.745412314562202, 'validation/accuracy': 0.6615912914276123, 'validation/loss': 1.5894999504089355, 'validation/bleu': 28.380652771479404, 'validation/num_examples': 3000, 'test/accuracy': 0.6738365292549133, 'test/loss': 1.5105801820755005, 'test/bleu': 27.961993724325723, 'test/num_examples': 3003, 'score': 10126.724228143692, 'total_duration': 16699.740110874176, 'accumulated_submission_time': 10126.724228143692, 'accumulated_eval_time': 6572.285377502441, 'accumulated_logging_time': 0.3163130283355713}
I0919 18:16:55.180539 139716895373056 logging_writer.py:48] [28242] accumulated_eval_time=6572.285378, accumulated_logging_time=0.316313, accumulated_submission_time=10126.724228, global_step=28242, preemption_count=0, score=10126.724228, test/accuracy=0.673837, test/bleu=27.961994, test/loss=1.510580, test/num_examples=3003, total_duration=16699.740111, train/accuracy=0.643154, train/bleu=31.745412, train/loss=1.718692, validation/accuracy=0.661591, validation/bleu=28.380653, validation/loss=1.589500, validation/num_examples=3000
I0919 18:18:27.593434 139716903765760 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.21789878606796265, loss=1.76612389087677
I0919 18:21:26.121718 139716895373056 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.18009085953235626, loss=1.7476038932800293
I0919 18:24:24.653866 139716903765760 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.21992769837379456, loss=1.814161777496338
I0919 18:27:23.155340 139716895373056 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.19905032217502594, loss=1.7970784902572632
I0919 18:30:21.642325 139716903765760 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.1848931610584259, loss=1.7715569734573364
I0919 18:30:55.264676 139893447890752 spec.py:320] Evaluating on the training split.
I0919 18:30:58.242802 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 18:34:27.164064 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 18:34:29.796676 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 18:36:38.501844 139893447890752 spec.py:348] Evaluating on the test split.
I0919 18:36:41.195163 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 18:39:01.366708 139893447890752 submission_runner.py:376] Time since start: 18025.94s, 	Step: 30596, 	{'train/accuracy': 0.6410382390022278, 'train/loss': 1.7249096632003784, 'train/bleu': 31.462253542668456, 'validation/accuracy': 0.6622236371040344, 'validation/loss': 1.5801713466644287, 'validation/bleu': 28.201391954729644, 'validation/num_examples': 3000, 'test/accuracy': 0.6750566959381104, 'test/loss': 1.4950681924819946, 'test/bleu': 27.965461235464893, 'test/num_examples': 3003, 'score': 10966.763080120087, 'total_duration': 18025.9434363842, 'accumulated_submission_time': 10966.763080120087, 'accumulated_eval_time': 7058.387634515762, 'accumulated_logging_time': 0.34311413764953613}
I0919 18:39:01.384155 139716895373056 logging_writer.py:48] [30596] accumulated_eval_time=7058.387635, accumulated_logging_time=0.343114, accumulated_submission_time=10966.763080, global_step=30596, preemption_count=0, score=10966.763080, test/accuracy=0.675057, test/bleu=27.965461, test/loss=1.495068, test/num_examples=3003, total_duration=18025.943436, train/accuracy=0.641038, train/bleu=31.462254, train/loss=1.724910, validation/accuracy=0.662224, validation/bleu=28.201392, validation/loss=1.580171, validation/num_examples=3000
I0919 18:41:25.944923 139716903765760 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.17910443246364594, loss=1.7555787563323975
I0919 18:44:24.391782 139716895373056 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.20669010281562805, loss=1.7593618631362915
I0919 18:47:22.825549 139716903765760 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.18908162415027618, loss=1.7746473550796509
I0919 18:50:21.206222 139716895373056 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.1964726448059082, loss=1.804040551185608
I0919 18:53:01.446252 139893447890752 spec.py:320] Evaluating on the training split.
I0919 18:53:04.423918 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 18:56:32.444865 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 18:56:35.085329 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 18:59:32.541065 139893447890752 spec.py:348] Evaluating on the test split.
I0919 18:59:35.236334 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 19:03:00.237464 139893447890752 submission_runner.py:376] Time since start: 19464.81s, 	Step: 32951, 	{'train/accuracy': 0.64990234375, 'train/loss': 1.6726881265640259, 'train/bleu': 31.721529984247024, 'validation/accuracy': 0.6627939939498901, 'validation/loss': 1.5707138776779175, 'validation/bleu': 28.173019190570095, 'validation/num_examples': 3000, 'test/accuracy': 0.675254225730896, 'test/loss': 1.4890516996383667, 'test/bleu': 28.315225871542676, 'test/num_examples': 3003, 'score': 11806.779775381088, 'total_duration': 19464.814161777496, 'accumulated_submission_time': 11806.779775381088, 'accumulated_eval_time': 7657.178781986237, 'accumulated_logging_time': 0.37096452713012695}
I0919 19:03:00.255420 139716903765760 logging_writer.py:48] [32951] accumulated_eval_time=7657.178782, accumulated_logging_time=0.370965, accumulated_submission_time=11806.779775, global_step=32951, preemption_count=0, score=11806.779775, test/accuracy=0.675254, test/bleu=28.315226, test/loss=1.489052, test/num_examples=3003, total_duration=19464.814162, train/accuracy=0.649902, train/bleu=31.721530, train/loss=1.672688, validation/accuracy=0.662794, validation/bleu=28.173019, validation/loss=1.570714, validation/num_examples=3000
I0919 19:03:18.082164 139716895373056 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.19865022599697113, loss=1.75462007522583
I0919 19:06:16.556316 139716903765760 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.20656417310237885, loss=1.746294379234314
I0919 19:09:15.057129 139716895373056 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.18343068659305573, loss=1.7724212408065796
I0919 19:12:13.555828 139716903765760 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.183381125330925, loss=1.7360291481018066
I0919 19:15:12.134847 139716895373056 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.20540934801101685, loss=1.7386553287506104
I0919 19:17:00.437201 139893447890752 spec.py:320] Evaluating on the training split.
I0919 19:17:03.435709 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 19:21:01.583960 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 19:21:04.213796 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 19:23:50.961134 139893447890752 spec.py:348] Evaluating on the test split.
I0919 19:23:53.639034 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 19:27:05.733018 139893447890752 submission_runner.py:376] Time since start: 20910.31s, 	Step: 35305, 	{'train/accuracy': 0.643582820892334, 'train/loss': 1.7148653268814087, 'train/bleu': 31.49457209748028, 'validation/accuracy': 0.6627196073532104, 'validation/loss': 1.568458080291748, 'validation/bleu': 28.588793654073218, 'validation/num_examples': 3000, 'test/accuracy': 0.676021158695221, 'test/loss': 1.4819279909133911, 'test/bleu': 28.083742612164922, 'test/num_examples': 3003, 'score': 12646.915295362473, 'total_duration': 20910.309740543365, 'accumulated_submission_time': 12646.915295362473, 'accumulated_eval_time': 8262.474550485611, 'accumulated_logging_time': 0.39999938011169434}
I0919 19:27:05.749746 139716903765760 logging_writer.py:48] [35305] accumulated_eval_time=8262.474550, accumulated_logging_time=0.399999, accumulated_submission_time=12646.915295, global_step=35305, preemption_count=0, score=12646.915295, test/accuracy=0.676021, test/bleu=28.083743, test/loss=1.481928, test/num_examples=3003, total_duration=20910.309741, train/accuracy=0.643583, train/bleu=31.494572, train/loss=1.714865, validation/accuracy=0.662720, validation/bleu=28.588794, validation/loss=1.568458, validation/num_examples=3000
I0919 19:28:15.707161 139716895373056 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.20398642122745514, loss=1.784500002861023
I0919 19:31:14.164919 139716903765760 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.18042698502540588, loss=1.7305772304534912
I0919 19:34:12.621462 139716895373056 logging_writer.py:48] [36500] global_step=36500, grad_norm=0.17201311886310577, loss=1.784323811531067
I0919 19:37:11.052413 139716903765760 logging_writer.py:48] [37000] global_step=37000, grad_norm=0.1853301227092743, loss=1.8071905374526978
I0919 19:40:09.430800 139716895373056 logging_writer.py:48] [37500] global_step=37500, grad_norm=0.19066792726516724, loss=1.820752501487732
I0919 19:41:05.927115 139893447890752 spec.py:320] Evaluating on the training split.
I0919 19:41:08.907101 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 19:44:33.992769 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 19:44:36.609058 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 19:46:50.613164 139893447890752 spec.py:348] Evaluating on the test split.
I0919 19:46:53.305817 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 19:49:10.673732 139893447890752 submission_runner.py:376] Time since start: 22235.25s, 	Step: 37660, 	{'train/accuracy': 0.6750354170799255, 'train/loss': 1.4914193153381348, 'train/bleu': 33.5374128749934, 'validation/accuracy': 0.6667245030403137, 'validation/loss': 1.549566626548767, 'validation/bleu': 28.66948557740173, 'validation/num_examples': 3000, 'test/accuracy': 0.6783103942871094, 'test/loss': 1.4724562168121338, 'test/bleu': 27.966596225337117, 'test/num_examples': 3003, 'score': 13487.047506570816, 'total_duration': 22235.250456094742, 'accumulated_submission_time': 13487.047506570816, 'accumulated_eval_time': 8747.221109390259, 'accumulated_logging_time': 0.4267709255218506}
I0919 19:49:10.690231 139716903765760 logging_writer.py:48] [37660] accumulated_eval_time=8747.221109, accumulated_logging_time=0.426771, accumulated_submission_time=13487.047507, global_step=37660, preemption_count=0, score=13487.047507, test/accuracy=0.678310, test/bleu=27.966596, test/loss=1.472456, test/num_examples=3003, total_duration=22235.250456, train/accuracy=0.675035, train/bleu=33.537413, train/loss=1.491419, validation/accuracy=0.666725, validation/bleu=28.669486, validation/loss=1.549567, validation/num_examples=3000
I0919 19:51:12.444220 139716895373056 logging_writer.py:48] [38000] global_step=38000, grad_norm=0.1904182732105255, loss=1.7733807563781738
I0919 19:54:10.975898 139716903765760 logging_writer.py:48] [38500] global_step=38500, grad_norm=0.3015485405921936, loss=1.755845546722412
I0919 19:57:09.469720 139716895373056 logging_writer.py:48] [39000] global_step=39000, grad_norm=0.19894658029079437, loss=1.7453879117965698
I0919 20:00:07.941407 139716903765760 logging_writer.py:48] [39500] global_step=39500, grad_norm=0.20859238505363464, loss=1.7730631828308105
I0919 20:03:06.441699 139716895373056 logging_writer.py:48] [40000] global_step=40000, grad_norm=0.20098771154880524, loss=1.6885672807693481
I0919 20:03:10.801781 139893447890752 spec.py:320] Evaluating on the training split.
I0919 20:03:13.783966 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 20:07:29.959270 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 20:07:32.598418 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 20:10:52.216576 139893447890752 spec.py:348] Evaluating on the test split.
I0919 20:10:54.905107 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 20:14:34.303118 139893447890752 submission_runner.py:376] Time since start: 23758.88s, 	Step: 40014, 	{'train/accuracy': 0.6524672508239746, 'train/loss': 1.653410792350769, 'train/bleu': 32.01533529036341, 'validation/accuracy': 0.6676792502403259, 'validation/loss': 1.540696144104004, 'validation/bleu': 28.744897528988325, 'validation/num_examples': 3000, 'test/accuracy': 0.6795654296875, 'test/loss': 1.4615223407745361, 'test/bleu': 28.371424385505, 'test/num_examples': 3003, 'score': 14327.11462688446, 'total_duration': 23758.879850149155, 'accumulated_submission_time': 14327.11462688446, 'accumulated_eval_time': 9430.722401618958, 'accumulated_logging_time': 0.4527890682220459}
I0919 20:14:34.320087 139716903765760 logging_writer.py:48] [40014] accumulated_eval_time=9430.722402, accumulated_logging_time=0.452789, accumulated_submission_time=14327.114627, global_step=40014, preemption_count=0, score=14327.114627, test/accuracy=0.679565, test/bleu=28.371424, test/loss=1.461522, test/num_examples=3003, total_duration=23758.879850, train/accuracy=0.652467, train/bleu=32.015335, train/loss=1.653411, validation/accuracy=0.667679, validation/bleu=28.744898, validation/loss=1.540696, validation/num_examples=3000
I0919 20:17:28.017159 139716895373056 logging_writer.py:48] [40500] global_step=40500, grad_norm=0.18944741785526276, loss=1.7097768783569336
I0919 20:20:26.380012 139716903765760 logging_writer.py:48] [41000] global_step=41000, grad_norm=0.1865493655204773, loss=1.6882565021514893
I0919 20:23:24.754507 139716895373056 logging_writer.py:48] [41500] global_step=41500, grad_norm=0.20299457013607025, loss=1.7381722927093506
I0919 20:26:23.120589 139716903765760 logging_writer.py:48] [42000] global_step=42000, grad_norm=0.2581638991832733, loss=1.7250880002975464
I0919 20:28:34.507915 139893447890752 spec.py:320] Evaluating on the training split.
I0919 20:28:37.492499 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 20:32:39.742198 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 20:32:42.365226 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 20:35:08.646615 139893447890752 spec.py:348] Evaluating on the test split.
I0919 20:35:11.340708 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 20:37:36.293463 139893447890752 submission_runner.py:376] Time since start: 25140.87s, 	Step: 42370, 	{'train/accuracy': 0.6537200212478638, 'train/loss': 1.644946813583374, 'train/bleu': 31.888651052234906, 'validation/accuracy': 0.6686463952064514, 'validation/loss': 1.5342216491699219, 'validation/bleu': 28.734077134773415, 'validation/num_examples': 3000, 'test/accuracy': 0.6826797127723694, 'test/loss': 1.4480257034301758, 'test/bleu': 28.466429057401516, 'test/num_examples': 3003, 'score': 15167.25780916214, 'total_duration': 25140.87017059326, 'accumulated_submission_time': 15167.25780916214, 'accumulated_eval_time': 9972.50788974762, 'accumulated_logging_time': 0.479290246963501}
I0919 20:37:36.310767 139716895373056 logging_writer.py:48] [42370] accumulated_eval_time=9972.507890, accumulated_logging_time=0.479290, accumulated_submission_time=15167.257809, global_step=42370, preemption_count=0, score=15167.257809, test/accuracy=0.682680, test/bleu=28.466429, test/loss=1.448026, test/num_examples=3003, total_duration=25140.870171, train/accuracy=0.653720, train/bleu=31.888651, train/loss=1.644947, validation/accuracy=0.668646, validation/bleu=28.734077, validation/loss=1.534222, validation/num_examples=3000
I0919 20:38:23.068559 139716903765760 logging_writer.py:48] [42500] global_step=42500, grad_norm=0.20936161279678345, loss=1.7695317268371582
I0919 20:41:21.406844 139716895373056 logging_writer.py:48] [43000] global_step=43000, grad_norm=0.2392922043800354, loss=1.7311028242111206
I0919 20:44:19.871690 139716903765760 logging_writer.py:48] [43500] global_step=43500, grad_norm=0.17796960473060608, loss=1.7212942838668823
I0919 20:47:18.246605 139716895373056 logging_writer.py:48] [44000] global_step=44000, grad_norm=0.19945423305034637, loss=1.7746574878692627
I0919 20:50:16.646752 139716903765760 logging_writer.py:48] [44500] global_step=44500, grad_norm=0.1873304545879364, loss=1.658290147781372
I0919 20:51:36.618246 139893447890752 spec.py:320] Evaluating on the training split.
I0919 20:51:39.601593 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 20:55:25.869594 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 20:55:28.498586 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 20:58:36.851461 139893447890752 spec.py:348] Evaluating on the test split.
I0919 20:58:39.546322 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 21:02:20.026928 139893447890752 submission_runner.py:376] Time since start: 26624.60s, 	Step: 44726, 	{'train/accuracy': 0.6600672602653503, 'train/loss': 1.5931910276412964, 'train/bleu': 33.08935672667615, 'validation/accuracy': 0.6714485883712769, 'validation/loss': 1.5209060907363892, 'validation/bleu': 28.76862689643593, 'validation/num_examples': 3000, 'test/accuracy': 0.6840857863426208, 'test/loss': 1.4394794702529907, 'test/bleu': 28.66588361400673, 'test/num_examples': 3003, 'score': 16007.520249605179, 'total_duration': 26624.603650808334, 'accumulated_submission_time': 16007.520249605179, 'accumulated_eval_time': 10615.91652560234, 'accumulated_logging_time': 0.5059785842895508}
I0919 21:02:20.045899 139716895373056 logging_writer.py:48] [44726] accumulated_eval_time=10615.916526, accumulated_logging_time=0.505979, accumulated_submission_time=16007.520250, global_step=44726, preemption_count=0, score=16007.520250, test/accuracy=0.684086, test/bleu=28.665884, test/loss=1.439479, test/num_examples=3003, total_duration=26624.603651, train/accuracy=0.660067, train/bleu=33.089357, train/loss=1.593191, validation/accuracy=0.671449, validation/bleu=28.768627, validation/loss=1.520906, validation/num_examples=3000
I0919 21:03:58.165901 139716903765760 logging_writer.py:48] [45000] global_step=45000, grad_norm=0.19420380890369415, loss=1.6727986335754395
I0919 21:06:56.568151 139716895373056 logging_writer.py:48] [45500] global_step=45500, grad_norm=0.22665515542030334, loss=1.73809814453125
I0919 21:09:54.990794 139716903765760 logging_writer.py:48] [46000] global_step=46000, grad_norm=0.213873490691185, loss=1.6824086904525757
I0919 21:12:53.404220 139716895373056 logging_writer.py:48] [46500] global_step=46500, grad_norm=0.31859299540519714, loss=1.658504605293274
I0919 21:15:51.846312 139716903765760 logging_writer.py:48] [47000] global_step=47000, grad_norm=0.20269624888896942, loss=1.7009888887405396
I0919 21:16:20.107750 139893447890752 spec.py:320] Evaluating on the training split.
I0919 21:16:23.094791 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 21:20:03.362362 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 21:20:05.996077 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 21:22:54.263010 139893447890752 spec.py:348] Evaluating on the test split.
I0919 21:22:56.944639 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 21:25:47.742573 139893447890752 submission_runner.py:376] Time since start: 28032.32s, 	Step: 47081, 	{'train/accuracy': 0.6531199216842651, 'train/loss': 1.6436289548873901, 'train/bleu': 31.975095981027742, 'validation/accuracy': 0.6720685362815857, 'validation/loss': 1.5198124647140503, 'validation/bleu': 28.781026071222705, 'validation/num_examples': 3000, 'test/accuracy': 0.6863401532173157, 'test/loss': 1.4274227619171143, 'test/bleu': 28.78792581200404, 'test/num_examples': 3003, 'score': 16847.536018133163, 'total_duration': 28032.319281101227, 'accumulated_submission_time': 16847.536018133163, 'accumulated_eval_time': 11183.551272153854, 'accumulated_logging_time': 0.5357234477996826}
I0919 21:25:47.760189 139716895373056 logging_writer.py:48] [47081] accumulated_eval_time=11183.551272, accumulated_logging_time=0.535723, accumulated_submission_time=16847.536018, global_step=47081, preemption_count=0, score=16847.536018, test/accuracy=0.686340, test/bleu=28.787926, test/loss=1.427423, test/num_examples=3003, total_duration=28032.319281, train/accuracy=0.653120, train/bleu=31.975096, train/loss=1.643629, validation/accuracy=0.672069, validation/bleu=28.781026, validation/loss=1.519812, validation/num_examples=3000
I0919 21:28:17.555093 139716903765760 logging_writer.py:48] [47500] global_step=47500, grad_norm=0.21209941804409027, loss=1.7224303483963013
I0919 21:31:15.993663 139716895373056 logging_writer.py:48] [48000] global_step=48000, grad_norm=0.20330163836479187, loss=1.706769585609436
I0919 21:34:14.409477 139716903765760 logging_writer.py:48] [48500] global_step=48500, grad_norm=0.18907000124454498, loss=1.6780192852020264
I0919 21:37:12.852754 139716895373056 logging_writer.py:48] [49000] global_step=49000, grad_norm=0.19043774902820587, loss=1.7015628814697266
I0919 21:39:47.827560 139893447890752 spec.py:320] Evaluating on the training split.
I0919 21:39:50.809802 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 21:43:22.246999 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 21:43:24.880962 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 21:45:43.491428 139893447890752 spec.py:348] Evaluating on the test split.
I0919 21:45:46.188488 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 21:48:04.257714 139893447890752 submission_runner.py:376] Time since start: 29368.83s, 	Step: 49436, 	{'train/accuracy': 0.6556416749954224, 'train/loss': 1.6273813247680664, 'train/bleu': 32.10085491711795, 'validation/accuracy': 0.6736184358596802, 'validation/loss': 1.5064789056777954, 'validation/bleu': 29.353998546367293, 'validation/num_examples': 3000, 'test/accuracy': 0.6879902482032776, 'test/loss': 1.4197542667388916, 'test/bleu': 28.627085888697408, 'test/num_examples': 3003, 'score': 17687.556476831436, 'total_duration': 29368.83440732956, 'accumulated_submission_time': 17687.556476831436, 'accumulated_eval_time': 11679.981359243393, 'accumulated_logging_time': 0.5647683143615723}
I0919 21:48:04.274883 139716903765760 logging_writer.py:48] [49436] accumulated_eval_time=11679.981359, accumulated_logging_time=0.564768, accumulated_submission_time=17687.556477, global_step=49436, preemption_count=0, score=17687.556477, test/accuracy=0.687990, test/bleu=28.627086, test/loss=1.419754, test/num_examples=3003, total_duration=29368.834407, train/accuracy=0.655642, train/bleu=32.100855, train/loss=1.627381, validation/accuracy=0.673618, validation/bleu=29.353999, validation/loss=1.506479, validation/num_examples=3000
I0919 21:48:27.476713 139716895373056 logging_writer.py:48] [49500] global_step=49500, grad_norm=0.19144095480442047, loss=1.5759248733520508
I0919 21:51:25.961283 139716903765760 logging_writer.py:48] [50000] global_step=50000, grad_norm=0.19869768619537354, loss=1.7512093782424927
I0919 21:54:24.449637 139716895373056 logging_writer.py:48] [50500] global_step=50500, grad_norm=0.18619169294834137, loss=1.6692191362380981
I0919 21:57:22.918869 139716903765760 logging_writer.py:48] [51000] global_step=51000, grad_norm=0.19919776916503906, loss=1.7296295166015625
I0919 22:00:21.389388 139716895373056 logging_writer.py:48] [51500] global_step=51500, grad_norm=0.2008049190044403, loss=1.6691511869430542
I0919 22:02:04.274729 139893447890752 spec.py:320] Evaluating on the training split.
I0919 22:02:07.256117 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 22:05:57.666589 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 22:06:00.293553 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 22:08:38.139422 139893447890752 spec.py:348] Evaluating on the test split.
I0919 22:08:40.822003 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 22:11:19.693322 139893447890752 submission_runner.py:376] Time since start: 30764.27s, 	Step: 51790, 	{'train/accuracy': 0.6627727150917053, 'train/loss': 1.5808186531066895, 'train/bleu': 32.636743534686076, 'validation/accuracy': 0.6744987368583679, 'validation/loss': 1.4930343627929688, 'validation/bleu': 28.953372526636766, 'validation/num_examples': 3000, 'test/accuracy': 0.6898959875106812, 'test/loss': 1.403241515159607, 'test/bleu': 29.217195641015813, 'test/num_examples': 3003, 'score': 18527.511578321457, 'total_duration': 30764.270045518875, 'accumulated_submission_time': 18527.511578321457, 'accumulated_eval_time': 12235.399912595749, 'accumulated_logging_time': 0.5912847518920898}
I0919 22:11:19.711493 139716903765760 logging_writer.py:48] [51790] accumulated_eval_time=12235.399913, accumulated_logging_time=0.591285, accumulated_submission_time=18527.511578, global_step=51790, preemption_count=0, score=18527.511578, test/accuracy=0.689896, test/bleu=29.217196, test/loss=1.403242, test/num_examples=3003, total_duration=30764.270046, train/accuracy=0.662773, train/bleu=32.636744, train/loss=1.580819, validation/accuracy=0.674499, validation/bleu=28.953373, validation/loss=1.493034, validation/num_examples=3000
I0919 22:12:35.004009 139716895373056 logging_writer.py:48] [52000] global_step=52000, grad_norm=0.18098363280296326, loss=1.6145761013031006
I0919 22:15:33.449742 139716903765760 logging_writer.py:48] [52500] global_step=52500, grad_norm=0.2049189656972885, loss=1.6996170282363892
I0919 22:18:31.879329 139716895373056 logging_writer.py:48] [53000] global_step=53000, grad_norm=0.19300036132335663, loss=1.7431119680404663
I0919 22:21:30.379112 139716903765760 logging_writer.py:48] [53500] global_step=53500, grad_norm=0.3008364140987396, loss=1.631877064704895
I0919 22:24:28.784539 139716895373056 logging_writer.py:48] [54000] global_step=54000, grad_norm=0.19398602843284607, loss=1.6735594272613525
I0919 22:25:19.871309 139893447890752 spec.py:320] Evaluating on the training split.
I0919 22:25:22.845525 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 22:29:01.766694 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 22:29:04.411343 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 22:32:32.987145 139893447890752 spec.py:348] Evaluating on the test split.
I0919 22:32:35.671461 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 22:35:53.051681 139893447890752 submission_runner.py:376] Time since start: 32237.63s, 	Step: 54145, 	{'train/accuracy': 0.6540789604187012, 'train/loss': 1.6331303119659424, 'train/bleu': 32.36771906244592, 'validation/accuracy': 0.6761974096298218, 'validation/loss': 1.4889857769012451, 'validation/bleu': 29.432292479448968, 'validation/num_examples': 3000, 'test/accuracy': 0.6913136839866638, 'test/loss': 1.3917614221572876, 'test/bleu': 29.00583413290922, 'test/num_examples': 3003, 'score': 19367.626319169998, 'total_duration': 32237.628411769867, 'accumulated_submission_time': 19367.626319169998, 'accumulated_eval_time': 12868.58023738861, 'accumulated_logging_time': 0.6192111968994141}
I0919 22:35:53.070456 139716903765760 logging_writer.py:48] [54145] accumulated_eval_time=12868.580237, accumulated_logging_time=0.619211, accumulated_submission_time=19367.626319, global_step=54145, preemption_count=0, score=19367.626319, test/accuracy=0.691314, test/bleu=29.005834, test/loss=1.391761, test/num_examples=3003, total_duration=32237.628412, train/accuracy=0.654079, train/bleu=32.367719, train/loss=1.633130, validation/accuracy=0.676197, validation/bleu=29.432292, validation/loss=1.488986, validation/num_examples=3000
I0919 22:38:00.017389 139716895373056 logging_writer.py:48] [54500] global_step=54500, grad_norm=0.2019502967596054, loss=1.6300352811813354
I0919 22:40:58.394144 139716903765760 logging_writer.py:48] [55000] global_step=55000, grad_norm=0.1900164783000946, loss=1.614927887916565
I0919 22:43:56.824678 139716895373056 logging_writer.py:48] [55500] global_step=55500, grad_norm=0.19631680846214294, loss=1.6447123289108276
I0919 22:46:55.217443 139716903765760 logging_writer.py:48] [56000] global_step=56000, grad_norm=0.1808747798204422, loss=1.6492180824279785
I0919 22:49:53.581727 139716895373056 logging_writer.py:48] [56500] global_step=56500, grad_norm=0.19583344459533691, loss=1.6741708517074585
I0919 22:49:53.587804 139893447890752 spec.py:320] Evaluating on the training split.
I0919 22:49:56.281985 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 22:53:18.222825 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 22:53:20.862820 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 22:55:34.613582 139893447890752 spec.py:348] Evaluating on the test split.
I0919 22:55:37.301548 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 22:57:47.999289 139893447890752 submission_runner.py:376] Time since start: 33552.58s, 	Step: 56501, 	{'train/accuracy': 0.6786210536956787, 'train/loss': 1.472409725189209, 'train/bleu': 34.48414807015081, 'validation/accuracy': 0.6776977181434631, 'validation/loss': 1.4757193326950073, 'validation/bleu': 29.40557344804655, 'validation/num_examples': 3000, 'test/accuracy': 0.6908372640609741, 'test/loss': 1.3876988887786865, 'test/bleu': 29.222403776771802, 'test/num_examples': 3003, 'score': 20208.097794294357, 'total_duration': 33552.57602405548, 'accumulated_submission_time': 20208.097794294357, 'accumulated_eval_time': 13342.99164891243, 'accumulated_logging_time': 0.6485104560852051}
I0919 22:57:48.016903 139716903765760 logging_writer.py:48] [56501] accumulated_eval_time=13342.991649, accumulated_logging_time=0.648510, accumulated_submission_time=20208.097794, global_step=56501, preemption_count=0, score=20208.097794, test/accuracy=0.690837, test/bleu=29.222404, test/loss=1.387699, test/num_examples=3003, total_duration=33552.576024, train/accuracy=0.678621, train/bleu=34.484148, train/loss=1.472410, validation/accuracy=0.677698, validation/bleu=29.405573, validation/loss=1.475719, validation/num_examples=3000
I0919 23:00:46.510549 139716895373056 logging_writer.py:48] [57000] global_step=57000, grad_norm=0.18791691958904266, loss=1.6207658052444458
I0919 23:03:45.032721 139716903765760 logging_writer.py:48] [57500] global_step=57500, grad_norm=0.18548017740249634, loss=1.628299355506897
I0919 23:06:43.595760 139716895373056 logging_writer.py:48] [58000] global_step=58000, grad_norm=0.20009839534759521, loss=1.617069125175476
I0919 23:09:42.088750 139716903765760 logging_writer.py:48] [58500] global_step=58500, grad_norm=0.18690979480743408, loss=1.5638834238052368
I0919 23:11:48.181076 139893447890752 spec.py:320] Evaluating on the training split.
I0919 23:11:51.164876 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 23:16:05.717221 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 23:16:08.338835 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 23:19:47.506213 139893447890752 spec.py:348] Evaluating on the test split.
I0919 23:19:50.187757 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 23:24:00.271582 139893447890752 submission_runner.py:376] Time since start: 35124.85s, 	Step: 58855, 	{'train/accuracy': 0.6685560345649719, 'train/loss': 1.5453472137451172, 'train/bleu': 32.735772999917856, 'validation/accuracy': 0.6788260340690613, 'validation/loss': 1.467403769493103, 'validation/bleu': 29.541419099289623, 'validation/num_examples': 3000, 'test/accuracy': 0.6940677762031555, 'test/loss': 1.3734157085418701, 'test/bleu': 29.396471965935515, 'test/num_examples': 3003, 'score': 21048.216207504272, 'total_duration': 35124.84830379486, 'accumulated_submission_time': 21048.216207504272, 'accumulated_eval_time': 14075.082108259201, 'accumulated_logging_time': 0.6768617630004883}
I0919 23:24:00.289565 139716895373056 logging_writer.py:48] [58855] accumulated_eval_time=14075.082108, accumulated_logging_time=0.676862, accumulated_submission_time=21048.216208, global_step=58855, preemption_count=0, score=21048.216208, test/accuracy=0.694068, test/bleu=29.396472, test/loss=1.373416, test/num_examples=3003, total_duration=35124.848304, train/accuracy=0.668556, train/bleu=32.735773, train/loss=1.545347, validation/accuracy=0.678826, validation/bleu=29.541419, validation/loss=1.467404, validation/num_examples=3000
I0919 23:24:52.338670 139716903765760 logging_writer.py:48] [59000] global_step=59000, grad_norm=0.1963166445493698, loss=1.6049091815948486
I0919 23:27:50.716450 139716895373056 logging_writer.py:48] [59500] global_step=59500, grad_norm=0.21487314999103546, loss=1.5925077199935913
I0919 23:30:49.130235 139716903765760 logging_writer.py:48] [60000] global_step=60000, grad_norm=0.2002260535955429, loss=1.6669596433639526
I0919 23:33:47.501158 139716895373056 logging_writer.py:48] [60500] global_step=60500, grad_norm=0.21315377950668335, loss=1.5831079483032227
I0919 23:36:45.960935 139716903765760 logging_writer.py:48] [61000] global_step=61000, grad_norm=0.1940683126449585, loss=1.6385960578918457
I0919 23:38:00.618295 139893447890752 spec.py:320] Evaluating on the training split.
I0919 23:38:03.612699 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 23:42:21.242703 139893447890752 spec.py:332] Evaluating on the validation split.
I0919 23:42:23.883283 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 23:44:54.727891 139893447890752 spec.py:348] Evaluating on the test split.
I0919 23:44:57.428081 139893447890752 workload.py:179] Translating evaluation dataset.
I0919 23:47:51.507755 139893447890752 submission_runner.py:376] Time since start: 36556.08s, 	Step: 61211, 	{'train/accuracy': 0.665136992931366, 'train/loss': 1.5755027532577515, 'train/bleu': 33.046904600355454, 'validation/accuracy': 0.6804999113082886, 'validation/loss': 1.4599628448486328, 'validation/bleu': 29.711303320275704, 'validation/num_examples': 3000, 'test/accuracy': 0.6964848041534424, 'test/loss': 1.3657292127609253, 'test/bleu': 29.84307793739068, 'test/num_examples': 3003, 'score': 21888.499173879623, 'total_duration': 36556.08446121216, 'accumulated_submission_time': 21888.499173879623, 'accumulated_eval_time': 14665.971496582031, 'accumulated_logging_time': 0.7054507732391357}
I0919 23:47:51.525509 139716895373056 logging_writer.py:48] [61211] accumulated_eval_time=14665.971497, accumulated_logging_time=0.705451, accumulated_submission_time=21888.499174, global_step=61211, preemption_count=0, score=21888.499174, test/accuracy=0.696485, test/bleu=29.843078, test/loss=1.365729, test/num_examples=3003, total_duration=36556.084461, train/accuracy=0.665137, train/bleu=33.046905, train/loss=1.575503, validation/accuracy=0.680500, validation/bleu=29.711303, validation/loss=1.459963, validation/num_examples=3000
I0919 23:49:34.925968 139716903765760 logging_writer.py:48] [61500] global_step=61500, grad_norm=0.19459299743175507, loss=1.589308738708496
I0919 23:52:33.338301 139716895373056 logging_writer.py:48] [62000] global_step=62000, grad_norm=0.1922847330570221, loss=1.6305760145187378
I0919 23:55:31.845232 139716903765760 logging_writer.py:48] [62500] global_step=62500, grad_norm=0.18927566707134247, loss=1.5909950733184814
I0919 23:58:30.185657 139716895373056 logging_writer.py:48] [63000] global_step=63000, grad_norm=0.1942438781261444, loss=1.608520746231079
I0920 00:01:28.586261 139716903765760 logging_writer.py:48] [63500] global_step=63500, grad_norm=0.24580226838588715, loss=1.6337946653366089
I0920 00:01:51.849074 139893447890752 spec.py:320] Evaluating on the training split.
I0920 00:01:54.829862 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 00:05:36.166019 139893447890752 spec.py:332] Evaluating on the validation split.
I0920 00:05:38.813104 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 00:08:41.822992 139893447890752 spec.py:348] Evaluating on the test split.
I0920 00:08:44.500972 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 00:11:44.735358 139893447890752 submission_runner.py:376] Time since start: 37989.31s, 	Step: 63567, 	{'train/accuracy': 0.6747167110443115, 'train/loss': 1.50295889377594, 'train/bleu': 33.625067372427374, 'validation/accuracy': 0.6816158294677734, 'validation/loss': 1.450143814086914, 'validation/bleu': 29.592450712162044, 'validation/num_examples': 3000, 'test/accuracy': 0.6963686347007751, 'test/loss': 1.3518720865249634, 'test/bleu': 29.471091336196636, 'test/num_examples': 3003, 'score': 22728.77717614174, 'total_duration': 37989.31209397316, 'accumulated_submission_time': 22728.77717614174, 'accumulated_eval_time': 15258.857730865479, 'accumulated_logging_time': 0.7335500717163086}
I0920 00:11:44.752998 139716895373056 logging_writer.py:48] [63567] accumulated_eval_time=15258.857731, accumulated_logging_time=0.733550, accumulated_submission_time=22728.777176, global_step=63567, preemption_count=0, score=22728.777176, test/accuracy=0.696369, test/bleu=29.471091, test/loss=1.351872, test/num_examples=3003, total_duration=37989.312094, train/accuracy=0.674717, train/bleu=33.625067, train/loss=1.502959, validation/accuracy=0.681616, validation/bleu=29.592451, validation/loss=1.450144, validation/num_examples=3000
I0920 00:14:19.561733 139716903765760 logging_writer.py:48] [64000] global_step=64000, grad_norm=0.1920813024044037, loss=1.5896722078323364
I0920 00:17:17.939237 139716895373056 logging_writer.py:48] [64500] global_step=64500, grad_norm=0.20019373297691345, loss=1.5787856578826904
I0920 00:20:16.311380 139716903765760 logging_writer.py:48] [65000] global_step=65000, grad_norm=0.2004796266555786, loss=1.641333818435669
I0920 00:23:14.722764 139716895373056 logging_writer.py:48] [65500] global_step=65500, grad_norm=0.20334088802337646, loss=1.659206509590149
I0920 00:25:44.742884 139893447890752 spec.py:320] Evaluating on the training split.
I0920 00:25:47.731211 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 00:29:22.321371 139893447890752 spec.py:332] Evaluating on the validation split.
I0920 00:29:24.953405 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 00:31:57.754996 139893447890752 spec.py:348] Evaluating on the test split.
I0920 00:32:00.443586 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 00:34:12.793388 139893447890752 submission_runner.py:376] Time since start: 39337.37s, 	Step: 65922, 	{'train/accuracy': 0.6708354353904724, 'train/loss': 1.5267027616500854, 'train/bleu': 33.43694136803427, 'validation/accuracy': 0.6823474168777466, 'validation/loss': 1.4454008340835571, 'validation/bleu': 29.76893615295852, 'validation/num_examples': 3000, 'test/accuracy': 0.7004357576370239, 'test/loss': 1.3402730226516724, 'test/bleu': 29.920619656632354, 'test/num_examples': 3003, 'score': 23568.720961093903, 'total_duration': 39337.3701171875, 'accumulated_submission_time': 23568.720961093903, 'accumulated_eval_time': 15766.90819811821, 'accumulated_logging_time': 0.7617778778076172}
I0920 00:34:12.812560 139716903765760 logging_writer.py:48] [65922] accumulated_eval_time=15766.908198, accumulated_logging_time=0.761778, accumulated_submission_time=23568.720961, global_step=65922, preemption_count=0, score=23568.720961, test/accuracy=0.700436, test/bleu=29.920620, test/loss=1.340273, test/num_examples=3003, total_duration=39337.370117, train/accuracy=0.670835, train/bleu=33.436941, train/loss=1.526703, validation/accuracy=0.682347, validation/bleu=29.768936, validation/loss=1.445401, validation/num_examples=3000
I0920 00:34:41.042002 139716895373056 logging_writer.py:48] [66000] global_step=66000, grad_norm=0.19221995770931244, loss=1.5669152736663818
I0920 00:37:39.566709 139716903765760 logging_writer.py:48] [66500] global_step=66500, grad_norm=0.2069629579782486, loss=1.619910717010498
I0920 00:40:37.991107 139716895373056 logging_writer.py:48] [67000] global_step=67000, grad_norm=0.20407545566558838, loss=1.6979267597198486
I0920 00:43:36.414881 139716903765760 logging_writer.py:48] [67500] global_step=67500, grad_norm=0.20229369401931763, loss=1.5942431688308716
I0920 00:46:34.839378 139716895373056 logging_writer.py:48] [68000] global_step=68000, grad_norm=0.20547129213809967, loss=1.518885612487793
I0920 00:48:13.093957 139893447890752 spec.py:320] Evaluating on the training split.
I0920 00:48:16.083755 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 00:51:49.481597 139893447890752 spec.py:332] Evaluating on the validation split.
I0920 00:51:52.103097 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 00:54:08.194219 139893447890752 spec.py:348] Evaluating on the test split.
I0920 00:54:10.883438 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 00:56:41.602018 139893447890752 submission_runner.py:376] Time since start: 40686.18s, 	Step: 68277, 	{'train/accuracy': 0.6709253787994385, 'train/loss': 1.5292772054672241, 'train/bleu': 33.54533099395434, 'validation/accuracy': 0.685050368309021, 'validation/loss': 1.4331506490707397, 'validation/bleu': 30.100808382372218, 'validation/num_examples': 3000, 'test/accuracy': 0.701109766960144, 'test/loss': 1.3304002285003662, 'test/bleu': 29.975857775453964, 'test/num_examples': 3003, 'score': 24408.957591295242, 'total_duration': 40686.17873048782, 'accumulated_submission_time': 24408.957591295242, 'accumulated_eval_time': 16275.41618680954, 'accumulated_logging_time': 0.7903876304626465}
I0920 00:56:41.620616 139716903765760 logging_writer.py:48] [68277] accumulated_eval_time=16275.416187, accumulated_logging_time=0.790388, accumulated_submission_time=24408.957591, global_step=68277, preemption_count=0, score=24408.957591, test/accuracy=0.701110, test/bleu=29.975858, test/loss=1.330400, test/num_examples=3003, total_duration=40686.178730, train/accuracy=0.670925, train/bleu=33.545331, train/loss=1.529277, validation/accuracy=0.685050, validation/bleu=30.100808, validation/loss=1.433151, validation/num_examples=3000
I0920 00:58:01.566358 139716895373056 logging_writer.py:48] [68500] global_step=68500, grad_norm=0.20602020621299744, loss=1.6745455265045166
I0920 01:00:59.985300 139716903765760 logging_writer.py:48] [69000] global_step=69000, grad_norm=0.27457547187805176, loss=1.5811457633972168
I0920 01:03:58.400869 139716895373056 logging_writer.py:48] [69500] global_step=69500, grad_norm=0.19724851846694946, loss=1.5922088623046875
I0920 01:06:56.831589 139716903765760 logging_writer.py:48] [70000] global_step=70000, grad_norm=0.2158367931842804, loss=1.6402920484542847
I0920 01:09:55.198865 139716895373056 logging_writer.py:48] [70500] global_step=70500, grad_norm=0.1964998096227646, loss=1.6177235841751099
I0920 01:10:41.664365 139893447890752 spec.py:320] Evaluating on the training split.
I0920 01:10:44.646646 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 01:14:59.859272 139893447890752 spec.py:332] Evaluating on the validation split.
I0920 01:15:02.494684 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 01:18:18.667281 139893447890752 spec.py:348] Evaluating on the test split.
I0920 01:18:21.364466 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 01:21:36.081865 139893447890752 submission_runner.py:376] Time since start: 42180.66s, 	Step: 70632, 	{'train/accuracy': 0.6786221265792847, 'train/loss': 1.4771839380264282, 'train/bleu': 34.154001402245406, 'validation/accuracy': 0.6856207251548767, 'validation/loss': 1.42377507686615, 'validation/bleu': 29.803221863871073, 'validation/num_examples': 3000, 'test/accuracy': 0.7014119029045105, 'test/loss': 1.3253968954086304, 'test/bleu': 29.96280475058441, 'test/num_examples': 3003, 'score': 25248.954988479614, 'total_duration': 42180.658596515656, 'accumulated_submission_time': 25248.954988479614, 'accumulated_eval_time': 16929.83368253708, 'accumulated_logging_time': 0.8197112083435059}
I0920 01:21:36.101428 139716903765760 logging_writer.py:48] [70632] accumulated_eval_time=16929.833683, accumulated_logging_time=0.819711, accumulated_submission_time=25248.954988, global_step=70632, preemption_count=0, score=25248.954988, test/accuracy=0.701412, test/bleu=29.962805, test/loss=1.325397, test/num_examples=3003, total_duration=42180.658597, train/accuracy=0.678622, train/bleu=34.154001, train/loss=1.477184, validation/accuracy=0.685621, validation/bleu=29.803222, validation/loss=1.423775, validation/num_examples=3000
I0920 01:23:47.709794 139716895373056 logging_writer.py:48] [71000] global_step=71000, grad_norm=0.20402555167675018, loss=1.5596383810043335
I0920 01:26:46.075116 139716903765760 logging_writer.py:48] [71500] global_step=71500, grad_norm=0.20845955610275269, loss=1.5476391315460205
I0920 01:29:44.513340 139716895373056 logging_writer.py:48] [72000] global_step=72000, grad_norm=0.20537668466567993, loss=1.5956394672393799
I0920 01:32:42.971255 139716903765760 logging_writer.py:48] [72500] global_step=72500, grad_norm=0.1976221352815628, loss=1.5405852794647217
I0920 01:35:36.414542 139893447890752 spec.py:320] Evaluating on the training split.
I0920 01:35:39.403259 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 01:38:45.187558 139893447890752 spec.py:332] Evaluating on the validation split.
I0920 01:38:47.820880 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 01:41:33.296075 139893447890752 spec.py:348] Evaluating on the test split.
I0920 01:41:35.993317 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 01:44:36.237608 139893447890752 submission_runner.py:376] Time since start: 43560.81s, 	Step: 72988, 	{'train/accuracy': 0.6799107193946838, 'train/loss': 1.4843158721923828, 'train/bleu': 33.88770682935594, 'validation/accuracy': 0.6877533793449402, 'validation/loss': 1.4163566827774048, 'validation/bleu': 30.27833681555915, 'validation/num_examples': 3000, 'test/accuracy': 0.7038870453834534, 'test/loss': 1.3102107048034668, 'test/bleu': 30.37073882439016, 'test/num_examples': 3003, 'score': 26089.221060991287, 'total_duration': 43560.81432199478, 'accumulated_submission_time': 26089.221060991287, 'accumulated_eval_time': 17469.656693696976, 'accumulated_logging_time': 0.8507094383239746}
I0920 01:44:36.255510 139716895373056 logging_writer.py:48] [72988] accumulated_eval_time=17469.656694, accumulated_logging_time=0.850709, accumulated_submission_time=26089.221061, global_step=72988, preemption_count=0, score=26089.221061, test/accuracy=0.703887, test/bleu=30.370739, test/loss=1.310211, test/num_examples=3003, total_duration=43560.814322, train/accuracy=0.679911, train/bleu=33.887707, train/loss=1.484316, validation/accuracy=0.687753, validation/bleu=30.278337, validation/loss=1.416357, validation/num_examples=3000
I0920 01:44:40.905537 139716903765760 logging_writer.py:48] [73000] global_step=73000, grad_norm=0.20062796771526337, loss=1.5588055849075317
I0920 01:47:39.250508 139716895373056 logging_writer.py:48] [73500] global_step=73500, grad_norm=0.1949268877506256, loss=1.5700217485427856
I0920 01:50:37.669044 139716903765760 logging_writer.py:48] [74000] global_step=74000, grad_norm=0.20369058847427368, loss=1.5736409425735474
I0920 01:53:36.106827 139716895373056 logging_writer.py:48] [74500] global_step=74500, grad_norm=0.2253679633140564, loss=1.6084578037261963
I0920 01:56:34.522309 139716903765760 logging_writer.py:48] [75000] global_step=75000, grad_norm=0.21017767488956451, loss=1.5366945266723633
I0920 01:58:36.303898 139893447890752 spec.py:320] Evaluating on the training split.
I0920 01:58:39.289084 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 02:02:10.930660 139893447890752 spec.py:332] Evaluating on the validation split.
I0920 02:02:13.563488 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 02:05:03.999869 139893447890752 spec.py:348] Evaluating on the test split.
I0920 02:05:06.695172 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 02:08:10.328131 139893447890752 submission_runner.py:376] Time since start: 44974.90s, 	Step: 75343, 	{'train/accuracy': 0.6882423758506775, 'train/loss': 1.4102529287338257, 'train/bleu': 34.70146480705934, 'validation/accuracy': 0.6881377696990967, 'validation/loss': 1.4110521078109741, 'validation/bleu': 30.37036569512352, 'validation/num_examples': 3000, 'test/accuracy': 0.7033060193061829, 'test/loss': 1.3084625005722046, 'test/bleu': 30.152400108210642, 'test/num_examples': 3003, 'score': 26929.22295165062, 'total_duration': 44974.904829502106, 'accumulated_submission_time': 26929.22295165062, 'accumulated_eval_time': 18043.6808552742, 'accumulated_logging_time': 0.8794536590576172}
I0920 02:08:10.347340 139716895373056 logging_writer.py:48] [75343] accumulated_eval_time=18043.680855, accumulated_logging_time=0.879454, accumulated_submission_time=26929.222952, global_step=75343, preemption_count=0, score=26929.222952, test/accuracy=0.703306, test/bleu=30.152400, test/loss=1.308463, test/num_examples=3003, total_duration=44974.904830, train/accuracy=0.688242, train/bleu=34.701465, train/loss=1.410253, validation/accuracy=0.688138, validation/bleu=30.370366, validation/loss=1.411052, validation/num_examples=3000
I0920 02:09:06.730563 139716903765760 logging_writer.py:48] [75500] global_step=75500, grad_norm=0.21649445593357086, loss=1.6189417839050293
I0920 02:12:05.215157 139716895373056 logging_writer.py:48] [76000] global_step=76000, grad_norm=0.2159355878829956, loss=1.5645455121994019
I0920 02:15:03.692817 139716903765760 logging_writer.py:48] [76500] global_step=76500, grad_norm=0.21425671875476837, loss=1.5169111490249634
I0920 02:18:02.092200 139716895373056 logging_writer.py:48] [77000] global_step=77000, grad_norm=0.20626987516880035, loss=1.4961564540863037
I0920 02:21:00.526627 139716903765760 logging_writer.py:48] [77500] global_step=77500, grad_norm=0.2143009901046753, loss=1.506712794303894
I0920 02:22:10.567800 139893447890752 spec.py:320] Evaluating on the training split.
I0920 02:22:13.555464 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 02:26:32.892374 139893447890752 spec.py:332] Evaluating on the validation split.
I0920 02:26:35.530611 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 02:30:23.460822 139893447890752 spec.py:348] Evaluating on the test split.
I0920 02:30:26.145901 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 02:34:38.948430 139893447890752 submission_runner.py:376] Time since start: 46563.53s, 	Step: 77698, 	{'train/accuracy': 0.6838017702102661, 'train/loss': 1.4448941946029663, 'train/bleu': 34.31984224041812, 'validation/accuracy': 0.6899976134300232, 'validation/loss': 1.40022611618042, 'validation/bleu': 30.344190337597727, 'validation/num_examples': 3000, 'test/accuracy': 0.7067573070526123, 'test/loss': 1.2971179485321045, 'test/bleu': 30.313982933082816, 'test/num_examples': 3003, 'score': 27769.396897792816, 'total_duration': 46563.525133132935, 'accumulated_submission_time': 27769.396897792816, 'accumulated_eval_time': 18792.061408758163, 'accumulated_logging_time': 0.9094645977020264}
I0920 02:34:38.967295 139716895373056 logging_writer.py:48] [77698] accumulated_eval_time=18792.061409, accumulated_logging_time=0.909465, accumulated_submission_time=27769.396898, global_step=77698, preemption_count=0, score=27769.396898, test/accuracy=0.706757, test/bleu=30.313983, test/loss=1.297118, test/num_examples=3003, total_duration=46563.525133, train/accuracy=0.683802, train/bleu=34.319842, train/loss=1.444894, validation/accuracy=0.689998, validation/bleu=30.344190, validation/loss=1.400226, validation/num_examples=3000
I0920 02:36:27.050749 139716903765760 logging_writer.py:48] [78000] global_step=78000, grad_norm=0.2110947072505951, loss=1.571051836013794
I0920 02:39:25.539592 139716895373056 logging_writer.py:48] [78500] global_step=78500, grad_norm=0.2068146914243698, loss=1.5205748081207275
I0920 02:42:24.044771 139716903765760 logging_writer.py:48] [79000] global_step=79000, grad_norm=0.23341551423072815, loss=1.5766323804855347
I0920 02:45:22.616348 139716895373056 logging_writer.py:48] [79500] global_step=79500, grad_norm=0.22761669754981995, loss=1.5510674715042114
I0920 02:48:21.076706 139716903765760 logging_writer.py:48] [80000] global_step=80000, grad_norm=0.2156555950641632, loss=1.5276609659194946
I0920 02:48:39.016271 139893447890752 spec.py:320] Evaluating on the training split.
I0920 02:48:42.000551 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 02:52:38.388718 139893447890752 spec.py:332] Evaluating on the validation split.
I0920 02:52:41.022503 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 02:55:33.599398 139893447890752 spec.py:348] Evaluating on the test split.
I0920 02:55:36.292996 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 02:58:40.325161 139893447890752 submission_runner.py:376] Time since start: 48004.90s, 	Step: 80052, 	{'train/accuracy': 0.6808838844299316, 'train/loss': 1.4630376100540161, 'train/bleu': 34.63216915381069, 'validation/accuracy': 0.6903820037841797, 'validation/loss': 1.3929818868637085, 'validation/bleu': 30.636862740860767, 'validation/num_examples': 3000, 'test/accuracy': 0.7079774737358093, 'test/loss': 1.2864859104156494, 'test/bleu': 30.806089332451336, 'test/num_examples': 3003, 'score': 28609.3996219635, 'total_duration': 48004.901880025864, 'accumulated_submission_time': 28609.3996219635, 'accumulated_eval_time': 19393.37023305893, 'accumulated_logging_time': 0.9397079944610596}
I0920 02:58:40.343875 139716895373056 logging_writer.py:48] [80052] accumulated_eval_time=19393.370233, accumulated_logging_time=0.939708, accumulated_submission_time=28609.399622, global_step=80052, preemption_count=0, score=28609.399622, test/accuracy=0.707977, test/bleu=30.806089, test/loss=1.286486, test/num_examples=3003, total_duration=48004.901880, train/accuracy=0.680884, train/bleu=34.632169, train/loss=1.463038, validation/accuracy=0.690382, validation/bleu=30.636863, validation/loss=1.392982, validation/num_examples=3000
I0920 03:01:20.460857 139716903765760 logging_writer.py:48] [80500] global_step=80500, grad_norm=0.20949006080627441, loss=1.5110034942626953
I0920 03:04:18.846983 139716895373056 logging_writer.py:48] [81000] global_step=81000, grad_norm=0.2123430222272873, loss=1.5111620426177979
I0920 03:07:17.187439 139716903765760 logging_writer.py:48] [81500] global_step=81500, grad_norm=0.21807055175304413, loss=1.39366614818573
I0920 03:10:15.583553 139716895373056 logging_writer.py:48] [82000] global_step=82000, grad_norm=0.2097085565328598, loss=1.5008434057235718
I0920 03:12:40.442792 139893447890752 spec.py:320] Evaluating on the training split.
I0920 03:12:43.425023 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 03:16:46.198216 139893447890752 spec.py:332] Evaluating on the validation split.
I0920 03:16:48.831822 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 03:19:50.491346 139893447890752 spec.py:348] Evaluating on the test split.
I0920 03:19:53.204455 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 03:23:18.411678 139893447890752 submission_runner.py:376] Time since start: 49482.99s, 	Step: 82408, 	{'train/accuracy': 0.6884999871253967, 'train/loss': 1.4175782203674316, 'train/bleu': 34.719468404490534, 'validation/accuracy': 0.691299557685852, 'validation/loss': 1.391406536102295, 'validation/bleu': 30.585640606790022, 'validation/num_examples': 3000, 'test/accuracy': 0.708291232585907, 'test/loss': 1.2817376852035522, 'test/bleu': 30.433517564510232, 'test/num_examples': 3003, 'score': 29449.451961755753, 'total_duration': 49482.98837900162, 'accumulated_submission_time': 29449.451961755753, 'accumulated_eval_time': 20031.339049100876, 'accumulated_logging_time': 0.9696953296661377}
I0920 03:23:18.430788 139716903765760 logging_writer.py:48] [82408] accumulated_eval_time=20031.339049, accumulated_logging_time=0.969695, accumulated_submission_time=29449.451962, global_step=82408, preemption_count=0, score=29449.451962, test/accuracy=0.708291, test/bleu=30.433518, test/loss=1.281738, test/num_examples=3003, total_duration=49482.988379, train/accuracy=0.688500, train/bleu=34.719468, train/loss=1.417578, validation/accuracy=0.691300, validation/bleu=30.585641, validation/loss=1.391407, validation/num_examples=3000
I0920 03:23:51.579391 139716895373056 logging_writer.py:48] [82500] global_step=82500, grad_norm=0.21976129710674286, loss=1.5674083232879639
I0920 03:26:49.933825 139716903765760 logging_writer.py:48] [83000] global_step=83000, grad_norm=0.22444181144237518, loss=1.497787594795227
I0920 03:29:48.336301 139716895373056 logging_writer.py:48] [83500] global_step=83500, grad_norm=0.2134154587984085, loss=1.533493161201477
I0920 03:32:46.738089 139716903765760 logging_writer.py:48] [84000] global_step=84000, grad_norm=0.22106289863586426, loss=1.542667269706726
I0920 03:35:45.124410 139716895373056 logging_writer.py:48] [84500] global_step=84500, grad_norm=0.20427772402763367, loss=1.4804362058639526
I0920 03:37:18.674887 139893447890752 spec.py:320] Evaluating on the training split.
I0920 03:37:21.672161 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 03:41:51.246253 139893447890752 spec.py:332] Evaluating on the validation split.
I0920 03:41:53.883672 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 03:45:45.046727 139893447890752 spec.py:348] Evaluating on the test split.
I0920 03:45:47.736633 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 03:50:00.919751 139893447890752 submission_runner.py:376] Time since start: 51085.50s, 	Step: 84764, 	{'train/accuracy': 0.6859747767448425, 'train/loss': 1.4265786409378052, 'train/bleu': 34.6070502126212, 'validation/accuracy': 0.6927130222320557, 'validation/loss': 1.3863006830215454, 'validation/bleu': 29.959039985920395, 'validation/num_examples': 3000, 'test/accuracy': 0.7108244895935059, 'test/loss': 1.274747610092163, 'test/bleu': 30.843567367629213, 'test/num_examples': 3003, 'score': 30289.650393009186, 'total_duration': 51085.49648594856, 'accumulated_submission_time': 30289.650393009186, 'accumulated_eval_time': 20793.583874464035, 'accumulated_logging_time': 0.9989745616912842}
I0920 03:50:00.938806 139716903765760 logging_writer.py:48] [84764] accumulated_eval_time=20793.583874, accumulated_logging_time=0.998975, accumulated_submission_time=30289.650393, global_step=84764, preemption_count=0, score=30289.650393, test/accuracy=0.710824, test/bleu=30.843567, test/loss=1.274748, test/num_examples=3003, total_duration=51085.496486, train/accuracy=0.685975, train/bleu=34.607050, train/loss=1.426579, validation/accuracy=0.692713, validation/bleu=29.959040, validation/loss=1.386301, validation/num_examples=3000
I0920 03:51:25.441328 139716895373056 logging_writer.py:48] [85000] global_step=85000, grad_norm=0.22586339712142944, loss=1.5728648900985718
I0920 03:54:23.814866 139716903765760 logging_writer.py:48] [85500] global_step=85500, grad_norm=0.21932771801948547, loss=1.533845067024231
I0920 03:57:22.227954 139716895373056 logging_writer.py:48] [86000] global_step=86000, grad_norm=0.2168513387441635, loss=1.601300597190857
I0920 04:00:20.629968 139716903765760 logging_writer.py:48] [86500] global_step=86500, grad_norm=0.21878793835639954, loss=1.5594661235809326
I0920 04:03:19.028155 139716895373056 logging_writer.py:48] [87000] global_step=87000, grad_norm=0.22624072432518005, loss=1.4164170026779175
I0920 04:04:01.190905 139893447890752 spec.py:320] Evaluating on the training split.
I0920 04:04:04.201328 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 04:08:10.587290 139893447890752 spec.py:332] Evaluating on the validation split.
I0920 04:08:13.227721 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 04:11:18.136204 139893447890752 spec.py:348] Evaluating on the test split.
I0920 04:11:20.838827 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 04:14:42.016812 139893447890752 submission_runner.py:376] Time since start: 52566.59s, 	Step: 87120, 	{'train/accuracy': 0.6864790320396423, 'train/loss': 1.4287083148956299, 'train/bleu': 34.93763426245714, 'validation/accuracy': 0.6924898624420166, 'validation/loss': 1.3810315132141113, 'validation/bleu': 30.55028821593838, 'validation/num_examples': 3000, 'test/accuracy': 0.7108826041221619, 'test/loss': 1.272445559501648, 'test/bleu': 31.11997017345376, 'test/num_examples': 3003, 'score': 31129.857532978058, 'total_duration': 52566.59352707863, 'accumulated_submission_time': 31129.857532978058, 'accumulated_eval_time': 21434.409713983536, 'accumulated_logging_time': 1.0275912284851074}
I0920 04:14:42.035531 139716903765760 logging_writer.py:48] [87120] accumulated_eval_time=21434.409714, accumulated_logging_time=1.027591, accumulated_submission_time=31129.857533, global_step=87120, preemption_count=0, score=31129.857533, test/accuracy=0.710883, test/bleu=31.119970, test/loss=1.272446, test/num_examples=3003, total_duration=52566.593527, train/accuracy=0.686479, train/bleu=34.937634, train/loss=1.428708, validation/accuracy=0.692490, validation/bleu=30.550288, validation/loss=1.381032, validation/num_examples=3000
I0920 04:16:57.999165 139716895373056 logging_writer.py:48] [87500] global_step=87500, grad_norm=0.20844343304634094, loss=1.4421004056930542
I0920 04:19:56.475950 139716903765760 logging_writer.py:48] [88000] global_step=88000, grad_norm=0.21563982963562012, loss=1.469509243965149
I0920 04:22:55.005350 139716895373056 logging_writer.py:48] [88500] global_step=88500, grad_norm=0.22870692610740662, loss=1.43217933177948
I0920 04:25:53.482842 139716903765760 logging_writer.py:48] [89000] global_step=89000, grad_norm=0.22476652264595032, loss=1.43388032913208
I0920 04:28:42.074985 139893447890752 spec.py:320] Evaluating on the training split.
I0920 04:28:45.063226 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 04:33:04.180268 139893447890752 spec.py:332] Evaluating on the validation split.
I0920 04:33:06.823503 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 04:36:22.289671 139893447890752 spec.py:348] Evaluating on the test split.
I0920 04:36:24.981344 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 04:40:10.002556 139893447890752 submission_runner.py:376] Time since start: 54094.58s, 	Step: 89474, 	{'train/accuracy': 0.6920066475868225, 'train/loss': 1.4008373022079468, 'train/bleu': 35.18598370051251, 'validation/accuracy': 0.6944488883018494, 'validation/loss': 1.3764303922653198, 'validation/bleu': 30.69497641932349, 'validation/num_examples': 3000, 'test/accuracy': 0.711544930934906, 'test/loss': 1.2680366039276123, 'test/bleu': 30.909970851213476, 'test/num_examples': 3003, 'score': 31969.852482795715, 'total_duration': 54094.579277038574, 'accumulated_submission_time': 31969.852482795715, 'accumulated_eval_time': 22122.33724284172, 'accumulated_logging_time': 1.0557479858398438}
I0920 04:40:10.022172 139716895373056 logging_writer.py:48] [89474] accumulated_eval_time=22122.337243, accumulated_logging_time=1.055748, accumulated_submission_time=31969.852483, global_step=89474, preemption_count=0, score=31969.852483, test/accuracy=0.711545, test/bleu=30.909971, test/loss=1.268037, test/num_examples=3003, total_duration=54094.579277, train/accuracy=0.692007, train/bleu=35.185984, train/loss=1.400837, validation/accuracy=0.694449, validation/bleu=30.694976, validation/loss=1.376430, validation/num_examples=3000
I0920 04:40:19.646232 139716903765760 logging_writer.py:48] [89500] global_step=89500, grad_norm=0.22594888508319855, loss=1.5272819995880127
I0920 04:43:18.032906 139716895373056 logging_writer.py:48] [90000] global_step=90000, grad_norm=0.2137283980846405, loss=1.483867883682251
I0920 04:46:16.458864 139716903765760 logging_writer.py:48] [90500] global_step=90500, grad_norm=0.21276232600212097, loss=1.4465159177780151
I0920 04:49:14.845706 139716895373056 logging_writer.py:48] [91000] global_step=91000, grad_norm=0.22372379899024963, loss=1.4571064710617065
I0920 04:52:13.265904 139716903765760 logging_writer.py:48] [91500] global_step=91500, grad_norm=0.21030378341674805, loss=1.431943416595459
I0920 04:54:10.030390 139893447890752 spec.py:320] Evaluating on the training split.
I0920 04:54:13.021614 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 04:58:24.295583 139893447890752 spec.py:332] Evaluating on the validation split.
I0920 04:58:26.937410 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 05:01:56.430896 139893447890752 spec.py:348] Evaluating on the test split.
I0920 05:01:59.112169 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 05:05:50.925576 139893447890752 submission_runner.py:376] Time since start: 55635.50s, 	Step: 91829, 	{'train/accuracy': 0.6896260976791382, 'train/loss': 1.4150826930999756, 'train/bleu': 35.45518595890269, 'validation/accuracy': 0.6950068473815918, 'validation/loss': 1.373129963874817, 'validation/bleu': 30.777306216806316, 'validation/num_examples': 3000, 'test/accuracy': 0.7132531404495239, 'test/loss': 1.2620350122451782, 'test/bleu': 31.176622263884134, 'test/num_examples': 3003, 'score': 32809.814227342606, 'total_duration': 55635.502299547195, 'accumulated_submission_time': 32809.814227342606, 'accumulated_eval_time': 22823.23236966133, 'accumulated_logging_time': 1.086176872253418}
I0920 05:05:50.945041 139716895373056 logging_writer.py:48] [91829] accumulated_eval_time=22823.232370, accumulated_logging_time=1.086177, accumulated_submission_time=32809.814227, global_step=91829, preemption_count=0, score=32809.814227, test/accuracy=0.713253, test/bleu=31.176622, test/loss=1.262035, test/num_examples=3003, total_duration=55635.502300, train/accuracy=0.689626, train/bleu=35.455186, train/loss=1.415083, validation/accuracy=0.695007, validation/bleu=30.777306, validation/loss=1.373130, validation/num_examples=3000
I0920 05:06:52.303967 139716903765760 logging_writer.py:48] [92000] global_step=92000, grad_norm=0.23559243977069855, loss=1.4944936037063599
I0920 05:09:50.673835 139716895373056 logging_writer.py:48] [92500] global_step=92500, grad_norm=0.22518083453178406, loss=1.5299071073532104
I0920 05:12:49.079786 139716903765760 logging_writer.py:48] [93000] global_step=93000, grad_norm=0.2233356237411499, loss=1.5335396528244019
I0920 05:15:47.462496 139716895373056 logging_writer.py:48] [93500] global_step=93500, grad_norm=0.2244902402162552, loss=1.5386788845062256
I0920 05:18:45.910574 139716903765760 logging_writer.py:48] [94000] global_step=94000, grad_norm=0.2233993113040924, loss=1.4721596240997314
I0920 05:19:50.985134 139893447890752 spec.py:320] Evaluating on the training split.
I0920 05:19:53.974627 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 05:23:59.902368 139893447890752 spec.py:332] Evaluating on the validation split.
I0920 05:24:02.541083 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 05:26:56.622962 139893447890752 spec.py:348] Evaluating on the test split.
I0920 05:26:59.324245 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 05:30:38.414918 139893447890752 submission_runner.py:376] Time since start: 57122.99s, 	Step: 94184, 	{'train/accuracy': 0.6916075944900513, 'train/loss': 1.397290825843811, 'train/bleu': 35.39453109228952, 'validation/accuracy': 0.6952424645423889, 'validation/loss': 1.3712801933288574, 'validation/bleu': 30.946564705441354, 'validation/num_examples': 3000, 'test/accuracy': 0.7133228778839111, 'test/loss': 1.2604559659957886, 'test/bleu': 31.186716763294925, 'test/num_examples': 3003, 'score': 33649.809299230576, 'total_duration': 57122.99164867401, 'accumulated_submission_time': 33649.809299230576, 'accumulated_eval_time': 23470.66210770607, 'accumulated_logging_time': 1.1148681640625}
I0920 05:30:38.434294 139716895373056 logging_writer.py:48] [94184] accumulated_eval_time=23470.662108, accumulated_logging_time=1.114868, accumulated_submission_time=33649.809299, global_step=94184, preemption_count=0, score=33649.809299, test/accuracy=0.713323, test/bleu=31.186717, test/loss=1.260456, test/num_examples=3003, total_duration=57122.991649, train/accuracy=0.691608, train/bleu=35.394531, train/loss=1.397291, validation/accuracy=0.695242, validation/bleu=30.946565, validation/loss=1.371280, validation/num_examples=3000
I0920 05:32:31.463354 139716903765760 logging_writer.py:48] [94500] global_step=94500, grad_norm=0.2049292027950287, loss=1.4702684879302979
I0920 05:35:29.864557 139716895373056 logging_writer.py:48] [95000] global_step=95000, grad_norm=0.21568186581134796, loss=1.515523076057434
I0920 05:38:28.287053 139716903765760 logging_writer.py:48] [95500] global_step=95500, grad_norm=0.2292514443397522, loss=1.4211523532867432
I0920 05:41:26.747502 139716895373056 logging_writer.py:48] [96000] global_step=96000, grad_norm=0.20732039213180542, loss=1.3534433841705322
I0920 05:44:25.224351 139716903765760 logging_writer.py:48] [96500] global_step=96500, grad_norm=0.22469936311244965, loss=1.4559953212738037
I0920 05:44:38.512396 139893447890752 spec.py:320] Evaluating on the training split.
I0920 05:44:41.489257 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 05:48:38.289752 139893447890752 spec.py:332] Evaluating on the validation split.
I0920 05:48:40.915947 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 05:51:56.526651 139893447890752 spec.py:348] Evaluating on the test split.
I0920 05:51:59.208755 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 05:55:52.479208 139893447890752 submission_runner.py:376] Time since start: 58637.06s, 	Step: 96539, 	{'train/accuracy': 0.6916161775588989, 'train/loss': 1.4004050493240356, 'train/bleu': 35.15158742799602, 'validation/accuracy': 0.6955276131629944, 'validation/loss': 1.3707915544509888, 'validation/bleu': 30.686707997506677, 'validation/num_examples': 3000, 'test/accuracy': 0.7132067084312439, 'test/loss': 1.2603013515472412, 'test/bleu': 31.18369207715012, 'test/num_examples': 3003, 'score': 34489.842451334, 'total_duration': 58637.05592226982, 'accumulated_submission_time': 34489.842451334, 'accumulated_eval_time': 24144.62884926796, 'accumulated_logging_time': 1.1436142921447754}
I0920 05:55:52.498688 139716895373056 logging_writer.py:48] [96539] accumulated_eval_time=24144.628849, accumulated_logging_time=1.143614, accumulated_submission_time=34489.842451, global_step=96539, preemption_count=0, score=34489.842451, test/accuracy=0.713207, test/bleu=31.183692, test/loss=1.260301, test/num_examples=3003, total_duration=58637.055922, train/accuracy=0.691616, train/bleu=35.151587, train/loss=1.400405, validation/accuracy=0.695528, validation/bleu=30.686708, validation/loss=1.370792, validation/num_examples=3000
I0920 05:58:37.322157 139716903765760 logging_writer.py:48] [97000] global_step=97000, grad_norm=0.21888108551502228, loss=1.4472742080688477
I0920 06:01:35.747852 139716895373056 logging_writer.py:48] [97500] global_step=97500, grad_norm=0.22244501113891602, loss=1.4626445770263672
I0920 06:04:34.228801 139716903765760 logging_writer.py:48] [98000] global_step=98000, grad_norm=0.2114637792110443, loss=1.4512033462524414
I0920 06:07:32.661556 139716895373056 logging_writer.py:48] [98500] global_step=98500, grad_norm=0.2143513560295105, loss=1.4351013898849487
I0920 06:09:52.634881 139893447890752 spec.py:320] Evaluating on the training split.
I0920 06:09:55.622280 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 06:14:11.326979 139893447890752 spec.py:332] Evaluating on the validation split.
I0920 06:14:13.973102 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 06:17:25.102681 139893447890752 spec.py:348] Evaluating on the test split.
I0920 06:17:27.785859 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 06:21:20.269074 139893447890752 submission_runner.py:376] Time since start: 60164.85s, 	Step: 98894, 	{'train/accuracy': 0.6908577084541321, 'train/loss': 1.405752420425415, 'train/bleu': 35.49042967712508, 'validation/accuracy': 0.6957508325576782, 'validation/loss': 1.3702772855758667, 'validation/bleu': 30.82650066258248, 'validation/num_examples': 3000, 'test/accuracy': 0.7133345007896423, 'test/loss': 1.2597142457962036, 'test/bleu': 31.220260054630778, 'test/num_examples': 3003, 'score': 35329.93285369873, 'total_duration': 60164.84579181671, 'accumulated_submission_time': 35329.93285369873, 'accumulated_eval_time': 24832.26297569275, 'accumulated_logging_time': 1.1734983921051025}
I0920 06:21:20.289867 139716903765760 logging_writer.py:48] [98894] accumulated_eval_time=24832.262976, accumulated_logging_time=1.173498, accumulated_submission_time=35329.932854, global_step=98894, preemption_count=0, score=35329.932854, test/accuracy=0.713335, test/bleu=31.220260, test/loss=1.259714, test/num_examples=3003, total_duration=60164.845792, train/accuracy=0.690858, train/bleu=35.490430, train/loss=1.405752, validation/accuracy=0.695751, validation/bleu=30.826501, validation/loss=1.370277, validation/num_examples=3000
I0920 06:21:58.451693 139716895373056 logging_writer.py:48] [99000] global_step=99000, grad_norm=0.22481252253055573, loss=1.4352554082870483
I0920 06:24:56.912900 139716903765760 logging_writer.py:48] [99500] global_step=99500, grad_norm=0.2141299545764923, loss=1.5127485990524292
I0920 06:27:54.747677 139893447890752 spec.py:320] Evaluating on the training split.
I0920 06:27:57.731931 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 06:32:09.887652 139893447890752 spec.py:332] Evaluating on the validation split.
I0920 06:32:12.522065 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 06:35:25.275665 139893447890752 spec.py:348] Evaluating on the test split.
I0920 06:35:27.975980 139893447890752 workload.py:179] Translating evaluation dataset.
I0920 06:39:20.751510 139893447890752 submission_runner.py:376] Time since start: 61245.33s, 	Step: 100000, 	{'train/accuracy': 0.6923977732658386, 'train/loss': 1.396432638168335, 'train/bleu': 34.916977801861414, 'validation/accuracy': 0.6957632303237915, 'validation/loss': 1.370367407798767, 'validation/bleu': 30.8082741282124, 'validation/num_examples': 3000, 'test/accuracy': 0.7132531404495239, 'test/loss': 1.2598369121551514, 'test/bleu': 31.191815589120935, 'test/num_examples': 3003, 'score': 35724.363859176636, 'total_duration': 61245.32824444771, 'accumulated_submission_time': 35724.363859176636, 'accumulated_eval_time': 25518.266776561737, 'accumulated_logging_time': 1.2040939331054688}
I0920 06:39:20.771146 139716895373056 logging_writer.py:48] [100000] accumulated_eval_time=25518.266777, accumulated_logging_time=1.204094, accumulated_submission_time=35724.363859, global_step=100000, preemption_count=0, score=35724.363859, test/accuracy=0.713253, test/bleu=31.191816, test/loss=1.259837, test/num_examples=3003, total_duration=61245.328244, train/accuracy=0.692398, train/bleu=34.916978, train/loss=1.396433, validation/accuracy=0.695763, validation/bleu=30.808274, validation/loss=1.370367, validation/num_examples=3000
I0920 06:39:20.791425 139716903765760 logging_writer.py:48] [100000] global_step=100000, preemption_count=0, score=35724.363859
I0920 06:39:21.887988 139893447890752 checkpoints.py:490] Saving checkpoint at step: 100000
I0920 06:39:25.670018 139893447890752 checkpoints.py:422] Saved checkpoint at /experiment_runs/targets_check_jax_run_01/nadamw_run_0/wmt_jax/trial_1/checkpoint_100000
I0920 06:39:25.675187 139893447890752 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/targets_check_jax_run_01/nadamw_run_0/wmt_jax/trial_1/checkpoint_100000.
I0920 06:39:25.716769 139893447890752 submission_runner.py:540] Tuning trial 1/1
I0920 06:39:25.716934 139893447890752 submission_runner.py:541] Hyperparameters: Hyperparameters(learning_rate=0.0017486387539278373, beta1=0.9326607383586145, beta2=0.9955159689799007, warmup_steps=1999, weight_decay=0.08121616522670176, label_smoothing=0.0)
I0920 06:39:25.718753 139893447890752 submission_runner.py:542] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0005717618041671813, 'train/loss': 11.013775825500488, 'train/bleu': 0.0, 'validation/accuracy': 0.0004835649742744863, 'validation/loss': 11.0232572555542, 'validation/bleu': 0.0, 'validation/num_examples': 3000, 'test/accuracy': 0.0007088489946909249, 'test/loss': 11.036556243896484, 'test/bleu': 0.0, 'test/num_examples': 3003, 'score': 45.49011206626892, 'total_duration': 905.1354348659515, 'accumulated_submission_time': 45.49011206626892, 'accumulated_eval_time': 859.6452877521515, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (2348, {'train/accuracy': 0.5223027467727661, 'train/loss': 2.756577730178833, 'train/bleu': 22.847602082953824, 'validation/accuracy': 0.5262922644615173, 'validation/loss': 2.7263078689575195, 'validation/bleu': 19.09381751292806, 'validation/num_examples': 3000, 'test/accuracy': 0.522596001625061, 'test/loss': 2.7707769870758057, 'test/bleu': 17.304567851597227, 'test/num_examples': 3003, 'score': 885.7435092926025, 'total_duration': 2205.6185047626495, 'accumulated_submission_time': 885.7435092926025, 'accumulated_eval_time': 1319.8082892894745, 'accumulated_logging_time': 0.03294658660888672, 'global_step': 2348, 'preemption_count': 0}), (4702, {'train/accuracy': 0.5791102647781372, 'train/loss': 2.2252321243286133, 'train/bleu': 27.499746212286194, 'validation/accuracy': 0.5956528782844543, 'validation/loss': 2.106135606765747, 'validation/bleu': 23.72745635793008, 'validation/num_examples': 3000, 'test/accuracy': 0.5980942845344543, 'test/loss': 2.089252471923828, 'test/bleu': 22.38019268071747, 'test/num_examples': 3003, 'score': 1726.006341457367, 'total_duration': 3481.7187197208405, 'accumulated_submission_time': 1726.006341457367, 'accumulated_eval_time': 1755.5865097045898, 'accumulated_logging_time': 0.05828285217285156, 'global_step': 4702, 'preemption_count': 0}), (7056, {'train/accuracy': 0.6083300709724426, 'train/loss': 1.986690878868103, 'train/bleu': 29.13191209704578, 'validation/accuracy': 0.6204262971878052, 'validation/loss': 1.903771162033081, 'validation/bleu': 25.60077053364534, 'validation/num_examples': 3000, 'test/accuracy': 0.6244494915008545, 'test/loss': 1.861025094985962, 'test/bleu': 24.510254880278833, 'test/num_examples': 3003, 'score': 2565.9905123710632, 'total_duration': 4770.427384853363, 'accumulated_submission_time': 2565.9905123710632, 'accumulated_eval_time': 2204.250458717346, 'accumulated_logging_time': 0.08476591110229492, 'global_step': 7056, 'preemption_count': 0}), (9410, {'train/accuracy': 0.6192506551742554, 'train/loss': 1.9133780002593994, 'train/bleu': 29.970172083927032, 'validation/accuracy': 0.6329493522644043, 'validation/loss': 1.804319143295288, 'validation/bleu': 26.322287874286733, 'validation/num_examples': 3000, 'test/accuracy': 0.6389169692993164, 'test/loss': 1.7473876476287842, 'test/bleu': 25.383847748661594, 'test/num_examples': 3003, 'score': 3406.172182559967, 'total_duration': 6045.015289068222, 'accumulated_submission_time': 3406.172182559967, 'accumulated_eval_time': 2638.597517490387, 'accumulated_logging_time': 0.10985875129699707, 'global_step': 9410, 'preemption_count': 0}), (11764, {'train/accuracy': 0.620331883430481, 'train/loss': 1.8951793909072876, 'train/bleu': 29.83833860940748, 'validation/accuracy': 0.6390373110771179, 'validation/loss': 1.7426457405090332, 'validation/bleu': 26.54636428136027, 'validation/num_examples': 3000, 'test/accuracy': 0.6477950215339661, 'test/loss': 1.6812012195587158, 'test/bleu': 25.394898018748137, 'test/num_examples': 3003, 'score': 4246.178511142731, 'total_duration': 7298.496207475662, 'accumulated_submission_time': 4246.178511142731, 'accumulated_eval_time': 3052.0126888751984, 'accumulated_logging_time': 0.13535833358764648, 'global_step': 11764, 'preemption_count': 0}), (14118, {'train/accuracy': 0.6296640038490295, 'train/loss': 1.8099462985992432, 'train/bleu': 30.076540343096546, 'validation/accuracy': 0.6466999650001526, 'validation/loss': 1.6975938081741333, 'validation/bleu': 27.278604848140947, 'validation/num_examples': 3000, 'test/accuracy': 0.654093325138092, 'test/loss': 1.6343461275100708, 'test/bleu': 26.315594765409987, 'test/num_examples': 3003, 'score': 5086.171936750412, 'total_duration': 8605.804715633392, 'accumulated_submission_time': 5086.171936750412, 'accumulated_eval_time': 3519.268178462982, 'accumulated_logging_time': 0.16052460670471191, 'global_step': 14118, 'preemption_count': 0}), (16471, {'train/accuracy': 0.628422737121582, 'train/loss': 1.817078948020935, 'train/bleu': 30.346818653597612, 'validation/accuracy': 0.6486218571662903, 'validation/loss': 1.6729240417480469, 'validation/bleu': 27.41113805093856, 'validation/num_examples': 3000, 'test/accuracy': 0.6577188968658447, 'test/loss': 1.6027809381484985, 'test/bleu': 26.406408728211915, 'test/num_examples': 3003, 'score': 5926.226072311401, 'total_duration': 9909.895950555801, 'accumulated_submission_time': 5926.226072311401, 'accumulated_eval_time': 3983.243810892105, 'accumulated_logging_time': 0.18732285499572754, 'global_step': 16471, 'preemption_count': 0}), (18824, {'train/accuracy': 0.6679422855377197, 'train/loss': 1.536102294921875, 'train/bleu': 33.41147710430217, 'validation/accuracy': 0.6535567045211792, 'validation/loss': 1.6475372314453125, 'validation/bleu': 27.90157434961957, 'validation/num_examples': 3000, 'test/accuracy': 0.6603683829307556, 'test/loss': 1.5781642198562622, 'test/bleu': 26.770949558872914, 'test/num_examples': 3003, 'score': 6766.224604606628, 'total_duration': 11236.46910738945, 'accumulated_submission_time': 6766.224604606628, 'accumulated_eval_time': 4469.757536888123, 'accumulated_logging_time': 0.21306157112121582, 'global_step': 18824, 'preemption_count': 0}), (21179, {'train/accuracy': 0.6381531953811646, 'train/loss': 1.7443022727966309, 'train/bleu': 30.73251058386486, 'validation/accuracy': 0.6548957824707031, 'validation/loss': 1.6329565048217773, 'validation/bleu': 27.683706875417723, 'validation/num_examples': 3000, 'test/accuracy': 0.6660391688346863, 'test/loss': 1.5578665733337402, 'test/bleu': 27.463220896539916, 'test/num_examples': 3003, 'score': 7606.333317279816, 'total_duration': 12550.716458320618, 'accumulated_submission_time': 7606.333317279816, 'accumulated_eval_time': 4943.835241317749, 'accumulated_logging_time': 0.23907184600830078, 'global_step': 21179, 'preemption_count': 0}), (23533, {'train/accuracy': 0.6357744336128235, 'train/loss': 1.762818455696106, 'train/bleu': 30.517142124662858, 'validation/accuracy': 0.6572763919830322, 'validation/loss': 1.6141091585159302, 'validation/bleu': 27.860278731603966, 'validation/num_examples': 3000, 'test/accuracy': 0.6679797768592834, 'test/loss': 1.5416169166564941, 'test/bleu': 27.46032153571663, 'test/num_examples': 3003, 'score': 8446.604129314423, 'total_duration': 13872.250803232193, 'accumulated_submission_time': 8446.604129314423, 'accumulated_eval_time': 5425.037862062454, 'accumulated_logging_time': 0.26519775390625, 'global_step': 23533, 'preemption_count': 0}), (25887, {'train/accuracy': 0.6444838047027588, 'train/loss': 1.6967813968658447, 'train/bleu': 31.689275246780817, 'validation/accuracy': 0.6590370535850525, 'validation/loss': 1.601287603378296, 'validation/bleu': 28.0668084718369, 'validation/num_examples': 3000, 'test/accuracy': 0.6697112321853638, 'test/loss': 1.528649926185608, 'test/bleu': 27.513607473954195, 'test/num_examples': 3003, 'score': 9286.687712907791, 'total_duration': 15182.397433280945, 'accumulated_submission_time': 9286.687712907791, 'accumulated_eval_time': 5895.039499044418, 'accumulated_logging_time': 0.2910938262939453, 'global_step': 25887, 'preemption_count': 0}), (28242, {'train/accuracy': 0.6431544423103333, 'train/loss': 1.7186918258666992, 'train/bleu': 31.745412314562202, 'validation/accuracy': 0.6615912914276123, 'validation/loss': 1.5894999504089355, 'validation/bleu': 28.380652771479404, 'validation/num_examples': 3000, 'test/accuracy': 0.6738365292549133, 'test/loss': 1.5105801820755005, 'test/bleu': 27.961993724325723, 'test/num_examples': 3003, 'score': 10126.724228143692, 'total_duration': 16699.740110874176, 'accumulated_submission_time': 10126.724228143692, 'accumulated_eval_time': 6572.285377502441, 'accumulated_logging_time': 0.3163130283355713, 'global_step': 28242, 'preemption_count': 0}), (30596, {'train/accuracy': 0.6410382390022278, 'train/loss': 1.7249096632003784, 'train/bleu': 31.462253542668456, 'validation/accuracy': 0.6622236371040344, 'validation/loss': 1.5801713466644287, 'validation/bleu': 28.201391954729644, 'validation/num_examples': 3000, 'test/accuracy': 0.6750566959381104, 'test/loss': 1.4950681924819946, 'test/bleu': 27.965461235464893, 'test/num_examples': 3003, 'score': 10966.763080120087, 'total_duration': 18025.9434363842, 'accumulated_submission_time': 10966.763080120087, 'accumulated_eval_time': 7058.387634515762, 'accumulated_logging_time': 0.34311413764953613, 'global_step': 30596, 'preemption_count': 0}), (32951, {'train/accuracy': 0.64990234375, 'train/loss': 1.6726881265640259, 'train/bleu': 31.721529984247024, 'validation/accuracy': 0.6627939939498901, 'validation/loss': 1.5707138776779175, 'validation/bleu': 28.173019190570095, 'validation/num_examples': 3000, 'test/accuracy': 0.675254225730896, 'test/loss': 1.4890516996383667, 'test/bleu': 28.315225871542676, 'test/num_examples': 3003, 'score': 11806.779775381088, 'total_duration': 19464.814161777496, 'accumulated_submission_time': 11806.779775381088, 'accumulated_eval_time': 7657.178781986237, 'accumulated_logging_time': 0.37096452713012695, 'global_step': 32951, 'preemption_count': 0}), (35305, {'train/accuracy': 0.643582820892334, 'train/loss': 1.7148653268814087, 'train/bleu': 31.49457209748028, 'validation/accuracy': 0.6627196073532104, 'validation/loss': 1.568458080291748, 'validation/bleu': 28.588793654073218, 'validation/num_examples': 3000, 'test/accuracy': 0.676021158695221, 'test/loss': 1.4819279909133911, 'test/bleu': 28.083742612164922, 'test/num_examples': 3003, 'score': 12646.915295362473, 'total_duration': 20910.309740543365, 'accumulated_submission_time': 12646.915295362473, 'accumulated_eval_time': 8262.474550485611, 'accumulated_logging_time': 0.39999938011169434, 'global_step': 35305, 'preemption_count': 0}), (37660, {'train/accuracy': 0.6750354170799255, 'train/loss': 1.4914193153381348, 'train/bleu': 33.5374128749934, 'validation/accuracy': 0.6667245030403137, 'validation/loss': 1.549566626548767, 'validation/bleu': 28.66948557740173, 'validation/num_examples': 3000, 'test/accuracy': 0.6783103942871094, 'test/loss': 1.4724562168121338, 'test/bleu': 27.966596225337117, 'test/num_examples': 3003, 'score': 13487.047506570816, 'total_duration': 22235.250456094742, 'accumulated_submission_time': 13487.047506570816, 'accumulated_eval_time': 8747.221109390259, 'accumulated_logging_time': 0.4267709255218506, 'global_step': 37660, 'preemption_count': 0}), (40014, {'train/accuracy': 0.6524672508239746, 'train/loss': 1.653410792350769, 'train/bleu': 32.01533529036341, 'validation/accuracy': 0.6676792502403259, 'validation/loss': 1.540696144104004, 'validation/bleu': 28.744897528988325, 'validation/num_examples': 3000, 'test/accuracy': 0.6795654296875, 'test/loss': 1.4615223407745361, 'test/bleu': 28.371424385505, 'test/num_examples': 3003, 'score': 14327.11462688446, 'total_duration': 23758.879850149155, 'accumulated_submission_time': 14327.11462688446, 'accumulated_eval_time': 9430.722401618958, 'accumulated_logging_time': 0.4527890682220459, 'global_step': 40014, 'preemption_count': 0}), (42370, {'train/accuracy': 0.6537200212478638, 'train/loss': 1.644946813583374, 'train/bleu': 31.888651052234906, 'validation/accuracy': 0.6686463952064514, 'validation/loss': 1.5342216491699219, 'validation/bleu': 28.734077134773415, 'validation/num_examples': 3000, 'test/accuracy': 0.6826797127723694, 'test/loss': 1.4480257034301758, 'test/bleu': 28.466429057401516, 'test/num_examples': 3003, 'score': 15167.25780916214, 'total_duration': 25140.87017059326, 'accumulated_submission_time': 15167.25780916214, 'accumulated_eval_time': 9972.50788974762, 'accumulated_logging_time': 0.479290246963501, 'global_step': 42370, 'preemption_count': 0}), (44726, {'train/accuracy': 0.6600672602653503, 'train/loss': 1.5931910276412964, 'train/bleu': 33.08935672667615, 'validation/accuracy': 0.6714485883712769, 'validation/loss': 1.5209060907363892, 'validation/bleu': 28.76862689643593, 'validation/num_examples': 3000, 'test/accuracy': 0.6840857863426208, 'test/loss': 1.4394794702529907, 'test/bleu': 28.66588361400673, 'test/num_examples': 3003, 'score': 16007.520249605179, 'total_duration': 26624.603650808334, 'accumulated_submission_time': 16007.520249605179, 'accumulated_eval_time': 10615.91652560234, 'accumulated_logging_time': 0.5059785842895508, 'global_step': 44726, 'preemption_count': 0}), (47081, {'train/accuracy': 0.6531199216842651, 'train/loss': 1.6436289548873901, 'train/bleu': 31.975095981027742, 'validation/accuracy': 0.6720685362815857, 'validation/loss': 1.5198124647140503, 'validation/bleu': 28.781026071222705, 'validation/num_examples': 3000, 'test/accuracy': 0.6863401532173157, 'test/loss': 1.4274227619171143, 'test/bleu': 28.78792581200404, 'test/num_examples': 3003, 'score': 16847.536018133163, 'total_duration': 28032.319281101227, 'accumulated_submission_time': 16847.536018133163, 'accumulated_eval_time': 11183.551272153854, 'accumulated_logging_time': 0.5357234477996826, 'global_step': 47081, 'preemption_count': 0}), (49436, {'train/accuracy': 0.6556416749954224, 'train/loss': 1.6273813247680664, 'train/bleu': 32.10085491711795, 'validation/accuracy': 0.6736184358596802, 'validation/loss': 1.5064789056777954, 'validation/bleu': 29.353998546367293, 'validation/num_examples': 3000, 'test/accuracy': 0.6879902482032776, 'test/loss': 1.4197542667388916, 'test/bleu': 28.627085888697408, 'test/num_examples': 3003, 'score': 17687.556476831436, 'total_duration': 29368.83440732956, 'accumulated_submission_time': 17687.556476831436, 'accumulated_eval_time': 11679.981359243393, 'accumulated_logging_time': 0.5647683143615723, 'global_step': 49436, 'preemption_count': 0}), (51790, {'train/accuracy': 0.6627727150917053, 'train/loss': 1.5808186531066895, 'train/bleu': 32.636743534686076, 'validation/accuracy': 0.6744987368583679, 'validation/loss': 1.4930343627929688, 'validation/bleu': 28.953372526636766, 'validation/num_examples': 3000, 'test/accuracy': 0.6898959875106812, 'test/loss': 1.403241515159607, 'test/bleu': 29.217195641015813, 'test/num_examples': 3003, 'score': 18527.511578321457, 'total_duration': 30764.270045518875, 'accumulated_submission_time': 18527.511578321457, 'accumulated_eval_time': 12235.399912595749, 'accumulated_logging_time': 0.5912847518920898, 'global_step': 51790, 'preemption_count': 0}), (54145, {'train/accuracy': 0.6540789604187012, 'train/loss': 1.6331303119659424, 'train/bleu': 32.36771906244592, 'validation/accuracy': 0.6761974096298218, 'validation/loss': 1.4889857769012451, 'validation/bleu': 29.432292479448968, 'validation/num_examples': 3000, 'test/accuracy': 0.6913136839866638, 'test/loss': 1.3917614221572876, 'test/bleu': 29.00583413290922, 'test/num_examples': 3003, 'score': 19367.626319169998, 'total_duration': 32237.628411769867, 'accumulated_submission_time': 19367.626319169998, 'accumulated_eval_time': 12868.58023738861, 'accumulated_logging_time': 0.6192111968994141, 'global_step': 54145, 'preemption_count': 0}), (56501, {'train/accuracy': 0.6786210536956787, 'train/loss': 1.472409725189209, 'train/bleu': 34.48414807015081, 'validation/accuracy': 0.6776977181434631, 'validation/loss': 1.4757193326950073, 'validation/bleu': 29.40557344804655, 'validation/num_examples': 3000, 'test/accuracy': 0.6908372640609741, 'test/loss': 1.3876988887786865, 'test/bleu': 29.222403776771802, 'test/num_examples': 3003, 'score': 20208.097794294357, 'total_duration': 33552.57602405548, 'accumulated_submission_time': 20208.097794294357, 'accumulated_eval_time': 13342.99164891243, 'accumulated_logging_time': 0.6485104560852051, 'global_step': 56501, 'preemption_count': 0}), (58855, {'train/accuracy': 0.6685560345649719, 'train/loss': 1.5453472137451172, 'train/bleu': 32.735772999917856, 'validation/accuracy': 0.6788260340690613, 'validation/loss': 1.467403769493103, 'validation/bleu': 29.541419099289623, 'validation/num_examples': 3000, 'test/accuracy': 0.6940677762031555, 'test/loss': 1.3734157085418701, 'test/bleu': 29.396471965935515, 'test/num_examples': 3003, 'score': 21048.216207504272, 'total_duration': 35124.84830379486, 'accumulated_submission_time': 21048.216207504272, 'accumulated_eval_time': 14075.082108259201, 'accumulated_logging_time': 0.6768617630004883, 'global_step': 58855, 'preemption_count': 0}), (61211, {'train/accuracy': 0.665136992931366, 'train/loss': 1.5755027532577515, 'train/bleu': 33.046904600355454, 'validation/accuracy': 0.6804999113082886, 'validation/loss': 1.4599628448486328, 'validation/bleu': 29.711303320275704, 'validation/num_examples': 3000, 'test/accuracy': 0.6964848041534424, 'test/loss': 1.3657292127609253, 'test/bleu': 29.84307793739068, 'test/num_examples': 3003, 'score': 21888.499173879623, 'total_duration': 36556.08446121216, 'accumulated_submission_time': 21888.499173879623, 'accumulated_eval_time': 14665.971496582031, 'accumulated_logging_time': 0.7054507732391357, 'global_step': 61211, 'preemption_count': 0}), (63567, {'train/accuracy': 0.6747167110443115, 'train/loss': 1.50295889377594, 'train/bleu': 33.625067372427374, 'validation/accuracy': 0.6816158294677734, 'validation/loss': 1.450143814086914, 'validation/bleu': 29.592450712162044, 'validation/num_examples': 3000, 'test/accuracy': 0.6963686347007751, 'test/loss': 1.3518720865249634, 'test/bleu': 29.471091336196636, 'test/num_examples': 3003, 'score': 22728.77717614174, 'total_duration': 37989.31209397316, 'accumulated_submission_time': 22728.77717614174, 'accumulated_eval_time': 15258.857730865479, 'accumulated_logging_time': 0.7335500717163086, 'global_step': 63567, 'preemption_count': 0}), (65922, {'train/accuracy': 0.6708354353904724, 'train/loss': 1.5267027616500854, 'train/bleu': 33.43694136803427, 'validation/accuracy': 0.6823474168777466, 'validation/loss': 1.4454008340835571, 'validation/bleu': 29.76893615295852, 'validation/num_examples': 3000, 'test/accuracy': 0.7004357576370239, 'test/loss': 1.3402730226516724, 'test/bleu': 29.920619656632354, 'test/num_examples': 3003, 'score': 23568.720961093903, 'total_duration': 39337.3701171875, 'accumulated_submission_time': 23568.720961093903, 'accumulated_eval_time': 15766.90819811821, 'accumulated_logging_time': 0.7617778778076172, 'global_step': 65922, 'preemption_count': 0}), (68277, {'train/accuracy': 0.6709253787994385, 'train/loss': 1.5292772054672241, 'train/bleu': 33.54533099395434, 'validation/accuracy': 0.685050368309021, 'validation/loss': 1.4331506490707397, 'validation/bleu': 30.100808382372218, 'validation/num_examples': 3000, 'test/accuracy': 0.701109766960144, 'test/loss': 1.3304002285003662, 'test/bleu': 29.975857775453964, 'test/num_examples': 3003, 'score': 24408.957591295242, 'total_duration': 40686.17873048782, 'accumulated_submission_time': 24408.957591295242, 'accumulated_eval_time': 16275.41618680954, 'accumulated_logging_time': 0.7903876304626465, 'global_step': 68277, 'preemption_count': 0}), (70632, {'train/accuracy': 0.6786221265792847, 'train/loss': 1.4771839380264282, 'train/bleu': 34.154001402245406, 'validation/accuracy': 0.6856207251548767, 'validation/loss': 1.42377507686615, 'validation/bleu': 29.803221863871073, 'validation/num_examples': 3000, 'test/accuracy': 0.7014119029045105, 'test/loss': 1.3253968954086304, 'test/bleu': 29.96280475058441, 'test/num_examples': 3003, 'score': 25248.954988479614, 'total_duration': 42180.658596515656, 'accumulated_submission_time': 25248.954988479614, 'accumulated_eval_time': 16929.83368253708, 'accumulated_logging_time': 0.8197112083435059, 'global_step': 70632, 'preemption_count': 0}), (72988, {'train/accuracy': 0.6799107193946838, 'train/loss': 1.4843158721923828, 'train/bleu': 33.88770682935594, 'validation/accuracy': 0.6877533793449402, 'validation/loss': 1.4163566827774048, 'validation/bleu': 30.27833681555915, 'validation/num_examples': 3000, 'test/accuracy': 0.7038870453834534, 'test/loss': 1.3102107048034668, 'test/bleu': 30.37073882439016, 'test/num_examples': 3003, 'score': 26089.221060991287, 'total_duration': 43560.81432199478, 'accumulated_submission_time': 26089.221060991287, 'accumulated_eval_time': 17469.656693696976, 'accumulated_logging_time': 0.8507094383239746, 'global_step': 72988, 'preemption_count': 0}), (75343, {'train/accuracy': 0.6882423758506775, 'train/loss': 1.4102529287338257, 'train/bleu': 34.70146480705934, 'validation/accuracy': 0.6881377696990967, 'validation/loss': 1.4110521078109741, 'validation/bleu': 30.37036569512352, 'validation/num_examples': 3000, 'test/accuracy': 0.7033060193061829, 'test/loss': 1.3084625005722046, 'test/bleu': 30.152400108210642, 'test/num_examples': 3003, 'score': 26929.22295165062, 'total_duration': 44974.904829502106, 'accumulated_submission_time': 26929.22295165062, 'accumulated_eval_time': 18043.6808552742, 'accumulated_logging_time': 0.8794536590576172, 'global_step': 75343, 'preemption_count': 0}), (77698, {'train/accuracy': 0.6838017702102661, 'train/loss': 1.4448941946029663, 'train/bleu': 34.31984224041812, 'validation/accuracy': 0.6899976134300232, 'validation/loss': 1.40022611618042, 'validation/bleu': 30.344190337597727, 'validation/num_examples': 3000, 'test/accuracy': 0.7067573070526123, 'test/loss': 1.2971179485321045, 'test/bleu': 30.313982933082816, 'test/num_examples': 3003, 'score': 27769.396897792816, 'total_duration': 46563.525133132935, 'accumulated_submission_time': 27769.396897792816, 'accumulated_eval_time': 18792.061408758163, 'accumulated_logging_time': 0.9094645977020264, 'global_step': 77698, 'preemption_count': 0}), (80052, {'train/accuracy': 0.6808838844299316, 'train/loss': 1.4630376100540161, 'train/bleu': 34.63216915381069, 'validation/accuracy': 0.6903820037841797, 'validation/loss': 1.3929818868637085, 'validation/bleu': 30.636862740860767, 'validation/num_examples': 3000, 'test/accuracy': 0.7079774737358093, 'test/loss': 1.2864859104156494, 'test/bleu': 30.806089332451336, 'test/num_examples': 3003, 'score': 28609.3996219635, 'total_duration': 48004.901880025864, 'accumulated_submission_time': 28609.3996219635, 'accumulated_eval_time': 19393.37023305893, 'accumulated_logging_time': 0.9397079944610596, 'global_step': 80052, 'preemption_count': 0}), (82408, {'train/accuracy': 0.6884999871253967, 'train/loss': 1.4175782203674316, 'train/bleu': 34.719468404490534, 'validation/accuracy': 0.691299557685852, 'validation/loss': 1.391406536102295, 'validation/bleu': 30.585640606790022, 'validation/num_examples': 3000, 'test/accuracy': 0.708291232585907, 'test/loss': 1.2817376852035522, 'test/bleu': 30.433517564510232, 'test/num_examples': 3003, 'score': 29449.451961755753, 'total_duration': 49482.98837900162, 'accumulated_submission_time': 29449.451961755753, 'accumulated_eval_time': 20031.339049100876, 'accumulated_logging_time': 0.9696953296661377, 'global_step': 82408, 'preemption_count': 0}), (84764, {'train/accuracy': 0.6859747767448425, 'train/loss': 1.4265786409378052, 'train/bleu': 34.6070502126212, 'validation/accuracy': 0.6927130222320557, 'validation/loss': 1.3863006830215454, 'validation/bleu': 29.959039985920395, 'validation/num_examples': 3000, 'test/accuracy': 0.7108244895935059, 'test/loss': 1.274747610092163, 'test/bleu': 30.843567367629213, 'test/num_examples': 3003, 'score': 30289.650393009186, 'total_duration': 51085.49648594856, 'accumulated_submission_time': 30289.650393009186, 'accumulated_eval_time': 20793.583874464035, 'accumulated_logging_time': 0.9989745616912842, 'global_step': 84764, 'preemption_count': 0}), (87120, {'train/accuracy': 0.6864790320396423, 'train/loss': 1.4287083148956299, 'train/bleu': 34.93763426245714, 'validation/accuracy': 0.6924898624420166, 'validation/loss': 1.3810315132141113, 'validation/bleu': 30.55028821593838, 'validation/num_examples': 3000, 'test/accuracy': 0.7108826041221619, 'test/loss': 1.272445559501648, 'test/bleu': 31.11997017345376, 'test/num_examples': 3003, 'score': 31129.857532978058, 'total_duration': 52566.59352707863, 'accumulated_submission_time': 31129.857532978058, 'accumulated_eval_time': 21434.409713983536, 'accumulated_logging_time': 1.0275912284851074, 'global_step': 87120, 'preemption_count': 0}), (89474, {'train/accuracy': 0.6920066475868225, 'train/loss': 1.4008373022079468, 'train/bleu': 35.18598370051251, 'validation/accuracy': 0.6944488883018494, 'validation/loss': 1.3764303922653198, 'validation/bleu': 30.69497641932349, 'validation/num_examples': 3000, 'test/accuracy': 0.711544930934906, 'test/loss': 1.2680366039276123, 'test/bleu': 30.909970851213476, 'test/num_examples': 3003, 'score': 31969.852482795715, 'total_duration': 54094.579277038574, 'accumulated_submission_time': 31969.852482795715, 'accumulated_eval_time': 22122.33724284172, 'accumulated_logging_time': 1.0557479858398438, 'global_step': 89474, 'preemption_count': 0}), (91829, {'train/accuracy': 0.6896260976791382, 'train/loss': 1.4150826930999756, 'train/bleu': 35.45518595890269, 'validation/accuracy': 0.6950068473815918, 'validation/loss': 1.373129963874817, 'validation/bleu': 30.777306216806316, 'validation/num_examples': 3000, 'test/accuracy': 0.7132531404495239, 'test/loss': 1.2620350122451782, 'test/bleu': 31.176622263884134, 'test/num_examples': 3003, 'score': 32809.814227342606, 'total_duration': 55635.502299547195, 'accumulated_submission_time': 32809.814227342606, 'accumulated_eval_time': 22823.23236966133, 'accumulated_logging_time': 1.086176872253418, 'global_step': 91829, 'preemption_count': 0}), (94184, {'train/accuracy': 0.6916075944900513, 'train/loss': 1.397290825843811, 'train/bleu': 35.39453109228952, 'validation/accuracy': 0.6952424645423889, 'validation/loss': 1.3712801933288574, 'validation/bleu': 30.946564705441354, 'validation/num_examples': 3000, 'test/accuracy': 0.7133228778839111, 'test/loss': 1.2604559659957886, 'test/bleu': 31.186716763294925, 'test/num_examples': 3003, 'score': 33649.809299230576, 'total_duration': 57122.99164867401, 'accumulated_submission_time': 33649.809299230576, 'accumulated_eval_time': 23470.66210770607, 'accumulated_logging_time': 1.1148681640625, 'global_step': 94184, 'preemption_count': 0}), (96539, {'train/accuracy': 0.6916161775588989, 'train/loss': 1.4004050493240356, 'train/bleu': 35.15158742799602, 'validation/accuracy': 0.6955276131629944, 'validation/loss': 1.3707915544509888, 'validation/bleu': 30.686707997506677, 'validation/num_examples': 3000, 'test/accuracy': 0.7132067084312439, 'test/loss': 1.2603013515472412, 'test/bleu': 31.18369207715012, 'test/num_examples': 3003, 'score': 34489.842451334, 'total_duration': 58637.05592226982, 'accumulated_submission_time': 34489.842451334, 'accumulated_eval_time': 24144.62884926796, 'accumulated_logging_time': 1.1436142921447754, 'global_step': 96539, 'preemption_count': 0}), (98894, {'train/accuracy': 0.6908577084541321, 'train/loss': 1.405752420425415, 'train/bleu': 35.49042967712508, 'validation/accuracy': 0.6957508325576782, 'validation/loss': 1.3702772855758667, 'validation/bleu': 30.82650066258248, 'validation/num_examples': 3000, 'test/accuracy': 0.7133345007896423, 'test/loss': 1.2597142457962036, 'test/bleu': 31.220260054630778, 'test/num_examples': 3003, 'score': 35329.93285369873, 'total_duration': 60164.84579181671, 'accumulated_submission_time': 35329.93285369873, 'accumulated_eval_time': 24832.26297569275, 'accumulated_logging_time': 1.1734983921051025, 'global_step': 98894, 'preemption_count': 0}), (100000, {'train/accuracy': 0.6923977732658386, 'train/loss': 1.396432638168335, 'train/bleu': 34.916977801861414, 'validation/accuracy': 0.6957632303237915, 'validation/loss': 1.370367407798767, 'validation/bleu': 30.8082741282124, 'validation/num_examples': 3000, 'test/accuracy': 0.7132531404495239, 'test/loss': 1.2598369121551514, 'test/bleu': 31.191815589120935, 'test/num_examples': 3003, 'score': 35724.363859176636, 'total_duration': 61245.32824444771, 'accumulated_submission_time': 35724.363859176636, 'accumulated_eval_time': 25518.266776561737, 'accumulated_logging_time': 1.2040939331054688, 'global_step': 100000, 'preemption_count': 0})], 'global_step': 100000}
I0920 06:39:25.718905 139893447890752 submission_runner.py:543] Timing: 35724.363859176636
I0920 06:39:25.718959 139893447890752 submission_runner.py:545] Total number of evals: 44
I0920 06:39:25.719004 139893447890752 submission_runner.py:546] ====================
I0920 06:39:25.719154 139893447890752 submission_runner.py:614] Final wmt score: 35724.363859176636
