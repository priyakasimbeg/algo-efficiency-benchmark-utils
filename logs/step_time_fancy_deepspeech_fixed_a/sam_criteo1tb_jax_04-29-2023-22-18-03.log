python3 submission_runner.py --framework=jax --workload=criteo1tb --submission_path=baselines/sam/jax/submission.py --tuning_search_space=baselines/sam/tuning_search_space.json --data_dir=/data/criteo1tb --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_fancy/timing_sam --overwrite=True --save_checkpoints=False --max_global_steps=1600 2>&1 | tee -a /logs/criteo1tb_jax_04-29-2023-22-18-03.log
I0429 22:18:22.408256 140353998980928 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_fancy/timing_sam/criteo1tb_jax.
I0429 22:18:22.554807 140353998980928 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0429 22:18:23.430483 140353998980928 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0429 22:18:23.431194 140353998980928 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0429 22:18:23.437054 140353998980928 submission_runner.py:538] Using RNG seed 3935906119
I0429 22:18:26.014822 140353998980928 submission_runner.py:547] --- Tuning run 1/1 ---
I0429 22:18:26.015050 140353998980928 submission_runner.py:552] Creating tuning directory at /experiment_runs/timing_fancy/timing_sam/criteo1tb_jax/trial_1.
I0429 22:18:26.015251 140353998980928 logger_utils.py:92] Saving hparams to /experiment_runs/timing_fancy/timing_sam/criteo1tb_jax/trial_1/hparams.json.
I0429 22:18:26.150438 140353998980928 submission_runner.py:241] Initializing dataset.
I0429 22:18:26.150628 140353998980928 submission_runner.py:248] Initializing model.
I0429 22:18:32.494582 140353998980928 submission_runner.py:258] Initializing optimizer.
I0429 22:18:35.405300 140353998980928 submission_runner.py:265] Initializing metrics bundle.
I0429 22:18:35.405509 140353998980928 submission_runner.py:282] Initializing checkpoint and logger.
I0429 22:18:35.409411 140353998980928 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_fancy/timing_sam/criteo1tb_jax/trial_1 with prefix checkpoint_
I0429 22:18:35.409721 140353998980928 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0429 22:18:35.409791 140353998980928 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0429 22:18:36.185583 140353998980928 submission_runner.py:303] Saving meta data to /experiment_runs/timing_fancy/timing_sam/criteo1tb_jax/trial_1/meta_data_0.json.
I0429 22:18:36.189448 140353998980928 submission_runner.py:306] Saving flags to /experiment_runs/timing_fancy/timing_sam/criteo1tb_jax/trial_1/flags_0.json.
I0429 22:18:36.240385 140353998980928 submission_runner.py:318] Starting training loop.
I0429 22:19:02.058947 140177682978560 logging_writer.py:48] [0] global_step=0, grad_norm=8.119457244873047, loss=0.8885293006896973
I0429 22:19:02.066250 140353998980928 spec.py:298] Evaluating on the training split.
I0429 22:23:54.911586 140353998980928 spec.py:310] Evaluating on the validation split.
I0429 22:28:46.451698 140353998980928 spec.py:326] Evaluating on the test split.
I0429 22:33:38.304585 140353998980928 submission_runner.py:415] Time since start: 902.06s, 	Step: 1, 	{'train/loss': 0.8887322364790287, 'validation/loss': 0.8881113707865168, 'validation/num_examples': 89000000, 'test/loss': 0.888425051787105, 'test/num_examples': 89274637, 'score': 25.82568073272705, 'total_duration': 902.0640988349915, 'accumulated_submission_time': 25.82568073272705, 'accumulated_eval_time': 876.2382357120514, 'accumulated_logging_time': 0}
I0429 22:33:38.321880 140164554639104 logging_writer.py:48] [1] accumulated_eval_time=876.238236, accumulated_logging_time=0, accumulated_submission_time=25.825681, global_step=1, preemption_count=0, score=25.825681, test/loss=0.888425, test/num_examples=89274637, total_duration=902.064099, train/loss=0.888732, validation/loss=0.888111, validation/num_examples=89000000
I0429 22:34:45.302759 140164546246400 logging_writer.py:48] [100] global_step=100, grad_norm=0.13028135895729065, loss=0.13497145473957062
I0429 22:35:38.711322 140353998980928 spec.py:298] Evaluating on the training split.
I0429 22:40:29.617887 140353998980928 spec.py:310] Evaluating on the validation split.
I0429 22:45:08.588276 140353998980928 spec.py:326] Evaluating on the test split.
I0429 22:49:55.422422 140353998980928 submission_runner.py:415] Time since start: 1879.18s, 	Step: 163, 	{'train/loss': 0.1299200780782917, 'validation/loss': 0.12995037078651686, 'validation/num_examples': 89000000, 'test/loss': 0.13289561737450695, 'test/num_examples': 89274637, 'score': 146.20587706565857, 'total_duration': 1879.181916475296, 'accumulated_submission_time': 146.20587706565857, 'accumulated_eval_time': 1732.9492428302765, 'accumulated_logging_time': 0.024344921112060547}
I0429 22:49:55.431413 140164554639104 logging_writer.py:48] [163] accumulated_eval_time=1732.949243, accumulated_logging_time=0.024345, accumulated_submission_time=146.205877, global_step=163, preemption_count=0, score=146.205877, test/loss=0.132896, test/num_examples=89274637, total_duration=1879.181916, train/loss=0.129920, validation/loss=0.129950, validation/num_examples=89000000
I0429 22:50:07.958262 140164546246400 logging_writer.py:48] [200] global_step=200, grad_norm=0.04993602633476257, loss=0.12532010674476624
I0429 22:51:35.575371 140164554639104 logging_writer.py:48] [300] global_step=300, grad_norm=0.04635138437151909, loss=0.12250283360481262
I0429 22:51:55.505812 140353998980928 spec.py:298] Evaluating on the training split.
I0429 22:56:57.358116 140353998980928 spec.py:310] Evaluating on the validation split.
I0429 23:01:36.263715 140353998980928 spec.py:326] Evaluating on the test split.
I0429 23:06:24.075446 140353998980928 submission_runner.py:415] Time since start: 2867.83s, 	Step: 324, 	{'train/loss': 0.1272763777866883, 'validation/loss': 0.12827785393258426, 'validation/num_examples': 89000000, 'test/loss': 0.1312318749613062, 'test/num_examples': 89274637, 'score': 266.27153992652893, 'total_duration': 2867.834951877594, 'accumulated_submission_time': 266.27153992652893, 'accumulated_eval_time': 2601.5187911987305, 'accumulated_logging_time': 0.03990435600280762}
I0429 23:06:24.084904 140164546246400 logging_writer.py:48] [324] accumulated_eval_time=2601.518791, accumulated_logging_time=0.039904, accumulated_submission_time=266.271540, global_step=324, preemption_count=0, score=266.271540, test/loss=0.131232, test/num_examples=89274637, total_duration=2867.834952, train/loss=0.127276, validation/loss=0.128278, validation/num_examples=89000000
I0429 23:07:10.036786 140164554639104 logging_writer.py:48] [400] global_step=400, grad_norm=0.06020171567797661, loss=0.11752332746982574
I0429 23:08:24.261991 140353998980928 spec.py:298] Evaluating on the training split.
I0429 23:13:11.050533 140353998980928 spec.py:310] Evaluating on the validation split.
I0429 23:17:51.158993 140353998980928 spec.py:326] Evaluating on the test split.
I0429 23:22:39.168389 140353998980928 submission_runner.py:415] Time since start: 3842.93s, 	Step: 486, 	{'train/loss': 0.12736532563580757, 'validation/loss': 0.1277527191011236, 'validation/num_examples': 89000000, 'test/loss': 0.1309310504393314, 'test/num_examples': 89274637, 'score': 386.4392092227936, 'total_duration': 3842.927891731262, 'accumulated_submission_time': 386.4392092227936, 'accumulated_eval_time': 3456.425109386444, 'accumulated_logging_time': 0.05658268928527832}
I0429 23:22:39.182364 140164546246400 logging_writer.py:48] [486] accumulated_eval_time=3456.425109, accumulated_logging_time=0.056583, accumulated_submission_time=386.439209, global_step=486, preemption_count=0, score=386.439209, test/loss=0.130931, test/num_examples=89274637, total_duration=3842.927892, train/loss=0.127365, validation/loss=0.127753, validation/num_examples=89000000
I0429 23:22:41.952391 140164554639104 logging_writer.py:48] [500] global_step=500, grad_norm=0.04455825686454773, loss=0.12953701615333557
I0429 23:23:58.110270 140164546246400 logging_writer.py:48] [600] global_step=600, grad_norm=0.008242171257734299, loss=0.12399483472108841
I0429 23:24:39.498580 140353998980928 spec.py:298] Evaluating on the training split.
I0429 23:29:32.652074 140353998980928 spec.py:310] Evaluating on the validation split.
I0429 23:34:11.917342 140353998980928 spec.py:326] Evaluating on the test split.
I0429 23:39:00.810980 140353998980928 submission_runner.py:415] Time since start: 4824.57s, 	Step: 649, 	{'train/loss': 0.12330436566193548, 'validation/loss': 0.1269876404494382, 'validation/num_examples': 89000000, 'test/loss': 0.12973079912943247, 'test/num_examples': 89274637, 'score': 506.7454023361206, 'total_duration': 4824.5704708099365, 'accumulated_submission_time': 506.7454023361206, 'accumulated_eval_time': 4317.737415552139, 'accumulated_logging_time': 0.07833313941955566}
I0429 23:39:00.820589 140164554639104 logging_writer.py:48] [649] accumulated_eval_time=4317.737416, accumulated_logging_time=0.078333, accumulated_submission_time=506.745402, global_step=649, preemption_count=0, score=506.745402, test/loss=0.129731, test/num_examples=89274637, total_duration=4824.570471, train/loss=0.123304, validation/loss=0.126988, validation/num_examples=89000000
I0429 23:39:25.672832 140164546246400 logging_writer.py:48] [700] global_step=700, grad_norm=0.02770877815783024, loss=0.12640920281410217
I0429 23:40:52.607896 140164554639104 logging_writer.py:48] [800] global_step=800, grad_norm=0.026204142719507217, loss=0.12465745210647583
I0429 23:41:01.119435 140353998980928 spec.py:298] Evaluating on the training split.
I0429 23:45:51.291458 140353998980928 spec.py:310] Evaluating on the validation split.
I0429 23:50:29.716066 140353998980928 spec.py:326] Evaluating on the test split.
I0429 23:55:13.200285 140353998980928 submission_runner.py:415] Time since start: 5796.96s, 	Step: 811, 	{'train/loss': 0.12705225660311464, 'validation/loss': 0.12739053932584268, 'validation/num_examples': 89000000, 'test/loss': 0.13015966673714954, 'test/num_examples': 89274637, 'score': 627.0342762470245, 'total_duration': 5796.959781885147, 'accumulated_submission_time': 627.0342762470245, 'accumulated_eval_time': 5169.8181848526, 'accumulated_logging_time': 0.09564709663391113}
I0429 23:55:13.209492 140164546246400 logging_writer.py:48] [811] accumulated_eval_time=5169.818185, accumulated_logging_time=0.095647, accumulated_submission_time=627.034276, global_step=811, preemption_count=0, score=627.034276, test/loss=0.130160, test/num_examples=89274637, total_duration=5796.959782, train/loss=0.127052, validation/loss=0.127391, validation/num_examples=89000000
I0429 23:56:10.469741 140164554639104 logging_writer.py:48] [900] global_step=900, grad_norm=0.006464201025664806, loss=0.1202511265873909
I0429 23:57:13.614645 140353998980928 spec.py:298] Evaluating on the training split.
I0430 00:02:01.654602 140353998980928 spec.py:310] Evaluating on the validation split.
I0430 00:06:43.263039 140353998980928 spec.py:326] Evaluating on the test split.
I0430 00:11:41.366610 140353998980928 submission_runner.py:415] Time since start: 6785.13s, 	Step: 974, 	{'train/loss': 0.1256471567946905, 'validation/loss': 0.12647377528089887, 'validation/num_examples': 89000000, 'test/loss': 0.12906237860143863, 'test/num_examples': 89274637, 'score': 747.4296765327454, 'total_duration': 6785.126108646393, 'accumulated_submission_time': 747.4296765327454, 'accumulated_eval_time': 6037.570066452026, 'accumulated_logging_time': 0.11245918273925781}
I0430 00:11:41.376379 140164546246400 logging_writer.py:48] [974] accumulated_eval_time=6037.570066, accumulated_logging_time=0.112459, accumulated_submission_time=747.429677, global_step=974, preemption_count=0, score=747.429677, test/loss=0.129062, test/num_examples=89274637, total_duration=6785.126109, train/loss=0.125647, validation/loss=0.126474, validation/num_examples=89000000
I0430 00:11:46.341206 140164554639104 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.008981824852526188, loss=0.12176868319511414
I0430 00:13:11.611163 140164546246400 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.009720303118228912, loss=0.12117157131433487
I0430 00:13:41.832569 140353998980928 spec.py:298] Evaluating on the training split.
I0430 00:18:31.419612 140353998980928 spec.py:310] Evaluating on the validation split.
I0430 00:23:11.159630 140353998980928 spec.py:326] Evaluating on the test split.
I0430 00:27:55.558009 140353998980928 submission_runner.py:415] Time since start: 7759.32s, 	Step: 1136, 	{'train/loss': 0.1258148911948411, 'validation/loss': 0.12597776404494382, 'validation/num_examples': 89000000, 'test/loss': 0.1285103629152813, 'test/num_examples': 89274637, 'score': 867.8758900165558, 'total_duration': 7759.317533254623, 'accumulated_submission_time': 867.8758900165558, 'accumulated_eval_time': 6891.295436620712, 'accumulated_logging_time': 0.13019418716430664}
I0430 00:27:55.566695 140164554639104 logging_writer.py:48] [1136] accumulated_eval_time=6891.295437, accumulated_logging_time=0.130194, accumulated_submission_time=867.875890, global_step=1136, preemption_count=0, score=867.875890, test/loss=0.128510, test/num_examples=89274637, total_duration=7759.317533, train/loss=0.125815, validation/loss=0.125978, validation/num_examples=89000000
I0430 00:28:31.465974 140164546246400 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.03170812875032425, loss=0.12393029034137726
I0430 00:29:55.868346 140353998980928 spec.py:298] Evaluating on the training split.
I0430 00:34:46.456728 140353998980928 spec.py:310] Evaluating on the validation split.
I0430 00:39:23.836864 140353998980928 spec.py:326] Evaluating on the test split.
I0430 00:44:08.467779 140353998980928 submission_runner.py:415] Time since start: 8732.23s, 	Step: 1299, 	{'train/loss': 0.1248322543718957, 'validation/loss': 0.12596979775280898, 'validation/num_examples': 89000000, 'test/loss': 0.12851998490903974, 'test/num_examples': 89274637, 'score': 988.1676166057587, 'total_duration': 8732.227287054062, 'accumulated_submission_time': 988.1676166057587, 'accumulated_eval_time': 7743.894797563553, 'accumulated_logging_time': 0.14665985107421875}
I0430 00:44:08.478450 140164554639104 logging_writer.py:48] [1299] accumulated_eval_time=7743.894798, accumulated_logging_time=0.146660, accumulated_submission_time=988.167617, global_step=1299, preemption_count=0, score=988.167617, test/loss=0.128520, test/num_examples=89274637, total_duration=8732.227287, train/loss=0.124832, validation/loss=0.125970, validation/num_examples=89000000
I0430 00:44:08.871901 140164546246400 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.02383231185376644, loss=0.13099609315395355
I0430 00:45:16.814672 140164554639104 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.013371704146265984, loss=0.11520138382911682
I0430 00:46:08.710667 140353998980928 spec.py:298] Evaluating on the training split.
I0430 00:51:04.411652 140353998980928 spec.py:310] Evaluating on the validation split.
I0430 00:55:46.543665 140353998980928 spec.py:326] Evaluating on the test split.
I0430 01:00:28.756420 140353998980928 submission_runner.py:415] Time since start: 9712.52s, 	Step: 1460, 	{'train/loss': 0.124457925623879, 'validation/loss': 0.12577539325842696, 'validation/num_examples': 89000000, 'test/loss': 0.12837664072495752, 'test/num_examples': 89274637, 'score': 1108.3901278972626, 'total_duration': 9712.51591038704, 'accumulated_submission_time': 1108.3901278972626, 'accumulated_eval_time': 8603.940457820892, 'accumulated_logging_time': 0.1649646759033203}
I0430 01:00:28.766264 140164546246400 logging_writer.py:48] [1460] accumulated_eval_time=8603.940458, accumulated_logging_time=0.164965, accumulated_submission_time=1108.390128, global_step=1460, preemption_count=0, score=1108.390128, test/loss=0.128377, test/num_examples=89274637, total_duration=9712.515910, train/loss=0.124458, validation/loss=0.125775, validation/num_examples=89000000
I0430 01:00:43.728607 140164554639104 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.011618793942034245, loss=0.1247362494468689
I0430 01:02:10.032384 140353998980928 spec.py:298] Evaluating on the training split.
I0430 01:07:00.675026 140353998980928 spec.py:310] Evaluating on the validation split.
I0430 01:11:35.147365 140353998980928 spec.py:326] Evaluating on the test split.
I0430 01:16:22.070523 140353998980928 submission_runner.py:415] Time since start: 10665.83s, 	Step: 1600, 	{'train/loss': 0.12242827089153904, 'validation/loss': 0.12582391011235955, 'validation/num_examples': 89000000, 'test/loss': 0.1285430149662776, 'test/num_examples': 89274637, 'score': 1209.646722793579, 'total_duration': 10665.83004283905, 'accumulated_submission_time': 1209.646722793579, 'accumulated_eval_time': 9455.978553295135, 'accumulated_logging_time': 0.18233394622802734}
I0430 01:16:22.080818 140164546246400 logging_writer.py:48] [1600] accumulated_eval_time=9455.978553, accumulated_logging_time=0.182334, accumulated_submission_time=1209.646723, global_step=1600, preemption_count=0, score=1209.646723, test/loss=0.128543, test/num_examples=89274637, total_duration=10665.830043, train/loss=0.122428, validation/loss=0.125824, validation/num_examples=89000000
I0430 01:16:22.093746 140164554639104 logging_writer.py:48] [1600] global_step=1600, preemption_count=0, score=1209.646723
I0430 01:16:25.340995 140353998980928 checkpoints.py:356] Saving checkpoint at step: 1600
I0430 01:16:53.891383 140353998980928 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_fancy/timing_sam/criteo1tb_jax/trial_1/checkpoint_1600
I0430 01:16:54.088855 140353998980928 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_fancy/timing_sam/criteo1tb_jax/trial_1/checkpoint_1600.
I0430 01:16:54.135661 140353998980928 submission_runner.py:578] Tuning trial 1/1
I0430 01:16:54.135884 140353998980928 submission_runner.py:579] Hyperparameters: Hyperparameters(learning_rate=0.0013159053452895648, one_minus_beta1=0.2018302260773442, beta2=0.999, warmup_factor=0.05, weight_decay=0.07935861128365443, label_smoothing=0.1, dropout_rate=0.0, rho=0.01)
I0430 01:16:54.137204 140353998980928 submission_runner.py:580] Metrics: {'eval_results': [(1, {'train/loss': 0.8887322364790287, 'validation/loss': 0.8881113707865168, 'validation/num_examples': 89000000, 'test/loss': 0.888425051787105, 'test/num_examples': 89274637, 'score': 25.82568073272705, 'total_duration': 902.0640988349915, 'accumulated_submission_time': 25.82568073272705, 'accumulated_eval_time': 876.2382357120514, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (163, {'train/loss': 0.1299200780782917, 'validation/loss': 0.12995037078651686, 'validation/num_examples': 89000000, 'test/loss': 0.13289561737450695, 'test/num_examples': 89274637, 'score': 146.20587706565857, 'total_duration': 1879.181916475296, 'accumulated_submission_time': 146.20587706565857, 'accumulated_eval_time': 1732.9492428302765, 'accumulated_logging_time': 0.024344921112060547, 'global_step': 163, 'preemption_count': 0}), (324, {'train/loss': 0.1272763777866883, 'validation/loss': 0.12827785393258426, 'validation/num_examples': 89000000, 'test/loss': 0.1312318749613062, 'test/num_examples': 89274637, 'score': 266.27153992652893, 'total_duration': 2867.834951877594, 'accumulated_submission_time': 266.27153992652893, 'accumulated_eval_time': 2601.5187911987305, 'accumulated_logging_time': 0.03990435600280762, 'global_step': 324, 'preemption_count': 0}), (486, {'train/loss': 0.12736532563580757, 'validation/loss': 0.1277527191011236, 'validation/num_examples': 89000000, 'test/loss': 0.1309310504393314, 'test/num_examples': 89274637, 'score': 386.4392092227936, 'total_duration': 3842.927891731262, 'accumulated_submission_time': 386.4392092227936, 'accumulated_eval_time': 3456.425109386444, 'accumulated_logging_time': 0.05658268928527832, 'global_step': 486, 'preemption_count': 0}), (649, {'train/loss': 0.12330436566193548, 'validation/loss': 0.1269876404494382, 'validation/num_examples': 89000000, 'test/loss': 0.12973079912943247, 'test/num_examples': 89274637, 'score': 506.7454023361206, 'total_duration': 4824.5704708099365, 'accumulated_submission_time': 506.7454023361206, 'accumulated_eval_time': 4317.737415552139, 'accumulated_logging_time': 0.07833313941955566, 'global_step': 649, 'preemption_count': 0}), (811, {'train/loss': 0.12705225660311464, 'validation/loss': 0.12739053932584268, 'validation/num_examples': 89000000, 'test/loss': 0.13015966673714954, 'test/num_examples': 89274637, 'score': 627.0342762470245, 'total_duration': 5796.959781885147, 'accumulated_submission_time': 627.0342762470245, 'accumulated_eval_time': 5169.8181848526, 'accumulated_logging_time': 0.09564709663391113, 'global_step': 811, 'preemption_count': 0}), (974, {'train/loss': 0.1256471567946905, 'validation/loss': 0.12647377528089887, 'validation/num_examples': 89000000, 'test/loss': 0.12906237860143863, 'test/num_examples': 89274637, 'score': 747.4296765327454, 'total_duration': 6785.126108646393, 'accumulated_submission_time': 747.4296765327454, 'accumulated_eval_time': 6037.570066452026, 'accumulated_logging_time': 0.11245918273925781, 'global_step': 974, 'preemption_count': 0}), (1136, {'train/loss': 0.1258148911948411, 'validation/loss': 0.12597776404494382, 'validation/num_examples': 89000000, 'test/loss': 0.1285103629152813, 'test/num_examples': 89274637, 'score': 867.8758900165558, 'total_duration': 7759.317533254623, 'accumulated_submission_time': 867.8758900165558, 'accumulated_eval_time': 6891.295436620712, 'accumulated_logging_time': 0.13019418716430664, 'global_step': 1136, 'preemption_count': 0}), (1299, {'train/loss': 0.1248322543718957, 'validation/loss': 0.12596979775280898, 'validation/num_examples': 89000000, 'test/loss': 0.12851998490903974, 'test/num_examples': 89274637, 'score': 988.1676166057587, 'total_duration': 8732.227287054062, 'accumulated_submission_time': 988.1676166057587, 'accumulated_eval_time': 7743.894797563553, 'accumulated_logging_time': 0.14665985107421875, 'global_step': 1299, 'preemption_count': 0}), (1460, {'train/loss': 0.124457925623879, 'validation/loss': 0.12577539325842696, 'validation/num_examples': 89000000, 'test/loss': 0.12837664072495752, 'test/num_examples': 89274637, 'score': 1108.3901278972626, 'total_duration': 9712.51591038704, 'accumulated_submission_time': 1108.3901278972626, 'accumulated_eval_time': 8603.940457820892, 'accumulated_logging_time': 0.1649646759033203, 'global_step': 1460, 'preemption_count': 0}), (1600, {'train/loss': 0.12242827089153904, 'validation/loss': 0.12582391011235955, 'validation/num_examples': 89000000, 'test/loss': 0.1285430149662776, 'test/num_examples': 89274637, 'score': 1209.646722793579, 'total_duration': 10665.83004283905, 'accumulated_submission_time': 1209.646722793579, 'accumulated_eval_time': 9455.978553295135, 'accumulated_logging_time': 0.18233394622802734, 'global_step': 1600, 'preemption_count': 0})], 'global_step': 1600}
I0430 01:16:54.137314 140353998980928 submission_runner.py:581] Timing: 1209.646722793579
I0430 01:16:54.137362 140353998980928 submission_runner.py:582] ====================
I0430 01:16:54.137498 140353998980928 submission_runner.py:645] Final criteo1tb score: 1209.646722793579
