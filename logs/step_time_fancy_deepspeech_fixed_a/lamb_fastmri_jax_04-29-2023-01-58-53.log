python3 submission_runner.py --framework=jax --workload=fastmri --submission_path=baselines/lamb/jax/submission.py --tuning_search_space=baselines/lamb/tuning_search_space.json --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_fancy/timing_lamb --overwrite=True --save_checkpoints=False --max_global_steps=5428 2>&1 | tee -a /logs/fastmri_jax_04-29-2023-01-58-53.log
I0429 01:59:13.617509 140539785910080 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_fancy/timing_lamb/fastmri_jax.
I0429 01:59:13.766503 140539785910080 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0429 01:59:14.620610 140539785910080 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0429 01:59:14.621339 140539785910080 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0429 01:59:14.625136 140539785910080 submission_runner.py:538] Using RNG seed 2261314022
I0429 01:59:17.353154 140539785910080 submission_runner.py:547] --- Tuning run 1/1 ---
I0429 01:59:17.353349 140539785910080 submission_runner.py:552] Creating tuning directory at /experiment_runs/timing_fancy/timing_lamb/fastmri_jax/trial_1.
I0429 01:59:17.353528 140539785910080 logger_utils.py:92] Saving hparams to /experiment_runs/timing_fancy/timing_lamb/fastmri_jax/trial_1/hparams.json.
I0429 01:59:17.478616 140539785910080 submission_runner.py:241] Initializing dataset.
I0429 01:59:21.434852 140539785910080 submission_runner.py:248] Initializing model.
I0429 01:59:28.647974 140539785910080 submission_runner.py:258] Initializing optimizer.
I0429 01:59:29.093369 140539785910080 submission_runner.py:265] Initializing metrics bundle.
I0429 01:59:29.093556 140539785910080 submission_runner.py:282] Initializing checkpoint and logger.
I0429 01:59:29.095409 140539785910080 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_fancy/timing_lamb/fastmri_jax/trial_1 with prefix checkpoint_
I0429 01:59:29.095656 140539785910080 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0429 01:59:29.095717 140539785910080 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0429 01:59:29.976549 140539785910080 submission_runner.py:303] Saving meta data to /experiment_runs/timing_fancy/timing_lamb/fastmri_jax/trial_1/meta_data_0.json.
I0429 01:59:29.977450 140539785910080 submission_runner.py:306] Saving flags to /experiment_runs/timing_fancy/timing_lamb/fastmri_jax/trial_1/flags_0.json.
I0429 01:59:29.982875 140539785910080 submission_runner.py:318] Starting training loop.
I0429 02:00:37.299370 140363121555200 logging_writer.py:48] [0] global_step=0, grad_norm=4.216292858123779, loss=0.8225525617599487
I0429 02:00:37.308480 140539785910080 spec.py:298] Evaluating on the training split.
I0429 02:02:09.151205 140539785910080 spec.py:310] Evaluating on the validation split.
I0429 02:03:13.131747 140539785910080 spec.py:326] Evaluating on the test split.
I0429 02:04:14.679376 140539785910080 submission_runner.py:415] Time since start: 284.70s, 	Step: 1, 	{'train/ssim': 0.24746649605887278, 'train/loss': 0.8312621116638184, 'validation/ssim': 0.23567495952513892, 'validation/loss': 0.8407013334447102, 'validation/num_examples': 3554, 'test/ssim': 0.25987310550692894, 'test/loss': 0.8378596046189961, 'test/num_examples': 3581, 'score': 67.32542753219604, 'total_duration': 284.6964030265808, 'accumulated_submission_time': 67.32542753219604, 'accumulated_eval_time': 217.37081623077393, 'accumulated_logging_time': 0}
I0429 02:04:14.695891 140333526529792 logging_writer.py:48] [1] accumulated_eval_time=217.370816, accumulated_logging_time=0, accumulated_submission_time=67.325428, global_step=1, preemption_count=0, score=67.325428, test/loss=0.837860, test/num_examples=3581, test/ssim=0.259873, total_duration=284.696403, train/loss=0.831262, train/ssim=0.247466, validation/loss=0.840701, validation/num_examples=3554, validation/ssim=0.235675
I0429 02:04:36.456471 140333518137088 logging_writer.py:48] [100] global_step=100, grad_norm=3.2888238430023193, loss=0.5790815949440002
I0429 02:05:00.491244 140333526529792 logging_writer.py:48] [200] global_step=200, grad_norm=0.4818120002746582, loss=0.4073486626148224
I0429 02:05:24.295947 140333518137088 logging_writer.py:48] [300] global_step=300, grad_norm=0.16575537621974945, loss=0.38322752714157104
I0429 02:05:35.059836 140539785910080 spec.py:298] Evaluating on the training split.
I0429 02:05:36.915777 140539785910080 spec.py:310] Evaluating on the validation split.
I0429 02:05:38.262137 140539785910080 spec.py:326] Evaluating on the test split.
I0429 02:05:39.610531 140539785910080 submission_runner.py:415] Time since start: 369.63s, 	Step: 331, 	{'train/ssim': 0.6715486390250069, 'train/loss': 0.3282586506434849, 'validation/ssim': 0.6476284149461874, 'validation/loss': 0.3484233283030564, 'validation/num_examples': 3554, 'test/ssim': 0.6675198066837127, 'test/loss': 0.3494381834028554, 'test/num_examples': 3581, 'score': 147.67657256126404, 'total_duration': 369.6275591850281, 'accumulated_submission_time': 147.67657256126404, 'accumulated_eval_time': 221.92145013809204, 'accumulated_logging_time': 0.024431705474853516}
I0429 02:05:39.621853 140333526529792 logging_writer.py:48] [331] accumulated_eval_time=221.921450, accumulated_logging_time=0.024432, accumulated_submission_time=147.676573, global_step=331, preemption_count=0, score=147.676573, test/loss=0.349438, test/num_examples=3581, test/ssim=0.667520, total_duration=369.627559, train/loss=0.328259, train/ssim=0.671549, validation/loss=0.348423, validation/num_examples=3554, validation/ssim=0.647628
I0429 02:06:00.870023 140333518137088 logging_writer.py:48] [400] global_step=400, grad_norm=0.10571501404047012, loss=0.31384962797164917
I0429 02:06:37.591956 140333526529792 logging_writer.py:48] [500] global_step=500, grad_norm=0.17466694116592407, loss=0.2360234558582306
I0429 02:06:59.694557 140539785910080 spec.py:298] Evaluating on the training split.
I0429 02:07:01.098871 140539785910080 spec.py:310] Evaluating on the validation split.
I0429 02:07:02.447736 140539785910080 spec.py:326] Evaluating on the test split.
I0429 02:07:03.796459 140539785910080 submission_runner.py:415] Time since start: 453.81s, 	Step: 561, 	{'train/ssim': 0.7069178989955357, 'train/loss': 0.30312749317714144, 'validation/ssim': 0.6862289437297763, 'validation/loss': 0.3210422084381155, 'validation/num_examples': 3554, 'test/ssim': 0.7043093649643954, 'test/loss': 0.32294258516083146, 'test/num_examples': 3581, 'score': 227.7330882549286, 'total_duration': 453.8135116100311, 'accumulated_submission_time': 227.7330882549286, 'accumulated_eval_time': 226.02331042289734, 'accumulated_logging_time': 0.04869437217712402}
I0429 02:07:03.808022 140333518137088 logging_writer.py:48] [561] accumulated_eval_time=226.023310, accumulated_logging_time=0.048694, accumulated_submission_time=227.733088, global_step=561, preemption_count=0, score=227.733088, test/loss=0.322943, test/num_examples=3581, test/ssim=0.704309, total_duration=453.813512, train/loss=0.303127, train/ssim=0.706918, validation/loss=0.321042, validation/num_examples=3554, validation/ssim=0.686229
I0429 02:07:15.327316 140333526529792 logging_writer.py:48] [600] global_step=600, grad_norm=0.19804151356220245, loss=0.33723586797714233
I0429 02:07:52.397096 140333518137088 logging_writer.py:48] [700] global_step=700, grad_norm=0.34774988889694214, loss=0.22332149744033813
I0429 02:08:23.855130 140539785910080 spec.py:298] Evaluating on the training split.
I0429 02:08:25.257996 140539785910080 spec.py:310] Evaluating on the validation split.
I0429 02:08:26.607807 140539785910080 spec.py:326] Evaluating on the test split.
I0429 02:08:27.957286 140539785910080 submission_runner.py:415] Time since start: 537.97s, 	Step: 787, 	{'train/ssim': 0.7150580542428153, 'train/loss': 0.2948972838265555, 'validation/ssim': 0.6951711265035875, 'validation/loss': 0.31188432460563803, 'validation/num_examples': 3554, 'test/ssim': 0.7125673312709438, 'test/loss': 0.31417104406284907, 'test/num_examples': 3581, 'score': 307.76205229759216, 'total_duration': 537.9743309020996, 'accumulated_submission_time': 307.76205229759216, 'accumulated_eval_time': 230.12543058395386, 'accumulated_logging_time': 0.07505321502685547}
I0429 02:08:27.967784 140333526529792 logging_writer.py:48] [787] accumulated_eval_time=230.125431, accumulated_logging_time=0.075053, accumulated_submission_time=307.762052, global_step=787, preemption_count=0, score=307.762052, test/loss=0.314171, test/num_examples=3581, test/ssim=0.712567, total_duration=537.974331, train/loss=0.294897, train/ssim=0.715058, validation/loss=0.311884, validation/num_examples=3554, validation/ssim=0.695171
I0429 02:08:29.289198 140333518137088 logging_writer.py:48] [800] global_step=800, grad_norm=0.857650637626648, loss=0.27296897768974304
I0429 02:09:08.611323 140333526529792 logging_writer.py:48] [900] global_step=900, grad_norm=0.34464162588119507, loss=0.29800304770469666
I0429 02:09:41.337424 140333518137088 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.23344682157039642, loss=0.2589867413043976
I0429 02:09:48.175836 140539785910080 spec.py:298] Evaluating on the training split.
I0429 02:09:49.579566 140539785910080 spec.py:310] Evaluating on the validation split.
I0429 02:09:50.926192 140539785910080 spec.py:326] Evaluating on the test split.
I0429 02:09:52.273901 140539785910080 submission_runner.py:415] Time since start: 622.29s, 	Step: 1030, 	{'train/ssim': 0.7207576887948173, 'train/loss': 0.29063299724033903, 'validation/ssim': 0.7005196197286508, 'validation/loss': 0.3078587177300225, 'validation/num_examples': 3554, 'test/ssim': 0.7178819747451829, 'test/loss': 0.30993887553232335, 'test/num_examples': 3581, 'score': 387.95099687576294, 'total_duration': 622.2909388542175, 'accumulated_submission_time': 387.95099687576294, 'accumulated_eval_time': 234.22343945503235, 'accumulated_logging_time': 0.10109281539916992}
I0429 02:09:52.282016 140333526529792 logging_writer.py:48] [1030] accumulated_eval_time=234.223439, accumulated_logging_time=0.101093, accumulated_submission_time=387.950997, global_step=1030, preemption_count=0, score=387.950997, test/loss=0.309939, test/num_examples=3581, test/ssim=0.717882, total_duration=622.290939, train/loss=0.290633, train/ssim=0.720758, validation/loss=0.307859, validation/num_examples=3554, validation/ssim=0.700520
I0429 02:10:07.053056 140333518137088 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.33578670024871826, loss=0.2604827880859375
I0429 02:10:30.953107 140333526529792 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.41164958477020264, loss=0.2635768949985504
I0429 02:10:54.793128 140333518137088 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.17731770873069763, loss=0.3191494643688202
I0429 02:11:12.337609 140539785910080 spec.py:298] Evaluating on the training split.
I0429 02:11:13.742100 140539785910080 spec.py:310] Evaluating on the validation split.
I0429 02:11:15.090498 140539785910080 spec.py:326] Evaluating on the test split.
I0429 02:11:16.439583 140539785910080 submission_runner.py:415] Time since start: 706.46s, 	Step: 1375, 	{'train/ssim': 0.7249381201607841, 'train/loss': 0.2853630610874721, 'validation/ssim': 0.7042697268922341, 'validation/loss': 0.3021058880618669, 'validation/num_examples': 3554, 'test/ssim': 0.7215097230827632, 'test/loss': 0.3042023889647619, 'test/num_examples': 3581, 'score': 467.9926550388336, 'total_duration': 706.4566271305084, 'accumulated_submission_time': 467.9926550388336, 'accumulated_eval_time': 238.3253674507141, 'accumulated_logging_time': 0.11867952346801758}
I0429 02:11:16.447946 140333526529792 logging_writer.py:48] [1375] accumulated_eval_time=238.325367, accumulated_logging_time=0.118680, accumulated_submission_time=467.992655, global_step=1375, preemption_count=0, score=467.992655, test/loss=0.304202, test/num_examples=3581, test/ssim=0.721510, total_duration=706.456627, train/loss=0.285363, train/ssim=0.724938, validation/loss=0.302106, validation/num_examples=3554, validation/ssim=0.704270
I0429 02:11:20.376063 140333518137088 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.12019078433513641, loss=0.227474182844162
I0429 02:11:43.732574 140333526529792 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.2312355935573578, loss=0.2930096685886383
I0429 02:12:07.440382 140333518137088 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.1379493772983551, loss=0.23971466720104218
I0429 02:12:30.813711 140333526529792 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.4927857220172882, loss=0.3060450851917267
I0429 02:12:36.483669 140539785910080 spec.py:298] Evaluating on the training split.
I0429 02:12:37.886810 140539785910080 spec.py:310] Evaluating on the validation split.
I0429 02:12:39.235250 140539785910080 spec.py:326] Evaluating on the test split.
I0429 02:12:40.584587 140539785910080 submission_runner.py:415] Time since start: 790.60s, 	Step: 1726, 	{'train/ssim': 0.7273995535714286, 'train/loss': 0.2847374847957066, 'validation/ssim': 0.7069135074475943, 'validation/loss': 0.3024657104011325, 'validation/num_examples': 3554, 'test/ssim': 0.7237334412524434, 'test/loss': 0.30419182158222213, 'test/num_examples': 3581, 'score': 548.0149538516998, 'total_duration': 790.6016018390656, 'accumulated_submission_time': 548.0149538516998, 'accumulated_eval_time': 242.4262113571167, 'accumulated_logging_time': 0.13587284088134766}
I0429 02:12:40.594566 140333518137088 logging_writer.py:48] [1726] accumulated_eval_time=242.426211, accumulated_logging_time=0.135873, accumulated_submission_time=548.014954, global_step=1726, preemption_count=0, score=548.014954, test/loss=0.304192, test/num_examples=3581, test/ssim=0.723733, total_duration=790.601602, train/loss=0.284737, train/ssim=0.727400, validation/loss=0.302466, validation/num_examples=3554, validation/ssim=0.706914
I0429 02:12:56.052577 140333526529792 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.4221480190753937, loss=0.25036340951919556
I0429 02:13:19.705774 140333518137088 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.16177041828632355, loss=0.26698410511016846
I0429 02:13:43.535960 140333526529792 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.22818204760551453, loss=0.2805097699165344
I0429 02:14:00.649455 140539785910080 spec.py:298] Evaluating on the training split.
I0429 02:14:02.055186 140539785910080 spec.py:310] Evaluating on the validation split.
I0429 02:14:03.404729 140539785910080 spec.py:326] Evaluating on the test split.
I0429 02:14:04.752535 140539785910080 submission_runner.py:415] Time since start: 874.77s, 	Step: 2070, 	{'train/ssim': 0.731095450265067, 'train/loss': 0.27942529746464323, 'validation/ssim': 0.7112507473972988, 'validation/loss': 0.29621553179516036, 'validation/num_examples': 3554, 'test/ssim': 0.7286501375532324, 'test/loss': 0.29783189353314365, 'test/num_examples': 3581, 'score': 628.0572845935822, 'total_duration': 874.7695789337158, 'accumulated_submission_time': 628.0572845935822, 'accumulated_eval_time': 246.5292637348175, 'accumulated_logging_time': 0.15390849113464355}
I0429 02:14:04.760926 140333518137088 logging_writer.py:48] [2070] accumulated_eval_time=246.529264, accumulated_logging_time=0.153908, accumulated_submission_time=628.057285, global_step=2070, preemption_count=0, score=628.057285, test/loss=0.297832, test/num_examples=3581, test/ssim=0.728650, total_duration=874.769579, train/loss=0.279425, train/ssim=0.731095, validation/loss=0.296216, validation/num_examples=3554, validation/ssim=0.711251
I0429 02:14:09.875967 140333526529792 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.17767281830310822, loss=0.31422361731529236
I0429 02:14:33.730874 140333518137088 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.33573633432388306, loss=0.2645815908908844
I0429 02:14:57.189974 140333526529792 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.2053661346435547, loss=0.2195662260055542
I0429 02:15:20.643050 140333518137088 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.22532963752746582, loss=0.3295542597770691
I0429 02:15:24.866137 140539785910080 spec.py:298] Evaluating on the training split.
I0429 02:15:26.266779 140539785910080 spec.py:310] Evaluating on the validation split.
I0429 02:15:27.619126 140539785910080 spec.py:326] Evaluating on the test split.
I0429 02:15:28.971746 140539785910080 submission_runner.py:415] Time since start: 958.99s, 	Step: 2419, 	{'train/ssim': 0.7337995937892369, 'train/loss': 0.27874289240155903, 'validation/ssim': 0.7125858957336804, 'validation/loss': 0.2968753778203257, 'validation/num_examples': 3554, 'test/ssim': 0.7294778704010751, 'test/loss': 0.2986412868590303, 'test/num_examples': 3581, 'score': 708.1503098011017, 'total_duration': 958.9887974262238, 'accumulated_submission_time': 708.1503098011017, 'accumulated_eval_time': 250.63483452796936, 'accumulated_logging_time': 0.16992497444152832}
I0429 02:15:28.980209 140333526529792 logging_writer.py:48] [2419] accumulated_eval_time=250.634835, accumulated_logging_time=0.169925, accumulated_submission_time=708.150310, global_step=2419, preemption_count=0, score=708.150310, test/loss=0.298641, test/num_examples=3581, test/ssim=0.729478, total_duration=958.988797, train/loss=0.278743, train/ssim=0.733800, validation/loss=0.296875, validation/num_examples=3554, validation/ssim=0.712586
I0429 02:15:46.280085 140333518137088 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.30974382162094116, loss=0.29681432247161865
I0429 02:16:10.048517 140333526529792 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.3137741684913635, loss=0.28472575545310974
I0429 02:16:33.796655 140333518137088 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.1955677717924118, loss=0.3414038121700287
I0429 02:16:49.080096 140539785910080 spec.py:298] Evaluating on the training split.
I0429 02:16:50.483354 140539785910080 spec.py:310] Evaluating on the validation split.
I0429 02:16:51.831492 140539785910080 spec.py:326] Evaluating on the test split.
I0429 02:16:53.180821 140539785910080 submission_runner.py:415] Time since start: 1043.20s, 	Step: 2766, 	{'train/ssim': 0.734788077218192, 'train/loss': 0.275736791746957, 'validation/ssim': 0.7142063327632597, 'validation/loss': 0.29293495225450195, 'validation/num_examples': 3554, 'test/ssim': 0.7314729240479265, 'test/loss': 0.2945010545566008, 'test/num_examples': 3581, 'score': 788.2379522323608, 'total_duration': 1043.1978704929352, 'accumulated_submission_time': 788.2379522323608, 'accumulated_eval_time': 254.73551988601685, 'accumulated_logging_time': 0.18621373176574707}
I0429 02:16:53.190227 140333526529792 logging_writer.py:48] [2766] accumulated_eval_time=254.735520, accumulated_logging_time=0.186214, accumulated_submission_time=788.237952, global_step=2766, preemption_count=0, score=788.237952, test/loss=0.294501, test/num_examples=3581, test/ssim=0.731473, total_duration=1043.197870, train/loss=0.275737, train/ssim=0.734788, validation/loss=0.292935, validation/num_examples=3554, validation/ssim=0.714206
I0429 02:16:59.268862 140333518137088 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.14168696105480194, loss=0.33135557174682617
I0429 02:17:22.842846 140333526529792 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.1799270361661911, loss=0.2900207042694092
I0429 02:17:46.422686 140333518137088 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.1259736567735672, loss=0.24692706763744354
I0429 02:18:10.220730 140333526529792 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.19859641790390015, loss=0.2371303141117096
I0429 02:18:13.255393 140539785910080 spec.py:298] Evaluating on the training split.
I0429 02:18:14.659824 140539785910080 spec.py:310] Evaluating on the validation split.
I0429 02:18:16.009212 140539785910080 spec.py:326] Evaluating on the test split.
I0429 02:18:17.358464 140539785910080 submission_runner.py:415] Time since start: 1127.38s, 	Step: 3113, 	{'train/ssim': 0.7353628022330148, 'train/loss': 0.27536109515598844, 'validation/ssim': 0.7151233370410102, 'validation/loss': 0.29252824584754855, 'validation/num_examples': 3554, 'test/ssim': 0.7323495395620986, 'test/loss': 0.294078222901686, 'test/num_examples': 3581, 'score': 868.2897658348083, 'total_duration': 1127.375515460968, 'accumulated_submission_time': 868.2897658348083, 'accumulated_eval_time': 258.83854937553406, 'accumulated_logging_time': 0.20448684692382812}
I0429 02:18:17.367279 140333518137088 logging_writer.py:48] [3113] accumulated_eval_time=258.838549, accumulated_logging_time=0.204487, accumulated_submission_time=868.289766, global_step=3113, preemption_count=0, score=868.289766, test/loss=0.294078, test/num_examples=3581, test/ssim=0.732350, total_duration=1127.375515, train/loss=0.275361, train/ssim=0.735363, validation/loss=0.292528, validation/num_examples=3554, validation/ssim=0.715123
I0429 02:18:36.025001 140333526529792 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.20744039118289948, loss=0.2905135154724121
I0429 02:18:59.776565 140333518137088 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.2888597548007965, loss=0.2948804795742035
I0429 02:19:23.496906 140333526529792 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.12768293917179108, loss=0.3665570914745331
I0429 02:19:37.596224 140539785910080 spec.py:298] Evaluating on the training split.
I0429 02:19:38.999503 140539785910080 spec.py:310] Evaluating on the validation split.
I0429 02:19:40.347219 140539785910080 spec.py:326] Evaluating on the test split.
I0429 02:19:41.697229 140539785910080 submission_runner.py:415] Time since start: 1211.71s, 	Step: 3461, 	{'train/ssim': 0.7393684387207031, 'train/loss': 0.27410738808768137, 'validation/ssim': 0.7178773037422622, 'validation/loss': 0.2920780557558385, 'validation/num_examples': 3554, 'test/ssim': 0.7348711215660779, 'test/loss': 0.29366865160744204, 'test/num_examples': 3581, 'score': 948.5062127113342, 'total_duration': 1211.7142672538757, 'accumulated_submission_time': 948.5062127113342, 'accumulated_eval_time': 262.93949818611145, 'accumulated_logging_time': 0.2212672233581543}
I0429 02:19:41.705861 140333518137088 logging_writer.py:48] [3461] accumulated_eval_time=262.939498, accumulated_logging_time=0.221267, accumulated_submission_time=948.506213, global_step=3461, preemption_count=0, score=948.506213, test/loss=0.293669, test/num_examples=3581, test/ssim=0.734871, total_duration=1211.714267, train/loss=0.274107, train/ssim=0.739368, validation/loss=0.292078, validation/num_examples=3554, validation/ssim=0.717877
I0429 02:19:48.989969 140333526529792 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.10934492200613022, loss=0.40147456526756287
I0429 02:20:12.558852 140333518137088 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.11862185597419739, loss=0.2956538498401642
I0429 02:20:36.304512 140333526529792 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.1253649741411209, loss=0.2798407971858978
I0429 02:20:59.859457 140333518137088 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.1986004263162613, loss=0.27261772751808167
I0429 02:21:01.967085 140539785910080 spec.py:298] Evaluating on the training split.
I0429 02:21:03.369555 140539785910080 spec.py:310] Evaluating on the validation split.
I0429 02:21:04.719489 140539785910080 spec.py:326] Evaluating on the test split.
I0429 02:21:06.069406 140539785910080 submission_runner.py:415] Time since start: 1296.09s, 	Step: 3810, 	{'train/ssim': 0.7367277145385742, 'train/loss': 0.27425895418439594, 'validation/ssim': 0.7152640922859805, 'validation/loss': 0.2920967063410066, 'validation/num_examples': 3554, 'test/ssim': 0.7325144589063809, 'test/loss': 0.2936287341721063, 'test/num_examples': 3581, 'score': 1028.7549340724945, 'total_duration': 1296.0864536762238, 'accumulated_submission_time': 1028.7549340724945, 'accumulated_eval_time': 267.0417878627777, 'accumulated_logging_time': 0.2379755973815918}
I0429 02:21:06.077909 140333526529792 logging_writer.py:48] [3810] accumulated_eval_time=267.041788, accumulated_logging_time=0.237976, accumulated_submission_time=1028.754934, global_step=3810, preemption_count=0, score=1028.754934, test/loss=0.293629, test/num_examples=3581, test/ssim=0.732514, total_duration=1296.086454, train/loss=0.274259, train/ssim=0.736728, validation/loss=0.292097, validation/num_examples=3554, validation/ssim=0.715264
I0429 02:21:25.272101 140333518137088 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.15299779176712036, loss=0.27894991636276245
I0429 02:21:48.790354 140333526529792 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.18907645344734192, loss=0.21086736023426056
I0429 02:22:12.576335 140333518137088 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.1782377064228058, loss=0.27767157554626465
I0429 02:22:26.174936 140539785910080 spec.py:298] Evaluating on the training split.
I0429 02:22:27.577979 140539785910080 spec.py:310] Evaluating on the validation split.
I0429 02:22:28.925100 140539785910080 spec.py:326] Evaluating on the test split.
I0429 02:22:30.274272 140539785910080 submission_runner.py:415] Time since start: 1380.29s, 	Step: 4158, 	{'train/ssim': 0.7375711713518415, 'train/loss': 0.27315832887377056, 'validation/ssim': 0.7166850401835959, 'validation/loss': 0.29076567968090533, 'validation/num_examples': 3554, 'test/ssim': 0.7339212161407428, 'test/loss': 0.29220019449438006, 'test/num_examples': 3581, 'score': 1108.8399138450623, 'total_duration': 1380.2913031578064, 'accumulated_submission_time': 1108.8399138450623, 'accumulated_eval_time': 271.14106488227844, 'accumulated_logging_time': 0.2539694309234619}
I0429 02:22:30.282852 140333526529792 logging_writer.py:48] [4158] accumulated_eval_time=271.141065, accumulated_logging_time=0.253969, accumulated_submission_time=1108.839914, global_step=4158, preemption_count=0, score=1108.839914, test/loss=0.292200, test/num_examples=3581, test/ssim=0.733921, total_duration=1380.291303, train/loss=0.273158, train/ssim=0.737571, validation/loss=0.290766, validation/num_examples=3554, validation/ssim=0.716685
I0429 02:22:38.461931 140333518137088 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.16734382510185242, loss=0.30375659465789795
I0429 02:23:02.379432 140333526529792 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.15394030511379242, loss=0.3288100063800812
I0429 02:23:26.019349 140333518137088 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.2630423307418823, loss=0.28394821286201477
I0429 02:23:49.901288 140333526529792 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.1590729057788849, loss=0.23606044054031372
I0429 02:23:50.511543 140539785910080 spec.py:298] Evaluating on the training split.
I0429 02:23:51.916235 140539785910080 spec.py:310] Evaluating on the validation split.
I0429 02:23:53.264505 140539785910080 spec.py:326] Evaluating on the test split.
I0429 02:23:54.616579 140539785910080 submission_runner.py:415] Time since start: 1464.63s, 	Step: 4504, 	{'train/ssim': 0.7411070551191058, 'train/loss': 0.2723360913140433, 'validation/ssim': 0.7193260042601646, 'validation/loss': 0.2905454791256331, 'validation/num_examples': 3554, 'test/ssim': 0.73643829848506, 'test/loss': 0.29218734319367845, 'test/num_examples': 3581, 'score': 1189.056071281433, 'total_duration': 1464.633614063263, 'accumulated_submission_time': 1189.056071281433, 'accumulated_eval_time': 275.2460539340973, 'accumulated_logging_time': 0.27057838439941406}
I0429 02:23:54.625375 140333518137088 logging_writer.py:48] [4504] accumulated_eval_time=275.246054, accumulated_logging_time=0.270578, accumulated_submission_time=1189.056071, global_step=4504, preemption_count=0, score=1189.056071, test/loss=0.292187, test/num_examples=3581, test/ssim=0.736438, total_duration=1464.633614, train/loss=0.272336, train/ssim=0.741107, validation/loss=0.290545, validation/num_examples=3554, validation/ssim=0.719326
I0429 02:24:15.534674 140333526529792 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.1299104243516922, loss=0.33780428767204285
I0429 02:24:39.030558 140333518137088 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.2749847173690796, loss=0.28359276056289673
I0429 02:25:02.762445 140333526529792 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.05875670909881592, loss=0.283358633518219
I0429 02:25:14.646455 140539785910080 spec.py:298] Evaluating on the training split.
I0429 02:25:16.049987 140539785910080 spec.py:310] Evaluating on the validation split.
I0429 02:25:17.398656 140539785910080 spec.py:326] Evaluating on the test split.
I0429 02:25:18.751811 140539785910080 submission_runner.py:415] Time since start: 1548.77s, 	Step: 4852, 	{'train/ssim': 0.7403174127851214, 'train/loss': 0.27198709760393414, 'validation/ssim': 0.7187750735307048, 'validation/loss': 0.2899403827003904, 'validation/num_examples': 3554, 'test/ssim': 0.7359084294715164, 'test/loss': 0.29145604623359395, 'test/num_examples': 3581, 'score': 1269.0647795200348, 'total_duration': 1548.7688572406769, 'accumulated_submission_time': 1269.0647795200348, 'accumulated_eval_time': 279.3513662815094, 'accumulated_logging_time': 0.287339448928833}
I0429 02:25:18.761967 140333518137088 logging_writer.py:48] [4852] accumulated_eval_time=279.351366, accumulated_logging_time=0.287339, accumulated_submission_time=1269.064780, global_step=4852, preemption_count=0, score=1269.064780, test/loss=0.291456, test/num_examples=3581, test/ssim=0.735908, total_duration=1548.768857, train/loss=0.271987, train/ssim=0.740317, validation/loss=0.289940, validation/num_examples=3554, validation/ssim=0.718775
I0429 02:25:28.067816 140333526529792 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.08608531206846237, loss=0.33858558535575867
I0429 02:25:51.803814 140333518137088 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.13678276538848877, loss=0.374337762594223
I0429 02:26:15.255359 140333526529792 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.11398313194513321, loss=0.24084143340587616
I0429 02:26:39.014824 140333518137088 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.0955280214548111, loss=0.24952757358551025
I0429 02:26:39.019111 140539785910080 spec.py:298] Evaluating on the training split.
I0429 02:26:40.364984 140539785910080 spec.py:310] Evaluating on the validation split.
I0429 02:26:41.713905 140539785910080 spec.py:326] Evaluating on the test split.
I0429 02:26:43.065814 140539785910080 submission_runner.py:415] Time since start: 1633.08s, 	Step: 5201, 	{'train/ssim': 0.7397410529000419, 'train/loss': 0.2732788154057094, 'validation/ssim': 0.7192100477674803, 'validation/loss': 0.290820944490363, 'validation/num_examples': 3554, 'test/ssim': 0.7363480325851718, 'test/loss': 0.29220765983881947, 'test/num_examples': 3581, 'score': 1349.3097264766693, 'total_duration': 1633.0828609466553, 'accumulated_submission_time': 1349.3097264766693, 'accumulated_eval_time': 283.3979983329773, 'accumulated_logging_time': 0.3052060604095459}
I0429 02:26:43.077680 140333526529792 logging_writer.py:48] [5201] accumulated_eval_time=283.397998, accumulated_logging_time=0.305206, accumulated_submission_time=1349.309726, global_step=5201, preemption_count=0, score=1349.309726, test/loss=0.292208, test/num_examples=3581, test/ssim=0.736348, total_duration=1633.082861, train/loss=0.273279, train/ssim=0.739741, validation/loss=0.290821, validation/num_examples=3554, validation/ssim=0.719210
I0429 02:27:05.130440 140333518137088 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.1342521607875824, loss=0.18795716762542725
I0429 02:27:28.627351 140333526529792 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.11736200004816055, loss=0.3058958649635315
I0429 02:27:35.242205 140539785910080 spec.py:298] Evaluating on the training split.
I0429 02:27:36.645739 140539785910080 spec.py:310] Evaluating on the validation split.
I0429 02:27:37.996187 140539785910080 spec.py:326] Evaluating on the test split.
I0429 02:27:39.344172 140539785910080 submission_runner.py:415] Time since start: 1689.36s, 	Step: 5428, 	{'train/ssim': 0.7410827364240374, 'train/loss': 0.2717184509549822, 'validation/ssim': 0.7198157280968627, 'validation/loss': 0.2895858498456844, 'validation/num_examples': 3554, 'test/ssim': 0.7369983015830075, 'test/loss': 0.29108260856997, 'test/num_examples': 3581, 'score': 1401.4630432128906, 'total_duration': 1689.3612105846405, 'accumulated_submission_time': 1401.4630432128906, 'accumulated_eval_time': 287.49992513656616, 'accumulated_logging_time': 0.3252122402191162}
I0429 02:27:39.353520 140333518137088 logging_writer.py:48] [5428] accumulated_eval_time=287.499925, accumulated_logging_time=0.325212, accumulated_submission_time=1401.463043, global_step=5428, preemption_count=0, score=1401.463043, test/loss=0.291083, test/num_examples=3581, test/ssim=0.736998, total_duration=1689.361211, train/loss=0.271718, train/ssim=0.741083, validation/loss=0.289586, validation/num_examples=3554, validation/ssim=0.719816
I0429 02:27:39.367156 140333526529792 logging_writer.py:48] [5428] global_step=5428, preemption_count=0, score=1401.463043
I0429 02:27:39.421794 140539785910080 checkpoints.py:356] Saving checkpoint at step: 5428
I0429 02:27:39.670301 140539785910080 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_fancy/timing_lamb/fastmri_jax/trial_1/checkpoint_5428
I0429 02:27:39.670860 140539785910080 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_fancy/timing_lamb/fastmri_jax/trial_1/checkpoint_5428.
I0429 02:27:40.475083 140539785910080 submission_runner.py:578] Tuning trial 1/1
I0429 02:27:40.475334 140539785910080 submission_runner.py:579] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.19395352613343847, beta2=0.999, warmup_factor=0.05, weight_decay=0.002578922011395245, label_smoothing=0.1, dropout_rate=0.0)
I0429 02:27:40.483057 140539785910080 submission_runner.py:580] Metrics: {'eval_results': [(1, {'train/ssim': 0.24746649605887278, 'train/loss': 0.8312621116638184, 'validation/ssim': 0.23567495952513892, 'validation/loss': 0.8407013334447102, 'validation/num_examples': 3554, 'test/ssim': 0.25987310550692894, 'test/loss': 0.8378596046189961, 'test/num_examples': 3581, 'score': 67.32542753219604, 'total_duration': 284.6964030265808, 'accumulated_submission_time': 67.32542753219604, 'accumulated_eval_time': 217.37081623077393, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (331, {'train/ssim': 0.6715486390250069, 'train/loss': 0.3282586506434849, 'validation/ssim': 0.6476284149461874, 'validation/loss': 0.3484233283030564, 'validation/num_examples': 3554, 'test/ssim': 0.6675198066837127, 'test/loss': 0.3494381834028554, 'test/num_examples': 3581, 'score': 147.67657256126404, 'total_duration': 369.6275591850281, 'accumulated_submission_time': 147.67657256126404, 'accumulated_eval_time': 221.92145013809204, 'accumulated_logging_time': 0.024431705474853516, 'global_step': 331, 'preemption_count': 0}), (561, {'train/ssim': 0.7069178989955357, 'train/loss': 0.30312749317714144, 'validation/ssim': 0.6862289437297763, 'validation/loss': 0.3210422084381155, 'validation/num_examples': 3554, 'test/ssim': 0.7043093649643954, 'test/loss': 0.32294258516083146, 'test/num_examples': 3581, 'score': 227.7330882549286, 'total_duration': 453.8135116100311, 'accumulated_submission_time': 227.7330882549286, 'accumulated_eval_time': 226.02331042289734, 'accumulated_logging_time': 0.04869437217712402, 'global_step': 561, 'preemption_count': 0}), (787, {'train/ssim': 0.7150580542428153, 'train/loss': 0.2948972838265555, 'validation/ssim': 0.6951711265035875, 'validation/loss': 0.31188432460563803, 'validation/num_examples': 3554, 'test/ssim': 0.7125673312709438, 'test/loss': 0.31417104406284907, 'test/num_examples': 3581, 'score': 307.76205229759216, 'total_duration': 537.9743309020996, 'accumulated_submission_time': 307.76205229759216, 'accumulated_eval_time': 230.12543058395386, 'accumulated_logging_time': 0.07505321502685547, 'global_step': 787, 'preemption_count': 0}), (1030, {'train/ssim': 0.7207576887948173, 'train/loss': 0.29063299724033903, 'validation/ssim': 0.7005196197286508, 'validation/loss': 0.3078587177300225, 'validation/num_examples': 3554, 'test/ssim': 0.7178819747451829, 'test/loss': 0.30993887553232335, 'test/num_examples': 3581, 'score': 387.95099687576294, 'total_duration': 622.2909388542175, 'accumulated_submission_time': 387.95099687576294, 'accumulated_eval_time': 234.22343945503235, 'accumulated_logging_time': 0.10109281539916992, 'global_step': 1030, 'preemption_count': 0}), (1375, {'train/ssim': 0.7249381201607841, 'train/loss': 0.2853630610874721, 'validation/ssim': 0.7042697268922341, 'validation/loss': 0.3021058880618669, 'validation/num_examples': 3554, 'test/ssim': 0.7215097230827632, 'test/loss': 0.3042023889647619, 'test/num_examples': 3581, 'score': 467.9926550388336, 'total_duration': 706.4566271305084, 'accumulated_submission_time': 467.9926550388336, 'accumulated_eval_time': 238.3253674507141, 'accumulated_logging_time': 0.11867952346801758, 'global_step': 1375, 'preemption_count': 0}), (1726, {'train/ssim': 0.7273995535714286, 'train/loss': 0.2847374847957066, 'validation/ssim': 0.7069135074475943, 'validation/loss': 0.3024657104011325, 'validation/num_examples': 3554, 'test/ssim': 0.7237334412524434, 'test/loss': 0.30419182158222213, 'test/num_examples': 3581, 'score': 548.0149538516998, 'total_duration': 790.6016018390656, 'accumulated_submission_time': 548.0149538516998, 'accumulated_eval_time': 242.4262113571167, 'accumulated_logging_time': 0.13587284088134766, 'global_step': 1726, 'preemption_count': 0}), (2070, {'train/ssim': 0.731095450265067, 'train/loss': 0.27942529746464323, 'validation/ssim': 0.7112507473972988, 'validation/loss': 0.29621553179516036, 'validation/num_examples': 3554, 'test/ssim': 0.7286501375532324, 'test/loss': 0.29783189353314365, 'test/num_examples': 3581, 'score': 628.0572845935822, 'total_duration': 874.7695789337158, 'accumulated_submission_time': 628.0572845935822, 'accumulated_eval_time': 246.5292637348175, 'accumulated_logging_time': 0.15390849113464355, 'global_step': 2070, 'preemption_count': 0}), (2419, {'train/ssim': 0.7337995937892369, 'train/loss': 0.27874289240155903, 'validation/ssim': 0.7125858957336804, 'validation/loss': 0.2968753778203257, 'validation/num_examples': 3554, 'test/ssim': 0.7294778704010751, 'test/loss': 0.2986412868590303, 'test/num_examples': 3581, 'score': 708.1503098011017, 'total_duration': 958.9887974262238, 'accumulated_submission_time': 708.1503098011017, 'accumulated_eval_time': 250.63483452796936, 'accumulated_logging_time': 0.16992497444152832, 'global_step': 2419, 'preemption_count': 0}), (2766, {'train/ssim': 0.734788077218192, 'train/loss': 0.275736791746957, 'validation/ssim': 0.7142063327632597, 'validation/loss': 0.29293495225450195, 'validation/num_examples': 3554, 'test/ssim': 0.7314729240479265, 'test/loss': 0.2945010545566008, 'test/num_examples': 3581, 'score': 788.2379522323608, 'total_duration': 1043.1978704929352, 'accumulated_submission_time': 788.2379522323608, 'accumulated_eval_time': 254.73551988601685, 'accumulated_logging_time': 0.18621373176574707, 'global_step': 2766, 'preemption_count': 0}), (3113, {'train/ssim': 0.7353628022330148, 'train/loss': 0.27536109515598844, 'validation/ssim': 0.7151233370410102, 'validation/loss': 0.29252824584754855, 'validation/num_examples': 3554, 'test/ssim': 0.7323495395620986, 'test/loss': 0.294078222901686, 'test/num_examples': 3581, 'score': 868.2897658348083, 'total_duration': 1127.375515460968, 'accumulated_submission_time': 868.2897658348083, 'accumulated_eval_time': 258.83854937553406, 'accumulated_logging_time': 0.20448684692382812, 'global_step': 3113, 'preemption_count': 0}), (3461, {'train/ssim': 0.7393684387207031, 'train/loss': 0.27410738808768137, 'validation/ssim': 0.7178773037422622, 'validation/loss': 0.2920780557558385, 'validation/num_examples': 3554, 'test/ssim': 0.7348711215660779, 'test/loss': 0.29366865160744204, 'test/num_examples': 3581, 'score': 948.5062127113342, 'total_duration': 1211.7142672538757, 'accumulated_submission_time': 948.5062127113342, 'accumulated_eval_time': 262.93949818611145, 'accumulated_logging_time': 0.2212672233581543, 'global_step': 3461, 'preemption_count': 0}), (3810, {'train/ssim': 0.7367277145385742, 'train/loss': 0.27425895418439594, 'validation/ssim': 0.7152640922859805, 'validation/loss': 0.2920967063410066, 'validation/num_examples': 3554, 'test/ssim': 0.7325144589063809, 'test/loss': 0.2936287341721063, 'test/num_examples': 3581, 'score': 1028.7549340724945, 'total_duration': 1296.0864536762238, 'accumulated_submission_time': 1028.7549340724945, 'accumulated_eval_time': 267.0417878627777, 'accumulated_logging_time': 0.2379755973815918, 'global_step': 3810, 'preemption_count': 0}), (4158, {'train/ssim': 0.7375711713518415, 'train/loss': 0.27315832887377056, 'validation/ssim': 0.7166850401835959, 'validation/loss': 0.29076567968090533, 'validation/num_examples': 3554, 'test/ssim': 0.7339212161407428, 'test/loss': 0.29220019449438006, 'test/num_examples': 3581, 'score': 1108.8399138450623, 'total_duration': 1380.2913031578064, 'accumulated_submission_time': 1108.8399138450623, 'accumulated_eval_time': 271.14106488227844, 'accumulated_logging_time': 0.2539694309234619, 'global_step': 4158, 'preemption_count': 0}), (4504, {'train/ssim': 0.7411070551191058, 'train/loss': 0.2723360913140433, 'validation/ssim': 0.7193260042601646, 'validation/loss': 0.2905454791256331, 'validation/num_examples': 3554, 'test/ssim': 0.73643829848506, 'test/loss': 0.29218734319367845, 'test/num_examples': 3581, 'score': 1189.056071281433, 'total_duration': 1464.633614063263, 'accumulated_submission_time': 1189.056071281433, 'accumulated_eval_time': 275.2460539340973, 'accumulated_logging_time': 0.27057838439941406, 'global_step': 4504, 'preemption_count': 0}), (4852, {'train/ssim': 0.7403174127851214, 'train/loss': 0.27198709760393414, 'validation/ssim': 0.7187750735307048, 'validation/loss': 0.2899403827003904, 'validation/num_examples': 3554, 'test/ssim': 0.7359084294715164, 'test/loss': 0.29145604623359395, 'test/num_examples': 3581, 'score': 1269.0647795200348, 'total_duration': 1548.7688572406769, 'accumulated_submission_time': 1269.0647795200348, 'accumulated_eval_time': 279.3513662815094, 'accumulated_logging_time': 0.287339448928833, 'global_step': 4852, 'preemption_count': 0}), (5201, {'train/ssim': 0.7397410529000419, 'train/loss': 0.2732788154057094, 'validation/ssim': 0.7192100477674803, 'validation/loss': 0.290820944490363, 'validation/num_examples': 3554, 'test/ssim': 0.7363480325851718, 'test/loss': 0.29220765983881947, 'test/num_examples': 3581, 'score': 1349.3097264766693, 'total_duration': 1633.0828609466553, 'accumulated_submission_time': 1349.3097264766693, 'accumulated_eval_time': 283.3979983329773, 'accumulated_logging_time': 0.3052060604095459, 'global_step': 5201, 'preemption_count': 0}), (5428, {'train/ssim': 0.7410827364240374, 'train/loss': 0.2717184509549822, 'validation/ssim': 0.7198157280968627, 'validation/loss': 0.2895858498456844, 'validation/num_examples': 3554, 'test/ssim': 0.7369983015830075, 'test/loss': 0.29108260856997, 'test/num_examples': 3581, 'score': 1401.4630432128906, 'total_duration': 1689.3612105846405, 'accumulated_submission_time': 1401.4630432128906, 'accumulated_eval_time': 287.49992513656616, 'accumulated_logging_time': 0.3252122402191162, 'global_step': 5428, 'preemption_count': 0})], 'global_step': 5428}
I0429 02:27:40.483204 140539785910080 submission_runner.py:581] Timing: 1401.4630432128906
I0429 02:27:40.483246 140539785910080 submission_runner.py:582] ====================
I0429 02:27:40.483359 140539785910080 submission_runner.py:645] Final fastmri score: 1401.4630432128906
