python3 submission_runner.py --framework=jax --workload=imagenet_vit --submission_path=baselines/sam/jax/submission.py --tuning_search_space=baselines/sam/tuning_search_space.json --data_dir=/data/imagenet/jax --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_fancy/timing_sam --overwrite=True --save_checkpoints=False --max_global_steps=28000 --imagenet_v2_data_dir=/data/imagenet/jax 2>&1 | tee -a /logs/imagenet_vit_jax_04-28-2023-10-45-05.log
I0428 10:45:28.014297 140139854550848 logger_utils.py:61] Removing existing experiment directory /experiment_runs/timing_fancy/timing_sam/imagenet_vit_jax because --overwrite was set.
I0428 10:45:28.017609 140139854550848 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_fancy/timing_sam/imagenet_vit_jax.
I0428 10:45:28.093271 140139854550848 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0428 10:45:28.973217 140139854550848 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter Host CUDA
I0428 10:45:28.974282 140139854550848 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0428 10:45:28.980381 140139854550848 submission_runner.py:538] Using RNG seed 184099742
I0428 10:45:31.846719 140139854550848 submission_runner.py:547] --- Tuning run 1/1 ---
I0428 10:45:31.846989 140139854550848 submission_runner.py:552] Creating tuning directory at /experiment_runs/timing_fancy/timing_sam/imagenet_vit_jax/trial_1.
I0428 10:45:31.847187 140139854550848 logger_utils.py:92] Saving hparams to /experiment_runs/timing_fancy/timing_sam/imagenet_vit_jax/trial_1/hparams.json.
I0428 10:45:31.981016 140139854550848 submission_runner.py:241] Initializing dataset.
I0428 10:45:31.997198 140139854550848 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0428 10:45:32.006929 140139854550848 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0428 10:45:32.007049 140139854550848 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0428 10:45:32.291722 140139854550848 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0428 10:45:40.630497 140139854550848 submission_runner.py:248] Initializing model.
I0428 10:45:52.653381 140139854550848 submission_runner.py:258] Initializing optimizer.
I0428 10:45:53.421777 140139854550848 submission_runner.py:265] Initializing metrics bundle.
I0428 10:45:53.422001 140139854550848 submission_runner.py:282] Initializing checkpoint and logger.
I0428 10:45:53.423061 140139854550848 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_fancy/timing_sam/imagenet_vit_jax/trial_1 with prefix checkpoint_
I0428 10:45:54.325697 140139854550848 submission_runner.py:303] Saving meta data to /experiment_runs/timing_fancy/timing_sam/imagenet_vit_jax/trial_1/meta_data_0.json.
I0428 10:45:54.326649 140139854550848 submission_runner.py:306] Saving flags to /experiment_runs/timing_fancy/timing_sam/imagenet_vit_jax/trial_1/flags_0.json.
I0428 10:45:54.331997 140139854550848 submission_runner.py:318] Starting training loop.
I0428 10:47:02.937940 139963354052352 logging_writer.py:48] [0] global_step=0, grad_norm=0.3345949649810791, loss=6.907756805419922
I0428 10:47:02.958425 140139854550848 spec.py:298] Evaluating on the training split.
I0428 10:47:02.967066 140139854550848 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0428 10:47:02.976246 140139854550848 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0428 10:47:02.976357 140139854550848 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0428 10:47:03.057987 140139854550848 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0428 10:47:22.160783 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 10:47:22.169274 140139854550848 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0428 10:47:22.186984 140139854550848 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0428 10:47:22.187299 140139854550848 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0428 10:47:22.258334 140139854550848 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0428 10:47:41.369400 140139854550848 spec.py:326] Evaluating on the test split.
I0428 10:47:41.376531 140139854550848 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0428 10:47:41.381666 140139854550848 dataset_builder.py:510] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0428 10:47:41.418102 140139854550848 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0428 10:47:52.756661 140139854550848 submission_runner.py:415] Time since start: 118.42s, 	Step: 1, 	{'train/accuracy': 0.0008398437057621777, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 68.62623286247253, 'total_duration': 118.4245970249176, 'accumulated_submission_time': 68.62623286247253, 'accumulated_eval_time': 49.79820489883423, 'accumulated_logging_time': 0}
I0428 10:47:52.773925 139903694255872 logging_writer.py:48] [1] accumulated_eval_time=49.798205, accumulated_logging_time=0, accumulated_submission_time=68.626233, global_step=1, preemption_count=0, score=68.626233, test/accuracy=0.001000, test/loss=6.907757, test/num_examples=10000, total_duration=118.424597, train/accuracy=0.000840, train/loss=6.907756, validation/accuracy=0.001000, validation/loss=6.907756, validation/num_examples=50000
I0428 10:49:43.591999 139958077564672 logging_writer.py:48] [100] global_step=100, grad_norm=0.09884815663099289, loss=6.907160758972168
I0428 10:51:02.479875 139958085957376 logging_writer.py:48] [200] global_step=200, grad_norm=0.47213637828826904, loss=6.859492301940918
I0428 10:52:21.318785 139958077564672 logging_writer.py:48] [300] global_step=300, grad_norm=0.5354392528533936, loss=6.79081392288208
I0428 10:53:40.187294 139958085957376 logging_writer.py:48] [400] global_step=400, grad_norm=0.5554028153419495, loss=6.72855281829834
I0428 10:54:53.246317 140139854550848 spec.py:298] Evaluating on the training split.
I0428 10:55:00.101943 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 10:55:06.641342 140139854550848 spec.py:326] Evaluating on the test split.
I0428 10:55:08.445113 140139854550848 submission_runner.py:415] Time since start: 554.11s, 	Step: 494, 	{'train/accuracy': 0.010546875186264515, 'train/loss': 6.555016994476318, 'validation/accuracy': 0.010259999893605709, 'validation/loss': 6.565260410308838, 'validation/num_examples': 50000, 'test/accuracy': 0.008100000210106373, 'test/loss': 6.594497203826904, 'test/num_examples': 10000, 'score': 489.0834889411926, 'total_duration': 554.1130173206329, 'accumulated_submission_time': 489.0834889411926, 'accumulated_eval_time': 64.99695420265198, 'accumulated_logging_time': 0.025815963745117188}
I0428 10:55:08.457274 139903862044416 logging_writer.py:48] [494] accumulated_eval_time=64.996954, accumulated_logging_time=0.025816, accumulated_submission_time=489.083489, global_step=494, preemption_count=0, score=489.083489, test/accuracy=0.008100, test/loss=6.594497, test/num_examples=10000, total_duration=554.113017, train/accuracy=0.010547, train/loss=6.555017, validation/accuracy=0.010260, validation/loss=6.565260, validation/num_examples=50000
I0428 10:55:14.100761 139903945914112 logging_writer.py:48] [500] global_step=500, grad_norm=0.647854208946228, loss=6.669792652130127
I0428 10:56:32.967525 139903862044416 logging_writer.py:48] [600] global_step=600, grad_norm=0.7865727543830872, loss=6.6550822257995605
I0428 10:57:51.874404 139903945914112 logging_writer.py:48] [700] global_step=700, grad_norm=0.940254807472229, loss=6.556484222412109
I0428 10:59:10.725827 139903862044416 logging_writer.py:48] [800] global_step=800, grad_norm=0.7248642444610596, loss=6.5844011306762695
I0428 11:00:29.694300 139903945914112 logging_writer.py:48] [900] global_step=900, grad_norm=1.1366562843322754, loss=6.4793524742126465
I0428 11:01:48.591320 139903862044416 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.7552624940872192, loss=6.441509246826172
I0428 11:02:08.871269 140139854550848 spec.py:298] Evaluating on the training split.
I0428 11:02:15.706521 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 11:02:22.297468 140139854550848 spec.py:326] Evaluating on the test split.
I0428 11:02:24.040937 140139854550848 submission_runner.py:415] Time since start: 989.71s, 	Step: 1027, 	{'train/accuracy': 0.025214843451976776, 'train/loss': 6.11329984664917, 'validation/accuracy': 0.024639999493956566, 'validation/loss': 6.139117240905762, 'validation/num_examples': 50000, 'test/accuracy': 0.01720000058412552, 'test/loss': 6.217530727386475, 'test/num_examples': 10000, 'score': 909.4748973846436, 'total_duration': 989.70885181427, 'accumulated_submission_time': 909.4748973846436, 'accumulated_eval_time': 80.16657638549805, 'accumulated_logging_time': 0.05368757247924805}
I0428 11:02:24.052343 139903945914112 logging_writer.py:48] [1027] accumulated_eval_time=80.166576, accumulated_logging_time=0.053688, accumulated_submission_time=909.474897, global_step=1027, preemption_count=0, score=909.474897, test/accuracy=0.017200, test/loss=6.217531, test/num_examples=10000, total_duration=989.708852, train/accuracy=0.025215, train/loss=6.113300, validation/accuracy=0.024640, validation/loss=6.139117, validation/num_examples=50000
I0428 11:03:22.612753 139903862044416 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.7783178091049194, loss=6.425295829772949
I0428 11:04:43.203218 139903945914112 logging_writer.py:48] [1200] global_step=1200, grad_norm=1.1797363758087158, loss=6.534176349639893
I0428 11:06:02.134213 139903862044416 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.9570120573043823, loss=6.735349178314209
I0428 11:07:21.141590 139903945914112 logging_writer.py:48] [1400] global_step=1400, grad_norm=1.4944841861724854, loss=6.319943428039551
I0428 11:08:40.105386 139903862044416 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.8951472640037537, loss=6.272520542144775
I0428 11:09:24.816270 140139854550848 spec.py:298] Evaluating on the training split.
I0428 11:09:31.664314 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 11:09:38.240662 140139854550848 spec.py:326] Evaluating on the test split.
I0428 11:09:39.983909 140139854550848 submission_runner.py:415] Time since start: 1425.65s, 	Step: 1558, 	{'train/accuracy': 0.04140624776482582, 'train/loss': 5.8310465812683105, 'validation/accuracy': 0.03945999965071678, 'validation/loss': 5.869046211242676, 'validation/num_examples': 50000, 'test/accuracy': 0.029000001028180122, 'test/loss': 5.98787784576416, 'test/num_examples': 10000, 'score': 1330.2129111289978, 'total_duration': 1425.6517963409424, 'accumulated_submission_time': 1330.2129111289978, 'accumulated_eval_time': 95.33414936065674, 'accumulated_logging_time': 0.08363580703735352}
I0428 11:09:39.996639 139903945914112 logging_writer.py:48] [1558] accumulated_eval_time=95.334149, accumulated_logging_time=0.083636, accumulated_submission_time=1330.212911, global_step=1558, preemption_count=0, score=1330.212911, test/accuracy=0.029000, test/loss=5.987878, test/num_examples=10000, total_duration=1425.651796, train/accuracy=0.041406, train/loss=5.831047, validation/accuracy=0.039460, validation/loss=5.869046, validation/num_examples=50000
I0428 11:10:14.067376 139903862044416 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.9564807415008545, loss=6.191291809082031
I0428 11:11:33.070330 139903945914112 logging_writer.py:48] [1700] global_step=1700, grad_norm=1.0504761934280396, loss=6.168713569641113
I0428 11:12:52.036078 139903862044416 logging_writer.py:48] [1800] global_step=1800, grad_norm=1.0091155767440796, loss=6.64047384262085
I0428 11:14:11.014593 139903945914112 logging_writer.py:48] [1900] global_step=1900, grad_norm=1.3449361324310303, loss=6.221996307373047
I0428 11:15:30.062143 139903862044416 logging_writer.py:48] [2000] global_step=2000, grad_norm=1.0740917921066284, loss=6.144247055053711
I0428 11:16:40.035681 140139854550848 spec.py:298] Evaluating on the training split.
I0428 11:16:46.891854 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 11:16:53.477602 140139854550848 spec.py:326] Evaluating on the test split.
I0428 11:16:55.217062 140139854550848 submission_runner.py:415] Time since start: 1860.88s, 	Step: 2090, 	{'train/accuracy': 0.05296874791383743, 'train/loss': 5.600213527679443, 'validation/accuracy': 0.050680000334978104, 'validation/loss': 5.632956504821777, 'validation/num_examples': 50000, 'test/accuracy': 0.03700000047683716, 'test/loss': 5.799388408660889, 'test/num_examples': 10000, 'score': 1750.2307333946228, 'total_duration': 1860.8849341869354, 'accumulated_submission_time': 1750.2307333946228, 'accumulated_eval_time': 110.51544833183289, 'accumulated_logging_time': 0.11061310768127441}
I0428 11:16:55.234247 139903945914112 logging_writer.py:48] [2090] accumulated_eval_time=110.515448, accumulated_logging_time=0.110613, accumulated_submission_time=1750.230733, global_step=2090, preemption_count=0, score=1750.230733, test/accuracy=0.037000, test/loss=5.799388, test/num_examples=10000, total_duration=1860.884934, train/accuracy=0.052969, train/loss=5.600214, validation/accuracy=0.050680, validation/loss=5.632957, validation/num_examples=50000
I0428 11:17:04.240641 139903862044416 logging_writer.py:48] [2100] global_step=2100, grad_norm=1.530165195465088, loss=6.095825672149658
I0428 11:18:23.273611 139903945914112 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.9125679731369019, loss=5.976705551147461
I0428 11:19:43.653310 139903862044416 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.9408765435218811, loss=6.009236812591553
I0428 11:21:02.642734 139903945914112 logging_writer.py:48] [2400] global_step=2400, grad_norm=1.0389411449432373, loss=6.019408226013184
I0428 11:22:21.710839 139903862044416 logging_writer.py:48] [2500] global_step=2500, grad_norm=1.0803650617599487, loss=6.011588096618652
I0428 11:23:42.163066 139903945914112 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.987256646156311, loss=5.94992733001709
I0428 11:23:55.314205 140139854550848 spec.py:298] Evaluating on the training split.
I0428 11:24:02.148683 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 11:24:08.790247 140139854550848 spec.py:326] Evaluating on the test split.
I0428 11:24:10.530340 140139854550848 submission_runner.py:415] Time since start: 2296.20s, 	Step: 2618, 	{'train/accuracy': 0.07707031071186066, 'train/loss': 5.318606376647949, 'validation/accuracy': 0.07075999677181244, 'validation/loss': 5.357625484466553, 'validation/num_examples': 50000, 'test/accuracy': 0.055400002747774124, 'test/loss': 5.568378925323486, 'test/num_examples': 10000, 'score': 2170.288941383362, 'total_duration': 2296.1982436180115, 'accumulated_submission_time': 2170.288941383362, 'accumulated_eval_time': 125.7315263748169, 'accumulated_logging_time': 0.14241790771484375}
I0428 11:24:10.541515 139903862044416 logging_writer.py:48] [2618] accumulated_eval_time=125.731526, accumulated_logging_time=0.142418, accumulated_submission_time=2170.288941, global_step=2618, preemption_count=0, score=2170.288941, test/accuracy=0.055400, test/loss=5.568379, test/num_examples=10000, total_duration=2296.198244, train/accuracy=0.077070, train/loss=5.318606, validation/accuracy=0.070760, validation/loss=5.357625, validation/num_examples=50000
I0428 11:25:16.172465 139903945914112 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.8368207812309265, loss=6.070100784301758
I0428 11:26:35.146576 139903862044416 logging_writer.py:48] [2800] global_step=2800, grad_norm=1.0328840017318726, loss=5.835100173950195
I0428 11:27:54.144747 139903945914112 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.9269435405731201, loss=5.917613983154297
I0428 11:29:13.168021 139903862044416 logging_writer.py:48] [3000] global_step=3000, grad_norm=1.0015112161636353, loss=5.932499408721924
I0428 11:30:32.244488 139903945914112 logging_writer.py:48] [3100] global_step=3100, grad_norm=1.0185843706130981, loss=6.414054870605469
I0428 11:31:10.682677 140139854550848 spec.py:298] Evaluating on the training split.
I0428 11:31:17.544087 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 11:31:24.124418 140139854550848 spec.py:326] Evaluating on the test split.
I0428 11:31:25.862762 140139854550848 submission_runner.py:415] Time since start: 2731.53s, 	Step: 3150, 	{'train/accuracy': 0.0927148386836052, 'train/loss': 5.099536418914795, 'validation/accuracy': 0.08735999464988708, 'validation/loss': 5.1613850593566895, 'validation/num_examples': 50000, 'test/accuracy': 0.06640000641345978, 'test/loss': 5.398782253265381, 'test/num_examples': 10000, 'score': 2590.4081902503967, 'total_duration': 2731.530677318573, 'accumulated_submission_time': 2590.4081902503967, 'accumulated_eval_time': 140.91156840324402, 'accumulated_logging_time': 0.1684880256652832}
I0428 11:31:25.874485 139903862044416 logging_writer.py:48] [3150] accumulated_eval_time=140.911568, accumulated_logging_time=0.168488, accumulated_submission_time=2590.408190, global_step=3150, preemption_count=0, score=2590.408190, test/accuracy=0.066400, test/loss=5.398782, test/num_examples=10000, total_duration=2731.530677, train/accuracy=0.092715, train/loss=5.099536, validation/accuracy=0.087360, validation/loss=5.161385, validation/num_examples=50000
I0428 11:32:06.235611 139903945914112 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.931807816028595, loss=6.543259620666504
I0428 11:33:25.236285 139903862044416 logging_writer.py:48] [3300] global_step=3300, grad_norm=1.136077642440796, loss=5.739829063415527
I0428 11:34:46.207796 139903945914112 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.8824682831764221, loss=5.725075721740723
I0428 11:36:05.284005 139903862044416 logging_writer.py:48] [3500] global_step=3500, grad_norm=1.1446714401245117, loss=5.728771209716797
I0428 11:37:24.344327 139903945914112 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.8077407479286194, loss=6.595166206359863
I0428 11:38:26.207159 140139854550848 spec.py:298] Evaluating on the training split.
I0428 11:38:33.059482 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 11:38:39.715936 140139854550848 spec.py:326] Evaluating on the test split.
I0428 11:38:41.452553 140139854550848 submission_runner.py:415] Time since start: 3167.12s, 	Step: 3677, 	{'train/accuracy': 0.1263085901737213, 'train/loss': 4.826124668121338, 'validation/accuracy': 0.11747999489307404, 'validation/loss': 4.887425899505615, 'validation/num_examples': 50000, 'test/accuracy': 0.09140000492334366, 'test/loss': 5.158858299255371, 'test/num_examples': 10000, 'score': 3010.720355272293, 'total_duration': 3167.1204624176025, 'accumulated_submission_time': 3010.720355272293, 'accumulated_eval_time': 156.1569242477417, 'accumulated_logging_time': 0.19378304481506348}
I0428 11:38:41.464905 139903862044416 logging_writer.py:48] [3677] accumulated_eval_time=156.156924, accumulated_logging_time=0.193783, accumulated_submission_time=3010.720355, global_step=3677, preemption_count=0, score=3010.720355, test/accuracy=0.091400, test/loss=5.158858, test/num_examples=10000, total_duration=3167.120462, train/accuracy=0.126309, train/loss=4.826125, validation/accuracy=0.117480, validation/loss=4.887426, validation/num_examples=50000
I0428 11:39:00.544969 139903945914112 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.6840530633926392, loss=6.531352996826172
I0428 11:40:19.620490 139903862044416 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.8615052700042725, loss=5.637318134307861
I0428 11:41:38.675757 139903945914112 logging_writer.py:48] [3900] global_step=3900, grad_norm=1.099710464477539, loss=5.643115043640137
I0428 11:42:57.692500 139903862044416 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.9224964380264282, loss=6.0460615158081055
I0428 11:44:16.795476 139903945914112 logging_writer.py:48] [4100] global_step=4100, grad_norm=1.021772861480713, loss=5.568497657775879
I0428 11:45:35.874444 139903862044416 logging_writer.py:48] [4200] global_step=4200, grad_norm=1.0305958986282349, loss=5.4690446853637695
I0428 11:45:41.908063 140139854550848 spec.py:298] Evaluating on the training split.
I0428 11:45:48.765924 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 11:45:55.323710 140139854550848 spec.py:326] Evaluating on the test split.
I0428 11:45:57.056476 140139854550848 submission_runner.py:415] Time since start: 3602.72s, 	Step: 4209, 	{'train/accuracy': 0.1545117199420929, 'train/loss': 4.596144199371338, 'validation/accuracy': 0.1357799917459488, 'validation/loss': 4.702473163604736, 'validation/num_examples': 50000, 'test/accuracy': 0.10190000385046005, 'test/loss': 5.005126953125, 'test/num_examples': 10000, 'score': 3431.1415600776672, 'total_duration': 3602.7243819236755, 'accumulated_submission_time': 3431.1415600776672, 'accumulated_eval_time': 171.30527925491333, 'accumulated_logging_time': 0.2211616039276123}
I0428 11:45:57.069393 139903945914112 logging_writer.py:48] [4209] accumulated_eval_time=171.305279, accumulated_logging_time=0.221162, accumulated_submission_time=3431.141560, global_step=4209, preemption_count=0, score=3431.141560, test/accuracy=0.101900, test/loss=5.005127, test/num_examples=10000, total_duration=3602.724382, train/accuracy=0.154512, train/loss=4.596144, validation/accuracy=0.135780, validation/loss=4.702473, validation/num_examples=50000
I0428 11:47:12.615214 139903862044416 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.869602620601654, loss=5.618271827697754
I0428 11:48:31.640273 139903945914112 logging_writer.py:48] [4400] global_step=4400, grad_norm=1.0672240257263184, loss=5.547176837921143
I0428 11:49:50.672220 139903862044416 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.9498512148857117, loss=5.453114986419678
I0428 11:51:09.715116 139903945914112 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.7213477492332458, loss=6.2497148513793945
I0428 11:52:28.793923 139903862044416 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.7433097958564758, loss=6.462216377258301
I0428 11:52:57.765664 140139854550848 spec.py:298] Evaluating on the training split.
I0428 11:53:04.627527 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 11:53:11.266485 140139854550848 spec.py:326] Evaluating on the test split.
I0428 11:53:13.008710 140139854550848 submission_runner.py:415] Time since start: 4038.68s, 	Step: 4738, 	{'train/accuracy': 0.18035155534744263, 'train/loss': 4.386256694793701, 'validation/accuracy': 0.1657799929380417, 'validation/loss': 4.46188497543335, 'validation/num_examples': 50000, 'test/accuracy': 0.1274000108242035, 'test/loss': 4.790294647216797, 'test/num_examples': 10000, 'score': 3851.818570137024, 'total_duration': 4038.6766154766083, 'accumulated_submission_time': 3851.818570137024, 'accumulated_eval_time': 186.54827523231506, 'accumulated_logging_time': 0.246412992477417}
I0428 11:53:13.021518 139903945914112 logging_writer.py:48] [4738] accumulated_eval_time=186.548275, accumulated_logging_time=0.246413, accumulated_submission_time=3851.818570, global_step=4738, preemption_count=0, score=3851.818570, test/accuracy=0.127400, test/loss=4.790295, test/num_examples=10000, total_duration=4038.676615, train/accuracy=0.180352, train/loss=4.386257, validation/accuracy=0.165780, validation/loss=4.461885, validation/num_examples=50000
I0428 11:54:02.907235 139903862044416 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.8146563172340393, loss=6.362415313720703
I0428 11:55:22.055086 139903945914112 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.9015347361564636, loss=5.770191669464111
I0428 11:56:41.190081 139903862044416 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.9529244899749756, loss=5.58803653717041
I0428 11:58:00.241769 139903945914112 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.8763609528541565, loss=5.4226298332214355
I0428 11:59:19.296348 139903862044416 logging_writer.py:48] [5200] global_step=5200, grad_norm=1.1597245931625366, loss=5.320431709289551
I0428 12:00:13.556275 140139854550848 spec.py:298] Evaluating on the training split.
I0428 12:00:20.441042 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 12:00:27.044917 140139854550848 spec.py:326] Evaluating on the test split.
I0428 12:00:28.794738 140139854550848 submission_runner.py:415] Time since start: 4474.46s, 	Step: 5270, 	{'train/accuracy': 0.1917382776737213, 'train/loss': 4.260013103485107, 'validation/accuracy': 0.17931999266147614, 'validation/loss': 4.344618797302246, 'validation/num_examples': 50000, 'test/accuracy': 0.13370001316070557, 'test/loss': 4.6894426345825195, 'test/num_examples': 10000, 'score': 4272.332301616669, 'total_duration': 4474.462612390518, 'accumulated_submission_time': 4272.332301616669, 'accumulated_eval_time': 201.78666234016418, 'accumulated_logging_time': 0.27331113815307617}
I0428 12:00:28.810457 139903945914112 logging_writer.py:48] [5270] accumulated_eval_time=201.786662, accumulated_logging_time=0.273311, accumulated_submission_time=4272.332302, global_step=5270, preemption_count=0, score=4272.332302, test/accuracy=0.133700, test/loss=4.689443, test/num_examples=10000, total_duration=4474.462612, train/accuracy=0.191738, train/loss=4.260013, validation/accuracy=0.179320, validation/loss=4.344619, validation/num_examples=50000
I0428 12:00:56.392019 139903862044416 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.9632902145385742, loss=5.355140686035156
I0428 12:02:15.518362 139903945914112 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.6605718731880188, loss=6.051990985870361
I0428 12:03:34.593559 139903862044416 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.9214423894882202, loss=5.262107849121094
I0428 12:04:53.694269 139903945914112 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.994556725025177, loss=5.059234619140625
I0428 12:06:12.808618 139903862044416 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.7524349689483643, loss=6.025163173675537
I0428 12:07:29.255251 140139854550848 spec.py:298] Evaluating on the training split.
I0428 12:07:36.096443 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 12:07:42.838362 140139854550848 spec.py:326] Evaluating on the test split.
I0428 12:07:44.581815 140139854550848 submission_runner.py:415] Time since start: 4910.25s, 	Step: 5798, 	{'train/accuracy': 0.23185546696186066, 'train/loss': 3.9212608337402344, 'validation/accuracy': 0.21381999552249908, 'validation/loss': 4.0400309562683105, 'validation/num_examples': 50000, 'test/accuracy': 0.15980000793933868, 'test/loss': 4.44034481048584, 'test/num_examples': 10000, 'score': 4692.7579889297485, 'total_duration': 4910.249724149704, 'accumulated_submission_time': 4692.7579889297485, 'accumulated_eval_time': 217.1131889820099, 'accumulated_logging_time': 0.3010697364807129}
I0428 12:07:44.594467 139903945914112 logging_writer.py:48] [5798] accumulated_eval_time=217.113189, accumulated_logging_time=0.301070, accumulated_submission_time=4692.757989, global_step=5798, preemption_count=0, score=4692.757989, test/accuracy=0.159800, test/loss=4.440345, test/num_examples=10000, total_duration=4910.249724, train/accuracy=0.231855, train/loss=3.921261, validation/accuracy=0.213820, validation/loss=4.040031, validation/num_examples=50000
I0428 12:07:47.639383 139903862044416 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.8787105679512024, loss=5.459371089935303
I0428 12:09:07.407006 139903945914112 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.8202006220817566, loss=4.999505519866943
I0428 12:10:26.494648 139903862044416 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.7056155204772949, loss=6.429256439208984
I0428 12:11:45.544399 139903945914112 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.8497123718261719, loss=5.583176136016846
I0428 12:13:04.580874 139903862044416 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.8998796343803406, loss=5.223186016082764
I0428 12:14:23.628420 139903945914112 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.8078016638755798, loss=5.209692478179932
I0428 12:14:44.676823 140139854550848 spec.py:298] Evaluating on the training split.
I0428 12:14:51.539760 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 12:14:58.335350 140139854550848 spec.py:326] Evaluating on the test split.
I0428 12:15:00.067805 140139854550848 submission_runner.py:415] Time since start: 5345.74s, 	Step: 6328, 	{'train/accuracy': 0.25687500834465027, 'train/loss': 3.780136823654175, 'validation/accuracy': 0.23615999519824982, 'validation/loss': 3.8986923694610596, 'validation/num_examples': 50000, 'test/accuracy': 0.1819000095129013, 'test/loss': 4.325060844421387, 'test/num_examples': 10000, 'score': 5112.819319009781, 'total_duration': 5345.7357177734375, 'accumulated_submission_time': 5112.819319009781, 'accumulated_eval_time': 232.5041265487671, 'accumulated_logging_time': 0.3278629779815674}
I0428 12:15:00.082046 139903862044416 logging_writer.py:48] [6328] accumulated_eval_time=232.504127, accumulated_logging_time=0.327863, accumulated_submission_time=5112.819319, global_step=6328, preemption_count=0, score=5112.819319, test/accuracy=0.181900, test/loss=4.325061, test/num_examples=10000, total_duration=5345.735718, train/accuracy=0.256875, train/loss=3.780137, validation/accuracy=0.236160, validation/loss=3.898692, validation/num_examples=50000
I0428 12:15:58.410383 139903945914112 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.8703824281692505, loss=4.956037998199463
I0428 12:17:17.441280 139903862044416 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.6023485064506531, loss=6.302463531494141
I0428 12:18:36.498169 139903945914112 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.8554379343986511, loss=5.145023822784424
I0428 12:19:55.503991 139903862044416 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.8968065977096558, loss=5.466715335845947
I0428 12:21:14.642745 139903945914112 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.6553545594215393, loss=5.642923355102539
I0428 12:22:00.168326 140139854550848 spec.py:298] Evaluating on the training split.
I0428 12:22:07.059530 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 12:22:13.839496 140139854550848 spec.py:326] Evaluating on the test split.
I0428 12:22:15.564640 140139854550848 submission_runner.py:415] Time since start: 5781.23s, 	Step: 6859, 	{'train/accuracy': 0.2718749940395355, 'train/loss': 3.7162458896636963, 'validation/accuracy': 0.2526399791240692, 'validation/loss': 3.832369327545166, 'validation/num_examples': 50000, 'test/accuracy': 0.19470000267028809, 'test/loss': 4.258881092071533, 'test/num_examples': 10000, 'score': 5532.885047674179, 'total_duration': 5781.2325031757355, 'accumulated_submission_time': 5532.885047674179, 'accumulated_eval_time': 247.9003825187683, 'accumulated_logging_time': 0.3556487560272217}
I0428 12:22:15.582149 139903862044416 logging_writer.py:48] [6859] accumulated_eval_time=247.900383, accumulated_logging_time=0.355649, accumulated_submission_time=5532.885048, global_step=6859, preemption_count=0, score=5532.885048, test/accuracy=0.194700, test/loss=4.258881, test/num_examples=10000, total_duration=5781.232503, train/accuracy=0.271875, train/loss=3.716246, validation/accuracy=0.252640, validation/loss=3.832369, validation/num_examples=50000
I0428 12:22:48.927315 139903945914112 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.8844313621520996, loss=5.128901958465576
I0428 12:24:08.006251 139903862044416 logging_writer.py:48] [7000] global_step=7000, grad_norm=1.2170442342758179, loss=4.880731582641602
I0428 12:25:27.086057 139903945914112 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.9356507062911987, loss=4.793105125427246
I0428 12:26:46.171037 139903862044416 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.6822567582130432, loss=5.237796783447266
I0428 12:28:05.170114 139903945914112 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.8248090744018555, loss=4.772435188293457
I0428 12:29:15.983257 140139854550848 spec.py:298] Evaluating on the training split.
I0428 12:29:22.866722 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 12:29:29.565140 140139854550848 spec.py:326] Evaluating on the test split.
I0428 12:29:31.312292 140139854550848 submission_runner.py:415] Time since start: 6216.98s, 	Step: 7391, 	{'train/accuracy': 0.29435545206069946, 'train/loss': 3.515049457550049, 'validation/accuracy': 0.2699599862098694, 'validation/loss': 3.643329381942749, 'validation/num_examples': 50000, 'test/accuracy': 0.20160001516342163, 'test/loss': 4.11616849899292, 'test/num_examples': 10000, 'score': 5953.2651352882385, 'total_duration': 6216.980197429657, 'accumulated_submission_time': 5953.2651352882385, 'accumulated_eval_time': 263.22939467430115, 'accumulated_logging_time': 0.38712024688720703}
I0428 12:29:31.329337 139903862044416 logging_writer.py:48] [7391] accumulated_eval_time=263.229395, accumulated_logging_time=0.387120, accumulated_submission_time=5953.265135, global_step=7391, preemption_count=0, score=5953.265135, test/accuracy=0.201600, test/loss=4.116168, test/num_examples=10000, total_duration=6216.980197, train/accuracy=0.294355, train/loss=3.515049, validation/accuracy=0.269960, validation/loss=3.643329, validation/num_examples=50000
I0428 12:29:42.134910 139903945914112 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.6301780939102173, loss=5.839020252227783
I0428 12:31:01.139700 139903862044416 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.9175655841827393, loss=4.892892360687256
I0428 12:32:20.179678 139903945914112 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.6727931499481201, loss=6.0959792137146
I0428 12:33:39.208260 139903862044416 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.7432932257652283, loss=5.468539237976074
I0428 12:34:58.335535 139903945914112 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.5944316983222961, loss=6.18815279006958
I0428 12:36:17.401334 139903862044416 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.6822085976600647, loss=5.514009952545166
I0428 12:36:32.128873 140139854550848 spec.py:298] Evaluating on the training split.
I0428 12:36:39.064430 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 12:36:45.862362 140139854550848 spec.py:326] Evaluating on the test split.
I0428 12:36:47.590659 140139854550848 submission_runner.py:415] Time since start: 6653.26s, 	Step: 7920, 	{'train/accuracy': 0.3250390589237213, 'train/loss': 3.34314227104187, 'validation/accuracy': 0.3007799983024597, 'validation/loss': 3.472012758255005, 'validation/num_examples': 50000, 'test/accuracy': 0.23160001635551453, 'test/loss': 3.9504685401916504, 'test/num_examples': 10000, 'score': 6374.04229092598, 'total_duration': 6653.258536100388, 'accumulated_submission_time': 6374.04229092598, 'accumulated_eval_time': 278.6911153793335, 'accumulated_logging_time': 0.4194324016571045}
I0428 12:36:47.608171 139903945914112 logging_writer.py:48] [7920] accumulated_eval_time=278.691115, accumulated_logging_time=0.419432, accumulated_submission_time=6374.042291, global_step=7920, preemption_count=0, score=6374.042291, test/accuracy=0.231600, test/loss=3.950469, test/num_examples=10000, total_duration=6653.258536, train/accuracy=0.325039, train/loss=3.343142, validation/accuracy=0.300780, validation/loss=3.472013, validation/num_examples=50000
I0428 12:37:53.815032 139903862044416 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.924498975276947, loss=4.655704021453857
I0428 12:39:12.877990 139903945914112 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.7208709120750427, loss=5.092319488525391
I0428 12:40:31.937724 139903862044416 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.7572299242019653, loss=4.709075927734375
I0428 12:41:50.977734 139903945914112 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.8635203838348389, loss=4.529891490936279
I0428 12:43:10.065060 139903862044416 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.8486396670341492, loss=4.666903495788574
I0428 12:43:47.701874 140139854550848 spec.py:298] Evaluating on the training split.
I0428 12:43:54.655156 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 12:44:01.947102 140139854550848 spec.py:326] Evaluating on the test split.
I0428 12:44:03.681858 140139854550848 submission_runner.py:415] Time since start: 7089.35s, 	Step: 8449, 	{'train/accuracy': 0.3560546934604645, 'train/loss': 3.1021382808685303, 'validation/accuracy': 0.3172599971294403, 'validation/loss': 3.3010668754577637, 'validation/num_examples': 50000, 'test/accuracy': 0.24150000512599945, 'test/loss': 3.8180270195007324, 'test/num_examples': 10000, 'score': 6794.115318536758, 'total_duration': 7089.349767208099, 'accumulated_submission_time': 6794.115318536758, 'accumulated_eval_time': 294.67105293273926, 'accumulated_logging_time': 0.4504721164703369}
I0428 12:44:03.694825 139903945914112 logging_writer.py:48] [8449] accumulated_eval_time=294.671053, accumulated_logging_time=0.450472, accumulated_submission_time=6794.115319, global_step=8449, preemption_count=0, score=6794.115319, test/accuracy=0.241500, test/loss=3.818027, test/num_examples=10000, total_duration=7089.349767, train/accuracy=0.356055, train/loss=3.102138, validation/accuracy=0.317260, validation/loss=3.301067, validation/num_examples=50000
I0428 12:44:44.951218 139903862044416 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.6597415208816528, loss=5.695535182952881
I0428 12:46:03.932260 139903945914112 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.5535033345222473, loss=6.23028564453125
I0428 12:47:22.963576 139903862044416 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.8277531862258911, loss=4.585055351257324
I0428 12:48:41.961123 139903945914112 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.577483594417572, loss=6.200045108795166
I0428 12:50:00.934947 139903862044416 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.6510366201400757, loss=5.6920952796936035
I0428 12:51:03.847622 140139854550848 spec.py:298] Evaluating on the training split.
I0428 12:51:10.840898 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 12:51:18.657769 140139854550848 spec.py:326] Evaluating on the test split.
I0428 12:51:20.375217 140139854550848 submission_runner.py:415] Time since start: 7526.04s, 	Step: 8981, 	{'train/accuracy': 0.349433571100235, 'train/loss': 3.1157596111297607, 'validation/accuracy': 0.3248800039291382, 'validation/loss': 3.2564899921417236, 'validation/num_examples': 50000, 'test/accuracy': 0.24420000612735748, 'test/loss': 3.782517433166504, 'test/num_examples': 10000, 'score': 7214.247290611267, 'total_duration': 7526.043137311935, 'accumulated_submission_time': 7214.247290611267, 'accumulated_eval_time': 311.1986184120178, 'accumulated_logging_time': 0.47666311264038086}
I0428 12:51:20.388009 139903945914112 logging_writer.py:48] [8981] accumulated_eval_time=311.198618, accumulated_logging_time=0.476663, accumulated_submission_time=7214.247291, global_step=8981, preemption_count=0, score=7214.247291, test/accuracy=0.244200, test/loss=3.782517, test/num_examples=10000, total_duration=7526.043137, train/accuracy=0.349434, train/loss=3.115760, validation/accuracy=0.324880, validation/loss=3.256490, validation/num_examples=50000
I0428 12:51:36.295110 139903862044416 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.5900624990463257, loss=5.6025261878967285
I0428 12:52:55.330170 139903945914112 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.7545251250267029, loss=4.606634616851807
I0428 12:54:14.359462 139903862044416 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.7815813422203064, loss=4.656162738800049
I0428 12:55:33.380642 139903945914112 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.8352062702178955, loss=4.3876729011535645
I0428 12:56:52.398302 139903862044416 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.7352144122123718, loss=4.657469749450684
I0428 12:58:11.463905 139903945914112 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.6227561831474304, loss=5.500543117523193
I0428 12:58:20.651100 140139854550848 spec.py:298] Evaluating on the training split.
I0428 12:58:28.078750 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 12:58:36.445462 140139854550848 spec.py:326] Evaluating on the test split.
I0428 12:58:38.176918 140139854550848 submission_runner.py:415] Time since start: 7963.84s, 	Step: 9513, 	{'train/accuracy': 0.3665820360183716, 'train/loss': 3.022933006286621, 'validation/accuracy': 0.34147998690605164, 'validation/loss': 3.1442012786865234, 'validation/num_examples': 50000, 'test/accuracy': 0.2647000253200531, 'test/loss': 3.6739513874053955, 'test/num_examples': 10000, 'score': 7634.493385314941, 'total_duration': 7963.844837188721, 'accumulated_submission_time': 7634.493385314941, 'accumulated_eval_time': 328.7243986129761, 'accumulated_logging_time': 0.49944138526916504}
I0428 12:58:38.190815 139903862044416 logging_writer.py:48] [9513] accumulated_eval_time=328.724399, accumulated_logging_time=0.499441, accumulated_submission_time=7634.493385, global_step=9513, preemption_count=0, score=7634.493385, test/accuracy=0.264700, test/loss=3.673951, test/num_examples=10000, total_duration=7963.844837, train/accuracy=0.366582, train/loss=3.022933, validation/accuracy=0.341480, validation/loss=3.144201, validation/num_examples=50000
I0428 12:59:47.821586 139903945914112 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.7665290236473083, loss=4.418428421020508
I0428 13:01:06.866320 139903862044416 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.6855709552764893, loss=4.290188312530518
I0428 13:02:25.901375 139903945914112 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.5869098901748657, loss=5.3125176429748535
I0428 13:03:44.900073 139903862044416 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.7958859205245972, loss=4.469958305358887
I0428 13:05:03.905153 139903945914112 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.7714048027992249, loss=4.314134120941162
I0428 13:05:38.406306 140139854550848 spec.py:298] Evaluating on the training split.
I0428 13:05:46.153225 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 13:05:55.240384 140139854550848 spec.py:326] Evaluating on the test split.
I0428 13:05:56.975856 140139854550848 submission_runner.py:415] Time since start: 8402.64s, 	Step: 10045, 	{'train/accuracy': 0.3947070240974426, 'train/loss': 2.9099371433258057, 'validation/accuracy': 0.3610199987888336, 'validation/loss': 3.0789377689361572, 'validation/num_examples': 50000, 'test/accuracy': 0.2766000032424927, 'test/loss': 3.6357946395874023, 'test/num_examples': 10000, 'score': 8054.689996957779, 'total_duration': 8402.643758535385, 'accumulated_submission_time': 8054.689996957779, 'accumulated_eval_time': 347.29389333724976, 'accumulated_logging_time': 0.5252082347869873}
I0428 13:05:56.988834 139903862044416 logging_writer.py:48] [10045] accumulated_eval_time=347.293893, accumulated_logging_time=0.525208, accumulated_submission_time=8054.689997, global_step=10045, preemption_count=0, score=8054.689997, test/accuracy=0.276600, test/loss=3.635795, test/num_examples=10000, total_duration=8402.643759, train/accuracy=0.394707, train/loss=2.909937, validation/accuracy=0.361020, validation/loss=3.078938, validation/num_examples=50000
I0428 13:06:41.324607 139903945914112 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.7598172426223755, loss=4.225163459777832
I0428 13:08:00.370926 139903862044416 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.7231917381286621, loss=4.369714736938477
I0428 13:09:19.425400 139903945914112 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.642528235912323, loss=5.824397087097168
I0428 13:10:38.476084 139903862044416 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.6226486563682556, loss=5.210792541503906
I0428 13:11:57.554423 139903945914112 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.7615089416503906, loss=4.601657390594482
I0428 13:12:57.338857 140139854550848 spec.py:298] Evaluating on the training split.
I0428 13:13:05.478588 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 13:13:14.255955 140139854550848 spec.py:326] Evaluating on the test split.
I0428 13:13:15.979022 140139854550848 submission_runner.py:415] Time since start: 8841.65s, 	Step: 10577, 	{'train/accuracy': 0.40474608540534973, 'train/loss': 2.79238224029541, 'validation/accuracy': 0.3785399794578552, 'validation/loss': 2.940905809402466, 'validation/num_examples': 50000, 'test/accuracy': 0.2896000146865845, 'test/loss': 3.5022192001342773, 'test/num_examples': 10000, 'score': 8475.020947217941, 'total_duration': 8841.646888494492, 'accumulated_submission_time': 8475.020947217941, 'accumulated_eval_time': 365.9339756965637, 'accumulated_logging_time': 0.5502102375030518}
I0428 13:13:15.996913 139903862044416 logging_writer.py:48] [10577] accumulated_eval_time=365.933976, accumulated_logging_time=0.550210, accumulated_submission_time=8475.020947, global_step=10577, preemption_count=0, score=8475.020947, test/accuracy=0.289600, test/loss=3.502219, test/num_examples=10000, total_duration=8841.646888, train/accuracy=0.404746, train/loss=2.792382, validation/accuracy=0.378540, validation/loss=2.940906, validation/num_examples=50000
I0428 13:13:35.048178 139903945914112 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.7478089928627014, loss=4.254567623138428
I0428 13:14:54.099578 139903862044416 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.5789763331413269, loss=5.847601890563965
I0428 13:16:13.111510 139903945914112 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.5722125768661499, loss=6.02153205871582
I0428 13:17:32.187690 139903862044416 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.7291260957717896, loss=4.457467555999756
I0428 13:18:51.271882 139903945914112 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.7297141551971436, loss=4.345688819885254
I0428 13:20:10.331131 139903862044416 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.8295730352401733, loss=4.2397332191467285
I0428 13:20:16.362224 140139854550848 spec.py:298] Evaluating on the training split.
I0428 13:20:24.604129 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 13:20:33.524443 140139854550848 spec.py:326] Evaluating on the test split.
I0428 13:20:35.265069 140139854550848 submission_runner.py:415] Time since start: 9280.93s, 	Step: 11109, 	{'train/accuracy': 0.442695289850235, 'train/loss': 2.671494960784912, 'validation/accuracy': 0.3866399824619293, 'validation/loss': 2.9483296871185303, 'validation/num_examples': 50000, 'test/accuracy': 0.29750001430511475, 'test/loss': 3.4916672706604004, 'test/num_examples': 10000, 'score': 8895.366245031357, 'total_duration': 9280.932976484299, 'accumulated_submission_time': 8895.366245031357, 'accumulated_eval_time': 384.83676171302795, 'accumulated_logging_time': 0.580998420715332}
I0428 13:20:35.278664 139903945914112 logging_writer.py:48] [11109] accumulated_eval_time=384.836762, accumulated_logging_time=0.580998, accumulated_submission_time=8895.366245, global_step=11109, preemption_count=0, score=8895.366245, test/accuracy=0.297500, test/loss=3.491667, test/num_examples=10000, total_duration=9280.932976, train/accuracy=0.442695, train/loss=2.671495, validation/accuracy=0.386640, validation/loss=2.948330, validation/num_examples=50000
I0428 13:21:48.122397 139903862044416 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.5581550002098083, loss=6.124242782592773
I0428 13:23:07.217127 139903945914112 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.6182137131690979, loss=5.360969543457031
I0428 13:24:26.233872 139903862044416 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.6480040550231934, loss=4.707091808319092
I0428 13:25:45.254405 139903945914112 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.7766489386558533, loss=4.427535533905029
I0428 13:27:04.321627 139903862044416 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.7886015176773071, loss=4.033816337585449
I0428 13:27:35.665317 140139854550848 spec.py:298] Evaluating on the training split.
I0428 13:27:44.008532 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 13:27:52.972917 140139854550848 spec.py:326] Evaluating on the test split.
I0428 13:27:54.708951 140139854550848 submission_runner.py:415] Time since start: 9720.38s, 	Step: 11641, 	{'train/accuracy': 0.43720701336860657, 'train/loss': 2.7271111011505127, 'validation/accuracy': 0.4032000005245209, 'validation/loss': 2.897920846939087, 'validation/num_examples': 50000, 'test/accuracy': 0.3116000294685364, 'test/loss': 3.4618184566497803, 'test/num_examples': 10000, 'score': 9315.73442697525, 'total_duration': 9720.376859664917, 'accumulated_submission_time': 9315.73442697525, 'accumulated_eval_time': 403.8803470134735, 'accumulated_logging_time': 0.6061239242553711}
I0428 13:27:54.728377 139903945914112 logging_writer.py:48] [11641] accumulated_eval_time=403.880347, accumulated_logging_time=0.606124, accumulated_submission_time=9315.734427, global_step=11641, preemption_count=0, score=9315.734427, test/accuracy=0.311600, test/loss=3.461818, test/num_examples=10000, total_duration=9720.376860, train/accuracy=0.437207, train/loss=2.727111, validation/accuracy=0.403200, validation/loss=2.897921, validation/num_examples=50000
I0428 13:28:42.195693 139903862044416 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.7402545809745789, loss=4.277990341186523
I0428 13:30:01.286121 139903945914112 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.6290313005447388, loss=5.055810451507568
I0428 13:31:20.339033 139903862044416 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.7785809636116028, loss=4.2521138191223145
I0428 13:32:39.356693 139903945914112 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.7758730053901672, loss=4.081916332244873
I0428 13:33:58.435167 139903862044416 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.5596007704734802, loss=5.84037446975708
I0428 13:34:55.059332 140139854550848 spec.py:298] Evaluating on the training split.
I0428 13:35:03.570291 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 13:35:12.118334 140139854550848 spec.py:326] Evaluating on the test split.
I0428 13:35:13.837017 140139854550848 submission_runner.py:415] Time since start: 10159.50s, 	Step: 12173, 	{'train/accuracy': 0.4430468678474426, 'train/loss': 2.600149154663086, 'validation/accuracy': 0.4129199981689453, 'validation/loss': 2.7539680004119873, 'validation/num_examples': 50000, 'test/accuracy': 0.31390002369880676, 'test/loss': 3.352325439453125, 'test/num_examples': 10000, 'score': 9736.04249048233, 'total_duration': 10159.504890203476, 'accumulated_submission_time': 9736.04249048233, 'accumulated_eval_time': 422.65795135498047, 'accumulated_logging_time': 0.6414608955383301}
I0428 13:35:13.856892 139903945914112 logging_writer.py:48] [12173] accumulated_eval_time=422.657951, accumulated_logging_time=0.641461, accumulated_submission_time=9736.042490, global_step=12173, preemption_count=0, score=9736.042490, test/accuracy=0.313900, test/loss=3.352325, test/num_examples=10000, total_duration=10159.504890, train/accuracy=0.443047, train/loss=2.600149, validation/accuracy=0.412920, validation/loss=2.753968, validation/num_examples=50000
I0428 13:35:36.088653 139903862044416 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.6707308292388916, loss=6.096894264221191
I0428 13:36:55.138640 139903945914112 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.7662032246589661, loss=3.999462127685547
I0428 13:38:14.183713 139903862044416 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.7519648671150208, loss=4.409562587738037
I0428 13:39:33.210035 139903945914112 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.8676625490188599, loss=4.067502021789551
I0428 13:40:52.285481 139903862044416 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.7047507762908936, loss=3.9313149452209473
I0428 13:42:11.349430 139903945914112 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.5723186135292053, loss=4.901310920715332
I0428 13:42:14.223414 140139854550848 spec.py:298] Evaluating on the training split.
I0428 13:42:22.851425 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 13:42:31.405843 140139854550848 spec.py:326] Evaluating on the test split.
I0428 13:42:33.128213 140139854550848 submission_runner.py:415] Time since start: 10598.80s, 	Step: 12705, 	{'train/accuracy': 0.4716796875, 'train/loss': 2.4259772300720215, 'validation/accuracy': 0.4305199980735779, 'validation/loss': 2.649397373199463, 'validation/num_examples': 50000, 'test/accuracy': 0.3327000141143799, 'test/loss': 3.2345829010009766, 'test/num_examples': 10000, 'score': 10156.387952327728, 'total_duration': 10598.796095848083, 'accumulated_submission_time': 10156.387952327728, 'accumulated_eval_time': 441.56267404556274, 'accumulated_logging_time': 0.6752793788909912}
I0428 13:42:33.145308 139903862044416 logging_writer.py:48] [12705] accumulated_eval_time=441.562674, accumulated_logging_time=0.675279, accumulated_submission_time=10156.387952, global_step=12705, preemption_count=0, score=10156.387952, test/accuracy=0.332700, test/loss=3.234583, test/num_examples=10000, total_duration=10598.796096, train/accuracy=0.471680, train/loss=2.425977, validation/accuracy=0.430520, validation/loss=2.649397, validation/num_examples=50000
I0428 13:43:49.042142 139903945914112 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.7121967077255249, loss=4.245382308959961
I0428 13:45:08.104101 139903862044416 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.705762505531311, loss=3.901322841644287
I0428 13:46:27.131787 139903945914112 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.7822369933128357, loss=4.04073429107666
I0428 13:47:46.149655 139903862044416 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.7459976077079773, loss=3.9830596446990967
I0428 13:49:05.180336 139903945914112 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.8689048886299133, loss=3.9442341327667236
I0428 13:49:33.355561 140139854550848 spec.py:298] Evaluating on the training split.
I0428 13:49:42.060808 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 13:49:50.625912 140139854550848 spec.py:326] Evaluating on the test split.
I0428 13:49:52.360341 140139854550848 submission_runner.py:415] Time since start: 11038.03s, 	Step: 13237, 	{'train/accuracy': 0.457832008600235, 'train/loss': 2.5370965003967285, 'validation/accuracy': 0.4262000024318695, 'validation/loss': 2.693544864654541, 'validation/num_examples': 50000, 'test/accuracy': 0.33390000462532043, 'test/loss': 3.26370906829834, 'test/num_examples': 10000, 'score': 10576.579124450684, 'total_duration': 11038.028251171112, 'accumulated_submission_time': 10576.579124450684, 'accumulated_eval_time': 460.5674238204956, 'accumulated_logging_time': 0.7043473720550537}
I0428 13:49:52.372262 139903862044416 logging_writer.py:48] [13237] accumulated_eval_time=460.567424, accumulated_logging_time=0.704347, accumulated_submission_time=10576.579124, global_step=13237, preemption_count=0, score=10576.579124, test/accuracy=0.333900, test/loss=3.263709, test/num_examples=10000, total_duration=11038.028251, train/accuracy=0.457832, train/loss=2.537097, validation/accuracy=0.426200, validation/loss=2.693545, validation/num_examples=50000
I0428 13:50:42.957739 139903945914112 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.5450807809829712, loss=5.952905178070068
I0428 13:52:02.037577 139903862044416 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.5845233201980591, loss=5.975727081298828
I0428 13:53:21.083544 139903945914112 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.8244658708572388, loss=3.9180474281311035
I0428 13:54:40.145862 139903862044416 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.6606003046035767, loss=5.478034019470215
I0428 13:55:59.237631 139903945914112 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.6852536201477051, loss=5.381389617919922
I0428 13:56:52.676580 140139854550848 spec.py:298] Evaluating on the training split.
I0428 13:57:01.310939 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 13:57:09.961488 140139854550848 spec.py:326] Evaluating on the test split.
I0428 13:57:11.691951 140139854550848 submission_runner.py:415] Time since start: 11477.36s, 	Step: 13769, 	{'train/accuracy': 0.4757617115974426, 'train/loss': 2.4135210514068604, 'validation/accuracy': 0.44463998079299927, 'validation/loss': 2.5901448726654053, 'validation/num_examples': 50000, 'test/accuracy': 0.3472000062465668, 'test/loss': 3.194788694381714, 'test/num_examples': 10000, 'score': 10996.867826223373, 'total_duration': 11477.359836101532, 'accumulated_submission_time': 10996.867826223373, 'accumulated_eval_time': 479.5827302932739, 'accumulated_logging_time': 0.7248437404632568}
I0428 13:57:11.711541 139903862044416 logging_writer.py:48] [13769] accumulated_eval_time=479.582730, accumulated_logging_time=0.724844, accumulated_submission_time=10996.867826, global_step=13769, preemption_count=0, score=10996.867826, test/accuracy=0.347200, test/loss=3.194789, test/num_examples=10000, total_duration=11477.359836, train/accuracy=0.475762, train/loss=2.413521, validation/accuracy=0.444640, validation/loss=2.590145, validation/num_examples=50000
I0428 13:57:37.020178 139903945914112 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.7764754295349121, loss=4.169050693511963
I0428 13:58:56.061006 139903862044416 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.7273686528205872, loss=3.8992738723754883
I0428 14:00:15.079563 139903945914112 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.578465461730957, loss=4.823564052581787
I0428 14:01:34.124684 139903862044416 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.6380226016044617, loss=5.368223667144775
I0428 14:02:53.224776 139903945914112 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.8497287034988403, loss=3.906191825866699
I0428 14:04:12.383100 139903862044416 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.7317630052566528, loss=3.830177068710327
I0428 14:04:12.393880 140139854550848 spec.py:298] Evaluating on the training split.
I0428 14:04:20.806945 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 14:04:29.346721 140139854550848 spec.py:326] Evaluating on the test split.
I0428 14:04:31.072654 140139854550848 submission_runner.py:415] Time since start: 11916.74s, 	Step: 14301, 	{'train/accuracy': 0.4971874952316284, 'train/loss': 2.3649439811706543, 'validation/accuracy': 0.4597399830818176, 'validation/loss': 2.551039695739746, 'validation/num_examples': 50000, 'test/accuracy': 0.3468000292778015, 'test/loss': 3.1658267974853516, 'test/num_examples': 10000, 'score': 11417.531684398651, 'total_duration': 11916.740573883057, 'accumulated_submission_time': 11417.531684398651, 'accumulated_eval_time': 498.26143622398376, 'accumulated_logging_time': 0.7559685707092285}
I0428 14:04:31.085751 139903945914112 logging_writer.py:48] [14301] accumulated_eval_time=498.261436, accumulated_logging_time=0.755969, accumulated_submission_time=11417.531684, global_step=14301, preemption_count=0, score=11417.531684, test/accuracy=0.346800, test/loss=3.165827, test/num_examples=10000, total_duration=11916.740574, train/accuracy=0.497187, train/loss=2.364944, validation/accuracy=0.459740, validation/loss=2.551040, validation/num_examples=50000
I0428 14:05:50.154850 139903862044416 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.8665145039558411, loss=3.8763771057128906
I0428 14:07:09.243304 139903945914112 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.741811215877533, loss=3.81413197517395
I0428 14:08:28.324625 139903862044416 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.8233564496040344, loss=3.799767017364502
I0428 14:09:47.350965 139903945914112 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.8899170756340027, loss=3.8976383209228516
I0428 14:11:06.388014 139903862044416 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.7656272649765015, loss=3.7088587284088135
I0428 14:11:31.412327 140139854550848 spec.py:298] Evaluating on the training split.
I0428 14:11:40.064120 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 14:11:48.736160 140139854550848 spec.py:326] Evaluating on the test split.
I0428 14:11:50.462948 140139854550848 submission_runner.py:415] Time since start: 12356.13s, 	Step: 14833, 	{'train/accuracy': 0.4978320300579071, 'train/loss': 2.3248939514160156, 'validation/accuracy': 0.46355998516082764, 'validation/loss': 2.4946036338806152, 'validation/num_examples': 50000, 'test/accuracy': 0.35840001702308655, 'test/loss': 3.106715679168701, 'test/num_examples': 10000, 'score': 11837.842361688614, 'total_duration': 12356.130858659744, 'accumulated_submission_time': 11837.842361688614, 'accumulated_eval_time': 517.3120231628418, 'accumulated_logging_time': 0.7780416011810303}
I0428 14:11:50.475213 139903945914112 logging_writer.py:48] [14833] accumulated_eval_time=517.312023, accumulated_logging_time=0.778042, accumulated_submission_time=11837.842362, global_step=14833, preemption_count=0, score=11837.842362, test/accuracy=0.358400, test/loss=3.106716, test/num_examples=10000, total_duration=12356.130859, train/accuracy=0.497832, train/loss=2.324894, validation/accuracy=0.463560, validation/loss=2.494604, validation/num_examples=50000
I0428 14:12:44.197094 139903862044416 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.8371008038520813, loss=3.931811809539795
I0428 14:14:03.285192 139903945914112 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.7939701676368713, loss=3.8645682334899902
I0428 14:15:22.409462 139903862044416 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.7388937473297119, loss=3.896656036376953
I0428 14:16:41.496408 139903945914112 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.7804710268974304, loss=3.7745187282562256
I0428 14:18:00.627827 139903862044416 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.6329108476638794, loss=5.1486287117004395
I0428 14:18:50.983685 140139854550848 spec.py:298] Evaluating on the training split.
I0428 14:18:59.643723 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 14:19:08.258332 140139854550848 spec.py:326] Evaluating on the test split.
I0428 14:19:09.998326 140139854550848 submission_runner.py:415] Time since start: 12795.67s, 	Step: 15365, 	{'train/accuracy': 0.5204492211341858, 'train/loss': 2.185494899749756, 'validation/accuracy': 0.46705999970436096, 'validation/loss': 2.431356906890869, 'validation/num_examples': 50000, 'test/accuracy': 0.3630000054836273, 'test/loss': 3.044809579849243, 'test/num_examples': 10000, 'score': 12258.334409952164, 'total_duration': 12795.66621851921, 'accumulated_submission_time': 12258.334409952164, 'accumulated_eval_time': 536.326602935791, 'accumulated_logging_time': 0.7996213436126709}
I0428 14:19:10.018991 139903945914112 logging_writer.py:48] [15365] accumulated_eval_time=536.326603, accumulated_logging_time=0.799621, accumulated_submission_time=12258.334410, global_step=15365, preemption_count=0, score=12258.334410, test/accuracy=0.363000, test/loss=3.044810, test/num_examples=10000, total_duration=12795.666219, train/accuracy=0.520449, train/loss=2.185495, validation/accuracy=0.467060, validation/loss=2.431357, validation/num_examples=50000
I0428 14:19:38.480310 139903862044416 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.5592624545097351, loss=5.712963104248047
I0428 14:20:57.586550 139903945914112 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.8225654363632202, loss=3.9016873836517334
I0428 14:22:16.659771 139903862044416 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.8689624071121216, loss=3.766578197479248
I0428 14:23:35.673731 139903945914112 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.7554805278778076, loss=3.714625835418701
I0428 14:24:54.761825 139903862044416 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.8146181106567383, loss=3.8164846897125244
I0428 14:26:10.316204 140139854550848 spec.py:298] Evaluating on the training split.
I0428 14:26:19.070310 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 14:26:27.679064 140139854550848 spec.py:326] Evaluating on the test split.
I0428 14:26:29.406424 140139854550848 submission_runner.py:415] Time since start: 13235.07s, 	Step: 15897, 	{'train/accuracy': 0.5139062404632568, 'train/loss': 2.328256845474243, 'validation/accuracy': 0.4758400022983551, 'validation/loss': 2.50581693649292, 'validation/num_examples': 50000, 'test/accuracy': 0.36660000681877136, 'test/loss': 3.117124557495117, 'test/num_examples': 10000, 'score': 12678.610414981842, 'total_duration': 13235.07434797287, 'accumulated_submission_time': 12678.610414981842, 'accumulated_eval_time': 555.4167995452881, 'accumulated_logging_time': 0.834545373916626}
I0428 14:26:29.418167 139903945914112 logging_writer.py:48] [15897] accumulated_eval_time=555.416800, accumulated_logging_time=0.834545, accumulated_submission_time=12678.610415, global_step=15897, preemption_count=0, score=12678.610415, test/accuracy=0.366600, test/loss=3.117125, test/num_examples=10000, total_duration=13235.074348, train/accuracy=0.513906, train/loss=2.328257, validation/accuracy=0.475840, validation/loss=2.505817, validation/num_examples=50000
I0428 14:26:32.604168 139903862044416 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.6460426449775696, loss=4.4762773513793945
I0428 14:27:51.614962 139903945914112 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.8115563988685608, loss=3.7261276245117188
I0428 14:29:10.675935 139903862044416 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.8093847036361694, loss=3.9809181690216064
I0428 14:30:29.788795 139903945914112 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.7076972126960754, loss=4.727867126464844
I0428 14:31:48.889602 139903862044416 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.8405327200889587, loss=3.786665439605713
I0428 14:33:07.981565 139903945914112 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.5958677530288696, loss=5.309566497802734
I0428 14:33:29.829756 140139854550848 spec.py:298] Evaluating on the training split.
I0428 14:33:38.493699 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 14:33:47.134665 140139854550848 spec.py:326] Evaluating on the test split.
I0428 14:33:48.872256 140139854550848 submission_runner.py:415] Time since start: 13674.54s, 	Step: 16429, 	{'train/accuracy': 0.5244335532188416, 'train/loss': 2.1837618350982666, 'validation/accuracy': 0.48687997460365295, 'validation/loss': 2.377197027206421, 'validation/num_examples': 50000, 'test/accuracy': 0.37780001759529114, 'test/loss': 2.9959685802459717, 'test/num_examples': 10000, 'score': 13099.006846666336, 'total_duration': 13674.540163516998, 'accumulated_submission_time': 13099.006846666336, 'accumulated_eval_time': 574.4592666625977, 'accumulated_logging_time': 0.8544793128967285}
I0428 14:33:48.887429 139903862044416 logging_writer.py:48] [16429] accumulated_eval_time=574.459267, accumulated_logging_time=0.854479, accumulated_submission_time=13099.006847, global_step=16429, preemption_count=0, score=13099.006847, test/accuracy=0.377800, test/loss=2.995969, test/num_examples=10000, total_duration=13674.540164, train/accuracy=0.524434, train/loss=2.183762, validation/accuracy=0.486880, validation/loss=2.377197, validation/num_examples=50000
I0428 14:34:45.761169 139903945914112 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.6509295701980591, loss=4.80724573135376
I0428 14:36:04.749486 139903862044416 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.7378982901573181, loss=4.0124945640563965
I0428 14:37:23.761822 139903945914112 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.7321239113807678, loss=3.865527391433716
I0428 14:38:42.784359 139903862044416 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.8618265390396118, loss=3.7287402153015137
I0428 14:40:01.794346 139903945914112 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.7224156856536865, loss=3.864673137664795
I0428 14:40:48.903926 140139854550848 spec.py:298] Evaluating on the training split.
I0428 14:40:57.573952 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 14:41:06.158056 140139854550848 spec.py:326] Evaluating on the test split.
I0428 14:41:07.905676 140139854550848 submission_runner.py:415] Time since start: 14113.57s, 	Step: 16961, 	{'train/accuracy': 0.5375390648841858, 'train/loss': 2.1189522743225098, 'validation/accuracy': 0.4976399838924408, 'validation/loss': 2.316465139389038, 'validation/num_examples': 50000, 'test/accuracy': 0.3846000134944916, 'test/loss': 2.953903913497925, 'test/num_examples': 10000, 'score': 13519.002524614334, 'total_duration': 14113.573559045792, 'accumulated_submission_time': 13519.002524614334, 'accumulated_eval_time': 593.4609508514404, 'accumulated_logging_time': 0.8834478855133057}
I0428 14:41:07.924890 139903862044416 logging_writer.py:48] [16961] accumulated_eval_time=593.460951, accumulated_logging_time=0.883448, accumulated_submission_time=13519.002525, global_step=16961, preemption_count=0, score=13519.002525, test/accuracy=0.384600, test/loss=2.953904, test/num_examples=10000, total_duration=14113.573559, train/accuracy=0.537539, train/loss=2.118952, validation/accuracy=0.497640, validation/loss=2.316465, validation/num_examples=50000
I0428 14:41:39.556473 139903945914112 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.6878068447113037, loss=4.259267807006836
I0428 14:42:58.609684 139903862044416 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.7914596199989319, loss=3.7821598052978516
I0428 14:44:17.683817 139903945914112 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.6771941781044006, loss=5.670240879058838
I0428 14:45:36.689579 139903862044416 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.7350574135780334, loss=4.159470081329346
I0428 14:46:55.770383 139903945914112 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.7671322226524353, loss=3.5451126098632812
I0428 14:48:08.154533 140139854550848 spec.py:298] Evaluating on the training split.
I0428 14:48:16.794926 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 14:48:25.404571 140139854550848 spec.py:326] Evaluating on the test split.
I0428 14:48:27.133685 140139854550848 submission_runner.py:415] Time since start: 14552.80s, 	Step: 17493, 	{'train/accuracy': 0.5332617163658142, 'train/loss': 2.166902780532837, 'validation/accuracy': 0.49616000056266785, 'validation/loss': 2.3383491039276123, 'validation/num_examples': 50000, 'test/accuracy': 0.392300009727478, 'test/loss': 2.9509389400482178, 'test/num_examples': 10000, 'score': 13939.211968898773, 'total_duration': 14552.80158662796, 'accumulated_submission_time': 13939.211968898773, 'accumulated_eval_time': 612.4400579929352, 'accumulated_logging_time': 0.9158008098602295}
I0428 14:48:27.152319 139903862044416 logging_writer.py:48] [17493] accumulated_eval_time=612.440058, accumulated_logging_time=0.915801, accumulated_submission_time=13939.211969, global_step=17493, preemption_count=0, score=13939.211969, test/accuracy=0.392300, test/loss=2.950939, test/num_examples=10000, total_duration=14552.801587, train/accuracy=0.533262, train/loss=2.166903, validation/accuracy=0.496160, validation/loss=2.338349, validation/num_examples=50000
I0428 14:48:33.504629 139903945914112 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.6132866144180298, loss=5.005276203155518
I0428 14:49:52.511103 139903862044416 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.6742239594459534, loss=5.800939559936523
I0428 14:51:11.570005 139903945914112 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.8158300518989563, loss=3.6808810234069824
I0428 14:52:30.628003 139903862044416 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.7409483790397644, loss=4.138193130493164
I0428 14:53:49.682581 139903945914112 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.8925430178642273, loss=3.5900275707244873
I0428 14:55:08.699734 139903862044416 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.7242019772529602, loss=3.8162879943847656
I0428 14:55:27.385038 140139854550848 spec.py:298] Evaluating on the training split.
I0428 14:55:36.067277 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 14:55:44.728338 140139854550848 spec.py:326] Evaluating on the test split.
I0428 14:55:46.452713 140139854550848 submission_runner.py:415] Time since start: 14992.12s, 	Step: 18025, 	{'train/accuracy': 0.5684961080551147, 'train/loss': 2.0121724605560303, 'validation/accuracy': 0.5016199946403503, 'validation/loss': 2.319152355194092, 'validation/num_examples': 50000, 'test/accuracy': 0.38700002431869507, 'test/loss': 2.9415924549102783, 'test/num_examples': 10000, 'score': 14359.42431640625, 'total_duration': 14992.120625019073, 'accumulated_submission_time': 14359.42431640625, 'accumulated_eval_time': 631.5076887607574, 'accumulated_logging_time': 0.947563886642456}
I0428 14:55:46.469053 139903945914112 logging_writer.py:48] [18025] accumulated_eval_time=631.507689, accumulated_logging_time=0.947564, accumulated_submission_time=14359.424316, global_step=18025, preemption_count=0, score=14359.424316, test/accuracy=0.387000, test/loss=2.941592, test/num_examples=10000, total_duration=14992.120625, train/accuracy=0.568496, train/loss=2.012172, validation/accuracy=0.501620, validation/loss=2.319152, validation/num_examples=50000
I0428 14:56:46.515067 139903862044416 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.7612649202346802, loss=3.984722137451172
I0428 14:58:05.534096 139903945914112 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.9391878843307495, loss=3.728593587875366
I0428 14:59:24.581799 139903862044416 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.8097359538078308, loss=5.492863655090332
I0428 15:00:43.638066 139903945914112 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.680671751499176, loss=4.615263938903809
I0428 15:02:02.651970 139903862044416 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.7807451486587524, loss=3.5913913249969482
I0428 15:02:46.628254 140139854550848 spec.py:298] Evaluating on the training split.
I0428 15:02:55.276148 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 15:03:03.948962 140139854550848 spec.py:326] Evaluating on the test split.
I0428 15:03:05.679631 140139854550848 submission_runner.py:415] Time since start: 15431.35s, 	Step: 18557, 	{'train/accuracy': 0.5511132478713989, 'train/loss': 2.0523898601531982, 'validation/accuracy': 0.5094799995422363, 'validation/loss': 2.25439190864563, 'validation/num_examples': 50000, 'test/accuracy': 0.39180001616477966, 'test/loss': 2.8889594078063965, 'test/num_examples': 10000, 'score': 14779.566605567932, 'total_duration': 15431.34752202034, 'accumulated_submission_time': 14779.566605567932, 'accumulated_eval_time': 650.5590052604675, 'accumulated_logging_time': 0.9737651348114014}
I0428 15:03:05.700723 139903945914112 logging_writer.py:48] [18557] accumulated_eval_time=650.559005, accumulated_logging_time=0.973765, accumulated_submission_time=14779.566606, global_step=18557, preemption_count=0, score=14779.566606, test/accuracy=0.391800, test/loss=2.888959, test/num_examples=10000, total_duration=15431.347522, train/accuracy=0.551113, train/loss=2.052390, validation/accuracy=0.509480, validation/loss=2.254392, validation/num_examples=50000
I0428 15:03:40.469452 139903862044416 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.7085712552070618, loss=4.231215953826904
I0428 15:04:59.547673 139903945914112 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.7614564299583435, loss=5.537142753601074
I0428 15:06:18.617530 139903862044416 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.8381309509277344, loss=3.674046516418457
I0428 15:07:37.663901 139903945914112 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.839156448841095, loss=3.5312345027923584
I0428 15:08:56.712991 139903862044416 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.8192936182022095, loss=3.8099873065948486
I0428 15:10:05.955082 140139854550848 spec.py:298] Evaluating on the training split.
I0428 15:10:14.759437 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 15:10:23.449962 140139854550848 spec.py:326] Evaluating on the test split.
I0428 15:10:25.167087 140139854550848 submission_runner.py:415] Time since start: 15870.84s, 	Step: 19089, 	{'train/accuracy': 0.5531445145606995, 'train/loss': 2.077678918838501, 'validation/accuracy': 0.5150799751281738, 'validation/loss': 2.260133743286133, 'validation/num_examples': 50000, 'test/accuracy': 0.4002000093460083, 'test/loss': 2.8854315280914307, 'test/num_examples': 10000, 'score': 15199.800146818161, 'total_duration': 15870.835018873215, 'accumulated_submission_time': 15199.800146818161, 'accumulated_eval_time': 669.7709956169128, 'accumulated_logging_time': 1.008716344833374}
I0428 15:10:25.180367 139903945914112 logging_writer.py:48] [19089] accumulated_eval_time=669.770996, accumulated_logging_time=1.008716, accumulated_submission_time=15199.800147, global_step=19089, preemption_count=0, score=15199.800147, test/accuracy=0.400200, test/loss=2.885432, test/num_examples=10000, total_duration=15870.835019, train/accuracy=0.553145, train/loss=2.077679, validation/accuracy=0.515080, validation/loss=2.260134, validation/num_examples=50000
I0428 15:10:34.668790 139903862044416 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.7388449907302856, loss=3.882632255554199
I0428 15:11:53.695431 139903945914112 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.6679340600967407, loss=4.947933197021484
I0428 15:13:12.732335 139903862044416 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.8222412467002869, loss=3.5652902126312256
I0428 15:14:31.749120 139903945914112 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.6388555765151978, loss=5.196996688842773
I0428 15:15:50.779428 139903862044416 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.7002195715904236, loss=5.102643966674805
I0428 15:17:09.836233 139903945914112 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.7460234761238098, loss=3.541330337524414
I0428 15:17:25.347911 140139854550848 spec.py:298] Evaluating on the training split.
I0428 15:17:33.980089 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 15:17:42.661999 140139854550848 spec.py:326] Evaluating on the test split.
I0428 15:17:44.396017 140139854550848 submission_runner.py:415] Time since start: 16310.06s, 	Step: 19621, 	{'train/accuracy': 0.5641406178474426, 'train/loss': 2.0283477306365967, 'validation/accuracy': 0.5128799676895142, 'validation/loss': 2.267571210861206, 'validation/num_examples': 50000, 'test/accuracy': 0.3947000205516815, 'test/loss': 2.917112350463867, 'test/num_examples': 10000, 'score': 15619.951186418533, 'total_duration': 16310.063931703568, 'accumulated_submission_time': 15619.951186418533, 'accumulated_eval_time': 688.8190546035767, 'accumulated_logging_time': 1.0314035415649414}
I0428 15:17:44.408929 139903862044416 logging_writer.py:48] [19621] accumulated_eval_time=688.819055, accumulated_logging_time=1.031404, accumulated_submission_time=15619.951186, global_step=19621, preemption_count=0, score=15619.951186, test/accuracy=0.394700, test/loss=2.917112, test/num_examples=10000, total_duration=16310.063932, train/accuracy=0.564141, train/loss=2.028348, validation/accuracy=0.512880, validation/loss=2.267571, validation/num_examples=50000
I0428 15:18:47.607286 139903945914112 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.7691829204559326, loss=3.5582966804504395
I0428 15:20:06.640799 139903862044416 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.8477930426597595, loss=3.491135835647583
I0428 15:21:25.710714 139903945914112 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.7438936233520508, loss=4.596277236938477
I0428 15:22:44.761269 139903862044416 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.6653786301612854, loss=5.772246360778809
I0428 15:24:03.787889 139903945914112 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.7178853750228882, loss=4.268060207366943
I0428 15:24:44.568048 140139854550848 spec.py:298] Evaluating on the training split.
I0428 15:24:53.195732 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 15:25:01.896761 140139854550848 spec.py:326] Evaluating on the test split.
I0428 15:25:03.625182 140139854550848 submission_runner.py:415] Time since start: 16749.29s, 	Step: 20153, 	{'train/accuracy': 0.5636132955551147, 'train/loss': 1.9520843029022217, 'validation/accuracy': 0.5191999673843384, 'validation/loss': 2.1721267700195312, 'validation/num_examples': 50000, 'test/accuracy': 0.41050001978874207, 'test/loss': 2.8079943656921387, 'test/num_examples': 10000, 'score': 16040.094812870026, 'total_duration': 16749.29306912422, 'accumulated_submission_time': 16040.094812870026, 'accumulated_eval_time': 707.8761336803436, 'accumulated_logging_time': 1.0528249740600586}
I0428 15:25:03.646295 139903862044416 logging_writer.py:48] [20153] accumulated_eval_time=707.876134, accumulated_logging_time=1.052825, accumulated_submission_time=16040.094813, global_step=20153, preemption_count=0, score=16040.094813, test/accuracy=0.410500, test/loss=2.807994, test/num_examples=10000, total_duration=16749.293069, train/accuracy=0.563613, train/loss=1.952084, validation/accuracy=0.519200, validation/loss=2.172127, validation/num_examples=50000
I0428 15:25:41.586511 139903945914112 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.9032493829727173, loss=3.7457661628723145
I0428 15:27:00.591119 139903862044416 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.8048721551895142, loss=3.744260311126709
I0428 15:28:19.642083 139903945914112 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.6966367959976196, loss=4.079881191253662
I0428 15:29:38.669257 139903862044416 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.7813636064529419, loss=3.475872755050659
I0428 15:30:57.676337 139903945914112 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.7141861915588379, loss=5.751729965209961
I0428 15:32:03.767546 140139854550848 spec.py:298] Evaluating on the training split.
I0428 15:32:12.470839 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 15:32:21.126183 140139854550848 spec.py:326] Evaluating on the test split.
I0428 15:32:22.856887 140139854550848 submission_runner.py:415] Time since start: 17188.52s, 	Step: 20685, 	{'train/accuracy': 0.5686327815055847, 'train/loss': 1.9721496105194092, 'validation/accuracy': 0.5298399925231934, 'validation/loss': 2.1614620685577393, 'validation/num_examples': 50000, 'test/accuracy': 0.41360002756118774, 'test/loss': 2.797513008117676, 'test/num_examples': 10000, 'score': 16460.195034503937, 'total_duration': 17188.524811029434, 'accumulated_submission_time': 16460.195034503937, 'accumulated_eval_time': 726.9654531478882, 'accumulated_logging_time': 1.087967872619629}
I0428 15:32:22.869019 139903862044416 logging_writer.py:48] [20685] accumulated_eval_time=726.965453, accumulated_logging_time=1.087968, accumulated_submission_time=16460.195035, global_step=20685, preemption_count=0, score=16460.195035, test/accuracy=0.413600, test/loss=2.797513, test/num_examples=10000, total_duration=17188.524811, train/accuracy=0.568633, train/loss=1.972150, validation/accuracy=0.529840, validation/loss=2.161462, validation/num_examples=50000
I0428 15:32:35.516930 139903945914112 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.9155667424201965, loss=3.618786573410034
I0428 15:33:54.544581 139903862044416 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.7295402884483337, loss=4.019412994384766
I0428 15:35:13.631432 139903945914112 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.8441094160079956, loss=3.609711170196533
I0428 15:36:32.695782 139903862044416 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.8144599199295044, loss=3.5088143348693848
I0428 15:37:51.730021 139903945914112 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.7036809325218201, loss=5.575206279754639
I0428 15:39:10.809570 139903862044416 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.6793965697288513, loss=4.584656715393066
I0428 15:39:23.159576 140139854550848 spec.py:298] Evaluating on the training split.
I0428 15:39:31.811769 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 15:39:40.546565 140139854550848 spec.py:326] Evaluating on the test split.
I0428 15:39:42.277357 140139854550848 submission_runner.py:415] Time since start: 17627.95s, 	Step: 21217, 	{'train/accuracy': 0.5780078172683716, 'train/loss': 1.881686806678772, 'validation/accuracy': 0.5295199751853943, 'validation/loss': 2.1187939643859863, 'validation/num_examples': 50000, 'test/accuracy': 0.41430002450942993, 'test/loss': 2.755758047103882, 'test/num_examples': 10000, 'score': 16880.469057559967, 'total_duration': 17627.945291757584, 'accumulated_submission_time': 16880.469057559967, 'accumulated_eval_time': 746.0832223892212, 'accumulated_logging_time': 1.1094913482666016}
I0428 15:39:42.289476 139903945914112 logging_writer.py:48] [21217] accumulated_eval_time=746.083222, accumulated_logging_time=1.109491, accumulated_submission_time=16880.469058, global_step=21217, preemption_count=0, score=16880.469058, test/accuracy=0.414300, test/loss=2.755758, test/num_examples=10000, total_duration=17627.945292, train/accuracy=0.578008, train/loss=1.881687, validation/accuracy=0.529520, validation/loss=2.118794, validation/num_examples=50000
I0428 15:40:48.651119 139903862044416 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.7875415086746216, loss=3.6130707263946533
I0428 15:42:07.712908 139903945914112 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.7057101130485535, loss=4.088424205780029
I0428 15:43:26.776318 139903862044416 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.8236725926399231, loss=3.6774606704711914
I0428 15:44:45.865661 139903945914112 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.7874658107757568, loss=3.650235891342163
I0428 15:46:04.944609 139903862044416 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.8948732614517212, loss=3.4726195335388184
I0428 15:46:42.592461 140139854550848 spec.py:298] Evaluating on the training split.
I0428 15:46:51.251370 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 15:46:59.945763 140139854550848 spec.py:326] Evaluating on the test split.
I0428 15:47:01.675720 140139854550848 submission_runner.py:415] Time since start: 18067.34s, 	Step: 21749, 	{'train/accuracy': 0.5782617330551147, 'train/loss': 1.9042574167251587, 'validation/accuracy': 0.5382800102233887, 'validation/loss': 2.106940269470215, 'validation/num_examples': 50000, 'test/accuracy': 0.4287000298500061, 'test/loss': 2.7356207370758057, 'test/num_examples': 10000, 'score': 17300.757103443146, 'total_duration': 18067.343608617783, 'accumulated_submission_time': 17300.757103443146, 'accumulated_eval_time': 765.1664226055145, 'accumulated_logging_time': 1.1296513080596924}
I0428 15:47:01.698011 139903945914112 logging_writer.py:48] [21749] accumulated_eval_time=765.166423, accumulated_logging_time=1.129651, accumulated_submission_time=17300.757103, global_step=21749, preemption_count=0, score=17300.757103, test/accuracy=0.428700, test/loss=2.735621, test/num_examples=10000, total_duration=18067.343609, train/accuracy=0.578262, train/loss=1.904257, validation/accuracy=0.538280, validation/loss=2.106940, validation/num_examples=50000
I0428 15:47:42.843029 139903862044416 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.842531144618988, loss=3.4811582565307617
I0428 15:49:01.935146 139903945914112 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.828426718711853, loss=3.5177159309387207
I0428 15:50:20.986791 139903862044416 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.9053412079811096, loss=3.415327787399292
I0428 15:51:40.009813 139903945914112 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.7498118281364441, loss=4.615871429443359
I0428 15:52:59.055427 139903862044416 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.7333751320838928, loss=4.407349586486816
I0428 15:54:02.004948 140139854550848 spec.py:298] Evaluating on the training split.
I0428 15:54:10.638801 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 15:54:19.384726 140139854550848 spec.py:326] Evaluating on the test split.
I0428 15:54:21.133090 140139854550848 submission_runner.py:415] Time since start: 18506.80s, 	Step: 22281, 	{'train/accuracy': 0.5894922018051147, 'train/loss': 1.885851502418518, 'validation/accuracy': 0.5292800068855286, 'validation/loss': 2.1599833965301514, 'validation/num_examples': 50000, 'test/accuracy': 0.4183000326156616, 'test/loss': 2.782557487487793, 'test/num_examples': 10000, 'score': 17721.043602228165, 'total_duration': 18506.80100297928, 'accumulated_submission_time': 17721.043602228165, 'accumulated_eval_time': 784.2945342063904, 'accumulated_logging_time': 1.1654083728790283}
I0428 15:54:21.147313 139903945914112 logging_writer.py:48] [22281] accumulated_eval_time=784.294534, accumulated_logging_time=1.165408, accumulated_submission_time=17721.043602, global_step=22281, preemption_count=0, score=17721.043602, test/accuracy=0.418300, test/loss=2.782557, test/num_examples=10000, total_duration=18506.801003, train/accuracy=0.589492, train/loss=1.885852, validation/accuracy=0.529280, validation/loss=2.159983, validation/num_examples=50000
I0428 15:54:37.004214 139903862044416 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.8952320218086243, loss=3.4778451919555664
I0428 15:55:56.040688 139903945914112 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.8308346271514893, loss=3.422503709793091
I0428 15:57:15.069740 139903862044416 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.7821962237358093, loss=3.8354759216308594
I0428 15:58:34.129015 139903945914112 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.8304622769355774, loss=3.514521598815918
I0428 15:59:53.177755 139903862044416 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.7676684260368347, loss=3.8793396949768066
I0428 16:01:12.248946 139903945914112 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.8183574080467224, loss=5.642911911010742
I0428 16:01:21.440828 140139854550848 spec.py:298] Evaluating on the training split.
I0428 16:01:30.070501 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 16:01:38.754040 140139854550848 spec.py:326] Evaluating on the test split.
I0428 16:01:40.481773 140139854550848 submission_runner.py:415] Time since start: 18946.15s, 	Step: 22813, 	{'train/accuracy': 0.5831249952316284, 'train/loss': 1.8943523168563843, 'validation/accuracy': 0.5414000153541565, 'validation/loss': 2.102210521697998, 'validation/num_examples': 50000, 'test/accuracy': 0.4333000183105469, 'test/loss': 2.72176456451416, 'test/num_examples': 10000, 'score': 18141.31456375122, 'total_duration': 18946.149666786194, 'accumulated_submission_time': 18141.31456375122, 'accumulated_eval_time': 803.3354117870331, 'accumulated_logging_time': 1.1950960159301758}
I0428 16:01:40.503775 139903862044416 logging_writer.py:48] [22813] accumulated_eval_time=803.335412, accumulated_logging_time=1.195096, accumulated_submission_time=18141.314564, global_step=22813, preemption_count=0, score=18141.314564, test/accuracy=0.433300, test/loss=2.721765, test/num_examples=10000, total_duration=18946.149667, train/accuracy=0.583125, train/loss=1.894352, validation/accuracy=0.541400, validation/loss=2.102211, validation/num_examples=50000
I0428 16:02:50.018883 139903945914112 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.6455956101417542, loss=5.59716796875
I0428 16:04:09.054174 139903862044416 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.7253990173339844, loss=5.6769890785217285
I0428 16:05:28.140460 139903945914112 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.852482259273529, loss=3.4965603351593018
I0428 16:06:47.204210 139903862044416 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.8621143698692322, loss=4.200715065002441
I0428 16:08:06.226462 139903945914112 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.8262526392936707, loss=3.444889545440674
I0428 16:08:40.719943 140139854550848 spec.py:298] Evaluating on the training split.
I0428 16:08:49.354045 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 16:08:58.041701 140139854550848 spec.py:326] Evaluating on the test split.
I0428 16:08:59.779215 140139854550848 submission_runner.py:415] Time since start: 19385.45s, 	Step: 23345, 	{'train/accuracy': 0.5859960913658142, 'train/loss': 1.8466678857803345, 'validation/accuracy': 0.5458799600601196, 'validation/loss': 2.030139207839966, 'validation/num_examples': 50000, 'test/accuracy': 0.42830002307891846, 'test/loss': 2.6725568771362305, 'test/num_examples': 10000, 'score': 18561.51037311554, 'total_duration': 19385.447127342224, 'accumulated_submission_time': 18561.51037311554, 'accumulated_eval_time': 822.3946404457092, 'accumulated_logging_time': 1.230358600616455}
I0428 16:08:59.796375 139903862044416 logging_writer.py:48] [23345] accumulated_eval_time=822.394640, accumulated_logging_time=1.230359, accumulated_submission_time=18561.510373, global_step=23345, preemption_count=0, score=18561.510373, test/accuracy=0.428300, test/loss=2.672557, test/num_examples=10000, total_duration=19385.447127, train/accuracy=0.585996, train/loss=1.846668, validation/accuracy=0.545880, validation/loss=2.030139, validation/num_examples=50000
I0428 16:09:44.049546 139903945914112 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.7939139008522034, loss=3.4496490955352783
I0428 16:11:03.080594 139903862044416 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.9450041651725769, loss=3.525646924972534
I0428 16:12:22.117819 139903945914112 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.7464575171470642, loss=4.082181930541992
I0428 16:13:41.176221 139903862044416 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.923300564289093, loss=3.549034833908081
I0428 16:15:00.232041 139903945914112 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.8598117828369141, loss=3.4695253372192383
I0428 16:15:59.967432 140139854550848 spec.py:298] Evaluating on the training split.
I0428 16:16:08.606443 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 16:16:17.316382 140139854550848 spec.py:326] Evaluating on the test split.
I0428 16:16:19.033524 140139854550848 submission_runner.py:415] Time since start: 19824.70s, 	Step: 23877, 	{'train/accuracy': 0.5992968678474426, 'train/loss': 1.8475979566574097, 'validation/accuracy': 0.5438599586486816, 'validation/loss': 2.0886754989624023, 'validation/num_examples': 50000, 'test/accuracy': 0.4311000108718872, 'test/loss': 2.7140560150146484, 'test/num_examples': 10000, 'score': 18981.66078186035, 'total_duration': 19824.70140004158, 'accumulated_submission_time': 18981.66078186035, 'accumulated_eval_time': 841.4606614112854, 'accumulated_logging_time': 1.2611160278320312}
I0428 16:16:19.055356 139903862044416 logging_writer.py:48] [23877] accumulated_eval_time=841.460661, accumulated_logging_time=1.261116, accumulated_submission_time=18981.660782, global_step=23877, preemption_count=0, score=18981.660782, test/accuracy=0.431100, test/loss=2.714056, test/num_examples=10000, total_duration=19824.701400, train/accuracy=0.599297, train/loss=1.847598, validation/accuracy=0.543860, validation/loss=2.088675, validation/num_examples=50000
I0428 16:16:38.016599 139903945914112 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.8150727152824402, loss=3.4930577278137207
I0428 16:17:57.060654 139903862044416 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.9002404808998108, loss=3.481722116470337
I0428 16:19:16.105165 139903945914112 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.7163732647895813, loss=4.503814697265625
I0428 16:20:35.196731 139903862044416 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.8454378247261047, loss=3.3638153076171875
I0428 16:21:54.220505 139903945914112 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.848129391670227, loss=3.4194366931915283
I0428 16:23:13.275046 139903862044416 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.8090789318084717, loss=3.370675563812256
I0428 16:23:19.307307 140139854550848 spec.py:298] Evaluating on the training split.
I0428 16:23:27.966830 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 16:23:36.695383 140139854550848 spec.py:326] Evaluating on the test split.
I0428 16:23:38.414080 140139854550848 submission_runner.py:415] Time since start: 20264.08s, 	Step: 24409, 	{'train/accuracy': 0.5884374976158142, 'train/loss': 1.9141781330108643, 'validation/accuracy': 0.5453400015830994, 'validation/loss': 2.121791124343872, 'validation/num_examples': 50000, 'test/accuracy': 0.43400001525878906, 'test/loss': 2.7335002422332764, 'test/num_examples': 10000, 'score': 19401.89533162117, 'total_duration': 20264.081995010376, 'accumulated_submission_time': 19401.89533162117, 'accumulated_eval_time': 860.567390203476, 'accumulated_logging_time': 1.2933521270751953}
I0428 16:23:38.429208 139903945914112 logging_writer.py:48] [24409] accumulated_eval_time=860.567390, accumulated_logging_time=1.293352, accumulated_submission_time=19401.895332, global_step=24409, preemption_count=0, score=19401.895332, test/accuracy=0.434000, test/loss=2.733500, test/num_examples=10000, total_duration=20264.081995, train/accuracy=0.588437, train/loss=1.914178, validation/accuracy=0.545340, validation/loss=2.121791, validation/num_examples=50000
I0428 16:24:51.160084 139903862044416 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.9092189073562622, loss=5.650162220001221
I0428 16:26:10.220808 139903945914112 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.6447943449020386, loss=5.374457359313965
I0428 16:27:29.227773 139903862044416 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.7175475358963013, loss=4.520120143890381
I0428 16:28:48.255649 139903945914112 logging_writer.py:48] [24800] global_step=24800, grad_norm=1.0317187309265137, loss=3.533759832382202
I0428 16:30:07.283391 139903862044416 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.8076820969581604, loss=3.7016398906707764
I0428 16:30:38.581129 140139854550848 spec.py:298] Evaluating on the training split.
I0428 16:30:47.310177 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 16:30:56.049087 140139854550848 spec.py:326] Evaluating on the test split.
I0428 16:30:57.780502 140139854550848 submission_runner.py:415] Time since start: 20703.45s, 	Step: 24941, 	{'train/accuracy': 0.6340429782867432, 'train/loss': 1.6811357736587524, 'validation/accuracy': 0.5588600039482117, 'validation/loss': 2.0230722427368164, 'validation/num_examples': 50000, 'test/accuracy': 0.4375000298023224, 'test/loss': 2.6648430824279785, 'test/num_examples': 10000, 'score': 19822.031492233276, 'total_duration': 20703.448432445526, 'accumulated_submission_time': 19822.031492233276, 'accumulated_eval_time': 879.7667362689972, 'accumulated_logging_time': 1.3172316551208496}
I0428 16:30:57.793584 139903945914112 logging_writer.py:48] [24941] accumulated_eval_time=879.766736, accumulated_logging_time=1.317232, accumulated_submission_time=19822.031492, global_step=24941, preemption_count=0, score=19822.031492, test/accuracy=0.437500, test/loss=2.664843, test/num_examples=10000, total_duration=20703.448432, train/accuracy=0.634043, train/loss=1.681136, validation/accuracy=0.558860, validation/loss=2.023072, validation/num_examples=50000
I0428 16:31:45.177773 139903862044416 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.7436351776123047, loss=4.2974395751953125
I0428 16:33:04.218505 139903945914112 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.978546142578125, loss=3.4256248474121094
I0428 16:34:23.317286 139903862044416 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.7710415124893188, loss=4.550192356109619
I0428 16:35:42.413009 139903945914112 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.8122009634971619, loss=5.662369251251221
I0428 16:37:01.484812 139903862044416 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.8726974725723267, loss=3.4082019329071045
I0428 16:37:58.129434 140139854550848 spec.py:298] Evaluating on the training split.
I0428 16:38:06.741670 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 16:38:15.456989 140139854550848 spec.py:326] Evaluating on the test split.
I0428 16:38:17.185505 140139854550848 submission_runner.py:415] Time since start: 21142.85s, 	Step: 25473, 	{'train/accuracy': 0.5976366996765137, 'train/loss': 1.8113563060760498, 'validation/accuracy': 0.549560010433197, 'validation/loss': 2.036475658416748, 'validation/num_examples': 50000, 'test/accuracy': 0.4351000189781189, 'test/loss': 2.6800668239593506, 'test/num_examples': 10000, 'score': 20242.351449251175, 'total_duration': 21142.853382110596, 'accumulated_submission_time': 20242.351449251175, 'accumulated_eval_time': 898.8227500915527, 'accumulated_logging_time': 1.3390610218048096}
I0428 16:38:17.209993 139903945914112 logging_writer.py:48] [25473] accumulated_eval_time=898.822750, accumulated_logging_time=1.339061, accumulated_submission_time=20242.351449, global_step=25473, preemption_count=0, score=20242.351449, test/accuracy=0.435100, test/loss=2.680067, test/num_examples=10000, total_duration=21142.853382, train/accuracy=0.597637, train/loss=1.811356, validation/accuracy=0.549560, validation/loss=2.036476, validation/num_examples=50000
I0428 16:38:39.463817 139903862044416 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.7625601887702942, loss=4.704007148742676
I0428 16:39:58.571242 139903945914112 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.8902876377105713, loss=3.4675846099853516
I0428 16:41:17.666012 139903862044416 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.8186839818954468, loss=3.383066177368164
I0428 16:42:36.695424 139903945914112 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.8022646903991699, loss=5.316153526306152
I0428 16:43:55.748904 139903862044416 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.8793617486953735, loss=3.45512056350708
I0428 16:45:14.852003 139903945914112 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.7331259846687317, loss=4.117384910583496
I0428 16:45:17.724302 140139854550848 spec.py:298] Evaluating on the training split.
I0428 16:45:26.464485 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 16:45:35.095051 140139854550848 spec.py:326] Evaluating on the test split.
I0428 16:45:36.819015 140139854550848 submission_runner.py:415] Time since start: 21582.49s, 	Step: 26005, 	{'train/accuracy': 0.6085156202316284, 'train/loss': 1.7616348266601562, 'validation/accuracy': 0.562559962272644, 'validation/loss': 1.9715509414672852, 'validation/num_examples': 50000, 'test/accuracy': 0.4474000334739685, 'test/loss': 2.5949759483337402, 'test/num_examples': 10000, 'score': 20662.84351158142, 'total_duration': 21582.48693728447, 'accumulated_submission_time': 20662.84351158142, 'accumulated_eval_time': 917.9174213409424, 'accumulated_logging_time': 1.3783669471740723}
I0428 16:45:36.833625 139903862044416 logging_writer.py:48] [26005] accumulated_eval_time=917.917421, accumulated_logging_time=1.378367, accumulated_submission_time=20662.843512, global_step=26005, preemption_count=0, score=20662.843512, test/accuracy=0.447400, test/loss=2.594976, test/num_examples=10000, total_duration=21582.486937, train/accuracy=0.608516, train/loss=1.761635, validation/accuracy=0.562560, validation/loss=1.971551, validation/num_examples=50000
I0428 16:46:52.682233 139903945914112 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.8902118802070618, loss=3.5322489738464355
I0428 16:48:11.756180 139903862044416 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.6766782402992249, loss=4.521852016448975
I0428 16:49:30.811770 139903945914112 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.8890109658241272, loss=3.698108434677124
I0428 16:50:49.857886 139903862044416 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.8186191320419312, loss=3.5019454956054688
I0428 16:52:08.943019 139903945914112 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.9367412328720093, loss=3.6094374656677246
I0428 16:52:37.134177 140139854550848 spec.py:298] Evaluating on the training split.
I0428 16:52:45.868292 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 16:52:54.380714 140139854550848 spec.py:326] Evaluating on the test split.
I0428 16:52:56.120369 140139854550848 submission_runner.py:415] Time since start: 22021.79s, 	Step: 26537, 	{'train/accuracy': 0.6108593344688416, 'train/loss': 1.7679498195648193, 'validation/accuracy': 0.5570999979972839, 'validation/loss': 2.0205562114715576, 'validation/num_examples': 50000, 'test/accuracy': 0.4353000223636627, 'test/loss': 2.6779720783233643, 'test/num_examples': 10000, 'score': 21083.127097845078, 'total_duration': 22021.788258075714, 'accumulated_submission_time': 21083.127097845078, 'accumulated_eval_time': 936.9035468101501, 'accumulated_logging_time': 1.4029452800750732}
I0428 16:52:56.143217 139903862044416 logging_writer.py:48] [26537] accumulated_eval_time=936.903547, accumulated_logging_time=1.402945, accumulated_submission_time=21083.127098, global_step=26537, preemption_count=0, score=21083.127098, test/accuracy=0.435300, test/loss=2.677972, test/num_examples=10000, total_duration=22021.788258, train/accuracy=0.610859, train/loss=1.767950, validation/accuracy=0.557100, validation/loss=2.020556, validation/num_examples=50000
I0428 16:53:46.729354 139903945914112 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.7355732917785645, loss=4.568227291107178
I0428 16:55:05.818962 139903862044416 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.7475507855415344, loss=3.925699234008789
I0428 16:56:24.868410 139903945914112 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.9185662865638733, loss=3.3878962993621826
I0428 16:57:43.937777 139903862044416 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.8614187836647034, loss=3.409245014190674
I0428 16:59:03.006117 139903945914112 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.7591451406478882, loss=3.879037857055664
I0428 16:59:56.487465 140139854550848 spec.py:298] Evaluating on the training split.
I0428 17:00:05.278691 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 17:00:13.933550 140139854550848 spec.py:326] Evaluating on the test split.
I0428 17:00:15.664850 140139854550848 submission_runner.py:415] Time since start: 22461.33s, 	Step: 27069, 	{'train/accuracy': 0.614941418170929, 'train/loss': 1.7377660274505615, 'validation/accuracy': 0.5674200057983398, 'validation/loss': 1.9550787210464478, 'validation/num_examples': 50000, 'test/accuracy': 0.451200008392334, 'test/loss': 2.579590082168579, 'test/num_examples': 10000, 'score': 21503.45072197914, 'total_duration': 22461.33272600174, 'accumulated_submission_time': 21503.45072197914, 'accumulated_eval_time': 956.0808563232422, 'accumulated_logging_time': 1.4392459392547607}
I0428 17:00:15.684419 139903862044416 logging_writer.py:48] [27069] accumulated_eval_time=956.080856, accumulated_logging_time=1.439246, accumulated_submission_time=21503.450722, global_step=27069, preemption_count=0, score=21503.450722, test/accuracy=0.451200, test/loss=2.579590, test/num_examples=10000, total_duration=22461.332726, train/accuracy=0.614941, train/loss=1.737766, validation/accuracy=0.567420, validation/loss=1.955079, validation/num_examples=50000
I0428 17:00:40.984186 139903945914112 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.7477601170539856, loss=3.741145610809326
I0428 17:02:00.045703 139903862044416 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.7563842535018921, loss=3.3120648860931396
I0428 17:03:19.088311 139903945914112 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.8952378630638123, loss=3.373382329940796
I0428 17:04:38.149078 139903862044416 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.7034811973571777, loss=4.358321189880371
I0428 17:05:57.220004 139903945914112 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.6559938192367554, loss=4.797566890716553
I0428 17:07:16.259609 139903862044416 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.8021712899208069, loss=3.4389188289642334
I0428 17:07:16.269214 140139854550848 spec.py:298] Evaluating on the training split.
I0428 17:07:24.696175 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 17:07:33.357746 140139854550848 spec.py:326] Evaluating on the test split.
I0428 17:07:35.087896 140139854550848 submission_runner.py:415] Time since start: 22900.76s, 	Step: 27601, 	{'train/accuracy': 0.6180077791213989, 'train/loss': 1.7051883935928345, 'validation/accuracy': 0.5708199739456177, 'validation/loss': 1.9247636795043945, 'validation/num_examples': 50000, 'test/accuracy': 0.4520000219345093, 'test/loss': 2.579827308654785, 'test/num_examples': 10000, 'score': 21924.01610469818, 'total_duration': 22900.75580596924, 'accumulated_submission_time': 21924.01610469818, 'accumulated_eval_time': 974.8994526863098, 'accumulated_logging_time': 1.4711635112762451}
I0428 17:07:35.105606 139903945914112 logging_writer.py:48] [27601] accumulated_eval_time=974.899453, accumulated_logging_time=1.471164, accumulated_submission_time=21924.016105, global_step=27601, preemption_count=0, score=21924.016105, test/accuracy=0.452000, test/loss=2.579827, test/num_examples=10000, total_duration=22900.755806, train/accuracy=0.618008, train/loss=1.705188, validation/accuracy=0.570820, validation/loss=1.924764, validation/num_examples=50000
I0428 17:08:54.091720 139903862044416 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.8854607939720154, loss=3.409578561782837
I0428 17:10:13.083457 139903945914112 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.7649621963500977, loss=4.426235198974609
I0428 17:11:32.108933 139903862044416 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.8391808271408081, loss=3.615269184112549
I0428 17:12:50.055014 140139854550848 spec.py:298] Evaluating on the training split.
I0428 17:12:58.724212 140139854550848 spec.py:310] Evaluating on the validation split.
I0428 17:13:07.454477 140139854550848 spec.py:326] Evaluating on the test split.
I0428 17:13:09.195283 140139854550848 submission_runner.py:415] Time since start: 23234.86s, 	Step: 28000, 	{'train/accuracy': 0.6153124570846558, 'train/loss': 1.7094998359680176, 'validation/accuracy': 0.561959981918335, 'validation/loss': 1.9638110399246216, 'validation/num_examples': 50000, 'test/accuracy': 0.4464000165462494, 'test/loss': 2.61926531791687, 'test/num_examples': 10000, 'score': 22238.94670701027, 'total_duration': 23234.863209962845, 'accumulated_submission_time': 22238.94670701027, 'accumulated_eval_time': 994.0397081375122, 'accumulated_logging_time': 1.5023539066314697}
I0428 17:13:09.208962 139903945914112 logging_writer.py:48] [28000] accumulated_eval_time=994.039708, accumulated_logging_time=1.502354, accumulated_submission_time=22238.946707, global_step=28000, preemption_count=0, score=22238.946707, test/accuracy=0.446400, test/loss=2.619265, test/num_examples=10000, total_duration=23234.863210, train/accuracy=0.615312, train/loss=1.709500, validation/accuracy=0.561960, validation/loss=1.963811, validation/num_examples=50000
I0428 17:13:09.229382 139903862044416 logging_writer.py:48] [28000] global_step=28000, preemption_count=0, score=22238.946707
I0428 17:13:09.460001 140139854550848 checkpoints.py:356] Saving checkpoint at step: 28000
I0428 17:13:10.300371 140139854550848 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_fancy/timing_sam/imagenet_vit_jax/trial_1/checkpoint_28000
I0428 17:13:10.318252 140139854550848 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_fancy/timing_sam/imagenet_vit_jax/trial_1/checkpoint_28000.
I0428 17:13:11.521669 140139854550848 submission_runner.py:578] Tuning trial 1/1
I0428 17:13:11.521941 140139854550848 submission_runner.py:579] Hyperparameters: Hyperparameters(learning_rate=0.0013159053452895648, one_minus_beta1=0.2018302260773442, beta2=0.999, warmup_factor=0.05, weight_decay=0.07935861128365443, label_smoothing=0.1, dropout_rate=0.0, rho=0.01)
I0428 17:13:11.528442 140139854550848 submission_runner.py:580] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0008398437057621777, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 68.62623286247253, 'total_duration': 118.4245970249176, 'accumulated_submission_time': 68.62623286247253, 'accumulated_eval_time': 49.79820489883423, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (494, {'train/accuracy': 0.010546875186264515, 'train/loss': 6.555016994476318, 'validation/accuracy': 0.010259999893605709, 'validation/loss': 6.565260410308838, 'validation/num_examples': 50000, 'test/accuracy': 0.008100000210106373, 'test/loss': 6.594497203826904, 'test/num_examples': 10000, 'score': 489.0834889411926, 'total_duration': 554.1130173206329, 'accumulated_submission_time': 489.0834889411926, 'accumulated_eval_time': 64.99695420265198, 'accumulated_logging_time': 0.025815963745117188, 'global_step': 494, 'preemption_count': 0}), (1027, {'train/accuracy': 0.025214843451976776, 'train/loss': 6.11329984664917, 'validation/accuracy': 0.024639999493956566, 'validation/loss': 6.139117240905762, 'validation/num_examples': 50000, 'test/accuracy': 0.01720000058412552, 'test/loss': 6.217530727386475, 'test/num_examples': 10000, 'score': 909.4748973846436, 'total_duration': 989.70885181427, 'accumulated_submission_time': 909.4748973846436, 'accumulated_eval_time': 80.16657638549805, 'accumulated_logging_time': 0.05368757247924805, 'global_step': 1027, 'preemption_count': 0}), (1558, {'train/accuracy': 0.04140624776482582, 'train/loss': 5.8310465812683105, 'validation/accuracy': 0.03945999965071678, 'validation/loss': 5.869046211242676, 'validation/num_examples': 50000, 'test/accuracy': 0.029000001028180122, 'test/loss': 5.98787784576416, 'test/num_examples': 10000, 'score': 1330.2129111289978, 'total_duration': 1425.6517963409424, 'accumulated_submission_time': 1330.2129111289978, 'accumulated_eval_time': 95.33414936065674, 'accumulated_logging_time': 0.08363580703735352, 'global_step': 1558, 'preemption_count': 0}), (2090, {'train/accuracy': 0.05296874791383743, 'train/loss': 5.600213527679443, 'validation/accuracy': 0.050680000334978104, 'validation/loss': 5.632956504821777, 'validation/num_examples': 50000, 'test/accuracy': 0.03700000047683716, 'test/loss': 5.799388408660889, 'test/num_examples': 10000, 'score': 1750.2307333946228, 'total_duration': 1860.8849341869354, 'accumulated_submission_time': 1750.2307333946228, 'accumulated_eval_time': 110.51544833183289, 'accumulated_logging_time': 0.11061310768127441, 'global_step': 2090, 'preemption_count': 0}), (2618, {'train/accuracy': 0.07707031071186066, 'train/loss': 5.318606376647949, 'validation/accuracy': 0.07075999677181244, 'validation/loss': 5.357625484466553, 'validation/num_examples': 50000, 'test/accuracy': 0.055400002747774124, 'test/loss': 5.568378925323486, 'test/num_examples': 10000, 'score': 2170.288941383362, 'total_duration': 2296.1982436180115, 'accumulated_submission_time': 2170.288941383362, 'accumulated_eval_time': 125.7315263748169, 'accumulated_logging_time': 0.14241790771484375, 'global_step': 2618, 'preemption_count': 0}), (3150, {'train/accuracy': 0.0927148386836052, 'train/loss': 5.099536418914795, 'validation/accuracy': 0.08735999464988708, 'validation/loss': 5.1613850593566895, 'validation/num_examples': 50000, 'test/accuracy': 0.06640000641345978, 'test/loss': 5.398782253265381, 'test/num_examples': 10000, 'score': 2590.4081902503967, 'total_duration': 2731.530677318573, 'accumulated_submission_time': 2590.4081902503967, 'accumulated_eval_time': 140.91156840324402, 'accumulated_logging_time': 0.1684880256652832, 'global_step': 3150, 'preemption_count': 0}), (3677, {'train/accuracy': 0.1263085901737213, 'train/loss': 4.826124668121338, 'validation/accuracy': 0.11747999489307404, 'validation/loss': 4.887425899505615, 'validation/num_examples': 50000, 'test/accuracy': 0.09140000492334366, 'test/loss': 5.158858299255371, 'test/num_examples': 10000, 'score': 3010.720355272293, 'total_duration': 3167.1204624176025, 'accumulated_submission_time': 3010.720355272293, 'accumulated_eval_time': 156.1569242477417, 'accumulated_logging_time': 0.19378304481506348, 'global_step': 3677, 'preemption_count': 0}), (4209, {'train/accuracy': 0.1545117199420929, 'train/loss': 4.596144199371338, 'validation/accuracy': 0.1357799917459488, 'validation/loss': 4.702473163604736, 'validation/num_examples': 50000, 'test/accuracy': 0.10190000385046005, 'test/loss': 5.005126953125, 'test/num_examples': 10000, 'score': 3431.1415600776672, 'total_duration': 3602.7243819236755, 'accumulated_submission_time': 3431.1415600776672, 'accumulated_eval_time': 171.30527925491333, 'accumulated_logging_time': 0.2211616039276123, 'global_step': 4209, 'preemption_count': 0}), (4738, {'train/accuracy': 0.18035155534744263, 'train/loss': 4.386256694793701, 'validation/accuracy': 0.1657799929380417, 'validation/loss': 4.46188497543335, 'validation/num_examples': 50000, 'test/accuracy': 0.1274000108242035, 'test/loss': 4.790294647216797, 'test/num_examples': 10000, 'score': 3851.818570137024, 'total_duration': 4038.6766154766083, 'accumulated_submission_time': 3851.818570137024, 'accumulated_eval_time': 186.54827523231506, 'accumulated_logging_time': 0.246412992477417, 'global_step': 4738, 'preemption_count': 0}), (5270, {'train/accuracy': 0.1917382776737213, 'train/loss': 4.260013103485107, 'validation/accuracy': 0.17931999266147614, 'validation/loss': 4.344618797302246, 'validation/num_examples': 50000, 'test/accuracy': 0.13370001316070557, 'test/loss': 4.6894426345825195, 'test/num_examples': 10000, 'score': 4272.332301616669, 'total_duration': 4474.462612390518, 'accumulated_submission_time': 4272.332301616669, 'accumulated_eval_time': 201.78666234016418, 'accumulated_logging_time': 0.27331113815307617, 'global_step': 5270, 'preemption_count': 0}), (5798, {'train/accuracy': 0.23185546696186066, 'train/loss': 3.9212608337402344, 'validation/accuracy': 0.21381999552249908, 'validation/loss': 4.0400309562683105, 'validation/num_examples': 50000, 'test/accuracy': 0.15980000793933868, 'test/loss': 4.44034481048584, 'test/num_examples': 10000, 'score': 4692.7579889297485, 'total_duration': 4910.249724149704, 'accumulated_submission_time': 4692.7579889297485, 'accumulated_eval_time': 217.1131889820099, 'accumulated_logging_time': 0.3010697364807129, 'global_step': 5798, 'preemption_count': 0}), (6328, {'train/accuracy': 0.25687500834465027, 'train/loss': 3.780136823654175, 'validation/accuracy': 0.23615999519824982, 'validation/loss': 3.8986923694610596, 'validation/num_examples': 50000, 'test/accuracy': 0.1819000095129013, 'test/loss': 4.325060844421387, 'test/num_examples': 10000, 'score': 5112.819319009781, 'total_duration': 5345.7357177734375, 'accumulated_submission_time': 5112.819319009781, 'accumulated_eval_time': 232.5041265487671, 'accumulated_logging_time': 0.3278629779815674, 'global_step': 6328, 'preemption_count': 0}), (6859, {'train/accuracy': 0.2718749940395355, 'train/loss': 3.7162458896636963, 'validation/accuracy': 0.2526399791240692, 'validation/loss': 3.832369327545166, 'validation/num_examples': 50000, 'test/accuracy': 0.19470000267028809, 'test/loss': 4.258881092071533, 'test/num_examples': 10000, 'score': 5532.885047674179, 'total_duration': 5781.2325031757355, 'accumulated_submission_time': 5532.885047674179, 'accumulated_eval_time': 247.9003825187683, 'accumulated_logging_time': 0.3556487560272217, 'global_step': 6859, 'preemption_count': 0}), (7391, {'train/accuracy': 0.29435545206069946, 'train/loss': 3.515049457550049, 'validation/accuracy': 0.2699599862098694, 'validation/loss': 3.643329381942749, 'validation/num_examples': 50000, 'test/accuracy': 0.20160001516342163, 'test/loss': 4.11616849899292, 'test/num_examples': 10000, 'score': 5953.2651352882385, 'total_duration': 6216.980197429657, 'accumulated_submission_time': 5953.2651352882385, 'accumulated_eval_time': 263.22939467430115, 'accumulated_logging_time': 0.38712024688720703, 'global_step': 7391, 'preemption_count': 0}), (7920, {'train/accuracy': 0.3250390589237213, 'train/loss': 3.34314227104187, 'validation/accuracy': 0.3007799983024597, 'validation/loss': 3.472012758255005, 'validation/num_examples': 50000, 'test/accuracy': 0.23160001635551453, 'test/loss': 3.9504685401916504, 'test/num_examples': 10000, 'score': 6374.04229092598, 'total_duration': 6653.258536100388, 'accumulated_submission_time': 6374.04229092598, 'accumulated_eval_time': 278.6911153793335, 'accumulated_logging_time': 0.4194324016571045, 'global_step': 7920, 'preemption_count': 0}), (8449, {'train/accuracy': 0.3560546934604645, 'train/loss': 3.1021382808685303, 'validation/accuracy': 0.3172599971294403, 'validation/loss': 3.3010668754577637, 'validation/num_examples': 50000, 'test/accuracy': 0.24150000512599945, 'test/loss': 3.8180270195007324, 'test/num_examples': 10000, 'score': 6794.115318536758, 'total_duration': 7089.349767208099, 'accumulated_submission_time': 6794.115318536758, 'accumulated_eval_time': 294.67105293273926, 'accumulated_logging_time': 0.4504721164703369, 'global_step': 8449, 'preemption_count': 0}), (8981, {'train/accuracy': 0.349433571100235, 'train/loss': 3.1157596111297607, 'validation/accuracy': 0.3248800039291382, 'validation/loss': 3.2564899921417236, 'validation/num_examples': 50000, 'test/accuracy': 0.24420000612735748, 'test/loss': 3.782517433166504, 'test/num_examples': 10000, 'score': 7214.247290611267, 'total_duration': 7526.043137311935, 'accumulated_submission_time': 7214.247290611267, 'accumulated_eval_time': 311.1986184120178, 'accumulated_logging_time': 0.47666311264038086, 'global_step': 8981, 'preemption_count': 0}), (9513, {'train/accuracy': 0.3665820360183716, 'train/loss': 3.022933006286621, 'validation/accuracy': 0.34147998690605164, 'validation/loss': 3.1442012786865234, 'validation/num_examples': 50000, 'test/accuracy': 0.2647000253200531, 'test/loss': 3.6739513874053955, 'test/num_examples': 10000, 'score': 7634.493385314941, 'total_duration': 7963.844837188721, 'accumulated_submission_time': 7634.493385314941, 'accumulated_eval_time': 328.7243986129761, 'accumulated_logging_time': 0.49944138526916504, 'global_step': 9513, 'preemption_count': 0}), (10045, {'train/accuracy': 0.3947070240974426, 'train/loss': 2.9099371433258057, 'validation/accuracy': 0.3610199987888336, 'validation/loss': 3.0789377689361572, 'validation/num_examples': 50000, 'test/accuracy': 0.2766000032424927, 'test/loss': 3.6357946395874023, 'test/num_examples': 10000, 'score': 8054.689996957779, 'total_duration': 8402.643758535385, 'accumulated_submission_time': 8054.689996957779, 'accumulated_eval_time': 347.29389333724976, 'accumulated_logging_time': 0.5252082347869873, 'global_step': 10045, 'preemption_count': 0}), (10577, {'train/accuracy': 0.40474608540534973, 'train/loss': 2.79238224029541, 'validation/accuracy': 0.3785399794578552, 'validation/loss': 2.940905809402466, 'validation/num_examples': 50000, 'test/accuracy': 0.2896000146865845, 'test/loss': 3.5022192001342773, 'test/num_examples': 10000, 'score': 8475.020947217941, 'total_duration': 8841.646888494492, 'accumulated_submission_time': 8475.020947217941, 'accumulated_eval_time': 365.9339756965637, 'accumulated_logging_time': 0.5502102375030518, 'global_step': 10577, 'preemption_count': 0}), (11109, {'train/accuracy': 0.442695289850235, 'train/loss': 2.671494960784912, 'validation/accuracy': 0.3866399824619293, 'validation/loss': 2.9483296871185303, 'validation/num_examples': 50000, 'test/accuracy': 0.29750001430511475, 'test/loss': 3.4916672706604004, 'test/num_examples': 10000, 'score': 8895.366245031357, 'total_duration': 9280.932976484299, 'accumulated_submission_time': 8895.366245031357, 'accumulated_eval_time': 384.83676171302795, 'accumulated_logging_time': 0.580998420715332, 'global_step': 11109, 'preemption_count': 0}), (11641, {'train/accuracy': 0.43720701336860657, 'train/loss': 2.7271111011505127, 'validation/accuracy': 0.4032000005245209, 'validation/loss': 2.897920846939087, 'validation/num_examples': 50000, 'test/accuracy': 0.3116000294685364, 'test/loss': 3.4618184566497803, 'test/num_examples': 10000, 'score': 9315.73442697525, 'total_duration': 9720.376859664917, 'accumulated_submission_time': 9315.73442697525, 'accumulated_eval_time': 403.8803470134735, 'accumulated_logging_time': 0.6061239242553711, 'global_step': 11641, 'preemption_count': 0}), (12173, {'train/accuracy': 0.4430468678474426, 'train/loss': 2.600149154663086, 'validation/accuracy': 0.4129199981689453, 'validation/loss': 2.7539680004119873, 'validation/num_examples': 50000, 'test/accuracy': 0.31390002369880676, 'test/loss': 3.352325439453125, 'test/num_examples': 10000, 'score': 9736.04249048233, 'total_duration': 10159.504890203476, 'accumulated_submission_time': 9736.04249048233, 'accumulated_eval_time': 422.65795135498047, 'accumulated_logging_time': 0.6414608955383301, 'global_step': 12173, 'preemption_count': 0}), (12705, {'train/accuracy': 0.4716796875, 'train/loss': 2.4259772300720215, 'validation/accuracy': 0.4305199980735779, 'validation/loss': 2.649397373199463, 'validation/num_examples': 50000, 'test/accuracy': 0.3327000141143799, 'test/loss': 3.2345829010009766, 'test/num_examples': 10000, 'score': 10156.387952327728, 'total_duration': 10598.796095848083, 'accumulated_submission_time': 10156.387952327728, 'accumulated_eval_time': 441.56267404556274, 'accumulated_logging_time': 0.6752793788909912, 'global_step': 12705, 'preemption_count': 0}), (13237, {'train/accuracy': 0.457832008600235, 'train/loss': 2.5370965003967285, 'validation/accuracy': 0.4262000024318695, 'validation/loss': 2.693544864654541, 'validation/num_examples': 50000, 'test/accuracy': 0.33390000462532043, 'test/loss': 3.26370906829834, 'test/num_examples': 10000, 'score': 10576.579124450684, 'total_duration': 11038.028251171112, 'accumulated_submission_time': 10576.579124450684, 'accumulated_eval_time': 460.5674238204956, 'accumulated_logging_time': 0.7043473720550537, 'global_step': 13237, 'preemption_count': 0}), (13769, {'train/accuracy': 0.4757617115974426, 'train/loss': 2.4135210514068604, 'validation/accuracy': 0.44463998079299927, 'validation/loss': 2.5901448726654053, 'validation/num_examples': 50000, 'test/accuracy': 0.3472000062465668, 'test/loss': 3.194788694381714, 'test/num_examples': 10000, 'score': 10996.867826223373, 'total_duration': 11477.359836101532, 'accumulated_submission_time': 10996.867826223373, 'accumulated_eval_time': 479.5827302932739, 'accumulated_logging_time': 0.7248437404632568, 'global_step': 13769, 'preemption_count': 0}), (14301, {'train/accuracy': 0.4971874952316284, 'train/loss': 2.3649439811706543, 'validation/accuracy': 0.4597399830818176, 'validation/loss': 2.551039695739746, 'validation/num_examples': 50000, 'test/accuracy': 0.3468000292778015, 'test/loss': 3.1658267974853516, 'test/num_examples': 10000, 'score': 11417.531684398651, 'total_duration': 11916.740573883057, 'accumulated_submission_time': 11417.531684398651, 'accumulated_eval_time': 498.26143622398376, 'accumulated_logging_time': 0.7559685707092285, 'global_step': 14301, 'preemption_count': 0}), (14833, {'train/accuracy': 0.4978320300579071, 'train/loss': 2.3248939514160156, 'validation/accuracy': 0.46355998516082764, 'validation/loss': 2.4946036338806152, 'validation/num_examples': 50000, 'test/accuracy': 0.35840001702308655, 'test/loss': 3.106715679168701, 'test/num_examples': 10000, 'score': 11837.842361688614, 'total_duration': 12356.130858659744, 'accumulated_submission_time': 11837.842361688614, 'accumulated_eval_time': 517.3120231628418, 'accumulated_logging_time': 0.7780416011810303, 'global_step': 14833, 'preemption_count': 0}), (15365, {'train/accuracy': 0.5204492211341858, 'train/loss': 2.185494899749756, 'validation/accuracy': 0.46705999970436096, 'validation/loss': 2.431356906890869, 'validation/num_examples': 50000, 'test/accuracy': 0.3630000054836273, 'test/loss': 3.044809579849243, 'test/num_examples': 10000, 'score': 12258.334409952164, 'total_duration': 12795.66621851921, 'accumulated_submission_time': 12258.334409952164, 'accumulated_eval_time': 536.326602935791, 'accumulated_logging_time': 0.7996213436126709, 'global_step': 15365, 'preemption_count': 0}), (15897, {'train/accuracy': 0.5139062404632568, 'train/loss': 2.328256845474243, 'validation/accuracy': 0.4758400022983551, 'validation/loss': 2.50581693649292, 'validation/num_examples': 50000, 'test/accuracy': 0.36660000681877136, 'test/loss': 3.117124557495117, 'test/num_examples': 10000, 'score': 12678.610414981842, 'total_duration': 13235.07434797287, 'accumulated_submission_time': 12678.610414981842, 'accumulated_eval_time': 555.4167995452881, 'accumulated_logging_time': 0.834545373916626, 'global_step': 15897, 'preemption_count': 0}), (16429, {'train/accuracy': 0.5244335532188416, 'train/loss': 2.1837618350982666, 'validation/accuracy': 0.48687997460365295, 'validation/loss': 2.377197027206421, 'validation/num_examples': 50000, 'test/accuracy': 0.37780001759529114, 'test/loss': 2.9959685802459717, 'test/num_examples': 10000, 'score': 13099.006846666336, 'total_duration': 13674.540163516998, 'accumulated_submission_time': 13099.006846666336, 'accumulated_eval_time': 574.4592666625977, 'accumulated_logging_time': 0.8544793128967285, 'global_step': 16429, 'preemption_count': 0}), (16961, {'train/accuracy': 0.5375390648841858, 'train/loss': 2.1189522743225098, 'validation/accuracy': 0.4976399838924408, 'validation/loss': 2.316465139389038, 'validation/num_examples': 50000, 'test/accuracy': 0.3846000134944916, 'test/loss': 2.953903913497925, 'test/num_examples': 10000, 'score': 13519.002524614334, 'total_duration': 14113.573559045792, 'accumulated_submission_time': 13519.002524614334, 'accumulated_eval_time': 593.4609508514404, 'accumulated_logging_time': 0.8834478855133057, 'global_step': 16961, 'preemption_count': 0}), (17493, {'train/accuracy': 0.5332617163658142, 'train/loss': 2.166902780532837, 'validation/accuracy': 0.49616000056266785, 'validation/loss': 2.3383491039276123, 'validation/num_examples': 50000, 'test/accuracy': 0.392300009727478, 'test/loss': 2.9509389400482178, 'test/num_examples': 10000, 'score': 13939.211968898773, 'total_duration': 14552.80158662796, 'accumulated_submission_time': 13939.211968898773, 'accumulated_eval_time': 612.4400579929352, 'accumulated_logging_time': 0.9158008098602295, 'global_step': 17493, 'preemption_count': 0}), (18025, {'train/accuracy': 0.5684961080551147, 'train/loss': 2.0121724605560303, 'validation/accuracy': 0.5016199946403503, 'validation/loss': 2.319152355194092, 'validation/num_examples': 50000, 'test/accuracy': 0.38700002431869507, 'test/loss': 2.9415924549102783, 'test/num_examples': 10000, 'score': 14359.42431640625, 'total_duration': 14992.120625019073, 'accumulated_submission_time': 14359.42431640625, 'accumulated_eval_time': 631.5076887607574, 'accumulated_logging_time': 0.947563886642456, 'global_step': 18025, 'preemption_count': 0}), (18557, {'train/accuracy': 0.5511132478713989, 'train/loss': 2.0523898601531982, 'validation/accuracy': 0.5094799995422363, 'validation/loss': 2.25439190864563, 'validation/num_examples': 50000, 'test/accuracy': 0.39180001616477966, 'test/loss': 2.8889594078063965, 'test/num_examples': 10000, 'score': 14779.566605567932, 'total_duration': 15431.34752202034, 'accumulated_submission_time': 14779.566605567932, 'accumulated_eval_time': 650.5590052604675, 'accumulated_logging_time': 0.9737651348114014, 'global_step': 18557, 'preemption_count': 0}), (19089, {'train/accuracy': 0.5531445145606995, 'train/loss': 2.077678918838501, 'validation/accuracy': 0.5150799751281738, 'validation/loss': 2.260133743286133, 'validation/num_examples': 50000, 'test/accuracy': 0.4002000093460083, 'test/loss': 2.8854315280914307, 'test/num_examples': 10000, 'score': 15199.800146818161, 'total_duration': 15870.835018873215, 'accumulated_submission_time': 15199.800146818161, 'accumulated_eval_time': 669.7709956169128, 'accumulated_logging_time': 1.008716344833374, 'global_step': 19089, 'preemption_count': 0}), (19621, {'train/accuracy': 0.5641406178474426, 'train/loss': 2.0283477306365967, 'validation/accuracy': 0.5128799676895142, 'validation/loss': 2.267571210861206, 'validation/num_examples': 50000, 'test/accuracy': 0.3947000205516815, 'test/loss': 2.917112350463867, 'test/num_examples': 10000, 'score': 15619.951186418533, 'total_duration': 16310.063931703568, 'accumulated_submission_time': 15619.951186418533, 'accumulated_eval_time': 688.8190546035767, 'accumulated_logging_time': 1.0314035415649414, 'global_step': 19621, 'preemption_count': 0}), (20153, {'train/accuracy': 0.5636132955551147, 'train/loss': 1.9520843029022217, 'validation/accuracy': 0.5191999673843384, 'validation/loss': 2.1721267700195312, 'validation/num_examples': 50000, 'test/accuracy': 0.41050001978874207, 'test/loss': 2.8079943656921387, 'test/num_examples': 10000, 'score': 16040.094812870026, 'total_duration': 16749.29306912422, 'accumulated_submission_time': 16040.094812870026, 'accumulated_eval_time': 707.8761336803436, 'accumulated_logging_time': 1.0528249740600586, 'global_step': 20153, 'preemption_count': 0}), (20685, {'train/accuracy': 0.5686327815055847, 'train/loss': 1.9721496105194092, 'validation/accuracy': 0.5298399925231934, 'validation/loss': 2.1614620685577393, 'validation/num_examples': 50000, 'test/accuracy': 0.41360002756118774, 'test/loss': 2.797513008117676, 'test/num_examples': 10000, 'score': 16460.195034503937, 'total_duration': 17188.524811029434, 'accumulated_submission_time': 16460.195034503937, 'accumulated_eval_time': 726.9654531478882, 'accumulated_logging_time': 1.087967872619629, 'global_step': 20685, 'preemption_count': 0}), (21217, {'train/accuracy': 0.5780078172683716, 'train/loss': 1.881686806678772, 'validation/accuracy': 0.5295199751853943, 'validation/loss': 2.1187939643859863, 'validation/num_examples': 50000, 'test/accuracy': 0.41430002450942993, 'test/loss': 2.755758047103882, 'test/num_examples': 10000, 'score': 16880.469057559967, 'total_duration': 17627.945291757584, 'accumulated_submission_time': 16880.469057559967, 'accumulated_eval_time': 746.0832223892212, 'accumulated_logging_time': 1.1094913482666016, 'global_step': 21217, 'preemption_count': 0}), (21749, {'train/accuracy': 0.5782617330551147, 'train/loss': 1.9042574167251587, 'validation/accuracy': 0.5382800102233887, 'validation/loss': 2.106940269470215, 'validation/num_examples': 50000, 'test/accuracy': 0.4287000298500061, 'test/loss': 2.7356207370758057, 'test/num_examples': 10000, 'score': 17300.757103443146, 'total_duration': 18067.343608617783, 'accumulated_submission_time': 17300.757103443146, 'accumulated_eval_time': 765.1664226055145, 'accumulated_logging_time': 1.1296513080596924, 'global_step': 21749, 'preemption_count': 0}), (22281, {'train/accuracy': 0.5894922018051147, 'train/loss': 1.885851502418518, 'validation/accuracy': 0.5292800068855286, 'validation/loss': 2.1599833965301514, 'validation/num_examples': 50000, 'test/accuracy': 0.4183000326156616, 'test/loss': 2.782557487487793, 'test/num_examples': 10000, 'score': 17721.043602228165, 'total_duration': 18506.80100297928, 'accumulated_submission_time': 17721.043602228165, 'accumulated_eval_time': 784.2945342063904, 'accumulated_logging_time': 1.1654083728790283, 'global_step': 22281, 'preemption_count': 0}), (22813, {'train/accuracy': 0.5831249952316284, 'train/loss': 1.8943523168563843, 'validation/accuracy': 0.5414000153541565, 'validation/loss': 2.102210521697998, 'validation/num_examples': 50000, 'test/accuracy': 0.4333000183105469, 'test/loss': 2.72176456451416, 'test/num_examples': 10000, 'score': 18141.31456375122, 'total_duration': 18946.149666786194, 'accumulated_submission_time': 18141.31456375122, 'accumulated_eval_time': 803.3354117870331, 'accumulated_logging_time': 1.1950960159301758, 'global_step': 22813, 'preemption_count': 0}), (23345, {'train/accuracy': 0.5859960913658142, 'train/loss': 1.8466678857803345, 'validation/accuracy': 0.5458799600601196, 'validation/loss': 2.030139207839966, 'validation/num_examples': 50000, 'test/accuracy': 0.42830002307891846, 'test/loss': 2.6725568771362305, 'test/num_examples': 10000, 'score': 18561.51037311554, 'total_duration': 19385.447127342224, 'accumulated_submission_time': 18561.51037311554, 'accumulated_eval_time': 822.3946404457092, 'accumulated_logging_time': 1.230358600616455, 'global_step': 23345, 'preemption_count': 0}), (23877, {'train/accuracy': 0.5992968678474426, 'train/loss': 1.8475979566574097, 'validation/accuracy': 0.5438599586486816, 'validation/loss': 2.0886754989624023, 'validation/num_examples': 50000, 'test/accuracy': 0.4311000108718872, 'test/loss': 2.7140560150146484, 'test/num_examples': 10000, 'score': 18981.66078186035, 'total_duration': 19824.70140004158, 'accumulated_submission_time': 18981.66078186035, 'accumulated_eval_time': 841.4606614112854, 'accumulated_logging_time': 1.2611160278320312, 'global_step': 23877, 'preemption_count': 0}), (24409, {'train/accuracy': 0.5884374976158142, 'train/loss': 1.9141781330108643, 'validation/accuracy': 0.5453400015830994, 'validation/loss': 2.121791124343872, 'validation/num_examples': 50000, 'test/accuracy': 0.43400001525878906, 'test/loss': 2.7335002422332764, 'test/num_examples': 10000, 'score': 19401.89533162117, 'total_duration': 20264.081995010376, 'accumulated_submission_time': 19401.89533162117, 'accumulated_eval_time': 860.567390203476, 'accumulated_logging_time': 1.2933521270751953, 'global_step': 24409, 'preemption_count': 0}), (24941, {'train/accuracy': 0.6340429782867432, 'train/loss': 1.6811357736587524, 'validation/accuracy': 0.5588600039482117, 'validation/loss': 2.0230722427368164, 'validation/num_examples': 50000, 'test/accuracy': 0.4375000298023224, 'test/loss': 2.6648430824279785, 'test/num_examples': 10000, 'score': 19822.031492233276, 'total_duration': 20703.448432445526, 'accumulated_submission_time': 19822.031492233276, 'accumulated_eval_time': 879.7667362689972, 'accumulated_logging_time': 1.3172316551208496, 'global_step': 24941, 'preemption_count': 0}), (25473, {'train/accuracy': 0.5976366996765137, 'train/loss': 1.8113563060760498, 'validation/accuracy': 0.549560010433197, 'validation/loss': 2.036475658416748, 'validation/num_examples': 50000, 'test/accuracy': 0.4351000189781189, 'test/loss': 2.6800668239593506, 'test/num_examples': 10000, 'score': 20242.351449251175, 'total_duration': 21142.853382110596, 'accumulated_submission_time': 20242.351449251175, 'accumulated_eval_time': 898.8227500915527, 'accumulated_logging_time': 1.3390610218048096, 'global_step': 25473, 'preemption_count': 0}), (26005, {'train/accuracy': 0.6085156202316284, 'train/loss': 1.7616348266601562, 'validation/accuracy': 0.562559962272644, 'validation/loss': 1.9715509414672852, 'validation/num_examples': 50000, 'test/accuracy': 0.4474000334739685, 'test/loss': 2.5949759483337402, 'test/num_examples': 10000, 'score': 20662.84351158142, 'total_duration': 21582.48693728447, 'accumulated_submission_time': 20662.84351158142, 'accumulated_eval_time': 917.9174213409424, 'accumulated_logging_time': 1.3783669471740723, 'global_step': 26005, 'preemption_count': 0}), (26537, {'train/accuracy': 0.6108593344688416, 'train/loss': 1.7679498195648193, 'validation/accuracy': 0.5570999979972839, 'validation/loss': 2.0205562114715576, 'validation/num_examples': 50000, 'test/accuracy': 0.4353000223636627, 'test/loss': 2.6779720783233643, 'test/num_examples': 10000, 'score': 21083.127097845078, 'total_duration': 22021.788258075714, 'accumulated_submission_time': 21083.127097845078, 'accumulated_eval_time': 936.9035468101501, 'accumulated_logging_time': 1.4029452800750732, 'global_step': 26537, 'preemption_count': 0}), (27069, {'train/accuracy': 0.614941418170929, 'train/loss': 1.7377660274505615, 'validation/accuracy': 0.5674200057983398, 'validation/loss': 1.9550787210464478, 'validation/num_examples': 50000, 'test/accuracy': 0.451200008392334, 'test/loss': 2.579590082168579, 'test/num_examples': 10000, 'score': 21503.45072197914, 'total_duration': 22461.33272600174, 'accumulated_submission_time': 21503.45072197914, 'accumulated_eval_time': 956.0808563232422, 'accumulated_logging_time': 1.4392459392547607, 'global_step': 27069, 'preemption_count': 0}), (27601, {'train/accuracy': 0.6180077791213989, 'train/loss': 1.7051883935928345, 'validation/accuracy': 0.5708199739456177, 'validation/loss': 1.9247636795043945, 'validation/num_examples': 50000, 'test/accuracy': 0.4520000219345093, 'test/loss': 2.579827308654785, 'test/num_examples': 10000, 'score': 21924.01610469818, 'total_duration': 22900.75580596924, 'accumulated_submission_time': 21924.01610469818, 'accumulated_eval_time': 974.8994526863098, 'accumulated_logging_time': 1.4711635112762451, 'global_step': 27601, 'preemption_count': 0}), (28000, {'train/accuracy': 0.6153124570846558, 'train/loss': 1.7094998359680176, 'validation/accuracy': 0.561959981918335, 'validation/loss': 1.9638110399246216, 'validation/num_examples': 50000, 'test/accuracy': 0.4464000165462494, 'test/loss': 2.61926531791687, 'test/num_examples': 10000, 'score': 22238.94670701027, 'total_duration': 23234.863209962845, 'accumulated_submission_time': 22238.94670701027, 'accumulated_eval_time': 994.0397081375122, 'accumulated_logging_time': 1.5023539066314697, 'global_step': 28000, 'preemption_count': 0})], 'global_step': 28000}
I0428 17:13:11.528610 140139854550848 submission_runner.py:581] Timing: 22238.94670701027
I0428 17:13:11.528660 140139854550848 submission_runner.py:582] ====================
I0428 17:13:11.528835 140139854550848 submission_runner.py:645] Final imagenet_vit score: 22238.94670701027
