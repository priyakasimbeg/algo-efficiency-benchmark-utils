python3 submission_runner.py --framework=jax --workload=imagenet_vit --submission_path=baselines/shampoo/jax/submission.py --tuning_search_space=baselines/shampoo/tuning_search_space.json --data_dir=/data/imagenet/jax --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_fancy/timing_shampoo --overwrite=True --save_checkpoints=False --max_global_steps=28000 --imagenet_v2_data_dir=/data/imagenet/jax 2>&1 | tee -a /logs/imagenet_vit_jax_04-28-2023-12-21-33.log
I0428 12:21:55.619123 139903503492928 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_fancy/timing_shampoo/imagenet_vit_jax.
I0428 12:21:55.723981 139903503492928 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0428 12:21:56.542186 139903503492928 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Host Interpreter CUDA
I0428 12:21:56.542822 139903503492928 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0428 12:21:56.548139 139903503492928 submission_runner.py:538] Using RNG seed 3022373433
I0428 12:21:59.143563 139903503492928 submission_runner.py:547] --- Tuning run 1/1 ---
I0428 12:21:59.143764 139903503492928 submission_runner.py:552] Creating tuning directory at /experiment_runs/timing_fancy/timing_shampoo/imagenet_vit_jax/trial_1.
I0428 12:21:59.143943 139903503492928 logger_utils.py:92] Saving hparams to /experiment_runs/timing_fancy/timing_shampoo/imagenet_vit_jax/trial_1/hparams.json.
I0428 12:21:59.277557 139903503492928 submission_runner.py:241] Initializing dataset.
I0428 12:21:59.294202 139903503492928 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0428 12:21:59.303568 139903503492928 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0428 12:21:59.303683 139903503492928 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0428 12:21:59.607094 139903503492928 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0428 12:22:08.681333 139903503492928 submission_runner.py:248] Initializing model.
I0428 12:22:21.490659 139903503492928 submission_runner.py:258] Initializing optimizer.
I0428 12:22:37.535865 139903503492928 submission_runner.py:265] Initializing metrics bundle.
I0428 12:22:37.536144 139903503492928 submission_runner.py:282] Initializing checkpoint and logger.
I0428 12:22:37.537333 139903503492928 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_fancy/timing_shampoo/imagenet_vit_jax/trial_1 with prefix checkpoint_
I0428 12:22:38.457052 139903503492928 submission_runner.py:303] Saving meta data to /experiment_runs/timing_fancy/timing_shampoo/imagenet_vit_jax/trial_1/meta_data_0.json.
I0428 12:22:38.458149 139903503492928 submission_runner.py:306] Saving flags to /experiment_runs/timing_fancy/timing_shampoo/imagenet_vit_jax/trial_1/flags_0.json.
I0428 12:22:38.462997 139903503492928 submission_runner.py:318] Starting training loop.
/algorithmic-efficiency/baselines/shampoo/jax/distributed_shampoo.py:812: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.
  matrix = matrix.astype(_MAT_INV_PTH_ROOT_DTYPE)
/algorithmic-efficiency/baselines/shampoo/jax/distributed_shampoo.py:813: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.
  alpha = jnp.asarray(-1.0 / p, _MAT_INV_PTH_ROOT_DTYPE)
/algorithmic-efficiency/baselines/shampoo/jax/distributed_shampoo.py:814: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in eye is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.
  identity = jnp.eye(matrix_size, dtype=_MAT_INV_PTH_ROOT_DTYPE)
I0428 12:27:33.617762 139726661089024 logging_writer.py:48] [0] global_step=0, grad_norm=0.3355698585510254, loss=6.907756805419922
I0428 12:27:33.703121 139903503492928 spec.py:298] Evaluating on the training split.
I0428 12:27:33.723378 139903503492928 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0428 12:27:33.731299 139903503492928 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0428 12:27:33.731457 139903503492928 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0428 12:27:33.807723 139903503492928 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0428 12:27:54.056455 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 12:27:54.065820 139903503492928 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0428 12:27:54.085509 139903503492928 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0428 12:27:54.085793 139903503492928 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0428 12:27:54.147278 139903503492928 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0428 12:28:14.458541 139903503492928 spec.py:326] Evaluating on the test split.
I0428 12:28:14.465079 139903503492928 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0428 12:28:14.470252 139903503492928 dataset_builder.py:510] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0428 12:28:14.503932 139903503492928 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0428 12:28:25.925582 139903503492928 submission_runner.py:415] Time since start: 347.46s, 	Step: 1, 	{'train/accuracy': 0.0008984374580904841, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 295.23993730545044, 'total_duration': 347.46252036094666, 'accumulated_submission_time': 295.23993730545044, 'accumulated_eval_time': 52.222418546676636, 'accumulated_logging_time': 0}
I0428 12:28:25.942738 139671120111360 logging_writer.py:48] [1] accumulated_eval_time=52.222419, accumulated_logging_time=0, accumulated_submission_time=295.239937, global_step=1, preemption_count=0, score=295.239937, test/accuracy=0.001000, test/loss=6.907757, test/num_examples=10000, total_duration=347.462520, train/accuracy=0.000898, train/loss=6.907756, validation/accuracy=0.001000, validation/loss=6.907756, validation/num_examples=50000
I0428 12:34:59.238744 139720402937600 logging_writer.py:48] [100] global_step=100, grad_norm=0.4963616728782654, loss=6.8542256355285645
I0428 12:35:26.229360 139903503492928 spec.py:298] Evaluating on the training split.
I0428 12:35:32.814685 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 12:35:39.842854 139903503492928 spec.py:326] Evaluating on the test split.
I0428 12:35:41.627824 139903503492928 submission_runner.py:415] Time since start: 783.16s, 	Step: 131, 	{'train/accuracy': 0.004277343861758709, 'train/loss': 6.797806739807129, 'validation/accuracy': 0.003719999920576811, 'validation/loss': 6.8065948486328125, 'validation/num_examples': 50000, 'test/accuracy': 0.003900000127032399, 'test/loss': 6.817415714263916, 'test/num_examples': 10000, 'score': 715.516547203064, 'total_duration': 783.164742231369, 'accumulated_submission_time': 715.516547203064, 'accumulated_eval_time': 67.62083768844604, 'accumulated_logging_time': 0.025347471237182617}
I0428 12:35:41.640299 139671363368704 logging_writer.py:48] [131] accumulated_eval_time=67.620838, accumulated_logging_time=0.025347, accumulated_submission_time=715.516547, global_step=131, preemption_count=0, score=715.516547, test/accuracy=0.003900, test/loss=6.817416, test/num_examples=10000, total_duration=783.164742, train/accuracy=0.004277, train/loss=6.797807, validation/accuracy=0.003720, validation/loss=6.806595, validation/num_examples=50000
I0428 12:36:53.165181 139671371761408 logging_writer.py:48] [200] global_step=200, grad_norm=0.5362515449523926, loss=6.81400203704834
I0428 12:38:32.176461 139671363368704 logging_writer.py:48] [300] global_step=300, grad_norm=0.611965000629425, loss=6.716584205627441
I0428 12:40:11.526010 139671371761408 logging_writer.py:48] [400] global_step=400, grad_norm=0.8207951784133911, loss=6.632200241088867
I0428 12:41:51.175995 139671363368704 logging_writer.py:48] [500] global_step=500, grad_norm=0.8836461901664734, loss=6.521244525909424
I0428 12:42:41.820096 139903503492928 spec.py:298] Evaluating on the training split.
I0428 12:42:48.406666 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 12:42:55.409854 139903503492928 spec.py:326] Evaluating on the test split.
I0428 12:42:57.130365 139903503492928 submission_runner.py:415] Time since start: 1218.67s, 	Step: 556, 	{'train/accuracy': 0.02597656100988388, 'train/loss': 6.262216567993164, 'validation/accuracy': 0.02393999882042408, 'validation/loss': 6.279642105102539, 'validation/num_examples': 50000, 'test/accuracy': 0.018200000748038292, 'test/loss': 6.336015701293945, 'test/num_examples': 10000, 'score': 1135.677639722824, 'total_duration': 1218.6672382354736, 'accumulated_submission_time': 1135.677639722824, 'accumulated_eval_time': 82.9310073852539, 'accumulated_logging_time': 0.05135703086853027}
I0428 12:42:57.145223 139671371761408 logging_writer.py:48] [556] accumulated_eval_time=82.931007, accumulated_logging_time=0.051357, accumulated_submission_time=1135.677640, global_step=556, preemption_count=0, score=1135.677640, test/accuracy=0.018200, test/loss=6.336016, test/num_examples=10000, total_duration=1218.667238, train/accuracy=0.025977, train/loss=6.262217, validation/accuracy=0.023940, validation/loss=6.279642, validation/num_examples=50000
I0428 12:43:47.016695 139671363368704 logging_writer.py:48] [600] global_step=600, grad_norm=1.2886992692947388, loss=6.474416732788086
I0428 12:45:28.098789 139671371761408 logging_writer.py:48] [700] global_step=700, grad_norm=1.5503085851669312, loss=6.686702728271484
I0428 12:47:08.210272 139671363368704 logging_writer.py:48] [800] global_step=800, grad_norm=1.3186843395233154, loss=6.307143211364746
I0428 12:48:48.943718 139671371761408 logging_writer.py:48] [900] global_step=900, grad_norm=0.8960217237472534, loss=6.62814998626709
I0428 12:49:57.479766 139903503492928 spec.py:298] Evaluating on the training split.
I0428 12:50:04.054236 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 12:50:10.953205 139903503492928 spec.py:326] Evaluating on the test split.
I0428 12:50:12.666852 139903503492928 submission_runner.py:415] Time since start: 1654.20s, 	Step: 973, 	{'train/accuracy': 0.051738280802965164, 'train/loss': 5.752218723297119, 'validation/accuracy': 0.04989999905228615, 'validation/loss': 5.77405309677124, 'validation/num_examples': 50000, 'test/accuracy': 0.03880000114440918, 'test/loss': 5.903034210205078, 'test/num_examples': 10000, 'score': 1555.9941320419312, 'total_duration': 1654.2037448883057, 'accumulated_submission_time': 1555.9941320419312, 'accumulated_eval_time': 98.11801266670227, 'accumulated_logging_time': 0.07878470420837402}
I0428 12:50:12.681915 139671363368704 logging_writer.py:48] [973] accumulated_eval_time=98.118013, accumulated_logging_time=0.078785, accumulated_submission_time=1555.994132, global_step=973, preemption_count=0, score=1555.994132, test/accuracy=0.038800, test/loss=5.903034, test/num_examples=10000, total_duration=1654.203745, train/accuracy=0.051738, train/loss=5.752219, validation/accuracy=0.049900, validation/loss=5.774053, validation/num_examples=50000
I0428 12:50:44.539380 139671371761408 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.4230494499206543, loss=6.150996208190918
I0428 12:52:25.376027 139671363368704 logging_writer.py:48] [1100] global_step=1100, grad_norm=1.3782696723937988, loss=6.505036354064941
I0428 12:54:06.099103 139671371761408 logging_writer.py:48] [1200] global_step=1200, grad_norm=1.133682131767273, loss=6.583815574645996
I0428 12:55:47.243943 139671363368704 logging_writer.py:48] [1300] global_step=1300, grad_norm=1.2386558055877686, loss=6.033881187438965
I0428 12:57:13.195286 139903503492928 spec.py:298] Evaluating on the training split.
I0428 12:57:19.771429 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 12:57:26.619957 139903503492928 spec.py:326] Evaluating on the test split.
I0428 12:57:28.343795 139903503492928 submission_runner.py:415] Time since start: 2089.88s, 	Step: 1389, 	{'train/accuracy': 0.07619140297174454, 'train/loss': 5.402970314025879, 'validation/accuracy': 0.07109999656677246, 'validation/loss': 5.432634353637695, 'validation/num_examples': 50000, 'test/accuracy': 0.055400002747774124, 'test/loss': 5.610576629638672, 'test/num_examples': 10000, 'score': 1976.4876470565796, 'total_duration': 2089.880674600601, 'accumulated_submission_time': 1976.4876470565796, 'accumulated_eval_time': 113.26643872261047, 'accumulated_logging_time': 0.1085042953491211}
I0428 12:57:28.359393 139671371761408 logging_writer.py:48] [1389] accumulated_eval_time=113.266439, accumulated_logging_time=0.108504, accumulated_submission_time=1976.487647, global_step=1389, preemption_count=0, score=1976.487647, test/accuracy=0.055400, test/loss=5.610577, test/num_examples=10000, total_duration=2089.880675, train/accuracy=0.076191, train/loss=5.402970, validation/accuracy=0.071100, validation/loss=5.432634, validation/num_examples=50000
I0428 12:57:43.233675 139671363368704 logging_writer.py:48] [1400] global_step=1400, grad_norm=1.4933134317398071, loss=5.9033942222595215
I0428 12:59:24.018319 139671371761408 logging_writer.py:48] [1500] global_step=1500, grad_norm=1.4963030815124512, loss=5.89940881729126
I0428 13:01:05.603543 139671363368704 logging_writer.py:48] [1600] global_step=1600, grad_norm=1.6786248683929443, loss=5.915741443634033
I0428 13:02:47.330111 139671371761408 logging_writer.py:48] [1700] global_step=1700, grad_norm=1.3685299158096313, loss=6.403406143188477
I0428 13:04:28.914105 139671363368704 logging_writer.py:48] [1800] global_step=1800, grad_norm=1.1872305870056152, loss=6.591233253479004
I0428 13:04:28.965584 139903503492928 spec.py:298] Evaluating on the training split.
I0428 13:04:35.553873 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 13:04:42.431607 139903503492928 spec.py:326] Evaluating on the test split.
I0428 13:04:44.166847 139903503492928 submission_runner.py:415] Time since start: 2525.70s, 	Step: 1801, 	{'train/accuracy': 0.10039062052965164, 'train/loss': 5.088702201843262, 'validation/accuracy': 0.09253999590873718, 'validation/loss': 5.141936302185059, 'validation/num_examples': 50000, 'test/accuracy': 0.07150000333786011, 'test/loss': 5.375046253204346, 'test/num_examples': 10000, 'score': 2397.075027704239, 'total_duration': 2525.7037451267242, 'accumulated_submission_time': 2397.075027704239, 'accumulated_eval_time': 128.46760249137878, 'accumulated_logging_time': 0.13761544227600098}
I0428 13:04:44.181568 139671371761408 logging_writer.py:48] [1801] accumulated_eval_time=128.467602, accumulated_logging_time=0.137615, accumulated_submission_time=2397.075028, global_step=1801, preemption_count=0, score=2397.075028, test/accuracy=0.071500, test/loss=5.375046, test/num_examples=10000, total_duration=2525.703745, train/accuracy=0.100391, train/loss=5.088702, validation/accuracy=0.092540, validation/loss=5.141936, validation/num_examples=50000
I0428 13:06:25.715455 139671363368704 logging_writer.py:48] [1900] global_step=1900, grad_norm=1.4793422222137451, loss=5.704178333282471
I0428 13:08:07.132882 139671371761408 logging_writer.py:48] [2000] global_step=2000, grad_norm=1.423863172531128, loss=5.639634132385254
I0428 13:09:48.388930 139671363368704 logging_writer.py:48] [2100] global_step=2100, grad_norm=1.6520767211914062, loss=5.571378231048584
I0428 13:11:29.746145 139671371761408 logging_writer.py:48] [2200] global_step=2200, grad_norm=1.4058247804641724, loss=5.568020343780518
I0428 13:11:50.256971 139903503492928 spec.py:298] Evaluating on the training split.
I0428 13:11:56.858676 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 13:12:03.907116 139903503492928 spec.py:326] Evaluating on the test split.
I0428 13:12:05.643094 139903503492928 submission_runner.py:415] Time since start: 2967.18s, 	Step: 2221, 	{'train/accuracy': 0.13701172173023224, 'train/loss': 4.738317012786865, 'validation/accuracy': 0.12814000248908997, 'validation/loss': 4.799259185791016, 'validation/num_examples': 50000, 'test/accuracy': 0.09540000557899475, 'test/loss': 5.067623138427734, 'test/num_examples': 10000, 'score': 2823.1320683956146, 'total_duration': 2967.1799783706665, 'accumulated_submission_time': 2823.1320683956146, 'accumulated_eval_time': 143.85363674163818, 'accumulated_logging_time': 0.16557860374450684}
I0428 13:12:05.658833 139671363368704 logging_writer.py:48] [2221] accumulated_eval_time=143.853637, accumulated_logging_time=0.165579, accumulated_submission_time=2823.132068, global_step=2221, preemption_count=0, score=2823.132068, test/accuracy=0.095400, test/loss=5.067623, test/num_examples=10000, total_duration=2967.179978, train/accuracy=0.137012, train/loss=4.738317, validation/accuracy=0.128140, validation/loss=4.799259, validation/num_examples=50000
I0428 13:13:27.611515 139671371761408 logging_writer.py:48] [2300] global_step=2300, grad_norm=1.2439831495285034, loss=5.98820686340332
I0428 13:15:09.123517 139671363368704 logging_writer.py:48] [2400] global_step=2400, grad_norm=1.24325430393219, loss=5.463621139526367
I0428 13:16:50.725638 139671371761408 logging_writer.py:48] [2500] global_step=2500, grad_norm=1.09998619556427, loss=6.31632661819458
I0428 13:18:33.073193 139671363368704 logging_writer.py:48] [2600] global_step=2600, grad_norm=1.3119982481002808, loss=6.413102149963379
I0428 13:19:06.110146 139903503492928 spec.py:298] Evaluating on the training split.
I0428 13:19:12.687773 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 13:19:19.651013 139903503492928 spec.py:326] Evaluating on the test split.
I0428 13:19:21.382356 139903503492928 submission_runner.py:415] Time since start: 3402.92s, 	Step: 2639, 	{'train/accuracy': 0.18544921278953552, 'train/loss': 4.404040336608887, 'validation/accuracy': 0.1682399958372116, 'validation/loss': 4.49139404296875, 'validation/num_examples': 50000, 'test/accuracy': 0.12270000576972961, 'test/loss': 4.81296443939209, 'test/num_examples': 10000, 'score': 3243.5654950141907, 'total_duration': 3402.9192757606506, 'accumulated_submission_time': 3243.5654950141907, 'accumulated_eval_time': 159.12579607963562, 'accumulated_logging_time': 0.19392704963684082}
I0428 13:19:21.394241 139671371761408 logging_writer.py:48] [2639] accumulated_eval_time=159.125796, accumulated_logging_time=0.193927, accumulated_submission_time=3243.565495, global_step=2639, preemption_count=0, score=3243.565495, test/accuracy=0.122700, test/loss=4.812964, test/num_examples=10000, total_duration=3402.919276, train/accuracy=0.185449, train/loss=4.404040, validation/accuracy=0.168240, validation/loss=4.491394, validation/num_examples=50000
I0428 13:20:30.633305 139671363368704 logging_writer.py:48] [2700] global_step=2700, grad_norm=1.3291388750076294, loss=5.5713701248168945
I0428 13:22:11.775635 139671371761408 logging_writer.py:48] [2800] global_step=2800, grad_norm=1.481428861618042, loss=5.216094493865967
I0428 13:23:52.892701 139671363368704 logging_writer.py:48] [2900] global_step=2900, grad_norm=1.1963694095611572, loss=5.14810848236084
I0428 13:25:33.399617 139671371761408 logging_writer.py:48] [3000] global_step=3000, grad_norm=1.308912754058838, loss=5.389413833618164
I0428 13:26:21.658817 139903503492928 spec.py:298] Evaluating on the training split.
I0428 13:26:28.244429 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 13:26:35.173578 139903503492928 spec.py:326] Evaluating on the test split.
I0428 13:26:36.907007 139903503492928 submission_runner.py:415] Time since start: 3838.44s, 	Step: 3052, 	{'train/accuracy': 0.2240038961172104, 'train/loss': 4.072768211364746, 'validation/accuracy': 0.20075999200344086, 'validation/loss': 4.200099468231201, 'validation/num_examples': 50000, 'test/accuracy': 0.15600000321865082, 'test/loss': 4.574591636657715, 'test/num_examples': 10000, 'score': 3663.811623096466, 'total_duration': 3838.4438993930817, 'accumulated_submission_time': 3663.811623096466, 'accumulated_eval_time': 174.37390851974487, 'accumulated_logging_time': 0.21916627883911133}
I0428 13:26:36.919409 139671363368704 logging_writer.py:48] [3052] accumulated_eval_time=174.373909, accumulated_logging_time=0.219166, accumulated_submission_time=3663.811623, global_step=3052, preemption_count=0, score=3663.811623, test/accuracy=0.156000, test/loss=4.574592, test/num_examples=10000, total_duration=3838.443899, train/accuracy=0.224004, train/loss=4.072768, validation/accuracy=0.200760, validation/loss=4.200099, validation/num_examples=50000
I0428 13:27:30.017416 139671371761408 logging_writer.py:48] [3100] global_step=3100, grad_norm=1.2049967050552368, loss=6.236837387084961
I0428 13:29:11.311799 139671363368704 logging_writer.py:48] [3200] global_step=3200, grad_norm=1.5650789737701416, loss=5.437555313110352
I0428 13:30:51.836796 139671371761408 logging_writer.py:48] [3300] global_step=3300, grad_norm=1.526269793510437, loss=5.003056526184082
I0428 13:32:33.267858 139671363368704 logging_writer.py:48] [3400] global_step=3400, grad_norm=1.4591137170791626, loss=5.004070281982422
I0428 13:33:37.165691 139903503492928 spec.py:298] Evaluating on the training split.
I0428 13:33:43.790452 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 13:33:50.699496 139903503492928 spec.py:326] Evaluating on the test split.
I0428 13:33:52.435225 139903503492928 submission_runner.py:415] Time since start: 4273.97s, 	Step: 3465, 	{'train/accuracy': 0.2492968738079071, 'train/loss': 3.8584694862365723, 'validation/accuracy': 0.2280000001192093, 'validation/loss': 3.9765539169311523, 'validation/num_examples': 50000, 'test/accuracy': 0.1712000072002411, 'test/loss': 4.402194499969482, 'test/num_examples': 10000, 'score': 4084.037281513214, 'total_duration': 4273.972116470337, 'accumulated_submission_time': 4084.037281513214, 'accumulated_eval_time': 189.64336466789246, 'accumulated_logging_time': 0.24701333045959473}
I0428 13:33:52.449755 139671371761408 logging_writer.py:48] [3465] accumulated_eval_time=189.643365, accumulated_logging_time=0.247013, accumulated_submission_time=4084.037282, global_step=3465, preemption_count=0, score=4084.037282, test/accuracy=0.171200, test/loss=4.402194, test/num_examples=10000, total_duration=4273.972116, train/accuracy=0.249297, train/loss=3.858469, validation/accuracy=0.228000, validation/loss=3.976554, validation/num_examples=50000
I0428 13:34:30.347981 139671363368704 logging_writer.py:48] [3500] global_step=3500, grad_norm=1.301965355873108, loss=5.3272905349731445
I0428 13:36:11.235751 139671371761408 logging_writer.py:48] [3600] global_step=3600, grad_norm=1.2920689582824707, loss=5.691490173339844
I0428 13:37:52.725333 139671363368704 logging_writer.py:48] [3700] global_step=3700, grad_norm=1.5113625526428223, loss=4.89200496673584
I0428 13:39:34.335775 139671371761408 logging_writer.py:48] [3800] global_step=3800, grad_norm=1.555503010749817, loss=4.870462417602539
I0428 13:40:54.718221 139903503492928 spec.py:298] Evaluating on the training split.
I0428 13:41:01.337129 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 13:41:08.282711 139903503492928 spec.py:326] Evaluating on the test split.
I0428 13:41:09.997335 139903503492928 submission_runner.py:415] Time since start: 4711.53s, 	Step: 3881, 	{'train/accuracy': 0.27314451336860657, 'train/loss': 3.6525137424468994, 'validation/accuracy': 0.255840003490448, 'validation/loss': 3.7469425201416016, 'validation/num_examples': 50000, 'test/accuracy': 0.19100001454353333, 'test/loss': 4.195384502410889, 'test/num_examples': 10000, 'score': 4506.287321090698, 'total_duration': 4711.534224748611, 'accumulated_submission_time': 4506.287321090698, 'accumulated_eval_time': 204.92239952087402, 'accumulated_logging_time': 0.274822473526001}
I0428 13:41:10.012192 139671363368704 logging_writer.py:48] [3881] accumulated_eval_time=204.922400, accumulated_logging_time=0.274822, accumulated_submission_time=4506.287321, global_step=3881, preemption_count=0, score=4506.287321, test/accuracy=0.191000, test/loss=4.195385, test/num_examples=10000, total_duration=4711.534225, train/accuracy=0.273145, train/loss=3.652514, validation/accuracy=0.255840, validation/loss=3.746943, validation/num_examples=50000
I0428 13:41:31.103999 139671371761408 logging_writer.py:48] [3900] global_step=3900, grad_norm=1.088468074798584, loss=5.2855143547058105
I0428 13:43:13.295401 139671363368704 logging_writer.py:48] [4000] global_step=4000, grad_norm=1.489867091178894, loss=4.831549644470215
I0428 13:44:56.263065 139671371761408 logging_writer.py:48] [4100] global_step=4100, grad_norm=1.4517107009887695, loss=4.810408115386963
I0428 13:46:39.247666 139671363368704 logging_writer.py:48] [4200] global_step=4200, grad_norm=1.0911965370178223, loss=5.08430290222168
I0428 13:48:10.274235 139903503492928 spec.py:298] Evaluating on the training split.
I0428 13:48:16.880379 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 13:48:24.229782 139903503492928 spec.py:326] Evaluating on the test split.
I0428 13:48:25.962853 139903503492928 submission_runner.py:415] Time since start: 5147.50s, 	Step: 4293, 	{'train/accuracy': 0.30818358063697815, 'train/loss': 3.4497087001800537, 'validation/accuracy': 0.28105998039245605, 'validation/loss': 3.572171449661255, 'validation/num_examples': 50000, 'test/accuracy': 0.21580001711845398, 'test/loss': 4.046998023986816, 'test/num_examples': 10000, 'score': 4926.530014514923, 'total_duration': 5147.499765634537, 'accumulated_submission_time': 4926.530014514923, 'accumulated_eval_time': 220.61096239089966, 'accumulated_logging_time': 0.3038480281829834}
I0428 13:48:25.976146 139671371761408 logging_writer.py:48] [4293] accumulated_eval_time=220.610962, accumulated_logging_time=0.303848, accumulated_submission_time=4926.530015, global_step=4293, preemption_count=0, score=4926.530015, test/accuracy=0.215800, test/loss=4.046998, test/num_examples=10000, total_duration=5147.499766, train/accuracy=0.308184, train/loss=3.449709, validation/accuracy=0.281060, validation/loss=3.572171, validation/num_examples=50000
I0428 13:48:38.111536 139671363368704 logging_writer.py:48] [4300] global_step=4300, grad_norm=1.0660457611083984, loss=5.5199408531188965
I0428 13:50:19.423390 139671371761408 logging_writer.py:48] [4400] global_step=4400, grad_norm=1.0564720630645752, loss=6.091580390930176
I0428 13:52:00.422862 139671363368704 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.9746305346488953, loss=6.228945255279541
I0428 13:53:41.308555 139671371761408 logging_writer.py:48] [4600] global_step=4600, grad_norm=1.320404291152954, loss=4.729168891906738
I0428 13:55:22.685493 139671363368704 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.8468393087387085, loss=6.216479778289795
I0428 13:55:26.932749 139903503492928 spec.py:298] Evaluating on the training split.
I0428 13:55:33.684657 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 13:55:41.249993 139903503492928 spec.py:326] Evaluating on the test split.
I0428 13:55:42.962266 139903503492928 submission_runner.py:415] Time since start: 5584.50s, 	Step: 4706, 	{'train/accuracy': 0.33128905296325684, 'train/loss': 3.3321714401245117, 'validation/accuracy': 0.3010999858379364, 'validation/loss': 3.488948345184326, 'validation/num_examples': 50000, 'test/accuracy': 0.2290000170469284, 'test/loss': 3.9732789993286133, 'test/num_examples': 10000, 'score': 5347.467670679092, 'total_duration': 5584.49915599823, 'accumulated_submission_time': 5347.467670679092, 'accumulated_eval_time': 236.64039492607117, 'accumulated_logging_time': 0.33097171783447266}
I0428 13:55:42.978924 139671371761408 logging_writer.py:48] [4706] accumulated_eval_time=236.640395, accumulated_logging_time=0.330972, accumulated_submission_time=5347.467671, global_step=4706, preemption_count=0, score=5347.467671, test/accuracy=0.229000, test/loss=3.973279, test/num_examples=10000, total_duration=5584.499156, train/accuracy=0.331289, train/loss=3.332171, validation/accuracy=0.301100, validation/loss=3.488948, validation/num_examples=50000
I0428 13:57:21.956579 139671363368704 logging_writer.py:48] [4800] global_step=4800, grad_norm=1.0331922769546509, loss=5.592042922973633
I0428 13:59:04.949137 139671371761408 logging_writer.py:48] [4900] global_step=4900, grad_norm=1.0260308980941772, loss=5.944624423980713
I0428 14:00:47.820617 139671363368704 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.9345815777778625, loss=5.246365547180176
I0428 14:02:30.313000 139671371761408 logging_writer.py:48] [5100] global_step=5100, grad_norm=1.149282693862915, loss=5.1943511962890625
I0428 14:02:43.582664 139903503492928 spec.py:298] Evaluating on the training split.
I0428 14:02:50.361632 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 14:02:57.717458 139903503492928 spec.py:326] Evaluating on the test split.
I0428 14:02:59.433668 139903503492928 submission_runner.py:415] Time since start: 6020.97s, 	Step: 5119, 	{'train/accuracy': 0.35115233063697815, 'train/loss': 3.1426680088043213, 'validation/accuracy': 0.3225799798965454, 'validation/loss': 3.290813684463501, 'validation/num_examples': 50000, 'test/accuracy': 0.24890001118183136, 'test/loss': 3.8148205280303955, 'test/num_examples': 10000, 'score': 5768.052061319351, 'total_duration': 6020.970591783524, 'accumulated_submission_time': 5768.052061319351, 'accumulated_eval_time': 252.49135041236877, 'accumulated_logging_time': 0.36170458793640137}
I0428 14:02:59.446003 139671363368704 logging_writer.py:48] [5119] accumulated_eval_time=252.491350, accumulated_logging_time=0.361705, accumulated_submission_time=5768.052061, global_step=5119, preemption_count=0, score=5768.052061, test/accuracy=0.248900, test/loss=3.814821, test/num_examples=10000, total_duration=6020.970592, train/accuracy=0.351152, train/loss=3.142668, validation/accuracy=0.322580, validation/loss=3.290814, validation/num_examples=50000
I0428 14:04:28.649097 139671371761408 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.8430331349372864, loss=6.092475891113281
I0428 14:06:11.294723 139671363368704 logging_writer.py:48] [5300] global_step=5300, grad_norm=1.0480718612670898, loss=4.622006893157959
I0428 14:07:54.726659 139671371761408 logging_writer.py:48] [5400] global_step=5400, grad_norm=1.3718818426132202, loss=4.626230716705322
I0428 14:09:38.051396 139671363368704 logging_writer.py:48] [5500] global_step=5500, grad_norm=1.0609859228134155, loss=4.562776565551758
I0428 14:09:59.551152 139903503492928 spec.py:298] Evaluating on the training split.
I0428 14:10:06.298323 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 14:10:13.595806 139903503492928 spec.py:326] Evaluating on the test split.
I0428 14:10:15.318375 139903503492928 submission_runner.py:415] Time since start: 6456.86s, 	Step: 5522, 	{'train/accuracy': 0.37128904461860657, 'train/loss': 3.038233518600464, 'validation/accuracy': 0.34147998690605164, 'validation/loss': 3.1798148155212402, 'validation/num_examples': 50000, 'test/accuracy': 0.2648000121116638, 'test/loss': 3.71653151512146, 'test/num_examples': 10000, 'score': 6188.138451099396, 'total_duration': 6456.855275392532, 'accumulated_submission_time': 6188.138451099396, 'accumulated_eval_time': 268.2585060596466, 'accumulated_logging_time': 0.3876798152923584}
I0428 14:10:15.336499 139671371761408 logging_writer.py:48] [5522] accumulated_eval_time=268.258506, accumulated_logging_time=0.387680, accumulated_submission_time=6188.138451, global_step=5522, preemption_count=0, score=6188.138451, test/accuracy=0.264800, test/loss=3.716532, test/num_examples=10000, total_duration=6456.855275, train/accuracy=0.371289, train/loss=3.038234, validation/accuracy=0.341480, validation/loss=3.179815, validation/num_examples=50000
I0428 14:11:38.771349 139671363368704 logging_writer.py:48] [5600] global_step=5600, grad_norm=1.255982518196106, loss=4.372045993804932
I0428 14:13:22.481308 139671371761408 logging_writer.py:48] [5700] global_step=5700, grad_norm=1.1519194841384888, loss=4.387119770050049
I0428 14:15:05.822933 139671363368704 logging_writer.py:48] [5800] global_step=5800, grad_norm=1.147238850593567, loss=4.285371780395508
I0428 14:16:50.068392 139671371761408 logging_writer.py:48] [5900] global_step=5900, grad_norm=1.102363109588623, loss=4.3748087882995605
I0428 14:17:16.019467 139903503492928 spec.py:298] Evaluating on the training split.
I0428 14:17:22.747019 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 14:17:29.996005 139903503492928 spec.py:326] Evaluating on the test split.
I0428 14:17:31.726191 139903503492928 submission_runner.py:415] Time since start: 6893.26s, 	Step: 5928, 	{'train/accuracy': 0.39765623211860657, 'train/loss': 2.918809413909912, 'validation/accuracy': 0.3563399910926819, 'validation/loss': 3.1231062412261963, 'validation/num_examples': 50000, 'test/accuracy': 0.2629000246524811, 'test/loss': 3.682025909423828, 'test/num_examples': 10000, 'score': 6608.802738666534, 'total_duration': 6893.263090372086, 'accumulated_submission_time': 6608.802738666534, 'accumulated_eval_time': 283.96515703201294, 'accumulated_logging_time': 0.4193258285522461}
I0428 14:17:31.743356 139671363368704 logging_writer.py:48] [5928] accumulated_eval_time=283.965157, accumulated_logging_time=0.419326, accumulated_submission_time=6608.802739, global_step=5928, preemption_count=0, score=6608.802739, test/accuracy=0.262900, test/loss=3.682026, test/num_examples=10000, total_duration=6893.263090, train/accuracy=0.397656, train/loss=2.918809, validation/accuracy=0.356340, validation/loss=3.123106, validation/num_examples=50000
I0428 14:18:49.853024 139671371761408 logging_writer.py:48] [6000] global_step=6000, grad_norm=1.1005853414535522, loss=4.3023834228515625
I0428 14:20:34.001290 139671363368704 logging_writer.py:48] [6100] global_step=6100, grad_norm=1.2830209732055664, loss=4.399405002593994
I0428 14:22:18.170098 139671371761408 logging_writer.py:48] [6200] global_step=6200, grad_norm=1.2584439516067505, loss=4.3199543952941895
I0428 14:24:03.599121 139671363368704 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.9145102500915527, loss=5.043423175811768
I0428 14:24:32.110365 139903503492928 spec.py:298] Evaluating on the training split.
I0428 14:24:38.843062 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 14:24:46.169544 139903503492928 spec.py:326] Evaluating on the test split.
I0428 14:24:47.886761 139903503492928 submission_runner.py:415] Time since start: 7329.42s, 	Step: 6331, 	{'train/accuracy': 0.39130857586860657, 'train/loss': 2.9234819412231445, 'validation/accuracy': 0.3583199977874756, 'validation/loss': 3.0890860557556152, 'validation/num_examples': 50000, 'test/accuracy': 0.2734000086784363, 'test/loss': 3.64874005317688, 'test/num_examples': 10000, 'score': 7029.150061845779, 'total_duration': 7329.423683166504, 'accumulated_submission_time': 7029.150061845779, 'accumulated_eval_time': 299.7415020465851, 'accumulated_logging_time': 0.45100998878479004}
I0428 14:24:47.899965 139671371761408 logging_writer.py:48] [6331] accumulated_eval_time=299.741502, accumulated_logging_time=0.451010, accumulated_submission_time=7029.150062, global_step=6331, preemption_count=0, score=7029.150062, test/accuracy=0.273400, test/loss=3.648740, test/num_examples=10000, total_duration=7329.423683, train/accuracy=0.391309, train/loss=2.923482, validation/accuracy=0.358320, validation/loss=3.089086, validation/num_examples=50000
I0428 14:26:04.636207 139671363368704 logging_writer.py:48] [6400] global_step=6400, grad_norm=1.1755905151367188, loss=4.2344584465026855
I0428 14:27:49.489551 139671371761408 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.9747951030731201, loss=4.721179485321045
I0428 14:29:35.270698 139671363368704 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.9353406429290771, loss=4.197937965393066
I0428 14:31:19.560010 139671371761408 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.9966495633125305, loss=4.219407081604004
I0428 14:31:48.098953 139903503492928 spec.py:298] Evaluating on the training split.
I0428 14:31:54.830966 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 14:32:02.131721 139903503492928 spec.py:326] Evaluating on the test split.
I0428 14:32:03.840105 139903503492928 submission_runner.py:415] Time since start: 7765.38s, 	Step: 6731, 	{'train/accuracy': 0.4015820324420929, 'train/loss': 2.8508877754211426, 'validation/accuracy': 0.37351998686790466, 'validation/loss': 2.9977729320526123, 'validation/num_examples': 50000, 'test/accuracy': 0.289000004529953, 'test/loss': 3.563725233078003, 'test/num_examples': 10000, 'score': 7449.329925060272, 'total_duration': 7765.377031326294, 'accumulated_submission_time': 7449.329925060272, 'accumulated_eval_time': 315.48260521888733, 'accumulated_logging_time': 0.47809457778930664}
I0428 14:32:03.853183 139671363368704 logging_writer.py:48] [6731] accumulated_eval_time=315.482605, accumulated_logging_time=0.478095, accumulated_submission_time=7449.329925, global_step=6731, preemption_count=0, score=7449.329925, test/accuracy=0.289000, test/loss=3.563725, test/num_examples=10000, total_duration=7765.377031, train/accuracy=0.401582, train/loss=2.850888, validation/accuracy=0.373520, validation/loss=2.997773, validation/num_examples=50000
I0428 14:33:20.261953 139671371761408 logging_writer.py:48] [6800] global_step=6800, grad_norm=1.0323923826217651, loss=4.269421577453613
I0428 14:35:04.242387 139671363368704 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.776746928691864, loss=6.138034820556641
I0428 14:36:48.455606 139671371761408 logging_writer.py:48] [7000] global_step=7000, grad_norm=1.016340732574463, loss=4.742250442504883
I0428 14:38:32.087187 139671363368704 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.8487926721572876, loss=5.758189678192139
I0428 14:39:04.269654 139903503492928 spec.py:298] Evaluating on the training split.
I0428 14:39:10.996867 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 14:39:18.694694 139903503492928 spec.py:326] Evaluating on the test split.
I0428 14:39:20.415651 139903503492928 submission_runner.py:415] Time since start: 8201.95s, 	Step: 7136, 	{'train/accuracy': 0.4229491949081421, 'train/loss': 2.7149205207824707, 'validation/accuracy': 0.3876599967479706, 'validation/loss': 2.8770227432250977, 'validation/num_examples': 50000, 'test/accuracy': 0.29490000009536743, 'test/loss': 3.4742774963378906, 'test/num_examples': 10000, 'score': 7869.728478431702, 'total_duration': 8201.952518463135, 'accumulated_submission_time': 7869.728478431702, 'accumulated_eval_time': 331.62850546836853, 'accumulated_logging_time': 0.504000186920166}
I0428 14:39:20.437219 139671371761408 logging_writer.py:48] [7136] accumulated_eval_time=331.628505, accumulated_logging_time=0.504000, accumulated_submission_time=7869.728478, global_step=7136, preemption_count=0, score=7869.728478, test/accuracy=0.294900, test/loss=3.474277, test/num_examples=10000, total_duration=8201.952518, train/accuracy=0.422949, train/loss=2.714921, validation/accuracy=0.387660, validation/loss=2.877023, validation/num_examples=50000
I0428 14:40:34.641785 139671363368704 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.9595997333526611, loss=4.3273701667785645
I0428 14:42:20.872305 139671371761408 logging_writer.py:48] [7300] global_step=7300, grad_norm=1.002224087715149, loss=4.20741605758667
I0428 14:44:06.521157 139671363368704 logging_writer.py:48] [7400] global_step=7400, grad_norm=1.0032148361206055, loss=4.211485385894775
I0428 14:45:51.440239 139671371761408 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.7644320130348206, loss=4.9568939208984375
I0428 14:46:21.021520 139903503492928 spec.py:298] Evaluating on the training split.
I0428 14:46:28.115751 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 14:46:36.154127 139903503492928 spec.py:326] Evaluating on the test split.
I0428 14:46:37.876992 139903503492928 submission_runner.py:415] Time since start: 8639.41s, 	Step: 7532, 	{'train/accuracy': 0.4313281178474426, 'train/loss': 2.7128753662109375, 'validation/accuracy': 0.39980000257492065, 'validation/loss': 2.8735580444335938, 'validation/num_examples': 50000, 'test/accuracy': 0.3076000213623047, 'test/loss': 3.450944423675537, 'test/num_examples': 10000, 'score': 8290.292822122574, 'total_duration': 8639.413896799088, 'accumulated_submission_time': 8290.292822122574, 'accumulated_eval_time': 348.48392057418823, 'accumulated_logging_time': 0.5402426719665527}
I0428 14:46:37.891144 139671363368704 logging_writer.py:48] [7532] accumulated_eval_time=348.483921, accumulated_logging_time=0.540243, accumulated_submission_time=8290.292822, global_step=7532, preemption_count=0, score=8290.292822, test/accuracy=0.307600, test/loss=3.450944, test/num_examples=10000, total_duration=8639.413897, train/accuracy=0.431328, train/loss=2.712875, validation/accuracy=0.399800, validation/loss=2.873558, validation/num_examples=50000
I0428 14:47:53.817557 139671371761408 logging_writer.py:48] [7600] global_step=7600, grad_norm=1.0365393161773682, loss=4.245931148529053
I0428 14:49:38.534498 139671363368704 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.8777083158493042, loss=4.432924270629883
I0428 14:51:23.457376 139671371761408 logging_writer.py:48] [7800] global_step=7800, grad_norm=1.1059142351150513, loss=4.1382856369018555
I0428 14:53:08.783259 139671363368704 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.7878351211547852, loss=5.792084693908691
I0428 14:53:37.928240 139903503492928 spec.py:298] Evaluating on the training split.
I0428 14:53:45.188759 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 14:53:53.498352 139903503492928 spec.py:326] Evaluating on the test split.
I0428 14:53:55.220525 139903503492928 submission_runner.py:415] Time since start: 9076.76s, 	Step: 7932, 	{'train/accuracy': 0.43681639432907104, 'train/loss': 2.652195692062378, 'validation/accuracy': 0.4043799936771393, 'validation/loss': 2.825620651245117, 'validation/num_examples': 50000, 'test/accuracy': 0.3132000267505646, 'test/loss': 3.4030473232269287, 'test/num_examples': 10000, 'score': 8710.311620235443, 'total_duration': 9076.757446289062, 'accumulated_submission_time': 8710.311620235443, 'accumulated_eval_time': 365.7761573791504, 'accumulated_logging_time': 0.5674097537994385}
I0428 14:53:55.235333 139671371761408 logging_writer.py:48] [7932] accumulated_eval_time=365.776157, accumulated_logging_time=0.567410, accumulated_submission_time=8710.311620, global_step=7932, preemption_count=0, score=8710.311620, test/accuracy=0.313200, test/loss=3.403047, test/num_examples=10000, total_duration=9076.757446, train/accuracy=0.436816, train/loss=2.652196, validation/accuracy=0.404380, validation/loss=2.825621, validation/num_examples=50000
I0428 14:55:11.912005 139671363368704 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.8387985825538635, loss=5.142940998077393
I0428 14:56:57.372618 139671371761408 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.8209224343299866, loss=4.024104595184326
I0428 14:58:42.109777 139671363368704 logging_writer.py:48] [8200] global_step=8200, grad_norm=1.0262844562530518, loss=3.943007469177246
I0428 15:00:27.648493 139671371761408 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.863073468208313, loss=6.087440013885498
I0428 15:00:55.637993 139903503492928 spec.py:298] Evaluating on the training split.
I0428 15:01:03.242039 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 15:01:11.900273 139903503492928 spec.py:326] Evaluating on the test split.
I0428 15:01:13.617528 139903503492928 submission_runner.py:415] Time since start: 9515.15s, 	Step: 8330, 	{'train/accuracy': 0.4400585889816284, 'train/loss': 2.609130382537842, 'validation/accuracy': 0.4103599786758423, 'validation/loss': 2.7594637870788574, 'validation/num_examples': 50000, 'test/accuracy': 0.3111000061035156, 'test/loss': 3.361201047897339, 'test/num_examples': 10000, 'score': 9130.695872545242, 'total_duration': 9515.154428958893, 'accumulated_submission_time': 9130.695872545242, 'accumulated_eval_time': 383.7556371688843, 'accumulated_logging_time': 0.5953879356384277}
I0428 15:01:13.634061 139671363368704 logging_writer.py:48] [8330] accumulated_eval_time=383.755637, accumulated_logging_time=0.595388, accumulated_submission_time=9130.695873, global_step=8330, preemption_count=0, score=9130.695873, test/accuracy=0.311100, test/loss=3.361201, test/num_examples=10000, total_duration=9515.154429, train/accuracy=0.440059, train/loss=2.609130, validation/accuracy=0.410360, validation/loss=2.759464, validation/num_examples=50000
I0428 15:02:31.784631 139671371761408 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.6060178279876709, loss=5.962524890899658
I0428 15:04:17.530623 139671363368704 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.8763057589530945, loss=4.077902317047119
I0428 15:06:02.822099 139671371761408 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.777157187461853, loss=4.430063247680664
I0428 15:07:48.711591 139671363368704 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.8920162320137024, loss=4.026995658874512
I0428 15:08:14.234214 139903503492928 spec.py:298] Evaluating on the training split.
I0428 15:08:21.766840 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 15:08:30.074792 139903503492928 spec.py:326] Evaluating on the test split.
I0428 15:08:31.790991 139903503492928 submission_runner.py:415] Time since start: 9953.33s, 	Step: 8727, 	{'train/accuracy': 0.4756835699081421, 'train/loss': 2.4381632804870605, 'validation/accuracy': 0.4244999885559082, 'validation/loss': 2.7078731060028076, 'validation/num_examples': 50000, 'test/accuracy': 0.3207000195980072, 'test/loss': 3.3253490924835205, 'test/num_examples': 10000, 'score': 9551.277529239655, 'total_duration': 9953.327883958817, 'accumulated_submission_time': 9551.277529239655, 'accumulated_eval_time': 401.3123371601105, 'accumulated_logging_time': 0.6252126693725586}
I0428 15:08:31.810215 139671371761408 logging_writer.py:48] [8727] accumulated_eval_time=401.312337, accumulated_logging_time=0.625213, accumulated_submission_time=9551.277529, global_step=8727, preemption_count=0, score=9551.277529, test/accuracy=0.320700, test/loss=3.325349, test/num_examples=10000, total_duration=9953.327884, train/accuracy=0.475684, train/loss=2.438163, validation/accuracy=0.424500, validation/loss=2.707873, validation/num_examples=50000
I0428 15:09:53.079996 139671363368704 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.9380971193313599, loss=4.139391899108887
I0428 15:11:38.547296 139671371761408 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.6834480166435242, loss=5.684485912322998
I0428 15:13:24.899539 139671363368704 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.9006478190422058, loss=3.9696035385131836
I0428 15:15:10.584327 139671371761408 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.8575927019119263, loss=4.0438432693481445
I0428 15:15:31.931328 139903503492928 spec.py:298] Evaluating on the training split.
I0428 15:15:39.611131 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 15:15:47.779367 139903503492928 spec.py:326] Evaluating on the test split.
I0428 15:15:49.505898 139903503492928 submission_runner.py:415] Time since start: 10391.04s, 	Step: 9121, 	{'train/accuracy': 0.46552732586860657, 'train/loss': 2.5152130126953125, 'validation/accuracy': 0.42479997873306274, 'validation/loss': 2.7100131511688232, 'validation/num_examples': 50000, 'test/accuracy': 0.32610002160072327, 'test/loss': 3.3012638092041016, 'test/num_examples': 10000, 'score': 9971.379585504532, 'total_duration': 10391.042766809464, 'accumulated_submission_time': 9971.379585504532, 'accumulated_eval_time': 418.8867988586426, 'accumulated_logging_time': 0.6579458713531494}
I0428 15:15:49.527440 139671363368704 logging_writer.py:48] [9121] accumulated_eval_time=418.886799, accumulated_logging_time=0.657946, accumulated_submission_time=9971.379586, global_step=9121, preemption_count=0, score=9971.379586, test/accuracy=0.326100, test/loss=3.301264, test/num_examples=10000, total_duration=10391.042767, train/accuracy=0.465527, train/loss=2.515213, validation/accuracy=0.424800, validation/loss=2.710013, validation/num_examples=50000
I0428 15:17:15.215065 139671371761408 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.7825830578804016, loss=4.145185470581055
I0428 15:19:01.822399 139671363368704 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.8517594337463379, loss=4.223276138305664
I0428 15:20:47.350764 139671371761408 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.6436492800712585, loss=5.90903902053833
I0428 15:22:33.628159 139671363368704 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.6759350895881653, loss=5.275505542755127
I0428 15:22:55.045310 139903503492928 spec.py:298] Evaluating on the training split.
I0428 15:23:03.051827 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 15:23:11.254138 139903503492928 spec.py:326] Evaluating on the test split.
I0428 15:23:12.971822 139903503492928 submission_runner.py:415] Time since start: 10834.51s, 	Step: 9521, 	{'train/accuracy': 0.47398436069488525, 'train/loss': 2.4670724868774414, 'validation/accuracy': 0.43873998522758484, 'validation/loss': 2.6311655044555664, 'validation/num_examples': 50000, 'test/accuracy': 0.34150001406669617, 'test/loss': 3.2237355709075928, 'test/num_examples': 10000, 'score': 10396.878695726395, 'total_duration': 10834.508744955063, 'accumulated_submission_time': 10396.878695726395, 'accumulated_eval_time': 436.8132598400116, 'accumulated_logging_time': 0.692777156829834}
I0428 15:23:12.987423 139671371761408 logging_writer.py:48] [9521] accumulated_eval_time=436.813260, accumulated_logging_time=0.692777, accumulated_submission_time=10396.878696, global_step=9521, preemption_count=0, score=10396.878696, test/accuracy=0.341500, test/loss=3.223736, test/num_examples=10000, total_duration=10834.508745, train/accuracy=0.473984, train/loss=2.467072, validation/accuracy=0.438740, validation/loss=2.631166, validation/num_examples=50000
I0428 15:24:37.385301 139671363368704 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.7393555641174316, loss=4.043172836303711
I0428 15:26:24.170732 139671371761408 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.6960084438323975, loss=4.93104362487793
I0428 15:28:10.356662 139671363368704 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.7386408448219299, loss=4.035976886749268
I0428 15:29:56.507920 139671371761408 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.7493757009506226, loss=4.414897918701172
I0428 15:30:18.033452 139903503492928 spec.py:298] Evaluating on the training split.
I0428 15:30:26.053128 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 15:30:34.480205 139903503492928 spec.py:326] Evaluating on the test split.
I0428 15:30:36.201374 139903503492928 submission_runner.py:415] Time since start: 11277.74s, 	Step: 9921, 	{'train/accuracy': 0.4839257597923279, 'train/loss': 2.3659372329711914, 'validation/accuracy': 0.4550800025463104, 'validation/loss': 2.5185301303863525, 'validation/num_examples': 50000, 'test/accuracy': 0.3468000292778015, 'test/loss': 3.153414487838745, 'test/num_examples': 10000, 'score': 10821.906108856201, 'total_duration': 11277.738247871399, 'accumulated_submission_time': 10821.906108856201, 'accumulated_eval_time': 454.98109769821167, 'accumulated_logging_time': 0.7215988636016846}
I0428 15:30:36.221843 139671363368704 logging_writer.py:48] [9921] accumulated_eval_time=454.981098, accumulated_logging_time=0.721599, accumulated_submission_time=10821.906109, global_step=9921, preemption_count=0, score=10821.906109, test/accuracy=0.346800, test/loss=3.153414, test/num_examples=10000, total_duration=11277.738248, train/accuracy=0.483926, train/loss=2.365937, validation/accuracy=0.455080, validation/loss=2.518530, validation/num_examples=50000
I0428 15:32:01.418530 139671371761408 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.7449510097503662, loss=4.234205722808838
I0428 15:33:48.527705 139671363368704 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.6929280161857605, loss=3.8847458362579346
I0428 15:35:34.763357 139671371761408 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.561591625213623, loss=5.487580299377441
I0428 15:37:21.042077 139671363368704 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.8165196776390076, loss=3.8139636516571045
I0428 15:37:42.276646 139903503492928 spec.py:298] Evaluating on the training split.
I0428 15:37:50.327779 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 15:37:58.703726 139903503492928 spec.py:326] Evaluating on the test split.
I0428 15:38:00.415547 139903503492928 submission_runner.py:415] Time since start: 11721.95s, 	Step: 10321, 	{'train/accuracy': 0.5147265791893005, 'train/loss': 2.2110495567321777, 'validation/accuracy': 0.4705999791622162, 'validation/loss': 2.431706190109253, 'validation/num_examples': 50000, 'test/accuracy': 0.36830002069473267, 'test/loss': 3.027301549911499, 'test/num_examples': 10000, 'score': 11247.945413351059, 'total_duration': 11721.952479839325, 'accumulated_submission_time': 11247.945413351059, 'accumulated_eval_time': 473.1199595928192, 'accumulated_logging_time': 0.7521257400512695}
I0428 15:38:00.427758 139671371761408 logging_writer.py:48] [10321] accumulated_eval_time=473.119960, accumulated_logging_time=0.752126, accumulated_submission_time=11247.945413, global_step=10321, preemption_count=0, score=11247.945413, test/accuracy=0.368300, test/loss=3.027302, test/num_examples=10000, total_duration=11721.952480, train/accuracy=0.514727, train/loss=2.211050, validation/accuracy=0.470600, validation/loss=2.431706, validation/num_examples=50000
I0428 15:39:25.008925 139671363368704 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.7475204467773438, loss=3.7754604816436768
I0428 15:41:11.685682 139671371761408 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.8068618178367615, loss=3.8123648166656494
I0428 15:42:59.049179 139671363368704 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.6340755820274353, loss=5.54667329788208
I0428 15:44:45.048636 139671371761408 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.5846714973449707, loss=4.658048152923584
I0428 15:45:06.528027 139903503492928 spec.py:298] Evaluating on the training split.
I0428 15:45:14.583021 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 15:45:22.999448 139903503492928 spec.py:326] Evaluating on the test split.
I0428 15:45:24.700531 139903503492928 submission_runner.py:415] Time since start: 12166.24s, 	Step: 10721, 	{'train/accuracy': 0.5159375071525574, 'train/loss': 2.2091686725616455, 'validation/accuracy': 0.4818999767303467, 'validation/loss': 2.387497663497925, 'validation/num_examples': 50000, 'test/accuracy': 0.3712000250816345, 'test/loss': 3.0307586193084717, 'test/num_examples': 10000, 'score': 11674.032290697098, 'total_duration': 12166.237461090088, 'accumulated_submission_time': 11674.032290697098, 'accumulated_eval_time': 491.2924301624298, 'accumulated_logging_time': 0.7723338603973389}
I0428 15:45:24.712022 139671363368704 logging_writer.py:48] [10721] accumulated_eval_time=491.292430, accumulated_logging_time=0.772334, accumulated_submission_time=11674.032291, global_step=10721, preemption_count=0, score=11674.032291, test/accuracy=0.371200, test/loss=3.030759, test/num_examples=10000, total_duration=12166.237461, train/accuracy=0.515938, train/loss=2.209169, validation/accuracy=0.481900, validation/loss=2.387498, validation/num_examples=50000
I0428 15:46:49.918042 139671371761408 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.7489517331123352, loss=3.9808316230773926
I0428 15:48:36.229465 139671363368704 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.7985020875930786, loss=3.87570858001709
I0428 15:50:23.049574 139671371761408 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.7694147229194641, loss=3.7318787574768066
I0428 15:52:09.554620 139671363368704 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.8083983659744263, loss=3.6705732345581055
I0428 15:52:30.853852 139903503492928 spec.py:298] Evaluating on the training split.
I0428 15:52:38.948189 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 15:52:47.364709 139903503492928 spec.py:326] Evaluating on the test split.
I0428 15:52:49.072730 139903503492928 submission_runner.py:415] Time since start: 12610.61s, 	Step: 11121, 	{'train/accuracy': 0.5235351324081421, 'train/loss': 2.1831657886505127, 'validation/accuracy': 0.4909600019454956, 'validation/loss': 2.3377301692962646, 'validation/num_examples': 50000, 'test/accuracy': 0.387800008058548, 'test/loss': 2.9446089267730713, 'test/num_examples': 10000, 'score': 12100.160240888596, 'total_duration': 12610.60964179039, 'accumulated_submission_time': 12100.160240888596, 'accumulated_eval_time': 509.51124691963196, 'accumulated_logging_time': 0.7922308444976807}
I0428 15:52:49.087942 139671371761408 logging_writer.py:48] [11121] accumulated_eval_time=509.511247, accumulated_logging_time=0.792231, accumulated_submission_time=12100.160241, global_step=11121, preemption_count=0, score=12100.160241, test/accuracy=0.387800, test/loss=2.944609, test/num_examples=10000, total_duration=12610.609642, train/accuracy=0.523535, train/loss=2.183166, validation/accuracy=0.490960, validation/loss=2.337730, validation/num_examples=50000
I0428 15:54:13.667854 139671363368704 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.6902574300765991, loss=4.3264241218566895
I0428 15:56:00.690841 139671371761408 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.6888545751571655, loss=3.703406810760498
I0428 15:57:46.712416 139671363368704 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.7123174667358398, loss=4.036679267883301
I0428 15:59:32.687275 139671371761408 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.6936095356941223, loss=5.742165565490723
I0428 15:59:53.542304 139903503492928 spec.py:298] Evaluating on the training split.
I0428 16:00:01.627471 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 16:00:10.074831 139903503492928 spec.py:326] Evaluating on the test split.
I0428 16:00:11.785249 139903503492928 submission_runner.py:415] Time since start: 13053.32s, 	Step: 11521, 	{'train/accuracy': 0.5712109208106995, 'train/loss': 1.9663407802581787, 'validation/accuracy': 0.5010200142860413, 'validation/loss': 2.2908246517181396, 'validation/num_examples': 50000, 'test/accuracy': 0.39000001549720764, 'test/loss': 2.9200243949890137, 'test/num_examples': 10000, 'score': 12524.595651865005, 'total_duration': 13053.322176933289, 'accumulated_submission_time': 12524.595651865005, 'accumulated_eval_time': 527.7541630268097, 'accumulated_logging_time': 0.8210840225219727}
I0428 16:00:11.796873 139671363368704 logging_writer.py:48] [11521] accumulated_eval_time=527.754163, accumulated_logging_time=0.821084, accumulated_submission_time=12524.595652, global_step=11521, preemption_count=0, score=12524.595652, test/accuracy=0.390000, test/loss=2.920024, test/num_examples=10000, total_duration=13053.322177, train/accuracy=0.571211, train/loss=1.966341, validation/accuracy=0.501020, validation/loss=2.290825, validation/num_examples=50000
I0428 16:01:36.320348 139671371761408 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.6791766285896301, loss=4.037663459777832
I0428 16:03:22.046715 139671363368704 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.6933210492134094, loss=3.5849881172180176
I0428 16:05:08.197243 139671371761408 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.7248905897140503, loss=3.6812431812286377
I0428 16:06:54.689155 139671363368704 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.7063911557197571, loss=3.5662503242492676
I0428 16:07:15.687707 139903503492928 spec.py:298] Evaluating on the training split.
I0428 16:07:23.753438 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 16:07:32.202804 139903503492928 spec.py:326] Evaluating on the test split.
I0428 16:07:33.919063 139903503492928 submission_runner.py:415] Time since start: 13495.46s, 	Step: 11921, 	{'train/accuracy': 0.5531249642372131, 'train/loss': 2.044267177581787, 'validation/accuracy': 0.5115000009536743, 'validation/loss': 2.25663685798645, 'validation/num_examples': 50000, 'test/accuracy': 0.39250001311302185, 'test/loss': 2.8767056465148926, 'test/num_examples': 10000, 'score': 12948.47294473648, 'total_duration': 13495.455977916718, 'accumulated_submission_time': 12948.47294473648, 'accumulated_eval_time': 545.98548412323, 'accumulated_logging_time': 0.8408727645874023}
I0428 16:07:33.932760 139671371761408 logging_writer.py:48] [11921] accumulated_eval_time=545.985484, accumulated_logging_time=0.840873, accumulated_submission_time=12948.472945, global_step=11921, preemption_count=0, score=12948.472945, test/accuracy=0.392500, test/loss=2.876706, test/num_examples=10000, total_duration=13495.455978, train/accuracy=0.553125, train/loss=2.044267, validation/accuracy=0.511500, validation/loss=2.256637, validation/num_examples=50000
I0428 16:08:59.665487 139671363368704 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.7664634585380554, loss=3.8773257732391357
I0428 16:10:46.116861 139671371761408 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.6930861473083496, loss=3.6395695209503174
I0428 16:12:33.222079 139671363368704 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.8037705421447754, loss=3.6247360706329346
I0428 16:14:19.326820 139671371761408 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.6280868053436279, loss=4.998505592346191
I0428 16:14:40.181261 139903503492928 spec.py:298] Evaluating on the training split.
I0428 16:14:48.281335 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 16:14:56.793749 139903503492928 spec.py:326] Evaluating on the test split.
I0428 16:14:58.518568 139903503492928 submission_runner.py:415] Time since start: 13940.06s, 	Step: 12321, 	{'train/accuracy': 0.5609179735183716, 'train/loss': 1.9938178062438965, 'validation/accuracy': 0.5188400149345398, 'validation/loss': 2.1853928565979004, 'validation/num_examples': 50000, 'test/accuracy': 0.40890002250671387, 'test/loss': 2.809438705444336, 'test/num_examples': 10000, 'score': 13374.702414751053, 'total_duration': 13940.055477619171, 'accumulated_submission_time': 13374.702414751053, 'accumulated_eval_time': 564.3227257728577, 'accumulated_logging_time': 0.8680617809295654}
I0428 16:14:58.533377 139671363368704 logging_writer.py:48] [12321] accumulated_eval_time=564.322726, accumulated_logging_time=0.868062, accumulated_submission_time=13374.702415, global_step=12321, preemption_count=0, score=13374.702415, test/accuracy=0.408900, test/loss=2.809439, test/num_examples=10000, total_duration=13940.055478, train/accuracy=0.560918, train/loss=1.993818, validation/accuracy=0.518840, validation/loss=2.185393, validation/num_examples=50000
I0428 16:16:23.734687 139671371761408 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.6169255971908569, loss=5.142077445983887
I0428 16:18:10.132555 139671363368704 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.7549225091934204, loss=3.4308128356933594
I0428 16:19:56.466150 139671371761408 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.6197515726089478, loss=5.538561820983887
I0428 16:21:43.224830 139671363368704 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.7050266861915588, loss=3.521806478500366
I0428 16:22:04.770192 139903503492928 spec.py:298] Evaluating on the training split.
I0428 16:22:12.784370 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 16:22:21.291066 139903503492928 spec.py:326] Evaluating on the test split.
I0428 16:22:23.010814 139903503492928 submission_runner.py:415] Time since start: 14384.55s, 	Step: 12721, 	{'train/accuracy': 0.570019543170929, 'train/loss': 1.9629398584365845, 'validation/accuracy': 0.5336799621582031, 'validation/loss': 2.123461961746216, 'validation/num_examples': 50000, 'test/accuracy': 0.4132000207901001, 'test/loss': 2.7619576454162598, 'test/num_examples': 10000, 'score': 13800.920033931732, 'total_duration': 14384.547704696655, 'accumulated_submission_time': 13800.920033931732, 'accumulated_eval_time': 582.5632865428925, 'accumulated_logging_time': 0.8966207504272461}
I0428 16:22:23.028259 139671371761408 logging_writer.py:48] [12721] accumulated_eval_time=582.563287, accumulated_logging_time=0.896621, accumulated_submission_time=13800.920034, global_step=12721, preemption_count=0, score=13800.920034, test/accuracy=0.413200, test/loss=2.761958, test/num_examples=10000, total_duration=14384.547705, train/accuracy=0.570020, train/loss=1.962940, validation/accuracy=0.533680, validation/loss=2.123462, validation/num_examples=50000
I0428 16:23:48.279656 139671363368704 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.6488789916038513, loss=4.837247848510742
I0428 16:25:34.494497 139671371761408 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.6720645427703857, loss=3.397519111633301
I0428 16:27:20.247366 139671363368704 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.7261810898780823, loss=3.616506338119507
I0428 16:29:06.351937 139671371761408 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.7256079912185669, loss=3.560439109802246
I0428 16:29:27.596961 139903503492928 spec.py:298] Evaluating on the training split.
I0428 16:29:35.599370 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 16:29:44.161427 139903503492928 spec.py:326] Evaluating on the test split.
I0428 16:29:45.884703 139903503492928 submission_runner.py:415] Time since start: 14827.42s, 	Step: 13121, 	{'train/accuracy': 0.590136706829071, 'train/loss': 1.8529216051101685, 'validation/accuracy': 0.5370599627494812, 'validation/loss': 2.1021406650543213, 'validation/num_examples': 50000, 'test/accuracy': 0.42270001769065857, 'test/loss': 2.7279887199401855, 'test/num_examples': 10000, 'score': 14225.474731206894, 'total_duration': 14827.421613454819, 'accumulated_submission_time': 14225.474731206894, 'accumulated_eval_time': 600.8509647846222, 'accumulated_logging_time': 0.92275071144104}
I0428 16:29:45.901308 139671363368704 logging_writer.py:48] [13121] accumulated_eval_time=600.850965, accumulated_logging_time=0.922751, accumulated_submission_time=14225.474731, global_step=13121, preemption_count=0, score=14225.474731, test/accuracy=0.422700, test/loss=2.727989, test/num_examples=10000, total_duration=14827.421613, train/accuracy=0.590137, train/loss=1.852922, validation/accuracy=0.537060, validation/loss=2.102141, validation/num_examples=50000
I0428 16:31:11.030494 139671371761408 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.6138011813163757, loss=3.993837356567383
I0428 16:32:57.357106 139671363368704 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.7300982475280762, loss=3.5347743034362793
I0428 16:34:43.855436 139671371761408 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.6689351201057434, loss=3.8250973224639893
I0428 16:36:30.174761 139671363368704 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.6125940680503845, loss=5.330787181854248
I0428 16:36:51.504659 139903503492928 spec.py:298] Evaluating on the training split.
I0428 16:36:59.524626 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 16:37:07.956473 139903503492928 spec.py:326] Evaluating on the test split.
I0428 16:37:09.674332 139903503492928 submission_runner.py:415] Time since start: 15271.21s, 	Step: 13521, 	{'train/accuracy': 0.5941405892372131, 'train/loss': 1.8079285621643066, 'validation/accuracy': 0.5467000007629395, 'validation/loss': 2.0349292755126953, 'validation/num_examples': 50000, 'test/accuracy': 0.4296000301837921, 'test/loss': 2.6776962280273438, 'test/num_examples': 10000, 'score': 14651.058849573135, 'total_duration': 15271.211242437363, 'accumulated_submission_time': 14651.058849573135, 'accumulated_eval_time': 619.0205767154694, 'accumulated_logging_time': 0.9531431198120117}
I0428 16:37:09.690029 139671371761408 logging_writer.py:48] [13521] accumulated_eval_time=619.020577, accumulated_logging_time=0.953143, accumulated_submission_time=14651.058850, global_step=13521, preemption_count=0, score=14651.058850, test/accuracy=0.429600, test/loss=2.677696, test/num_examples=10000, total_duration=15271.211242, train/accuracy=0.594141, train/loss=1.807929, validation/accuracy=0.546700, validation/loss=2.034929, validation/num_examples=50000
I0428 16:38:34.801000 139671363368704 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.9179320335388184, loss=5.395023822784424
I0428 16:40:21.574719 139671371761408 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.6599987149238586, loss=3.5150086879730225
I0428 16:42:08.644818 139671363368704 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.6678054332733154, loss=5.562398433685303
I0428 16:43:55.132205 139671371761408 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.6887532472610474, loss=4.013814926147461
I0428 16:44:10.087538 139903503492928 spec.py:298] Evaluating on the training split.
I0428 16:44:18.115997 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 16:44:26.695341 139903503492928 spec.py:326] Evaluating on the test split.
I0428 16:44:28.422127 139903503492928 submission_runner.py:415] Time since start: 15709.96s, 	Step: 13920, 	{'train/accuracy': 0.5951757431030273, 'train/loss': 1.8053202629089355, 'validation/accuracy': 0.5530200004577637, 'validation/loss': 2.007859230041504, 'validation/num_examples': 50000, 'test/accuracy': 0.44300001859664917, 'test/loss': 2.640056610107422, 'test/num_examples': 10000, 'score': 15071.437667608261, 'total_duration': 15709.959007263184, 'accumulated_submission_time': 15071.437667608261, 'accumulated_eval_time': 637.3550798892975, 'accumulated_logging_time': 0.9819111824035645}
I0428 16:44:28.441659 139671363368704 logging_writer.py:48] [13920] accumulated_eval_time=637.355080, accumulated_logging_time=0.981911, accumulated_submission_time=15071.437668, global_step=13920, preemption_count=0, score=15071.437668, test/accuracy=0.443000, test/loss=2.640057, test/num_examples=10000, total_duration=15709.959007, train/accuracy=0.595176, train/loss=1.805320, validation/accuracy=0.553020, validation/loss=2.007859, validation/num_examples=50000
I0428 16:45:59.558688 139671371761408 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.6446546316146851, loss=4.115298271179199
I0428 16:47:46.129529 139671363368704 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.634652853012085, loss=4.560986042022705
I0428 16:49:32.657919 139671371761408 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.6410180926322937, loss=5.074854850769043
I0428 16:51:19.173363 139671363368704 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.7291085720062256, loss=4.297516822814941
I0428 16:51:28.797184 139903503492928 spec.py:298] Evaluating on the training split.
I0428 16:51:36.814090 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 16:51:45.365872 139903503492928 spec.py:326] Evaluating on the test split.
I0428 16:51:47.084372 139903503492928 submission_runner.py:415] Time since start: 16148.62s, 	Step: 14313, 	{'train/accuracy': 0.6090624928474426, 'train/loss': 1.7258493900299072, 'validation/accuracy': 0.5591999888420105, 'validation/loss': 1.949966549873352, 'validation/num_examples': 50000, 'test/accuracy': 0.4466000199317932, 'test/loss': 2.589061975479126, 'test/num_examples': 10000, 'score': 15491.773736953735, 'total_duration': 16148.62124633789, 'accumulated_submission_time': 15491.773736953735, 'accumulated_eval_time': 655.642162322998, 'accumulated_logging_time': 1.015451192855835}
I0428 16:51:47.103535 139671371761408 logging_writer.py:48] [14313] accumulated_eval_time=655.642162, accumulated_logging_time=1.015451, accumulated_submission_time=15491.773737, global_step=14313, preemption_count=0, score=15491.773737, test/accuracy=0.446600, test/loss=2.589062, test/num_examples=10000, total_duration=16148.621246, train/accuracy=0.609062, train/loss=1.725849, validation/accuracy=0.559200, validation/loss=1.949967, validation/num_examples=50000
I0428 16:53:24.023656 139671363368704 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.6869140863418579, loss=3.500110626220703
I0428 16:55:10.460006 139671371761408 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.7346693277359009, loss=3.4008920192718506
I0428 16:56:57.574302 139671363368704 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.8045995235443115, loss=3.6739044189453125
I0428 16:58:43.859314 139671371761408 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.6511214971542358, loss=3.8781208992004395
I0428 16:58:47.653910 139903503492928 spec.py:298] Evaluating on the training split.
I0428 16:58:55.702448 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 16:59:04.272156 139903503492928 spec.py:326] Evaluating on the test split.
I0428 16:59:06.007103 139903503492928 submission_runner.py:415] Time since start: 16587.54s, 	Step: 14706, 	{'train/accuracy': 0.6206445097923279, 'train/loss': 1.6915498971939087, 'validation/accuracy': 0.565559983253479, 'validation/loss': 1.935001015663147, 'validation/num_examples': 50000, 'test/accuracy': 0.44460001587867737, 'test/loss': 2.581625461578369, 'test/num_examples': 10000, 'score': 15912.304953575134, 'total_duration': 16587.543986797333, 'accumulated_submission_time': 15912.304953575134, 'accumulated_eval_time': 673.9952645301819, 'accumulated_logging_time': 1.0483109951019287}
I0428 16:59:06.027484 139671363368704 logging_writer.py:48] [14706] accumulated_eval_time=673.995265, accumulated_logging_time=1.048311, accumulated_submission_time=15912.304954, global_step=14706, preemption_count=0, score=15912.304954, test/accuracy=0.444600, test/loss=2.581625, test/num_examples=10000, total_duration=16587.543987, train/accuracy=0.620645, train/loss=1.691550, validation/accuracy=0.565560, validation/loss=1.935001, validation/num_examples=50000
I0428 17:00:48.435904 139671371761408 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.6245815753936768, loss=5.370914936065674
I0428 17:02:33.969089 139671363368704 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.7315955758094788, loss=3.3162858486175537
I0428 17:04:19.777826 139671371761408 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.7283389568328857, loss=3.320411443710327
I0428 17:06:05.867203 139671363368704 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.6782909631729126, loss=3.981109142303467
I0428 17:06:06.691055 139903503492928 spec.py:298] Evaluating on the training split.
I0428 17:06:14.741168 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 17:06:23.378823 139903503492928 spec.py:326] Evaluating on the test split.
I0428 17:06:25.105857 139903503492928 submission_runner.py:415] Time since start: 17026.64s, 	Step: 15102, 	{'train/accuracy': 0.6183984279632568, 'train/loss': 1.737562656402588, 'validation/accuracy': 0.5741199851036072, 'validation/loss': 1.953713059425354, 'validation/num_examples': 50000, 'test/accuracy': 0.44780001044273376, 'test/loss': 2.5946013927459717, 'test/num_examples': 10000, 'score': 16332.949893951416, 'total_duration': 17026.642771959305, 'accumulated_submission_time': 16332.949893951416, 'accumulated_eval_time': 692.410008430481, 'accumulated_logging_time': 1.081965684890747}
I0428 17:06:25.120997 139671371761408 logging_writer.py:48] [15102] accumulated_eval_time=692.410008, accumulated_logging_time=1.081966, accumulated_submission_time=16332.949894, global_step=15102, preemption_count=0, score=16332.949894, test/accuracy=0.447800, test/loss=2.594601, test/num_examples=10000, total_duration=17026.642772, train/accuracy=0.618398, train/loss=1.737563, validation/accuracy=0.574120, validation/loss=1.953713, validation/num_examples=50000
I0428 17:08:10.197284 139671363368704 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.7224000096321106, loss=3.52809476852417
I0428 17:09:56.940877 139671371761408 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.6207295656204224, loss=4.23304557800293
I0428 17:11:43.193297 139671363368704 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.7599002718925476, loss=3.354616165161133
I0428 17:13:29.306182 139671371761408 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.8485209941864014, loss=5.182006359100342
I0428 17:13:29.358941 139903503492928 spec.py:298] Evaluating on the training split.
I0428 17:13:37.376128 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 17:13:45.823514 139903503492928 spec.py:326] Evaluating on the test split.
I0428 17:13:47.534510 139903503492928 submission_runner.py:415] Time since start: 17469.07s, 	Step: 15501, 	{'train/accuracy': 0.61376953125, 'train/loss': 1.7334959506988525, 'validation/accuracy': 0.5723999738693237, 'validation/loss': 1.9359074831008911, 'validation/num_examples': 50000, 'test/accuracy': 0.4489000141620636, 'test/loss': 2.585946798324585, 'test/num_examples': 10000, 'score': 16757.16921687126, 'total_duration': 17469.071436166763, 'accumulated_submission_time': 16757.16921687126, 'accumulated_eval_time': 710.5855083465576, 'accumulated_logging_time': 1.1104052066802979}
I0428 17:13:47.550263 139671363368704 logging_writer.py:48] [15501] accumulated_eval_time=710.585508, accumulated_logging_time=1.110405, accumulated_submission_time=16757.169217, global_step=15501, preemption_count=0, score=16757.169217, test/accuracy=0.448900, test/loss=2.585947, test/num_examples=10000, total_duration=17469.071436, train/accuracy=0.613770, train/loss=1.733496, validation/accuracy=0.572400, validation/loss=1.935907, validation/num_examples=50000
I0428 17:15:33.202266 139671371761408 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.6822988390922546, loss=5.286821365356445
I0428 17:17:19.307205 139671363368704 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.7075393795967102, loss=3.1717369556427
I0428 17:19:06.247409 139671371761408 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.7283949255943298, loss=3.4684994220733643
I0428 17:20:51.990893 139671363368704 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.6535372138023376, loss=3.431546688079834
I0428 17:20:52.041143 139903503492928 spec.py:298] Evaluating on the training split.
I0428 17:21:00.024111 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 17:21:08.592334 139903503492928 spec.py:326] Evaluating on the test split.
I0428 17:21:10.308092 139903503492928 submission_runner.py:415] Time since start: 17911.84s, 	Step: 15901, 	{'train/accuracy': 0.6464257836341858, 'train/loss': 1.5724749565124512, 'validation/accuracy': 0.5799999833106995, 'validation/loss': 1.8763573169708252, 'validation/num_examples': 50000, 'test/accuracy': 0.4540000259876251, 'test/loss': 2.5238494873046875, 'test/num_examples': 10000, 'score': 17181.6416079998, 'total_duration': 17911.844989538193, 'accumulated_submission_time': 17181.6416079998, 'accumulated_eval_time': 728.8523530960083, 'accumulated_logging_time': 1.1393272876739502}
I0428 17:21:10.329187 139671371761408 logging_writer.py:48] [15901] accumulated_eval_time=728.852353, accumulated_logging_time=1.139327, accumulated_submission_time=17181.641608, global_step=15901, preemption_count=0, score=17181.641608, test/accuracy=0.454000, test/loss=2.523849, test/num_examples=10000, total_duration=17911.844990, train/accuracy=0.646426, train/loss=1.572475, validation/accuracy=0.580000, validation/loss=1.876357, validation/num_examples=50000
I0428 17:22:56.260277 139671363368704 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.7209736704826355, loss=3.2482476234436035
I0428 17:24:41.936160 139671371761408 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.7150856852531433, loss=5.309257507324219
I0428 17:26:28.024769 139671363368704 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.8812365531921387, loss=3.297254800796509
I0428 17:28:13.984199 139671371761408 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.6366521120071411, loss=3.886556625366211
I0428 17:28:14.036591 139903503492928 spec.py:298] Evaluating on the training split.
I0428 17:28:22.053099 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 17:28:30.621603 139903503492928 spec.py:326] Evaluating on the test split.
I0428 17:28:32.338853 139903503492928 submission_runner.py:415] Time since start: 18353.88s, 	Step: 16301, 	{'train/accuracy': 0.6430858969688416, 'train/loss': 1.602251648902893, 'validation/accuracy': 0.5914799571037292, 'validation/loss': 1.8467577695846558, 'validation/num_examples': 50000, 'test/accuracy': 0.4686000347137451, 'test/loss': 2.4845173358917236, 'test/num_examples': 10000, 'score': 17605.33087515831, 'total_duration': 18353.875778198242, 'accumulated_submission_time': 17605.33087515831, 'accumulated_eval_time': 747.154542684555, 'accumulated_logging_time': 1.1732375621795654}
I0428 17:28:32.352251 139671363368704 logging_writer.py:48] [16301] accumulated_eval_time=747.154543, accumulated_logging_time=1.173238, accumulated_submission_time=17605.330875, global_step=16301, preemption_count=0, score=17605.330875, test/accuracy=0.468600, test/loss=2.484517, test/num_examples=10000, total_duration=18353.875778, train/accuracy=0.643086, train/loss=1.602252, validation/accuracy=0.591480, validation/loss=1.846758, validation/num_examples=50000
I0428 17:30:17.973168 139671371761408 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.7126874327659607, loss=3.725741386413574
I0428 17:32:04.513797 139671363368704 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.766405463218689, loss=3.523120403289795
I0428 17:33:50.699859 139671371761408 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.7500821352005005, loss=3.233098030090332
I0428 17:35:36.731555 139671363368704 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.771710991859436, loss=3.187617301940918
I0428 17:35:36.782326 139903503492928 spec.py:298] Evaluating on the training split.
I0428 17:35:44.787425 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 17:35:53.274632 139903503492928 spec.py:326] Evaluating on the test split.
I0428 17:35:54.987091 139903503492928 submission_runner.py:415] Time since start: 18796.52s, 	Step: 16701, 	{'train/accuracy': 0.643359363079071, 'train/loss': 1.6095776557922363, 'validation/accuracy': 0.5931800007820129, 'validation/loss': 1.8343344926834106, 'validation/num_examples': 50000, 'test/accuracy': 0.4678000211715698, 'test/loss': 2.478806257247925, 'test/num_examples': 10000, 'score': 18029.746867656708, 'total_duration': 18796.524010181427, 'accumulated_submission_time': 18029.746867656708, 'accumulated_eval_time': 765.3592269420624, 'accumulated_logging_time': 1.1954035758972168}
I0428 17:35:55.006067 139671371761408 logging_writer.py:48] [16701] accumulated_eval_time=765.359227, accumulated_logging_time=1.195404, accumulated_submission_time=18029.746868, global_step=16701, preemption_count=0, score=18029.746868, test/accuracy=0.467800, test/loss=2.478806, test/num_examples=10000, total_duration=18796.524010, train/accuracy=0.643359, train/loss=1.609578, validation/accuracy=0.593180, validation/loss=1.834334, validation/num_examples=50000
I0428 17:37:40.801013 139671363368704 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.7180430889129639, loss=5.1486287117004395
I0428 17:39:28.784525 139671371761408 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.6881310939788818, loss=3.987293243408203
I0428 17:41:15.143663 139671363368704 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.6552878618240356, loss=4.002161502838135
I0428 17:43:01.427982 139671371761408 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.6851951479911804, loss=4.824540615081787
I0428 17:43:01.492266 139903503492928 spec.py:298] Evaluating on the training split.
I0428 17:43:09.508877 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 17:43:18.001762 139903503492928 spec.py:326] Evaluating on the test split.
I0428 17:43:19.737711 139903503492928 submission_runner.py:415] Time since start: 19241.27s, 	Step: 17101, 	{'train/accuracy': 0.6371093392372131, 'train/loss': 1.6720467805862427, 'validation/accuracy': 0.5889399647712708, 'validation/loss': 1.876125454902649, 'validation/num_examples': 50000, 'test/accuracy': 0.46560001373291016, 'test/loss': 2.5320634841918945, 'test/num_examples': 10000, 'score': 18456.21490573883, 'total_duration': 19241.27462744713, 'accumulated_submission_time': 18456.21490573883, 'accumulated_eval_time': 783.6046245098114, 'accumulated_logging_time': 1.2269718647003174}
I0428 17:43:19.751740 139671363368704 logging_writer.py:48] [17101] accumulated_eval_time=783.604625, accumulated_logging_time=1.226972, accumulated_submission_time=18456.214906, global_step=17101, preemption_count=0, score=18456.214906, test/accuracy=0.465600, test/loss=2.532063, test/num_examples=10000, total_duration=19241.274627, train/accuracy=0.637109, train/loss=1.672047, validation/accuracy=0.588940, validation/loss=1.876125, validation/num_examples=50000
I0428 17:45:05.406628 139671371761408 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.7583644390106201, loss=3.2005558013916016
I0428 17:46:51.252565 139671363368704 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.7239376306533813, loss=3.2427635192871094
I0428 17:48:37.184975 139671371761408 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.6985851526260376, loss=3.2372021675109863
I0428 17:50:23.165479 139671363368704 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.7291954159736633, loss=4.5808916091918945
I0428 17:50:23.215779 139903503492928 spec.py:298] Evaluating on the training split.
I0428 17:50:31.238743 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 17:50:39.811702 139903503492928 spec.py:326] Evaluating on the test split.
I0428 17:50:41.527393 139903503492928 submission_runner.py:415] Time since start: 19683.06s, 	Step: 17501, 	{'train/accuracy': 0.6621484160423279, 'train/loss': 1.5361453294754028, 'validation/accuracy': 0.5992599725723267, 'validation/loss': 1.8087482452392578, 'validation/num_examples': 50000, 'test/accuracy': 0.47630003094673157, 'test/loss': 2.444333076477051, 'test/num_examples': 10000, 'score': 18879.662127256393, 'total_duration': 19683.06428718567, 'accumulated_submission_time': 18879.662127256393, 'accumulated_eval_time': 801.9161303043365, 'accumulated_logging_time': 1.2525112628936768}
I0428 17:50:41.548508 139671371761408 logging_writer.py:48] [17501] accumulated_eval_time=801.916130, accumulated_logging_time=1.252511, accumulated_submission_time=18879.662127, global_step=17501, preemption_count=0, score=18879.662127, test/accuracy=0.476300, test/loss=2.444333, test/num_examples=10000, total_duration=19683.064287, train/accuracy=0.662148, train/loss=1.536145, validation/accuracy=0.599260, validation/loss=1.808748, validation/num_examples=50000
I0428 17:52:27.560834 139671363368704 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.7324236035346985, loss=3.3049967288970947
I0428 17:54:13.875392 139671371761408 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.7602980732917786, loss=3.2279677391052246
I0428 17:55:59.578583 139671363368704 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.7193043231964111, loss=3.7333297729492188
I0428 17:57:46.241490 139671371761408 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.8252978920936584, loss=5.255553245544434
I0428 17:57:46.294551 139903503492928 spec.py:298] Evaluating on the training split.
I0428 17:57:54.320465 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 17:58:02.980201 139903503492928 spec.py:326] Evaluating on the test split.
I0428 17:58:04.697731 139903503492928 submission_runner.py:415] Time since start: 20126.23s, 	Step: 17901, 	{'train/accuracy': 0.6515429615974426, 'train/loss': 1.6296273469924927, 'validation/accuracy': 0.5973799824714661, 'validation/loss': 1.8643845319747925, 'validation/num_examples': 50000, 'test/accuracy': 0.47220003604888916, 'test/loss': 2.501556158065796, 'test/num_examples': 10000, 'score': 19304.389524936676, 'total_duration': 20126.234627008438, 'accumulated_submission_time': 19304.389524936676, 'accumulated_eval_time': 820.3192043304443, 'accumulated_logging_time': 1.2868199348449707}
I0428 17:58:04.719625 139671363368704 logging_writer.py:48] [17901] accumulated_eval_time=820.319204, accumulated_logging_time=1.286820, accumulated_submission_time=19304.389525, global_step=17901, preemption_count=0, score=19304.389525, test/accuracy=0.472200, test/loss=2.501556, test/num_examples=10000, total_duration=20126.234627, train/accuracy=0.651543, train/loss=1.629627, validation/accuracy=0.597380, validation/loss=1.864385, validation/num_examples=50000
I0428 17:59:50.805883 139671371761408 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.8679444193840027, loss=3.3203799724578857
I0428 18:01:36.640956 139671363368704 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.8850594758987427, loss=4.92337703704834
I0428 18:03:22.664137 139671371761408 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.8230717778205872, loss=5.135681629180908
I0428 18:05:08.434681 139671363368704 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.7487486004829407, loss=3.25015926361084
I0428 18:05:08.485481 139903503492928 spec.py:298] Evaluating on the training split.
I0428 18:05:16.473702 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 18:05:25.048466 139903503492928 spec.py:326] Evaluating on the test split.
I0428 18:05:26.746025 139903503492928 submission_runner.py:415] Time since start: 20568.28s, 	Step: 18301, 	{'train/accuracy': 0.6532031297683716, 'train/loss': 1.53575599193573, 'validation/accuracy': 0.606719970703125, 'validation/loss': 1.7462965250015259, 'validation/num_examples': 50000, 'test/accuracy': 0.4771000146865845, 'test/loss': 2.410719633102417, 'test/num_examples': 10000, 'score': 19728.13902282715, 'total_duration': 20568.28292798996, 'accumulated_submission_time': 19728.13902282715, 'accumulated_eval_time': 838.5796527862549, 'accumulated_logging_time': 1.319887638092041}
I0428 18:05:26.768393 139671371761408 logging_writer.py:48] [18301] accumulated_eval_time=838.579653, accumulated_logging_time=1.319888, accumulated_submission_time=19728.139023, global_step=18301, preemption_count=0, score=19728.139023, test/accuracy=0.477100, test/loss=2.410720, test/num_examples=10000, total_duration=20568.282928, train/accuracy=0.653203, train/loss=1.535756, validation/accuracy=0.606720, validation/loss=1.746297, validation/num_examples=50000
I0428 18:07:12.903042 139671363368704 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.6754048466682434, loss=3.6763317584991455
I0428 18:08:58.578381 139671371761408 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.7235602736473083, loss=3.7430009841918945
I0428 18:10:45.013413 139671363368704 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.740408718585968, loss=3.44275164604187
I0428 18:12:30.988240 139671371761408 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.711815595626831, loss=3.1250925064086914
I0428 18:12:31.039010 139903503492928 spec.py:298] Evaluating on the training split.
I0428 18:12:39.019576 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 18:12:47.586027 139903503492928 spec.py:326] Evaluating on the test split.
I0428 18:12:49.297867 139903503492928 submission_runner.py:415] Time since start: 21010.83s, 	Step: 18701, 	{'train/accuracy': 0.6934765577316284, 'train/loss': 1.3545461893081665, 'validation/accuracy': 0.6125999689102173, 'validation/loss': 1.716591715812683, 'validation/num_examples': 50000, 'test/accuracy': 0.48730000853538513, 'test/loss': 2.371211290359497, 'test/num_examples': 10000, 'score': 20152.390095233917, 'total_duration': 21010.834761619568, 'accumulated_submission_time': 20152.390095233917, 'accumulated_eval_time': 856.838406085968, 'accumulated_logging_time': 1.3558118343353271}
I0428 18:12:49.320593 139671363368704 logging_writer.py:48] [18701] accumulated_eval_time=856.838406, accumulated_logging_time=1.355812, accumulated_submission_time=20152.390095, global_step=18701, preemption_count=0, score=20152.390095, test/accuracy=0.487300, test/loss=2.371211, test/num_examples=10000, total_duration=21010.834762, train/accuracy=0.693477, train/loss=1.354546, validation/accuracy=0.612600, validation/loss=1.716592, validation/num_examples=50000
I0428 18:14:35.984904 139671371761408 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.8236844539642334, loss=3.1023330688476562
I0428 18:16:22.491174 139671363368704 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.7523106336593628, loss=3.132624626159668
I0428 18:18:08.101395 139671371761408 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.8218981027603149, loss=3.114818811416626
I0428 18:19:54.084902 139671363368704 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.7354645133018494, loss=3.3758504390716553
I0428 18:19:54.134916 139903503492928 spec.py:298] Evaluating on the training split.
I0428 18:20:02.133381 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 18:20:10.807008 139903503492928 spec.py:326] Evaluating on the test split.
I0428 18:20:12.543592 139903503492928 submission_runner.py:415] Time since start: 21454.08s, 	Step: 19101, 	{'train/accuracy': 0.6709374785423279, 'train/loss': 1.4499142169952393, 'validation/accuracy': 0.6169399619102478, 'validation/loss': 1.7016091346740723, 'validation/num_examples': 50000, 'test/accuracy': 0.4912000298500061, 'test/loss': 2.3572542667388916, 'test/num_examples': 10000, 'score': 20577.18582725525, 'total_duration': 21454.080466270447, 'accumulated_submission_time': 20577.18582725525, 'accumulated_eval_time': 875.2469525337219, 'accumulated_logging_time': 1.3917033672332764}
I0428 18:20:12.566704 139671371761408 logging_writer.py:48] [19101] accumulated_eval_time=875.246953, accumulated_logging_time=1.391703, accumulated_submission_time=20577.185827, global_step=19101, preemption_count=0, score=20577.185827, test/accuracy=0.491200, test/loss=2.357254, test/num_examples=10000, total_duration=21454.080466, train/accuracy=0.670937, train/loss=1.449914, validation/accuracy=0.616940, validation/loss=1.701609, validation/num_examples=50000
I0428 18:21:58.198130 139671363368704 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.8324771523475647, loss=3.1283602714538574
I0428 18:23:44.208794 139671371761408 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.8044285178184509, loss=3.2537193298339844
I0428 18:25:30.781199 139671363368704 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.7748192548751831, loss=3.2495579719543457
I0428 18:27:17.076187 139671371761408 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.8065691590309143, loss=3.1488351821899414
I0428 18:27:17.129272 139903503492928 spec.py:298] Evaluating on the training split.
I0428 18:27:25.092667 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 18:27:33.701423 139903503492928 spec.py:326] Evaluating on the test split.
I0428 18:27:35.413523 139903503492928 submission_runner.py:415] Time since start: 21896.95s, 	Step: 19501, 	{'train/accuracy': 0.6678515672683716, 'train/loss': 1.4874067306518555, 'validation/accuracy': 0.620419979095459, 'validation/loss': 1.719892144203186, 'validation/num_examples': 50000, 'test/accuracy': 0.4994000196456909, 'test/loss': 2.3544278144836426, 'test/num_examples': 10000, 'score': 21001.72945165634, 'total_duration': 21896.950417995453, 'accumulated_submission_time': 21001.72945165634, 'accumulated_eval_time': 893.5311057567596, 'accumulated_logging_time': 1.4282326698303223}
I0428 18:27:35.436524 139671363368704 logging_writer.py:48] [19501] accumulated_eval_time=893.531106, accumulated_logging_time=1.428233, accumulated_submission_time=21001.729452, global_step=19501, preemption_count=0, score=21001.729452, test/accuracy=0.499400, test/loss=2.354428, test/num_examples=10000, total_duration=21896.950418, train/accuracy=0.667852, train/loss=1.487407, validation/accuracy=0.620420, validation/loss=1.719892, validation/num_examples=50000
I0428 18:29:21.716619 139671371761408 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.8212812542915344, loss=4.955065727233887
I0428 18:31:08.742305 139671363368704 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.8696262836456299, loss=5.096660137176514
I0428 18:32:54.632140 139671371761408 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.7799323201179504, loss=3.0597920417785645
I0428 18:34:41.691867 139671363368704 logging_writer.py:48] [19900] global_step=19900, grad_norm=1.001471996307373, loss=4.968826770782471
I0428 18:34:41.754784 139903503492928 spec.py:298] Evaluating on the training split.
I0428 18:34:49.697764 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 18:34:58.360136 139903503492928 spec.py:326] Evaluating on the test split.
I0428 18:35:00.074066 139903503492928 submission_runner.py:415] Time since start: 22341.61s, 	Step: 19901, 	{'train/accuracy': 0.6683788895606995, 'train/loss': 1.4888917207717896, 'validation/accuracy': 0.6207399964332581, 'validation/loss': 1.6988160610198975, 'validation/num_examples': 50000, 'test/accuracy': 0.4978000223636627, 'test/loss': 2.343045473098755, 'test/num_examples': 10000, 'score': 21428.028529644012, 'total_duration': 22341.61098265648, 'accumulated_submission_time': 21428.028529644012, 'accumulated_eval_time': 911.8503241539001, 'accumulated_logging_time': 1.4646968841552734}
I0428 18:35:00.090785 139671371761408 logging_writer.py:48] [19901] accumulated_eval_time=911.850324, accumulated_logging_time=1.464697, accumulated_submission_time=21428.028530, global_step=19901, preemption_count=0, score=21428.028530, test/accuracy=0.497800, test/loss=2.343045, test/num_examples=10000, total_duration=22341.610983, train/accuracy=0.668379, train/loss=1.488892, validation/accuracy=0.620740, validation/loss=1.698816, validation/num_examples=50000
I0428 18:36:45.851522 139671363368704 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.7322905659675598, loss=3.04016375541687
I0428 18:38:32.254086 139671371761408 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.9170728325843811, loss=3.0411887168884277
I0428 18:40:17.861219 139671363368704 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.831940233707428, loss=3.172391891479492
I0428 18:42:04.290099 139671371761408 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.8105425834655762, loss=3.0529897212982178
I0428 18:42:04.341341 139903503492928 spec.py:298] Evaluating on the training split.
I0428 18:42:12.256386 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 18:42:20.942345 139903503492928 spec.py:326] Evaluating on the test split.
I0428 18:42:22.667233 139903503492928 submission_runner.py:415] Time since start: 22784.20s, 	Step: 20301, 	{'train/accuracy': 0.6885741949081421, 'train/loss': 1.3539657592773438, 'validation/accuracy': 0.6247199773788452, 'validation/loss': 1.6561819314956665, 'validation/num_examples': 50000, 'test/accuracy': 0.49790000915527344, 'test/loss': 2.3099851608276367, 'test/num_examples': 10000, 'score': 21852.260316848755, 'total_duration': 22784.20414686203, 'accumulated_submission_time': 21852.260316848755, 'accumulated_eval_time': 930.1761314868927, 'accumulated_logging_time': 1.4947741031646729}
I0428 18:42:22.683191 139671363368704 logging_writer.py:48] [20301] accumulated_eval_time=930.176131, accumulated_logging_time=1.494774, accumulated_submission_time=21852.260317, global_step=20301, preemption_count=0, score=21852.260317, test/accuracy=0.497900, test/loss=2.309985, test/num_examples=10000, total_duration=22784.204147, train/accuracy=0.688574, train/loss=1.353966, validation/accuracy=0.624720, validation/loss=1.656182, validation/num_examples=50000
I0428 18:44:08.664903 139671371761408 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.7548677921295166, loss=4.332453727722168
I0428 18:45:55.343543 139671363368704 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.9407146573066711, loss=5.093383312225342
I0428 18:47:41.522597 139671371761408 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.8420459628105164, loss=3.0981132984161377
I0428 18:49:27.678843 139671363368704 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.9135956764221191, loss=4.576245307922363
I0428 18:49:27.729179 139903503492928 spec.py:298] Evaluating on the training split.
I0428 18:49:35.656594 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 18:49:44.220010 139903503492928 spec.py:326] Evaluating on the test split.
I0428 18:49:45.934293 139903503492928 submission_runner.py:415] Time since start: 23227.47s, 	Step: 20701, 	{'train/accuracy': 0.6799218654632568, 'train/loss': 1.4225764274597168, 'validation/accuracy': 0.6275599598884583, 'validation/loss': 1.6653140783309937, 'validation/num_examples': 50000, 'test/accuracy': 0.5002000331878662, 'test/loss': 2.31603741645813, 'test/num_examples': 10000, 'score': 22277.28802895546, 'total_duration': 23227.47119450569, 'accumulated_submission_time': 22277.28802895546, 'accumulated_eval_time': 948.3811473846436, 'accumulated_logging_time': 1.5235581398010254}
I0428 18:49:45.953779 139671371761408 logging_writer.py:48] [20701] accumulated_eval_time=948.381147, accumulated_logging_time=1.523558, accumulated_submission_time=22277.288029, global_step=20701, preemption_count=0, score=22277.288029, test/accuracy=0.500200, test/loss=2.316037, test/num_examples=10000, total_duration=23227.471195, train/accuracy=0.679922, train/loss=1.422576, validation/accuracy=0.627560, validation/loss=1.665314, validation/num_examples=50000
I0428 18:51:33.230427 139671363368704 logging_writer.py:48] [20800] global_step=20800, grad_norm=1.1580030918121338, loss=3.0701160430908203
I0428 18:53:20.147993 139671371761408 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.7401449084281921, loss=3.1557295322418213
I0428 18:55:06.267154 139671363368704 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.8839666247367859, loss=4.720150470733643
I0428 18:56:46.034095 139903503492928 spec.py:298] Evaluating on the training split.
I0428 18:56:54.038634 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 18:57:02.597576 139903503492928 spec.py:326] Evaluating on the test split.
I0428 18:57:04.309927 139903503492928 submission_runner.py:415] Time since start: 23665.85s, 	Step: 21100, 	{'train/accuracy': 0.6833202838897705, 'train/loss': 1.410420298576355, 'validation/accuracy': 0.6351400017738342, 'validation/loss': 1.6420440673828125, 'validation/num_examples': 50000, 'test/accuracy': 0.508400022983551, 'test/loss': 2.2954564094543457, 'test/num_examples': 10000, 'score': 22697.34977579117, 'total_duration': 23665.846835136414, 'accumulated_submission_time': 22697.34977579117, 'accumulated_eval_time': 966.6569211483002, 'accumulated_logging_time': 1.55600905418396}
I0428 18:57:04.326996 139671371761408 logging_writer.py:48] [21100] accumulated_eval_time=966.656921, accumulated_logging_time=1.556009, accumulated_submission_time=22697.349776, global_step=21100, preemption_count=0, score=22697.349776, test/accuracy=0.508400, test/loss=2.295456, test/num_examples=10000, total_duration=23665.846835, train/accuracy=0.683320, train/loss=1.410420, validation/accuracy=0.635140, validation/loss=1.642044, validation/num_examples=50000
I0428 18:57:10.879911 139671363368704 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.828504204750061, loss=3.1399619579315186
I0428 18:58:57.389555 139671371761408 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.8173102140426636, loss=2.9726722240448
I0428 19:00:43.854946 139671363368704 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.9214533567428589, loss=3.1269710063934326
I0428 19:02:30.128345 139671371761408 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.7174928188323975, loss=3.7519121170043945
I0428 19:04:04.560750 139903503492928 spec.py:298] Evaluating on the training split.
I0428 19:04:12.512978 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 19:04:21.180001 139903503492928 spec.py:326] Evaluating on the test split.
I0428 19:04:22.879463 139903503492928 submission_runner.py:415] Time since start: 24104.42s, 	Step: 21492, 	{'train/accuracy': 0.6937695145606995, 'train/loss': 1.4141901731491089, 'validation/accuracy': 0.6278199553489685, 'validation/loss': 1.7047410011291504, 'validation/num_examples': 50000, 'test/accuracy': 0.5034000277519226, 'test/loss': 2.3582873344421387, 'test/num_examples': 10000, 'score': 23117.5638256073, 'total_duration': 24104.41635107994, 'accumulated_submission_time': 23117.5638256073, 'accumulated_eval_time': 984.9755582809448, 'accumulated_logging_time': 1.5873923301696777}
I0428 19:04:22.903537 139671363368704 logging_writer.py:48] [21492] accumulated_eval_time=984.975558, accumulated_logging_time=1.587392, accumulated_submission_time=23117.563826, global_step=21492, preemption_count=0, score=23117.563826, test/accuracy=0.503400, test/loss=2.358287, test/num_examples=10000, total_duration=24104.416351, train/accuracy=0.693770, train/loss=1.414190, validation/accuracy=0.627820, validation/loss=1.704741, validation/num_examples=50000
I0428 19:04:35.433301 139671371761408 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.8538249731063843, loss=3.146418809890747
I0428 19:06:21.502779 139671363368704 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.889209508895874, loss=3.0924811363220215
I0428 19:08:07.923373 139671371761408 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.8247232437133789, loss=3.0048584938049316
I0428 19:09:54.265599 139671363368704 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.7089739441871643, loss=4.076672077178955
I0428 19:11:23.702287 139903503492928 spec.py:298] Evaluating on the training split.
I0428 19:11:31.638417 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 19:11:40.456237 139903503492928 spec.py:326] Evaluating on the test split.
I0428 19:11:42.169420 139903503492928 submission_runner.py:415] Time since start: 24543.71s, 	Step: 21886, 	{'train/accuracy': 0.6940820217132568, 'train/loss': 1.3495880365371704, 'validation/accuracy': 0.6366400122642517, 'validation/loss': 1.6158816814422607, 'validation/num_examples': 50000, 'test/accuracy': 0.5078000426292419, 'test/loss': 2.2668209075927734, 'test/num_examples': 10000, 'score': 23538.34276175499, 'total_duration': 24543.706295967102, 'accumulated_submission_time': 23538.34276175499, 'accumulated_eval_time': 1003.4426016807556, 'accumulated_logging_time': 1.6258487701416016}
I0428 19:11:42.193778 139671371761408 logging_writer.py:48] [21886] accumulated_eval_time=1003.442602, accumulated_logging_time=1.625849, accumulated_submission_time=23538.342762, global_step=21886, preemption_count=0, score=23538.342762, test/accuracy=0.507800, test/loss=2.266821, test/num_examples=10000, total_duration=24543.706296, train/accuracy=0.694082, train/loss=1.349588, validation/accuracy=0.636640, validation/loss=1.615882, validation/num_examples=50000
I0428 19:11:59.246253 139671363368704 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.838932454586029, loss=3.0994834899902344
I0428 19:13:45.374617 139671371761408 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.8023133873939514, loss=3.1385161876678467
I0428 19:15:31.418529 139671363368704 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.6826041340827942, loss=3.552701473236084
I0428 19:17:17.355932 139671371761408 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.7710310816764832, loss=3.058624744415283
I0428 19:18:42.539116 139903503492928 spec.py:298] Evaluating on the training split.
I0428 19:18:50.481780 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 19:18:59.173602 139903503492928 spec.py:326] Evaluating on the test split.
I0428 19:19:00.901520 139903503492928 submission_runner.py:415] Time since start: 24982.44s, 	Step: 22281, 	{'train/accuracy': 0.6926562190055847, 'train/loss': 1.3622392416000366, 'validation/accuracy': 0.6378600001335144, 'validation/loss': 1.6067862510681152, 'validation/num_examples': 50000, 'test/accuracy': 0.5163000226020813, 'test/loss': 2.250131130218506, 'test/num_examples': 10000, 'score': 23958.668736696243, 'total_duration': 24982.438442230225, 'accumulated_submission_time': 23958.668736696243, 'accumulated_eval_time': 1021.8049738407135, 'accumulated_logging_time': 1.6641297340393066}
I0428 19:19:00.919672 139671363368704 logging_writer.py:48] [22281] accumulated_eval_time=1021.804974, accumulated_logging_time=1.664130, accumulated_submission_time=23958.668737, global_step=22281, preemption_count=0, score=23958.668737, test/accuracy=0.516300, test/loss=2.250131, test/num_examples=10000, total_duration=24982.438442, train/accuracy=0.692656, train/loss=1.362239, validation/accuracy=0.637860, validation/loss=1.606786, validation/num_examples=50000
I0428 19:19:21.783830 139671371761408 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.7697645425796509, loss=3.350883960723877
I0428 19:21:07.924833 139671363368704 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.8106939196586609, loss=4.283692836761475
I0428 19:22:54.722049 139671371761408 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.9721776247024536, loss=4.06719446182251
I0428 19:24:40.694563 139671363368704 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.7215304970741272, loss=3.2569971084594727
I0428 19:26:06.969539 139903503492928 spec.py:298] Evaluating on the training split.
I0428 19:26:14.880081 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 19:26:23.624850 139903503492928 spec.py:326] Evaluating on the test split.
I0428 19:26:25.347571 139903503492928 submission_runner.py:415] Time since start: 25426.88s, 	Step: 22681, 	{'train/accuracy': 0.6877734065055847, 'train/loss': 1.3627800941467285, 'validation/accuracy': 0.6381199955940247, 'validation/loss': 1.58297860622406, 'validation/num_examples': 50000, 'test/accuracy': 0.5169000029563904, 'test/loss': 2.2285635471343994, 'test/num_examples': 10000, 'score': 24384.69821548462, 'total_duration': 25426.884453058243, 'accumulated_submission_time': 24384.69821548462, 'accumulated_eval_time': 1040.1829235553741, 'accumulated_logging_time': 1.6971683502197266}
I0428 19:26:25.371625 139671371761408 logging_writer.py:48] [22681] accumulated_eval_time=1040.182924, accumulated_logging_time=1.697168, accumulated_submission_time=24384.698215, global_step=22681, preemption_count=0, score=24384.698215, test/accuracy=0.516900, test/loss=2.228564, test/num_examples=10000, total_duration=25426.884453, train/accuracy=0.687773, train/loss=1.362780, validation/accuracy=0.638120, validation/loss=1.582979, validation/num_examples=50000
I0428 19:26:47.199810 139671363368704 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.743354856967926, loss=3.3684451580047607
I0428 19:28:33.911067 139671371761408 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.7908640503883362, loss=3.65324330329895
I0428 19:30:21.204009 139671363368704 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.7825826406478882, loss=3.0950071811676025
I0428 19:32:07.204476 139671371761408 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.9335986375808716, loss=4.798128604888916
I0428 19:33:25.884363 139903503492928 spec.py:298] Evaluating on the training split.
I0428 19:33:33.847718 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 19:33:42.592450 139903503492928 spec.py:326] Evaluating on the test split.
I0428 19:33:44.319493 139903503492928 submission_runner.py:415] Time since start: 25865.86s, 	Step: 23080, 	{'train/accuracy': 0.7146288752555847, 'train/loss': 1.2157279253005981, 'validation/accuracy': 0.6473999619483948, 'validation/loss': 1.5290677547454834, 'validation/num_examples': 50000, 'test/accuracy': 0.517300009727478, 'test/loss': 2.1935038566589355, 'test/num_examples': 10000, 'score': 24805.191913604736, 'total_duration': 25865.85638976097, 'accumulated_submission_time': 24805.191913604736, 'accumulated_eval_time': 1058.6179785728455, 'accumulated_logging_time': 1.7346899509429932}
I0428 19:33:44.344305 139671363368704 logging_writer.py:48] [23080] accumulated_eval_time=1058.617979, accumulated_logging_time=1.734690, accumulated_submission_time=24805.191914, global_step=23080, preemption_count=0, score=24805.191914, test/accuracy=0.517300, test/loss=2.193504, test/num_examples=10000, total_duration=25865.856390, train/accuracy=0.714629, train/loss=1.215728, validation/accuracy=0.647400, validation/loss=1.529068, validation/num_examples=50000
I0428 19:34:12.196836 139671371761408 logging_writer.py:48] [23100] global_step=23100, grad_norm=1.0969674587249756, loss=2.913825035095215
I0428 19:35:58.464560 139671363368704 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.7922108769416809, loss=2.999419927597046
I0428 19:37:44.225752 139671371761408 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.8250465989112854, loss=3.0553207397460938
I0428 19:39:30.604890 139671363368704 logging_writer.py:48] [23400] global_step=23400, grad_norm=1.7353047132492065, loss=4.865254878997803
I0428 19:40:44.506762 139903503492928 spec.py:298] Evaluating on the training split.
I0428 19:40:52.409952 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 19:41:01.098808 139903503492928 spec.py:326] Evaluating on the test split.
I0428 19:41:02.811710 139903503492928 submission_runner.py:415] Time since start: 26304.35s, 	Step: 23474, 	{'train/accuracy': 0.7038476467132568, 'train/loss': 1.304925799369812, 'validation/accuracy': 0.6427199840545654, 'validation/loss': 1.5697730779647827, 'validation/num_examples': 50000, 'test/accuracy': 0.5149000287055969, 'test/loss': 2.2244274616241455, 'test/num_examples': 10000, 'score': 25225.334848165512, 'total_duration': 26304.34862613678, 'accumulated_submission_time': 25225.334848165512, 'accumulated_eval_time': 1076.9228863716125, 'accumulated_logging_time': 1.773622751235962}
I0428 19:41:02.829105 139671371761408 logging_writer.py:48] [23474] accumulated_eval_time=1076.922886, accumulated_logging_time=1.773623, accumulated_submission_time=25225.334848, global_step=23474, preemption_count=0, score=25225.334848, test/accuracy=0.514900, test/loss=2.224427, test/num_examples=10000, total_duration=26304.348626, train/accuracy=0.703848, train/loss=1.304926, validation/accuracy=0.642720, validation/loss=1.569773, validation/num_examples=50000
I0428 19:41:35.285280 139671363368704 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.8226456046104431, loss=3.378774642944336
I0428 19:43:21.379162 139671371761408 logging_writer.py:48] [23600] global_step=23600, grad_norm=1.3700886964797974, loss=4.674553871154785
I0428 19:45:07.590522 139671363368704 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.8015758395195007, loss=4.3153486251831055
I0428 19:46:54.027049 139671371761408 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.8060791492462158, loss=4.3931121826171875
I0428 19:48:03.118281 139903503492928 spec.py:298] Evaluating on the training split.
I0428 19:48:11.055095 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 19:48:19.713921 139903503492928 spec.py:326] Evaluating on the test split.
I0428 19:48:21.424559 139903503492928 submission_runner.py:415] Time since start: 26742.96s, 	Step: 23868, 	{'train/accuracy': 0.7015429735183716, 'train/loss': 1.3140352964401245, 'validation/accuracy': 0.6487199664115906, 'validation/loss': 1.5559242963790894, 'validation/num_examples': 50000, 'test/accuracy': 0.5182000398635864, 'test/loss': 2.1963918209075928, 'test/num_examples': 10000, 'score': 25645.605207443237, 'total_duration': 26742.961475610733, 'accumulated_submission_time': 25645.605207443237, 'accumulated_eval_time': 1095.229112625122, 'accumulated_logging_time': 1.8044366836547852}
I0428 19:48:21.443042 139671363368704 logging_writer.py:48] [23868] accumulated_eval_time=1095.229113, accumulated_logging_time=1.804437, accumulated_submission_time=25645.605207, global_step=23868, preemption_count=0, score=25645.605207, test/accuracy=0.518200, test/loss=2.196392, test/num_examples=10000, total_duration=26742.961476, train/accuracy=0.701543, train/loss=1.314035, validation/accuracy=0.648720, validation/loss=1.555924, validation/num_examples=50000
I0428 19:48:58.582238 139671371761408 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.9249369502067566, loss=3.8832859992980957
I0428 19:50:45.156863 139671363368704 logging_writer.py:48] [24000] global_step=24000, grad_norm=1.434249997138977, loss=4.9633708000183105
I0428 19:52:31.167545 139671371761408 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.8006643056869507, loss=3.0702028274536133
I0428 19:54:16.892738 139671363368704 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.9467482566833496, loss=2.9348247051239014
I0428 19:55:21.788723 139903503492928 spec.py:298] Evaluating on the training split.
I0428 19:55:29.900444 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 19:55:38.593860 139903503492928 spec.py:326] Evaluating on the test split.
I0428 19:55:40.301934 139903503492928 submission_runner.py:415] Time since start: 27181.84s, 	Step: 24263, 	{'train/accuracy': 0.7036523222923279, 'train/loss': 1.2732949256896973, 'validation/accuracy': 0.6514399647712708, 'validation/loss': 1.5141762495040894, 'validation/num_examples': 50000, 'test/accuracy': 0.5260000228881836, 'test/loss': 2.1605770587921143, 'test/num_examples': 10000, 'score': 26065.932987213135, 'total_duration': 27181.838849782944, 'accumulated_submission_time': 26065.932987213135, 'accumulated_eval_time': 1113.742267370224, 'accumulated_logging_time': 1.8355610370635986}
I0428 19:55:40.319002 139671371761408 logging_writer.py:48] [24263] accumulated_eval_time=1113.742267, accumulated_logging_time=1.835561, accumulated_submission_time=26065.932987, global_step=24263, preemption_count=0, score=26065.932987, test/accuracy=0.526000, test/loss=2.160577, test/num_examples=10000, total_duration=27181.838850, train/accuracy=0.703652, train/loss=1.273295, validation/accuracy=0.651440, validation/loss=1.514176, validation/num_examples=50000
I0428 19:56:21.812129 139671363368704 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.8597485423088074, loss=3.0143609046936035
I0428 19:58:08.451020 139671371761408 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.98287034034729, loss=2.8243002891540527
I0428 19:59:55.060382 139671363368704 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.7468295693397522, loss=3.347858190536499
I0428 20:01:40.879266 139671371761408 logging_writer.py:48] [24600] global_step=24600, grad_norm=1.0599547624588013, loss=4.811304569244385
I0428 20:02:44.223415 139903503492928 spec.py:298] Evaluating on the training split.
I0428 20:02:52.108513 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 20:03:00.726922 139903503492928 spec.py:326] Evaluating on the test split.
I0428 20:03:02.443895 139903503492928 submission_runner.py:415] Time since start: 27623.98s, 	Step: 24661, 	{'train/accuracy': 0.7214257717132568, 'train/loss': 1.2498676776885986, 'validation/accuracy': 0.6494799852371216, 'validation/loss': 1.550089955329895, 'validation/num_examples': 50000, 'test/accuracy': 0.52510005235672, 'test/loss': 2.1941280364990234, 'test/num_examples': 10000, 'score': 26489.82123684883, 'total_duration': 27623.980819940567, 'accumulated_submission_time': 26489.82123684883, 'accumulated_eval_time': 1131.9627180099487, 'accumulated_logging_time': 1.863340139389038}
I0428 20:03:02.462251 139671363368704 logging_writer.py:48] [24661] accumulated_eval_time=1131.962718, accumulated_logging_time=1.863340, accumulated_submission_time=26489.821237, global_step=24661, preemption_count=0, score=26489.821237, test/accuracy=0.525100, test/loss=2.194128, test/num_examples=10000, total_duration=27623.980820, train/accuracy=0.721426, train/loss=1.249868, validation/accuracy=0.649480, validation/loss=1.550090, validation/num_examples=50000
I0428 20:03:45.160496 139671371761408 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.823817789554596, loss=3.3586010932922363
I0428 20:05:31.211756 139671363368704 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.8531913161277771, loss=2.9125351905822754
I0428 20:07:17.356331 139671371761408 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.8843926787376404, loss=2.929245948791504
I0428 20:09:03.402325 139671363368704 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.8258327841758728, loss=3.3248162269592285
I0428 20:10:06.981476 139903503492928 spec.py:298] Evaluating on the training split.
I0428 20:10:14.888964 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 20:10:23.446635 139903503492928 spec.py:326] Evaluating on the test split.
I0428 20:10:25.163732 139903503492928 submission_runner.py:415] Time since start: 28066.70s, 	Step: 25061, 	{'train/accuracy': 0.7122656106948853, 'train/loss': 1.2646727561950684, 'validation/accuracy': 0.6521399617195129, 'validation/loss': 1.5378425121307373, 'validation/num_examples': 50000, 'test/accuracy': 0.5270000100135803, 'test/loss': 2.1722800731658936, 'test/num_examples': 10000, 'score': 26914.321694612503, 'total_duration': 28066.700620174408, 'accumulated_submission_time': 26914.321694612503, 'accumulated_eval_time': 1150.1448888778687, 'accumulated_logging_time': 1.895167350769043}
I0428 20:10:25.187353 139671371761408 logging_writer.py:48] [25061] accumulated_eval_time=1150.144889, accumulated_logging_time=1.895167, accumulated_submission_time=26914.321695, global_step=25061, preemption_count=0, score=26914.321695, test/accuracy=0.527000, test/loss=2.172280, test/num_examples=10000, total_duration=28066.700620, train/accuracy=0.712266, train/loss=1.264673, validation/accuracy=0.652140, validation/loss=1.537843, validation/num_examples=50000
I0428 20:11:08.253999 139671363368704 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.8582900166511536, loss=3.045748710632324
I0428 20:12:54.300194 139671371761408 logging_writer.py:48] [25200] global_step=25200, grad_norm=1.1611599922180176, loss=4.448347091674805
I0428 20:14:40.351773 139671363368704 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.8487288951873779, loss=3.0893378257751465
I0428 20:16:26.942284 139671371761408 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.8226915001869202, loss=2.980210781097412
I0428 20:17:30.593090 139903503492928 spec.py:298] Evaluating on the training split.
I0428 20:17:38.492739 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 20:17:47.196102 139903503492928 spec.py:326] Evaluating on the test split.
I0428 20:17:48.909312 139903503492928 submission_runner.py:415] Time since start: 28510.45s, 	Step: 25461, 	{'train/accuracy': 0.7045507431030273, 'train/loss': 1.3274132013320923, 'validation/accuracy': 0.6525200009346008, 'validation/loss': 1.5565452575683594, 'validation/num_examples': 50000, 'test/accuracy': 0.5306000113487244, 'test/loss': 2.1865217685699463, 'test/num_examples': 10000, 'score': 27339.70870256424, 'total_duration': 28510.446217536926, 'accumulated_submission_time': 27339.70870256424, 'accumulated_eval_time': 1168.461064338684, 'accumulated_logging_time': 1.9319839477539062}
I0428 20:17:48.927687 139671363368704 logging_writer.py:48] [25461] accumulated_eval_time=1168.461064, accumulated_logging_time=1.931984, accumulated_submission_time=27339.708703, global_step=25461, preemption_count=0, score=27339.708703, test/accuracy=0.530600, test/loss=2.186522, test/num_examples=10000, total_duration=28510.446218, train/accuracy=0.704551, train/loss=1.327413, validation/accuracy=0.652520, validation/loss=1.556545, validation/num_examples=50000
I0428 20:18:31.729015 139671371761408 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.8692672848701477, loss=2.947934150695801
I0428 20:20:19.069256 139671363368704 logging_writer.py:48] [25600] global_step=25600, grad_norm=1.172721266746521, loss=4.866302967071533
I0428 20:22:05.161661 139671371761408 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.8810585141181946, loss=2.9253690242767334
I0428 20:23:51.849770 139671363368704 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.9927457571029663, loss=3.036759853363037
I0428 20:24:49.166660 139903503492928 spec.py:298] Evaluating on the training split.
I0428 20:24:57.071961 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 20:25:05.806292 139903503492928 spec.py:326] Evaluating on the test split.
I0428 20:25:07.530690 139903503492928 submission_runner.py:415] Time since start: 28949.07s, 	Step: 25860, 	{'train/accuracy': 0.7433788776397705, 'train/loss': 1.1645514965057373, 'validation/accuracy': 0.6562599539756775, 'validation/loss': 1.5322163105010986, 'validation/num_examples': 50000, 'test/accuracy': 0.5349000096321106, 'test/loss': 2.161813497543335, 'test/num_examples': 10000, 'score': 27759.928587198257, 'total_duration': 28949.06757235527, 'accumulated_submission_time': 27759.928587198257, 'accumulated_eval_time': 1186.8250255584717, 'accumulated_logging_time': 1.9638986587524414}
I0428 20:25:07.559826 139671371761408 logging_writer.py:48] [25860] accumulated_eval_time=1186.825026, accumulated_logging_time=1.963899, accumulated_submission_time=27759.928587, global_step=25860, preemption_count=0, score=27759.928587, test/accuracy=0.534900, test/loss=2.161813, test/num_examples=10000, total_duration=28949.067572, train/accuracy=0.743379, train/loss=1.164551, validation/accuracy=0.656260, validation/loss=1.532216, validation/num_examples=50000
I0428 20:25:56.486874 139671363368704 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.8659995794296265, loss=3.967822551727295
I0428 20:27:42.427443 139671371761408 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.9493883848190308, loss=4.575107097625732
I0428 20:29:29.700999 139671363368704 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.8451031446456909, loss=3.074756383895874
I0428 20:31:15.625663 139671371761408 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.885357141494751, loss=2.851949453353882
I0428 20:32:08.102116 139903503492928 spec.py:298] Evaluating on the training split.
I0428 20:32:15.991595 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 20:32:24.727605 139903503492928 spec.py:326] Evaluating on the test split.
I0428 20:32:26.462209 139903503492928 submission_runner.py:415] Time since start: 29388.00s, 	Step: 26254, 	{'train/accuracy': 0.720703125, 'train/loss': 1.219651222229004, 'validation/accuracy': 0.6569600105285645, 'validation/loss': 1.4992725849151611, 'validation/num_examples': 50000, 'test/accuracy': 0.5332000255584717, 'test/loss': 2.134916305541992, 'test/num_examples': 10000, 'score': 28180.452605962753, 'total_duration': 29387.999109745026, 'accumulated_submission_time': 28180.452605962753, 'accumulated_eval_time': 1205.18505525589, 'accumulated_logging_time': 2.005889415740967}
I0428 20:32:26.487283 139671363368704 logging_writer.py:48] [26254] accumulated_eval_time=1205.185055, accumulated_logging_time=2.005889, accumulated_submission_time=28180.452606, global_step=26254, preemption_count=0, score=28180.452606, test/accuracy=0.533200, test/loss=2.134916, test/num_examples=10000, total_duration=29387.999110, train/accuracy=0.720703, train/loss=1.219651, validation/accuracy=0.656960, validation/loss=1.499273, validation/num_examples=50000
I0428 20:33:20.256857 139671371761408 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.874553918838501, loss=2.895385503768921
I0428 20:35:06.993918 139671363368704 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.9362649321556091, loss=2.800485372543335
I0428 20:36:53.632560 139671371761408 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.820255696773529, loss=2.8539953231811523
I0428 20:38:40.041120 139671363368704 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.8345704674720764, loss=3.103785514831543
I0428 20:39:27.103851 139903503492928 spec.py:298] Evaluating on the training split.
I0428 20:39:35.022665 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 20:39:43.802278 139903503492928 spec.py:326] Evaluating on the test split.
I0428 20:39:45.526983 139903503492928 submission_runner.py:415] Time since start: 29827.06s, 	Step: 26647, 	{'train/accuracy': 0.713183581829071, 'train/loss': 1.2920280694961548, 'validation/accuracy': 0.6542800068855286, 'validation/loss': 1.5446299314498901, 'validation/num_examples': 50000, 'test/accuracy': 0.5312000513076782, 'test/loss': 2.1694157123565674, 'test/num_examples': 10000, 'score': 28601.04886651039, 'total_duration': 29827.06386232376, 'accumulated_submission_time': 28601.04886651039, 'accumulated_eval_time': 1223.608095407486, 'accumulated_logging_time': 2.0457589626312256}
I0428 20:39:45.553526 139671371761408 logging_writer.py:48] [26647] accumulated_eval_time=1223.608095, accumulated_logging_time=2.045759, accumulated_submission_time=28601.048867, global_step=26647, preemption_count=0, score=28601.048867, test/accuracy=0.531200, test/loss=2.169416, test/num_examples=10000, total_duration=29827.063862, train/accuracy=0.713184, train/loss=1.292028, validation/accuracy=0.654280, validation/loss=1.544630, validation/num_examples=50000
I0428 20:40:44.796950 139671363368704 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.7855565547943115, loss=3.5848493576049805
I0428 20:42:31.423832 139671371761408 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.8281151652336121, loss=2.871514081954956
I0428 20:44:17.312901 139671363368704 logging_writer.py:48] [26900] global_step=26900, grad_norm=1.1859993934631348, loss=4.886161804199219
I0428 20:46:03.033517 139671371761408 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.8649049997329712, loss=2.853726387023926
I0428 20:46:45.691783 139903503492928 spec.py:298] Evaluating on the training split.
I0428 20:46:53.562819 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 20:47:02.100338 139903503492928 spec.py:326] Evaluating on the test split.
I0428 20:47:03.813155 139903503492928 submission_runner.py:415] Time since start: 30265.35s, 	Step: 27041, 	{'train/accuracy': 0.7154101133346558, 'train/loss': 1.2688331604003906, 'validation/accuracy': 0.6618199944496155, 'validation/loss': 1.5109143257141113, 'validation/num_examples': 50000, 'test/accuracy': 0.5297999978065491, 'test/loss': 2.1646547317504883, 'test/num_examples': 10000, 'score': 29021.167956113815, 'total_duration': 30265.350011110306, 'accumulated_submission_time': 29021.167956113815, 'accumulated_eval_time': 1241.7293515205383, 'accumulated_logging_time': 2.0861716270446777}
I0428 20:47:03.832480 139671363368704 logging_writer.py:48] [27041] accumulated_eval_time=1241.729352, accumulated_logging_time=2.086172, accumulated_submission_time=29021.167956, global_step=27041, preemption_count=0, score=29021.167956, test/accuracy=0.529800, test/loss=2.164655, test/num_examples=10000, total_duration=30265.350011, train/accuracy=0.715410, train/loss=1.268833, validation/accuracy=0.661820, validation/loss=1.510914, validation/num_examples=50000
I0428 20:48:07.637040 139671371761408 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.7546535134315491, loss=3.372939109802246
I0428 20:49:54.703251 139671363368704 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.8197486400604248, loss=3.6787312030792236
I0428 20:51:41.253419 139671371761408 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.9041001200675964, loss=4.465155601501465
I0428 20:53:28.628861 139671363368704 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.9509662985801697, loss=3.3460817337036133
I0428 20:54:04.187076 139903503492928 spec.py:298] Evaluating on the training split.
I0428 20:54:12.233628 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 20:54:20.865999 139903503492928 spec.py:326] Evaluating on the test split.
I0428 20:54:22.582077 139903503492928 submission_runner.py:415] Time since start: 30704.12s, 	Step: 27439, 	{'train/accuracy': 0.733691394329071, 'train/loss': 1.1567423343658447, 'validation/accuracy': 0.659060001373291, 'validation/loss': 1.487488031387329, 'validation/num_examples': 50000, 'test/accuracy': 0.5325000286102295, 'test/loss': 2.1341910362243652, 'test/num_examples': 10000, 'score': 29441.50515937805, 'total_duration': 30704.11900115013, 'accumulated_submission_time': 29441.50515937805, 'accumulated_eval_time': 1260.1243057250977, 'accumulated_logging_time': 2.1173675060272217}
I0428 20:54:22.601004 139671371761408 logging_writer.py:48] [27439] accumulated_eval_time=1260.124306, accumulated_logging_time=2.117368, accumulated_submission_time=29441.505159, global_step=27439, preemption_count=0, score=29441.505159, test/accuracy=0.532500, test/loss=2.134191, test/num_examples=10000, total_duration=30704.119001, train/accuracy=0.733691, train/loss=1.156742, validation/accuracy=0.659060, validation/loss=1.487488, validation/num_examples=50000
I0428 20:55:33.729960 139671363368704 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.8279449343681335, loss=2.928732395172119
I0428 20:57:20.696039 139671371761408 logging_writer.py:48] [27600] global_step=27600, grad_norm=1.268685221672058, loss=4.613901615142822
I0428 20:59:07.318122 139671363368704 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.8451134562492371, loss=3.3144524097442627
I0428 21:00:54.460117 139671371761408 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.8594532012939453, loss=3.76088809967041
I0428 21:01:22.958668 139903503492928 spec.py:298] Evaluating on the training split.
I0428 21:01:30.913451 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 21:01:39.598248 139903503492928 spec.py:326] Evaluating on the test split.
I0428 21:01:41.323008 139903503492928 submission_runner.py:415] Time since start: 31142.86s, 	Step: 27830, 	{'train/accuracy': 0.726757824420929, 'train/loss': 1.2136718034744263, 'validation/accuracy': 0.6632199883460999, 'validation/loss': 1.488201379776001, 'validation/num_examples': 50000, 'test/accuracy': 0.5342000126838684, 'test/loss': 2.1213691234588623, 'test/num_examples': 10000, 'score': 29861.84357905388, 'total_duration': 31142.85990834236, 'accumulated_submission_time': 29861.84357905388, 'accumulated_eval_time': 1278.488567829132, 'accumulated_logging_time': 2.1501893997192383}
I0428 21:01:41.348567 139671363368704 logging_writer.py:48] [27830] accumulated_eval_time=1278.488568, accumulated_logging_time=2.150189, accumulated_submission_time=29861.843579, global_step=27830, preemption_count=0, score=29861.843579, test/accuracy=0.534200, test/loss=2.121369, test/num_examples=10000, total_duration=31142.859908, train/accuracy=0.726758, train/loss=1.213672, validation/accuracy=0.663220, validation/loss=1.488201, validation/num_examples=50000
I0428 21:02:59.562122 139671371761408 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.8339848518371582, loss=3.2759625911712646
I0428 21:04:39.468651 139903503492928 spec.py:298] Evaluating on the training split.
I0428 21:04:47.366070 139903503492928 spec.py:310] Evaluating on the validation split.
I0428 21:04:55.999801 139903503492928 spec.py:326] Evaluating on the test split.
I0428 21:04:57.725923 139903503492928 submission_runner.py:415] Time since start: 31339.26s, 	Step: 28000, 	{'train/accuracy': 0.7230077981948853, 'train/loss': 1.2427459955215454, 'validation/accuracy': 0.6633999943733215, 'validation/loss': 1.5126250982284546, 'validation/num_examples': 50000, 'test/accuracy': 0.5384000539779663, 'test/loss': 2.140953540802002, 'test/num_examples': 10000, 'score': 30039.94752430916, 'total_duration': 31339.262818336487, 'accumulated_submission_time': 30039.94752430916, 'accumulated_eval_time': 1296.7457683086395, 'accumulated_logging_time': 2.189225912094116}
I0428 21:04:57.753823 139671363368704 logging_writer.py:48] [28000] accumulated_eval_time=1296.745768, accumulated_logging_time=2.189226, accumulated_submission_time=30039.947524, global_step=28000, preemption_count=0, score=30039.947524, test/accuracy=0.538400, test/loss=2.140954, test/num_examples=10000, total_duration=31339.262818, train/accuracy=0.723008, train/loss=1.242746, validation/accuracy=0.663400, validation/loss=1.512625, validation/num_examples=50000
I0428 21:04:57.790016 139671371761408 logging_writer.py:48] [28000] global_step=28000, preemption_count=0, score=30039.947524
I0428 21:04:59.925563 139903503492928 checkpoints.py:356] Saving checkpoint at step: 28000
I0428 21:05:04.672343 139903503492928 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_fancy/timing_shampoo/imagenet_vit_jax/trial_1/checkpoint_28000
I0428 21:05:04.774563 139903503492928 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_fancy/timing_shampoo/imagenet_vit_jax/trial_1/checkpoint_28000.
I0428 21:05:06.124923 139903503492928 submission_runner.py:578] Tuning trial 1/1
I0428 21:05:06.125159 139903503492928 submission_runner.py:579] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.07758862577375368, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0428 21:05:06.160951 139903503492928 submission_runner.py:580] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0008984374580904841, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 295.23993730545044, 'total_duration': 347.46252036094666, 'accumulated_submission_time': 295.23993730545044, 'accumulated_eval_time': 52.222418546676636, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (131, {'train/accuracy': 0.004277343861758709, 'train/loss': 6.797806739807129, 'validation/accuracy': 0.003719999920576811, 'validation/loss': 6.8065948486328125, 'validation/num_examples': 50000, 'test/accuracy': 0.003900000127032399, 'test/loss': 6.817415714263916, 'test/num_examples': 10000, 'score': 715.516547203064, 'total_duration': 783.164742231369, 'accumulated_submission_time': 715.516547203064, 'accumulated_eval_time': 67.62083768844604, 'accumulated_logging_time': 0.025347471237182617, 'global_step': 131, 'preemption_count': 0}), (556, {'train/accuracy': 0.02597656100988388, 'train/loss': 6.262216567993164, 'validation/accuracy': 0.02393999882042408, 'validation/loss': 6.279642105102539, 'validation/num_examples': 50000, 'test/accuracy': 0.018200000748038292, 'test/loss': 6.336015701293945, 'test/num_examples': 10000, 'score': 1135.677639722824, 'total_duration': 1218.6672382354736, 'accumulated_submission_time': 1135.677639722824, 'accumulated_eval_time': 82.9310073852539, 'accumulated_logging_time': 0.05135703086853027, 'global_step': 556, 'preemption_count': 0}), (973, {'train/accuracy': 0.051738280802965164, 'train/loss': 5.752218723297119, 'validation/accuracy': 0.04989999905228615, 'validation/loss': 5.77405309677124, 'validation/num_examples': 50000, 'test/accuracy': 0.03880000114440918, 'test/loss': 5.903034210205078, 'test/num_examples': 10000, 'score': 1555.9941320419312, 'total_duration': 1654.2037448883057, 'accumulated_submission_time': 1555.9941320419312, 'accumulated_eval_time': 98.11801266670227, 'accumulated_logging_time': 0.07878470420837402, 'global_step': 973, 'preemption_count': 0}), (1389, {'train/accuracy': 0.07619140297174454, 'train/loss': 5.402970314025879, 'validation/accuracy': 0.07109999656677246, 'validation/loss': 5.432634353637695, 'validation/num_examples': 50000, 'test/accuracy': 0.055400002747774124, 'test/loss': 5.610576629638672, 'test/num_examples': 10000, 'score': 1976.4876470565796, 'total_duration': 2089.880674600601, 'accumulated_submission_time': 1976.4876470565796, 'accumulated_eval_time': 113.26643872261047, 'accumulated_logging_time': 0.1085042953491211, 'global_step': 1389, 'preemption_count': 0}), (1801, {'train/accuracy': 0.10039062052965164, 'train/loss': 5.088702201843262, 'validation/accuracy': 0.09253999590873718, 'validation/loss': 5.141936302185059, 'validation/num_examples': 50000, 'test/accuracy': 0.07150000333786011, 'test/loss': 5.375046253204346, 'test/num_examples': 10000, 'score': 2397.075027704239, 'total_duration': 2525.7037451267242, 'accumulated_submission_time': 2397.075027704239, 'accumulated_eval_time': 128.46760249137878, 'accumulated_logging_time': 0.13761544227600098, 'global_step': 1801, 'preemption_count': 0}), (2221, {'train/accuracy': 0.13701172173023224, 'train/loss': 4.738317012786865, 'validation/accuracy': 0.12814000248908997, 'validation/loss': 4.799259185791016, 'validation/num_examples': 50000, 'test/accuracy': 0.09540000557899475, 'test/loss': 5.067623138427734, 'test/num_examples': 10000, 'score': 2823.1320683956146, 'total_duration': 2967.1799783706665, 'accumulated_submission_time': 2823.1320683956146, 'accumulated_eval_time': 143.85363674163818, 'accumulated_logging_time': 0.16557860374450684, 'global_step': 2221, 'preemption_count': 0}), (2639, {'train/accuracy': 0.18544921278953552, 'train/loss': 4.404040336608887, 'validation/accuracy': 0.1682399958372116, 'validation/loss': 4.49139404296875, 'validation/num_examples': 50000, 'test/accuracy': 0.12270000576972961, 'test/loss': 4.81296443939209, 'test/num_examples': 10000, 'score': 3243.5654950141907, 'total_duration': 3402.9192757606506, 'accumulated_submission_time': 3243.5654950141907, 'accumulated_eval_time': 159.12579607963562, 'accumulated_logging_time': 0.19392704963684082, 'global_step': 2639, 'preemption_count': 0}), (3052, {'train/accuracy': 0.2240038961172104, 'train/loss': 4.072768211364746, 'validation/accuracy': 0.20075999200344086, 'validation/loss': 4.200099468231201, 'validation/num_examples': 50000, 'test/accuracy': 0.15600000321865082, 'test/loss': 4.574591636657715, 'test/num_examples': 10000, 'score': 3663.811623096466, 'total_duration': 3838.4438993930817, 'accumulated_submission_time': 3663.811623096466, 'accumulated_eval_time': 174.37390851974487, 'accumulated_logging_time': 0.21916627883911133, 'global_step': 3052, 'preemption_count': 0}), (3465, {'train/accuracy': 0.2492968738079071, 'train/loss': 3.8584694862365723, 'validation/accuracy': 0.2280000001192093, 'validation/loss': 3.9765539169311523, 'validation/num_examples': 50000, 'test/accuracy': 0.1712000072002411, 'test/loss': 4.402194499969482, 'test/num_examples': 10000, 'score': 4084.037281513214, 'total_duration': 4273.972116470337, 'accumulated_submission_time': 4084.037281513214, 'accumulated_eval_time': 189.64336466789246, 'accumulated_logging_time': 0.24701333045959473, 'global_step': 3465, 'preemption_count': 0}), (3881, {'train/accuracy': 0.27314451336860657, 'train/loss': 3.6525137424468994, 'validation/accuracy': 0.255840003490448, 'validation/loss': 3.7469425201416016, 'validation/num_examples': 50000, 'test/accuracy': 0.19100001454353333, 'test/loss': 4.195384502410889, 'test/num_examples': 10000, 'score': 4506.287321090698, 'total_duration': 4711.534224748611, 'accumulated_submission_time': 4506.287321090698, 'accumulated_eval_time': 204.92239952087402, 'accumulated_logging_time': 0.274822473526001, 'global_step': 3881, 'preemption_count': 0}), (4293, {'train/accuracy': 0.30818358063697815, 'train/loss': 3.4497087001800537, 'validation/accuracy': 0.28105998039245605, 'validation/loss': 3.572171449661255, 'validation/num_examples': 50000, 'test/accuracy': 0.21580001711845398, 'test/loss': 4.046998023986816, 'test/num_examples': 10000, 'score': 4926.530014514923, 'total_duration': 5147.499765634537, 'accumulated_submission_time': 4926.530014514923, 'accumulated_eval_time': 220.61096239089966, 'accumulated_logging_time': 0.3038480281829834, 'global_step': 4293, 'preemption_count': 0}), (4706, {'train/accuracy': 0.33128905296325684, 'train/loss': 3.3321714401245117, 'validation/accuracy': 0.3010999858379364, 'validation/loss': 3.488948345184326, 'validation/num_examples': 50000, 'test/accuracy': 0.2290000170469284, 'test/loss': 3.9732789993286133, 'test/num_examples': 10000, 'score': 5347.467670679092, 'total_duration': 5584.49915599823, 'accumulated_submission_time': 5347.467670679092, 'accumulated_eval_time': 236.64039492607117, 'accumulated_logging_time': 0.33097171783447266, 'global_step': 4706, 'preemption_count': 0}), (5119, {'train/accuracy': 0.35115233063697815, 'train/loss': 3.1426680088043213, 'validation/accuracy': 0.3225799798965454, 'validation/loss': 3.290813684463501, 'validation/num_examples': 50000, 'test/accuracy': 0.24890001118183136, 'test/loss': 3.8148205280303955, 'test/num_examples': 10000, 'score': 5768.052061319351, 'total_duration': 6020.970591783524, 'accumulated_submission_time': 5768.052061319351, 'accumulated_eval_time': 252.49135041236877, 'accumulated_logging_time': 0.36170458793640137, 'global_step': 5119, 'preemption_count': 0}), (5522, {'train/accuracy': 0.37128904461860657, 'train/loss': 3.038233518600464, 'validation/accuracy': 0.34147998690605164, 'validation/loss': 3.1798148155212402, 'validation/num_examples': 50000, 'test/accuracy': 0.2648000121116638, 'test/loss': 3.71653151512146, 'test/num_examples': 10000, 'score': 6188.138451099396, 'total_duration': 6456.855275392532, 'accumulated_submission_time': 6188.138451099396, 'accumulated_eval_time': 268.2585060596466, 'accumulated_logging_time': 0.3876798152923584, 'global_step': 5522, 'preemption_count': 0}), (5928, {'train/accuracy': 0.39765623211860657, 'train/loss': 2.918809413909912, 'validation/accuracy': 0.3563399910926819, 'validation/loss': 3.1231062412261963, 'validation/num_examples': 50000, 'test/accuracy': 0.2629000246524811, 'test/loss': 3.682025909423828, 'test/num_examples': 10000, 'score': 6608.802738666534, 'total_duration': 6893.263090372086, 'accumulated_submission_time': 6608.802738666534, 'accumulated_eval_time': 283.96515703201294, 'accumulated_logging_time': 0.4193258285522461, 'global_step': 5928, 'preemption_count': 0}), (6331, {'train/accuracy': 0.39130857586860657, 'train/loss': 2.9234819412231445, 'validation/accuracy': 0.3583199977874756, 'validation/loss': 3.0890860557556152, 'validation/num_examples': 50000, 'test/accuracy': 0.2734000086784363, 'test/loss': 3.64874005317688, 'test/num_examples': 10000, 'score': 7029.150061845779, 'total_duration': 7329.423683166504, 'accumulated_submission_time': 7029.150061845779, 'accumulated_eval_time': 299.7415020465851, 'accumulated_logging_time': 0.45100998878479004, 'global_step': 6331, 'preemption_count': 0}), (6731, {'train/accuracy': 0.4015820324420929, 'train/loss': 2.8508877754211426, 'validation/accuracy': 0.37351998686790466, 'validation/loss': 2.9977729320526123, 'validation/num_examples': 50000, 'test/accuracy': 0.289000004529953, 'test/loss': 3.563725233078003, 'test/num_examples': 10000, 'score': 7449.329925060272, 'total_duration': 7765.377031326294, 'accumulated_submission_time': 7449.329925060272, 'accumulated_eval_time': 315.48260521888733, 'accumulated_logging_time': 0.47809457778930664, 'global_step': 6731, 'preemption_count': 0}), (7136, {'train/accuracy': 0.4229491949081421, 'train/loss': 2.7149205207824707, 'validation/accuracy': 0.3876599967479706, 'validation/loss': 2.8770227432250977, 'validation/num_examples': 50000, 'test/accuracy': 0.29490000009536743, 'test/loss': 3.4742774963378906, 'test/num_examples': 10000, 'score': 7869.728478431702, 'total_duration': 8201.952518463135, 'accumulated_submission_time': 7869.728478431702, 'accumulated_eval_time': 331.62850546836853, 'accumulated_logging_time': 0.504000186920166, 'global_step': 7136, 'preemption_count': 0}), (7532, {'train/accuracy': 0.4313281178474426, 'train/loss': 2.7128753662109375, 'validation/accuracy': 0.39980000257492065, 'validation/loss': 2.8735580444335938, 'validation/num_examples': 50000, 'test/accuracy': 0.3076000213623047, 'test/loss': 3.450944423675537, 'test/num_examples': 10000, 'score': 8290.292822122574, 'total_duration': 8639.413896799088, 'accumulated_submission_time': 8290.292822122574, 'accumulated_eval_time': 348.48392057418823, 'accumulated_logging_time': 0.5402426719665527, 'global_step': 7532, 'preemption_count': 0}), (7932, {'train/accuracy': 0.43681639432907104, 'train/loss': 2.652195692062378, 'validation/accuracy': 0.4043799936771393, 'validation/loss': 2.825620651245117, 'validation/num_examples': 50000, 'test/accuracy': 0.3132000267505646, 'test/loss': 3.4030473232269287, 'test/num_examples': 10000, 'score': 8710.311620235443, 'total_duration': 9076.757446289062, 'accumulated_submission_time': 8710.311620235443, 'accumulated_eval_time': 365.7761573791504, 'accumulated_logging_time': 0.5674097537994385, 'global_step': 7932, 'preemption_count': 0}), (8330, {'train/accuracy': 0.4400585889816284, 'train/loss': 2.609130382537842, 'validation/accuracy': 0.4103599786758423, 'validation/loss': 2.7594637870788574, 'validation/num_examples': 50000, 'test/accuracy': 0.3111000061035156, 'test/loss': 3.361201047897339, 'test/num_examples': 10000, 'score': 9130.695872545242, 'total_duration': 9515.154428958893, 'accumulated_submission_time': 9130.695872545242, 'accumulated_eval_time': 383.7556371688843, 'accumulated_logging_time': 0.5953879356384277, 'global_step': 8330, 'preemption_count': 0}), (8727, {'train/accuracy': 0.4756835699081421, 'train/loss': 2.4381632804870605, 'validation/accuracy': 0.4244999885559082, 'validation/loss': 2.7078731060028076, 'validation/num_examples': 50000, 'test/accuracy': 0.3207000195980072, 'test/loss': 3.3253490924835205, 'test/num_examples': 10000, 'score': 9551.277529239655, 'total_duration': 9953.327883958817, 'accumulated_submission_time': 9551.277529239655, 'accumulated_eval_time': 401.3123371601105, 'accumulated_logging_time': 0.6252126693725586, 'global_step': 8727, 'preemption_count': 0}), (9121, {'train/accuracy': 0.46552732586860657, 'train/loss': 2.5152130126953125, 'validation/accuracy': 0.42479997873306274, 'validation/loss': 2.7100131511688232, 'validation/num_examples': 50000, 'test/accuracy': 0.32610002160072327, 'test/loss': 3.3012638092041016, 'test/num_examples': 10000, 'score': 9971.379585504532, 'total_duration': 10391.042766809464, 'accumulated_submission_time': 9971.379585504532, 'accumulated_eval_time': 418.8867988586426, 'accumulated_logging_time': 0.6579458713531494, 'global_step': 9121, 'preemption_count': 0}), (9521, {'train/accuracy': 0.47398436069488525, 'train/loss': 2.4670724868774414, 'validation/accuracy': 0.43873998522758484, 'validation/loss': 2.6311655044555664, 'validation/num_examples': 50000, 'test/accuracy': 0.34150001406669617, 'test/loss': 3.2237355709075928, 'test/num_examples': 10000, 'score': 10396.878695726395, 'total_duration': 10834.508744955063, 'accumulated_submission_time': 10396.878695726395, 'accumulated_eval_time': 436.8132598400116, 'accumulated_logging_time': 0.692777156829834, 'global_step': 9521, 'preemption_count': 0}), (9921, {'train/accuracy': 0.4839257597923279, 'train/loss': 2.3659372329711914, 'validation/accuracy': 0.4550800025463104, 'validation/loss': 2.5185301303863525, 'validation/num_examples': 50000, 'test/accuracy': 0.3468000292778015, 'test/loss': 3.153414487838745, 'test/num_examples': 10000, 'score': 10821.906108856201, 'total_duration': 11277.738247871399, 'accumulated_submission_time': 10821.906108856201, 'accumulated_eval_time': 454.98109769821167, 'accumulated_logging_time': 0.7215988636016846, 'global_step': 9921, 'preemption_count': 0}), (10321, {'train/accuracy': 0.5147265791893005, 'train/loss': 2.2110495567321777, 'validation/accuracy': 0.4705999791622162, 'validation/loss': 2.431706190109253, 'validation/num_examples': 50000, 'test/accuracy': 0.36830002069473267, 'test/loss': 3.027301549911499, 'test/num_examples': 10000, 'score': 11247.945413351059, 'total_duration': 11721.952479839325, 'accumulated_submission_time': 11247.945413351059, 'accumulated_eval_time': 473.1199595928192, 'accumulated_logging_time': 0.7521257400512695, 'global_step': 10321, 'preemption_count': 0}), (10721, {'train/accuracy': 0.5159375071525574, 'train/loss': 2.2091686725616455, 'validation/accuracy': 0.4818999767303467, 'validation/loss': 2.387497663497925, 'validation/num_examples': 50000, 'test/accuracy': 0.3712000250816345, 'test/loss': 3.0307586193084717, 'test/num_examples': 10000, 'score': 11674.032290697098, 'total_duration': 12166.237461090088, 'accumulated_submission_time': 11674.032290697098, 'accumulated_eval_time': 491.2924301624298, 'accumulated_logging_time': 0.7723338603973389, 'global_step': 10721, 'preemption_count': 0}), (11121, {'train/accuracy': 0.5235351324081421, 'train/loss': 2.1831657886505127, 'validation/accuracy': 0.4909600019454956, 'validation/loss': 2.3377301692962646, 'validation/num_examples': 50000, 'test/accuracy': 0.387800008058548, 'test/loss': 2.9446089267730713, 'test/num_examples': 10000, 'score': 12100.160240888596, 'total_duration': 12610.60964179039, 'accumulated_submission_time': 12100.160240888596, 'accumulated_eval_time': 509.51124691963196, 'accumulated_logging_time': 0.7922308444976807, 'global_step': 11121, 'preemption_count': 0}), (11521, {'train/accuracy': 0.5712109208106995, 'train/loss': 1.9663407802581787, 'validation/accuracy': 0.5010200142860413, 'validation/loss': 2.2908246517181396, 'validation/num_examples': 50000, 'test/accuracy': 0.39000001549720764, 'test/loss': 2.9200243949890137, 'test/num_examples': 10000, 'score': 12524.595651865005, 'total_duration': 13053.322176933289, 'accumulated_submission_time': 12524.595651865005, 'accumulated_eval_time': 527.7541630268097, 'accumulated_logging_time': 0.8210840225219727, 'global_step': 11521, 'preemption_count': 0}), (11921, {'train/accuracy': 0.5531249642372131, 'train/loss': 2.044267177581787, 'validation/accuracy': 0.5115000009536743, 'validation/loss': 2.25663685798645, 'validation/num_examples': 50000, 'test/accuracy': 0.39250001311302185, 'test/loss': 2.8767056465148926, 'test/num_examples': 10000, 'score': 12948.47294473648, 'total_duration': 13495.455977916718, 'accumulated_submission_time': 12948.47294473648, 'accumulated_eval_time': 545.98548412323, 'accumulated_logging_time': 0.8408727645874023, 'global_step': 11921, 'preemption_count': 0}), (12321, {'train/accuracy': 0.5609179735183716, 'train/loss': 1.9938178062438965, 'validation/accuracy': 0.5188400149345398, 'validation/loss': 2.1853928565979004, 'validation/num_examples': 50000, 'test/accuracy': 0.40890002250671387, 'test/loss': 2.809438705444336, 'test/num_examples': 10000, 'score': 13374.702414751053, 'total_duration': 13940.055477619171, 'accumulated_submission_time': 13374.702414751053, 'accumulated_eval_time': 564.3227257728577, 'accumulated_logging_time': 0.8680617809295654, 'global_step': 12321, 'preemption_count': 0}), (12721, {'train/accuracy': 0.570019543170929, 'train/loss': 1.9629398584365845, 'validation/accuracy': 0.5336799621582031, 'validation/loss': 2.123461961746216, 'validation/num_examples': 50000, 'test/accuracy': 0.4132000207901001, 'test/loss': 2.7619576454162598, 'test/num_examples': 10000, 'score': 13800.920033931732, 'total_duration': 14384.547704696655, 'accumulated_submission_time': 13800.920033931732, 'accumulated_eval_time': 582.5632865428925, 'accumulated_logging_time': 0.8966207504272461, 'global_step': 12721, 'preemption_count': 0}), (13121, {'train/accuracy': 0.590136706829071, 'train/loss': 1.8529216051101685, 'validation/accuracy': 0.5370599627494812, 'validation/loss': 2.1021406650543213, 'validation/num_examples': 50000, 'test/accuracy': 0.42270001769065857, 'test/loss': 2.7279887199401855, 'test/num_examples': 10000, 'score': 14225.474731206894, 'total_duration': 14827.421613454819, 'accumulated_submission_time': 14225.474731206894, 'accumulated_eval_time': 600.8509647846222, 'accumulated_logging_time': 0.92275071144104, 'global_step': 13121, 'preemption_count': 0}), (13521, {'train/accuracy': 0.5941405892372131, 'train/loss': 1.8079285621643066, 'validation/accuracy': 0.5467000007629395, 'validation/loss': 2.0349292755126953, 'validation/num_examples': 50000, 'test/accuracy': 0.4296000301837921, 'test/loss': 2.6776962280273438, 'test/num_examples': 10000, 'score': 14651.058849573135, 'total_duration': 15271.211242437363, 'accumulated_submission_time': 14651.058849573135, 'accumulated_eval_time': 619.0205767154694, 'accumulated_logging_time': 0.9531431198120117, 'global_step': 13521, 'preemption_count': 0}), (13920, {'train/accuracy': 0.5951757431030273, 'train/loss': 1.8053202629089355, 'validation/accuracy': 0.5530200004577637, 'validation/loss': 2.007859230041504, 'validation/num_examples': 50000, 'test/accuracy': 0.44300001859664917, 'test/loss': 2.640056610107422, 'test/num_examples': 10000, 'score': 15071.437667608261, 'total_duration': 15709.959007263184, 'accumulated_submission_time': 15071.437667608261, 'accumulated_eval_time': 637.3550798892975, 'accumulated_logging_time': 0.9819111824035645, 'global_step': 13920, 'preemption_count': 0}), (14313, {'train/accuracy': 0.6090624928474426, 'train/loss': 1.7258493900299072, 'validation/accuracy': 0.5591999888420105, 'validation/loss': 1.949966549873352, 'validation/num_examples': 50000, 'test/accuracy': 0.4466000199317932, 'test/loss': 2.589061975479126, 'test/num_examples': 10000, 'score': 15491.773736953735, 'total_duration': 16148.62124633789, 'accumulated_submission_time': 15491.773736953735, 'accumulated_eval_time': 655.642162322998, 'accumulated_logging_time': 1.015451192855835, 'global_step': 14313, 'preemption_count': 0}), (14706, {'train/accuracy': 0.6206445097923279, 'train/loss': 1.6915498971939087, 'validation/accuracy': 0.565559983253479, 'validation/loss': 1.935001015663147, 'validation/num_examples': 50000, 'test/accuracy': 0.44460001587867737, 'test/loss': 2.581625461578369, 'test/num_examples': 10000, 'score': 15912.304953575134, 'total_duration': 16587.543986797333, 'accumulated_submission_time': 15912.304953575134, 'accumulated_eval_time': 673.9952645301819, 'accumulated_logging_time': 1.0483109951019287, 'global_step': 14706, 'preemption_count': 0}), (15102, {'train/accuracy': 0.6183984279632568, 'train/loss': 1.737562656402588, 'validation/accuracy': 0.5741199851036072, 'validation/loss': 1.953713059425354, 'validation/num_examples': 50000, 'test/accuracy': 0.44780001044273376, 'test/loss': 2.5946013927459717, 'test/num_examples': 10000, 'score': 16332.949893951416, 'total_duration': 17026.642771959305, 'accumulated_submission_time': 16332.949893951416, 'accumulated_eval_time': 692.410008430481, 'accumulated_logging_time': 1.081965684890747, 'global_step': 15102, 'preemption_count': 0}), (15501, {'train/accuracy': 0.61376953125, 'train/loss': 1.7334959506988525, 'validation/accuracy': 0.5723999738693237, 'validation/loss': 1.9359074831008911, 'validation/num_examples': 50000, 'test/accuracy': 0.4489000141620636, 'test/loss': 2.585946798324585, 'test/num_examples': 10000, 'score': 16757.16921687126, 'total_duration': 17469.071436166763, 'accumulated_submission_time': 16757.16921687126, 'accumulated_eval_time': 710.5855083465576, 'accumulated_logging_time': 1.1104052066802979, 'global_step': 15501, 'preemption_count': 0}), (15901, {'train/accuracy': 0.6464257836341858, 'train/loss': 1.5724749565124512, 'validation/accuracy': 0.5799999833106995, 'validation/loss': 1.8763573169708252, 'validation/num_examples': 50000, 'test/accuracy': 0.4540000259876251, 'test/loss': 2.5238494873046875, 'test/num_examples': 10000, 'score': 17181.6416079998, 'total_duration': 17911.844989538193, 'accumulated_submission_time': 17181.6416079998, 'accumulated_eval_time': 728.8523530960083, 'accumulated_logging_time': 1.1393272876739502, 'global_step': 15901, 'preemption_count': 0}), (16301, {'train/accuracy': 0.6430858969688416, 'train/loss': 1.602251648902893, 'validation/accuracy': 0.5914799571037292, 'validation/loss': 1.8467577695846558, 'validation/num_examples': 50000, 'test/accuracy': 0.4686000347137451, 'test/loss': 2.4845173358917236, 'test/num_examples': 10000, 'score': 17605.33087515831, 'total_duration': 18353.875778198242, 'accumulated_submission_time': 17605.33087515831, 'accumulated_eval_time': 747.154542684555, 'accumulated_logging_time': 1.1732375621795654, 'global_step': 16301, 'preemption_count': 0}), (16701, {'train/accuracy': 0.643359363079071, 'train/loss': 1.6095776557922363, 'validation/accuracy': 0.5931800007820129, 'validation/loss': 1.8343344926834106, 'validation/num_examples': 50000, 'test/accuracy': 0.4678000211715698, 'test/loss': 2.478806257247925, 'test/num_examples': 10000, 'score': 18029.746867656708, 'total_duration': 18796.524010181427, 'accumulated_submission_time': 18029.746867656708, 'accumulated_eval_time': 765.3592269420624, 'accumulated_logging_time': 1.1954035758972168, 'global_step': 16701, 'preemption_count': 0}), (17101, {'train/accuracy': 0.6371093392372131, 'train/loss': 1.6720467805862427, 'validation/accuracy': 0.5889399647712708, 'validation/loss': 1.876125454902649, 'validation/num_examples': 50000, 'test/accuracy': 0.46560001373291016, 'test/loss': 2.5320634841918945, 'test/num_examples': 10000, 'score': 18456.21490573883, 'total_duration': 19241.27462744713, 'accumulated_submission_time': 18456.21490573883, 'accumulated_eval_time': 783.6046245098114, 'accumulated_logging_time': 1.2269718647003174, 'global_step': 17101, 'preemption_count': 0}), (17501, {'train/accuracy': 0.6621484160423279, 'train/loss': 1.5361453294754028, 'validation/accuracy': 0.5992599725723267, 'validation/loss': 1.8087482452392578, 'validation/num_examples': 50000, 'test/accuracy': 0.47630003094673157, 'test/loss': 2.444333076477051, 'test/num_examples': 10000, 'score': 18879.662127256393, 'total_duration': 19683.06428718567, 'accumulated_submission_time': 18879.662127256393, 'accumulated_eval_time': 801.9161303043365, 'accumulated_logging_time': 1.2525112628936768, 'global_step': 17501, 'preemption_count': 0}), (17901, {'train/accuracy': 0.6515429615974426, 'train/loss': 1.6296273469924927, 'validation/accuracy': 0.5973799824714661, 'validation/loss': 1.8643845319747925, 'validation/num_examples': 50000, 'test/accuracy': 0.47220003604888916, 'test/loss': 2.501556158065796, 'test/num_examples': 10000, 'score': 19304.389524936676, 'total_duration': 20126.234627008438, 'accumulated_submission_time': 19304.389524936676, 'accumulated_eval_time': 820.3192043304443, 'accumulated_logging_time': 1.2868199348449707, 'global_step': 17901, 'preemption_count': 0}), (18301, {'train/accuracy': 0.6532031297683716, 'train/loss': 1.53575599193573, 'validation/accuracy': 0.606719970703125, 'validation/loss': 1.7462965250015259, 'validation/num_examples': 50000, 'test/accuracy': 0.4771000146865845, 'test/loss': 2.410719633102417, 'test/num_examples': 10000, 'score': 19728.13902282715, 'total_duration': 20568.28292798996, 'accumulated_submission_time': 19728.13902282715, 'accumulated_eval_time': 838.5796527862549, 'accumulated_logging_time': 1.319887638092041, 'global_step': 18301, 'preemption_count': 0}), (18701, {'train/accuracy': 0.6934765577316284, 'train/loss': 1.3545461893081665, 'validation/accuracy': 0.6125999689102173, 'validation/loss': 1.716591715812683, 'validation/num_examples': 50000, 'test/accuracy': 0.48730000853538513, 'test/loss': 2.371211290359497, 'test/num_examples': 10000, 'score': 20152.390095233917, 'total_duration': 21010.834761619568, 'accumulated_submission_time': 20152.390095233917, 'accumulated_eval_time': 856.838406085968, 'accumulated_logging_time': 1.3558118343353271, 'global_step': 18701, 'preemption_count': 0}), (19101, {'train/accuracy': 0.6709374785423279, 'train/loss': 1.4499142169952393, 'validation/accuracy': 0.6169399619102478, 'validation/loss': 1.7016091346740723, 'validation/num_examples': 50000, 'test/accuracy': 0.4912000298500061, 'test/loss': 2.3572542667388916, 'test/num_examples': 10000, 'score': 20577.18582725525, 'total_duration': 21454.080466270447, 'accumulated_submission_time': 20577.18582725525, 'accumulated_eval_time': 875.2469525337219, 'accumulated_logging_time': 1.3917033672332764, 'global_step': 19101, 'preemption_count': 0}), (19501, {'train/accuracy': 0.6678515672683716, 'train/loss': 1.4874067306518555, 'validation/accuracy': 0.620419979095459, 'validation/loss': 1.719892144203186, 'validation/num_examples': 50000, 'test/accuracy': 0.4994000196456909, 'test/loss': 2.3544278144836426, 'test/num_examples': 10000, 'score': 21001.72945165634, 'total_duration': 21896.950417995453, 'accumulated_submission_time': 21001.72945165634, 'accumulated_eval_time': 893.5311057567596, 'accumulated_logging_time': 1.4282326698303223, 'global_step': 19501, 'preemption_count': 0}), (19901, {'train/accuracy': 0.6683788895606995, 'train/loss': 1.4888917207717896, 'validation/accuracy': 0.6207399964332581, 'validation/loss': 1.6988160610198975, 'validation/num_examples': 50000, 'test/accuracy': 0.4978000223636627, 'test/loss': 2.343045473098755, 'test/num_examples': 10000, 'score': 21428.028529644012, 'total_duration': 22341.61098265648, 'accumulated_submission_time': 21428.028529644012, 'accumulated_eval_time': 911.8503241539001, 'accumulated_logging_time': 1.4646968841552734, 'global_step': 19901, 'preemption_count': 0}), (20301, {'train/accuracy': 0.6885741949081421, 'train/loss': 1.3539657592773438, 'validation/accuracy': 0.6247199773788452, 'validation/loss': 1.6561819314956665, 'validation/num_examples': 50000, 'test/accuracy': 0.49790000915527344, 'test/loss': 2.3099851608276367, 'test/num_examples': 10000, 'score': 21852.260316848755, 'total_duration': 22784.20414686203, 'accumulated_submission_time': 21852.260316848755, 'accumulated_eval_time': 930.1761314868927, 'accumulated_logging_time': 1.4947741031646729, 'global_step': 20301, 'preemption_count': 0}), (20701, {'train/accuracy': 0.6799218654632568, 'train/loss': 1.4225764274597168, 'validation/accuracy': 0.6275599598884583, 'validation/loss': 1.6653140783309937, 'validation/num_examples': 50000, 'test/accuracy': 0.5002000331878662, 'test/loss': 2.31603741645813, 'test/num_examples': 10000, 'score': 22277.28802895546, 'total_duration': 23227.47119450569, 'accumulated_submission_time': 22277.28802895546, 'accumulated_eval_time': 948.3811473846436, 'accumulated_logging_time': 1.5235581398010254, 'global_step': 20701, 'preemption_count': 0}), (21100, {'train/accuracy': 0.6833202838897705, 'train/loss': 1.410420298576355, 'validation/accuracy': 0.6351400017738342, 'validation/loss': 1.6420440673828125, 'validation/num_examples': 50000, 'test/accuracy': 0.508400022983551, 'test/loss': 2.2954564094543457, 'test/num_examples': 10000, 'score': 22697.34977579117, 'total_duration': 23665.846835136414, 'accumulated_submission_time': 22697.34977579117, 'accumulated_eval_time': 966.6569211483002, 'accumulated_logging_time': 1.55600905418396, 'global_step': 21100, 'preemption_count': 0}), (21492, {'train/accuracy': 0.6937695145606995, 'train/loss': 1.4141901731491089, 'validation/accuracy': 0.6278199553489685, 'validation/loss': 1.7047410011291504, 'validation/num_examples': 50000, 'test/accuracy': 0.5034000277519226, 'test/loss': 2.3582873344421387, 'test/num_examples': 10000, 'score': 23117.5638256073, 'total_duration': 24104.41635107994, 'accumulated_submission_time': 23117.5638256073, 'accumulated_eval_time': 984.9755582809448, 'accumulated_logging_time': 1.5873923301696777, 'global_step': 21492, 'preemption_count': 0}), (21886, {'train/accuracy': 0.6940820217132568, 'train/loss': 1.3495880365371704, 'validation/accuracy': 0.6366400122642517, 'validation/loss': 1.6158816814422607, 'validation/num_examples': 50000, 'test/accuracy': 0.5078000426292419, 'test/loss': 2.2668209075927734, 'test/num_examples': 10000, 'score': 23538.34276175499, 'total_duration': 24543.706295967102, 'accumulated_submission_time': 23538.34276175499, 'accumulated_eval_time': 1003.4426016807556, 'accumulated_logging_time': 1.6258487701416016, 'global_step': 21886, 'preemption_count': 0}), (22281, {'train/accuracy': 0.6926562190055847, 'train/loss': 1.3622392416000366, 'validation/accuracy': 0.6378600001335144, 'validation/loss': 1.6067862510681152, 'validation/num_examples': 50000, 'test/accuracy': 0.5163000226020813, 'test/loss': 2.250131130218506, 'test/num_examples': 10000, 'score': 23958.668736696243, 'total_duration': 24982.438442230225, 'accumulated_submission_time': 23958.668736696243, 'accumulated_eval_time': 1021.8049738407135, 'accumulated_logging_time': 1.6641297340393066, 'global_step': 22281, 'preemption_count': 0}), (22681, {'train/accuracy': 0.6877734065055847, 'train/loss': 1.3627800941467285, 'validation/accuracy': 0.6381199955940247, 'validation/loss': 1.58297860622406, 'validation/num_examples': 50000, 'test/accuracy': 0.5169000029563904, 'test/loss': 2.2285635471343994, 'test/num_examples': 10000, 'score': 24384.69821548462, 'total_duration': 25426.884453058243, 'accumulated_submission_time': 24384.69821548462, 'accumulated_eval_time': 1040.1829235553741, 'accumulated_logging_time': 1.6971683502197266, 'global_step': 22681, 'preemption_count': 0}), (23080, {'train/accuracy': 0.7146288752555847, 'train/loss': 1.2157279253005981, 'validation/accuracy': 0.6473999619483948, 'validation/loss': 1.5290677547454834, 'validation/num_examples': 50000, 'test/accuracy': 0.517300009727478, 'test/loss': 2.1935038566589355, 'test/num_examples': 10000, 'score': 24805.191913604736, 'total_duration': 25865.85638976097, 'accumulated_submission_time': 24805.191913604736, 'accumulated_eval_time': 1058.6179785728455, 'accumulated_logging_time': 1.7346899509429932, 'global_step': 23080, 'preemption_count': 0}), (23474, {'train/accuracy': 0.7038476467132568, 'train/loss': 1.304925799369812, 'validation/accuracy': 0.6427199840545654, 'validation/loss': 1.5697730779647827, 'validation/num_examples': 50000, 'test/accuracy': 0.5149000287055969, 'test/loss': 2.2244274616241455, 'test/num_examples': 10000, 'score': 25225.334848165512, 'total_duration': 26304.34862613678, 'accumulated_submission_time': 25225.334848165512, 'accumulated_eval_time': 1076.9228863716125, 'accumulated_logging_time': 1.773622751235962, 'global_step': 23474, 'preemption_count': 0}), (23868, {'train/accuracy': 0.7015429735183716, 'train/loss': 1.3140352964401245, 'validation/accuracy': 0.6487199664115906, 'validation/loss': 1.5559242963790894, 'validation/num_examples': 50000, 'test/accuracy': 0.5182000398635864, 'test/loss': 2.1963918209075928, 'test/num_examples': 10000, 'score': 25645.605207443237, 'total_duration': 26742.961475610733, 'accumulated_submission_time': 25645.605207443237, 'accumulated_eval_time': 1095.229112625122, 'accumulated_logging_time': 1.8044366836547852, 'global_step': 23868, 'preemption_count': 0}), (24263, {'train/accuracy': 0.7036523222923279, 'train/loss': 1.2732949256896973, 'validation/accuracy': 0.6514399647712708, 'validation/loss': 1.5141762495040894, 'validation/num_examples': 50000, 'test/accuracy': 0.5260000228881836, 'test/loss': 2.1605770587921143, 'test/num_examples': 10000, 'score': 26065.932987213135, 'total_duration': 27181.838849782944, 'accumulated_submission_time': 26065.932987213135, 'accumulated_eval_time': 1113.742267370224, 'accumulated_logging_time': 1.8355610370635986, 'global_step': 24263, 'preemption_count': 0}), (24661, {'train/accuracy': 0.7214257717132568, 'train/loss': 1.2498676776885986, 'validation/accuracy': 0.6494799852371216, 'validation/loss': 1.550089955329895, 'validation/num_examples': 50000, 'test/accuracy': 0.52510005235672, 'test/loss': 2.1941280364990234, 'test/num_examples': 10000, 'score': 26489.82123684883, 'total_duration': 27623.980819940567, 'accumulated_submission_time': 26489.82123684883, 'accumulated_eval_time': 1131.9627180099487, 'accumulated_logging_time': 1.863340139389038, 'global_step': 24661, 'preemption_count': 0}), (25061, {'train/accuracy': 0.7122656106948853, 'train/loss': 1.2646727561950684, 'validation/accuracy': 0.6521399617195129, 'validation/loss': 1.5378425121307373, 'validation/num_examples': 50000, 'test/accuracy': 0.5270000100135803, 'test/loss': 2.1722800731658936, 'test/num_examples': 10000, 'score': 26914.321694612503, 'total_duration': 28066.700620174408, 'accumulated_submission_time': 26914.321694612503, 'accumulated_eval_time': 1150.1448888778687, 'accumulated_logging_time': 1.895167350769043, 'global_step': 25061, 'preemption_count': 0}), (25461, {'train/accuracy': 0.7045507431030273, 'train/loss': 1.3274132013320923, 'validation/accuracy': 0.6525200009346008, 'validation/loss': 1.5565452575683594, 'validation/num_examples': 50000, 'test/accuracy': 0.5306000113487244, 'test/loss': 2.1865217685699463, 'test/num_examples': 10000, 'score': 27339.70870256424, 'total_duration': 28510.446217536926, 'accumulated_submission_time': 27339.70870256424, 'accumulated_eval_time': 1168.461064338684, 'accumulated_logging_time': 1.9319839477539062, 'global_step': 25461, 'preemption_count': 0}), (25860, {'train/accuracy': 0.7433788776397705, 'train/loss': 1.1645514965057373, 'validation/accuracy': 0.6562599539756775, 'validation/loss': 1.5322163105010986, 'validation/num_examples': 50000, 'test/accuracy': 0.5349000096321106, 'test/loss': 2.161813497543335, 'test/num_examples': 10000, 'score': 27759.928587198257, 'total_duration': 28949.06757235527, 'accumulated_submission_time': 27759.928587198257, 'accumulated_eval_time': 1186.8250255584717, 'accumulated_logging_time': 1.9638986587524414, 'global_step': 25860, 'preemption_count': 0}), (26254, {'train/accuracy': 0.720703125, 'train/loss': 1.219651222229004, 'validation/accuracy': 0.6569600105285645, 'validation/loss': 1.4992725849151611, 'validation/num_examples': 50000, 'test/accuracy': 0.5332000255584717, 'test/loss': 2.134916305541992, 'test/num_examples': 10000, 'score': 28180.452605962753, 'total_duration': 29387.999109745026, 'accumulated_submission_time': 28180.452605962753, 'accumulated_eval_time': 1205.18505525589, 'accumulated_logging_time': 2.005889415740967, 'global_step': 26254, 'preemption_count': 0}), (26647, {'train/accuracy': 0.713183581829071, 'train/loss': 1.2920280694961548, 'validation/accuracy': 0.6542800068855286, 'validation/loss': 1.5446299314498901, 'validation/num_examples': 50000, 'test/accuracy': 0.5312000513076782, 'test/loss': 2.1694157123565674, 'test/num_examples': 10000, 'score': 28601.04886651039, 'total_duration': 29827.06386232376, 'accumulated_submission_time': 28601.04886651039, 'accumulated_eval_time': 1223.608095407486, 'accumulated_logging_time': 2.0457589626312256, 'global_step': 26647, 'preemption_count': 0}), (27041, {'train/accuracy': 0.7154101133346558, 'train/loss': 1.2688331604003906, 'validation/accuracy': 0.6618199944496155, 'validation/loss': 1.5109143257141113, 'validation/num_examples': 50000, 'test/accuracy': 0.5297999978065491, 'test/loss': 2.1646547317504883, 'test/num_examples': 10000, 'score': 29021.167956113815, 'total_duration': 30265.350011110306, 'accumulated_submission_time': 29021.167956113815, 'accumulated_eval_time': 1241.7293515205383, 'accumulated_logging_time': 2.0861716270446777, 'global_step': 27041, 'preemption_count': 0}), (27439, {'train/accuracy': 0.733691394329071, 'train/loss': 1.1567423343658447, 'validation/accuracy': 0.659060001373291, 'validation/loss': 1.487488031387329, 'validation/num_examples': 50000, 'test/accuracy': 0.5325000286102295, 'test/loss': 2.1341910362243652, 'test/num_examples': 10000, 'score': 29441.50515937805, 'total_duration': 30704.11900115013, 'accumulated_submission_time': 29441.50515937805, 'accumulated_eval_time': 1260.1243057250977, 'accumulated_logging_time': 2.1173675060272217, 'global_step': 27439, 'preemption_count': 0}), (27830, {'train/accuracy': 0.726757824420929, 'train/loss': 1.2136718034744263, 'validation/accuracy': 0.6632199883460999, 'validation/loss': 1.488201379776001, 'validation/num_examples': 50000, 'test/accuracy': 0.5342000126838684, 'test/loss': 2.1213691234588623, 'test/num_examples': 10000, 'score': 29861.84357905388, 'total_duration': 31142.85990834236, 'accumulated_submission_time': 29861.84357905388, 'accumulated_eval_time': 1278.488567829132, 'accumulated_logging_time': 2.1501893997192383, 'global_step': 27830, 'preemption_count': 0}), (28000, {'train/accuracy': 0.7230077981948853, 'train/loss': 1.2427459955215454, 'validation/accuracy': 0.6633999943733215, 'validation/loss': 1.5126250982284546, 'validation/num_examples': 50000, 'test/accuracy': 0.5384000539779663, 'test/loss': 2.140953540802002, 'test/num_examples': 10000, 'score': 30039.94752430916, 'total_duration': 31339.262818336487, 'accumulated_submission_time': 30039.94752430916, 'accumulated_eval_time': 1296.7457683086395, 'accumulated_logging_time': 2.189225912094116, 'global_step': 28000, 'preemption_count': 0})], 'global_step': 28000}
I0428 21:05:06.161183 139903503492928 submission_runner.py:581] Timing: 30039.94752430916
I0428 21:05:06.161237 139903503492928 submission_runner.py:582] ====================
I0428 21:05:06.161428 139903503492928 submission_runner.py:645] Final imagenet_vit score: 30039.94752430916
