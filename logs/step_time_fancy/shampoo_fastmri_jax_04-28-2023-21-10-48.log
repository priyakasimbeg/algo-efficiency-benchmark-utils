python3 submission_runner.py --framework=jax --workload=fastmri --submission_path=baselines/shampoo/jax/submission.py --tuning_search_space=baselines/shampoo/tuning_search_space.json --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_fancy/timing_shampoo --overwrite=True --save_checkpoints=False --max_global_steps=5428 2>&1 | tee -a /logs/fastmri_jax_04-28-2023-21-10-48.log
I0428 21:11:08.915170 140278278252352 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_fancy/timing_shampoo/fastmri_jax.
I0428 21:11:09.114389 140278278252352 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0428 21:11:09.939856 140278278252352 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Host Interpreter
I0428 21:11:09.940652 140278278252352 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0428 21:11:09.946151 140278278252352 submission_runner.py:538] Using RNG seed 3587143575
I0428 21:11:12.737046 140278278252352 submission_runner.py:547] --- Tuning run 1/1 ---
I0428 21:11:12.737274 140278278252352 submission_runner.py:552] Creating tuning directory at /experiment_runs/timing_fancy/timing_shampoo/fastmri_jax/trial_1.
I0428 21:11:12.737475 140278278252352 logger_utils.py:92] Saving hparams to /experiment_runs/timing_fancy/timing_shampoo/fastmri_jax/trial_1/hparams.json.
I0428 21:11:12.876065 140278278252352 submission_runner.py:241] Initializing dataset.
I0428 21:11:18.023116 140278278252352 submission_runner.py:248] Initializing model.
I0428 21:11:25.291675 140278278252352 submission_runner.py:258] Initializing optimizer.
I0428 21:11:36.309255 140278278252352 submission_runner.py:265] Initializing metrics bundle.
I0428 21:11:36.309468 140278278252352 submission_runner.py:282] Initializing checkpoint and logger.
I0428 21:11:36.311930 140278278252352 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_fancy/timing_shampoo/fastmri_jax/trial_1 with prefix checkpoint_
I0428 21:11:36.312200 140278278252352 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0428 21:11:36.312263 140278278252352 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0428 21:11:37.061432 140278278252352 submission_runner.py:303] Saving meta data to /experiment_runs/timing_fancy/timing_shampoo/fastmri_jax/trial_1/meta_data_0.json.
I0428 21:11:37.062710 140278278252352 submission_runner.py:306] Saving flags to /experiment_runs/timing_fancy/timing_shampoo/fastmri_jax/trial_1/flags_0.json.
I0428 21:11:37.068452 140278278252352 submission_runner.py:318] Starting training loop.
/algorithmic-efficiency/baselines/shampoo/jax/distributed_shampoo.py:812: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.
  matrix = matrix.astype(_MAT_INV_PTH_ROOT_DTYPE)
/algorithmic-efficiency/baselines/shampoo/jax/distributed_shampoo.py:813: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.
  alpha = jnp.asarray(-1.0 / p, _MAT_INV_PTH_ROOT_DTYPE)
/algorithmic-efficiency/baselines/shampoo/jax/distributed_shampoo.py:814: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in eye is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.
  identity = jnp.eye(matrix_size, dtype=_MAT_INV_PTH_ROOT_DTYPE)
I0428 21:12:46.840253 140100918830848 logging_writer.py:48] [0] global_step=0, grad_norm=6.11561918258667, loss=0.9854224920272827
I0428 21:12:46.859631 140278278252352 spec.py:298] Evaluating on the training split.
I0428 21:14:02.566219 140278278252352 spec.py:310] Evaluating on the validation split.
I0428 21:14:48.474757 140278278252352 spec.py:326] Evaluating on the test split.
I0428 21:15:30.064332 140278278252352 submission_runner.py:415] Time since start: 233.00s, 	Step: 1, 	{'train/ssim': 0.2534253937857492, 'train/loss': 1.0028910636901855, 'validation/ssim': 0.24635640382095877, 'validation/loss': 1.0001127965408694, 'validation/num_examples': 3554, 'test/ssim': 0.26854149531599064, 'test/loss': 0.9966813646458741, 'test/num_examples': 3581, 'score': 69.79099154472351, 'total_duration': 232.99575233459473, 'accumulated_submission_time': 69.79099154472351, 'accumulated_eval_time': 163.20459294319153, 'accumulated_logging_time': 0}
I0428 21:15:30.083009 140072330438400 logging_writer.py:48] [1] accumulated_eval_time=163.204593, accumulated_logging_time=0, accumulated_submission_time=69.790992, global_step=1, preemption_count=0, score=69.790992, test/loss=0.996681, test/num_examples=3581, test/ssim=0.268541, total_duration=232.995752, train/loss=1.002891, train/ssim=0.253425, validation/loss=1.000113, validation/num_examples=3554, validation/ssim=0.246356
I0428 21:15:54.800706 140072322045696 logging_writer.py:48] [100] global_step=100, grad_norm=0.22984565794467926, loss=0.2950565814971924
I0428 21:16:21.333550 140072330438400 logging_writer.py:48] [200] global_step=200, grad_norm=0.1661243885755539, loss=0.28984829783439636
I0428 21:16:47.518699 140072322045696 logging_writer.py:48] [300] global_step=300, grad_norm=0.3639269769191742, loss=0.29997944831848145
I0428 21:16:50.239844 140278278252352 spec.py:298] Evaluating on the training split.
I0428 21:16:51.906315 140278278252352 spec.py:310] Evaluating on the validation split.
I0428 21:16:53.262292 140278278252352 spec.py:326] Evaluating on the test split.
I0428 21:16:54.620504 140278278252352 submission_runner.py:415] Time since start: 317.55s, 	Step: 314, 	{'train/ssim': 0.7280290467398507, 'train/loss': 0.2898177078792027, 'validation/ssim': 0.7073808368431697, 'validation/loss': 0.30326579646173324, 'validation/num_examples': 3554, 'test/ssim': 0.7243597120654147, 'test/loss': 0.3054534307041504, 'test/num_examples': 3581, 'score': 149.9349136352539, 'total_duration': 317.5519587993622, 'accumulated_submission_time': 149.9349136352539, 'accumulated_eval_time': 167.5851972103119, 'accumulated_logging_time': 0.02743840217590332}
I0428 21:16:54.629180 140072330438400 logging_writer.py:48] [314] accumulated_eval_time=167.585197, accumulated_logging_time=0.027438, accumulated_submission_time=149.934914, global_step=314, preemption_count=0, score=149.934914, test/loss=0.305453, test/num_examples=3581, test/ssim=0.724360, total_duration=317.551959, train/loss=0.289818, train/ssim=0.728029, validation/loss=0.303266, validation/num_examples=3554, validation/ssim=0.707381
I0428 21:17:16.258835 140072322045696 logging_writer.py:48] [400] global_step=400, grad_norm=0.2519487142562866, loss=0.33308494091033936
I0428 21:17:42.679602 140072330438400 logging_writer.py:48] [500] global_step=500, grad_norm=0.30345457792282104, loss=0.27706649899482727
I0428 21:18:09.080196 140072322045696 logging_writer.py:48] [600] global_step=600, grad_norm=0.2292868047952652, loss=0.28181779384613037
I0428 21:18:14.697918 140278278252352 spec.py:298] Evaluating on the training split.
I0428 21:18:16.051105 140278278252352 spec.py:310] Evaluating on the validation split.
I0428 21:18:17.406225 140278278252352 spec.py:326] Evaluating on the test split.
I0428 21:18:18.762181 140278278252352 submission_runner.py:415] Time since start: 401.69s, 	Step: 624, 	{'train/ssim': 0.7319320269993373, 'train/loss': 0.2832962615149362, 'validation/ssim': 0.7114859577236916, 'validation/loss': 0.2970216286336698, 'validation/num_examples': 3554, 'test/ssim': 0.728477991482826, 'test/loss': 0.2988011270420274, 'test/num_examples': 3581, 'score': 229.99089360237122, 'total_duration': 401.69362473487854, 'accumulated_submission_time': 229.99089360237122, 'accumulated_eval_time': 171.64941453933716, 'accumulated_logging_time': 0.04468250274658203}
I0428 21:18:18.771558 140072330438400 logging_writer.py:48] [624] accumulated_eval_time=171.649415, accumulated_logging_time=0.044683, accumulated_submission_time=229.990894, global_step=624, preemption_count=0, score=229.990894, test/loss=0.298801, test/num_examples=3581, test/ssim=0.728478, total_duration=401.693625, train/loss=0.283296, train/ssim=0.731932, validation/loss=0.297022, validation/num_examples=3554, validation/ssim=0.711486
I0428 21:18:37.482185 140072322045696 logging_writer.py:48] [700] global_step=700, grad_norm=0.22342842817306519, loss=0.2877882719039917
I0428 21:19:04.000724 140072330438400 logging_writer.py:48] [800] global_step=800, grad_norm=0.24393101036548615, loss=0.36025139689445496
I0428 21:19:31.318708 140072322045696 logging_writer.py:48] [900] global_step=900, grad_norm=0.1982329934835434, loss=0.25409987568855286
I0428 21:19:39.005126 140278278252352 spec.py:298] Evaluating on the training split.
I0428 21:19:40.358841 140278278252352 spec.py:310] Evaluating on the validation split.
I0428 21:19:44.300889 140278278252352 spec.py:326] Evaluating on the test split.
I0428 21:19:45.662409 140278278252352 submission_runner.py:415] Time since start: 488.59s, 	Step: 932, 	{'train/ssim': 0.738248484475272, 'train/loss': 0.2786785875047956, 'validation/ssim': 0.7159468479618036, 'validation/loss': 0.2932534204417558, 'validation/num_examples': 3554, 'test/ssim': 0.7330769845408056, 'test/loss': 0.29492582924636973, 'test/num_examples': 3581, 'score': 310.21177554130554, 'total_duration': 488.59380316734314, 'accumulated_submission_time': 310.21177554130554, 'accumulated_eval_time': 178.30659794807434, 'accumulated_logging_time': 0.06263327598571777}
I0428 21:19:45.673084 140072330438400 logging_writer.py:48] [932] accumulated_eval_time=178.306598, accumulated_logging_time=0.062633, accumulated_submission_time=310.211776, global_step=932, preemption_count=0, score=310.211776, test/loss=0.294926, test/num_examples=3581, test/ssim=0.733077, total_duration=488.593803, train/loss=0.278679, train/ssim=0.738248, validation/loss=0.293253, validation/num_examples=3554, validation/ssim=0.715947
I0428 21:20:02.416869 140072322045696 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.2617031931877136, loss=0.1896495819091797
I0428 21:20:28.435559 140072330438400 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.32072576880455017, loss=0.22635439038276672
I0428 21:20:54.425273 140072322045696 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.23957613110542297, loss=0.2772192060947418
I0428 21:21:05.882378 140278278252352 spec.py:298] Evaluating on the training split.
I0428 21:21:07.245439 140278278252352 spec.py:310] Evaluating on the validation split.
I0428 21:21:08.603502 140278278252352 spec.py:326] Evaluating on the test split.
I0428 21:21:09.960116 140278278252352 submission_runner.py:415] Time since start: 572.89s, 	Step: 1249, 	{'train/ssim': 0.7391380582536969, 'train/loss': 0.27761546203068327, 'validation/ssim': 0.7175683841050576, 'validation/loss': 0.29206850720578925, 'validation/num_examples': 3554, 'test/ssim': 0.7346481157061575, 'test/loss': 0.2936299613520141, 'test/num_examples': 3581, 'score': 390.4075195789337, 'total_duration': 572.8915722370148, 'accumulated_submission_time': 390.4075195789337, 'accumulated_eval_time': 182.38429498672485, 'accumulated_logging_time': 0.08227324485778809}
I0428 21:21:09.969530 140072330438400 logging_writer.py:48] [1249] accumulated_eval_time=182.384295, accumulated_logging_time=0.082273, accumulated_submission_time=390.407520, global_step=1249, preemption_count=0, score=390.407520, test/loss=0.293630, test/num_examples=3581, test/ssim=0.734648, total_duration=572.891572, train/loss=0.277615, train/ssim=0.739138, validation/loss=0.292069, validation/num_examples=3554, validation/ssim=0.717568
I0428 21:21:21.725003 140072322045696 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.16154810786247253, loss=0.3708900213241577
I0428 21:21:47.577143 140072330438400 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.3659624755382538, loss=0.2443910390138626
I0428 21:22:13.414096 140072322045696 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.18870438635349274, loss=0.2941983640193939
I0428 21:22:30.227972 140278278252352 spec.py:298] Evaluating on the training split.
I0428 21:22:31.585734 140278278252352 spec.py:310] Evaluating on the validation split.
I0428 21:22:32.942789 140278278252352 spec.py:326] Evaluating on the test split.
I0428 21:22:34.301615 140278278252352 submission_runner.py:415] Time since start: 657.23s, 	Step: 1570, 	{'train/ssim': 0.7428384508405413, 'train/loss': 0.2760439089366368, 'validation/ssim': 0.7206814861995287, 'validation/loss': 0.29091361351206385, 'validation/num_examples': 3554, 'test/ssim': 0.7379160276240925, 'test/loss': 0.29236750002181655, 'test/num_examples': 3581, 'score': 470.65275144577026, 'total_duration': 657.2330589294434, 'accumulated_submission_time': 470.65275144577026, 'accumulated_eval_time': 186.45787739753723, 'accumulated_logging_time': 0.10025262832641602}
I0428 21:22:34.311761 140072330438400 logging_writer.py:48] [1570] accumulated_eval_time=186.457877, accumulated_logging_time=0.100253, accumulated_submission_time=470.652751, global_step=1570, preemption_count=0, score=470.652751, test/loss=0.292368, test/num_examples=3581, test/ssim=0.737916, total_duration=657.233059, train/loss=0.276044, train/ssim=0.742838, validation/loss=0.290914, validation/num_examples=3554, validation/ssim=0.720681
I0428 21:22:40.742703 140072322045696 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.12626679241657257, loss=0.30445823073387146
I0428 21:23:06.544379 140072330438400 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.16110074520111084, loss=0.31085485219955444
I0428 21:23:31.994788 140072322045696 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.23583470284938812, loss=0.31157857179641724
I0428 21:23:54.495269 140278278252352 spec.py:298] Evaluating on the training split.
I0428 21:23:55.855313 140278278252352 spec.py:310] Evaluating on the validation split.
I0428 21:23:57.209752 140278278252352 spec.py:326] Evaluating on the test split.
I0428 21:23:58.565402 140278278252352 submission_runner.py:415] Time since start: 741.50s, 	Step: 1891, 	{'train/ssim': 0.7426044600350517, 'train/loss': 0.2750907114573887, 'validation/ssim': 0.7201960901229248, 'validation/loss': 0.28983462735649973, 'validation/num_examples': 3554, 'test/ssim': 0.7373810453609327, 'test/loss': 0.2913760409212685, 'test/num_examples': 3581, 'score': 550.8227610588074, 'total_duration': 741.4968674182892, 'accumulated_submission_time': 550.8227610588074, 'accumulated_eval_time': 190.52798438072205, 'accumulated_logging_time': 0.11941003799438477}
I0428 21:23:58.574712 140072330438400 logging_writer.py:48] [1891] accumulated_eval_time=190.527984, accumulated_logging_time=0.119410, accumulated_submission_time=550.822761, global_step=1891, preemption_count=0, score=550.822761, test/loss=0.291376, test/num_examples=3581, test/ssim=0.737381, total_duration=741.496867, train/loss=0.275091, train/ssim=0.742604, validation/loss=0.289835, validation/num_examples=3554, validation/ssim=0.720196
I0428 21:24:00.630894 140072322045696 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.1731303334236145, loss=0.29342612624168396
I0428 21:24:25.577600 140072330438400 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.173699751496315, loss=0.20571103692054749
I0428 21:24:51.528395 140072322045696 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.0649876669049263, loss=0.3564281165599823
I0428 21:25:17.276365 140072330438400 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.22040025889873505, loss=0.23013485968112946
I0428 21:25:18.778914 140278278252352 spec.py:298] Evaluating on the training split.
I0428 21:25:20.133230 140278278252352 spec.py:310] Evaluating on the validation split.
I0428 21:25:23.122458 140278278252352 spec.py:326] Evaluating on the test split.
I0428 21:25:24.480834 140278278252352 submission_runner.py:415] Time since start: 827.41s, 	Step: 2210, 	{'train/ssim': 0.7451058796473912, 'train/loss': 0.2734111377171108, 'validation/ssim': 0.7221615801517656, 'validation/loss': 0.28901032644775254, 'validation/num_examples': 3554, 'test/ssim': 0.7393861891536931, 'test/loss': 0.29039835350635296, 'test/num_examples': 3581, 'score': 631.0138018131256, 'total_duration': 827.4122841358185, 'accumulated_submission_time': 631.0138018131256, 'accumulated_eval_time': 196.2298400402069, 'accumulated_logging_time': 0.13727998733520508}
I0428 21:25:24.490579 140072322045696 logging_writer.py:48] [2210] accumulated_eval_time=196.229840, accumulated_logging_time=0.137280, accumulated_submission_time=631.013802, global_step=2210, preemption_count=0, score=631.013802, test/loss=0.290398, test/num_examples=3581, test/ssim=0.739386, total_duration=827.412284, train/loss=0.273411, train/ssim=0.745106, validation/loss=0.289010, validation/num_examples=3554, validation/ssim=0.722162
I0428 21:25:46.704343 140072330438400 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.15928883850574493, loss=0.22266755998134613
I0428 21:26:12.425448 140072322045696 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.1322958767414093, loss=0.2620377838611603
I0428 21:26:38.394813 140072330438400 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.11545004695653915, loss=0.271659791469574
I0428 21:26:44.605830 140278278252352 spec.py:298] Evaluating on the training split.
I0428 21:26:45.964314 140278278252352 spec.py:310] Evaluating on the validation split.
I0428 21:26:47.324872 140278278252352 spec.py:326] Evaluating on the test split.
I0428 21:26:48.680159 140278278252352 submission_runner.py:415] Time since start: 911.61s, 	Step: 2528, 	{'train/ssim': 0.7436110632760184, 'train/loss': 0.27296476704733713, 'validation/ssim': 0.7206109368405318, 'validation/loss': 0.28817400398318793, 'validation/num_examples': 3554, 'test/ssim': 0.7379682509468375, 'test/loss': 0.28959536878665176, 'test/num_examples': 3581, 'score': 711.1160893440247, 'total_duration': 911.6115610599518, 'accumulated_submission_time': 711.1160893440247, 'accumulated_eval_time': 200.30405735969543, 'accumulated_logging_time': 0.15534329414367676}
I0428 21:26:48.691446 140072322045696 logging_writer.py:48] [2528] accumulated_eval_time=200.304057, accumulated_logging_time=0.155343, accumulated_submission_time=711.116089, global_step=2528, preemption_count=0, score=711.116089, test/loss=0.289595, test/num_examples=3581, test/ssim=0.737968, total_duration=911.611561, train/loss=0.272965, train/ssim=0.743611, validation/loss=0.288174, validation/num_examples=3554, validation/ssim=0.720611
I0428 21:27:06.089933 140072330438400 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.1453004777431488, loss=0.2519867718219757
I0428 21:27:32.120141 140072322045696 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.12411700934171677, loss=0.21667149662971497
I0428 21:27:58.085277 140072330438400 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.07215363532304764, loss=0.2613179683685303
I0428 21:28:08.701538 140278278252352 spec.py:298] Evaluating on the training split.
I0428 21:28:10.056026 140278278252352 spec.py:310] Evaluating on the validation split.
I0428 21:28:11.414097 140278278252352 spec.py:326] Evaluating on the test split.
I0428 21:28:12.776759 140278278252352 submission_runner.py:415] Time since start: 995.71s, 	Step: 2843, 	{'train/ssim': 0.7448797225952148, 'train/loss': 0.27290364674159456, 'validation/ssim': 0.7223862115090391, 'validation/loss': 0.2879233030234419, 'validation/num_examples': 3554, 'test/ssim': 0.7396970065536861, 'test/loss': 0.28928973281293635, 'test/num_examples': 3581, 'score': 791.1127367019653, 'total_duration': 995.7082159519196, 'accumulated_submission_time': 791.1127367019653, 'accumulated_eval_time': 204.3792314529419, 'accumulated_logging_time': 0.175506591796875}
I0428 21:28:12.786306 140072322045696 logging_writer.py:48] [2843] accumulated_eval_time=204.379231, accumulated_logging_time=0.175507, accumulated_submission_time=791.112737, global_step=2843, preemption_count=0, score=791.112737, test/loss=0.289290, test/num_examples=3581, test/ssim=0.739697, total_duration=995.708216, train/loss=0.272904, train/ssim=0.744880, validation/loss=0.287923, validation/num_examples=3554, validation/ssim=0.722386
I0428 21:28:26.286391 140072330438400 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.11944103986024857, loss=0.22198528051376343
I0428 21:28:51.901860 140072322045696 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.07547515630722046, loss=0.3041338324546814
I0428 21:29:17.712932 140072330438400 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.10213986784219742, loss=0.2416732758283615
I0428 21:29:33.368074 140278278252352 spec.py:298] Evaluating on the training split.
I0428 21:29:34.725951 140278278252352 spec.py:310] Evaluating on the validation split.
I0428 21:29:36.085938 140278278252352 spec.py:326] Evaluating on the test split.
I0428 21:29:37.449564 140278278252352 submission_runner.py:415] Time since start: 1080.38s, 	Step: 3161, 	{'train/ssim': 0.7450051307678223, 'train/loss': 0.27232517514910015, 'validation/ssim': 0.7219389409380276, 'validation/loss': 0.2880120907999789, 'validation/num_examples': 3554, 'test/ssim': 0.7392915599474658, 'test/loss': 0.28938770267557945, 'test/num_examples': 3581, 'score': 871.681554555893, 'total_duration': 1080.3810210227966, 'accumulated_submission_time': 871.681554555893, 'accumulated_eval_time': 208.4606637954712, 'accumulated_logging_time': 0.1935265064239502}
I0428 21:29:37.459611 140072322045696 logging_writer.py:48] [3161] accumulated_eval_time=208.460664, accumulated_logging_time=0.193527, accumulated_submission_time=871.681555, global_step=3161, preemption_count=0, score=871.681555, test/loss=0.289388, test/num_examples=3581, test/ssim=0.739292, total_duration=1080.381021, train/loss=0.272325, train/ssim=0.745005, validation/loss=0.288012, validation/num_examples=3554, validation/ssim=0.721939
I0428 21:29:46.095248 140072330438400 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.08837288618087769, loss=0.2525157034397125
I0428 21:30:12.104399 140072322045696 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.11661134660243988, loss=0.2731506824493408
I0428 21:30:37.664224 140072330438400 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.06052253767848015, loss=0.29236409068107605
I0428 21:30:58.279460 140278278252352 spec.py:298] Evaluating on the training split.
I0428 21:30:59.635967 140278278252352 spec.py:310] Evaluating on the validation split.
I0428 21:31:00.996220 140278278252352 spec.py:326] Evaluating on the test split.
I0428 21:31:02.354303 140278278252352 submission_runner.py:415] Time since start: 1165.29s, 	Step: 3481, 	{'train/ssim': 0.7471211978367397, 'train/loss': 0.27147730759211947, 'validation/ssim': 0.7239060796373804, 'validation/loss': 0.2872388299825021, 'validation/num_examples': 3554, 'test/ssim': 0.7411816215355348, 'test/loss': 0.28858550198748606, 'test/num_examples': 3581, 'score': 952.4871723651886, 'total_duration': 1165.2857434749603, 'accumulated_submission_time': 952.4871723651886, 'accumulated_eval_time': 212.53544640541077, 'accumulated_logging_time': 0.2132124900817871}
I0428 21:31:02.365185 140072322045696 logging_writer.py:48] [3481] accumulated_eval_time=212.535446, accumulated_logging_time=0.213212, accumulated_submission_time=952.487172, global_step=3481, preemption_count=0, score=952.487172, test/loss=0.288586, test/num_examples=3581, test/ssim=0.741182, total_duration=1165.285743, train/loss=0.271477, train/ssim=0.747121, validation/loss=0.287239, validation/num_examples=3554, validation/ssim=0.723906
I0428 21:31:05.940329 140072330438400 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.09142473340034485, loss=0.26368749141693115
I0428 21:31:31.330747 140072322045696 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.0648154616355896, loss=0.2787056565284729
I0428 21:31:57.116090 140072330438400 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.07974357157945633, loss=0.2569810152053833
I0428 21:32:23.090170 140072322045696 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.0798938125371933, loss=0.32658326625823975
I0428 21:32:23.103729 140278278252352 spec.py:298] Evaluating on the training split.
I0428 21:32:24.458584 140278278252352 spec.py:310] Evaluating on the validation split.
I0428 21:32:25.819724 140278278252352 spec.py:326] Evaluating on the test split.
I0428 21:32:27.178630 140278278252352 submission_runner.py:415] Time since start: 1250.11s, 	Step: 3801, 	{'train/ssim': 0.746438707624163, 'train/loss': 0.2713907446180071, 'validation/ssim': 0.7232772492262239, 'validation/loss': 0.28689614694710186, 'validation/num_examples': 3554, 'test/ssim': 0.7405801670273666, 'test/loss': 0.2882779570672473, 'test/num_examples': 3581, 'score': 1033.2127981185913, 'total_duration': 1250.11008477211, 'accumulated_submission_time': 1033.2127981185913, 'accumulated_eval_time': 216.61028122901917, 'accumulated_logging_time': 0.23240995407104492}
I0428 21:32:27.188370 140072330438400 logging_writer.py:48] [3801] accumulated_eval_time=216.610281, accumulated_logging_time=0.232410, accumulated_submission_time=1033.212798, global_step=3801, preemption_count=0, score=1033.212798, test/loss=0.288278, test/num_examples=3581, test/ssim=0.740580, total_duration=1250.110085, train/loss=0.271391, train/ssim=0.746439, validation/loss=0.286896, validation/num_examples=3554, validation/ssim=0.723277
I0428 21:32:51.276430 140072322045696 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.0759803056716919, loss=0.26086461544036865
I0428 21:33:17.021878 140072330438400 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.0945165827870369, loss=0.18368276953697205
I0428 21:33:43.007731 140072322045696 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.08863089233636856, loss=0.23258866369724274
I0428 21:33:48.143720 140278278252352 spec.py:298] Evaluating on the training split.
I0428 21:33:49.501434 140278278252352 spec.py:310] Evaluating on the validation split.
I0428 21:33:50.859934 140278278252352 spec.py:326] Evaluating on the test split.
I0428 21:33:52.221240 140278278252352 submission_runner.py:415] Time since start: 1335.15s, 	Step: 4121, 	{'train/ssim': 0.7465189525059291, 'train/loss': 0.271469031061445, 'validation/ssim': 0.7239271001864097, 'validation/loss': 0.2868824595471212, 'validation/num_examples': 3554, 'test/ssim': 0.7411461014948687, 'test/loss': 0.2881811802961812, 'test/num_examples': 3581, 'score': 1114.1549932956696, 'total_duration': 1335.1526548862457, 'accumulated_submission_time': 1114.1549932956696, 'accumulated_eval_time': 220.68770384788513, 'accumulated_logging_time': 0.2506687641143799}
I0428 21:33:52.231136 140072330438400 logging_writer.py:48] [4121] accumulated_eval_time=220.687704, accumulated_logging_time=0.250669, accumulated_submission_time=1114.154993, global_step=4121, preemption_count=0, score=1114.154993, test/loss=0.288181, test/num_examples=3581, test/ssim=0.741146, total_duration=1335.152655, train/loss=0.271469, train/ssim=0.746519, validation/loss=0.286882, validation/num_examples=3554, validation/ssim=0.723927
I0428 21:34:11.790481 140072322045696 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.07619000226259232, loss=0.285571813583374
I0428 21:34:37.658638 140072330438400 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.23784388601779938, loss=0.31204846501350403
I0428 21:35:03.724306 140072322045696 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.08667763322591782, loss=0.35993191599845886
I0428 21:35:12.393970 140278278252352 spec.py:298] Evaluating on the training split.
I0428 21:35:13.747087 140278278252352 spec.py:310] Evaluating on the validation split.
I0428 21:35:15.108246 140278278252352 spec.py:326] Evaluating on the test split.
I0428 21:35:16.465864 140278278252352 submission_runner.py:415] Time since start: 1419.40s, 	Step: 4438, 	{'train/ssim': 0.747859001159668, 'train/loss': 0.2706887722015381, 'validation/ssim': 0.72455304542417, 'validation/loss': 0.2867308849019151, 'validation/num_examples': 3554, 'test/ssim': 0.7417327616674811, 'test/loss': 0.2881057428201794, 'test/num_examples': 3581, 'score': 1194.304592847824, 'total_duration': 1419.3973271846771, 'accumulated_submission_time': 1194.304592847824, 'accumulated_eval_time': 224.75955891609192, 'accumulated_logging_time': 0.2691810131072998}
I0428 21:35:16.476170 140072330438400 logging_writer.py:48] [4438] accumulated_eval_time=224.759559, accumulated_logging_time=0.269181, accumulated_submission_time=1194.304593, global_step=4438, preemption_count=0, score=1194.304593, test/loss=0.288106, test/num_examples=3581, test/ssim=0.741733, total_duration=1419.397327, train/loss=0.270689, train/ssim=0.747859, validation/loss=0.286731, validation/num_examples=3554, validation/ssim=0.724553
I0428 21:35:31.595797 140072322045696 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.09265530854463577, loss=0.26876020431518555
I0428 21:35:57.435074 140072330438400 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.07525726407766342, loss=0.2864670753479004
I0428 21:36:23.376039 140072322045696 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.04918050393462181, loss=0.2456417679786682
I0428 21:36:36.622903 140278278252352 spec.py:298] Evaluating on the training split.
I0428 21:36:37.977370 140278278252352 spec.py:310] Evaluating on the validation split.
I0428 21:36:39.334456 140278278252352 spec.py:326] Evaluating on the test split.
I0428 21:36:40.691339 140278278252352 submission_runner.py:415] Time since start: 1503.62s, 	Step: 4756, 	{'train/ssim': 0.7477391106741769, 'train/loss': 0.2708656106676374, 'validation/ssim': 0.7245296892585819, 'validation/loss': 0.2866031644581809, 'validation/num_examples': 3554, 'test/ssim': 0.7417707360679628, 'test/loss': 0.2879547996915142, 'test/num_examples': 3581, 'score': 1274.4382655620575, 'total_duration': 1503.622799396515, 'accumulated_submission_time': 1274.4382655620575, 'accumulated_eval_time': 228.82794380187988, 'accumulated_logging_time': 0.2879459857940674}
I0428 21:36:40.701241 140072330438400 logging_writer.py:48] [4756] accumulated_eval_time=228.827944, accumulated_logging_time=0.287946, accumulated_submission_time=1274.438266, global_step=4756, preemption_count=0, score=1274.438266, test/loss=0.287955, test/num_examples=3581, test/ssim=0.741771, total_duration=1503.622799, train/loss=0.270866, train/ssim=0.747739, validation/loss=0.286603, validation/num_examples=3554, validation/ssim=0.724530
I0428 21:36:50.906160 140072322045696 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.09259989112615585, loss=0.30605289340019226
I0428 21:37:16.527698 140072330438400 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.08583977073431015, loss=0.3528512120246887
I0428 21:37:42.250224 140072322045696 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.05056723207235336, loss=0.26854407787323
I0428 21:38:00.811830 140278278252352 spec.py:298] Evaluating on the training split.
I0428 21:38:02.170483 140278278252352 spec.py:310] Evaluating on the validation split.
I0428 21:38:03.527596 140278278252352 spec.py:326] Evaluating on the test split.
I0428 21:38:04.886938 140278278252352 submission_runner.py:415] Time since start: 1587.82s, 	Step: 5076, 	{'train/ssim': 0.7474065508161273, 'train/loss': 0.27076307364872526, 'validation/ssim': 0.724282182597953, 'validation/loss': 0.2865323746680677, 'validation/num_examples': 3554, 'test/ssim': 0.7416463136606395, 'test/loss': 0.287786403337493, 'test/num_examples': 3581, 'score': 1354.5346808433533, 'total_duration': 1587.8184030056, 'accumulated_submission_time': 1354.5346808433533, 'accumulated_eval_time': 232.9030032157898, 'accumulated_logging_time': 0.30733299255371094}
I0428 21:38:04.897632 140072330438400 logging_writer.py:48] [5076] accumulated_eval_time=232.903003, accumulated_logging_time=0.307333, accumulated_submission_time=1354.534681, global_step=5076, preemption_count=0, score=1354.534681, test/loss=0.287786, test/num_examples=3581, test/ssim=0.741646, total_duration=1587.818403, train/loss=0.270763, train/ssim=0.747407, validation/loss=0.286532, validation/num_examples=3554, validation/ssim=0.724282
I0428 21:38:09.997685 140072322045696 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.05279337987303734, loss=0.22598370909690857
I0428 21:38:35.571449 140072330438400 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.07978355139493942, loss=0.28556686639785767
I0428 21:39:02.124009 140072322045696 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.13277000188827515, loss=0.25120314955711365
I0428 21:39:24.950687 140278278252352 spec.py:298] Evaluating on the training split.
I0428 21:39:26.307708 140278278252352 spec.py:310] Evaluating on the validation split.
I0428 21:39:27.670011 140278278252352 spec.py:326] Evaluating on the test split.
I0428 21:39:29.031367 140278278252352 submission_runner.py:415] Time since start: 1671.96s, 	Step: 5393, 	{'train/ssim': 0.7469350269862584, 'train/loss': 0.2711336442402431, 'validation/ssim': 0.7237447847056134, 'validation/loss': 0.28682188807945275, 'validation/num_examples': 3554, 'test/ssim': 0.7409279361779182, 'test/loss': 0.28819103182377476, 'test/num_examples': 3581, 'score': 1434.5748224258423, 'total_duration': 1671.9628355503082, 'accumulated_submission_time': 1434.5748224258423, 'accumulated_eval_time': 236.9836459159851, 'accumulated_logging_time': 0.3264427185058594}
I0428 21:39:29.041917 140072330438400 logging_writer.py:48] [5393] accumulated_eval_time=236.983646, accumulated_logging_time=0.326443, accumulated_submission_time=1434.574822, global_step=5393, preemption_count=0, score=1434.574822, test/loss=0.288191, test/num_examples=3581, test/ssim=0.740928, total_duration=1671.962836, train/loss=0.271134, train/ssim=0.746935, validation/loss=0.286822, validation/num_examples=3554, validation/ssim=0.723745
I0428 21:39:30.858263 140072322045696 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.08328570425510406, loss=0.33116966485977173
I0428 21:39:35.886879 140278278252352 spec.py:298] Evaluating on the training split.
I0428 21:39:37.242166 140278278252352 spec.py:310] Evaluating on the validation split.
I0428 21:39:38.605712 140278278252352 spec.py:326] Evaluating on the test split.
I0428 21:39:39.967599 140278278252352 submission_runner.py:415] Time since start: 1682.90s, 	Step: 5428, 	{'train/ssim': 0.746915340423584, 'train/loss': 0.270604065486363, 'validation/ssim': 0.7240914863753869, 'validation/loss': 0.2861252045725327, 'validation/num_examples': 3554, 'test/ssim': 0.741315997735444, 'test/loss': 0.2874502583077353, 'test/num_examples': 3581, 'score': 1441.410840511322, 'total_duration': 1682.8990046977997, 'accumulated_submission_time': 1441.410840511322, 'accumulated_eval_time': 241.06427025794983, 'accumulated_logging_time': 0.3451361656188965}
I0428 21:39:39.979410 140072330438400 logging_writer.py:48] [5428] accumulated_eval_time=241.064270, accumulated_logging_time=0.345136, accumulated_submission_time=1441.410841, global_step=5428, preemption_count=0, score=1441.410841, test/loss=0.287450, test/num_examples=3581, test/ssim=0.741316, total_duration=1682.899005, train/loss=0.270604, train/ssim=0.746915, validation/loss=0.286125, validation/num_examples=3554, validation/ssim=0.724091
I0428 21:39:39.996354 140072322045696 logging_writer.py:48] [5428] global_step=5428, preemption_count=0, score=1441.410841
I0428 21:39:40.225208 140278278252352 checkpoints.py:356] Saving checkpoint at step: 5428
I0428 21:39:41.146841 140278278252352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_fancy/timing_shampoo/fastmri_jax/trial_1/checkpoint_5428
I0428 21:39:41.164510 140278278252352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_fancy/timing_shampoo/fastmri_jax/trial_1/checkpoint_5428.
I0428 21:39:41.965819 140278278252352 submission_runner.py:578] Tuning trial 1/1
I0428 21:39:41.966114 140278278252352 submission_runner.py:579] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.07758862577375368, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0428 21:39:41.971467 140278278252352 submission_runner.py:580] Metrics: {'eval_results': [(1, {'train/ssim': 0.2534253937857492, 'train/loss': 1.0028910636901855, 'validation/ssim': 0.24635640382095877, 'validation/loss': 1.0001127965408694, 'validation/num_examples': 3554, 'test/ssim': 0.26854149531599064, 'test/loss': 0.9966813646458741, 'test/num_examples': 3581, 'score': 69.79099154472351, 'total_duration': 232.99575233459473, 'accumulated_submission_time': 69.79099154472351, 'accumulated_eval_time': 163.20459294319153, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (314, {'train/ssim': 0.7280290467398507, 'train/loss': 0.2898177078792027, 'validation/ssim': 0.7073808368431697, 'validation/loss': 0.30326579646173324, 'validation/num_examples': 3554, 'test/ssim': 0.7243597120654147, 'test/loss': 0.3054534307041504, 'test/num_examples': 3581, 'score': 149.9349136352539, 'total_duration': 317.5519587993622, 'accumulated_submission_time': 149.9349136352539, 'accumulated_eval_time': 167.5851972103119, 'accumulated_logging_time': 0.02743840217590332, 'global_step': 314, 'preemption_count': 0}), (624, {'train/ssim': 0.7319320269993373, 'train/loss': 0.2832962615149362, 'validation/ssim': 0.7114859577236916, 'validation/loss': 0.2970216286336698, 'validation/num_examples': 3554, 'test/ssim': 0.728477991482826, 'test/loss': 0.2988011270420274, 'test/num_examples': 3581, 'score': 229.99089360237122, 'total_duration': 401.69362473487854, 'accumulated_submission_time': 229.99089360237122, 'accumulated_eval_time': 171.64941453933716, 'accumulated_logging_time': 0.04468250274658203, 'global_step': 624, 'preemption_count': 0}), (932, {'train/ssim': 0.738248484475272, 'train/loss': 0.2786785875047956, 'validation/ssim': 0.7159468479618036, 'validation/loss': 0.2932534204417558, 'validation/num_examples': 3554, 'test/ssim': 0.7330769845408056, 'test/loss': 0.29492582924636973, 'test/num_examples': 3581, 'score': 310.21177554130554, 'total_duration': 488.59380316734314, 'accumulated_submission_time': 310.21177554130554, 'accumulated_eval_time': 178.30659794807434, 'accumulated_logging_time': 0.06263327598571777, 'global_step': 932, 'preemption_count': 0}), (1249, {'train/ssim': 0.7391380582536969, 'train/loss': 0.27761546203068327, 'validation/ssim': 0.7175683841050576, 'validation/loss': 0.29206850720578925, 'validation/num_examples': 3554, 'test/ssim': 0.7346481157061575, 'test/loss': 0.2936299613520141, 'test/num_examples': 3581, 'score': 390.4075195789337, 'total_duration': 572.8915722370148, 'accumulated_submission_time': 390.4075195789337, 'accumulated_eval_time': 182.38429498672485, 'accumulated_logging_time': 0.08227324485778809, 'global_step': 1249, 'preemption_count': 0}), (1570, {'train/ssim': 0.7428384508405413, 'train/loss': 0.2760439089366368, 'validation/ssim': 0.7206814861995287, 'validation/loss': 0.29091361351206385, 'validation/num_examples': 3554, 'test/ssim': 0.7379160276240925, 'test/loss': 0.29236750002181655, 'test/num_examples': 3581, 'score': 470.65275144577026, 'total_duration': 657.2330589294434, 'accumulated_submission_time': 470.65275144577026, 'accumulated_eval_time': 186.45787739753723, 'accumulated_logging_time': 0.10025262832641602, 'global_step': 1570, 'preemption_count': 0}), (1891, {'train/ssim': 0.7426044600350517, 'train/loss': 0.2750907114573887, 'validation/ssim': 0.7201960901229248, 'validation/loss': 0.28983462735649973, 'validation/num_examples': 3554, 'test/ssim': 0.7373810453609327, 'test/loss': 0.2913760409212685, 'test/num_examples': 3581, 'score': 550.8227610588074, 'total_duration': 741.4968674182892, 'accumulated_submission_time': 550.8227610588074, 'accumulated_eval_time': 190.52798438072205, 'accumulated_logging_time': 0.11941003799438477, 'global_step': 1891, 'preemption_count': 0}), (2210, {'train/ssim': 0.7451058796473912, 'train/loss': 0.2734111377171108, 'validation/ssim': 0.7221615801517656, 'validation/loss': 0.28901032644775254, 'validation/num_examples': 3554, 'test/ssim': 0.7393861891536931, 'test/loss': 0.29039835350635296, 'test/num_examples': 3581, 'score': 631.0138018131256, 'total_duration': 827.4122841358185, 'accumulated_submission_time': 631.0138018131256, 'accumulated_eval_time': 196.2298400402069, 'accumulated_logging_time': 0.13727998733520508, 'global_step': 2210, 'preemption_count': 0}), (2528, {'train/ssim': 0.7436110632760184, 'train/loss': 0.27296476704733713, 'validation/ssim': 0.7206109368405318, 'validation/loss': 0.28817400398318793, 'validation/num_examples': 3554, 'test/ssim': 0.7379682509468375, 'test/loss': 0.28959536878665176, 'test/num_examples': 3581, 'score': 711.1160893440247, 'total_duration': 911.6115610599518, 'accumulated_submission_time': 711.1160893440247, 'accumulated_eval_time': 200.30405735969543, 'accumulated_logging_time': 0.15534329414367676, 'global_step': 2528, 'preemption_count': 0}), (2843, {'train/ssim': 0.7448797225952148, 'train/loss': 0.27290364674159456, 'validation/ssim': 0.7223862115090391, 'validation/loss': 0.2879233030234419, 'validation/num_examples': 3554, 'test/ssim': 0.7396970065536861, 'test/loss': 0.28928973281293635, 'test/num_examples': 3581, 'score': 791.1127367019653, 'total_duration': 995.7082159519196, 'accumulated_submission_time': 791.1127367019653, 'accumulated_eval_time': 204.3792314529419, 'accumulated_logging_time': 0.175506591796875, 'global_step': 2843, 'preemption_count': 0}), (3161, {'train/ssim': 0.7450051307678223, 'train/loss': 0.27232517514910015, 'validation/ssim': 0.7219389409380276, 'validation/loss': 0.2880120907999789, 'validation/num_examples': 3554, 'test/ssim': 0.7392915599474658, 'test/loss': 0.28938770267557945, 'test/num_examples': 3581, 'score': 871.681554555893, 'total_duration': 1080.3810210227966, 'accumulated_submission_time': 871.681554555893, 'accumulated_eval_time': 208.4606637954712, 'accumulated_logging_time': 0.1935265064239502, 'global_step': 3161, 'preemption_count': 0}), (3481, {'train/ssim': 0.7471211978367397, 'train/loss': 0.27147730759211947, 'validation/ssim': 0.7239060796373804, 'validation/loss': 0.2872388299825021, 'validation/num_examples': 3554, 'test/ssim': 0.7411816215355348, 'test/loss': 0.28858550198748606, 'test/num_examples': 3581, 'score': 952.4871723651886, 'total_duration': 1165.2857434749603, 'accumulated_submission_time': 952.4871723651886, 'accumulated_eval_time': 212.53544640541077, 'accumulated_logging_time': 0.2132124900817871, 'global_step': 3481, 'preemption_count': 0}), (3801, {'train/ssim': 0.746438707624163, 'train/loss': 0.2713907446180071, 'validation/ssim': 0.7232772492262239, 'validation/loss': 0.28689614694710186, 'validation/num_examples': 3554, 'test/ssim': 0.7405801670273666, 'test/loss': 0.2882779570672473, 'test/num_examples': 3581, 'score': 1033.2127981185913, 'total_duration': 1250.11008477211, 'accumulated_submission_time': 1033.2127981185913, 'accumulated_eval_time': 216.61028122901917, 'accumulated_logging_time': 0.23240995407104492, 'global_step': 3801, 'preemption_count': 0}), (4121, {'train/ssim': 0.7465189525059291, 'train/loss': 0.271469031061445, 'validation/ssim': 0.7239271001864097, 'validation/loss': 0.2868824595471212, 'validation/num_examples': 3554, 'test/ssim': 0.7411461014948687, 'test/loss': 0.2881811802961812, 'test/num_examples': 3581, 'score': 1114.1549932956696, 'total_duration': 1335.1526548862457, 'accumulated_submission_time': 1114.1549932956696, 'accumulated_eval_time': 220.68770384788513, 'accumulated_logging_time': 0.2506687641143799, 'global_step': 4121, 'preemption_count': 0}), (4438, {'train/ssim': 0.747859001159668, 'train/loss': 0.2706887722015381, 'validation/ssim': 0.72455304542417, 'validation/loss': 0.2867308849019151, 'validation/num_examples': 3554, 'test/ssim': 0.7417327616674811, 'test/loss': 0.2881057428201794, 'test/num_examples': 3581, 'score': 1194.304592847824, 'total_duration': 1419.3973271846771, 'accumulated_submission_time': 1194.304592847824, 'accumulated_eval_time': 224.75955891609192, 'accumulated_logging_time': 0.2691810131072998, 'global_step': 4438, 'preemption_count': 0}), (4756, {'train/ssim': 0.7477391106741769, 'train/loss': 0.2708656106676374, 'validation/ssim': 0.7245296892585819, 'validation/loss': 0.2866031644581809, 'validation/num_examples': 3554, 'test/ssim': 0.7417707360679628, 'test/loss': 0.2879547996915142, 'test/num_examples': 3581, 'score': 1274.4382655620575, 'total_duration': 1503.622799396515, 'accumulated_submission_time': 1274.4382655620575, 'accumulated_eval_time': 228.82794380187988, 'accumulated_logging_time': 0.2879459857940674, 'global_step': 4756, 'preemption_count': 0}), (5076, {'train/ssim': 0.7474065508161273, 'train/loss': 0.27076307364872526, 'validation/ssim': 0.724282182597953, 'validation/loss': 0.2865323746680677, 'validation/num_examples': 3554, 'test/ssim': 0.7416463136606395, 'test/loss': 0.287786403337493, 'test/num_examples': 3581, 'score': 1354.5346808433533, 'total_duration': 1587.8184030056, 'accumulated_submission_time': 1354.5346808433533, 'accumulated_eval_time': 232.9030032157898, 'accumulated_logging_time': 0.30733299255371094, 'global_step': 5076, 'preemption_count': 0}), (5393, {'train/ssim': 0.7469350269862584, 'train/loss': 0.2711336442402431, 'validation/ssim': 0.7237447847056134, 'validation/loss': 0.28682188807945275, 'validation/num_examples': 3554, 'test/ssim': 0.7409279361779182, 'test/loss': 0.28819103182377476, 'test/num_examples': 3581, 'score': 1434.5748224258423, 'total_duration': 1671.9628355503082, 'accumulated_submission_time': 1434.5748224258423, 'accumulated_eval_time': 236.9836459159851, 'accumulated_logging_time': 0.3264427185058594, 'global_step': 5393, 'preemption_count': 0}), (5428, {'train/ssim': 0.746915340423584, 'train/loss': 0.270604065486363, 'validation/ssim': 0.7240914863753869, 'validation/loss': 0.2861252045725327, 'validation/num_examples': 3554, 'test/ssim': 0.741315997735444, 'test/loss': 0.2874502583077353, 'test/num_examples': 3581, 'score': 1441.410840511322, 'total_duration': 1682.8990046977997, 'accumulated_submission_time': 1441.410840511322, 'accumulated_eval_time': 241.06427025794983, 'accumulated_logging_time': 0.3451361656188965, 'global_step': 5428, 'preemption_count': 0})], 'global_step': 5428}
I0428 21:39:41.971621 140278278252352 submission_runner.py:581] Timing: 1441.410840511322
I0428 21:39:41.971678 140278278252352 submission_runner.py:582] ====================
I0428 21:39:41.971810 140278278252352 submission_runner.py:645] Final fastmri score: 1441.410840511322
