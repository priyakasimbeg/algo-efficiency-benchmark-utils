torchrun --redirects 1:0,2:0,3:0,4:0,5:0,6:0,7:0 --standalone --nnodes=1 --nproc_per_node=8 submission_runner.py --framework=pytorch --workload=fastmri --submission_path=baselines/adamw/pytorch/submission.py --tuning_search_space=baselines/adamw/tuning_search_space.json --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_prelaunch/adamw --overwrite=true --save_checkpoints=false --max_global_steps=2714 --torch_compile=true 2>&1 | tee -a /logs/fastmri_pytorch_09-26-2023-05-13-12.log
master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-09-26 05:13:22.160357: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-26 05:13:22.160365: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-26 05:13:22.160363: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-26 05:13:22.160362: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-26 05:13:22.160357: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-26 05:13:22.160368: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-26 05:13:22.160368: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-26 05:13:22.160373: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0926 05:13:36.735491 139998102861632 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 5
I0926 05:13:36.735522 140014307419968 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 4
I0926 05:13:36.735550 140504990574400 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
I0926 05:13:36.736649 140143531374400 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 6
I0926 05:13:36.737125 140143531374400 distributed_c10d.py:476] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0926 05:13:36.736775 140142999553856 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
I0926 05:13:36.737001 139919823263552 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
I0926 05:13:36.736946 140312334493504 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 7
I0926 05:13:36.737126 140589296052032 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
I0926 05:13:36.737447 140142999553856 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0926 05:13:36.737525 139919823263552 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0926 05:13:36.737570 140312334493504 distributed_c10d.py:476] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0926 05:13:36.737646 140589296052032 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0926 05:13:36.746344 139998102861632 distributed_c10d.py:476] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0926 05:13:36.746368 140014307419968 distributed_c10d.py:476] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0926 05:13:36.746385 140504990574400 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0926 05:13:37.073362 139919823263552 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_prelaunch/adamw/fastmri_pytorch.
W0926 05:13:37.114871 139998102861632 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0926 05:13:37.114899 140504990574400 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0926 05:13:37.115379 140143531374400 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0926 05:13:37.115602 139919823263552 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0926 05:13:37.115765 140589296052032 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0926 05:13:37.115802 140142999553856 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0926 05:13:37.115954 140312334493504 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0926 05:13:37.116172 140014307419968 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0926 05:13:37.121618 139919823263552 submission_runner.py:507] Using RNG seed 2637780342
I0926 05:13:37.123900 139919823263552 submission_runner.py:516] --- Tuning run 1/1 ---
I0926 05:13:37.124031 139919823263552 submission_runner.py:521] Creating tuning directory at /experiment_runs/timing_prelaunch/adamw/fastmri_pytorch/trial_1.
I0926 05:13:37.124597 139919823263552 logger_utils.py:92] Saving hparams to /experiment_runs/timing_prelaunch/adamw/fastmri_pytorch/trial_1/hparams.json.
I0926 05:13:37.125409 139919823263552 submission_runner.py:191] Initializing dataset.
I0926 05:13:37.125525 139919823263552 submission_runner.py:198] Initializing model.
I0926 05:13:41.615537 139919823263552 submission_runner.py:229] Performing `torch.compile`.
I0926 05:13:41.892019 139919823263552 submission_runner.py:232] Initializing optimizer.
I0926 05:13:41.892851 139919823263552 submission_runner.py:239] Initializing metrics bundle.
I0926 05:13:41.892949 139919823263552 submission_runner.py:257] Initializing checkpoint and logger.
I0926 05:13:41.893500 139919823263552 submission_runner.py:277] Saving meta data to /experiment_runs/timing_prelaunch/adamw/fastmri_pytorch/trial_1/meta_data_0.json.
I0926 05:13:41.893729 139919823263552 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0926 05:13:41.893793 139919823263552 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
I0926 05:13:42.343639 139919823263552 submission_runner.py:280] Saving flags to /experiment_runs/timing_prelaunch/adamw/fastmri_pytorch/trial_1/flags_0.json.
I0926 05:13:42.431902 139919823263552 submission_runner.py:290] Starting training loop.
[2023-09-26 05:13:42,454] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:13:42,454] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:13:42,454] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:13:42,454] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:13:42,454] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:13:42,454] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:13:42,454] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:13:42,748] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __iter__
[2023-09-26 05:13:42,748] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __iter__
[2023-09-26 05:13:42,748] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __iter__
[2023-09-26 05:13:42,749] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __iter__
[2023-09-26 05:13:42,749] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __iter__
[2023-09-26 05:13:42,753] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:13:42,753] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:13:42,754] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:13:42,754] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:13:42,754] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:13:42,755] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __iter__
[2023-09-26 05:13:42,759] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __iter__
[2023-09-26 05:13:42,760] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:13:42,764] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:13:42,794] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:13:42,794] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:13:42,795] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:13:42,795] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:13:42,795] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:13:42,796] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:13:42,796] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:13:42,797] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:13:42,797] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:13:42,797] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:13:42,797] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:13:42,797] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:13:42,797] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:13:42,797] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:13:42,797] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:13:42,797] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:13:42,797] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:13:42,797] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:13:42,797] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:13:42,797] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:13:42,803] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:13:42,805] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:13:42,805] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:13:42,806] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:13:42,808] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:13:42,810] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:13:42,810] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:13:42,811] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:13:47,522] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-26 05:13:47,523] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-26 05:13:47,523] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-26 05:13:47,523] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-26 05:13:47,524] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-26 05:13:47,525] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-26 05:13:47,528] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-26 05:14:28,708] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:28,753] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-26 05:14:28,753] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-26 05:14:28,753] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-26 05:14:28,754] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-26 05:14:28,754] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-26 05:14:28,754] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:28,754] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:28,754] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:28,755] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-26 05:14:28,755] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:28,755] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-26 05:14:28,755] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:28,756] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:28,756] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:29,144] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __iter__
[2023-09-26 05:14:29,150] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:29,206] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:29,208] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:29,208] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:29,209] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:32,386] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:32,388] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:32,394] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:32,437] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:32,437] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:32,439] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:32,439] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:32,440] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:32,440] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:32,440] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:32,441] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:32,443] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:32,446] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:32,446] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:32,446] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:32,456] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:32,464] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:32,486] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:32,506] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:32,509] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:32,509] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:32,510] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:32,513] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:32,516] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:32,516] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:32,517] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:32,535] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:32,538] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:32,538] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:32,539] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:32,544] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:32,596] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:32,598] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:32,599] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:32,599] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:32,902] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-26 05:14:32,903] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-26 05:14:32,907] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-26 05:14:32,967] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-26 05:14:32,969] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-26 05:14:33,022] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-26 05:14:33,090] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-26 05:14:34,495] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-26 05:14:34,496] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:34,510] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-26 05:14:34,511] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:34,555] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:34,560] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-26 05:14:34,561] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:34,570] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:34,577] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-26 05:14:34,577] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:34,592] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-26 05:14:34,593] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:34,602] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:34,604] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:34,605] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:34,605] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:34,617] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:34,619] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:34,620] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:34,620] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:34,621] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:34,646] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:34,669] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:34,671] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:34,671] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:34,671] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:34,672] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:34,692] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:34,694] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:34,694] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:34,695] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:34,716] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:34,718] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:34,719] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:34,719] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:34,759] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-26 05:14:34,760] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:34,814] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:34,851] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-26 05:14:34,852] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:34,859] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:34,862] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:34,862] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:34,862] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:34,908] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:34,954] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:34,956] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:34,956] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:34,957] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:35,065] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-26 05:14:35,081] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-26 05:14:35,123] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-26 05:14:35,145] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-26 05:14:35,167] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-26 05:14:35,304] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-26 05:14:35,432] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-26 05:14:35,955] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-26 05:14:35,956] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:35,966] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-26 05:14:35,967] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:36,017] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:36,025] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-26 05:14:36,026] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:36,028] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:36,046] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-26 05:14:36,046] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:36,063] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:36,064] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-26 05:14:36,065] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:36,065] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:36,065] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:36,066] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:36,074] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:36,076] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:36,077] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:36,077] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:36,089] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:36,109] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:36,125] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:36,133] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:36,135] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:36,135] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:36,136] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:36,148] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-26 05:14:36,153] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:36,156] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:36,156] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:36,156] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:36,169] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:36,171] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:36,172] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:36,172] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:36,204] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-26 05:14:36,205] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:36,263] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:36,306] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:36,308] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:36,308] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:36,308] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:36,313] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-26 05:14:36,322] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-26 05:14:36,371] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-26 05:14:36,372] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:36,376] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-26 05:14:36,400] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-26 05:14:36,411] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-26 05:14:36,430] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:36,479] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:36,481] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:36,481] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:36,481] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:36,542] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-26 05:14:36,730] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-26 05:14:37,074] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-26 05:14:37,078] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-26 05:14:37,140] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-26 05:14:37,167] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-26 05:14:37,172] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-26 05:14:37,322] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-26 05:14:37,350] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-26 05:14:37,363] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-26 05:14:37,418] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-26 05:14:37,447] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-26 05:14:37,484] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-26 05:14:37,551] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-26 05:14:37,556] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-26 05:14:37,563] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-26 05:14:37,574] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:37,581] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:37,595] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-26 05:14:37,618] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-26 05:14:37,643] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:37,646] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:37,650] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:37,650] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-26 05:14:37,669] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:37,694] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:37,694] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-26 05:14:37,696] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:37,697] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:37,697] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:37,700] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:37,702] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:37,702] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:37,703] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:37,705] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:37,712] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:37,731] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:37,756] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:37,759] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:37,759] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:37,760] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:37,768] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:37,781] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:37,784] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:37,784] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:37,785] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:37,796] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-26 05:14:37,813] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:37,819] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:37,821] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:37,821] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:37,822] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:37,833] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-26 05:14:37,868] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:37,915] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:37,917] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:37,917] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:37,918] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:37,960] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-26 05:14:37,965] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-26 05:14:38,023] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-26 05:14:38,031] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-26 05:14:38,049] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:38,051] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-26 05:14:38,086] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-26 05:14:38,105] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:38,153] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:38,155] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:38,155] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:38,156] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:38,176] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-26 05:14:38,197] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-26 05:14:38,198] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:38,434] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-26 05:14:38,974] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-26 05:14:38,984] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-26 05:14:39,049] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-26 05:14:39,078] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-26 05:14:39,108] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-26 05:14:39,204] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-26 05:14:39,240] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-26 05:14:39,269] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-26 05:14:39,308] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-26 05:14:39,332] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-26 05:14:39,367] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-26 05:14:39,427] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-26 05:14:39,443] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:39,455] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-26 05:14:39,460] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-26 05:14:39,471] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:39,502] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-26 05:14:39,503] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-26 05:14:39,503] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:39,518] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-26 05:14:39,518] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:39,526] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:39,528] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:39,528] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:39,528] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:39,534] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:39,538] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:39,554] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-26 05:14:39,561] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:39,562] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:39,563] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:39,563] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:39,571] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:39,589] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:39,595] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:39,611] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:39,613] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:39,613] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:39,613] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:39,617] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:39,619] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:39,619] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:39,619] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:39,631] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:39,649] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-26 05:14:39,657] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:39,659] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:39,659] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:39,659] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:39,676] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:39,755] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:39,776] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-26 05:14:39,779] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-26 05:14:39,790] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:39,793] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:39,793] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:39,794] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:39,816] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-26 05:14:39,868] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-26 05:14:39,870] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-26 05:14:39,921] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-26 05:14:39,980] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-26 05:14:39,999] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:40,009] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-26 05:14:40,010] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:40,020] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-26 05:14:40,021] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:40,060] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-26 05:14:40,078] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-26 05:14:40,078] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:40,080] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:40,089] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-26 05:14:40,090] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:40,106] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:40,108] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:40,108] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:40,109] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:40,123] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:40,123] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:40,150] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:40,170] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:40,172] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:40,172] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-26 05:14:40,173] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:40,173] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:40,174] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:40,174] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:40,175] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:40,176] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:40,177] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:40,177] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:40,199] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:40,201] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:40,202] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:40,202] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:40,222] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:40,224] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:40,225] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:40,225] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:40,248] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:40,291] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-26 05:14:40,292] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:40,309] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:40,312] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:40,312] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:40,312] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:40,366] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:40,369] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-26 05:14:40,417] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:40,419] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:40,420] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:40,420] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:40,433] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-26 05:14:40,447] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-26 05:14:40,460] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-26 05:14:40,476] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-26 05:14:40,559] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-26 05:14:40,567] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-26 05:14:40,568] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:40,620] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-26 05:14:40,637] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:40,637] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-26 05:14:40,647] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-26 05:14:40,672] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-26 05:14:40,685] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:40,687] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:40,688] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:40,688] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:40,694] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-26 05:14:40,748] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-26 05:14:40,863] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-26 05:14:40,874] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-26 05:14:40,893] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-26 05:14:40,905] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-26 05:14:40,946] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-26 05:14:40,957] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-26 05:14:41,000] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-26 05:14:41,008] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-26 05:14:41,017] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:41,023] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-26 05:14:41,034] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-26 05:14:41,040] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:41,050] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:41,070] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-26 05:14:41,078] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:41,086] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:41,098] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:41,100] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:41,100] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:41,100] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:41,115] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-26 05:14:41,118] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:41,118] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:41,130] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-26 05:14:41,139] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:41,139] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:41,141] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:41,141] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:41,141] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:41,141] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:41,141] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:41,141] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:41,145] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:41,149] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:41,151] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-26 05:14:41,171] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:41,172] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:41,173] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:41,173] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:41,199] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:41,221] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:41,222] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:41,222] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:41,223] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:41,239] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-26 05:14:41,255] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:41,309] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:41,329] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-26 05:14:41,330] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:41,331] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:41,332] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:41,332] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:41,370] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-26 05:14:41,374] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-26 05:14:41,401] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-26 05:14:41,433] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-26 05:14:41,458] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-26 05:14:41,545] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-26 05:14:41,546] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:41,570] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-26 05:14:41,575] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-26 05:14:41,583] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-26 05:14:41,584] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:41,585] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-26 05:14:41,586] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:41,587] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:41,614] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-26 05:14:41,614] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:41,637] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:41,651] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:41,669] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-26 05:14:41,670] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:41,674] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:41,676] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:41,676] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:41,677] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:41,681] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:41,683] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:41,683] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:41,683] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:41,704] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:41,705] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:41,705] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:41,748] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:41,768] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:41,771] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:41,771] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:41,772] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:41,772] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:41,772] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:41,774] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:41,775] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:41,775] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:41,775] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:41,775] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:41,776] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:41,784] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-26 05:14:41,785] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:41,795] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:41,798] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:41,798] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:41,798] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:41,851] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:41,893] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:41,896] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:41,898] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:41,898] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:41,899] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:41,926] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-26 05:14:41,975] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:41,978] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:41,979] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:41,981] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:42,133] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-26 05:14:42,134] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:42,155] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-26 05:14:42,201] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:42,245] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:42,247] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:42,248] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:42,248] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:42,256] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-26 05:14:42,264] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-26 05:14:42,272] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-26 05:14:42,286] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-26 05:14:42,348] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-26 05:14:42,451] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-26 05:14:42,452] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:42,504] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:42,526] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:42,529] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:42,529] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:42,530] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:42,530] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-26 05:14:42,531] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:42,559] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-26 05:14:42,559] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:42,566] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-26 05:14:42,570] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-26 05:14:42,570] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:42,596] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:42,598] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-26 05:14:42,599] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:42,616] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:42,618] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:42,618] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:42,618] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:42,625] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-26 05:14:42,626] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:42,632] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:42,633] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:42,653] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:42,654] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:42,654] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:42,655] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:42,655] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:42,656] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:42,656] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:42,656] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:42,664] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:42,678] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:42,687] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:42,688] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:42,689] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:42,689] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:42,699] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:42,700] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:42,700] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:42,701] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:42,733] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-26 05:14:42,783] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-26 05:14:42,845] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-26 05:14:42,882] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-26 05:14:42,883] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-26 05:14:42,925] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-26 05:14:42,931] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-26 05:14:42,979] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-26 05:14:42,979] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:43,025] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-26 05:14:43,026] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:43,038] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-26 05:14:43,038] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:43,063] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:43,084] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-26 05:14:43,084] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:43,106] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:43,107] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:43,109] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:43,109] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:43,109] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:43,112] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-26 05:14:43,113] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:43,129] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-26 05:14:43,130] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:43,131] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:43,132] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:43,134] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:43,134] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:43,135] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:43,143] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-26 05:14:43,143] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:43,169] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:43,174] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:43,177] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:43,177] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:43,178] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:43,201] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:43,210] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:43,212] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:43,215] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:43,215] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:43,215] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:43,225] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:43,251] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:43,253] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:43,254] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:43,254] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:43,255] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:43,257] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:43,258] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:43,258] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:43,271] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:43,273] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:43,274] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:43,274] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:43,385] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-26 05:14:43,557] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-26 05:14:43,590] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-26 05:14:43,591] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:43,618] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-26 05:14:43,662] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-26 05:14:43,672] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:43,709] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-26 05:14:43,720] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:43,723] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:43,723] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:43,723] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:43,733] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-26 05:14:43,743] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-26 05:14:43,846] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-26 05:14:43,846] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:43,898] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:43,899] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-26 05:14:43,900] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:43,921] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:43,923] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:43,923] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:43,923] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:43,951] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:43,951] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-26 05:14:43,952] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:43,976] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:43,978] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:43,978] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:43,978] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:44,001] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-26 05:14:44,002] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:44,004] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:44,021] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-26 05:14:44,022] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:44,030] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:44,032] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:44,032] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:44,032] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:44,042] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-26 05:14:44,043] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:44,054] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:44,073] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:44,077] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:44,079] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:44,079] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:44,080] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:44,095] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:44,096] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:44,098] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:44,098] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:44,098] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:44,120] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:44,122] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:44,122] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:44,122] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:44,167] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-26 05:14:44,197] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-26 05:14:44,217] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-26 05:14:44,271] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-26 05:14:44,320] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-26 05:14:44,337] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-26 05:14:44,374] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-26 05:14:44,383] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-26 05:14:44,384] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:44,419] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-26 05:14:44,419] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:44,447] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:44,469] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-26 05:14:44,469] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:44,494] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-26 05:14:44,494] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:44,507] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-26 05:14:44,508] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:44,513] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:44,515] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:44,516] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:44,516] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:44,554] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:44,555] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:44,578] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-26 05:14:44,579] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:44,579] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:44,581] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:44,582] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:44,582] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:44,597] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-26 05:14:44,597] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:44,611] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:44,616] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:44,618] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:44,618] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:44,619] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:44,621] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-26 05:14:44,621] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:44,646] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:44,661] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:44,664] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:44,664] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:44,664] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:44,696] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:44,698] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:44,698] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:44,699] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:44,717] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:44,729] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:44,759] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:44,767] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:44,769] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:44,769] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:44,770] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:44,779] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:44,781] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:44,781] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:44,782] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:44,811] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:44,814] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:44,814] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:44,814] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:44,834] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-26 05:14:45,126] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-26 05:14:45,165] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-26 05:14:45,165] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:45,181] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-26 05:14:45,189] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-26 05:14:45,232] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-26 05:14:45,257] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-26 05:14:45,269] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-26 05:14:45,299] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:45,311] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-26 05:14:45,352] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:45,354] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:45,355] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:45,355] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:45,845] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-26 05:14:45,845] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-26 05:14:45,846] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:45,846] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:45,871] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-26 05:14:45,887] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-26 05:14:45,887] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:45,916] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-26 05:14:45,917] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:45,954] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-26 05:14:45,955] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:45,960] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 15
[2023-09-26 05:14:45,962] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 15
[2023-09-26 05:14:45,977] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 15
[2023-09-26 05:14:45,994] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-26 05:14:45,994] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:46,010] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 15
[2023-09-26 05:14:46,035] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 15
[2023-09-26 05:14:46,072] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 15
[2023-09-26 05:14:46,449] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-26 05:14:46,450] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:46,531] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:46,597] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-26 05:14:46,598] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:46,635] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:46,640] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:46,641] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:46,641] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:46,695] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 15
[2023-09-26 05:14:47,017] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-26 05:14:48,328] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-26 05:14:48,774] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-26 05:14:48,989] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-26 05:14:49,014] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:49,073] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:49,139] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:49,141] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:49,142] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:49,142] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:49,439] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-26 05:14:51,373] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-26 05:14:51,699] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-26 05:14:51,895] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-26 05:14:51,918] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:51,981] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:52,010] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:52,012] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:52,012] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:52,013] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:52,318] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-26 05:14:52,522] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-26 05:14:52,523] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:52,592] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:52,651] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:52,653] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:52,654] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:52,654] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:52,952] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-26 05:14:53,148] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-26 05:14:53,473] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-26 05:14:53,602] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-26 05:14:53,624] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:53,679] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:53,705] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:53,707] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:53,707] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:53,708] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:54,003] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-26 05:14:54,216] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-26 05:14:54,217] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:54,281] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:54,339] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:54,341] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:54,341] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:54,342] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:54,908] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-26 05:14:55,198] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-26 05:14:55,199] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:55,252] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:55,285] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:55,286] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:55,286] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:55,287] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:55,577] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-26 05:14:55,817] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-26 05:14:55,817] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:55,898] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:55,956] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:55,958] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:55,959] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:55,961] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:56,529] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-26 05:14:56,853] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-26 05:14:56,854] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:56,906] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:56,936] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:56,938] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:56,938] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:56,938] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:57,216] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-26 05:14:57,475] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-26 05:14:57,476] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:57,607] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:14:57,658] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:14:57,660] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:14:57,661] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:14:57,661] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:14:58,123] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-26 05:14:59,179] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-26 05:14:59,180] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:14:59,250] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 15
[2023-09-26 05:14:59,290] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 15
[2023-09-26 05:14:59,290] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 15
[2023-09-26 05:14:59,290] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 15
[2023-09-26 05:14:59,291] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 15
[2023-09-26 05:14:59,291] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 15
[2023-09-26 05:14:59,295] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 15
[2023-09-26 05:14:59,295] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 15
[2023-09-26 05:14:59,966] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 14
[2023-09-26 05:14:59,984] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 14
[2023-09-26 05:14:59,986] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 14
[2023-09-26 05:14:59,988] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 14
[2023-09-26 05:14:59,990] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 14
[2023-09-26 05:14:59,992] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 14
[2023-09-26 05:15:00,002] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 14
[2023-09-26 05:15:00,556] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 15
[2023-09-26 05:15:00,687] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 14
[2023-09-26 05:15:00,687] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 14
[2023-09-26 05:15:00,690] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 14
[2023-09-26 05:15:00,694] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 14
[2023-09-26 05:15:00,698] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 14
[2023-09-26 05:15:00,708] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 14
[2023-09-26 05:15:00,722] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 13
[2023-09-26 05:15:00,726] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 13
[2023-09-26 05:15:00,730] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 13
[2023-09-26 05:15:00,732] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 13
[2023-09-26 05:15:00,733] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 13
[2023-09-26 05:15:00,749] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 13
[2023-09-26 05:15:00,753] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 14
[2023-09-26 05:15:00,788] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 13
[2023-09-26 05:15:00,947] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 14
[2023-09-26 05:15:01,328] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 13
[2023-09-26 05:15:01,337] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 13
[2023-09-26 05:15:01,351] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 13
[2023-09-26 05:15:01,377] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 13
[2023-09-26 05:15:01,422] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 13
[2023-09-26 05:15:01,425] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 13
[2023-09-26 05:15:01,459] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 13
[2023-09-26 05:15:01,647] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 12
[2023-09-26 05:15:01,772] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 12
[2023-09-26 05:15:01,817] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 12
[2023-09-26 05:15:01,826] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 12
[2023-09-26 05:15:01,832] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 12
[2023-09-26 05:15:01,851] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 11
[2023-09-26 05:15:01,901] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 12
[2023-09-26 05:15:01,913] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 12
[2023-09-26 05:15:01,913] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 12
[2023-09-26 05:15:01,932] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 12
[2023-09-26 05:15:01,939] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 12
[2023-09-26 05:15:01,945] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 12
[2023-09-26 05:15:01,989] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 11
[2023-09-26 05:15:01,990] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 11
[2023-09-26 05:15:01,990] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 11
[2023-09-26 05:15:02,012] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 12
[2023-09-26 05:15:02,026] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 12
[2023-09-26 05:15:02,029] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 12
[2023-09-26 05:15:02,046] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 11
[2023-09-26 05:15:02,065] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 11
[2023-09-26 05:15:02,066] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 11
[2023-09-26 05:15:02,374] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 14
[2023-09-26 05:15:02,408] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 13
[2023-09-26 05:15:02,526] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 11
[2023-09-26 05:15:02,527] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 11
[2023-09-26 05:15:02,570] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 11
[2023-09-26 05:15:02,761] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 11
[2023-09-26 05:15:02,858] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 10
[2023-09-26 05:15:02,862] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 10
[2023-09-26 05:15:02,874] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 10
[2023-09-26 05:15:02,913] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 11
[2023-09-26 05:15:03,010] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 11
[2023-09-26 05:15:03,046] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 11
[2023-09-26 05:15:03,147] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 10
[2023-09-26 05:15:03,254] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 10
[2023-09-26 05:15:03,303] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 13
[2023-09-26 05:15:03,319] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 10
[2023-09-26 05:15:03,323] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 10
[2023-09-26 05:15:03,333] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 10
[2023-09-26 05:15:03,512] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 10
[2023-09-26 05:15:03,529] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 9
[2023-09-26 05:15:03,529] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 9
[2023-09-26 05:15:03,529] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 9
[2023-09-26 05:15:03,530] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 9
[2023-09-26 05:15:03,550] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 10
[2023-09-26 05:15:03,550] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 10
[2023-09-26 05:15:03,616] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 10
[2023-09-26 05:15:03,653] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 10
[2023-09-26 05:15:03,653] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 10
[2023-09-26 05:15:03,799] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 9
[2023-09-26 05:15:03,805] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 9
[2023-09-26 05:15:03,805] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 9
[2023-09-26 05:15:03,862] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 12
[2023-09-26 05:15:03,925] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 9
[2023-09-26 05:15:03,925] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 9
[2023-09-26 05:15:03,955] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 9
[2023-09-26 05:15:03,955] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 9
[2023-09-26 05:15:03,972] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 12
[2023-09-26 05:15:03,982] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 8
[2023-09-26 05:15:03,991] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 8
[2023-09-26 05:15:04,012] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 11
[2023-09-26 05:15:04,020] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 8
[2023-09-26 05:15:04,023] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 8
[2023-09-26 05:15:04,087] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 8
[2023-09-26 05:15:04,097] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 8
[2023-09-26 05:15:04,127] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 8
[2023-09-26 05:15:04,132] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 8
[2023-09-26 05:15:04,205] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 9
[2023-09-26 05:15:04,205] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 9
[2023-09-26 05:15:04,208] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 9
[2023-09-26 05:15:04,209] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 7
[2023-09-26 05:15:04,226] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 7
[2023-09-26 05:15:04,262] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 7
[2023-09-26 05:15:04,275] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 7
[2023-09-26 05:15:04,306] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 8
[2023-09-26 05:15:04,307] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 8
[2023-09-26 05:15:04,307] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 8
[2023-09-26 05:15:04,313] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 7
[2023-09-26 05:15:04,335] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 7
[2023-09-26 05:15:04,343] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 6
[2023-09-26 05:15:04,366] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 6
[2023-09-26 05:15:04,376] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 7
[2023-09-26 05:15:04,381] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 7
[2023-09-26 05:15:04,411] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 8
[2023-09-26 05:15:04,412] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 6
[2023-09-26 05:15:04,412] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 8
[2023-09-26 05:15:04,413] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 6
[2023-09-26 05:15:04,420] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 8
[2023-09-26 05:15:04,539] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 7
[2023-09-26 05:15:04,554] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 7
[2023-09-26 05:15:04,554] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 7
[2023-09-26 05:15:04,646] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 7
[2023-09-26 05:15:04,666] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 7
[2023-09-26 05:15:04,671] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 7
[2023-09-26 05:15:04,681] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 6
[2023-09-26 05:15:04,702] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 6
[2023-09-26 05:15:04,703] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 6
[2023-09-26 05:15:04,846] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 11
[2023-09-26 05:15:05,045] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 6
[2023-09-26 05:15:05,116] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 6
[2023-09-26 05:15:05,149] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 10
[2023-09-26 05:15:05,167] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 5
[2023-09-26 05:15:05,172] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 6
[2023-09-26 05:15:05,181] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 5
[2023-09-26 05:15:05,233] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 5
[2023-09-26 05:15:05,243] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 6
[2023-09-26 05:15:05,254] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 10
[2023-09-26 05:15:05,271] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 5
[2023-09-26 05:15:05,284] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 5
[2023-09-26 05:15:05,288] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 9
[2023-09-26 05:15:05,310] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 5
[2023-09-26 05:15:05,312] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-26 05:15:05,323] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-26 05:15:05,339] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 5
[2023-09-26 05:15:05,374] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-26 05:15:05,374] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 6
[2023-09-26 05:15:05,399] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 6
[2023-09-26 05:15:05,400] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-26 05:15:05,403] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-26 05:15:05,409] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-26 05:15:05,412] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-26 05:15:05,413] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 5
[2023-09-26 05:15:05,445] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 5
[2023-09-26 05:15:05,457] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-26 05:15:05,460] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-26 05:15:05,463] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 5
[2023-09-26 05:15:05,463] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-26 05:15:05,470] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 6
[2023-09-26 05:15:05,507] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-26 05:15:05,513] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-26 05:15:05,531] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 5
[2023-09-26 05:15:05,543] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-26 05:15:05,544] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-26 05:15:05,549] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 5
[2023-09-26 05:15:05,549] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-26 05:15:05,550] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-26 05:15:05,567] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 5
[2023-09-26 05:15:05,569] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-26 05:15:05,593] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-26 05:15:05,610] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-26 05:15:05,611] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-26 05:15:05,633] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 5
[2023-09-26 05:15:05,652] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-26 05:15:05,671] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-26 05:15:05,680] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-26 05:15:05,683] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-26 05:15:05,690] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-26 05:15:05,697] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-26 05:15:05,702] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-26 05:15:05,726] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-26 05:15:05,732] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-26 05:15:05,757] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-26 05:15:05,762] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-26 05:15:05,766] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-26 05:15:05,773] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-26 05:15:05,786] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-26 05:15:05,799] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-26 05:15:05,811] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-26 05:15:05,823] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-26 05:15:05,843] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-26 05:15:05,847] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-26 05:15:05,869] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-26 05:15:05,874] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-26 05:15:05,904] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-26 05:15:05,916] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-26 05:15:05,955] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-26 05:15:05,957] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-26 05:15:05,989] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 9
[2023-09-26 05:15:06,006] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-26 05:15:06,021] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-26 05:15:06,026] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-26 05:15:06,028] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-26 05:15:06,044] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-26 05:15:06,046] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 8
[2023-09-26 05:15:06,053] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-26 05:15:06,086] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-26 05:15:06,089] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-26 05:15:06,091] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-26 05:15:06,103] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-26 05:15:06,131] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-26 05:15:06,148] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 8
[2023-09-26 05:15:06,165] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-26 05:15:06,233] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-26 05:15:06,242] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 7
[2023-09-26 05:15:06,256] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-26 05:15:06,266] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-26 05:15:06,268] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-26 05:15:06,295] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-26 05:15:06,313] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-26 05:15:06,333] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-26 05:15:06,333] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-26 05:15:06,353] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 7
[2023-09-26 05:15:06,372] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-26 05:15:06,384] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 6
[2023-09-26 05:15:06,412] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-26 05:15:06,534] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-26 05:15:06,568] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-26 05:15:06,611] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-26 05:15:07,638] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 6
[2023-09-26 05:15:07,696] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 5
[2023-09-26 05:15:07,796] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 5
[2023-09-26 05:15:07,831] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-26 05:15:07,916] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-26 05:15:07,921] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-26 05:15:08,020] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-26 05:15:08,052] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-26 05:15:08,227] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-26 05:15:08,266] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-26 05:15:08,441] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-26 05:15:08,498] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-26 05:15:08,729] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
I0926 05:15:08.780591 139877412759296 logging_writer.py:48] [0] global_step=0, grad_norm=2.297100, loss=0.737469
I0926 05:15:08.792823 139919823263552 submission.py:120] 0) loss = 0.737, grad_norm = 2.297
I0926 05:15:09.170853 139919823263552 spec.py:321] Evaluating on the training split.
[2023-09-26 05:16:03,497] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:03,498] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:03,498] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:03,498] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:03,499] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:03,499] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:03,499] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:03,499] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:03,543] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:03,544] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:03,544] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:03,544] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:03,544] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:03,545] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:03,545] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:03,546] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:03,546] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:03,546] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:03,546] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:03,546] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:03,546] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:03,546] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:03,546] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:03,547] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:03,547] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:03,547] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:03,547] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:03,547] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:03,547] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:03,547] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:03,547] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:03,547] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:03,547] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:03,547] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:03,547] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:03,548] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:03,567] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:03,569] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:03,570] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:03,571] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:03,740] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-26 05:16:03,741] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-26 05:16:03,741] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-26 05:16:03,747] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-26 05:16:03,748] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-26 05:16:03,748] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-26 05:16:03,749] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-26 05:16:03,831] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-26 05:16:04,335] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-26 05:16:04,335] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:04,336] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-26 05:16:04,337] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:04,351] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-26 05:16:04,351] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:04,351] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-26 05:16:04,352] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:04,353] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-26 05:16:04,354] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:04,361] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-26 05:16:04,362] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:04,371] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-26 05:16:04,371] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:04,563] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:04,601] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:04,609] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:04,611] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:04,612] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:04,612] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:04,617] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:04,620] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:04,621] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:04,621] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:04,621] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:04,649] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:04,652] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:04,652] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:04,653] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:04,666] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:04,667] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:04,667] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:04,668] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:04,669] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:04,669] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:04,669] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:04,669] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:04,670] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:04,670] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:04,670] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:04,671] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:04,671] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:04,671] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:04,671] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:04,672] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:04,672] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:04,672] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:04,672] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:04,672] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:04,798] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-26 05:16:04,799] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:04,844] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-26 05:16:04,861] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-26 05:16:04,883] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-26 05:16:04,886] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-26 05:16:04,889] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-26 05:16:04,889] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-26 05:16:04,932] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-26 05:16:05,000] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:05,063] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:05,065] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:05,065] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:05,066] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:05,334] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-26 05:16:05,435] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-26 05:16:05,436] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:05,460] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-26 05:16:05,460] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:05,484] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-26 05:16:05,485] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:05,486] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-26 05:16:05,487] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:05,510] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-26 05:16:05,511] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:05,570] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-26 05:16:05,571] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:05,571] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-26 05:16:05,571] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:05,627] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:05,641] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:05,670] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:05,673] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:05,673] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:05,673] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:05,688] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:05,692] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:05,694] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:05,695] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:05,695] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:05,707] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:05,718] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:05,734] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:05,736] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:05,736] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:05,737] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:05,760] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:05,762] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:05,763] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:05,763] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:05,765] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:05,767] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:05,767] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:05,768] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:05,833] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:05,840] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:05,875] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-26 05:16:05,879] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:05,881] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:05,882] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:05,882] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:05,888] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:05,890] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:05,890] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:05,891] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:05,915] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-26 05:16:05,963] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-26 05:16:05,966] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-26 05:16:05,970] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-26 05:16:06,084] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-26 05:16:06,088] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-26 05:16:06,304] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-26 05:16:06,306] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:06,478] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:06,501] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-26 05:16:06,502] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:06,534] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-26 05:16:06,534] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:06,545] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:06,547] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:06,547] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:06,548] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:06,579] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-26 05:16:06,579] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:06,588] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-26 05:16:06,589] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:06,609] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-26 05:16:06,610] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:06,693] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:06,706] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-26 05:16:06,707] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:06,714] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:06,732] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-26 05:16:06,733] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:06,736] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:06,738] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:06,738] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:06,739] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:06,756] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:06,758] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:06,760] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:06,761] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:06,761] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:06,804] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:06,806] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:06,807] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:06,807] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:06,815] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:06,825] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-26 05:16:06,844] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:06,849] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-26 05:16:06,859] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:06,861] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:06,861] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:06,862] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:06,877] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-26 05:16:06,888] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:06,890] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:06,890] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:06,891] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:06,925] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-26 05:16:06,960] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:06,961] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:06,971] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-26 05:16:07,004] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-26 05:16:07,005] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:07,006] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:07,007] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:07,007] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:07,008] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:07,008] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:07,009] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:07,009] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:07,117] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-26 05:16:07,125] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-26 05:16:07,330] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-26 05:16:07,389] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-26 05:16:07,474] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-26 05:16:07,474] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-26 05:16:07,503] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-26 05:16:07,523] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-26 05:16:07,533] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-26 05:16:07,598] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-26 05:16:07,610] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-26 05:16:07,614] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:07,643] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-26 05:16:07,646] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-26 05:16:07,647] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-26 05:16:07,664] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:07,683] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-26 05:16:07,688] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-26 05:16:07,735] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-26 05:16:07,753] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:07,765] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-26 05:16:07,765] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:07,771] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-26 05:16:07,780] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-26 05:16:07,788] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:07,796] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:07,803] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-26 05:16:07,817] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-26 05:16:07,820] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:07,843] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:07,855] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:07,858] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:07,858] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:07,858] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:07,889] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:07,892] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:07,893] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:07,893] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:07,902] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-26 05:16:07,919] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:07,940] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-26 05:16:07,957] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:07,969] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-26 05:16:08,005] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-26 05:16:08,015] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:08,028] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:08,029] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:08,030] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:08,071] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:08,073] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:08,073] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:08,074] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:08,089] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:08,090] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:08,092] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:08,092] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:08,093] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:08,093] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:08,093] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:08,094] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:08,094] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:08,096] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:08,096] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:08,097] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:08,181] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:08,182] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:08,186] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-26 05:16:08,202] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-26 05:16:08,205] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-26 05:16:08,226] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:08,226] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:08,228] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:08,228] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:08,228] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:08,228] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:08,229] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:08,229] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:08,258] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-26 05:16:08,337] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-26 05:16:08,340] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-26 05:16:08,718] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-26 05:16:08,742] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-26 05:16:08,847] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-26 05:16:08,871] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-26 05:16:08,944] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-26 05:16:08,946] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-26 05:16:08,970] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-26 05:16:08,981] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-26 05:16:08,987] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:09,004] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-26 05:16:09,021] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:09,091] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-26 05:16:09,099] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-26 05:16:09,109] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-26 05:16:09,127] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-26 05:16:09,130] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-26 05:16:09,150] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-26 05:16:09,150] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:09,171] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:09,173] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:09,173] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:09,174] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:09,185] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:09,207] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:09,209] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:09,209] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:09,209] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:09,220] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-26 05:16:09,226] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-26 05:16:09,232] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-26 05:16:09,236] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:09,244] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-26 05:16:09,260] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:09,274] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-26 05:16:09,274] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-26 05:16:09,294] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:09,298] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-09-26 05:16:09,314] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-26 05:16:09,345] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-26 05:16:09,350] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-26 05:16:09,362] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:09,366] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:09,389] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-26 05:16:09,389] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:09,401] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:09,424] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:09,425] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:09,426] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:09,426] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:09,429] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-09-26 05:16:09,432] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-26 05:16:09,432] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:09,436] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:09,450] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:09,454] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:09,460] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:09,461] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:09,461] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:09,462] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:09,476] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:09,478] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:09,478] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:09,478] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:09,506] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:09,532] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-26 05:16:09,547] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:09,549] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:09,552] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:09,552] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:09,552] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:09,557] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:09,568] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-26 05:16:09,574] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:09,580] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:09,581] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-26 05:16:09,582] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:09,582] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:09,583] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:09,592] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:09,594] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:09,594] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:09,595] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:09,607] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:09,609] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:09,610] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:09,610] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:09,631] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:09,650] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-26 05:16:09,651] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:09,667] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-26 05:16:09,691] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-26 05:16:09,692] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:09,695] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:09,695] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:09,696] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:09,696] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-26 05:16:09,697] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:09,709] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-26 05:16:09,710] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-26 05:16:09,710] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:09,733] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-26 05:16:09,773] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:09,788] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-26 05:16:09,806] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:09,814] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-26 05:16:09,814] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:09,817] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:09,819] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:09,821] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:09,821] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:09,822] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:09,823] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-26 05:16:09,849] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-26 05:16:09,850] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:09,852] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:09,854] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:09,854] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:09,855] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:09,856] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-09-26 05:16:09,862] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:09,864] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:09,865] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:09,865] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:09,911] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 25
[2023-09-26 05:16:09,930] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:09,937] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-26 05:16:09,943] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 25
[2023-09-26 05:16:09,956] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:09,964] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-26 05:16:09,972] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:09,974] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-26 05:16:09,974] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:09,975] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:09,975] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:09,999] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:10,001] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:10,002] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:10,002] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:10,008] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 25
[2023-09-26 05:16:10,023] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:10,040] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 25
[2023-09-26 05:16:10,049] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-26 05:16:10,057] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:10,076] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-26 05:16:10,091] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-26 05:16:10,092] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-26 05:16:10,116] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-26 05:16:10,182] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 25
[2023-09-26 05:16:10,202] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 25
[2023-09-26 05:16:10,205] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:10,212] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-26 05:16:10,220] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 25
[2023-09-26 05:16:10,228] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:10,229] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:10,230] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:10,230] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:10,240] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:10,242] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-26 05:16:10,263] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:10,265] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:10,265] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:10,265] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:10,286] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 25
[2023-09-26 05:16:10,302] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:10,304] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 25
[2023-09-26 05:16:10,320] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:10,321] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 25
[2023-09-26 05:16:10,335] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 26
[2023-09-26 05:16:10,338] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:10,340] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 25
[2023-09-26 05:16:10,367] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 25
[2023-09-26 05:16:10,370] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 26
[2023-09-26 05:16:10,444] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 25
[2023-09-26 05:16:10,459] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 26
[2023-09-26 05:16:10,459] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:10,460] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:10,478] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 25
[2023-09-26 05:16:10,494] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:10,495] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 26
[2023-09-26 05:16:10,496] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:10,503] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:10,503] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:10,525] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:10,525] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:10,527] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:10,527] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:10,527] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:10,527] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:10,527] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:10,528] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:10,543] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:10,566] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:10,567] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:10,568] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:10,568] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:10,603] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:10,635] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 26
[2023-09-26 05:16:10,637] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 26
[2023-09-26 05:16:10,642] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:10,650] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:10,652] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:10,653] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:10,653] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:10,666] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:10,674] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 26
[2023-09-26 05:16:10,687] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:10,688] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:10,689] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:10,690] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:10,690] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:10,690] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:10,690] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:10,691] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:10,700] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:10,722] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:10,724] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:10,724] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:10,725] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:10,758] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 26
[2023-09-26 05:16:10,759] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:10,767] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 26
[2023-09-26 05:16:10,768] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:10,795] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 26
[2023-09-26 05:16:10,804] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 26
[2023-09-26 05:16:10,805] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:10,830] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 26
[2023-09-26 05:16:10,854] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 27
[2023-09-26 05:16:10,889] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 27
[2023-09-26 05:16:10,914] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:10,914] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:10,929] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 26
[2023-09-26 05:16:10,929] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:10,929] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:10,956] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 26
[2023-09-26 05:16:10,957] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:10,959] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:10,961] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:10,961] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:10,961] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:10,962] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:10,964] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:10,964] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:10,964] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:10,975] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:10,977] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:10,977] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:10,978] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:11,054] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:11,058] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 27
[2023-09-26 05:16:11,059] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:11,086] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:11,098] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:11,098] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 27
[2023-09-26 05:16:11,099] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:11,100] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-09-26 05:16:11,100] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:11,101] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:11,101] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:11,132] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:11,135] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:11,135] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:11,135] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:11,166] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 27
[2023-09-26 05:16:11,178] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 27
[2023-09-26 05:16:11,182] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 27
[2023-09-26 05:16:11,249] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:11,279] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:11,281] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-09-26 05:16:11,281] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:11,281] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:11,281] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:11,282] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:11,298] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 27
[2023-09-26 05:16:11,301] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:11,303] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:11,303] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:11,304] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:11,331] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 27
[2023-09-26 05:16:11,358] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 27
[2023-09-26 05:16:11,359] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:11,371] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 27
[2023-09-26 05:16:11,372] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:11,380] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 27
[2023-09-26 05:16:11,380] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:11,400] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 28
[2023-09-26 05:16:11,414] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 28
[2023-09-26 05:16:11,447] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-09-26 05:16:11,475] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:11,492] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 27
[2023-09-26 05:16:11,492] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:11,525] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 27
[2023-09-26 05:16:11,526] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:11,528] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 28
[2023-09-26 05:16:11,529] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:11,542] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 28
[2023-09-26 05:16:11,543] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:11,587] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:11,608] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:11,610] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:11,610] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:11,611] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:11,611] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:11,612] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:11,634] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:11,635] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:11,636] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:11,636] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:11,636] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:11,637] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:11,637] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:11,637] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:11,691] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:11,708] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:11,713] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:11,715] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:11,715] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:11,716] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:11,716] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 28
[2023-09-26 05:16:11,742] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 28
[2023-09-26 05:16:11,742] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:11,744] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 28
[2023-09-26 05:16:11,744] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:11,744] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:11,746] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:11,779] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:11,799] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:11,799] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:11,810] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:11,812] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:11,812] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:11,813] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:11,816] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 28
[2023-09-26 05:16:11,843] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 28
[2023-09-26 05:16:11,844] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:11,844] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:11,844] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:11,846] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:11,846] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:11,846] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:11,846] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:11,847] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:11,847] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:11,868] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 28
[2023-09-26 05:16:11,868] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:11,870] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 28
[2023-09-26 05:16:11,871] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:11,885] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-09-26 05:16:11,917] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 28
[2023-09-26 05:16:11,941] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 28
[2023-09-26 05:16:11,941] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:12,006] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-09-26 05:16:12,007] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:12,035] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:12,038] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 29
[2023-09-26 05:16:12,041] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 28
[2023-09-26 05:16:12,041] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 29
[2023-09-26 05:16:12,042] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:12,078] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:12,079] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:12,080] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:12,081] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:12,081] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:12,082] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:12,119] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:12,124] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:12,125] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:12,126] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:12,126] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:12,127] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:12,127] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:12,127] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:12,127] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:12,128] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:12,170] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:12,172] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:12,172] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:12,173] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:12,183] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:12,185] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:12,185] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:12,186] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:12,230] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:12,234] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 29
[2023-09-26 05:16:12,234] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 29
[2023-09-26 05:16:12,235] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:12,235] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:12,272] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:12,275] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:12,275] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:12,275] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:12,279] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 29
[2023-09-26 05:16:12,320] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-09-26 05:16:12,321] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 29
[2023-09-26 05:16:12,326] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 29
[2023-09-26 05:16:12,361] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 29
[2023-09-26 05:16:12,437] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-09-26 05:16:12,463] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:12,464] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 29
[2023-09-26 05:16:12,464] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:12,465] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 29
[2023-09-26 05:16:12,467] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:12,485] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:12,486] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:12,487] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:12,487] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:12,489] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:12,491] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:12,491] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:12,491] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:12,510] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 29
[2023-09-26 05:16:12,510] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:12,522] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 29
[2023-09-26 05:16:12,523] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:12,552] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 29
[2023-09-26 05:16:12,553] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:12,589] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 30
[2023-09-26 05:16:12,595] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 30
[2023-09-26 05:16:12,616] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 25
[2023-09-26 05:16:12,662] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 29
[2023-09-26 05:16:12,663] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:12,696] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:12,711] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 30
[2023-09-26 05:16:12,711] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:12,717] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 30
[2023-09-26 05:16:12,717] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:12,717] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:12,719] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:12,719] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:12,719] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:12,731] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 25
[2023-09-26 05:16:12,753] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:12,803] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:12,804] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:12,806] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:12,824] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 30
[2023-09-26 05:16:12,825] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:12,827] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:12,827] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:12,827] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:12,828] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:12,828] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:12,829] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:12,829] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:12,829] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:12,830] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:12,830] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:12,830] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:12,886] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:12,907] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:12,909] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:12,909] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:12,910] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:12,930] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 30
[2023-09-26 05:16:12,931] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 30
[2023-09-26 05:16:12,934] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 30
[2023-09-26 05:16:12,946] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:12,957] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 30
[2023-09-26 05:16:12,958] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:12,980] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:12,981] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:12,982] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:12,982] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:13,013] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 30
[2023-09-26 05:16:13,046] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:13,054] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 30
[2023-09-26 05:16:13,054] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:13,056] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 30
[2023-09-26 05:16:13,056] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:13,065] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 30
[2023-09-26 05:16:13,066] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:13,095] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:13,098] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:13,098] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:13,098] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:13,102] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:13,118] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 26
[2023-09-26 05:16:13,135] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 30
[2023-09-26 05:16:13,136] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:13,152] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:13,154] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:13,155] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:13,155] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:13,243] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 26
[2023-09-26 05:16:13,244] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:13,260] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:13,292] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 31
[2023-09-26 05:16:13,310] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:13,312] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:13,313] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:13,313] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:13,353] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 31
[2023-09-26 05:16:13,379] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:13,404] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:13,407] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:13,407] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:13,436] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:13,442] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:13,445] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:13,445] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:13,446] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:13,459] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:13,461] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:13,461] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:13,462] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:13,462] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:13,462] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:13,463] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:13,464] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:13,464] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:13,464] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:13,464] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:13,464] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:13,488] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:13,490] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:13,490] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:13,491] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:13,519] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 31
[2023-09-26 05:16:13,666] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 31
[2023-09-26 05:16:13,669] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 31
[2023-09-26 05:16:13,692] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 31
[2023-09-26 05:16:13,697] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 31
[2023-09-26 05:16:13,697] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:13,715] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 31
[2023-09-26 05:16:13,719] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 27
[2023-09-26 05:16:13,744] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 31
[2023-09-26 05:16:13,745] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:13,893] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 31
[2023-09-26 05:16:13,894] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:13,925] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 27
[2023-09-26 05:16:13,925] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:14,051] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 31
[2023-09-26 05:16:14,051] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
[2023-09-26 05:16:14,065] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 31
[2023-09-26 05:16:14,066] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:14,079] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 31
[2023-09-26 05:16:14,079] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:14,120] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 31
[2023-09-26 05:16:14,120] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:14,168] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:14,200] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:14,202] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:14,202] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:14,202] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
[2023-09-26 05:16:14,338] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 28
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
[2023-09-26 05:16:14,476] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 28
[2023-09-26 05:16:14,477] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
[2023-09-26 05:16:14,659] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:14,712] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:14,714] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:14,714] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:14,715] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:14,972] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 29
[2023-09-26 05:16:15,175] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 29
[2023-09-26 05:16:15,175] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:15,375] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:15,405] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:15,406] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:15,406] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:15,407] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:15,543] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 30
[2023-09-26 05:16:15,670] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 30
[2023-09-26 05:16:15,671] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 05:16:15,973] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 05:16:16,038] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 05:16:16,040] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 05:16:16,041] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 05:16:16,042] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 05:16:16,322] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 31
[2023-09-26 05:16:17,001] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 31
[2023-09-26 05:16:17,002] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0926 05:16:46.236792 139919823263552 spec.py:333] Evaluating on the validation split.
I0926 05:17:50.277589 139919823263552 spec.py:349] Evaluating on the test split.
I0926 05:18:56.121053 139919823263552 submission_runner.py:381] Time since start: 313.69s, 	Step: 1, 	{'train/ssim': 0.27552500792912077, 'train/loss': 0.7460806029183524, 'validation/ssim': 0.2589159586084781, 'validation/loss': 0.7520700432171497, 'validation/num_examples': 3554, 'test/ssim': 0.28326034226320335, 'test/loss': 0.7556315967737713, 'test/num_examples': 3581, 'score': 86.36215353012085, 'total_duration': 313.6896834373474, 'accumulated_submission_time': 86.36215353012085, 'accumulated_eval_time': 226.95038771629333, 'accumulated_logging_time': 0}
I0926 05:18:56.144894 139861935757056 logging_writer.py:48] [1] accumulated_eval_time=226.950388, accumulated_logging_time=0, accumulated_submission_time=86.362154, global_step=1, preemption_count=0, score=86.362154, test/loss=0.755632, test/num_examples=3581, test/ssim=0.283260, total_duration=313.689683, train/loss=0.746081, train/ssim=0.275525, validation/loss=0.752070, validation/num_examples=3554, validation/ssim=0.258916
I0926 05:18:56.683678 140504990574400 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0926 05:18:56.683701 140143531374400 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0926 05:18:56.683700 140014307419968 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0926 05:18:56.683694 140142999553856 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0926 05:18:56.683703 140312334493504 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0926 05:18:56.683746 139919823263552 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0926 05:18:56.683871 139998102861632 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0926 05:18:56.683824 140589296052032 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0926 05:18:56.860321 139861717677824 logging_writer.py:48] [1] global_step=1, grad_norm=2.319219, loss=0.729076
I0926 05:18:56.864850 139919823263552 submission.py:120] 1) loss = 0.729, grad_norm = 2.319
I0926 05:18:56.935586 139861935757056 logging_writer.py:48] [2] global_step=2, grad_norm=2.454090, loss=0.783256
I0926 05:18:56.939224 139919823263552 submission.py:120] 2) loss = 0.783, grad_norm = 2.454
I0926 05:18:57.003084 139861717677824 logging_writer.py:48] [3] global_step=3, grad_norm=2.534082, loss=0.763723
I0926 05:18:57.009864 139919823263552 submission.py:120] 3) loss = 0.764, grad_norm = 2.534
I0926 05:18:57.101090 139861935757056 logging_writer.py:48] [4] global_step=4, grad_norm=2.306053, loss=0.726070
I0926 05:18:57.106180 139919823263552 submission.py:120] 4) loss = 0.726, grad_norm = 2.306
I0926 05:18:57.193714 139861717677824 logging_writer.py:48] [5] global_step=5, grad_norm=2.804467, loss=0.776168
I0926 05:18:57.204466 139919823263552 submission.py:120] 5) loss = 0.776, grad_norm = 2.804
I0926 05:18:57.290198 139861935757056 logging_writer.py:48] [6] global_step=6, grad_norm=2.485607, loss=0.760943
I0926 05:18:57.295127 139919823263552 submission.py:120] 6) loss = 0.761, grad_norm = 2.486
I0926 05:18:57.377788 139861717677824 logging_writer.py:48] [7] global_step=7, grad_norm=1.987693, loss=0.693205
I0926 05:18:57.382594 139919823263552 submission.py:120] 7) loss = 0.693, grad_norm = 1.988
I0926 05:18:57.460510 139861935757056 logging_writer.py:48] [8] global_step=8, grad_norm=2.256386, loss=0.713771
I0926 05:18:57.467991 139919823263552 submission.py:120] 8) loss = 0.714, grad_norm = 2.256
I0926 05:18:57.546691 139861717677824 logging_writer.py:48] [9] global_step=9, grad_norm=2.186452, loss=0.691911
I0926 05:18:57.553565 139919823263552 submission.py:120] 9) loss = 0.692, grad_norm = 2.186
I0926 05:18:57.656426 139861935757056 logging_writer.py:48] [10] global_step=10, grad_norm=2.226215, loss=0.713507
I0926 05:18:57.665285 139919823263552 submission.py:120] 10) loss = 0.714, grad_norm = 2.226
I0926 05:20:16.688155 139919823263552 spec.py:321] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0926 05:20:18.740294 139919823263552 spec.py:333] Evaluating on the validation split.
I0926 05:20:20.813618 139919823263552 spec.py:349] Evaluating on the test split.
I0926 05:20:22.867884 139919823263552 submission_runner.py:381] Time since start: 400.44s, 	Step: 305, 	{'train/ssim': 0.7122549329485212, 'train/loss': 0.2962135928017752, 'validation/ssim': 0.6872396474482977, 'validation/loss': 0.3189946627039955, 'validation/num_examples': 3554, 'test/ssim': 0.7051756176260123, 'test/loss': 0.3207836689079517, 'test/num_examples': 3581, 'score': 165.79113006591797, 'total_duration': 400.4365599155426, 'accumulated_submission_time': 165.79113006591797, 'accumulated_eval_time': 233.13023352622986, 'accumulated_logging_time': 0.03543448448181152}
I0926 05:20:22.885158 139861717677824 logging_writer.py:48] [305] accumulated_eval_time=233.130234, accumulated_logging_time=0.035434, accumulated_submission_time=165.791130, global_step=305, preemption_count=0, score=165.791130, test/loss=0.320784, test/num_examples=3581, test/ssim=0.705176, total_duration=400.436560, train/loss=0.296214, train/ssim=0.712255, validation/loss=0.318995, validation/num_examples=3554, validation/ssim=0.687240
I0926 05:21:35.351024 139861935757056 logging_writer.py:48] [500] global_step=500, grad_norm=0.406931, loss=0.279005
I0926 05:21:35.356650 139919823263552 submission.py:120] 500) loss = 0.279, grad_norm = 0.407
I0926 05:21:43.567791 139919823263552 spec.py:321] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0926 05:21:45.606518 139919823263552 spec.py:333] Evaluating on the validation split.
I0926 05:21:47.678680 139919823263552 spec.py:349] Evaluating on the test split.
I0926 05:21:49.724974 139919823263552 submission_runner.py:381] Time since start: 487.29s, 	Step: 523, 	{'train/ssim': 0.7214232853480748, 'train/loss': 0.2905304091317313, 'validation/ssim': 0.6962718201542276, 'validation/loss': 0.31255753173141176, 'validation/num_examples': 3554, 'test/ssim': 0.7138086237477311, 'test/loss': 0.3146263278086603, 'test/num_examples': 3581, 'score': 245.51059985160828, 'total_duration': 487.2936305999756, 'accumulated_submission_time': 245.51059985160828, 'accumulated_eval_time': 239.28776264190674, 'accumulated_logging_time': 0.06516242027282715}
I0926 05:21:49.741972 139861717677824 logging_writer.py:48] [523] accumulated_eval_time=239.287763, accumulated_logging_time=0.065162, accumulated_submission_time=245.510600, global_step=523, preemption_count=0, score=245.510600, test/loss=0.314626, test/num_examples=3581, test/ssim=0.713809, total_duration=487.293631, train/loss=0.290530, train/ssim=0.721423, validation/loss=0.312558, validation/num_examples=3554, validation/ssim=0.696272
I0926 05:23:10.265299 139919823263552 spec.py:321] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0926 05:23:12.390076 139919823263552 spec.py:333] Evaluating on the validation split.
I0926 05:23:14.472465 139919823263552 spec.py:349] Evaluating on the test split.
I0926 05:23:16.530262 139919823263552 submission_runner.py:381] Time since start: 574.10s, 	Step: 739, 	{'train/ssim': 0.7310340063912528, 'train/loss': 0.28003409930637907, 'validation/ssim': 0.7053805186497608, 'validation/loss': 0.30221933720148075, 'validation/num_examples': 3554, 'test/ssim': 0.722651136750384, 'test/loss': 0.3041025442439263, 'test/num_examples': 3581, 'score': 325.0791940689087, 'total_duration': 574.0989043712616, 'accumulated_submission_time': 325.0791940689087, 'accumulated_eval_time': 245.55297565460205, 'accumulated_logging_time': 0.09255599975585938}
I0926 05:23:16.547492 139861935757056 logging_writer.py:48] [739] accumulated_eval_time=245.552976, accumulated_logging_time=0.092556, accumulated_submission_time=325.079194, global_step=739, preemption_count=0, score=325.079194, test/loss=0.304103, test/num_examples=3581, test/ssim=0.722651, total_duration=574.098904, train/loss=0.280034, train/ssim=0.731034, validation/loss=0.302219, validation/num_examples=3554, validation/ssim=0.705381
I0926 05:24:36.947842 139919823263552 spec.py:321] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0926 05:24:38.975125 139919823263552 spec.py:333] Evaluating on the validation split.
I0926 05:24:41.688277 139919823263552 spec.py:349] Evaluating on the test split.
I0926 05:24:43.736154 139919823263552 submission_runner.py:381] Time since start: 661.30s, 	Step: 946, 	{'train/ssim': 0.7316200392586845, 'train/loss': 0.28102210589817594, 'validation/ssim': 0.7064639699546286, 'validation/loss': 0.3033051241229073, 'validation/num_examples': 3554, 'test/ssim': 0.7233931033580006, 'test/loss': 0.30511237695476123, 'test/num_examples': 3581, 'score': 404.5489971637726, 'total_duration': 661.3048150539398, 'accumulated_submission_time': 404.5489971637726, 'accumulated_eval_time': 252.34152936935425, 'accumulated_logging_time': 0.12106657028198242}
I0926 05:24:43.762928 139861717677824 logging_writer.py:48] [946] accumulated_eval_time=252.341529, accumulated_logging_time=0.121067, accumulated_submission_time=404.548997, global_step=946, preemption_count=0, score=404.548997, test/loss=0.305112, test/num_examples=3581, test/ssim=0.723393, total_duration=661.304815, train/loss=0.281022, train/ssim=0.731620, validation/loss=0.303305, validation/num_examples=3554, validation/ssim=0.706464
I0926 05:24:56.112710 139861935757056 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.200149, loss=0.259117
I0926 05:24:56.118349 139919823263552 submission.py:120] 1000) loss = 0.259, grad_norm = 0.200
I0926 05:26:04.401667 139919823263552 spec.py:321] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0926 05:26:06.384993 139919823263552 spec.py:333] Evaluating on the validation split.
I0926 05:26:08.397780 139919823263552 spec.py:349] Evaluating on the test split.
I0926 05:26:10.374038 139919823263552 submission_runner.py:381] Time since start: 747.94s, 	Step: 1253, 	{'train/ssim': 0.7364273752485003, 'train/loss': 0.27591490745544434, 'validation/ssim': 0.7102673154368317, 'validation/loss': 0.29883537228079277, 'validation/num_examples': 3554, 'test/ssim': 0.727470135895176, 'test/loss': 0.3003998697553058, 'test/num_examples': 3581, 'score': 484.237272977829, 'total_duration': 747.9427134990692, 'accumulated_submission_time': 484.237272977829, 'accumulated_eval_time': 258.31400871276855, 'accumulated_logging_time': 0.16480016708374023}
I0926 05:26:10.388676 139861717677824 logging_writer.py:48] [1253] accumulated_eval_time=258.314009, accumulated_logging_time=0.164800, accumulated_submission_time=484.237273, global_step=1253, preemption_count=0, score=484.237273, test/loss=0.300400, test/num_examples=3581, test/ssim=0.727470, total_duration=747.942713, train/loss=0.275915, train/ssim=0.736427, validation/loss=0.298835, validation/num_examples=3554, validation/ssim=0.710267
I0926 05:27:14.457204 139861935757056 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.208331, loss=0.325792
I0926 05:27:14.461017 139919823263552 submission.py:120] 1500) loss = 0.326, grad_norm = 0.208
I0926 05:27:30.924831 139919823263552 spec.py:321] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0926 05:27:32.909944 139919823263552 spec.py:333] Evaluating on the validation split.
I0926 05:27:34.927212 139919823263552 spec.py:349] Evaluating on the test split.
I0926 05:27:36.911187 139919823263552 submission_runner.py:381] Time since start: 834.48s, 	Step: 1561, 	{'train/ssim': 0.737476076398577, 'train/loss': 0.2751600912639073, 'validation/ssim': 0.7122942184422482, 'validation/loss': 0.29724454262582656, 'validation/num_examples': 3554, 'test/ssim': 0.7294373052874547, 'test/loss': 0.29889633574987784, 'test/num_examples': 3581, 'score': 563.8387637138367, 'total_duration': 834.4798460006714, 'accumulated_submission_time': 563.8387637138367, 'accumulated_eval_time': 264.30062532424927, 'accumulated_logging_time': 0.18928003311157227}
I0926 05:27:36.926709 139861717677824 logging_writer.py:48] [1561] accumulated_eval_time=264.300625, accumulated_logging_time=0.189280, accumulated_submission_time=563.838764, global_step=1561, preemption_count=0, score=563.838764, test/loss=0.298896, test/num_examples=3581, test/ssim=0.729437, total_duration=834.479846, train/loss=0.275160, train/ssim=0.737476, validation/loss=0.297245, validation/num_examples=3554, validation/ssim=0.712294
I0926 05:28:57.437724 139919823263552 spec.py:321] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0926 05:28:59.398306 139919823263552 spec.py:333] Evaluating on the validation split.
I0926 05:29:01.412105 139919823263552 spec.py:349] Evaluating on the test split.
I0926 05:29:03.432103 139919823263552 submission_runner.py:381] Time since start: 921.00s, 	Step: 1867, 	{'train/ssim': 0.7396823338099888, 'train/loss': 0.27358244146619526, 'validation/ssim': 0.7140212008036719, 'validation/loss': 0.2957339482691158, 'validation/num_examples': 3554, 'test/ssim': 0.7311541299785326, 'test/loss': 0.29745514930143463, 'test/num_examples': 3581, 'score': 643.4105815887451, 'total_duration': 921.0007770061493, 'accumulated_submission_time': 643.4105815887451, 'accumulated_eval_time': 270.29528617858887, 'accumulated_logging_time': 0.21340179443359375}
I0926 05:29:03.446756 139861935757056 logging_writer.py:48] [1867] accumulated_eval_time=270.295286, accumulated_logging_time=0.213402, accumulated_submission_time=643.410582, global_step=1867, preemption_count=0, score=643.410582, test/loss=0.297455, test/num_examples=3581, test/ssim=0.731154, total_duration=921.000777, train/loss=0.273582, train/ssim=0.739682, validation/loss=0.295734, validation/num_examples=3554, validation/ssim=0.714021
I0926 05:29:37.211914 139861717677824 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.135897, loss=0.306599
I0926 05:29:37.215501 139919823263552 submission.py:120] 2000) loss = 0.307, grad_norm = 0.136
I0926 05:30:24.070320 139919823263552 spec.py:321] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0926 05:30:26.053083 139919823263552 spec.py:333] Evaluating on the validation split.
I0926 05:30:28.153288 139919823263552 spec.py:349] Evaluating on the test split.
I0926 05:30:30.134852 139919823263552 submission_runner.py:381] Time since start: 1007.70s, 	Step: 2173, 	{'train/ssim': 0.7345232963562012, 'train/loss': 0.27672743797302246, 'validation/ssim': 0.7091712243247046, 'validation/loss': 0.2986587241048818, 'validation/num_examples': 3554, 'test/ssim': 0.7263247679811854, 'test/loss': 0.30058933269774507, 'test/num_examples': 3581, 'score': 723.0985331535339, 'total_duration': 1007.7035238742828, 'accumulated_submission_time': 723.0985331535339, 'accumulated_eval_time': 276.35997700691223, 'accumulated_logging_time': 0.2364046573638916}
I0926 05:30:30.149755 139861935757056 logging_writer.py:48] [2173] accumulated_eval_time=276.359977, accumulated_logging_time=0.236405, accumulated_submission_time=723.098533, global_step=2173, preemption_count=0, score=723.098533, test/loss=0.300589, test/num_examples=3581, test/ssim=0.726325, total_duration=1007.703524, train/loss=0.276727, train/ssim=0.734523, validation/loss=0.298659, validation/num_examples=3554, validation/ssim=0.709171
I0926 05:31:50.728800 139919823263552 spec.py:321] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0926 05:31:52.711000 139919823263552 spec.py:333] Evaluating on the validation split.
I0926 05:31:54.733349 139919823263552 spec.py:349] Evaluating on the test split.
I0926 05:31:56.723533 139919823263552 submission_runner.py:381] Time since start: 1094.29s, 	Step: 2483, 	{'train/ssim': 0.742342335837228, 'train/loss': 0.2707225595201765, 'validation/ssim': 0.7162722543041291, 'validation/loss': 0.2933777576762099, 'validation/num_examples': 3554, 'test/ssim': 0.7333746438451201, 'test/loss': 0.29500355064053335, 'test/num_examples': 3581, 'score': 802.7274103164673, 'total_duration': 1094.2921738624573, 'accumulated_submission_time': 802.7274103164673, 'accumulated_eval_time': 282.3549258708954, 'accumulated_logging_time': 0.2609105110168457}
I0926 05:31:56.738698 139861717677824 logging_writer.py:48] [2483] accumulated_eval_time=282.354926, accumulated_logging_time=0.260911, accumulated_submission_time=802.727410, global_step=2483, preemption_count=0, score=802.727410, test/loss=0.295004, test/num_examples=3581, test/ssim=0.733375, total_duration=1094.292174, train/loss=0.270723, train/ssim=0.742342, validation/loss=0.293378, validation/num_examples=3554, validation/ssim=0.716272
I0926 05:31:59.285037 139861935757056 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.184897, loss=0.202511
I0926 05:31:59.288700 139919823263552 submission.py:120] 2500) loss = 0.203, grad_norm = 0.185
I0926 05:32:56.502611 139919823263552 spec.py:321] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0926 05:32:58.477571 139919823263552 spec.py:333] Evaluating on the validation split.
I0926 05:33:00.508026 139919823263552 spec.py:349] Evaluating on the test split.
I0926 05:33:02.452373 139919823263552 submission_runner.py:381] Time since start: 1160.02s, 	Step: 2714, 	{'train/ssim': 0.7201528549194336, 'train/loss': 0.2929624148777553, 'validation/ssim': 0.6945777425084412, 'validation/loss': 0.31597550048141176, 'validation/num_examples': 3554, 'test/ssim': 0.7134784441758587, 'test/loss': 0.31645803017444496, 'test/num_examples': 3581, 'score': 861.5726964473724, 'total_duration': 1160.0210058689117, 'accumulated_submission_time': 861.5726964473724, 'accumulated_eval_time': 288.3047857284546, 'accumulated_logging_time': 0.28485608100891113}
I0926 05:33:02.469285 139861717677824 logging_writer.py:48] [2714] accumulated_eval_time=288.304786, accumulated_logging_time=0.284856, accumulated_submission_time=861.572696, global_step=2714, preemption_count=0, score=861.572696, test/loss=0.316458, test/num_examples=3581, test/ssim=0.713478, total_duration=1160.021006, train/loss=0.292962, train/ssim=0.720153, validation/loss=0.315976, validation/num_examples=3554, validation/ssim=0.694578
I0926 05:33:02.889982 139861935757056 logging_writer.py:48] [2714] global_step=2714, preemption_count=0, score=861.572696
I0926 05:33:03.076723 139919823263552 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_prelaunch/adamw/fastmri_pytorch/trial_1/checkpoint_2714.
I0926 05:33:04.266345 139919823263552 submission_runner.py:549] Tuning trial 1/1
I0926 05:33:04.266575 139919823263552 submission_runner.py:550] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0926 05:33:04.271616 139919823263552 submission_runner.py:551] Metrics: {'eval_results': [(1, {'train/ssim': 0.27552500792912077, 'train/loss': 0.7460806029183524, 'validation/ssim': 0.2589159586084781, 'validation/loss': 0.7520700432171497, 'validation/num_examples': 3554, 'test/ssim': 0.28326034226320335, 'test/loss': 0.7556315967737713, 'test/num_examples': 3581, 'score': 86.36215353012085, 'total_duration': 313.6896834373474, 'accumulated_submission_time': 86.36215353012085, 'accumulated_eval_time': 226.95038771629333, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (305, {'train/ssim': 0.7122549329485212, 'train/loss': 0.2962135928017752, 'validation/ssim': 0.6872396474482977, 'validation/loss': 0.3189946627039955, 'validation/num_examples': 3554, 'test/ssim': 0.7051756176260123, 'test/loss': 0.3207836689079517, 'test/num_examples': 3581, 'score': 165.79113006591797, 'total_duration': 400.4365599155426, 'accumulated_submission_time': 165.79113006591797, 'accumulated_eval_time': 233.13023352622986, 'accumulated_logging_time': 0.03543448448181152, 'global_step': 305, 'preemption_count': 0}), (523, {'train/ssim': 0.7214232853480748, 'train/loss': 0.2905304091317313, 'validation/ssim': 0.6962718201542276, 'validation/loss': 0.31255753173141176, 'validation/num_examples': 3554, 'test/ssim': 0.7138086237477311, 'test/loss': 0.3146263278086603, 'test/num_examples': 3581, 'score': 245.51059985160828, 'total_duration': 487.2936305999756, 'accumulated_submission_time': 245.51059985160828, 'accumulated_eval_time': 239.28776264190674, 'accumulated_logging_time': 0.06516242027282715, 'global_step': 523, 'preemption_count': 0}), (739, {'train/ssim': 0.7310340063912528, 'train/loss': 0.28003409930637907, 'validation/ssim': 0.7053805186497608, 'validation/loss': 0.30221933720148075, 'validation/num_examples': 3554, 'test/ssim': 0.722651136750384, 'test/loss': 0.3041025442439263, 'test/num_examples': 3581, 'score': 325.0791940689087, 'total_duration': 574.0989043712616, 'accumulated_submission_time': 325.0791940689087, 'accumulated_eval_time': 245.55297565460205, 'accumulated_logging_time': 0.09255599975585938, 'global_step': 739, 'preemption_count': 0}), (946, {'train/ssim': 0.7316200392586845, 'train/loss': 0.28102210589817594, 'validation/ssim': 0.7064639699546286, 'validation/loss': 0.3033051241229073, 'validation/num_examples': 3554, 'test/ssim': 0.7233931033580006, 'test/loss': 0.30511237695476123, 'test/num_examples': 3581, 'score': 404.5489971637726, 'total_duration': 661.3048150539398, 'accumulated_submission_time': 404.5489971637726, 'accumulated_eval_time': 252.34152936935425, 'accumulated_logging_time': 0.12106657028198242, 'global_step': 946, 'preemption_count': 0}), (1253, {'train/ssim': 0.7364273752485003, 'train/loss': 0.27591490745544434, 'validation/ssim': 0.7102673154368317, 'validation/loss': 0.29883537228079277, 'validation/num_examples': 3554, 'test/ssim': 0.727470135895176, 'test/loss': 0.3003998697553058, 'test/num_examples': 3581, 'score': 484.237272977829, 'total_duration': 747.9427134990692, 'accumulated_submission_time': 484.237272977829, 'accumulated_eval_time': 258.31400871276855, 'accumulated_logging_time': 0.16480016708374023, 'global_step': 1253, 'preemption_count': 0}), (1561, {'train/ssim': 0.737476076398577, 'train/loss': 0.2751600912639073, 'validation/ssim': 0.7122942184422482, 'validation/loss': 0.29724454262582656, 'validation/num_examples': 3554, 'test/ssim': 0.7294373052874547, 'test/loss': 0.29889633574987784, 'test/num_examples': 3581, 'score': 563.8387637138367, 'total_duration': 834.4798460006714, 'accumulated_submission_time': 563.8387637138367, 'accumulated_eval_time': 264.30062532424927, 'accumulated_logging_time': 0.18928003311157227, 'global_step': 1561, 'preemption_count': 0}), (1867, {'train/ssim': 0.7396823338099888, 'train/loss': 0.27358244146619526, 'validation/ssim': 0.7140212008036719, 'validation/loss': 0.2957339482691158, 'validation/num_examples': 3554, 'test/ssim': 0.7311541299785326, 'test/loss': 0.29745514930143463, 'test/num_examples': 3581, 'score': 643.4105815887451, 'total_duration': 921.0007770061493, 'accumulated_submission_time': 643.4105815887451, 'accumulated_eval_time': 270.29528617858887, 'accumulated_logging_time': 0.21340179443359375, 'global_step': 1867, 'preemption_count': 0}), (2173, {'train/ssim': 0.7345232963562012, 'train/loss': 0.27672743797302246, 'validation/ssim': 0.7091712243247046, 'validation/loss': 0.2986587241048818, 'validation/num_examples': 3554, 'test/ssim': 0.7263247679811854, 'test/loss': 0.30058933269774507, 'test/num_examples': 3581, 'score': 723.0985331535339, 'total_duration': 1007.7035238742828, 'accumulated_submission_time': 723.0985331535339, 'accumulated_eval_time': 276.35997700691223, 'accumulated_logging_time': 0.2364046573638916, 'global_step': 2173, 'preemption_count': 0}), (2483, {'train/ssim': 0.742342335837228, 'train/loss': 0.2707225595201765, 'validation/ssim': 0.7162722543041291, 'validation/loss': 0.2933777576762099, 'validation/num_examples': 3554, 'test/ssim': 0.7333746438451201, 'test/loss': 0.29500355064053335, 'test/num_examples': 3581, 'score': 802.7274103164673, 'total_duration': 1094.2921738624573, 'accumulated_submission_time': 802.7274103164673, 'accumulated_eval_time': 282.3549258708954, 'accumulated_logging_time': 0.2609105110168457, 'global_step': 2483, 'preemption_count': 0}), (2714, {'train/ssim': 0.7201528549194336, 'train/loss': 0.2929624148777553, 'validation/ssim': 0.6945777425084412, 'validation/loss': 0.31597550048141176, 'validation/num_examples': 3554, 'test/ssim': 0.7134784441758587, 'test/loss': 0.31645803017444496, 'test/num_examples': 3581, 'score': 861.5726964473724, 'total_duration': 1160.0210058689117, 'accumulated_submission_time': 861.5726964473724, 'accumulated_eval_time': 288.3047857284546, 'accumulated_logging_time': 0.28485608100891113, 'global_step': 2714, 'preemption_count': 0})], 'global_step': 2714}
I0926 05:33:04.271747 139919823263552 submission_runner.py:552] Timing: 861.5726964473724
I0926 05:33:04.271798 139919823263552 submission_runner.py:554] Total number of evals: 11
I0926 05:33:04.271842 139919823263552 submission_runner.py:555] ====================
I0926 05:33:04.271961 139919823263552 submission_runner.py:625] Final fastmri score: 861.5726964473724
