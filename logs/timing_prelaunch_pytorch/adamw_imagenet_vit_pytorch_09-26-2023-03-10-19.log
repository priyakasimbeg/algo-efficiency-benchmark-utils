torchrun --redirects 1:0,2:0,3:0,4:0,5:0,6:0,7:0 --standalone --nnodes=1 --nproc_per_node=8 submission_runner.py --framework=pytorch --workload=imagenet_vit --submission_path=baselines/adamw/pytorch/submission.py --tuning_search_space=baselines/adamw/tuning_search_space.json --data_dir=/data/imagenet/pytorch --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_prelaunch/adamw --overwrite=true --save_checkpoints=false --max_global_steps=14000 --imagenet_v2_data_dir=/data/imagenet/pytorch --torch_compile=true 2>&1 | tee -a /logs/imagenet_vit_pytorch_09-26-2023-03-10-19.log
master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-09-26 03:10:28.977066: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-26 03:10:28.977066: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-26 03:10:28.977069: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-26 03:10:28.977072: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-26 03:10:28.977066: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-26 03:10:28.977066: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-26 03:10:28.977084: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-26 03:10:28.977087: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0926 03:10:43.371428 139783584151360 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 7
I0926 03:10:43.371550 139876468008768 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 6
I0926 03:10:43.372478 140676642408256 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
I0926 03:10:43.372549 140404617828160 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 4
I0926 03:10:43.372624 140096680544064 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
I0926 03:10:43.372863 140220116084544 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 5
I0926 03:10:43.372873 140078343296832 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
I0926 03:10:43.382722 139722949982016 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
I0926 03:10:43.383359 140676642408256 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0926 03:10:43.383391 139722949982016 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0926 03:10:43.383385 140404617828160 distributed_c10d.py:476] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0926 03:10:43.383441 140096680544064 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0926 03:10:43.383639 140220116084544 distributed_c10d.py:476] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0926 03:10:43.383674 140078343296832 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0926 03:10:43.392683 139876468008768 distributed_c10d.py:476] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0926 03:10:43.392664 139783584151360 distributed_c10d.py:476] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
I0926 03:10:44.621077 139722949982016 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_prelaunch/adamw/imagenet_vit_pytorch.
W0926 03:10:44.662374 140404617828160 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0926 03:10:44.662379 140676642408256 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0926 03:10:44.662409 140096680544064 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0926 03:10:44.662496 139783584151360 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0926 03:10:44.663125 139876468008768 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0926 03:10:44.664903 140220116084544 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0926 03:10:44.664963 140078343296832 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0926 03:10:44.665448 139722949982016 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0926 03:10:44.670960 139722949982016 submission_runner.py:507] Using RNG seed 2804198170
I0926 03:10:44.672518 139722949982016 submission_runner.py:516] --- Tuning run 1/1 ---
I0926 03:10:44.672679 139722949982016 submission_runner.py:521] Creating tuning directory at /experiment_runs/timing_prelaunch/adamw/imagenet_vit_pytorch/trial_1.
I0926 03:10:44.673374 139722949982016 logger_utils.py:92] Saving hparams to /experiment_runs/timing_prelaunch/adamw/imagenet_vit_pytorch/trial_1/hparams.json.
I0926 03:10:44.675405 139722949982016 submission_runner.py:191] Initializing dataset.
I0926 03:10:51.372122 139722949982016 submission_runner.py:198] Initializing model.
I0926 03:10:55.956617 139722949982016 submission_runner.py:229] Performing `torch.compile`.
I0926 03:10:56.577594 139722949982016 submission_runner.py:232] Initializing optimizer.
I0926 03:10:56.579355 139722949982016 submission_runner.py:239] Initializing metrics bundle.
I0926 03:10:56.579486 139722949982016 submission_runner.py:257] Initializing checkpoint and logger.
I0926 03:10:56.580091 139722949982016 submission_runner.py:277] Saving meta data to /experiment_runs/timing_prelaunch/adamw/imagenet_vit_pytorch/trial_1/meta_data_0.json.
I0926 03:10:57.100160 139722949982016 submission_runner.py:280] Saving flags to /experiment_runs/timing_prelaunch/adamw/imagenet_vit_pytorch/trial_1/flags_0.json.
I0926 03:10:57.196570 139722949982016 submission_runner.py:290] Starting training loop.
[2023-09-26 03:10:59,736] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:10:59,737] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:10:59,759] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:10:59,818] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:10:59,823] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:10:59,832] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:10:59,851] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:10:59,890] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:11:02,126] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:11:02,211] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:11:02,215] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:11:02,216] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:11:02,243] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:11:02,306] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:11:02,311] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:11:02,312] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:11:02,381] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:11:02,383] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:11:02,432] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:11:02,436] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:11:02,446] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:11:02,451] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:11:02,452] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:11:02,455] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:11:02,459] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:11:02,466] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:11:02,468] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:11:02,496] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:11:02,498] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:11:02,501] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:11:02,502] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:11:02,503] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:11:02,503] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:11:02,540] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:11:02,590] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:11:02,594] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:11:02,601] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:11:02,603] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:11:02,609] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:11:02,615] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:11:07,937] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-26 03:11:07,937] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-26 03:11:07,937] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-26 03:11:07,937] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-26 03:11:07,939] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-26 03:11:07,941] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-26 03:11:08,076] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-26 03:11:08,146] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-09-26 03:11:14,154] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-26 03:11:14,165] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-26 03:11:14,199] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-26 03:11:14,202] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-26 03:11:14,232] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-26 03:11:14,233] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-26 03:11:14,303] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-26 03:11:14,323] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-09-26 03:11:17,803] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-26 03:11:17,823] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-26 03:11:17,827] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-26 03:11:17,853] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-26 03:11:17,867] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-26 03:11:17,882] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-26 03:11:17,977] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-26 03:11:18,183] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-09-26 03:11:24,777] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-26 03:11:24,792] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-26 03:11:24,832] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-26 03:11:24,842] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-26 03:11:24,845] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-26 03:11:24,877] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-26 03:11:24,966] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-26 03:11:25,189] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-09-26 03:11:28,100] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-26 03:11:28,116] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-26 03:11:28,135] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-26 03:11:28,147] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-26 03:11:28,185] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-26 03:11:28,317] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-26 03:11:28,338] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-26 03:11:28,523] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-09-26 03:11:29,330] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-26 03:11:29,357] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-26 03:11:29,363] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-26 03:11:29,372] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-26 03:11:29,412] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-26 03:11:29,546] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-26 03:11:29,625] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-26 03:11:29,740] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-09-26 03:11:32,604] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-26 03:11:32,638] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-26 03:11:32,640] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-26 03:11:32,645] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-26 03:11:32,693] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-26 03:11:32,845] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-26 03:11:33,025] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-26 03:11:33,066] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-09-26 03:11:36,288] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-26 03:11:36,297] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-26 03:11:36,305] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-26 03:11:36,307] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-26 03:11:36,361] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-26 03:11:36,493] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-26 03:11:36,520] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-26 03:11:36,526] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-26 03:11:36,529] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-26 03:11:36,534] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:11:36,536] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-26 03:11:36,536] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-26 03:11:36,538] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-26 03:11:36,542] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-26 03:11:36,543] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:11:36,544] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-26 03:11:36,549] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:11:36,551] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:11:36,591] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-26 03:11:36,597] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-26 03:11:36,604] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:11:36,716] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-26 03:11:36,722] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-26 03:11:36,729] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-26 03:11:36,736] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:11:36,804] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-09-26 03:11:36,941] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-26 03:11:36,948] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-26 03:11:36,954] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:11:37,040] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-09-26 03:11:37,047] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-09-26 03:11:37,055] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:11:45,592] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-26 03:11:45,592] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-26 03:11:45,601] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-26 03:11:45,604] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-26 03:11:45,630] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-26 03:11:45,635] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-26 03:11:45,642] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-26 03:11:45,677] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-09-26 03:11:46,088] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-26 03:11:46,104] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-26 03:11:46,105] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-26 03:11:46,115] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-26 03:11:46,128] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-26 03:11:46,131] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-26 03:11:46,138] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-26 03:11:46,139] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-26 03:11:46,152] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-26 03:11:46,161] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-26 03:11:46,163] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-26 03:11:46,172] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-26 03:11:46,177] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-26 03:11:46,196] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-26 03:11:46,214] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-09-26 03:11:46,238] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-09-26 03:11:51,013] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-26 03:11:51,014] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-26 03:11:51,059] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-26 03:11:51,098] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-26 03:11:51,164] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-26 03:11:51,182] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-26 03:11:51,215] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-26 03:11:51,232] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-09-26 03:11:53,011] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-26 03:11:53,030] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-26 03:11:53,033] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-26 03:11:53,050] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-26 03:11:53,144] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-26 03:11:53,162] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-26 03:11:53,191] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-26 03:11:53,234] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-09-26 03:11:58,097] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-26 03:11:58,157] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-26 03:11:58,237] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-26 03:11:58,302] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-26 03:11:58,303] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-26 03:11:58,329] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-26 03:11:58,387] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-26 03:11:58,408] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-09-26 03:11:59,309] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-26 03:11:59,367] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-26 03:11:59,447] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-26 03:11:59,509] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-26 03:11:59,513] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-26 03:11:59,538] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-26 03:11:59,595] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-26 03:11:59,618] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-09-26 03:12:01,567] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-26 03:12:01,580] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-26 03:12:01,582] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-26 03:12:01,595] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-26 03:12:01,800] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-26 03:12:01,812] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-26 03:12:01,829] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-26 03:12:01,831] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-26 03:12:01,951] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-26 03:12:01,968] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-26 03:12:01,986] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-26 03:12:02,003] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-26 03:12:02,042] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-26 03:12:02,062] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-09-26 03:12:02,062] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-26 03:12:02,080] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0
[2023-09-26 03:12:02,316] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-26 03:12:02,345] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-26 03:12:02,492] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-26 03:12:02,503] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-26 03:12:02,619] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-26 03:12:02,627] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-26 03:12:02,658] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
[2023-09-26 03:12:02,685] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0
I0926 03:12:03.186861 139694583035648 logging_writer.py:48] [0] global_step=0, grad_norm=0.336163, loss=6.907756
I0926 03:12:03.213835 139722949982016 submission.py:120] 0) loss = 6.908, grad_norm = 0.336
I0926 03:12:03.694251 139722949982016 spec.py:321] Evaluating on the training split.
[2023-09-26 03:12:15,455] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:12:15,489] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:12:15,491] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:12:15,508] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:12:15,571] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:12:15,592] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:12:15,642] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:12:16,170] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:12:17,111] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:12:17,123] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:12:17,131] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:12:17,148] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:12:17,155] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:12:17,158] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:12:17,159] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:12:17,166] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:12:17,169] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:12:17,170] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:12:17,174] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:12:17,177] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:12:17,178] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:12:17,190] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:12:17,194] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:12:17,195] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:12:17,209] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:12:17,252] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:12:17,255] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:12:17,256] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:12:17,283] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:12:17,326] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:12:17,330] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:12:17,330] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:12:17,331] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:12:17,376] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:12:17,379] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:12:17,380] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:12:17,651] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-26 03:12:17,658] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-26 03:12:17,666] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-26 03:12:17,678] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-26 03:12:17,740] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-26 03:12:17,821] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-26 03:12:17,898] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:12:17,899] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-26 03:12:17,943] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:12:17,947] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:12:17,948] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:12:18,548] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-09-26 03:12:20,157] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-26 03:12:20,208] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-26 03:12:20,208] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-26 03:12:20,244] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-26 03:12:20,312] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-26 03:12:20,349] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-26 03:12:20,523] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-26 03:12:21,034] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-09-26 03:12:21,669] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-26 03:12:21,698] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-26 03:12:21,704] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-26 03:12:21,809] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-26 03:12:21,846] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-26 03:12:21,857] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-26 03:12:22,024] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-26 03:12:22,569] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-09-26 03:12:25,360] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-26 03:12:25,385] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-26 03:12:25,425] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-26 03:12:25,463] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-26 03:12:25,518] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-26 03:12:25,570] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-26 03:12:25,679] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-26 03:12:26,334] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-09-26 03:12:27,025] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-26 03:12:27,027] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-26 03:12:27,061] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-26 03:12:27,106] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-26 03:12:27,152] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-26 03:12:27,260] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-26 03:12:27,376] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-26 03:12:27,952] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-09-26 03:12:28,038] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-26 03:12:28,045] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-26 03:12:28,073] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-26 03:12:28,125] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-26 03:12:28,161] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-26 03:12:28,295] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-26 03:12:28,382] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-26 03:12:28,975] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-09-26 03:12:29,457] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-26 03:12:29,487] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-26 03:12:29,501] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-26 03:12:29,552] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-26 03:12:29,572] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-26 03:12:29,785] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-26 03:12:29,806] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-26 03:12:30,395] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-09-26 03:12:33,171] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-26 03:12:33,185] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-26 03:12:33,257] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-26 03:12:33,283] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-26 03:12:33,375] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-26 03:12:33,380] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-26 03:12:33,386] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:12:33,390] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-26 03:12:33,395] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-26 03:12:33,399] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-26 03:12:33,400] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:12:33,448] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-26 03:12:33,458] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-26 03:12:33,463] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-26 03:12:33,468] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:12:33,494] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-26 03:12:33,499] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-26 03:12:33,504] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:12:33,577] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-26 03:12:33,598] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-26 03:12:33,603] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-26 03:12:33,608] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:12:33,657] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-26 03:12:33,662] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-26 03:12:33,667] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:12:33,778] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-26 03:12:33,783] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-26 03:12:33,788] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:12:34,111] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-09-26 03:12:34,306] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-09-26 03:12:34,311] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-09-26 03:12:34,316] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0926 03:13:24.888169 139722949982016 spec.py:333] Evaluating on the validation split.
[2023-09-26 03:14:16,399] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:14:16,553] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:14:16,965] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:14:17,496] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:14:17,538] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:14:17,543] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:14:17,647] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:14:18,280] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:14:18,321] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:14:18,325] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:14:18,325] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:14:18,369] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:14:18,410] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:14:18,414] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:14:18,414] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:14:18,797] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:14:18,816] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-26 03:14:18,838] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:14:18,842] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:14:18,842] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:14:18,890] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-26 03:14:19,317] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:14:19,334] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-26 03:14:19,373] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:14:19,379] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:14:19,386] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:14:19,387] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:14:19,440] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:14:19,446] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:14:19,447] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:14:19,492] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:14:19,539] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:14:19,543] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:14:19,543] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:14:19,615] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:14:19,661] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:14:19,665] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:14:19,665] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:14:19,940] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-26 03:14:19,980] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-26 03:14:20,066] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-26 03:14:20,191] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-26 03:14:20,354] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:14:21,246] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-26 03:14:21,267] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-26 03:14:21,674] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-26 03:14:22,325] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-26 03:14:22,330] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:14:22,377] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:14:22,381] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:14:22,381] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:14:22,389] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-26 03:14:22,407] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-26 03:14:22,593] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-26 03:14:22,783] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-26 03:14:22,797] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-26 03:14:22,905] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-09-26 03:14:23,191] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-26 03:14:23,816] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-26 03:14:23,951] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-26 03:14:23,954] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-26 03:14:24,186] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-26 03:14:25,357] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-09-26 03:14:26,155] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-26 03:14:26,250] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-26 03:14:26,726] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-26 03:14:27,224] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-09-26 03:14:27,378] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-26 03:14:27,497] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-26 03:14:27,585] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-26 03:14:27,706] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-26 03:14:27,941] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-26 03:14:28,014] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-26 03:14:28,461] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-26 03:14:28,994] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-26 03:14:29,032] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-26 03:14:29,098] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-26 03:14:29,169] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-26 03:14:29,255] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-26 03:14:29,374] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-26 03:14:29,546] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-26 03:14:30,061] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-26 03:14:30,191] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-26 03:14:30,273] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-26 03:14:30,284] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-09-26 03:14:30,381] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-26 03:14:30,408] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-26 03:14:30,604] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-26 03:14:30,967] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-26 03:14:31,455] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-26 03:14:31,599] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-26 03:14:31,676] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-26 03:14:31,804] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-26 03:14:31,954] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-09-26 03:14:33,031] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-09-26 03:14:33,134] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-26 03:14:33,335] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-26 03:14:33,340] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-26 03:14:33,346] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:14:33,415] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-26 03:14:33,627] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-26 03:14:33,632] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-26 03:14:33,638] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:14:33,664] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-26 03:14:33,867] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-26 03:14:33,873] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-26 03:14:33,878] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:14:34,195] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-26 03:14:34,317] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-26 03:14:34,386] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-26 03:14:34,394] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-26 03:14:34,399] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-26 03:14:34,404] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:14:34,484] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-09-26 03:14:34,538] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-26 03:14:34,542] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-26 03:14:34,547] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:14:34,562] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-26 03:14:34,580] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-26 03:14:34,585] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-26 03:14:34,591] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:14:34,758] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-26 03:14:34,763] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-26 03:14:34,767] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:14:37,059] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-09-26 03:14:37,256] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-09-26 03:14:37,261] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-09-26 03:14:37,266] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0926 03:14:40.331148 139722949982016 spec.py:349] Evaluating on the test split.
I0926 03:14:40.347208 139722949982016 dataset_info.py:578] Load dataset info from /data/imagenet/pytorch/imagenet_v2/matched-frequency/3.0.0
I0926 03:14:40.353233 139722949982016 dataset_builder.py:528] Reusing dataset imagenet_v2 (/data/imagenet/pytorch/imagenet_v2/matched-frequency/3.0.0)
I0926 03:14:40.429530 139722949982016 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/pytorch/imagenet_v2/matched-frequency/3.0.0
[2023-09-26 03:14:43,536] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:14:43,613] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:14:43,833] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:14:43,845] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:14:43,970] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:14:44,060] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:14:44,280] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:14:44,283] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-09-26 03:14:49,081] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:14:49,121] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:14:49,125] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:14:49,125] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:14:49,152] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:14:49,178] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:14:49,192] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:14:49,196] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:14:49,196] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:14:49,218] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:14:49,222] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:14:49,222] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:14:49,245] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:14:49,250] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:14:49,267] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:14:49,284] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:14:49,285] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:14:49,289] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:14:49,290] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:14:49,292] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:14:49,293] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-09-26 03:14:49,296] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:14:49,296] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:14:49,308] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:14:49,312] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:14:49,312] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:14:49,325] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:14:49,329] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:14:49,330] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:14:49,334] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-09-26 03:14:49,337] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-09-26 03:14:49,338] torch._dynamo.backends.distributed: [INFO] Please `pip install tabulate` in order to pretty-print ddp bucket sizes
[2023-09-26 03:14:49,603] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-26 03:14:49,679] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-26 03:14:49,706] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-26 03:14:49,772] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-26 03:14:49,785] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-26 03:14:49,789] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-26 03:14:49,809] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-26 03:14:49,821] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-09-26 03:14:50,415] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-26 03:14:50,459] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-26 03:14:50,509] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-26 03:14:50,583] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-26 03:14:50,616] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-26 03:14:50,625] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-26 03:14:50,644] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-26 03:14:50,665] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-09-26 03:14:51,862] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-26 03:14:51,926] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-26 03:14:51,968] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-26 03:14:52,028] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-26 03:14:52,066] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-26 03:14:52,091] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-26 03:14:52,101] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-26 03:14:52,111] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-09-26 03:14:53,204] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-26 03:14:53,328] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-26 03:14:53,337] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-26 03:14:53,365] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-26 03:14:53,414] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-26 03:14:53,443] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-26 03:14:53,462] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-26 03:14:53,505] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-09-26 03:14:54,805] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-26 03:14:54,919] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-26 03:14:54,920] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-26 03:14:54,950] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-26 03:14:55,009] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-26 03:14:55,041] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-26 03:14:55,071] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-26 03:14:55,093] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-09-26 03:14:55,755] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-26 03:14:55,870] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-26 03:14:55,875] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-26 03:14:55,905] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-26 03:14:55,948] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-26 03:14:55,995] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-26 03:14:56,027] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-26 03:14:56,037] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-09-26 03:14:57,130] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-26 03:14:57,258] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-26 03:14:57,265] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-26 03:14:57,275] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-26 03:14:57,332] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-26 03:14:57,385] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-26 03:14:57,427] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-26 03:14:57,439] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-09-26 03:14:58,573] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-26 03:14:58,698] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-26 03:14:58,718] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-26 03:14:58,760] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-26 03:14:58,770] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-26 03:14:58,782] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-26 03:14:58,785] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-26 03:14:58,791] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:14:58,826] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-26 03:14:58,866] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-26 03:14:58,893] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-09-26 03:14:58,964] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-26 03:14:58,968] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-26 03:14:58,970] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-26 03:14:58,971] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-26 03:14:58,973] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:14:58,974] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-26 03:14:58,975] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-26 03:14:58,979] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:14:58,980] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:14:58,982] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-26 03:14:58,986] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-26 03:14:58,992] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:14:59,046] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-26 03:14:59,051] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-26 03:14:59,059] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:14:59,105] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-26 03:14:59,112] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-26 03:14:59,113] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-09-26 03:14:59,117] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-09-26 03:14:59,120] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-09-26 03:14:59,124] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0926 03:15:05.031284 139722949982016 submission_runner.py:381] Time since start: 247.84s, 	Step: 1, 	{'train/accuracy': 0.0021875, 'train/loss': 6.90775634765625, 'validation/accuracy': 0.00204, 'validation/loss': 6.907755625, 'validation/num_examples': 50000, 'test/accuracy': 0.002, 'test/loss': 6.90775546875, 'test/num_examples': 10000, 'score': 66.02616572380066, 'total_duration': 247.83518886566162, 'accumulated_submission_time': 66.02616572380066, 'accumulated_eval_time': 181.3371286392212, 'accumulated_logging_time': 0}
I0926 03:15:05.050520 139689021359872 logging_writer.py:48] [1] accumulated_eval_time=181.337129, accumulated_logging_time=0, accumulated_submission_time=66.026166, global_step=1, preemption_count=0, score=66.026166, test/accuracy=0.002000, test/loss=6.907755, test/num_examples=10000, total_duration=247.835189, train/accuracy=0.002188, train/loss=6.907756, validation/accuracy=0.002040, validation/loss=6.907756, validation/num_examples=50000
I0926 03:15:05.550708 139722949982016 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0926 03:15:05.550671 140078343296832 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0926 03:15:05.550688 140096680544064 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0926 03:15:05.552048 140676642408256 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0926 03:15:05.554443 140220116084544 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0926 03:15:05.554428 140404617828160 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0926 03:15:05.554444 139876468008768 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0926 03:15:05.554847 139783584151360 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0926 03:15:06.208520 139689012967168 logging_writer.py:48] [1] global_step=1, grad_norm=0.348293, loss=6.907756
I0926 03:15:06.213278 139722949982016 submission.py:120] 1) loss = 6.908, grad_norm = 0.348
I0926 03:15:06.634541 139689021359872 logging_writer.py:48] [2] global_step=2, grad_norm=0.346023, loss=6.907755
I0926 03:15:06.638755 139722949982016 submission.py:120] 2) loss = 6.908, grad_norm = 0.346
I0926 03:15:07.025325 139689012967168 logging_writer.py:48] [3] global_step=3, grad_norm=0.350753, loss=6.907752
I0926 03:15:07.029059 139722949982016 submission.py:120] 3) loss = 6.908, grad_norm = 0.351
I0926 03:15:07.415116 139689021359872 logging_writer.py:48] [4] global_step=4, grad_norm=0.343426, loss=6.907752
I0926 03:15:07.419438 139722949982016 submission.py:120] 4) loss = 6.908, grad_norm = 0.343
I0926 03:15:07.811308 139689012967168 logging_writer.py:48] [5] global_step=5, grad_norm=0.349346, loss=6.907757
I0926 03:15:07.815349 139722949982016 submission.py:120] 5) loss = 6.908, grad_norm = 0.349
I0926 03:15:08.203831 139689021359872 logging_writer.py:48] [6] global_step=6, grad_norm=0.352112, loss=6.907742
I0926 03:15:08.207697 139722949982016 submission.py:120] 6) loss = 6.908, grad_norm = 0.352
I0926 03:15:08.596957 139689012967168 logging_writer.py:48] [7] global_step=7, grad_norm=0.353721, loss=6.907745
I0926 03:15:08.600967 139722949982016 submission.py:120] 7) loss = 6.908, grad_norm = 0.354
I0926 03:15:08.993435 139689021359872 logging_writer.py:48] [8] global_step=8, grad_norm=0.351904, loss=6.907742
I0926 03:15:08.998770 139722949982016 submission.py:120] 8) loss = 6.908, grad_norm = 0.352
I0926 03:15:09.388594 139689012967168 logging_writer.py:48] [9] global_step=9, grad_norm=0.356184, loss=6.907746
I0926 03:15:09.394198 139722949982016 submission.py:120] 9) loss = 6.908, grad_norm = 0.356
I0926 03:15:09.805646 139689021359872 logging_writer.py:48] [10] global_step=10, grad_norm=0.351638, loss=6.907731
I0926 03:15:09.809881 139722949982016 submission.py:120] 10) loss = 6.908, grad_norm = 0.352
I0926 03:18:27.201509 139689012967168 logging_writer.py:48] [500] global_step=500, grad_norm=0.699739, loss=6.666995
I0926 03:18:27.207662 139722949982016 submission.py:120] 500) loss = 6.667, grad_norm = 0.700
I0926 03:21:49.880929 139689021359872 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.081276, loss=6.371339
I0926 03:21:49.888957 139722949982016 submission.py:120] 1000) loss = 6.371, grad_norm = 1.081
I0926 03:22:06.498075 139722949982016 spec.py:321] Evaluating on the training split.
I0926 03:22:52.849215 139722949982016 spec.py:333] Evaluating on the validation split.
I0926 03:23:49.920153 139722949982016 spec.py:349] Evaluating on the test split.
I0926 03:23:51.368867 139722949982016 submission_runner.py:381] Time since start: 774.17s, 	Step: 1039, 	{'train/accuracy': 0.03521484375, 'train/loss': 5.912533569335937, 'validation/accuracy': 0.03592, 'validation/loss': 5.94000875, 'validation/num_examples': 50000, 'test/accuracy': 0.0267, 'test/loss': 6.051971484375, 'test/num_examples': 10000, 'score': 485.24132657051086, 'total_duration': 774.1728847026825, 'accumulated_submission_time': 485.24132657051086, 'accumulated_eval_time': 286.2086441516876, 'accumulated_logging_time': 0.027428388595581055}
I0926 03:23:51.386044 139678351083264 logging_writer.py:48] [1039] accumulated_eval_time=286.208644, accumulated_logging_time=0.027428, accumulated_submission_time=485.241327, global_step=1039, preemption_count=0, score=485.241327, test/accuracy=0.026700, test/loss=6.051971, test/num_examples=10000, total_duration=774.172885, train/accuracy=0.035215, train/loss=5.912534, validation/accuracy=0.035920, validation/loss=5.940009, validation/num_examples=50000
I0926 03:26:56.557078 139678359475968 logging_writer.py:48] [1500] global_step=1500, grad_norm=1.103080, loss=6.140960
I0926 03:26:56.562598 139722949982016 submission.py:120] 1500) loss = 6.141, grad_norm = 1.103
I0926 03:30:12.311424 139678351083264 logging_writer.py:48] [2000] global_step=2000, grad_norm=1.272245, loss=6.060458
I0926 03:30:12.317112 139722949982016 submission.py:120] 2000) loss = 6.060, grad_norm = 1.272
I0926 03:30:52.448707 139722949982016 spec.py:321] Evaluating on the training split.
I0926 03:31:38.244134 139722949982016 spec.py:333] Evaluating on the validation split.
I0926 03:32:36.008081 139722949982016 spec.py:349] Evaluating on the test split.
I0926 03:32:37.421501 139722949982016 submission_runner.py:381] Time since start: 1300.23s, 	Step: 2101, 	{'train/accuracy': 0.081875, 'train/loss': 5.245897827148437, 'validation/accuracy': 0.07766, 'validation/loss': 5.291456875, 'validation/num_examples': 50000, 'test/accuracy': 0.0588, 'test/loss': 5.496321875, 'test/num_examples': 10000, 'score': 904.0592317581177, 'total_duration': 1300.225441455841, 'accumulated_submission_time': 904.0592317581177, 'accumulated_eval_time': 391.18163108825684, 'accumulated_logging_time': 0.05280613899230957}
I0926 03:32:37.441323 139678359475968 logging_writer.py:48] [2101] accumulated_eval_time=391.181631, accumulated_logging_time=0.052806, accumulated_submission_time=904.059232, global_step=2101, preemption_count=0, score=904.059232, test/accuracy=0.058800, test/loss=5.496322, test/num_examples=10000, total_duration=1300.225441, train/accuracy=0.081875, train/loss=5.245898, validation/accuracy=0.077660, validation/loss=5.291457, validation/num_examples=50000
I0926 03:35:21.493019 139678351083264 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.837847, loss=6.046783
I0926 03:35:21.497112 139722949982016 submission.py:120] 2500) loss = 6.047, grad_norm = 0.838
I0926 03:38:38.717716 139678359475968 logging_writer.py:48] [3000] global_step=3000, grad_norm=1.211187, loss=5.772138
I0926 03:38:38.724485 139722949982016 submission.py:120] 3000) loss = 5.772, grad_norm = 1.211
I0926 03:39:38.688590 139722949982016 spec.py:321] Evaluating on the training split.
I0926 03:40:22.559083 139722949982016 spec.py:333] Evaluating on the validation split.
I0926 03:41:07.799867 139722949982016 spec.py:349] Evaluating on the test split.
I0926 03:41:09.214850 139722949982016 submission_runner.py:381] Time since start: 1812.02s, 	Step: 3152, 	{'train/accuracy': 0.13982421875, 'train/loss': 4.692079467773437, 'validation/accuracy': 0.13014, 'validation/loss': 4.7640534375, 'validation/num_examples': 50000, 'test/accuracy': 0.0971, 'test/loss': 5.039325390625, 'test/num_examples': 10000, 'score': 1322.984524488449, 'total_duration': 1812.0188994407654, 'accumulated_submission_time': 1322.984524488449, 'accumulated_eval_time': 481.70830726623535, 'accumulated_logging_time': 0.08301806449890137}
I0926 03:41:09.230253 139678351083264 logging_writer.py:48] [3152] accumulated_eval_time=481.708307, accumulated_logging_time=0.083018, accumulated_submission_time=1322.984524, global_step=3152, preemption_count=0, score=1322.984524, test/accuracy=0.097100, test/loss=5.039325, test/num_examples=10000, total_duration=1812.018899, train/accuracy=0.139824, train/loss=4.692079, validation/accuracy=0.130140, validation/loss=4.764053, validation/num_examples=50000
I0926 03:43:27.011651 139678359475968 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.823748, loss=5.532182
I0926 03:43:27.016523 139722949982016 submission.py:120] 3500) loss = 5.532, grad_norm = 0.824
I0926 03:46:48.064301 139678351083264 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.793036, loss=5.664681
I0926 03:46:48.070175 139722949982016 submission.py:120] 4000) loss = 5.665, grad_norm = 0.793
I0926 03:48:10.337088 139722949982016 spec.py:321] Evaluating on the training split.
I0926 03:48:56.522239 139722949982016 spec.py:333] Evaluating on the validation split.
I0926 03:49:42.291943 139722949982016 spec.py:349] Evaluating on the test split.
I0926 03:49:43.711165 139722949982016 submission_runner.py:381] Time since start: 2326.51s, 	Step: 4209, 	{'train/accuracy': 0.19333984375, 'train/loss': 4.2636181640625, 'validation/accuracy': 0.17996, 'validation/loss': 4.3643225, 'validation/num_examples': 50000, 'test/accuracy': 0.1356, 'test/loss': 4.72994375, 'test/num_examples': 10000, 'score': 1741.8057217597961, 'total_duration': 2326.513771057129, 'accumulated_submission_time': 1741.8057217597961, 'accumulated_eval_time': 575.0815587043762, 'accumulated_logging_time': 0.10768294334411621}
I0926 03:49:43.730393 139678359475968 logging_writer.py:48] [4209] accumulated_eval_time=575.081559, accumulated_logging_time=0.107683, accumulated_submission_time=1741.805722, global_step=4209, preemption_count=0, score=1741.805722, test/accuracy=0.135600, test/loss=4.729944, test/num_examples=10000, total_duration=2326.513771, train/accuracy=0.193340, train/loss=4.263618, validation/accuracy=0.179960, validation/loss=4.364323, validation/num_examples=50000
I0926 03:51:38.667780 139678351083264 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.774751, loss=5.507532
I0926 03:51:38.674244 139722949982016 submission.py:120] 4500) loss = 5.508, grad_norm = 0.775
I0926 03:55:01.968017 139678359475968 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.858522, loss=5.310894
I0926 03:55:01.976557 139722949982016 submission.py:120] 5000) loss = 5.311, grad_norm = 0.859
I0926 03:56:44.937377 139722949982016 spec.py:321] Evaluating on the training split.
I0926 03:57:31.211737 139722949982016 spec.py:333] Evaluating on the validation split.
I0926 03:58:17.946661 139722949982016 spec.py:349] Evaluating on the test split.
I0926 03:58:19.364945 139722949982016 submission_runner.py:381] Time since start: 2842.17s, 	Step: 5257, 	{'train/accuracy': 0.24576171875, 'train/loss': 3.8193963623046874, 'validation/accuracy': 0.22638, 'validation/loss': 3.946781875, 'validation/num_examples': 50000, 'test/accuracy': 0.172, 'test/loss': 4.37496328125, 'test/num_examples': 10000, 'score': 2160.7235345840454, 'total_duration': 2842.1688544750214, 'accumulated_submission_time': 2160.7235345840454, 'accumulated_eval_time': 669.5091352462769, 'accumulated_logging_time': 0.13694500923156738}
I0926 03:58:19.384409 139678351083264 logging_writer.py:48] [5257] accumulated_eval_time=669.509135, accumulated_logging_time=0.136945, accumulated_submission_time=2160.723535, global_step=5257, preemption_count=0, score=2160.723535, test/accuracy=0.172000, test/loss=4.374963, test/num_examples=10000, total_duration=2842.168854, train/accuracy=0.245762, train/loss=3.819396, validation/accuracy=0.226380, validation/loss=3.946782, validation/num_examples=50000
I0926 03:59:55.476352 139678359475968 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.980176, loss=5.503963
I0926 03:59:55.482309 139722949982016 submission.py:120] 5500) loss = 5.504, grad_norm = 0.980
I0926 04:03:13.489530 139678351083264 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.778885, loss=4.968061
I0926 04:03:13.495861 139722949982016 submission.py:120] 6000) loss = 4.968, grad_norm = 0.779
I0926 04:05:20.390497 139722949982016 spec.py:321] Evaluating on the training split.
I0926 04:06:05.957433 139722949982016 spec.py:333] Evaluating on the validation split.
I0926 04:07:03.474056 139722949982016 spec.py:349] Evaluating on the test split.
I0926 04:07:04.888666 139722949982016 submission_runner.py:381] Time since start: 3367.69s, 	Step: 6306, 	{'train/accuracy': 0.29228515625, 'train/loss': 3.548459167480469, 'validation/accuracy': 0.26728, 'validation/loss': 3.6847228125, 'validation/num_examples': 50000, 'test/accuracy': 0.2073, 'test/loss': 4.14680859375, 'test/num_examples': 10000, 'score': 2579.431699037552, 'total_duration': 3367.6913437843323, 'accumulated_submission_time': 2579.431699037552, 'accumulated_eval_time': 774.0063557624817, 'accumulated_logging_time': 0.16499733924865723}
I0926 04:07:04.909669 139678359475968 logging_writer.py:48] [6306] accumulated_eval_time=774.006356, accumulated_logging_time=0.164997, accumulated_submission_time=2579.431699, global_step=6306, preemption_count=0, score=2579.431699, test/accuracy=0.207300, test/loss=4.146809, test/num_examples=10000, total_duration=3367.691344, train/accuracy=0.292285, train/loss=3.548459, validation/accuracy=0.267280, validation/loss=3.684723, validation/num_examples=50000
I0926 04:08:21.856384 139678351083264 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.807770, loss=4.828322
I0926 04:08:21.861668 139722949982016 submission.py:120] 6500) loss = 4.828, grad_norm = 0.808
I0926 04:11:36.982036 139678359475968 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.749105, loss=4.739745
I0926 04:11:36.988292 139722949982016 submission.py:120] 7000) loss = 4.740, grad_norm = 0.749
I0926 04:14:06.065356 139722949982016 spec.py:321] Evaluating on the training split.
I0926 04:14:50.516594 139722949982016 spec.py:333] Evaluating on the validation split.
I0926 04:15:40.439906 139722949982016 spec.py:349] Evaluating on the test split.
I0926 04:15:41.853709 139722949982016 submission_runner.py:381] Time since start: 3884.66s, 	Step: 7368, 	{'train/accuracy': 0.33767578125, 'train/loss': 3.2392898559570313, 'validation/accuracy': 0.31054, 'validation/loss': 3.3931540625, 'validation/num_examples': 50000, 'test/accuracy': 0.2388, 'test/loss': 3.90351640625, 'test/num_examples': 10000, 'score': 2998.300581216812, 'total_duration': 3884.6576652526855, 'accumulated_submission_time': 2998.300581216812, 'accumulated_eval_time': 869.7952306270599, 'accumulated_logging_time': 0.1945481300354004}
I0926 04:15:41.870953 139678351083264 logging_writer.py:48] [7368] accumulated_eval_time=869.795231, accumulated_logging_time=0.194548, accumulated_submission_time=2998.300581, global_step=7368, preemption_count=0, score=2998.300581, test/accuracy=0.238800, test/loss=3.903516, test/num_examples=10000, total_duration=3884.657665, train/accuracy=0.337676, train/loss=3.239290, validation/accuracy=0.310540, validation/loss=3.393154, validation/num_examples=50000
I0926 04:16:36.827530 139678359475968 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.693034, loss=4.871411
I0926 04:16:36.831111 139722949982016 submission.py:120] 7500) loss = 4.871, grad_norm = 0.693
I0926 04:19:53.492443 139678351083264 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.743416, loss=4.780430
I0926 04:19:53.498142 139722949982016 submission.py:120] 8000) loss = 4.780, grad_norm = 0.743
I0926 04:22:43.266127 139722949982016 spec.py:321] Evaluating on the training split.
I0926 04:23:27.070114 139722949982016 spec.py:333] Evaluating on the validation split.
I0926 04:24:11.965879 139722949982016 spec.py:349] Evaluating on the test split.
I0926 04:24:13.384193 139722949982016 submission_runner.py:381] Time since start: 4396.19s, 	Step: 8429, 	{'train/accuracy': 0.3815625, 'train/loss': 2.94593505859375, 'validation/accuracy': 0.34916, 'validation/loss': 3.114986875, 'validation/num_examples': 50000, 'test/accuracy': 0.2656, 'test/loss': 3.669510546875, 'test/num_examples': 10000, 'score': 3417.3488733768463, 'total_duration': 4396.188070058823, 'accumulated_submission_time': 3417.3488733768463, 'accumulated_eval_time': 959.9135596752167, 'accumulated_logging_time': 0.2210242748260498}
I0926 04:24:13.402522 139678359475968 logging_writer.py:48] [8429] accumulated_eval_time=959.913560, accumulated_logging_time=0.221024, accumulated_submission_time=3417.348873, global_step=8429, preemption_count=0, score=3417.348873, test/accuracy=0.265600, test/loss=3.669511, test/num_examples=10000, total_duration=4396.188070, train/accuracy=0.381563, train/loss=2.945935, validation/accuracy=0.349160, validation/loss=3.114987, validation/num_examples=50000
I0926 04:24:42.910654 139678351083264 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.595770, loss=4.905020
I0926 04:24:42.916154 139722949982016 submission.py:120] 8500) loss = 4.905, grad_norm = 0.596
I0926 04:28:04.277634 139678359475968 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.693290, loss=4.554199
I0926 04:28:04.283347 139722949982016 submission.py:120] 9000) loss = 4.554, grad_norm = 0.693
I0926 04:31:14.692403 139722949982016 spec.py:321] Evaluating on the training split.
I0926 04:32:01.156720 139722949982016 spec.py:333] Evaluating on the validation split.
I0926 04:32:52.045107 139722949982016 spec.py:349] Evaluating on the test split.
I0926 04:32:53.461678 139722949982016 submission_runner.py:381] Time since start: 4916.27s, 	Step: 9487, 	{'train/accuracy': 0.41791015625, 'train/loss': 2.7536737060546876, 'validation/accuracy': 0.3832, 'validation/loss': 2.9346303125, 'validation/num_examples': 50000, 'test/accuracy': 0.2941, 'test/loss': 3.509633984375, 'test/num_examples': 10000, 'score': 3836.3886811733246, 'total_duration': 4916.265642166138, 'accumulated_submission_time': 3836.3886811733246, 'accumulated_eval_time': 1058.6830055713654, 'accumulated_logging_time': 0.24958181381225586}
I0926 04:32:53.480423 139678351083264 logging_writer.py:48] [9487] accumulated_eval_time=1058.683006, accumulated_logging_time=0.249582, accumulated_submission_time=3836.388681, global_step=9487, preemption_count=0, score=3836.388681, test/accuracy=0.294100, test/loss=3.509634, test/num_examples=10000, total_duration=4916.265642, train/accuracy=0.417910, train/loss=2.753674, validation/accuracy=0.383200, validation/loss=2.934630, validation/num_examples=50000
I0926 04:32:59.750803 139678359475968 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.609271, loss=5.182281
I0926 04:32:59.757096 139722949982016 submission.py:120] 9500) loss = 5.182, grad_norm = 0.609
I0926 04:36:21.331822 139678351083264 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.728959, loss=4.378097
I0926 04:36:21.337060 139722949982016 submission.py:120] 10000) loss = 4.378, grad_norm = 0.729
I0926 04:39:38.287357 139678359475968 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.581979, loss=4.516352
I0926 04:39:38.293995 139722949982016 submission.py:120] 10500) loss = 4.516, grad_norm = 0.582
I0926 04:39:54.497073 139722949982016 spec.py:321] Evaluating on the training split.
I0926 04:40:39.547397 139722949982016 spec.py:333] Evaluating on the validation split.
I0926 04:41:25.061793 139722949982016 spec.py:349] Evaluating on the test split.
I0926 04:41:26.477627 139722949982016 submission_runner.py:381] Time since start: 5429.28s, 	Step: 10540, 	{'train/accuracy': 0.4471875, 'train/loss': 2.656771545410156, 'validation/accuracy': 0.40756, 'validation/loss': 2.84613625, 'validation/num_examples': 50000, 'test/accuracy': 0.3189, 'test/loss': 3.37608515625, 'test/num_examples': 10000, 'score': 4255.131338834763, 'total_duration': 5429.279645681381, 'accumulated_submission_time': 4255.131338834763, 'accumulated_eval_time': 1150.6619889736176, 'accumulated_logging_time': 0.27755308151245117}
I0926 04:41:26.493163 139678351083264 logging_writer.py:48] [10540] accumulated_eval_time=1150.661989, accumulated_logging_time=0.277553, accumulated_submission_time=4255.131339, global_step=10540, preemption_count=0, score=4255.131339, test/accuracy=0.318900, test/loss=3.376085, test/num_examples=10000, total_duration=5429.279646, train/accuracy=0.447188, train/loss=2.656772, validation/accuracy=0.407560, validation/loss=2.846136, validation/num_examples=50000
I0926 04:44:29.996214 139678359475968 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.748930, loss=4.287637
I0926 04:44:30.004935 139722949982016 submission.py:120] 11000) loss = 4.288, grad_norm = 0.749
I0926 04:47:51.793114 139678351083264 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.601582, loss=4.410650
I0926 04:47:51.799461 139722949982016 submission.py:120] 11500) loss = 4.411, grad_norm = 0.602
I0926 04:48:27.491368 139722949982016 spec.py:321] Evaluating on the training split.
I0926 04:49:14.460111 139722949982016 spec.py:333] Evaluating on the validation split.
I0926 04:50:01.408605 139722949982016 spec.py:349] Evaluating on the test split.
I0926 04:50:02.829635 139722949982016 submission_runner.py:381] Time since start: 5945.63s, 	Step: 11590, 	{'train/accuracy': 0.48716796875, 'train/loss': 2.4142074584960938, 'validation/accuracy': 0.44586, 'validation/loss': 2.615408125, 'validation/num_examples': 50000, 'test/accuracy': 0.349, 'test/loss': 3.1775396484375, 'test/num_examples': 10000, 'score': 4673.912573814392, 'total_duration': 5945.633569955826, 'accumulated_submission_time': 4673.912573814392, 'accumulated_eval_time': 1246.0005843639374, 'accumulated_logging_time': 0.3014237880706787}
I0926 04:50:02.848239 139678359475968 logging_writer.py:48] [11590] accumulated_eval_time=1246.000584, accumulated_logging_time=0.301424, accumulated_submission_time=4673.912574, global_step=11590, preemption_count=0, score=4673.912574, test/accuracy=0.349000, test/loss=3.177540, test/num_examples=10000, total_duration=5945.633570, train/accuracy=0.487168, train/loss=2.414207, validation/accuracy=0.445860, validation/loss=2.615408, validation/num_examples=50000
I0926 04:52:44.665116 139678351083264 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.553029, loss=4.515501
I0926 04:52:44.671663 139722949982016 submission.py:120] 12000) loss = 4.516, grad_norm = 0.553
I0926 04:56:07.192729 139678359475968 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.672463, loss=4.441717
I0926 04:56:07.198346 139722949982016 submission.py:120] 12500) loss = 4.442, grad_norm = 0.672
I0926 04:57:04.043545 139722949982016 spec.py:321] Evaluating on the training split.
I0926 04:57:51.195214 139722949982016 spec.py:333] Evaluating on the validation split.
I0926 04:58:37.105827 139722949982016 spec.py:349] Evaluating on the test split.
I0926 04:58:38.520005 139722949982016 submission_runner.py:381] Time since start: 6461.32s, 	Step: 12639, 	{'train/accuracy': 0.52642578125, 'train/loss': 2.1602520751953125, 'validation/accuracy': 0.47882, 'validation/loss': 2.38573515625, 'validation/num_examples': 50000, 'test/accuracy': 0.3789, 'test/loss': 2.99403359375, 'test/num_examples': 10000, 'score': 5092.856876373291, 'total_duration': 6461.322880029678, 'accumulated_submission_time': 5092.856876373291, 'accumulated_eval_time': 1340.4762287139893, 'accumulated_logging_time': 0.3295118808746338}
I0926 04:58:38.538090 139678351083264 logging_writer.py:48] [12639] accumulated_eval_time=1340.476229, accumulated_logging_time=0.329512, accumulated_submission_time=5092.856876, global_step=12639, preemption_count=0, score=5092.856876, test/accuracy=0.378900, test/loss=2.994034, test/num_examples=10000, total_duration=6461.322880, train/accuracy=0.526426, train/loss=2.160252, validation/accuracy=0.478820, validation/loss=2.385735, validation/num_examples=50000
I0926 05:01:00.748412 139678359475968 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.649270, loss=4.701129
I0926 05:01:00.756187 139722949982016 submission.py:120] 13000) loss = 4.701, grad_norm = 0.649
I0926 05:04:18.297766 139678351083264 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.659060, loss=3.884709
I0926 05:04:18.303469 139722949982016 submission.py:120] 13500) loss = 3.885, grad_norm = 0.659
I0926 05:05:39.650405 139722949982016 spec.py:321] Evaluating on the training split.
I0926 05:06:24.509245 139722949982016 spec.py:333] Evaluating on the validation split.
I0926 05:07:21.471671 139722949982016 spec.py:349] Evaluating on the test split.
I0926 05:07:22.881456 139722949982016 submission_runner.py:381] Time since start: 6985.69s, 	Step: 13696, 	{'train/accuracy': 0.53833984375, 'train/loss': 2.090040588378906, 'validation/accuracy': 0.49022, 'validation/loss': 2.3185853125, 'validation/num_examples': 50000, 'test/accuracy': 0.39, 'test/loss': 2.913304296875, 'test/num_examples': 10000, 'score': 5511.724960327148, 'total_duration': 6985.685417890549, 'accumulated_submission_time': 5511.724960327148, 'accumulated_eval_time': 1443.7075390815735, 'accumulated_logging_time': 0.35614919662475586}
I0926 05:07:22.904000 139678359475968 logging_writer.py:48] [13696] accumulated_eval_time=1443.707539, accumulated_logging_time=0.356149, accumulated_submission_time=5511.724960, global_step=13696, preemption_count=0, score=5511.724960, test/accuracy=0.390000, test/loss=2.913304, test/num_examples=10000, total_duration=6985.685418, train/accuracy=0.538340, train/loss=2.090041, validation/accuracy=0.490220, validation/loss=2.318585, validation/num_examples=50000
I0926 05:09:25.735819 139722949982016 spec.py:321] Evaluating on the training split.
I0926 05:10:09.603243 139722949982016 spec.py:333] Evaluating on the validation split.
I0926 05:10:56.095603 139722949982016 spec.py:349] Evaluating on the test split.
I0926 05:10:57.509346 139722949982016 submission_runner.py:381] Time since start: 7200.31s, 	Step: 14000, 	{'train/accuracy': 0.53525390625, 'train/loss': 2.149097442626953, 'validation/accuracy': 0.49306, 'validation/loss': 2.37105328125, 'validation/num_examples': 50000, 'test/accuracy': 0.3779, 'test/loss': 2.9879953125, 'test/num_examples': 10000, 'score': 5632.833034276962, 'total_duration': 7200.313250541687, 'accumulated_submission_time': 5632.833034276962, 'accumulated_eval_time': 1535.4814357757568, 'accumulated_logging_time': 0.39162588119506836}
I0926 05:10:57.524271 139678351083264 logging_writer.py:48] [14000] accumulated_eval_time=1535.481436, accumulated_logging_time=0.391626, accumulated_submission_time=5632.833034, global_step=14000, preemption_count=0, score=5632.833034, test/accuracy=0.377900, test/loss=2.987995, test/num_examples=10000, total_duration=7200.313251, train/accuracy=0.535254, train/loss=2.149097, validation/accuracy=0.493060, validation/loss=2.371053, validation/num_examples=50000
I0926 05:10:58.074579 139678359475968 logging_writer.py:48] [14000] global_step=14000, preemption_count=0, score=5632.833034
I0926 05:10:58.898308 139722949982016 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_prelaunch/adamw/imagenet_vit_pytorch/trial_1/checkpoint_14000.
I0926 05:10:59.362030 139722949982016 submission_runner.py:549] Tuning trial 1/1
I0926 05:10:59.362252 139722949982016 submission_runner.py:550] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0926 05:10:59.363316 139722949982016 submission_runner.py:551] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0021875, 'train/loss': 6.90775634765625, 'validation/accuracy': 0.00204, 'validation/loss': 6.907755625, 'validation/num_examples': 50000, 'test/accuracy': 0.002, 'test/loss': 6.90775546875, 'test/num_examples': 10000, 'score': 66.02616572380066, 'total_duration': 247.83518886566162, 'accumulated_submission_time': 66.02616572380066, 'accumulated_eval_time': 181.3371286392212, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (1039, {'train/accuracy': 0.03521484375, 'train/loss': 5.912533569335937, 'validation/accuracy': 0.03592, 'validation/loss': 5.94000875, 'validation/num_examples': 50000, 'test/accuracy': 0.0267, 'test/loss': 6.051971484375, 'test/num_examples': 10000, 'score': 485.24132657051086, 'total_duration': 774.1728847026825, 'accumulated_submission_time': 485.24132657051086, 'accumulated_eval_time': 286.2086441516876, 'accumulated_logging_time': 0.027428388595581055, 'global_step': 1039, 'preemption_count': 0}), (2101, {'train/accuracy': 0.081875, 'train/loss': 5.245897827148437, 'validation/accuracy': 0.07766, 'validation/loss': 5.291456875, 'validation/num_examples': 50000, 'test/accuracy': 0.0588, 'test/loss': 5.496321875, 'test/num_examples': 10000, 'score': 904.0592317581177, 'total_duration': 1300.225441455841, 'accumulated_submission_time': 904.0592317581177, 'accumulated_eval_time': 391.18163108825684, 'accumulated_logging_time': 0.05280613899230957, 'global_step': 2101, 'preemption_count': 0}), (3152, {'train/accuracy': 0.13982421875, 'train/loss': 4.692079467773437, 'validation/accuracy': 0.13014, 'validation/loss': 4.7640534375, 'validation/num_examples': 50000, 'test/accuracy': 0.0971, 'test/loss': 5.039325390625, 'test/num_examples': 10000, 'score': 1322.984524488449, 'total_duration': 1812.0188994407654, 'accumulated_submission_time': 1322.984524488449, 'accumulated_eval_time': 481.70830726623535, 'accumulated_logging_time': 0.08301806449890137, 'global_step': 3152, 'preemption_count': 0}), (4209, {'train/accuracy': 0.19333984375, 'train/loss': 4.2636181640625, 'validation/accuracy': 0.17996, 'validation/loss': 4.3643225, 'validation/num_examples': 50000, 'test/accuracy': 0.1356, 'test/loss': 4.72994375, 'test/num_examples': 10000, 'score': 1741.8057217597961, 'total_duration': 2326.513771057129, 'accumulated_submission_time': 1741.8057217597961, 'accumulated_eval_time': 575.0815587043762, 'accumulated_logging_time': 0.10768294334411621, 'global_step': 4209, 'preemption_count': 0}), (5257, {'train/accuracy': 0.24576171875, 'train/loss': 3.8193963623046874, 'validation/accuracy': 0.22638, 'validation/loss': 3.946781875, 'validation/num_examples': 50000, 'test/accuracy': 0.172, 'test/loss': 4.37496328125, 'test/num_examples': 10000, 'score': 2160.7235345840454, 'total_duration': 2842.1688544750214, 'accumulated_submission_time': 2160.7235345840454, 'accumulated_eval_time': 669.5091352462769, 'accumulated_logging_time': 0.13694500923156738, 'global_step': 5257, 'preemption_count': 0}), (6306, {'train/accuracy': 0.29228515625, 'train/loss': 3.548459167480469, 'validation/accuracy': 0.26728, 'validation/loss': 3.6847228125, 'validation/num_examples': 50000, 'test/accuracy': 0.2073, 'test/loss': 4.14680859375, 'test/num_examples': 10000, 'score': 2579.431699037552, 'total_duration': 3367.6913437843323, 'accumulated_submission_time': 2579.431699037552, 'accumulated_eval_time': 774.0063557624817, 'accumulated_logging_time': 0.16499733924865723, 'global_step': 6306, 'preemption_count': 0}), (7368, {'train/accuracy': 0.33767578125, 'train/loss': 3.2392898559570313, 'validation/accuracy': 0.31054, 'validation/loss': 3.3931540625, 'validation/num_examples': 50000, 'test/accuracy': 0.2388, 'test/loss': 3.90351640625, 'test/num_examples': 10000, 'score': 2998.300581216812, 'total_duration': 3884.6576652526855, 'accumulated_submission_time': 2998.300581216812, 'accumulated_eval_time': 869.7952306270599, 'accumulated_logging_time': 0.1945481300354004, 'global_step': 7368, 'preemption_count': 0}), (8429, {'train/accuracy': 0.3815625, 'train/loss': 2.94593505859375, 'validation/accuracy': 0.34916, 'validation/loss': 3.114986875, 'validation/num_examples': 50000, 'test/accuracy': 0.2656, 'test/loss': 3.669510546875, 'test/num_examples': 10000, 'score': 3417.3488733768463, 'total_duration': 4396.188070058823, 'accumulated_submission_time': 3417.3488733768463, 'accumulated_eval_time': 959.9135596752167, 'accumulated_logging_time': 0.2210242748260498, 'global_step': 8429, 'preemption_count': 0}), (9487, {'train/accuracy': 0.41791015625, 'train/loss': 2.7536737060546876, 'validation/accuracy': 0.3832, 'validation/loss': 2.9346303125, 'validation/num_examples': 50000, 'test/accuracy': 0.2941, 'test/loss': 3.509633984375, 'test/num_examples': 10000, 'score': 3836.3886811733246, 'total_duration': 4916.265642166138, 'accumulated_submission_time': 3836.3886811733246, 'accumulated_eval_time': 1058.6830055713654, 'accumulated_logging_time': 0.24958181381225586, 'global_step': 9487, 'preemption_count': 0}), (10540, {'train/accuracy': 0.4471875, 'train/loss': 2.656771545410156, 'validation/accuracy': 0.40756, 'validation/loss': 2.84613625, 'validation/num_examples': 50000, 'test/accuracy': 0.3189, 'test/loss': 3.37608515625, 'test/num_examples': 10000, 'score': 4255.131338834763, 'total_duration': 5429.279645681381, 'accumulated_submission_time': 4255.131338834763, 'accumulated_eval_time': 1150.6619889736176, 'accumulated_logging_time': 0.27755308151245117, 'global_step': 10540, 'preemption_count': 0}), (11590, {'train/accuracy': 0.48716796875, 'train/loss': 2.4142074584960938, 'validation/accuracy': 0.44586, 'validation/loss': 2.615408125, 'validation/num_examples': 50000, 'test/accuracy': 0.349, 'test/loss': 3.1775396484375, 'test/num_examples': 10000, 'score': 4673.912573814392, 'total_duration': 5945.633569955826, 'accumulated_submission_time': 4673.912573814392, 'accumulated_eval_time': 1246.0005843639374, 'accumulated_logging_time': 0.3014237880706787, 'global_step': 11590, 'preemption_count': 0}), (12639, {'train/accuracy': 0.52642578125, 'train/loss': 2.1602520751953125, 'validation/accuracy': 0.47882, 'validation/loss': 2.38573515625, 'validation/num_examples': 50000, 'test/accuracy': 0.3789, 'test/loss': 2.99403359375, 'test/num_examples': 10000, 'score': 5092.856876373291, 'total_duration': 6461.322880029678, 'accumulated_submission_time': 5092.856876373291, 'accumulated_eval_time': 1340.4762287139893, 'accumulated_logging_time': 0.3295118808746338, 'global_step': 12639, 'preemption_count': 0}), (13696, {'train/accuracy': 0.53833984375, 'train/loss': 2.090040588378906, 'validation/accuracy': 0.49022, 'validation/loss': 2.3185853125, 'validation/num_examples': 50000, 'test/accuracy': 0.39, 'test/loss': 2.913304296875, 'test/num_examples': 10000, 'score': 5511.724960327148, 'total_duration': 6985.685417890549, 'accumulated_submission_time': 5511.724960327148, 'accumulated_eval_time': 1443.7075390815735, 'accumulated_logging_time': 0.35614919662475586, 'global_step': 13696, 'preemption_count': 0}), (14000, {'train/accuracy': 0.53525390625, 'train/loss': 2.149097442626953, 'validation/accuracy': 0.49306, 'validation/loss': 2.37105328125, 'validation/num_examples': 50000, 'test/accuracy': 0.3779, 'test/loss': 2.9879953125, 'test/num_examples': 10000, 'score': 5632.833034276962, 'total_duration': 7200.313250541687, 'accumulated_submission_time': 5632.833034276962, 'accumulated_eval_time': 1535.4814357757568, 'accumulated_logging_time': 0.39162588119506836, 'global_step': 14000, 'preemption_count': 0})], 'global_step': 14000}
I0926 05:10:59.363439 139722949982016 submission_runner.py:552] Timing: 5632.833034276962
I0926 05:10:59.363497 139722949982016 submission_runner.py:554] Total number of evals: 15
I0926 05:10:59.363547 139722949982016 submission_runner.py:555] ====================
I0926 05:10:59.363690 139722949982016 submission_runner.py:625] Final imagenet_vit score: 5632.833034276962
