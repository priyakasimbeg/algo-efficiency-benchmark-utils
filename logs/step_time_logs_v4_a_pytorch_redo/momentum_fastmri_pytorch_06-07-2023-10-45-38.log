torchrun --redirects 1:0,2:0,3:0,4:0,5:0,6:0,7:0 --standalone --nnodes=1 --nproc_per_node=8 submission_runner.py --framework=pytorch --workload=fastmri --submission_path=baselines/momentum/pytorch/submission.py --tuning_search_space=baselines/momentum/tuning_search_space.json --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_v4_a_pytorch/momentum --overwrite=True --save_checkpoints=False --max_global_steps=5428 2>&1 | tee -a /logs/fastmri_pytorch_06-07-2023-10-45-38.log
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
I0607 10:46:01.756581 139696441513792 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 6
I0607 10:46:01.756616 139730973275968 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 5
I0607 10:46:01.756635 140300143785792 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 2
I0607 10:46:01.757343 139793526458176 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 1
I0607 10:46:01.757479 140458885068608 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 3
I0607 10:46:01.757704 140082802067264 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 0
I0607 10:46:01.758099 139706857162560 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 4
I0607 10:46:01.758486 139706857162560 distributed_c10d.py:353] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0607 10:46:01.758439 140224727881536 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 7
I0607 10:46:01.758921 140224727881536 distributed_c10d.py:353] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0607 10:46:01.767438 139730973275968 distributed_c10d.py:353] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0607 10:46:01.767426 139696441513792 distributed_c10d.py:353] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0607 10:46:01.767466 140300143785792 distributed_c10d.py:353] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0607 10:46:01.768004 139793526458176 distributed_c10d.py:353] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0607 10:46:01.768214 140458885068608 distributed_c10d.py:353] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0607 10:46:01.768465 140082802067264 distributed_c10d.py:353] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0607 10:46:02.393566 140082802067264 logger_utils.py:61] Removing existing experiment directory /experiment_runs/timing_v4_a_pytorch/momentum/fastmri_pytorch because --overwrite was set.
I0607 10:46:02.399160 140082802067264 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_v4_a_pytorch/momentum/fastmri_pytorch.
W0607 10:46:02.510561 140458885068608 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0607 10:46:02.510554 140082802067264 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0607 10:46:02.510862 139696441513792 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0607 10:46:02.511049 139730973275968 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0607 10:46:02.511945 140224727881536 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0607 10:46:02.512356 139706857162560 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0607 10:46:02.513385 139793526458176 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0607 10:46:02.513910 140300143785792 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0607 10:46:02.516963 140082802067264 submission_runner.py:541] Using RNG seed 2812246295
I0607 10:46:02.518356 140082802067264 submission_runner.py:550] --- Tuning run 1/1 ---
I0607 10:46:02.518474 140082802067264 submission_runner.py:555] Creating tuning directory at /experiment_runs/timing_v4_a_pytorch/momentum/fastmri_pytorch/trial_1.
I0607 10:46:02.518821 140082802067264 logger_utils.py:92] Saving hparams to /experiment_runs/timing_v4_a_pytorch/momentum/fastmri_pytorch/trial_1/hparams.json.
I0607 10:46:02.519758 140082802067264 submission_runner.py:255] Initializing dataset.
I0607 10:46:02.519875 140082802067264 submission_runner.py:262] Initializing model.
I0607 10:46:06.667241 140082802067264 submission_runner.py:272] Initializing optimizer.
I0607 10:46:07.138883 140082802067264 submission_runner.py:279] Initializing metrics bundle.
I0607 10:46:07.139082 140082802067264 submission_runner.py:297] Initializing checkpoint and logger.
I0607 10:46:07.142042 140082802067264 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0607 10:46:07.142191 140082802067264 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0607 10:46:07.613142 140082802067264 submission_runner.py:318] Saving meta data to /experiment_runs/timing_v4_a_pytorch/momentum/fastmri_pytorch/trial_1/meta_data_0.json.
I0607 10:46:07.614113 140082802067264 submission_runner.py:321] Saving flags to /experiment_runs/timing_v4_a_pytorch/momentum/fastmri_pytorch/trial_1/flags_0.json.
I0607 10:46:07.664775 140082802067264 submission_runner.py:332] Starting training loop.
I0607 10:46:54.412110 140040378242816 logging_writer.py:48] [0] global_step=0, grad_norm=4.146657, loss=0.978613
I0607 10:46:54.422405 140082802067264 spec.py:298] Evaluating on the training split.
I0607 10:48:29.134860 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 10:49:32.095352 140082802067264 spec.py:326] Evaluating on the test split.
I0607 10:50:33.886682 140082802067264 submission_runner.py:419] Time since start: 266.22s, 	Step: 1, 	{'train/ssim': 0.18740405355181014, 'train/loss': 0.9259589740208217, 'validation/ssim': 0.187300304784222, 'validation/loss': 0.936197069433209, 'validation/num_examples': 3554, 'test/ssim': 0.20830935787402263, 'test/loss': 0.9347450492835451, 'test/num_examples': 3581, 'score': 46.757859230041504, 'total_duration': 266.2225139141083, 'accumulated_submission_time': 46.757859230041504, 'accumulated_eval_time': 219.46425366401672, 'accumulated_logging_time': 0}
I0607 10:50:33.904573 140015665411840 logging_writer.py:48] [1] accumulated_eval_time=219.464254, accumulated_logging_time=0, accumulated_submission_time=46.757859, global_step=1, preemption_count=0, score=46.757859, test/loss=0.934745, test/num_examples=3581, test/ssim=0.208309, total_duration=266.222514, train/loss=0.925959, train/ssim=0.187404, validation/loss=0.936197, validation/num_examples=3554, validation/ssim=0.187300
I0607 10:50:33.929259 140082802067264 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0607 10:50:33.929305 140458885068608 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0607 10:50:33.929326 139793526458176 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0607 10:50:33.929419 140224727881536 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0607 10:50:33.929415 139706857162560 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0607 10:50:33.929473 139730973275968 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0607 10:50:33.929518 139696441513792 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0607 10:50:33.929562 140300143785792 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0607 10:50:33.990362 140015657019136 logging_writer.py:48] [1] global_step=1, grad_norm=3.859480, loss=0.900029
I0607 10:50:34.072195 140015665411840 logging_writer.py:48] [2] global_step=2, grad_norm=3.819849, loss=0.920588
I0607 10:50:34.148414 140015657019136 logging_writer.py:48] [3] global_step=3, grad_norm=4.120036, loss=0.900628
I0607 10:50:34.218357 140015665411840 logging_writer.py:48] [4] global_step=4, grad_norm=3.587253, loss=0.840168
I0607 10:50:34.309670 140015657019136 logging_writer.py:48] [5] global_step=5, grad_norm=3.072449, loss=0.808711
I0607 10:50:34.392688 140015665411840 logging_writer.py:48] [6] global_step=6, grad_norm=2.559246, loss=0.763195
I0607 10:50:34.480606 140015657019136 logging_writer.py:48] [7] global_step=7, grad_norm=1.937288, loss=0.680419
I0607 10:50:34.553836 140015665411840 logging_writer.py:48] [8] global_step=8, grad_norm=1.633303, loss=0.639148
I0607 10:50:34.633364 140015657019136 logging_writer.py:48] [9] global_step=9, grad_norm=1.478783, loss=0.569216
I0607 10:50:34.726747 140015665411840 logging_writer.py:48] [10] global_step=10, grad_norm=1.317272, loss=0.572418
I0607 10:50:34.800866 140015657019136 logging_writer.py:48] [11] global_step=11, grad_norm=1.268228, loss=0.561037
I0607 10:50:34.878418 140015665411840 logging_writer.py:48] [12] global_step=12, grad_norm=1.209565, loss=0.518687
I0607 10:50:34.962868 140015657019136 logging_writer.py:48] [13] global_step=13, grad_norm=1.182724, loss=0.577432
I0607 10:50:35.040478 140015665411840 logging_writer.py:48] [14] global_step=14, grad_norm=1.190861, loss=0.502563
I0607 10:50:35.254783 140015657019136 logging_writer.py:48] [15] global_step=15, grad_norm=1.442616, loss=0.436703
I0607 10:50:35.550305 140015665411840 logging_writer.py:48] [16] global_step=16, grad_norm=1.302006, loss=0.414874
I0607 10:50:35.832378 140015657019136 logging_writer.py:48] [17] global_step=17, grad_norm=1.186984, loss=0.437790
I0607 10:50:35.995657 140015665411840 logging_writer.py:48] [18] global_step=18, grad_norm=1.137027, loss=0.402293
I0607 10:50:36.318202 140015657019136 logging_writer.py:48] [19] global_step=19, grad_norm=0.690470, loss=0.485343
I0607 10:50:36.614363 140015665411840 logging_writer.py:48] [20] global_step=20, grad_norm=0.817001, loss=0.402993
I0607 10:50:36.843875 140015657019136 logging_writer.py:48] [21] global_step=21, grad_norm=0.635612, loss=0.396035
I0607 10:50:37.145254 140015665411840 logging_writer.py:48] [22] global_step=22, grad_norm=0.719767, loss=0.349307
I0607 10:50:37.348197 140015657019136 logging_writer.py:48] [23] global_step=23, grad_norm=0.786705, loss=0.338929
I0607 10:50:37.618676 140015665411840 logging_writer.py:48] [24] global_step=24, grad_norm=0.593601, loss=0.385173
I0607 10:50:37.900102 140015657019136 logging_writer.py:48] [25] global_step=25, grad_norm=0.566069, loss=0.413604
I0607 10:50:38.202643 140015665411840 logging_writer.py:48] [26] global_step=26, grad_norm=0.501753, loss=0.370612
I0607 10:50:38.472752 140015657019136 logging_writer.py:48] [27] global_step=27, grad_norm=0.536136, loss=0.332486
I0607 10:50:38.721738 140015665411840 logging_writer.py:48] [28] global_step=28, grad_norm=0.514671, loss=0.343300
I0607 10:50:38.952405 140015657019136 logging_writer.py:48] [29] global_step=29, grad_norm=0.479206, loss=0.329208
I0607 10:50:39.211500 140015665411840 logging_writer.py:48] [30] global_step=30, grad_norm=0.375983, loss=0.393125
I0607 10:50:39.515850 140015657019136 logging_writer.py:48] [31] global_step=31, grad_norm=0.283375, loss=0.431661
I0607 10:50:39.799919 140015665411840 logging_writer.py:48] [32] global_step=32, grad_norm=0.244687, loss=0.459319
I0607 10:50:40.034696 140015657019136 logging_writer.py:48] [33] global_step=33, grad_norm=0.249420, loss=0.377944
I0607 10:50:40.281077 140015665411840 logging_writer.py:48] [34] global_step=34, grad_norm=0.319554, loss=0.420236
I0607 10:50:40.572568 140015657019136 logging_writer.py:48] [35] global_step=35, grad_norm=0.469237, loss=0.451529
I0607 10:50:40.788603 140015665411840 logging_writer.py:48] [36] global_step=36, grad_norm=0.435047, loss=0.315312
I0607 10:50:41.042791 140015657019136 logging_writer.py:48] [37] global_step=37, grad_norm=0.468351, loss=0.356705
I0607 10:50:41.300867 140015665411840 logging_writer.py:48] [38] global_step=38, grad_norm=0.481404, loss=0.344884
I0607 10:50:41.552958 140015657019136 logging_writer.py:48] [39] global_step=39, grad_norm=0.291554, loss=0.341613
I0607 10:50:41.853448 140015665411840 logging_writer.py:48] [40] global_step=40, grad_norm=0.218155, loss=0.387952
I0607 10:50:42.152302 140015657019136 logging_writer.py:48] [41] global_step=41, grad_norm=0.222978, loss=0.390332
I0607 10:50:42.438882 140015665411840 logging_writer.py:48] [42] global_step=42, grad_norm=0.208304, loss=0.291232
I0607 10:50:42.648877 140015657019136 logging_writer.py:48] [43] global_step=43, grad_norm=0.441778, loss=0.351678
I0607 10:50:42.934219 140015665411840 logging_writer.py:48] [44] global_step=44, grad_norm=0.448759, loss=0.355872
I0607 10:50:43.227459 140015657019136 logging_writer.py:48] [45] global_step=45, grad_norm=0.268706, loss=0.397643
I0607 10:50:43.464915 140015665411840 logging_writer.py:48] [46] global_step=46, grad_norm=0.187782, loss=0.348490
I0607 10:50:43.710067 140015657019136 logging_writer.py:48] [47] global_step=47, grad_norm=0.225883, loss=0.347570
I0607 10:50:44.002050 140015665411840 logging_writer.py:48] [48] global_step=48, grad_norm=0.099301, loss=0.426551
I0607 10:50:44.242330 140015657019136 logging_writer.py:48] [49] global_step=49, grad_norm=0.145383, loss=0.370736
I0607 10:50:44.521167 140015665411840 logging_writer.py:48] [50] global_step=50, grad_norm=0.108521, loss=0.415921
I0607 10:50:44.813020 140015657019136 logging_writer.py:48] [51] global_step=51, grad_norm=0.394027, loss=0.337584
I0607 10:50:45.091083 140015665411840 logging_writer.py:48] [52] global_step=52, grad_norm=0.397365, loss=0.366283
I0607 10:50:45.291368 140015657019136 logging_writer.py:48] [53] global_step=53, grad_norm=0.387428, loss=0.359012
I0607 10:50:45.610759 140015665411840 logging_writer.py:48] [54] global_step=54, grad_norm=0.221618, loss=0.347608
I0607 10:50:45.858805 140015657019136 logging_writer.py:48] [55] global_step=55, grad_norm=0.131507, loss=0.412062
I0607 10:50:46.157060 140015665411840 logging_writer.py:48] [56] global_step=56, grad_norm=0.317948, loss=0.355130
I0607 10:50:46.389169 140015657019136 logging_writer.py:48] [57] global_step=57, grad_norm=0.381125, loss=0.472790
I0607 10:50:46.647926 140015665411840 logging_writer.py:48] [58] global_step=58, grad_norm=0.285601, loss=0.453650
I0607 10:50:46.914003 140015657019136 logging_writer.py:48] [59] global_step=59, grad_norm=0.273922, loss=0.368658
I0607 10:50:47.182573 140015665411840 logging_writer.py:48] [60] global_step=60, grad_norm=0.154918, loss=0.407085
I0607 10:50:47.416112 140015657019136 logging_writer.py:48] [61] global_step=61, grad_norm=0.135078, loss=0.363163
I0607 10:50:47.701138 140015665411840 logging_writer.py:48] [62] global_step=62, grad_norm=0.259586, loss=0.428946
I0607 10:50:47.958341 140015657019136 logging_writer.py:48] [63] global_step=63, grad_norm=0.292427, loss=0.381457
I0607 10:50:48.226721 140015665411840 logging_writer.py:48] [64] global_step=64, grad_norm=0.489581, loss=0.336484
I0607 10:50:48.503682 140015657019136 logging_writer.py:48] [65] global_step=65, grad_norm=0.279900, loss=0.370886
I0607 10:50:48.810219 140015665411840 logging_writer.py:48] [66] global_step=66, grad_norm=0.081975, loss=0.347815
I0607 10:50:49.082178 140015657019136 logging_writer.py:48] [67] global_step=67, grad_norm=0.293396, loss=0.334720
I0607 10:50:49.353448 140015665411840 logging_writer.py:48] [68] global_step=68, grad_norm=0.376502, loss=0.340566
I0607 10:50:49.617185 140015657019136 logging_writer.py:48] [69] global_step=69, grad_norm=0.442378, loss=0.287051
I0607 10:50:49.904388 140015665411840 logging_writer.py:48] [70] global_step=70, grad_norm=0.422077, loss=0.404821
I0607 10:50:50.145385 140015657019136 logging_writer.py:48] [71] global_step=71, grad_norm=0.054856, loss=0.357228
I0607 10:50:50.422867 140015665411840 logging_writer.py:48] [72] global_step=72, grad_norm=0.343207, loss=0.346139
I0607 10:50:50.690758 140015657019136 logging_writer.py:48] [73] global_step=73, grad_norm=0.557270, loss=0.299771
I0607 10:50:51.014279 140015665411840 logging_writer.py:48] [74] global_step=74, grad_norm=0.439496, loss=0.301595
I0607 10:50:51.220491 140015657019136 logging_writer.py:48] [75] global_step=75, grad_norm=0.512290, loss=0.274891
I0607 10:50:51.493367 140015665411840 logging_writer.py:48] [76] global_step=76, grad_norm=0.165447, loss=0.296055
I0607 10:50:51.810623 140015657019136 logging_writer.py:48] [77] global_step=77, grad_norm=0.526782, loss=0.280302
I0607 10:50:52.028673 140015665411840 logging_writer.py:48] [78] global_step=78, grad_norm=0.755936, loss=0.381147
I0607 10:50:52.301504 140015657019136 logging_writer.py:48] [79] global_step=79, grad_norm=0.572448, loss=0.317100
I0607 10:50:52.625873 140015665411840 logging_writer.py:48] [80] global_step=80, grad_norm=0.174324, loss=0.252434
I0607 10:50:52.906516 140015657019136 logging_writer.py:48] [81] global_step=81, grad_norm=0.391950, loss=0.307193
I0607 10:50:53.155022 140015665411840 logging_writer.py:48] [82] global_step=82, grad_norm=0.434779, loss=0.310220
I0607 10:50:53.401208 140015657019136 logging_writer.py:48] [83] global_step=83, grad_norm=0.493681, loss=0.266181
I0607 10:50:53.638256 140015665411840 logging_writer.py:48] [84] global_step=84, grad_norm=0.326424, loss=0.254550
I0607 10:50:53.906987 140015657019136 logging_writer.py:48] [85] global_step=85, grad_norm=0.347232, loss=0.341170
I0607 10:50:54.221018 140015665411840 logging_writer.py:48] [86] global_step=86, grad_norm=0.553780, loss=0.380622
I0607 10:50:54.441275 140015657019136 logging_writer.py:48] [87] global_step=87, grad_norm=0.392581, loss=0.277805
I0607 10:50:54.723964 140015665411840 logging_writer.py:48] [88] global_step=88, grad_norm=0.157016, loss=0.371018
I0607 10:50:55.007787 140015657019136 logging_writer.py:48] [89] global_step=89, grad_norm=0.199721, loss=0.338644
I0607 10:50:55.313438 140015665411840 logging_writer.py:48] [90] global_step=90, grad_norm=0.357636, loss=0.260607
I0607 10:50:55.591100 140015657019136 logging_writer.py:48] [91] global_step=91, grad_norm=0.262945, loss=0.479643
I0607 10:50:55.863930 140015665411840 logging_writer.py:48] [92] global_step=92, grad_norm=0.241846, loss=0.284933
I0607 10:50:56.133167 140015657019136 logging_writer.py:48] [93] global_step=93, grad_norm=0.312740, loss=0.243092
I0607 10:50:56.367683 140015665411840 logging_writer.py:48] [94] global_step=94, grad_norm=0.257824, loss=0.299178
I0607 10:50:56.648828 140015657019136 logging_writer.py:48] [95] global_step=95, grad_norm=0.377877, loss=0.273449
I0607 10:50:56.881213 140015665411840 logging_writer.py:48] [96] global_step=96, grad_norm=0.495338, loss=0.274393
I0607 10:50:57.156305 140015657019136 logging_writer.py:48] [97] global_step=97, grad_norm=0.228650, loss=0.250073
I0607 10:50:57.406268 140015665411840 logging_writer.py:48] [98] global_step=98, grad_norm=0.166887, loss=0.340380
I0607 10:50:57.703212 140015657019136 logging_writer.py:48] [99] global_step=99, grad_norm=0.430100, loss=0.310358
I0607 10:50:57.984081 140015665411840 logging_writer.py:48] [100] global_step=100, grad_norm=0.440355, loss=0.338521
I0607 10:51:54.143464 140082802067264 spec.py:298] Evaluating on the training split.
I0607 10:51:56.378819 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 10:51:58.711145 140082802067264 spec.py:326] Evaluating on the test split.
I0607 10:52:00.980641 140082802067264 submission_runner.py:419] Time since start: 353.32s, 	Step: 310, 	{'train/ssim': 0.7052318709237235, 'train/loss': 0.3042196886880057, 'validation/ssim': 0.6854312619803391, 'validation/loss': 0.32450359217826746, 'validation/num_examples': 3554, 'test/ssim': 0.7040351584316532, 'test/loss': 0.3259420173855941, 'test/num_examples': 3581, 'score': 126.75010347366333, 'total_duration': 353.3164782524109, 'accumulated_submission_time': 126.75010347366333, 'accumulated_eval_time': 226.30137133598328, 'accumulated_logging_time': 0.025960445404052734}
I0607 10:52:00.991795 140015657019136 logging_writer.py:48] [310] accumulated_eval_time=226.301371, accumulated_logging_time=0.025960, accumulated_submission_time=126.750103, global_step=310, preemption_count=0, score=126.750103, test/loss=0.325942, test/num_examples=3581, test/ssim=0.704035, total_duration=353.316478, train/loss=0.304220, train/ssim=0.705232, validation/loss=0.324504, validation/num_examples=3554, validation/ssim=0.685431
I0607 10:53:07.350644 140015665411840 logging_writer.py:48] [500] global_step=500, grad_norm=0.276382, loss=0.373008
I0607 10:53:21.212941 140082802067264 spec.py:298] Evaluating on the training split.
I0607 10:53:23.409819 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 10:53:25.674036 140082802067264 spec.py:326] Evaluating on the test split.
I0607 10:53:27.930028 140082802067264 submission_runner.py:419] Time since start: 440.27s, 	Step: 537, 	{'train/ssim': 0.7092791284833636, 'train/loss': 0.29530474117824007, 'validation/ssim': 0.6896956856490926, 'validation/loss': 0.3147843016891179, 'validation/num_examples': 3554, 'test/ssim': 0.7080172208792935, 'test/loss': 0.3161736653191322, 'test/num_examples': 3581, 'score': 206.75187611579895, 'total_duration': 440.2658920288086, 'accumulated_submission_time': 206.75187611579895, 'accumulated_eval_time': 233.01930713653564, 'accumulated_logging_time': 0.04703927040100098}
I0607 10:53:27.942568 140015657019136 logging_writer.py:48] [537] accumulated_eval_time=233.019307, accumulated_logging_time=0.047039, accumulated_submission_time=206.751876, global_step=537, preemption_count=0, score=206.751876, test/loss=0.316174, test/num_examples=3581, test/ssim=0.708017, total_duration=440.265892, train/loss=0.295305, train/ssim=0.709279, validation/loss=0.314784, validation/num_examples=3554, validation/ssim=0.689696
I0607 10:54:47.964851 140082802067264 spec.py:298] Evaluating on the training split.
I0607 10:54:50.090157 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 10:54:52.302779 140082802067264 spec.py:326] Evaluating on the test split.
I0607 10:54:54.503954 140082802067264 submission_runner.py:419] Time since start: 526.84s, 	Step: 769, 	{'train/ssim': 0.6961404255458287, 'train/loss': 0.30774995258876253, 'validation/ssim': 0.6794952238015265, 'validation/loss': 0.3259564487197524, 'validation/num_examples': 3554, 'test/ssim': 0.6961414600277507, 'test/loss': 0.32830907698617706, 'test/num_examples': 3581, 'score': 286.55228781700134, 'total_duration': 526.8397493362427, 'accumulated_submission_time': 286.55228781700134, 'accumulated_eval_time': 239.55834460258484, 'accumulated_logging_time': 0.07612371444702148}
I0607 10:54:54.517233 140015665411840 logging_writer.py:48] [769] accumulated_eval_time=239.558345, accumulated_logging_time=0.076124, accumulated_submission_time=286.552288, global_step=769, preemption_count=0, score=286.552288, test/loss=0.328309, test/num_examples=3581, test/ssim=0.696141, total_duration=526.839749, train/loss=0.307750, train/ssim=0.696140, validation/loss=0.325956, validation/num_examples=3554, validation/ssim=0.679495
I0607 10:56:13.064463 140015657019136 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.331824, loss=0.257900
I0607 10:56:14.747630 140082802067264 spec.py:298] Evaluating on the training split.
I0607 10:56:16.930427 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 10:56:19.187274 140082802067264 spec.py:326] Evaluating on the test split.
I0607 10:56:21.398072 140082802067264 submission_runner.py:419] Time since start: 613.73s, 	Step: 1007, 	{'train/ssim': 0.7208937236240932, 'train/loss': 0.2899871894291469, 'validation/ssim': 0.7009236126987197, 'validation/loss': 0.3092052693707794, 'validation/num_examples': 3554, 'test/ssim': 0.7183062381099903, 'test/loss': 0.3112786151083845, 'test/num_examples': 3581, 'score': 366.55245900154114, 'total_duration': 613.7339458465576, 'accumulated_submission_time': 366.55245900154114, 'accumulated_eval_time': 246.20979070663452, 'accumulated_logging_time': 0.10266256332397461}
I0607 10:56:21.408069 140015665411840 logging_writer.py:48] [1007] accumulated_eval_time=246.209791, accumulated_logging_time=0.102663, accumulated_submission_time=366.552459, global_step=1007, preemption_count=0, score=366.552459, test/loss=0.311279, test/num_examples=3581, test/ssim=0.718306, total_duration=613.733946, train/loss=0.289987, train/ssim=0.720894, validation/loss=0.309205, validation/num_examples=3554, validation/ssim=0.700924
I0607 10:57:41.422957 140082802067264 spec.py:298] Evaluating on the training split.
I0607 10:57:43.564996 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 10:57:45.747387 140082802067264 spec.py:326] Evaluating on the test split.
I0607 10:57:47.897697 140082802067264 submission_runner.py:419] Time since start: 700.23s, 	Step: 1316, 	{'train/ssim': 0.7167935371398926, 'train/loss': 0.293940612248012, 'validation/ssim': 0.6976009920600028, 'validation/loss': 0.31298113701111424, 'validation/num_examples': 3554, 'test/ssim': 0.7148938598462371, 'test/loss': 0.31433160010079236, 'test/num_examples': 3581, 'score': 446.4350805282593, 'total_duration': 700.2335622310638, 'accumulated_submission_time': 446.4350805282593, 'accumulated_eval_time': 252.68460702896118, 'accumulated_logging_time': 0.12057304382324219}
I0607 10:57:47.908383 140015657019136 logging_writer.py:48] [1316] accumulated_eval_time=252.684607, accumulated_logging_time=0.120573, accumulated_submission_time=446.435081, global_step=1316, preemption_count=0, score=446.435081, test/loss=0.314332, test/num_examples=3581, test/ssim=0.714894, total_duration=700.233562, train/loss=0.293941, train/ssim=0.716794, validation/loss=0.312981, validation/num_examples=3554, validation/ssim=0.697601
I0607 10:58:33.744863 140015665411840 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.123531, loss=0.310336
I0607 10:59:07.948694 140082802067264 spec.py:298] Evaluating on the training split.
I0607 10:59:10.090905 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 10:59:12.284310 140082802067264 spec.py:326] Evaluating on the test split.
I0607 10:59:14.442826 140082802067264 submission_runner.py:419] Time since start: 786.78s, 	Step: 1630, 	{'train/ssim': 0.7193865094866071, 'train/loss': 0.29278394154139925, 'validation/ssim': 0.7033100632649831, 'validation/loss': 0.3105668994772615, 'validation/num_examples': 3554, 'test/ssim': 0.7202114349169226, 'test/loss': 0.31234861372303474, 'test/num_examples': 3581, 'score': 526.3412532806396, 'total_duration': 786.7786755561829, 'accumulated_submission_time': 526.3412532806396, 'accumulated_eval_time': 259.178781747818, 'accumulated_logging_time': 0.13937163352966309}
I0607 10:59:14.452681 140015657019136 logging_writer.py:48] [1630] accumulated_eval_time=259.178782, accumulated_logging_time=0.139372, accumulated_submission_time=526.341253, global_step=1630, preemption_count=0, score=526.341253, test/loss=0.312349, test/num_examples=3581, test/ssim=0.720211, total_duration=786.778676, train/loss=0.292784, train/ssim=0.719387, validation/loss=0.310567, validation/num_examples=3554, validation/ssim=0.703310
I0607 11:00:34.628548 140082802067264 spec.py:298] Evaluating on the training split.
I0607 11:00:36.713843 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 11:00:38.907077 140082802067264 spec.py:326] Evaluating on the test split.
I0607 11:00:41.031919 140082802067264 submission_runner.py:419] Time since start: 873.37s, 	Step: 1945, 	{'train/ssim': 0.7324652671813965, 'train/loss': 0.2819375821522304, 'validation/ssim': 0.7137198375729812, 'validation/loss': 0.30075054351171215, 'validation/num_examples': 3554, 'test/ssim': 0.7306740299279182, 'test/loss': 0.30282109571348786, 'test/num_examples': 3581, 'score': 606.381742477417, 'total_duration': 873.3677892684937, 'accumulated_submission_time': 606.381742477417, 'accumulated_eval_time': 265.5822319984436, 'accumulated_logging_time': 0.1570894718170166}
I0607 11:00:41.042948 140015665411840 logging_writer.py:48] [1945] accumulated_eval_time=265.582232, accumulated_logging_time=0.157089, accumulated_submission_time=606.381742, global_step=1945, preemption_count=0, score=606.381742, test/loss=0.302821, test/num_examples=3581, test/ssim=0.730674, total_duration=873.367789, train/loss=0.281938, train/ssim=0.732465, validation/loss=0.300751, validation/num_examples=3554, validation/ssim=0.713720
I0607 11:00:53.141399 140015657019136 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.333666, loss=0.271308
I0607 11:02:01.131347 140082802067264 spec.py:298] Evaluating on the training split.
I0607 11:02:03.198909 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 11:02:05.343669 140082802067264 spec.py:326] Evaluating on the test split.
I0607 11:02:07.450676 140082802067264 submission_runner.py:419] Time since start: 959.79s, 	Step: 2256, 	{'train/ssim': 0.7256829398018974, 'train/loss': 0.2821119853428432, 'validation/ssim': 0.7058533436137099, 'validation/loss': 0.30228717312359316, 'validation/num_examples': 3554, 'test/ssim': 0.7221666733934307, 'test/loss': 0.3045134108947396, 'test/num_examples': 3581, 'score': 686.3382005691528, 'total_duration': 959.7865138053894, 'accumulated_submission_time': 686.3382005691528, 'accumulated_eval_time': 271.9015235900879, 'accumulated_logging_time': 0.17635512351989746}
I0607 11:02:07.462294 140015665411840 logging_writer.py:48] [2256] accumulated_eval_time=271.901524, accumulated_logging_time=0.176355, accumulated_submission_time=686.338201, global_step=2256, preemption_count=0, score=686.338201, test/loss=0.304513, test/num_examples=3581, test/ssim=0.722167, total_duration=959.786514, train/loss=0.282112, train/ssim=0.725683, validation/loss=0.302287, validation/num_examples=3554, validation/ssim=0.705853
I0607 11:03:09.179522 140015657019136 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.301895, loss=0.222195
I0607 11:03:27.609451 140082802067264 spec.py:298] Evaluating on the training split.
I0607 11:03:29.813781 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 11:03:32.072241 140082802067264 spec.py:326] Evaluating on the test split.
I0607 11:03:34.305420 140082802067264 submission_runner.py:419] Time since start: 1046.64s, 	Step: 2570, 	{'train/ssim': 0.7351382119315011, 'train/loss': 0.27504355566842215, 'validation/ssim': 0.7154837776317178, 'validation/loss': 0.2948514630302124, 'validation/num_examples': 3554, 'test/ssim': 0.732560205446279, 'test/loss': 0.2965001988031451, 'test/num_examples': 3581, 'score': 766.3500363826752, 'total_duration': 1046.6412916183472, 'accumulated_submission_time': 766.3500363826752, 'accumulated_eval_time': 278.59747791290283, 'accumulated_logging_time': 0.19678068161010742}
I0607 11:03:34.315966 140015665411840 logging_writer.py:48] [2570] accumulated_eval_time=278.597478, accumulated_logging_time=0.196781, accumulated_submission_time=766.350036, global_step=2570, preemption_count=0, score=766.350036, test/loss=0.296500, test/num_examples=3581, test/ssim=0.732560, total_duration=1046.641292, train/loss=0.275044, train/ssim=0.735138, validation/loss=0.294851, validation/num_examples=3554, validation/ssim=0.715484
I0607 11:04:54.407632 140082802067264 spec.py:298] Evaluating on the training split.
I0607 11:04:56.535754 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 11:04:58.706361 140082802067264 spec.py:326] Evaluating on the test split.
I0607 11:05:00.844541 140082802067264 submission_runner.py:419] Time since start: 1133.18s, 	Step: 2882, 	{'train/ssim': 0.7312564849853516, 'train/loss': 0.2758436032703945, 'validation/ssim': 0.7110913072198579, 'validation/loss': 0.2956197434888506, 'validation/num_examples': 3554, 'test/ssim': 0.7281976490505445, 'test/loss': 0.29729060492879084, 'test/num_examples': 3581, 'score': 846.3069565296173, 'total_duration': 1133.1804027557373, 'accumulated_submission_time': 846.3069565296173, 'accumulated_eval_time': 285.0343647003174, 'accumulated_logging_time': 0.21626663208007812}
I0607 11:05:00.854977 140015657019136 logging_writer.py:48] [2882] accumulated_eval_time=285.034365, accumulated_logging_time=0.216267, accumulated_submission_time=846.306957, global_step=2882, preemption_count=0, score=846.306957, test/loss=0.297291, test/num_examples=3581, test/ssim=0.728198, total_duration=1133.180403, train/loss=0.275844, train/ssim=0.731256, validation/loss=0.295620, validation/num_examples=3554, validation/ssim=0.711091
I0607 11:05:29.542815 140015665411840 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.170413, loss=0.249825
I0607 11:06:20.850760 140082802067264 spec.py:298] Evaluating on the training split.
I0607 11:06:22.981792 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 11:06:25.150096 140082802067264 spec.py:326] Evaluating on the test split.
I0607 11:06:27.285155 140082802067264 submission_runner.py:419] Time since start: 1219.62s, 	Step: 3193, 	{'train/ssim': 0.7296384402683803, 'train/loss': 0.27800657067980084, 'validation/ssim': 0.7097500450636607, 'validation/loss': 0.29757613148257245, 'validation/num_examples': 3554, 'test/ssim': 0.7271236621011938, 'test/loss': 0.2990025209002374, 'test/num_examples': 3581, 'score': 926.1695668697357, 'total_duration': 1219.6210324764252, 'accumulated_submission_time': 926.1695668697357, 'accumulated_eval_time': 291.4687819480896, 'accumulated_logging_time': 0.2351830005645752}
I0607 11:06:27.295288 140015657019136 logging_writer.py:48] [3193] accumulated_eval_time=291.468782, accumulated_logging_time=0.235183, accumulated_submission_time=926.169567, global_step=3193, preemption_count=0, score=926.169567, test/loss=0.299003, test/num_examples=3581, test/ssim=0.727124, total_duration=1219.621032, train/loss=0.278007, train/ssim=0.729638, validation/loss=0.297576, validation/num_examples=3554, validation/ssim=0.709750
I0607 11:07:46.017627 140015665411840 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.160556, loss=0.283544
I0607 11:07:47.512223 140082802067264 spec.py:298] Evaluating on the training split.
I0607 11:07:49.640875 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 11:07:51.836745 140082802067264 spec.py:326] Evaluating on the test split.
I0607 11:07:53.999901 140082802067264 submission_runner.py:419] Time since start: 1306.34s, 	Step: 3507, 	{'train/ssim': 0.7325513022286552, 'train/loss': 0.2741603510720389, 'validation/ssim': 0.7124110679647931, 'validation/loss': 0.2943285940467607, 'validation/num_examples': 3554, 'test/ssim': 0.7291489861857722, 'test/loss': 0.29623737777288117, 'test/num_examples': 3581, 'score': 1006.2509062290192, 'total_duration': 1306.335785627365, 'accumulated_submission_time': 1006.2509062290192, 'accumulated_eval_time': 297.95650720596313, 'accumulated_logging_time': 0.2533903121948242}
I0607 11:07:54.009957 140015657019136 logging_writer.py:48] [3507] accumulated_eval_time=297.956507, accumulated_logging_time=0.253390, accumulated_submission_time=1006.250906, global_step=3507, preemption_count=0, score=1006.250906, test/loss=0.296237, test/num_examples=3581, test/ssim=0.729149, total_duration=1306.335786, train/loss=0.274160, train/ssim=0.732551, validation/loss=0.294329, validation/num_examples=3554, validation/ssim=0.712411
I0607 11:09:14.013523 140082802067264 spec.py:298] Evaluating on the training split.
I0607 11:09:16.159024 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 11:09:18.345653 140082802067264 spec.py:326] Evaluating on the test split.
I0607 11:09:20.497916 140082802067264 submission_runner.py:419] Time since start: 1392.83s, 	Step: 3820, 	{'train/ssim': 0.737180233001709, 'train/loss': 0.27213660308292936, 'validation/ssim': 0.7171377376283765, 'validation/loss': 0.2923888644946715, 'validation/num_examples': 3554, 'test/ssim': 0.734247509642907, 'test/loss': 0.29398349143046637, 'test/num_examples': 3581, 'score': 1086.1205325126648, 'total_duration': 1392.8337845802307, 'accumulated_submission_time': 1086.1205325126648, 'accumulated_eval_time': 304.4408800601959, 'accumulated_logging_time': 0.27137303352355957}
I0607 11:09:20.508265 140015665411840 logging_writer.py:48] [3820] accumulated_eval_time=304.440880, accumulated_logging_time=0.271373, accumulated_submission_time=1086.120533, global_step=3820, preemption_count=0, score=1086.120533, test/loss=0.293983, test/num_examples=3581, test/ssim=0.734248, total_duration=1392.833785, train/loss=0.272137, train/ssim=0.737180, validation/loss=0.292389, validation/num_examples=3554, validation/ssim=0.717138
I0607 11:10:05.740483 140015657019136 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.121150, loss=0.230313
I0607 11:10:40.532225 140082802067264 spec.py:298] Evaluating on the training split.
I0607 11:10:42.667799 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 11:10:44.831431 140082802067264 spec.py:326] Evaluating on the test split.
I0607 11:10:46.971130 140082802067264 submission_runner.py:419] Time since start: 1479.31s, 	Step: 4131, 	{'train/ssim': 0.7374694006783622, 'train/loss': 0.27376212392534527, 'validation/ssim': 0.7172535567318514, 'validation/loss': 0.2935997786385059, 'validation/num_examples': 3554, 'test/ssim': 0.734266190048171, 'test/loss': 0.2953370367804908, 'test/num_examples': 3581, 'score': 1166.0128228664398, 'total_duration': 1479.3070080280304, 'accumulated_submission_time': 1166.0128228664398, 'accumulated_eval_time': 310.87982082366943, 'accumulated_logging_time': 0.2897965908050537}
I0607 11:10:46.982348 140015665411840 logging_writer.py:48] [4131] accumulated_eval_time=310.879821, accumulated_logging_time=0.289797, accumulated_submission_time=1166.012823, global_step=4131, preemption_count=0, score=1166.012823, test/loss=0.295337, test/num_examples=3581, test/ssim=0.734266, total_duration=1479.307008, train/loss=0.273762, train/ssim=0.737469, validation/loss=0.293600, validation/num_examples=3554, validation/ssim=0.717254
I0607 11:12:07.278072 140082802067264 spec.py:298] Evaluating on the training split.
I0607 11:12:09.332118 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 11:12:11.455492 140082802067264 spec.py:326] Evaluating on the test split.
I0607 11:12:13.557800 140082802067264 submission_runner.py:419] Time since start: 1565.89s, 	Step: 4443, 	{'train/ssim': 0.7338150569370815, 'train/loss': 0.2723485231399536, 'validation/ssim': 0.7144687461531022, 'validation/loss': 0.2921742282023776, 'validation/num_examples': 3554, 'test/ssim': 0.7316614325171041, 'test/loss': 0.29372905612957273, 'test/num_examples': 3581, 'score': 1246.1761119365692, 'total_duration': 1565.8936433792114, 'accumulated_submission_time': 1246.1761119365692, 'accumulated_eval_time': 317.1595482826233, 'accumulated_logging_time': 0.30879712104797363}
I0607 11:12:13.569738 140015657019136 logging_writer.py:48] [4443] accumulated_eval_time=317.159548, accumulated_logging_time=0.308797, accumulated_submission_time=1246.176112, global_step=4443, preemption_count=0, score=1246.176112, test/loss=0.293729, test/num_examples=3581, test/ssim=0.731661, total_duration=1565.893643, train/loss=0.272349, train/ssim=0.733815, validation/loss=0.292174, validation/num_examples=3554, validation/ssim=0.714469
I0607 11:12:26.346616 140015665411840 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.104518, loss=0.242707
I0607 11:13:33.599358 140082802067264 spec.py:298] Evaluating on the training split.
I0607 11:13:35.798518 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 11:13:38.049479 140082802067264 spec.py:326] Evaluating on the test split.
I0607 11:13:40.282594 140082802067264 submission_runner.py:419] Time since start: 1652.62s, 	Step: 4756, 	{'train/ssim': 0.737752982548305, 'train/loss': 0.2711171422685896, 'validation/ssim': 0.7178034570422411, 'validation/loss': 0.29126557031909467, 'validation/num_examples': 3554, 'test/ssim': 0.7349390255209788, 'test/loss': 0.29285329282367006, 'test/num_examples': 3581, 'score': 1326.0707702636719, 'total_duration': 1652.618437051773, 'accumulated_submission_time': 1326.0707702636719, 'accumulated_eval_time': 323.8427426815033, 'accumulated_logging_time': 0.32967209815979004}
I0607 11:13:40.293124 140015657019136 logging_writer.py:48] [4756] accumulated_eval_time=323.842743, accumulated_logging_time=0.329672, accumulated_submission_time=1326.070770, global_step=4756, preemption_count=0, score=1326.070770, test/loss=0.292853, test/num_examples=3581, test/ssim=0.734939, total_duration=1652.618437, train/loss=0.271117, train/ssim=0.737753, validation/loss=0.291266, validation/num_examples=3554, validation/ssim=0.717803
I0607 11:14:42.188384 140015665411840 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.117293, loss=0.276329
I0607 11:15:00.366218 140082802067264 spec.py:298] Evaluating on the training split.
I0607 11:15:02.514685 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 11:15:04.709488 140082802067264 spec.py:326] Evaluating on the test split.
I0607 11:15:06.874253 140082802067264 submission_runner.py:419] Time since start: 1739.21s, 	Step: 5070, 	{'train/ssim': 0.7372445378984723, 'train/loss': 0.2714275462286813, 'validation/ssim': 0.7166044614123172, 'validation/loss': 0.29186541160708007, 'validation/num_examples': 3554, 'test/ssim': 0.7337530924933677, 'test/loss': 0.29352196952012355, 'test/num_examples': 3581, 'score': 1406.0088262557983, 'total_duration': 1739.2101290225983, 'accumulated_submission_time': 1406.0088262557983, 'accumulated_eval_time': 330.3507659435272, 'accumulated_logging_time': 0.34786009788513184}
I0607 11:15:06.885815 140015657019136 logging_writer.py:48] [5070] accumulated_eval_time=330.350766, accumulated_logging_time=0.347860, accumulated_submission_time=1406.008826, global_step=5070, preemption_count=0, score=1406.008826, test/loss=0.293522, test/num_examples=3581, test/ssim=0.733753, total_duration=1739.210129, train/loss=0.271428, train/ssim=0.737245, validation/loss=0.291865, validation/num_examples=3554, validation/ssim=0.716604
I0607 11:16:26.905191 140082802067264 spec.py:298] Evaluating on the training split.
I0607 11:16:29.016104 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 11:16:31.190868 140082802067264 spec.py:326] Evaluating on the test split.
I0607 11:16:33.335911 140082802067264 submission_runner.py:419] Time since start: 1825.67s, 	Step: 5382, 	{'train/ssim': 0.737713132585798, 'train/loss': 0.27124156270708355, 'validation/ssim': 0.7173849695105866, 'validation/loss': 0.2913842402486635, 'validation/num_examples': 3554, 'test/ssim': 0.734399543598157, 'test/loss': 0.29305059608218725, 'test/num_examples': 3581, 'score': 1485.8950505256653, 'total_duration': 1825.671775341034, 'accumulated_submission_time': 1485.8950505256653, 'accumulated_eval_time': 336.78146409988403, 'accumulated_logging_time': 0.36806178092956543}
I0607 11:16:33.346597 140015665411840 logging_writer.py:48] [5382] accumulated_eval_time=336.781464, accumulated_logging_time=0.368062, accumulated_submission_time=1485.895051, global_step=5382, preemption_count=0, score=1485.895051, test/loss=0.293051, test/num_examples=3581, test/ssim=0.734400, total_duration=1825.671775, train/loss=0.271242, train/ssim=0.737713, validation/loss=0.291384, validation/num_examples=3554, validation/ssim=0.717385
I0607 11:16:42.998865 140082802067264 spec.py:298] Evaluating on the training split.
I0607 11:16:45.079179 140082802067264 spec.py:310] Evaluating on the validation split.
I0607 11:16:47.195121 140082802067264 spec.py:326] Evaluating on the test split.
I0607 11:16:49.277243 140082802067264 submission_runner.py:419] Time since start: 1841.61s, 	Step: 5428, 	{'train/ssim': 0.7358083724975586, 'train/loss': 0.2724205596106393, 'validation/ssim': 0.7167662372063168, 'validation/loss': 0.2921991643438731, 'validation/num_examples': 3554, 'test/ssim': 0.7337109593165317, 'test/loss': 0.29375891750733035, 'test/num_examples': 3581, 'score': 1495.5205249786377, 'total_duration': 1841.613113641739, 'accumulated_submission_time': 1495.5205249786377, 'accumulated_eval_time': 343.05981969833374, 'accumulated_logging_time': 0.38640689849853516}
I0607 11:16:49.287928 140015657019136 logging_writer.py:48] [5428] accumulated_eval_time=343.059820, accumulated_logging_time=0.386407, accumulated_submission_time=1495.520525, global_step=5428, preemption_count=0, score=1495.520525, test/loss=0.293759, test/num_examples=3581, test/ssim=0.733711, total_duration=1841.613114, train/loss=0.272421, train/ssim=0.735808, validation/loss=0.292199, validation/num_examples=3554, validation/ssim=0.716766
I0607 11:16:49.305039 140015665411840 logging_writer.py:48] [5428] global_step=5428, preemption_count=0, score=1495.520525
I0607 11:16:49.397289 140082802067264 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v4_a_pytorch/momentum/fastmri_pytorch/trial_1/checkpoint_5428.
I0607 11:16:50.299440 140082802067264 submission_runner.py:581] Tuning trial 1/1
I0607 11:16:50.299689 140082802067264 submission_runner.py:582] Hyperparameters: Hyperparameters(learning_rate=0.4394877561366806, one_minus_beta1=0.07113602458522507, warmup_factor=0.05, weight_decay=9.611851572925426e-07, label_smoothing=0.2, dropout_rate=0.0, decay_steps_factor=0.9, end_factor=0.001)
I0607 11:16:50.308432 140082802067264 submission_runner.py:583] Metrics: {'eval_results': [(1, {'train/ssim': 0.18740405355181014, 'train/loss': 0.9259589740208217, 'validation/ssim': 0.187300304784222, 'validation/loss': 0.936197069433209, 'validation/num_examples': 3554, 'test/ssim': 0.20830935787402263, 'test/loss': 0.9347450492835451, 'test/num_examples': 3581, 'score': 46.757859230041504, 'total_duration': 266.2225139141083, 'accumulated_submission_time': 46.757859230041504, 'accumulated_eval_time': 219.46425366401672, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (310, {'train/ssim': 0.7052318709237235, 'train/loss': 0.3042196886880057, 'validation/ssim': 0.6854312619803391, 'validation/loss': 0.32450359217826746, 'validation/num_examples': 3554, 'test/ssim': 0.7040351584316532, 'test/loss': 0.3259420173855941, 'test/num_examples': 3581, 'score': 126.75010347366333, 'total_duration': 353.3164782524109, 'accumulated_submission_time': 126.75010347366333, 'accumulated_eval_time': 226.30137133598328, 'accumulated_logging_time': 0.025960445404052734, 'global_step': 310, 'preemption_count': 0}), (537, {'train/ssim': 0.7092791284833636, 'train/loss': 0.29530474117824007, 'validation/ssim': 0.6896956856490926, 'validation/loss': 0.3147843016891179, 'validation/num_examples': 3554, 'test/ssim': 0.7080172208792935, 'test/loss': 0.3161736653191322, 'test/num_examples': 3581, 'score': 206.75187611579895, 'total_duration': 440.2658920288086, 'accumulated_submission_time': 206.75187611579895, 'accumulated_eval_time': 233.01930713653564, 'accumulated_logging_time': 0.04703927040100098, 'global_step': 537, 'preemption_count': 0}), (769, {'train/ssim': 0.6961404255458287, 'train/loss': 0.30774995258876253, 'validation/ssim': 0.6794952238015265, 'validation/loss': 0.3259564487197524, 'validation/num_examples': 3554, 'test/ssim': 0.6961414600277507, 'test/loss': 0.32830907698617706, 'test/num_examples': 3581, 'score': 286.55228781700134, 'total_duration': 526.8397493362427, 'accumulated_submission_time': 286.55228781700134, 'accumulated_eval_time': 239.55834460258484, 'accumulated_logging_time': 0.07612371444702148, 'global_step': 769, 'preemption_count': 0}), (1007, {'train/ssim': 0.7208937236240932, 'train/loss': 0.2899871894291469, 'validation/ssim': 0.7009236126987197, 'validation/loss': 0.3092052693707794, 'validation/num_examples': 3554, 'test/ssim': 0.7183062381099903, 'test/loss': 0.3112786151083845, 'test/num_examples': 3581, 'score': 366.55245900154114, 'total_duration': 613.7339458465576, 'accumulated_submission_time': 366.55245900154114, 'accumulated_eval_time': 246.20979070663452, 'accumulated_logging_time': 0.10266256332397461, 'global_step': 1007, 'preemption_count': 0}), (1316, {'train/ssim': 0.7167935371398926, 'train/loss': 0.293940612248012, 'validation/ssim': 0.6976009920600028, 'validation/loss': 0.31298113701111424, 'validation/num_examples': 3554, 'test/ssim': 0.7148938598462371, 'test/loss': 0.31433160010079236, 'test/num_examples': 3581, 'score': 446.4350805282593, 'total_duration': 700.2335622310638, 'accumulated_submission_time': 446.4350805282593, 'accumulated_eval_time': 252.68460702896118, 'accumulated_logging_time': 0.12057304382324219, 'global_step': 1316, 'preemption_count': 0}), (1630, {'train/ssim': 0.7193865094866071, 'train/loss': 0.29278394154139925, 'validation/ssim': 0.7033100632649831, 'validation/loss': 0.3105668994772615, 'validation/num_examples': 3554, 'test/ssim': 0.7202114349169226, 'test/loss': 0.31234861372303474, 'test/num_examples': 3581, 'score': 526.3412532806396, 'total_duration': 786.7786755561829, 'accumulated_submission_time': 526.3412532806396, 'accumulated_eval_time': 259.178781747818, 'accumulated_logging_time': 0.13937163352966309, 'global_step': 1630, 'preemption_count': 0}), (1945, {'train/ssim': 0.7324652671813965, 'train/loss': 0.2819375821522304, 'validation/ssim': 0.7137198375729812, 'validation/loss': 0.30075054351171215, 'validation/num_examples': 3554, 'test/ssim': 0.7306740299279182, 'test/loss': 0.30282109571348786, 'test/num_examples': 3581, 'score': 606.381742477417, 'total_duration': 873.3677892684937, 'accumulated_submission_time': 606.381742477417, 'accumulated_eval_time': 265.5822319984436, 'accumulated_logging_time': 0.1570894718170166, 'global_step': 1945, 'preemption_count': 0}), (2256, {'train/ssim': 0.7256829398018974, 'train/loss': 0.2821119853428432, 'validation/ssim': 0.7058533436137099, 'validation/loss': 0.30228717312359316, 'validation/num_examples': 3554, 'test/ssim': 0.7221666733934307, 'test/loss': 0.3045134108947396, 'test/num_examples': 3581, 'score': 686.3382005691528, 'total_duration': 959.7865138053894, 'accumulated_submission_time': 686.3382005691528, 'accumulated_eval_time': 271.9015235900879, 'accumulated_logging_time': 0.17635512351989746, 'global_step': 2256, 'preemption_count': 0}), (2570, {'train/ssim': 0.7351382119315011, 'train/loss': 0.27504355566842215, 'validation/ssim': 0.7154837776317178, 'validation/loss': 0.2948514630302124, 'validation/num_examples': 3554, 'test/ssim': 0.732560205446279, 'test/loss': 0.2965001988031451, 'test/num_examples': 3581, 'score': 766.3500363826752, 'total_duration': 1046.6412916183472, 'accumulated_submission_time': 766.3500363826752, 'accumulated_eval_time': 278.59747791290283, 'accumulated_logging_time': 0.19678068161010742, 'global_step': 2570, 'preemption_count': 0}), (2882, {'train/ssim': 0.7312564849853516, 'train/loss': 0.2758436032703945, 'validation/ssim': 0.7110913072198579, 'validation/loss': 0.2956197434888506, 'validation/num_examples': 3554, 'test/ssim': 0.7281976490505445, 'test/loss': 0.29729060492879084, 'test/num_examples': 3581, 'score': 846.3069565296173, 'total_duration': 1133.1804027557373, 'accumulated_submission_time': 846.3069565296173, 'accumulated_eval_time': 285.0343647003174, 'accumulated_logging_time': 0.21626663208007812, 'global_step': 2882, 'preemption_count': 0}), (3193, {'train/ssim': 0.7296384402683803, 'train/loss': 0.27800657067980084, 'validation/ssim': 0.7097500450636607, 'validation/loss': 0.29757613148257245, 'validation/num_examples': 3554, 'test/ssim': 0.7271236621011938, 'test/loss': 0.2990025209002374, 'test/num_examples': 3581, 'score': 926.1695668697357, 'total_duration': 1219.6210324764252, 'accumulated_submission_time': 926.1695668697357, 'accumulated_eval_time': 291.4687819480896, 'accumulated_logging_time': 0.2351830005645752, 'global_step': 3193, 'preemption_count': 0}), (3507, {'train/ssim': 0.7325513022286552, 'train/loss': 0.2741603510720389, 'validation/ssim': 0.7124110679647931, 'validation/loss': 0.2943285940467607, 'validation/num_examples': 3554, 'test/ssim': 0.7291489861857722, 'test/loss': 0.29623737777288117, 'test/num_examples': 3581, 'score': 1006.2509062290192, 'total_duration': 1306.335785627365, 'accumulated_submission_time': 1006.2509062290192, 'accumulated_eval_time': 297.95650720596313, 'accumulated_logging_time': 0.2533903121948242, 'global_step': 3507, 'preemption_count': 0}), (3820, {'train/ssim': 0.737180233001709, 'train/loss': 0.27213660308292936, 'validation/ssim': 0.7171377376283765, 'validation/loss': 0.2923888644946715, 'validation/num_examples': 3554, 'test/ssim': 0.734247509642907, 'test/loss': 0.29398349143046637, 'test/num_examples': 3581, 'score': 1086.1205325126648, 'total_duration': 1392.8337845802307, 'accumulated_submission_time': 1086.1205325126648, 'accumulated_eval_time': 304.4408800601959, 'accumulated_logging_time': 0.27137303352355957, 'global_step': 3820, 'preemption_count': 0}), (4131, {'train/ssim': 0.7374694006783622, 'train/loss': 0.27376212392534527, 'validation/ssim': 0.7172535567318514, 'validation/loss': 0.2935997786385059, 'validation/num_examples': 3554, 'test/ssim': 0.734266190048171, 'test/loss': 0.2953370367804908, 'test/num_examples': 3581, 'score': 1166.0128228664398, 'total_duration': 1479.3070080280304, 'accumulated_submission_time': 1166.0128228664398, 'accumulated_eval_time': 310.87982082366943, 'accumulated_logging_time': 0.2897965908050537, 'global_step': 4131, 'preemption_count': 0}), (4443, {'train/ssim': 0.7338150569370815, 'train/loss': 0.2723485231399536, 'validation/ssim': 0.7144687461531022, 'validation/loss': 0.2921742282023776, 'validation/num_examples': 3554, 'test/ssim': 0.7316614325171041, 'test/loss': 0.29372905612957273, 'test/num_examples': 3581, 'score': 1246.1761119365692, 'total_duration': 1565.8936433792114, 'accumulated_submission_time': 1246.1761119365692, 'accumulated_eval_time': 317.1595482826233, 'accumulated_logging_time': 0.30879712104797363, 'global_step': 4443, 'preemption_count': 0}), (4756, {'train/ssim': 0.737752982548305, 'train/loss': 0.2711171422685896, 'validation/ssim': 0.7178034570422411, 'validation/loss': 0.29126557031909467, 'validation/num_examples': 3554, 'test/ssim': 0.7349390255209788, 'test/loss': 0.29285329282367006, 'test/num_examples': 3581, 'score': 1326.0707702636719, 'total_duration': 1652.618437051773, 'accumulated_submission_time': 1326.0707702636719, 'accumulated_eval_time': 323.8427426815033, 'accumulated_logging_time': 0.32967209815979004, 'global_step': 4756, 'preemption_count': 0}), (5070, {'train/ssim': 0.7372445378984723, 'train/loss': 0.2714275462286813, 'validation/ssim': 0.7166044614123172, 'validation/loss': 0.29186541160708007, 'validation/num_examples': 3554, 'test/ssim': 0.7337530924933677, 'test/loss': 0.29352196952012355, 'test/num_examples': 3581, 'score': 1406.0088262557983, 'total_duration': 1739.2101290225983, 'accumulated_submission_time': 1406.0088262557983, 'accumulated_eval_time': 330.3507659435272, 'accumulated_logging_time': 0.34786009788513184, 'global_step': 5070, 'preemption_count': 0}), (5382, {'train/ssim': 0.737713132585798, 'train/loss': 0.27124156270708355, 'validation/ssim': 0.7173849695105866, 'validation/loss': 0.2913842402486635, 'validation/num_examples': 3554, 'test/ssim': 0.734399543598157, 'test/loss': 0.29305059608218725, 'test/num_examples': 3581, 'score': 1485.8950505256653, 'total_duration': 1825.671775341034, 'accumulated_submission_time': 1485.8950505256653, 'accumulated_eval_time': 336.78146409988403, 'accumulated_logging_time': 0.36806178092956543, 'global_step': 5382, 'preemption_count': 0}), (5428, {'train/ssim': 0.7358083724975586, 'train/loss': 0.2724205596106393, 'validation/ssim': 0.7167662372063168, 'validation/loss': 0.2921991643438731, 'validation/num_examples': 3554, 'test/ssim': 0.7337109593165317, 'test/loss': 0.29375891750733035, 'test/num_examples': 3581, 'score': 1495.5205249786377, 'total_duration': 1841.613113641739, 'accumulated_submission_time': 1495.5205249786377, 'accumulated_eval_time': 343.05981969833374, 'accumulated_logging_time': 0.38640689849853516, 'global_step': 5428, 'preemption_count': 0})], 'global_step': 5428}
I0607 11:16:50.308647 140082802067264 submission_runner.py:584] Timing: 1495.5205249786377
I0607 11:16:50.308698 140082802067264 submission_runner.py:586] Total number of evals: 20
I0607 11:16:50.308741 140082802067264 submission_runner.py:587] ====================
I0607 11:16:50.308854 140082802067264 submission_runner.py:655] Final fastmri score: 1495.5205249786377
