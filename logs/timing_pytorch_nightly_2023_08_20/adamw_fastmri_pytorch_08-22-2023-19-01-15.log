torchrun --redirects 1:0,2:0,3:0,4:0,5:0,6:0,7:0 --standalone --nnodes=1 --nproc_per_node=8 submission_runner.py --framework=pytorch --workload=fastmri --submission_path=baselines/adamw/pytorch/submission.py --tuning_search_space=baselines/adamw/tuning_search_space.json --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_pytorch_nightly_2023_08_20/adamw --overwrite=True --save_checkpoints=False --max_global_steps=2714 --torch_compile=true 2>&1 | tee -a /logs/fastmri_pytorch_08-22-2023-19-01-15.log
[2023-08-22 19:01:19,676] torch.distributed.run: [WARNING] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
[2023-08-22 19:01:19,676] torch.distributed.run: [WARNING] 
[2023-08-22 19:01:19,676] torch.distributed.run: [WARNING] *****************************************
[2023-08-22 19:01:19,676] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-08-22 19:01:19,676] torch.distributed.run: [WARNING] *****************************************
2023-08-22 19:01:24.604483: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-08-22 19:01:24.604491: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-08-22 19:01:24.604481: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-08-22 19:01:24.604482: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-08-22 19:01:24.604481: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-08-22 19:01:24.604481: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-08-22 19:01:24.604481: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-08-22 19:01:24.604481: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0822 19:01:40.301203 140539023103808 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_pytorch_nightly_2023_08_20/adamw/fastmri_pytorch.
W0822 19:01:40.341091 140432825034560 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0822 19:01:40.341090 139636779968320 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0822 19:01:40.341091 140518148007744 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0822 19:01:40.341109 139676459382592 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0822 19:01:40.341109 140706814351168 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0822 19:01:40.341703 140355619161920 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0822 19:01:40.342502 140539023103808 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0822 19:01:40.342584 140060582197056 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0822 19:01:40.347227 140539023103808 submission_runner.py:494] Using RNG seed 2508338349
I0822 19:01:40.349060 140539023103808 submission_runner.py:503] --- Tuning run 1/1 ---
I0822 19:01:40.349175 140539023103808 submission_runner.py:508] Creating tuning directory at /experiment_runs/timing_pytorch_nightly_2023_08_20/adamw/fastmri_pytorch/trial_1.
I0822 19:01:40.350370 140539023103808 logger_utils.py:92] Saving hparams to /experiment_runs/timing_pytorch_nightly_2023_08_20/adamw/fastmri_pytorch/trial_1/hparams.json.
I0822 19:01:40.351267 140539023103808 submission_runner.py:177] Initializing dataset.
I0822 19:01:40.351398 140539023103808 submission_runner.py:184] Initializing model.
I0822 19:01:44.944482 140539023103808 submission_runner.py:215] Performing `torch.compile`.
I0822 19:01:49.121922 140539023103808 submission_runner.py:218] Initializing optimizer.
I0822 19:01:49.123862 140539023103808 submission_runner.py:225] Initializing metrics bundle.
I0822 19:01:49.123997 140539023103808 submission_runner.py:243] Initializing checkpoint and logger.
I0822 19:01:49.125242 140539023103808 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0822 19:01:49.125360 140539023103808 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
I0822 19:01:49.601852 140539023103808 submission_runner.py:264] Saving meta data to /experiment_runs/timing_pytorch_nightly_2023_08_20/adamw/fastmri_pytorch/trial_1/meta_data_0.json.
I0822 19:01:49.602920 140539023103808 submission_runner.py:267] Saving flags to /experiment_runs/timing_pytorch_nightly_2023_08_20/adamw/fastmri_pytorch/trial_1/flags_0.json.
I0822 19:01:49.696704 140539023103808 submission_runner.py:277] Starting training loop.
[rank7]:[2023-08-22 19:01:49,789] torch._dynamo.variables.torch: [WARNING] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank3]:[2023-08-22 19:01:49,789] torch._dynamo.variables.torch: [WARNING] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank4]:[2023-08-22 19:01:49,789] torch._dynamo.variables.torch: [WARNING] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank6]:[2023-08-22 19:01:49,789] torch._dynamo.variables.torch: [WARNING] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank1]:[2023-08-22 19:01:49,789] torch._dynamo.variables.torch: [WARNING] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank2]:[2023-08-22 19:01:49,797] torch._dynamo.variables.torch: [WARNING] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank5]:[2023-08-22 19:01:49,797] torch._dynamo.variables.torch: [WARNING] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank0]:[2023-08-22 19:02:32,705] torch._dynamo.variables.torch: [WARNING] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:111: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:112: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:118: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:119: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:111: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:112: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:118: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:119: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:111: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:112: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:118: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:119: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:111: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:112: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:118: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:119: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:111: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:112: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:118: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:119: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:111: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:112: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:118: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:119: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:111: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:112: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:118: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:119: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:111: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:112: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:118: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/usr/local/lib/python3.8/dist-packages/torch/overrides.py:119: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
I0822 19:04:03.359616 140496533976832 logging_writer.py:48] [0] global_step=0, grad_norm=4.222049, loss=1.179457
I0822 19:04:03.371416 140539023103808 submission.py:120] 0) loss = 1.179, grad_norm = 4.222
I0822 19:04:03.372688 140539023103808 spec.py:320] Evaluating on the training split.
[rank2]:[2023-08-22 19:04:57,692] torch._dynamo.variables.torch: [WARNING] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank3]:[2023-08-22 19:04:57,693] torch._dynamo.variables.torch: [WARNING] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank0]:[2023-08-22 19:04:57,693] torch._dynamo.variables.torch: [WARNING] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank6]:[2023-08-22 19:04:57,693] torch._dynamo.variables.torch: [WARNING] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank7]:[2023-08-22 19:04:57,694] torch._dynamo.variables.torch: [WARNING] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank1]:[2023-08-22 19:04:57,695] torch._dynamo.variables.torch: [WARNING] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank4]:[2023-08-22 19:04:57,695] torch._dynamo.variables.torch: [WARNING] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank5]:[2023-08-22 19:04:57,696] torch._dynamo.variables.torch: [WARNING] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0822 19:05:59.481332 140539023103808 spec.py:332] Evaluating on the validation split.
I0822 19:06:58.678263 140539023103808 spec.py:348] Evaluating on the test split.
I0822 19:07:57.708734 140539023103808 submission_runner.py:365] Time since start: 368.01s, 	Step: 1, 	{'train/ssim': 0.18742665222712926, 'train/loss': 1.1903172901698522, 'validation/ssim': 0.18415292408202025, 'validation/loss': 1.1949999395487478, 'validation/num_examples': 3554, 'test/ssim': 0.20378505234876781, 'test/loss': 1.192674063198129, 'test/num_examples': 3581, 'score': 133.67628121376038, 'total_duration': 368.01284289360046, 'accumulated_submission_time': 133.67628121376038, 'accumulated_eval_time': 234.3360550403595, 'accumulated_logging_time': 0}
I0822 19:07:57.734341 140475562456832 logging_writer.py:48] [1] accumulated_eval_time=234.336055, accumulated_logging_time=0, accumulated_submission_time=133.676281, global_step=1, preemption_count=0, score=133.676281, test/loss=1.192674, test/num_examples=3581, test/ssim=0.203785, total_duration=368.012843, train/loss=1.190317, train/ssim=0.187427, validation/loss=1.195000, validation/num_examples=3554, validation/ssim=0.184153
I0822 19:07:58.167726 140539023103808 submission_runner.py:396] Released all unoccupied cached memory.
I0822 19:07:58.382570 140475554064128 logging_writer.py:48] [1] global_step=1, grad_norm=3.954225, loss=1.136393
I0822 19:07:58.386017 140539023103808 submission.py:120] 1) loss = 1.136, grad_norm = 3.954
I0822 19:07:58.445525 140475562456832 logging_writer.py:48] [2] global_step=2, grad_norm=4.402357, loss=1.143823
I0822 19:07:58.449631 140539023103808 submission.py:120] 2) loss = 1.144, grad_norm = 4.402
I0822 19:07:58.511148 140475554064128 logging_writer.py:48] [3] global_step=3, grad_norm=4.610202, loss=1.138602
I0822 19:07:58.515056 140539023103808 submission.py:120] 3) loss = 1.139, grad_norm = 4.610
I0822 19:07:58.583507 140475562456832 logging_writer.py:48] [4] global_step=4, grad_norm=4.143889, loss=1.129285
I0822 19:07:58.589798 140539023103808 submission.py:120] 4) loss = 1.129, grad_norm = 4.144
I0822 19:07:58.665761 140475554064128 logging_writer.py:48] [5] global_step=5, grad_norm=3.864566, loss=1.212061
I0822 19:07:58.670811 140539023103808 submission.py:120] 5) loss = 1.212, grad_norm = 3.865
I0822 19:07:58.755788 140475562456832 logging_writer.py:48] [6] global_step=6, grad_norm=3.964674, loss=1.172704
I0822 19:07:58.762330 140539023103808 submission.py:120] 6) loss = 1.173, grad_norm = 3.965
I0822 19:07:58.848939 140475554064128 logging_writer.py:48] [7] global_step=7, grad_norm=4.144786, loss=1.154507
I0822 19:07:58.854005 140539023103808 submission.py:120] 7) loss = 1.155, grad_norm = 4.145
I0822 19:07:58.935033 140475562456832 logging_writer.py:48] [8] global_step=8, grad_norm=3.140043, loss=1.187591
I0822 19:07:58.941387 140539023103808 submission.py:120] 8) loss = 1.188, grad_norm = 3.140
I0822 19:07:59.033720 140475554064128 logging_writer.py:48] [9] global_step=9, grad_norm=3.940285, loss=1.118581
I0822 19:07:59.040190 140539023103808 submission.py:120] 9) loss = 1.119, grad_norm = 3.940
I0822 19:07:59.143529 140475562456832 logging_writer.py:48] [10] global_step=10, grad_norm=3.676788, loss=1.145272
I0822 19:07:59.149740 140539023103808 submission.py:120] 10) loss = 1.145, grad_norm = 3.677
I0822 19:09:17.836984 140539023103808 spec.py:320] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0822 19:09:19.845671 140539023103808 spec.py:332] Evaluating on the validation split.
I0822 19:09:21.982566 140539023103808 spec.py:348] Evaluating on the test split.
I0822 19:09:24.026032 140539023103808 submission_runner.py:365] Time since start: 454.33s, 	Step: 307, 	{'train/ssim': 0.6945889336722237, 'train/loss': 0.3165619373321533, 'validation/ssim': 0.6734374587832372, 'validation/loss': 0.33213456668542485, 'validation/num_examples': 3554, 'test/ssim': 0.6913414821715304, 'test/loss': 0.3340061915316951, 'test/num_examples': 3581, 'score': 213.0801079273224, 'total_duration': 454.33021450042725, 'accumulated_submission_time': 213.0801079273224, 'accumulated_eval_time': 240.5250952243805, 'accumulated_logging_time': 0.49597668647766113}
I0822 19:09:24.047249 140475554064128 logging_writer.py:48] [307] accumulated_eval_time=240.525095, accumulated_logging_time=0.495977, accumulated_submission_time=213.080108, global_step=307, preemption_count=0, score=213.080108, test/loss=0.334006, test/num_examples=3581, test/ssim=0.691341, total_duration=454.330215, train/loss=0.316562, train/ssim=0.694589, validation/loss=0.332135, validation/num_examples=3554, validation/ssim=0.673437
I0822 19:09:24.499039 140539023103808 submission_runner.py:396] Released all unoccupied cached memory.
I0822 19:10:28.316668 140475562456832 logging_writer.py:48] [500] global_step=500, grad_norm=0.287948, loss=0.294308
I0822 19:10:28.323856 140539023103808 submission.py:120] 500) loss = 0.294, grad_norm = 0.288
I0822 19:10:44.294925 140539023103808 spec.py:320] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0822 19:10:46.353256 140539023103808 spec.py:332] Evaluating on the validation split.
I0822 19:10:48.461991 140539023103808 spec.py:348] Evaluating on the test split.
I0822 19:10:50.523642 140539023103808 submission_runner.py:365] Time since start: 540.83s, 	Step: 545, 	{'train/ssim': 0.7143313544137138, 'train/loss': 0.30176888193402973, 'validation/ssim': 0.6923068362672341, 'validation/loss': 0.3168967638246518, 'validation/num_examples': 3554, 'test/ssim': 0.7101666264878874, 'test/loss': 0.3191100682202946, 'test/num_examples': 3581, 'score': 292.6656765937805, 'total_duration': 540.8275997638702, 'accumulated_submission_time': 292.6656765937805, 'accumulated_eval_time': 246.75370621681213, 'accumulated_logging_time': 0.9699728488922119}
I0822 19:10:50.545149 140475554064128 logging_writer.py:48] [545] accumulated_eval_time=246.753706, accumulated_logging_time=0.969973, accumulated_submission_time=292.665677, global_step=545, preemption_count=0, score=292.665677, test/loss=0.319110, test/num_examples=3581, test/ssim=0.710167, total_duration=540.827600, train/loss=0.301769, train/ssim=0.714331, validation/loss=0.316897, validation/num_examples=3554, validation/ssim=0.692307
I0822 19:10:50.955457 140539023103808 submission_runner.py:396] Released all unoccupied cached memory.
I0822 19:12:10.902350 140539023103808 spec.py:320] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0822 19:12:12.890458 140539023103808 spec.py:332] Evaluating on the validation split.
I0822 19:12:15.041340 140539023103808 spec.py:348] Evaluating on the test split.
I0822 19:12:17.079422 140539023103808 submission_runner.py:365] Time since start: 627.38s, 	Step: 778, 	{'train/ssim': 0.6986998830522809, 'train/loss': 0.32179008211408344, 'validation/ssim': 0.6778839231543683, 'validation/loss': 0.3378385888369619, 'validation/num_examples': 3554, 'test/ssim': 0.696097145197745, 'test/loss': 0.3396032909147235, 'test/num_examples': 3581, 'score': 372.3423388004303, 'total_duration': 627.3835716247559, 'accumulated_submission_time': 372.3423388004303, 'accumulated_eval_time': 252.93140363693237, 'accumulated_logging_time': 1.4629852771759033}
I0822 19:12:17.097845 140475562456832 logging_writer.py:48] [778] accumulated_eval_time=252.931404, accumulated_logging_time=1.462985, accumulated_submission_time=372.342339, global_step=778, preemption_count=0, score=372.342339, test/loss=0.339603, test/num_examples=3581, test/ssim=0.696097, total_duration=627.383572, train/loss=0.321790, train/ssim=0.698700, validation/loss=0.337839, validation/num_examples=3554, validation/ssim=0.677884
I0822 19:12:17.534658 140539023103808 submission_runner.py:396] Released all unoccupied cached memory.
I0822 19:13:31.617387 140475554064128 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.117673, loss=0.262110
I0822 19:13:31.626380 140539023103808 submission.py:120] 1000) loss = 0.262, grad_norm = 0.118
I0822 19:13:37.294153 140539023103808 spec.py:320] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0822 19:13:39.242325 140539023103808 spec.py:332] Evaluating on the validation split.
I0822 19:13:41.523138 140539023103808 spec.py:348] Evaluating on the test split.
I0822 19:13:43.505736 140539023103808 submission_runner.py:365] Time since start: 713.81s, 	Step: 1022, 	{'train/ssim': 0.7278941018240792, 'train/loss': 0.28850187574114117, 'validation/ssim': 0.7054885065683033, 'validation/loss': 0.3037145096194429, 'validation/num_examples': 3554, 'test/ssim': 0.7226668855592013, 'test/loss': 0.3059433822823583, 'test/num_examples': 3581, 'score': 451.86347556114197, 'total_duration': 713.8099088668823, 'accumulated_submission_time': 451.86347556114197, 'accumulated_eval_time': 259.14303183555603, 'accumulated_logging_time': 1.9506845474243164}
I0822 19:13:43.521848 140475562456832 logging_writer.py:48] [1022] accumulated_eval_time=259.143032, accumulated_logging_time=1.950685, accumulated_submission_time=451.863476, global_step=1022, preemption_count=0, score=451.863476, test/loss=0.305943, test/num_examples=3581, test/ssim=0.722667, total_duration=713.809909, train/loss=0.288502, train/ssim=0.727894, validation/loss=0.303715, validation/num_examples=3554, validation/ssim=0.705489
I0822 19:13:43.999698 140539023103808 submission_runner.py:396] Released all unoccupied cached memory.
I0822 19:15:03.586332 140539023103808 spec.py:320] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0822 19:15:05.528276 140539023103808 spec.py:332] Evaluating on the validation split.
I0822 19:15:07.506357 140539023103808 spec.py:348] Evaluating on the test split.
I0822 19:15:09.363738 140539023103808 submission_runner.py:365] Time since start: 799.67s, 	Step: 1330, 	{'train/ssim': 0.7310128893171038, 'train/loss': 0.2843325989586966, 'validation/ssim': 0.7080166741040025, 'validation/loss': 0.2997295012551878, 'validation/num_examples': 3554, 'test/ssim': 0.7250770668982128, 'test/loss': 0.3019521159854091, 'test/num_examples': 3581, 'score': 531.3096988201141, 'total_duration': 799.6678915023804, 'accumulated_submission_time': 531.3096988201141, 'accumulated_eval_time': 264.92046642303467, 'accumulated_logging_time': 2.4490373134613037}
I0822 19:15:09.380991 140475554064128 logging_writer.py:48] [1330] accumulated_eval_time=264.920466, accumulated_logging_time=2.449037, accumulated_submission_time=531.309699, global_step=1330, preemption_count=0, score=531.309699, test/loss=0.301952, test/num_examples=3581, test/ssim=0.725077, total_duration=799.667892, train/loss=0.284333, train/ssim=0.731013, validation/loss=0.299730, validation/num_examples=3554, validation/ssim=0.708017
I0822 19:15:09.879624 140539023103808 submission_runner.py:396] Released all unoccupied cached memory.
I0822 19:15:52.522505 140475562456832 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.150830, loss=0.295909
I0822 19:15:52.526664 140539023103808 submission.py:120] 1500) loss = 0.296, grad_norm = 0.151
I0822 19:16:29.477655 140539023103808 spec.py:320] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0822 19:16:31.482250 140539023103808 spec.py:332] Evaluating on the validation split.
I0822 19:16:33.656820 140539023103808 spec.py:348] Evaluating on the test split.
I0822 19:16:35.718628 140539023103808 submission_runner.py:365] Time since start: 886.02s, 	Step: 1639, 	{'train/ssim': 0.7352373940604073, 'train/loss': 0.2831190654209682, 'validation/ssim': 0.7122749152583356, 'validation/loss': 0.299416459941703, 'validation/num_examples': 3554, 'test/ssim': 0.7293682423293074, 'test/loss': 0.30130992592196665, 'test/num_examples': 3581, 'score': 610.7735204696655, 'total_duration': 886.0227644443512, 'accumulated_submission_time': 610.7735204696655, 'accumulated_eval_time': 271.16153621673584, 'accumulated_logging_time': 2.9649839401245117}
I0822 19:16:35.733503 140475554064128 logging_writer.py:48] [1639] accumulated_eval_time=271.161536, accumulated_logging_time=2.964984, accumulated_submission_time=610.773520, global_step=1639, preemption_count=0, score=610.773520, test/loss=0.301310, test/num_examples=3581, test/ssim=0.729368, total_duration=886.022764, train/loss=0.283119, train/ssim=0.735237, validation/loss=0.299416, validation/num_examples=3554, validation/ssim=0.712275
I0822 19:16:36.177866 140539023103808 submission_runner.py:396] Released all unoccupied cached memory.
I0822 19:17:55.918640 140539023103808 spec.py:320] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0822 19:17:57.881196 140539023103808 spec.py:332] Evaluating on the validation split.
I0822 19:17:59.966430 140539023103808 spec.py:348] Evaluating on the test split.
I0822 19:18:01.958861 140539023103808 submission_runner.py:365] Time since start: 972.26s, 	Step: 1946, 	{'train/ssim': 0.7355941363743373, 'train/loss': 0.28058832032339914, 'validation/ssim': 0.7128157478809088, 'validation/loss': 0.2962780438854108, 'validation/num_examples': 3554, 'test/ssim': 0.7297160796565205, 'test/loss': 0.29830527818259567, 'test/num_examples': 3581, 'score': 690.3442101478577, 'total_duration': 972.262766122818, 'accumulated_submission_time': 690.3442101478577, 'accumulated_eval_time': 277.2015380859375, 'accumulated_logging_time': 3.4599108695983887}
I0822 19:18:01.983491 140475562456832 logging_writer.py:48] [1946] accumulated_eval_time=277.201538, accumulated_logging_time=3.459911, accumulated_submission_time=690.344210, global_step=1946, preemption_count=0, score=690.344210, test/loss=0.298305, test/num_examples=3581, test/ssim=0.729716, total_duration=972.262766, train/loss=0.280588, train/ssim=0.735594, validation/loss=0.296278, validation/num_examples=3554, validation/ssim=0.712816
I0822 19:18:02.487668 140539023103808 submission_runner.py:396] Released all unoccupied cached memory.
I0822 19:18:14.384827 140475554064128 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.202861, loss=0.255635
I0822 19:18:14.388657 140539023103808 submission.py:120] 2000) loss = 0.256, grad_norm = 0.203
I0822 19:19:21.979086 140539023103808 spec.py:320] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0822 19:19:23.917474 140539023103808 spec.py:332] Evaluating on the validation split.
I0822 19:19:26.029061 140539023103808 spec.py:348] Evaluating on the test split.
I0822 19:19:27.997963 140539023103808 submission_runner.py:365] Time since start: 1058.30s, 	Step: 2254, 	{'train/ssim': 0.7362854140145438, 'train/loss': 0.28029336248125347, 'validation/ssim': 0.7129065621482836, 'validation/loss': 0.2968601619653911, 'validation/num_examples': 3554, 'test/ssim': 0.7298771129310947, 'test/loss': 0.29864275265725354, 'test/num_examples': 3581, 'score': 769.6981856822968, 'total_duration': 1058.3021421432495, 'accumulated_submission_time': 769.6981856822968, 'accumulated_eval_time': 283.22042965888977, 'accumulated_logging_time': 3.990530252456665}
I0822 19:19:28.013622 140475562456832 logging_writer.py:48] [2254] accumulated_eval_time=283.220430, accumulated_logging_time=3.990530, accumulated_submission_time=769.698186, global_step=2254, preemption_count=0, score=769.698186, test/loss=0.298643, test/num_examples=3581, test/ssim=0.729877, total_duration=1058.302142, train/loss=0.280293, train/ssim=0.736285, validation/loss=0.296860, validation/num_examples=3554, validation/ssim=0.712907
I0822 19:19:28.507224 140539023103808 submission_runner.py:396] Released all unoccupied cached memory.
I0822 19:20:31.065265 140475554064128 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.097201, loss=0.231519
I0822 19:20:31.069961 140539023103808 submission.py:120] 2500) loss = 0.232, grad_norm = 0.097
I0822 19:20:48.154342 140539023103808 spec.py:320] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0822 19:20:50.115394 140539023103808 spec.py:332] Evaluating on the validation split.
I0822 19:20:52.235364 140539023103808 spec.py:348] Evaluating on the test split.
I0822 19:20:54.223454 140539023103808 submission_runner.py:365] Time since start: 1144.53s, 	Step: 2566, 	{'train/ssim': 0.7389271599905831, 'train/loss': 0.27805464608328684, 'validation/ssim': 0.7157885068980374, 'validation/loss': 0.29377488118581174, 'validation/num_examples': 3554, 'test/ssim': 0.7329597206829447, 'test/loss': 0.2955675079848506, 'test/num_examples': 3581, 'score': 849.2069571018219, 'total_duration': 1144.5276415348053, 'accumulated_submission_time': 849.2069571018219, 'accumulated_eval_time': 289.28952646255493, 'accumulated_logging_time': 4.499828577041626}
I0822 19:20:54.238375 140475562456832 logging_writer.py:48] [2566] accumulated_eval_time=289.289526, accumulated_logging_time=4.499829, accumulated_submission_time=849.206957, global_step=2566, preemption_count=0, score=849.206957, test/loss=0.295568, test/num_examples=3581, test/ssim=0.732960, total_duration=1144.527642, train/loss=0.278055, train/ssim=0.738927, validation/loss=0.293775, validation/num_examples=3554, validation/ssim=0.715789
I0822 19:20:54.708184 140539023103808 submission_runner.py:396] Released all unoccupied cached memory.
I0822 19:21:31.511547 140539023103808 spec.py:320] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0822 19:21:33.442448 140539023103808 spec.py:332] Evaluating on the validation split.
I0822 19:21:35.491101 140539023103808 spec.py:348] Evaluating on the test split.
I0822 19:21:37.468519 140539023103808 submission_runner.py:365] Time since start: 1187.77s, 	Step: 2714, 	{'train/ssim': 0.7397570610046387, 'train/loss': 0.2762937205178397, 'validation/ssim': 0.7164654922270681, 'validation/loss': 0.29226682852947383, 'validation/num_examples': 3554, 'test/ssim': 0.7337072777768081, 'test/loss': 0.2939401310737224, 'test/num_examples': 3581, 'score': 885.9392790794373, 'total_duration': 1187.7727026939392, 'accumulated_submission_time': 885.9392790794373, 'accumulated_eval_time': 295.2465674877167, 'accumulated_logging_time': 4.9891676902771}
I0822 19:21:37.484077 140475554064128 logging_writer.py:48] [2714] accumulated_eval_time=295.246567, accumulated_logging_time=4.989168, accumulated_submission_time=885.939279, global_step=2714, preemption_count=0, score=885.939279, test/loss=0.293940, test/num_examples=3581, test/ssim=0.733707, total_duration=1187.772703, train/loss=0.276294, train/ssim=0.739757, validation/loss=0.292267, validation/num_examples=3554, validation/ssim=0.716465
I0822 19:21:37.947520 140539023103808 submission_runner.py:396] Released all unoccupied cached memory.
I0822 19:21:37.961978 140475562456832 logging_writer.py:48] [2714] global_step=2714, preemption_count=0, score=885.939279
I0822 19:21:38.132688 140539023103808 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_pytorch_nightly_2023_08_20/adamw/fastmri_pytorch/trial_1/checkpoint_2714.
I0822 19:21:39.280439 140539023103808 submission_runner.py:534] Tuning trial 1/1
I0822 19:21:39.280658 140539023103808 submission_runner.py:535] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0822 19:21:39.285586 140539023103808 submission_runner.py:536] Metrics: {'eval_results': [(1, {'train/ssim': 0.18742665222712926, 'train/loss': 1.1903172901698522, 'validation/ssim': 0.18415292408202025, 'validation/loss': 1.1949999395487478, 'validation/num_examples': 3554, 'test/ssim': 0.20378505234876781, 'test/loss': 1.192674063198129, 'test/num_examples': 3581, 'score': 133.67628121376038, 'total_duration': 368.01284289360046, 'accumulated_submission_time': 133.67628121376038, 'accumulated_eval_time': 234.3360550403595, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (307, {'train/ssim': 0.6945889336722237, 'train/loss': 0.3165619373321533, 'validation/ssim': 0.6734374587832372, 'validation/loss': 0.33213456668542485, 'validation/num_examples': 3554, 'test/ssim': 0.6913414821715304, 'test/loss': 0.3340061915316951, 'test/num_examples': 3581, 'score': 213.0801079273224, 'total_duration': 454.33021450042725, 'accumulated_submission_time': 213.0801079273224, 'accumulated_eval_time': 240.5250952243805, 'accumulated_logging_time': 0.49597668647766113, 'global_step': 307, 'preemption_count': 0}), (545, {'train/ssim': 0.7143313544137138, 'train/loss': 0.30176888193402973, 'validation/ssim': 0.6923068362672341, 'validation/loss': 0.3168967638246518, 'validation/num_examples': 3554, 'test/ssim': 0.7101666264878874, 'test/loss': 0.3191100682202946, 'test/num_examples': 3581, 'score': 292.6656765937805, 'total_duration': 540.8275997638702, 'accumulated_submission_time': 292.6656765937805, 'accumulated_eval_time': 246.75370621681213, 'accumulated_logging_time': 0.9699728488922119, 'global_step': 545, 'preemption_count': 0}), (778, {'train/ssim': 0.6986998830522809, 'train/loss': 0.32179008211408344, 'validation/ssim': 0.6778839231543683, 'validation/loss': 0.3378385888369619, 'validation/num_examples': 3554, 'test/ssim': 0.696097145197745, 'test/loss': 0.3396032909147235, 'test/num_examples': 3581, 'score': 372.3423388004303, 'total_duration': 627.3835716247559, 'accumulated_submission_time': 372.3423388004303, 'accumulated_eval_time': 252.93140363693237, 'accumulated_logging_time': 1.4629852771759033, 'global_step': 778, 'preemption_count': 0}), (1022, {'train/ssim': 0.7278941018240792, 'train/loss': 0.28850187574114117, 'validation/ssim': 0.7054885065683033, 'validation/loss': 0.3037145096194429, 'validation/num_examples': 3554, 'test/ssim': 0.7226668855592013, 'test/loss': 0.3059433822823583, 'test/num_examples': 3581, 'score': 451.86347556114197, 'total_duration': 713.8099088668823, 'accumulated_submission_time': 451.86347556114197, 'accumulated_eval_time': 259.14303183555603, 'accumulated_logging_time': 1.9506845474243164, 'global_step': 1022, 'preemption_count': 0}), (1330, {'train/ssim': 0.7310128893171038, 'train/loss': 0.2843325989586966, 'validation/ssim': 0.7080166741040025, 'validation/loss': 0.2997295012551878, 'validation/num_examples': 3554, 'test/ssim': 0.7250770668982128, 'test/loss': 0.3019521159854091, 'test/num_examples': 3581, 'score': 531.3096988201141, 'total_duration': 799.6678915023804, 'accumulated_submission_time': 531.3096988201141, 'accumulated_eval_time': 264.92046642303467, 'accumulated_logging_time': 2.4490373134613037, 'global_step': 1330, 'preemption_count': 0}), (1639, {'train/ssim': 0.7352373940604073, 'train/loss': 0.2831190654209682, 'validation/ssim': 0.7122749152583356, 'validation/loss': 0.299416459941703, 'validation/num_examples': 3554, 'test/ssim': 0.7293682423293074, 'test/loss': 0.30130992592196665, 'test/num_examples': 3581, 'score': 610.7735204696655, 'total_duration': 886.0227644443512, 'accumulated_submission_time': 610.7735204696655, 'accumulated_eval_time': 271.16153621673584, 'accumulated_logging_time': 2.9649839401245117, 'global_step': 1639, 'preemption_count': 0}), (1946, {'train/ssim': 0.7355941363743373, 'train/loss': 0.28058832032339914, 'validation/ssim': 0.7128157478809088, 'validation/loss': 0.2962780438854108, 'validation/num_examples': 3554, 'test/ssim': 0.7297160796565205, 'test/loss': 0.29830527818259567, 'test/num_examples': 3581, 'score': 690.3442101478577, 'total_duration': 972.262766122818, 'accumulated_submission_time': 690.3442101478577, 'accumulated_eval_time': 277.2015380859375, 'accumulated_logging_time': 3.4599108695983887, 'global_step': 1946, 'preemption_count': 0}), (2254, {'train/ssim': 0.7362854140145438, 'train/loss': 0.28029336248125347, 'validation/ssim': 0.7129065621482836, 'validation/loss': 0.2968601619653911, 'validation/num_examples': 3554, 'test/ssim': 0.7298771129310947, 'test/loss': 0.29864275265725354, 'test/num_examples': 3581, 'score': 769.6981856822968, 'total_duration': 1058.3021421432495, 'accumulated_submission_time': 769.6981856822968, 'accumulated_eval_time': 283.22042965888977, 'accumulated_logging_time': 3.990530252456665, 'global_step': 2254, 'preemption_count': 0}), (2566, {'train/ssim': 0.7389271599905831, 'train/loss': 0.27805464608328684, 'validation/ssim': 0.7157885068980374, 'validation/loss': 0.29377488118581174, 'validation/num_examples': 3554, 'test/ssim': 0.7329597206829447, 'test/loss': 0.2955675079848506, 'test/num_examples': 3581, 'score': 849.2069571018219, 'total_duration': 1144.5276415348053, 'accumulated_submission_time': 849.2069571018219, 'accumulated_eval_time': 289.28952646255493, 'accumulated_logging_time': 4.499828577041626, 'global_step': 2566, 'preemption_count': 0}), (2714, {'train/ssim': 0.7397570610046387, 'train/loss': 0.2762937205178397, 'validation/ssim': 0.7164654922270681, 'validation/loss': 0.29226682852947383, 'validation/num_examples': 3554, 'test/ssim': 0.7337072777768081, 'test/loss': 0.2939401310737224, 'test/num_examples': 3581, 'score': 885.9392790794373, 'total_duration': 1187.7727026939392, 'accumulated_submission_time': 885.9392790794373, 'accumulated_eval_time': 295.2465674877167, 'accumulated_logging_time': 4.9891676902771, 'global_step': 2714, 'preemption_count': 0})], 'global_step': 2714}
I0822 19:21:39.285735 140539023103808 submission_runner.py:537] Timing: 885.9392790794373
I0822 19:21:39.285786 140539023103808 submission_runner.py:539] Total number of evals: 11
I0822 19:21:39.285830 140539023103808 submission_runner.py:540] ====================
I0822 19:21:39.285936 140539023103808 submission_runner.py:608] Final fastmri score: 885.9392790794373
