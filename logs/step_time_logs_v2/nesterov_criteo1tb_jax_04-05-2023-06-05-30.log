I0405 06:05:49.644314 139874217699136 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_nesterov_v2/criteo1tb_jax.
I0405 06:05:50.015184 139874217699136 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0405 06:05:50.926920 139874217699136 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0405 06:05:50.927585 139874217699136 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0405 06:05:50.933180 139874217699136 submission_runner.py:511] Using RNG seed 2916238483
I0405 06:05:53.312476 139874217699136 submission_runner.py:520] --- Tuning run 1/1 ---
I0405 06:05:53.312661 139874217699136 submission_runner.py:525] Creating tuning directory at /experiment_runs/timing_nesterov_v2/criteo1tb_jax/trial_1.
I0405 06:05:53.312829 139874217699136 logger_utils.py:84] Saving hparams to /experiment_runs/timing_nesterov_v2/criteo1tb_jax/trial_1/hparams.json.
I0405 06:05:53.439301 139874217699136 submission_runner.py:230] Starting train once: RAM USED (GB) 4.095164416
I0405 06:05:53.439468 139874217699136 submission_runner.py:231] Initializing dataset.
I0405 06:05:53.439648 139874217699136 submission_runner.py:239] After Initializing dataset: RAM USED (GB) 4.095164416
I0405 06:05:53.439707 139874217699136 submission_runner.py:240] Initializing model.
I0405 06:05:59.436036 139874217699136 submission_runner.py:251] After Initializing model: RAM USED (GB) 7.89024768
I0405 06:05:59.436269 139874217699136 submission_runner.py:252] Initializing optimizer.
I0405 06:06:01.244638 139874217699136 submission_runner.py:260] After Initializing metrics bundle: RAM USED (GB) 7.89368832
I0405 06:06:01.244826 139874217699136 submission_runner.py:261] Initializing metrics bundle.
I0405 06:06:01.244883 139874217699136 submission_runner.py:276] Initializing checkpoint and logger.
I0405 06:06:01.245876 139874217699136 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_nesterov_v2/criteo1tb_jax/trial_1 with prefix checkpoint_
I0405 06:06:01.246191 139874217699136 logger_utils.py:231] Unable to record workload.train_mean information. Continuing without it.
I0405 06:06:01.246304 139874217699136 logger_utils.py:231] Unable to record workload.train_stddev information. Continuing without it.
I0405 06:06:02.154820 139874217699136 submission_runner.py:297] Saving meta data to /experiment_runs/timing_nesterov_v2/criteo1tb_jax/trial_1/meta_data_0.json.
I0405 06:06:02.155862 139874217699136 submission_runner.py:300] Saving flags to /experiment_runs/timing_nesterov_v2/criteo1tb_jax/trial_1/flags_0.json.
I0405 06:06:02.205180 139874217699136 submission_runner.py:305] After checkpoint and logger metrics bundle: RAM USED (GB) 7.93710592
I0405 06:06:02.205423 139874217699136 submission_runner.py:312] Before starting training loop and logger metrics bundle: RAM USED (GB) 7.93710592
I0405 06:06:02.205490 139874217699136 submission_runner.py:313] Starting training loop.
I0405 06:08:32.031198 139874217699136 submission_runner.py:335] After dataselection batch at step 0: RAM USED (GB) 46.11887104
I0405 06:08:54.095155 139667992205056 logging_writer.py:48] [0] global_step=0, grad_norm=6.972488880157471, loss=0.7668090462684631
I0405 06:08:54.122006 139874217699136 submission_runner.py:352] After update parameters step 0: RAM USED (GB) 53.98921216
I0405 06:08:54.122273 139874217699136 submission_runner.py:373] Before eval at step 1: RAM USED (GB) 53.98921216
I0405 06:08:54.122356 139874217699136 spec.py:298] Evaluating on the training split.
I0405 06:18:43.081843 139874217699136 spec.py:310] Evaluating on the validation split.
I0405 06:23:01.162619 139874217699136 spec.py:326] Evaluating on the test split.
I0405 06:28:08.284182 139874217699136 submission_runner.py:382] Time since start: 171.92s, 	Step: 1, 	{'train/loss': 0.7669004057153698, 'validation/loss': 0.7667492134831461, 'validation/num_examples': 89000000, 'test/loss': 0.7672621284363217, 'test/num_examples': 89274637}
I0405 06:28:08.285072 139874217699136 submission_runner.py:396] After eval at step 1: RAM USED (GB) 95.847170048
I0405 06:28:08.295486 139611719358208 logging_writer.py:48] [1] global_step=1, preemption_count=0, score=171.722384, test/loss=0.767262, test/num_examples=89274637, total_duration=171.916818, train/loss=0.766900, validation/loss=0.766749, validation/num_examples=89000000
I0405 06:28:12.485777 139874217699136 checkpoints.py:356] Saving checkpoint at step: 1
I0405 06:28:36.767910 139874217699136 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nesterov_v2/criteo1tb_jax/trial_1/checkpoint_1
I0405 06:28:37.123422 139874217699136 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nesterov_v2/criteo1tb_jax/trial_1/checkpoint_1.
I0405 06:28:37.478480 139874217699136 submission_runner.py:416] After logging and checkpointing eval at step 1: RAM USED (GB) 95.820587008
I0405 06:28:37.481459 139874217699136 submission_runner.py:335] After dataselection batch at step 1: RAM USED (GB) 95.779483648
I0405 06:28:37.519006 139874217699136 submission_runner.py:352] After update parameters step 1: RAM USED (GB) 95.7794304
I0405 06:30:08.136058 139611710965504 logging_writer.py:48] [100] global_step=100, grad_norm=0.01785571314394474, loss=0.13783210515975952
I0405 06:32:03.370065 139611602941696 logging_writer.py:48] [200] global_step=200, grad_norm=0.012225056067109108, loss=0.1369653195142746
I0405 06:34:00.355405 139611710965504 logging_writer.py:48] [300] global_step=300, grad_norm=0.014903114177286625, loss=0.13610240817070007
I0405 06:36:08.783655 139611602941696 logging_writer.py:48] [400] global_step=400, grad_norm=0.013397794216871262, loss=0.1361004114151001
I0405 06:37:37.901688 139874217699136 submission_runner.py:373] Before eval at step 475: RAM USED (GB) 104.267378688
I0405 06:37:37.901874 139874217699136 spec.py:298] Evaluating on the training split.
I0405 06:48:38.490938 139874217699136 spec.py:310] Evaluating on the validation split.
I0405 06:52:25.825644 139874217699136 spec.py:326] Evaluating on the test split.
I0405 06:56:40.029306 139874217699136 submission_runner.py:382] Time since start: 1895.70s, 	Step: 475, 	{'train/loss': 0.13657993880855063, 'validation/loss': 0.13681086516853933, 'validation/num_examples': 89000000, 'test/loss': 0.14015976340514272, 'test/num_examples': 89274637}
I0405 06:56:40.029925 139874217699136 submission_runner.py:396] After eval at step 475: RAM USED (GB) 109.729898496
I0405 06:56:40.037645 139611710965504 logging_writer.py:48] [475] global_step=475, preemption_count=0, score=710.290524, test/loss=0.140160, test/num_examples=89274637, total_duration=1895.695995, train/loss=0.136580, validation/loss=0.136811, validation/num_examples=89000000
I0405 06:56:44.994469 139874217699136 checkpoints.py:356] Saving checkpoint at step: 475
I0405 06:57:13.863864 139874217699136 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nesterov_v2/criteo1tb_jax/trial_1/checkpoint_475
I0405 06:57:14.209576 139874217699136 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nesterov_v2/criteo1tb_jax/trial_1/checkpoint_475.
I0405 06:57:14.558738 139874217699136 submission_runner.py:416] After logging and checkpointing eval at step 475: RAM USED (GB) 109.808689152
I0405 06:57:17.126990 139611602941696 logging_writer.py:48] [500] global_step=500, grad_norm=0.009373941458761692, loss=0.1373353749513626
I0405 06:59:23.167340 139667044288256 logging_writer.py:48] [600] global_step=600, grad_norm=0.030483093112707138, loss=0.13779260218143463
I0405 07:01:27.944673 139611602941696 logging_writer.py:48] [700] global_step=700, grad_norm=0.07252543419599533, loss=0.1382715106010437
I0405 07:03:23.460027 139874217699136 submission_runner.py:373] Before eval at step 800: RAM USED (GB) 110.292881408
I0405 07:03:23.460215 139874217699136 spec.py:298] Evaluating on the training split.
I0405 07:14:20.359094 139874217699136 spec.py:310] Evaluating on the validation split.
I0405 07:18:12.932165 139874217699136 spec.py:326] Evaluating on the test split.
I0405 07:23:09.503401 139874217699136 submission_runner.py:382] Time since start: 3441.25s, 	Step: 800, 	{'train/loss': 0.1341252386613836, 'validation/loss': 0.13454968539325843, 'validation/num_examples': 89000000, 'test/loss': 0.13776608243167654, 'test/num_examples': 89274637}
I0405 07:23:09.503913 139874217699136 submission_runner.py:396] After eval at step 800: RAM USED (GB) 113.506476032
I0405 07:23:09.511140 139611586156288 logging_writer.py:48] [800] global_step=800, preemption_count=0, score=1077.160071, test/loss=0.137766, test/num_examples=89274637, total_duration=3441.254342, train/loss=0.134125, validation/loss=0.134550, validation/num_examples=89000000
I0405 07:23:14.337288 139874217699136 checkpoints.py:356] Saving checkpoint at step: 800
I0405 07:23:42.585239 139874217699136 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nesterov_v2/criteo1tb_jax/trial_1/checkpoint_800
I0405 07:23:42.918301 139874217699136 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nesterov_v2/criteo1tb_jax/trial_1/checkpoint_800.
I0405 07:23:43.253416 139874217699136 submission_runner.py:416] After logging and checkpointing eval at step 800: RAM USED (GB) 113.544429568
I0405 07:23:43.260214 139611577763584 logging_writer.py:48] [800] global_step=800, preemption_count=0, score=1077.160071
I0405 07:23:48.067256 139874217699136 checkpoints.py:356] Saving checkpoint at step: 800
I0405 07:24:22.914724 139874217699136 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nesterov_v2/criteo1tb_jax/trial_1/checkpoint_800
I0405 07:24:23.252652 139874217699136 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nesterov_v2/criteo1tb_jax/trial_1/checkpoint_800.
I0405 07:26:16.974651 139874217699136 submission_runner.py:550] Tuning trial 1/1
I0405 07:26:16.974930 139874217699136 submission_runner.py:551] Hyperparameters: Hyperparameters(learning_rate=0.4394877561366806, one_minus_beta1=0.07113602458522507, warmup_factor=0.05, weight_decay=9.611851572925426e-07, label_smoothing=0.2, dropout_rate=0.0, decay_steps_factor=0.9, end_factor=0.001)
I0405 07:26:16.975967 139874217699136 submission_runner.py:552] Metrics: {'eval_results': [(1, {'train/loss': 0.7669004057153698, 'validation/loss': 0.7667492134831461, 'validation/num_examples': 89000000, 'test/loss': 0.7672621284363217, 'test/num_examples': 89274637, 'score': 171.7223837375641, 'total_duration': 171.91681814193726, 'global_step': 1, 'preemption_count': 0}), (475, {'train/loss': 0.13657993880855063, 'validation/loss': 0.13681086516853933, 'validation/num_examples': 89000000, 'test/loss': 0.14015976340514272, 'test/num_examples': 89274637, 'score': 710.2905242443085, 'total_duration': 1895.6959946155548, 'global_step': 475, 'preemption_count': 0}), (800, {'train/loss': 0.1341252386613836, 'validation/loss': 0.13454968539325843, 'validation/num_examples': 89000000, 'test/loss': 0.13776608243167654, 'test/num_examples': 89274637, 'score': 1077.1600711345673, 'total_duration': 3441.2543416023254, 'global_step': 800, 'preemption_count': 0})], 'global_step': 800}
I0405 07:26:16.976271 139874217699136 submission_runner.py:553] Timing: 1077.1600711345673
I0405 07:26:16.976340 139874217699136 submission_runner.py:554] ====================
I0405 07:26:16.976466 139874217699136 submission_runner.py:613] Final criteo1tb score: 1077.1600711345673
