I0404 21:34:04.236424 140191069685568 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_adamw_v2/fastmri_jax.
I0404 21:34:04.611502 140191069685568 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0404 21:34:05.455701 140191069685568 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0404 21:34:05.456298 140191069685568 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0404 21:34:05.460883 140191069685568 submission_runner.py:511] Using RNG seed 853278453
I0404 21:34:08.129909 140191069685568 submission_runner.py:520] --- Tuning run 1/1 ---
I0404 21:34:08.130121 140191069685568 submission_runner.py:525] Creating tuning directory at /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1.
I0404 21:34:08.130285 140191069685568 logger_utils.py:84] Saving hparams to /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/hparams.json.
I0404 21:34:08.257559 140191069685568 submission_runner.py:230] Starting train once: RAM USED (GB) 4.242296832
I0404 21:34:08.257722 140191069685568 submission_runner.py:231] Initializing dataset.
I0404 21:34:11.998685 140191069685568 submission_runner.py:239] After Initializing dataset: RAM USED (GB) 4.326588416
I0404 21:34:11.998865 140191069685568 submission_runner.py:240] Initializing model.
I0404 21:34:18.692833 140191069685568 submission_runner.py:251] After Initializing model: RAM USED (GB) 8.305119232
I0404 21:34:18.693050 140191069685568 submission_runner.py:252] Initializing optimizer.
I0404 21:34:19.146888 140191069685568 submission_runner.py:260] After Initializing metrics bundle: RAM USED (GB) 8.305098752
I0404 21:34:19.147047 140191069685568 submission_runner.py:261] Initializing metrics bundle.
I0404 21:34:19.147094 140191069685568 submission_runner.py:276] Initializing checkpoint and logger.
I0404 21:34:19.148058 140191069685568 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1 with prefix checkpoint_
I0404 21:34:19.148292 140191069685568 logger_utils.py:231] Unable to record workload.train_mean information. Continuing without it.
I0404 21:34:19.148353 140191069685568 logger_utils.py:231] Unable to record workload.train_stddev information. Continuing without it.
I0404 21:34:20.071361 140191069685568 submission_runner.py:297] Saving meta data to /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/meta_data_0.json.
I0404 21:34:20.072318 140191069685568 submission_runner.py:300] Saving flags to /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/flags_0.json.
I0404 21:34:20.077190 140191069685568 submission_runner.py:305] After checkpoint and logger metrics bundle: RAM USED (GB) 8.300896256
I0404 21:34:20.077393 140191069685568 submission_runner.py:312] Before starting training loop and logger metrics bundle: RAM USED (GB) 8.300896256
I0404 21:34:20.077472 140191069685568 submission_runner.py:313] Starting training loop.
I0404 21:34:58.918591 140191069685568 submission_runner.py:335] After dataselection batch at step 0: RAM USED (GB) 16.77643776
I0404 21:35:24.660936 140015019484928 logging_writer.py:48] [0] global_step=0, grad_norm=5.790983200073242, loss=1.2057262659072876
I0404 21:35:24.669502 140191069685568 submission_runner.py:352] After update parameters step 0: RAM USED (GB) 23.16232704
I0404 21:35:24.669816 140191069685568 submission_runner.py:373] Before eval at step 1: RAM USED (GB) 23.16232704
I0404 21:35:24.669914 140191069685568 spec.py:298] Evaluating on the training split.
I0404 21:36:52.154281 140191069685568 spec.py:310] Evaluating on the validation split.
I0404 21:37:55.091194 140191069685568 spec.py:326] Evaluating on the test split.
I0404 21:38:53.245243 140191069685568 submission_runner.py:382] Time since start: 64.59s, 	Step: 1, 	{'train/ssim': 0.17149945667811803, 'train/loss': 1.1992361886160714, 'validation/ssim': 0.164992161258661, 'validation/loss': 1.1959920270294035, 'validation/num_examples': 3554, 'test/ssim': 0.18802826686199733, 'test/loss': 1.1930955313198128, 'test/num_examples': 3581}
I0404 21:38:53.245806 140191069685568 submission_runner.py:396] After eval at step 1: RAM USED (GB) 58.220691456
I0404 21:38:53.254157 139986766636800 logging_writer.py:48] [1] global_step=1, preemption_count=0, score=64.463842, test/loss=1.193096, test/num_examples=3581, test/ssim=0.188028, total_duration=64.592381, train/loss=1.199236, train/ssim=0.171499, validation/loss=1.195992, validation/num_examples=3554, validation/ssim=0.164992
I0404 21:38:53.291219 140191069685568 checkpoints.py:356] Saving checkpoint at step: 1
I0404 21:38:53.513499 140191069685568 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_1
I0404 21:38:53.514213 140191069685568 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_1.
I0404 21:38:53.514930 140191069685568 submission_runner.py:416] After logging and checkpointing eval at step 1: RAM USED (GB) 58.233024512
I0404 21:38:53.517066 140191069685568 submission_runner.py:335] After dataselection batch at step 1: RAM USED (GB) 58.233024512
I0404 21:38:53.535574 140191069685568 submission_runner.py:352] After update parameters step 1: RAM USED (GB) 58.27069952
I0404 21:39:15.084910 139986758244096 logging_writer.py:48] [100] global_step=100, grad_norm=0.2562030553817749, loss=0.3456641733646393
I0404 21:39:39.151470 139986649204480 logging_writer.py:48] [200] global_step=200, grad_norm=0.20112410187721252, loss=0.365007221698761
I0404 21:40:03.003548 139986758244096 logging_writer.py:48] [300] global_step=300, grad_norm=0.36817920207977295, loss=0.3548407554626465
I0404 21:40:13.725810 140191069685568 submission_runner.py:373] Before eval at step 332: RAM USED (GB) 81.021267968
I0404 21:40:13.725991 140191069685568 spec.py:298] Evaluating on the training split.
I0404 21:40:15.569213 140191069685568 spec.py:310] Evaluating on the validation split.
I0404 21:40:16.928695 140191069685568 spec.py:326] Evaluating on the test split.
I0404 21:40:18.284399 140191069685568 submission_runner.py:382] Time since start: 353.65s, 	Step: 332, 	{'train/ssim': 0.7016995974949428, 'train/loss': 0.30703204018729074, 'validation/ssim': 0.6802226309703855, 'validation/loss': 0.32393267131884845, 'validation/num_examples': 3554, 'test/ssim': 0.6984961455642628, 'test/loss': 0.32560450882260544, 'test/num_examples': 3581}
I0404 21:40:18.284890 140191069685568 submission_runner.py:396] After eval at step 332: RAM USED (GB) 82.091462656
I0404 21:40:18.294014 139986649204480 logging_writer.py:48] [332] global_step=332, preemption_count=0, score=144.219242, test/loss=0.325605, test/num_examples=3581, test/ssim=0.698496, total_duration=353.648120, train/loss=0.307032, train/ssim=0.701700, validation/loss=0.323933, validation/num_examples=3554, validation/ssim=0.680223
I0404 21:40:18.379156 140191069685568 checkpoints.py:356] Saving checkpoint at step: 332
I0404 21:40:18.623443 140191069685568 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_332
I0404 21:40:18.624107 140191069685568 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_332.
I0404 21:40:18.626011 140191069685568 submission_runner.py:416] After logging and checkpointing eval at step 332: RAM USED (GB) 82.197929984
I0404 21:40:38.828236 139986758244096 logging_writer.py:48] [400] global_step=400, grad_norm=0.4906749427318573, loss=0.37347960472106934
I0404 21:41:14.817807 139986640811776 logging_writer.py:48] [500] global_step=500, grad_norm=0.5057055950164795, loss=0.3119320273399353
I0404 21:41:38.965436 140191069685568 submission_runner.py:373] Before eval at step 570: RAM USED (GB) 100.689461248
I0404 21:41:38.965761 140191069685568 spec.py:298] Evaluating on the training split.
I0404 21:41:40.371863 140191069685568 spec.py:310] Evaluating on the validation split.
I0404 21:41:41.727887 140191069685568 spec.py:326] Evaluating on the test split.
I0404 21:41:43.083559 140191069685568 submission_runner.py:382] Time since start: 438.89s, 	Step: 570, 	{'train/ssim': 0.7139105796813965, 'train/loss': 0.2946040630340576, 'validation/ssim': 0.6945511576964336, 'validation/loss': 0.31043692928522437, 'validation/num_examples': 3554, 'test/ssim': 0.711885155595504, 'test/loss': 0.3123422732935109, 'test/num_examples': 3581}
I0404 21:41:43.084282 140191069685568 submission_runner.py:396] After eval at step 570: RAM USED (GB) 101.768871936
I0404 21:41:43.095349 139986758244096 logging_writer.py:48] [570] global_step=570, preemption_count=0, score=224.226448, test/loss=0.312342, test/num_examples=3581, test/ssim=0.711885, total_duration=438.887321, train/loss=0.294604, train/ssim=0.713911, validation/loss=0.310437, validation/num_examples=3554, validation/ssim=0.694551
I0404 21:41:43.172530 140191069685568 checkpoints.py:356] Saving checkpoint at step: 570
I0404 21:41:43.428909 140191069685568 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_570
I0404 21:41:43.429538 140191069685568 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_570.
I0404 21:41:43.430301 140191069685568 submission_runner.py:416] After logging and checkpointing eval at step 570: RAM USED (GB) 101.916966912
I0404 21:41:49.629680 139986640811776 logging_writer.py:48] [600] global_step=600, grad_norm=0.24379730224609375, loss=0.3165689706802368
I0404 21:42:25.968078 139980827518720 logging_writer.py:48] [700] global_step=700, grad_norm=0.33063650131225586, loss=0.29305875301361084
I0404 21:43:01.156128 139986640811776 logging_writer.py:48] [800] global_step=800, grad_norm=0.140179842710495, loss=0.25028905272483826
I0404 21:43:03.552779 140191069685568 submission_runner.py:373] Before eval at step 809: RAM USED (GB) 120.318980096
I0404 21:43:03.552957 140191069685568 spec.py:298] Evaluating on the training split.
I0404 21:43:04.960737 140191069685568 spec.py:310] Evaluating on the validation split.
I0404 21:43:10.050702 140191069685568 spec.py:326] Evaluating on the test split.
I0404 21:43:11.409367 140191069685568 submission_runner.py:382] Time since start: 523.47s, 	Step: 809, 	{'train/ssim': 0.7240830148969378, 'train/loss': 0.2876413549695696, 'validation/ssim': 0.7031299460115363, 'validation/loss': 0.3035639310460045, 'validation/num_examples': 3554, 'test/ssim': 0.7203220856386136, 'test/loss': 0.30579745013831683, 'test/num_examples': 3581}
I0404 21:43:11.409871 140191069685568 submission_runner.py:396] After eval at step 809: RAM USED (GB) 121.181659136
I0404 21:43:11.419688 139980827518720 logging_writer.py:48] [809] global_step=809, preemption_count=0, score=304.013840, test/loss=0.305797, test/num_examples=3581, test/ssim=0.720322, total_duration=523.474969, train/loss=0.287641, train/ssim=0.724083, validation/loss=0.303564, validation/num_examples=3554, validation/ssim=0.703130
I0404 21:43:11.505015 140191069685568 checkpoints.py:356] Saving checkpoint at step: 809
I0404 21:43:11.747814 140191069685568 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_809
I0404 21:43:11.748391 140191069685568 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_809.
I0404 21:43:11.749740 140191069685568 submission_runner.py:416] After logging and checkpointing eval at step 809: RAM USED (GB) 121.334882304
I0404 21:43:41.656272 139986640811776 logging_writer.py:48] [900] global_step=900, grad_norm=0.29748621582984924, loss=0.3066108822822571
I0404 21:44:12.758992 139953925256960 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.4668583869934082, loss=0.3134310245513916
I0404 21:44:31.854843 140191069685568 submission_runner.py:373] Before eval at step 1082: RAM USED (GB) 135.894470656
I0404 21:44:31.855057 140191069685568 spec.py:298] Evaluating on the training split.
I0404 21:44:33.265408 140191069685568 spec.py:310] Evaluating on the validation split.
I0404 21:44:35.086404 140191069685568 spec.py:326] Evaluating on the test split.
I0404 21:44:36.437987 140191069685568 submission_runner.py:382] Time since start: 611.78s, 	Step: 1082, 	{'train/ssim': 0.7277802739824567, 'train/loss': 0.28484627178737093, 'validation/ssim': 0.7066135868036015, 'validation/loss': 0.30105637189170653, 'validation/num_examples': 3554, 'test/ssim': 0.7237287370627967, 'test/loss': 0.3031077444869624, 'test/num_examples': 3581}
I0404 21:44:36.438877 140191069685568 submission_runner.py:396] After eval at step 1082: RAM USED (GB) 136.07809024
I0404 21:44:36.448086 139986640811776 logging_writer.py:48] [1082] global_step=1082, preemption_count=0, score=383.767560, test/loss=0.303108, test/num_examples=3581, test/ssim=0.723729, total_duration=611.777125, train/loss=0.284846, train/ssim=0.727780, validation/loss=0.301056, validation/num_examples=3554, validation/ssim=0.706614
I0404 21:44:36.514368 140191069685568 checkpoints.py:356] Saving checkpoint at step: 1082
I0404 21:44:36.798431 140191069685568 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_1082
I0404 21:44:36.801446 140191069685568 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_1082.
I0404 21:44:36.802375 140191069685568 submission_runner.py:416] After logging and checkpointing eval at step 1082: RAM USED (GB) 136.1956864
I0404 21:44:39.061881 139953925256960 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.2598569691181183, loss=0.22511263191699982
I0404 21:45:02.563979 139937233209088 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.12286897003650665, loss=0.2822031080722809
I0404 21:45:26.478487 139953925256960 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.39412346482276917, loss=0.29787677526474
I0404 21:45:50.279300 139937233209088 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.3239307701587677, loss=0.26780757308006287
I0404 21:45:57.025110 140191069685568 submission_runner.py:373] Before eval at step 1430: RAM USED (GB) 136.36712448
I0404 21:45:57.025309 140191069685568 spec.py:298] Evaluating on the training split.
I0404 21:45:58.435062 140191069685568 spec.py:310] Evaluating on the validation split.
I0404 21:45:59.848874 140191069685568 spec.py:326] Evaluating on the test split.
I0404 21:46:01.206462 140191069685568 submission_runner.py:382] Time since start: 696.95s, 	Step: 1430, 	{'train/ssim': 0.7315491948808942, 'train/loss': 0.28182922090802875, 'validation/ssim': 0.7103291405810355, 'validation/loss': 0.29804140004000773, 'validation/num_examples': 3554, 'test/ssim': 0.7274328432613096, 'test/loss': 0.2999807537284453, 'test/num_examples': 3581}
I0404 21:46:01.207386 140191069685568 submission_runner.py:396] After eval at step 1430: RAM USED (GB) 136.364376064
I0404 21:46:01.215745 139953925256960 logging_writer.py:48] [1430] global_step=1430, preemption_count=0, score=463.628472, test/loss=0.299981, test/num_examples=3581, test/ssim=0.727433, total_duration=696.947408, train/loss=0.281829, train/ssim=0.731549, validation/loss=0.298041, validation/num_examples=3554, validation/ssim=0.710329
I0404 21:46:01.249412 140191069685568 checkpoints.py:356] Saving checkpoint at step: 1430
I0404 21:46:01.483098 140191069685568 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_1430
I0404 21:46:01.483734 140191069685568 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_1430.
I0404 21:46:01.484775 140191069685568 submission_runner.py:416] After logging and checkpointing eval at step 1430: RAM USED (GB) 136.399241216
I0404 21:46:15.872054 139937233209088 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.16181552410125732, loss=0.3131425380706787
I0404 21:46:39.744964 139937500337920 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.23084311187267303, loss=0.20476891100406647
I0404 21:47:03.554732 139937233209088 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.11207684129476547, loss=0.38313111662864685
I0404 21:47:21.614318 140191069685568 submission_runner.py:373] Before eval at step 1778: RAM USED (GB) 136.437813248
I0404 21:47:21.614537 140191069685568 spec.py:298] Evaluating on the training split.
I0404 21:47:23.026956 140191069685568 spec.py:310] Evaluating on the validation split.
I0404 21:47:24.384639 140191069685568 spec.py:326] Evaluating on the test split.
I0404 21:47:25.739776 140191069685568 submission_runner.py:382] Time since start: 781.54s, 	Step: 1778, 	{'train/ssim': 0.7267609323774066, 'train/loss': 0.28649609429495676, 'validation/ssim': 0.7061964044694359, 'validation/loss': 0.302717991336786, 'validation/num_examples': 3554, 'test/ssim': 0.7231066932028414, 'test/loss': 0.3045604527912071, 'test/num_examples': 3581}
I0404 21:47:25.740412 140191069685568 submission_runner.py:396] After eval at step 1778: RAM USED (GB) 136.43692032
I0404 21:47:25.747873 139937500337920 logging_writer.py:48] [1778] global_step=1778, preemption_count=0, score=543.397993, test/loss=0.304560, test/num_examples=3581, test/ssim=0.723107, total_duration=781.536669, train/loss=0.286496, train/ssim=0.726761, validation/loss=0.302718, validation/num_examples=3554, validation/ssim=0.706196
I0404 21:47:25.781600 140191069685568 checkpoints.py:356] Saving checkpoint at step: 1778
I0404 21:47:26.033254 140191069685568 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_1778
I0404 21:47:26.033761 140191069685568 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_1778.
I0404 21:47:26.034581 140191069685568 submission_runner.py:416] After logging and checkpointing eval at step 1778: RAM USED (GB) 136.439484416
I0404 21:47:29.179263 139937233209088 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.28166520595550537, loss=0.2547879219055176
I0404 21:47:52.811573 139937013823232 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.1937599778175354, loss=0.2687300741672516
I0404 21:48:16.456557 139937233209088 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.31336236000061035, loss=0.2393721342086792
I0404 21:48:40.602761 139937013823232 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.15177564322948456, loss=0.26833575963974
I0404 21:48:46.155865 140191069685568 submission_runner.py:373] Before eval at step 2125: RAM USED (GB) 136.469454848
I0404 21:48:46.156051 140191069685568 spec.py:298] Evaluating on the training split.
I0404 21:48:47.567972 140191069685568 spec.py:310] Evaluating on the validation split.
I0404 21:48:48.925005 140191069685568 spec.py:326] Evaluating on the test split.
I0404 21:48:50.284779 140191069685568 submission_runner.py:382] Time since start: 866.08s, 	Step: 2125, 	{'train/ssim': 0.7381272997174945, 'train/loss': 0.27748782294137136, 'validation/ssim': 0.7169212122344542, 'validation/loss': 0.2941051304977666, 'validation/num_examples': 3554, 'test/ssim': 0.7338070884093131, 'test/loss': 0.29596467112669295, 'test/num_examples': 3581}
I0404 21:48:50.285438 140191069685568 submission_runner.py:396] After eval at step 2125: RAM USED (GB) 136.470028288
I0404 21:48:50.293086 139937233209088 logging_writer.py:48] [2125] global_step=2125, preemption_count=0, score=623.161425, test/loss=0.295965, test/num_examples=3581, test/ssim=0.733807, total_duration=866.078095, train/loss=0.277488, train/ssim=0.738127, validation/loss=0.294105, validation/num_examples=3554, validation/ssim=0.716921
I0404 21:48:50.327768 140191069685568 checkpoints.py:356] Saving checkpoint at step: 2125
I0404 21:48:50.576200 140191069685568 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_2125
I0404 21:48:50.576697 140191069685568 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_2125.
I0404 21:48:50.577514 140191069685568 submission_runner.py:416] After logging and checkpointing eval at step 2125: RAM USED (GB) 136.471011328
I0404 21:49:06.448580 139937013823232 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.5847814679145813, loss=0.24525940418243408
I0404 21:49:30.179731 139937110091520 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.06398829072713852, loss=0.3086116909980774
I0404 21:49:53.586724 139937013823232 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.17019256949424744, loss=0.26891666650772095
I0404 21:50:10.687934 140191069685568 submission_runner.py:373] Before eval at step 2474: RAM USED (GB) 136.485576704
I0404 21:50:10.688119 140191069685568 spec.py:298] Evaluating on the training split.
I0404 21:50:12.099082 140191069685568 spec.py:310] Evaluating on the validation split.
I0404 21:50:13.456847 140191069685568 spec.py:326] Evaluating on the test split.
I0404 21:50:14.817540 140191069685568 submission_runner.py:382] Time since start: 950.61s, 	Step: 2474, 	{'train/ssim': 0.7387537275041852, 'train/loss': 0.2757133756365095, 'validation/ssim': 0.7175915341868317, 'validation/loss': 0.2923815828665764, 'validation/num_examples': 3554, 'test/ssim': 0.7346547970189891, 'test/loss': 0.2940741663903239, 'test/num_examples': 3581}
I0404 21:50:14.818244 140191069685568 submission_runner.py:396] After eval at step 2474: RAM USED (GB) 136.485609472
I0404 21:50:14.826210 139937110091520 logging_writer.py:48] [2474] global_step=2474, preemption_count=0, score=702.910905, test/loss=0.294074, test/num_examples=3581, test/ssim=0.734655, total_duration=950.610202, train/loss=0.275713, train/ssim=0.738754, validation/loss=0.292382, validation/num_examples=3554, validation/ssim=0.717592
I0404 21:50:14.861433 140191069685568 checkpoints.py:356] Saving checkpoint at step: 2474
I0404 21:50:15.109840 140191069685568 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_2474
I0404 21:50:15.110365 140191069685568 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_2474.
I0404 21:50:15.111238 140191069685568 submission_runner.py:416] After logging and checkpointing eval at step 2474: RAM USED (GB) 136.48631808
I0404 21:50:19.101304 139937013823232 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.2918708622455597, loss=0.22256571054458618
I0404 21:50:42.781888 139937005430528 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.12416931986808777, loss=0.3114057779312134
I0404 21:51:06.268842 139937013823232 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.07025563716888428, loss=0.2562604546546936
I0404 21:51:09.306136 140191069685568 submission_runner.py:373] Before eval at step 2714: RAM USED (GB) 136.488390656
I0404 21:51:09.306354 140191069685568 spec.py:298] Evaluating on the training split.
I0404 21:51:10.715738 140191069685568 spec.py:310] Evaluating on the validation split.
I0404 21:51:12.076474 140191069685568 spec.py:326] Evaluating on the test split.
I0404 21:51:13.438047 140191069685568 submission_runner.py:382] Time since start: 1009.23s, 	Step: 2714, 	{'train/ssim': 0.7396608761378697, 'train/loss': 0.275070207459586, 'validation/ssim': 0.7178830053944499, 'validation/loss': 0.2918336403524198, 'validation/num_examples': 3554, 'test/ssim': 0.7349524563233035, 'test/loss': 0.2934940852655508, 'test/num_examples': 3581}
I0404 21:51:13.438678 140191069685568 submission_runner.py:396] After eval at step 2714: RAM USED (GB) 136.493551616
I0404 21:51:13.446219 139937005430528 logging_writer.py:48] [2714] global_step=2714, preemption_count=0, score=756.856753, test/loss=0.293494, test/num_examples=3581, test/ssim=0.734952, total_duration=1009.228497, train/loss=0.275070, train/ssim=0.739661, validation/loss=0.291834, validation/num_examples=3554, validation/ssim=0.717883
I0404 21:51:13.480301 140191069685568 checkpoints.py:356] Saving checkpoint at step: 2714
I0404 21:51:13.724566 140191069685568 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_2714
I0404 21:51:13.725085 140191069685568 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_2714.
I0404 21:51:13.725920 140191069685568 submission_runner.py:416] After logging and checkpointing eval at step 2714: RAM USED (GB) 136.493531136
I0404 21:51:13.732611 139937013823232 logging_writer.py:48] [2714] global_step=2714, preemption_count=0, score=756.856753
I0404 21:51:13.762434 140191069685568 checkpoints.py:356] Saving checkpoint at step: 2714
I0404 21:51:14.087271 140191069685568 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_2714
I0404 21:51:14.087758 140191069685568 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw_v2/fastmri_jax/trial_1/checkpoint_2714.
I0404 21:51:14.926144 140191069685568 submission_runner.py:550] Tuning trial 1/1
I0404 21:51:14.926361 140191069685568 submission_runner.py:551] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0404 21:51:14.932301 140191069685568 submission_runner.py:552] Metrics: {'eval_results': [(1, {'train/ssim': 0.17149945667811803, 'train/loss': 1.1992361886160714, 'validation/ssim': 0.164992161258661, 'validation/loss': 1.1959920270294035, 'validation/num_examples': 3554, 'test/ssim': 0.18802826686199733, 'test/loss': 1.1930955313198128, 'test/num_examples': 3581, 'score': 64.4638421535492, 'total_duration': 64.5923810005188, 'global_step': 1, 'preemption_count': 0}), (332, {'train/ssim': 0.7016995974949428, 'train/loss': 0.30703204018729074, 'validation/ssim': 0.6802226309703855, 'validation/loss': 0.32393267131884845, 'validation/num_examples': 3554, 'test/ssim': 0.6984961455642628, 'test/loss': 0.32560450882260544, 'test/num_examples': 3581, 'score': 144.2192418575287, 'total_duration': 353.64811992645264, 'global_step': 332, 'preemption_count': 0}), (570, {'train/ssim': 0.7139105796813965, 'train/loss': 0.2946040630340576, 'validation/ssim': 0.6945511576964336, 'validation/loss': 0.31043692928522437, 'validation/num_examples': 3554, 'test/ssim': 0.711885155595504, 'test/loss': 0.3123422732935109, 'test/num_examples': 3581, 'score': 224.22644782066345, 'total_duration': 438.8873212337494, 'global_step': 570, 'preemption_count': 0}), (809, {'train/ssim': 0.7240830148969378, 'train/loss': 0.2876413549695696, 'validation/ssim': 0.7031299460115363, 'validation/loss': 0.3035639310460045, 'validation/num_examples': 3554, 'test/ssim': 0.7203220856386136, 'test/loss': 0.30579745013831683, 'test/num_examples': 3581, 'score': 304.01383996009827, 'total_duration': 523.4749689102173, 'global_step': 809, 'preemption_count': 0}), (1082, {'train/ssim': 0.7277802739824567, 'train/loss': 0.28484627178737093, 'validation/ssim': 0.7066135868036015, 'validation/loss': 0.30105637189170653, 'validation/num_examples': 3554, 'test/ssim': 0.7237287370627967, 'test/loss': 0.3031077444869624, 'test/num_examples': 3581, 'score': 383.7675597667694, 'total_duration': 611.7771246433258, 'global_step': 1082, 'preemption_count': 0}), (1430, {'train/ssim': 0.7315491948808942, 'train/loss': 0.28182922090802875, 'validation/ssim': 0.7103291405810355, 'validation/loss': 0.29804140004000773, 'validation/num_examples': 3554, 'test/ssim': 0.7274328432613096, 'test/loss': 0.2999807537284453, 'test/num_examples': 3581, 'score': 463.6284716129303, 'total_duration': 696.9474081993103, 'global_step': 1430, 'preemption_count': 0}), (1778, {'train/ssim': 0.7267609323774066, 'train/loss': 0.28649609429495676, 'validation/ssim': 0.7061964044694359, 'validation/loss': 0.302717991336786, 'validation/num_examples': 3554, 'test/ssim': 0.7231066932028414, 'test/loss': 0.3045604527912071, 'test/num_examples': 3581, 'score': 543.39799284935, 'total_duration': 781.5366687774658, 'global_step': 1778, 'preemption_count': 0}), (2125, {'train/ssim': 0.7381272997174945, 'train/loss': 0.27748782294137136, 'validation/ssim': 0.7169212122344542, 'validation/loss': 0.2941051304977666, 'validation/num_examples': 3554, 'test/ssim': 0.7338070884093131, 'test/loss': 0.29596467112669295, 'test/num_examples': 3581, 'score': 623.1614253520966, 'total_duration': 866.0780947208405, 'global_step': 2125, 'preemption_count': 0}), (2474, {'train/ssim': 0.7387537275041852, 'train/loss': 0.2757133756365095, 'validation/ssim': 0.7175915341868317, 'validation/loss': 0.2923815828665764, 'validation/num_examples': 3554, 'test/ssim': 0.7346547970189891, 'test/loss': 0.2940741663903239, 'test/num_examples': 3581, 'score': 702.9109053611755, 'total_duration': 950.6102015972137, 'global_step': 2474, 'preemption_count': 0}), (2714, {'train/ssim': 0.7396608761378697, 'train/loss': 0.275070207459586, 'validation/ssim': 0.7178830053944499, 'validation/loss': 0.2918336403524198, 'validation/num_examples': 3554, 'test/ssim': 0.7349524563233035, 'test/loss': 0.2934940852655508, 'test/num_examples': 3581, 'score': 756.856752872467, 'total_duration': 1009.2284967899323, 'global_step': 2714, 'preemption_count': 0})], 'global_step': 2714}
I0404 21:51:14.932426 140191069685568 submission_runner.py:553] Timing: 756.856752872467
I0404 21:51:14.932470 140191069685568 submission_runner.py:554] ====================
I0404 21:51:14.932572 140191069685568 submission_runner.py:613] Final fastmri score: 756.856752872467
