WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
I0406 03:15:52.302954 139809586906944 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 7
I0406 03:15:52.302991 140648076261184 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 3
I0406 03:15:52.303013 140006052349760 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 6
I0406 03:15:52.303045 139626954884928 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 4
I0406 03:15:52.304234 139812831323968 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 2
I0406 03:15:52.323179 140394744997696 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 1
I0406 03:15:52.323772 140546912470848 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 5
I0406 03:15:52.324786 140342066173760 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 0
I0406 03:15:52.325096 139812831323968 distributed_c10d.py:353] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 03:15:52.325205 140342066173760 distributed_c10d.py:353] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 03:15:52.333738 140394744997696 distributed_c10d.py:353] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 03:15:52.334037 139809586906944 distributed_c10d.py:353] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 03:15:52.334063 140648076261184 distributed_c10d.py:353] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 03:15:52.334323 140006052349760 distributed_c10d.py:353] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 03:15:52.334360 140546912470848 distributed_c10d.py:353] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 03:15:52.334348 139626954884928 distributed_c10d.py:353] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
W0406 03:15:52.719521 140394744997696 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 03:15:52.719766 139809586906944 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 03:15:52.719944 139812831323968 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 03:15:52.720284 139626954884928 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 03:15:52.720302 140648076261184 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 03:15:52.721070 140006052349760 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 03:15:52.722484 140546912470848 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0406 03:15:52.753188 140342066173760 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_v2/timing_nadamw/librispeech_deepspeech_pytorch.
W0406 03:15:52.785094 140342066173760 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0406 03:15:52.788672 140342066173760 submission_runner.py:511] Using RNG seed 2692958363
I0406 03:15:52.789770 140342066173760 submission_runner.py:520] --- Tuning run 1/1 ---
I0406 03:15:52.789880 140342066173760 submission_runner.py:525] Creating tuning directory at /experiment_runs/timing_v2/timing_nadamw/librispeech_deepspeech_pytorch/trial_1.
I0406 03:15:52.790077 140342066173760 logger_utils.py:84] Saving hparams to /experiment_runs/timing_v2/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/hparams.json.
I0406 03:15:52.791039 140342066173760 submission_runner.py:230] Starting train once: RAM USED (GB) 5.778477056
I0406 03:15:52.791135 140342066173760 submission_runner.py:231] Initializing dataset.
I0406 03:15:52.791218 140342066173760 input_pipeline.py:20] Loading split = train-clean-100
I0406 03:15:52.820617 140342066173760 input_pipeline.py:20] Loading split = train-clean-360
I0406 03:15:53.156813 140342066173760 input_pipeline.py:20] Loading split = train-other-500
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
I0406 03:15:53.567696 140342066173760 submission_runner.py:239] After Initializing dataset: RAM USED (GB) 6.04852224
I0406 03:15:53.567873 140342066173760 submission_runner.py:240] Initializing model.
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
I0406 03:16:00.630736 140342066173760 submission_runner.py:251] After Initializing model: RAM USED (GB) 22.85314048
I0406 03:16:00.630924 140342066173760 submission_runner.py:252] Initializing optimizer.
I0406 03:16:00.631641 140342066173760 submission_runner.py:260] After Initializing metrics bundle: RAM USED (GB) 21.845188608
I0406 03:16:00.631765 140342066173760 submission_runner.py:261] Initializing metrics bundle.
I0406 03:16:00.631818 140342066173760 submission_runner.py:276] Initializing checkpoint and logger.
I0406 03:16:00.633072 140342066173760 logger_utils.py:231] Unable to record workload.train_mean information. Continuing without it.
I0406 03:16:00.633183 140342066173760 logger_utils.py:231] Unable to record workload.train_stddev information. Continuing without it.
I0406 03:16:01.453385 140342066173760 submission_runner.py:297] Saving meta data to /experiment_runs/timing_v2/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/meta_data_0.json.
I0406 03:16:01.454329 140342066173760 submission_runner.py:300] Saving flags to /experiment_runs/timing_v2/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/flags_0.json.
I0406 03:16:01.457627 140342066173760 submission_runner.py:305] After checkpoint and logger metrics bundle: RAM USED (GB) 21.30735104
I0406 03:16:01.458820 140342066173760 submission_runner.py:312] Before starting training loop and logger metrics bundle: RAM USED (GB) 21.308391424
I0406 03:16:01.458924 140342066173760 submission_runner.py:313] Starting training loop.
I0406 03:16:03.870662 140342066173760 submission_runner.py:335] After dataselection batch at step 0: RAM USED (GB) 25.749139456
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
I0406 03:16:10.334567 140315990140672 logging_writer.py:48] [0] global_step=0, grad_norm=20.824129, loss=33.507511
I0406 03:16:10.345318 140342066173760 submission.py:296] 0) loss = 33.508, grad_norm = 20.824
I0406 03:16:10.346182 140342066173760 submission_runner.py:352] After update parameters step 0: RAM USED (GB) 31.513686016
I0406 03:16:10.346854 140342066173760 submission_runner.py:373] Before eval at step 1: RAM USED (GB) 31.513686016
I0406 03:16:10.347007 140342066173760 spec.py:298] Evaluating on the training split.
I0406 03:16:10.347826 140342066173760 input_pipeline.py:20] Loading split = train-clean-100
I0406 03:16:10.378427 140342066173760 input_pipeline.py:20] Loading split = train-clean-360
I0406 03:16:10.820967 140342066173760 input_pipeline.py:20] Loading split = train-other-500
I0406 03:16:27.537855 140342066173760 spec.py:310] Evaluating on the validation split.
I0406 03:16:27.539078 140342066173760 input_pipeline.py:20] Loading split = dev-clean
I0406 03:16:27.542733 140342066173760 input_pipeline.py:20] Loading split = dev-other
I0406 03:16:39.133867 140342066173760 spec.py:326] Evaluating on the test split.
I0406 03:16:39.135061 140342066173760 input_pipeline.py:20] Loading split = test-clean
I0406 03:16:46.080222 140342066173760 submission_runner.py:382] Time since start: 8.89s, 	Step: 1, 	{'train/ctc_loss': 31.87422901399124, 'train/wer': 4.423790647529022, 'validation/ctc_loss': 30.719431258790436, 'validation/wer': 4.163626707864626, 'validation/num_examples': 5348, 'test/ctc_loss': 30.883860249048325, 'test/wer': 4.299636422724595, 'test/num_examples': 2472}
I0406 03:16:46.081045 140342066173760 submission_runner.py:396] After eval at step 1: RAM USED (GB) 45.123678208
I0406 03:16:46.094643 140311204456192 logging_writer.py:48] [1] global_step=1, preemption_count=0, score=8.886390, test/ctc_loss=30.883860, test/num_examples=2472, test/wer=4.299636, total_duration=8.888576, train/ctc_loss=31.874229, train/wer=4.423791, validation/ctc_loss=30.719431, validation/num_examples=5348, validation/wer=4.163627
I0406 03:16:46.366893 140342066173760 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v2/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/checkpoint_1.
I0406 03:16:46.367388 140342066173760 submission_runner.py:416] After logging and checkpointing eval at step 1: RAM USED (GB) 45.148233728
I0406 03:16:46.370040 140342066173760 submission_runner.py:335] After dataselection batch at step 1: RAM USED (GB) 45.153394688
I0406 03:16:46.404386 140342066173760 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 03:16:46.406364 139812831323968 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 03:16:46.407208 140394744997696 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 03:16:46.407338 140006052349760 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 03:16:46.407412 140546912470848 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 03:16:46.407465 139626954884928 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 03:16:46.407517 139809586906944 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 03:16:46.407558 140648076261184 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 03:16:47.491451 140311196063488 logging_writer.py:48] [1] global_step=1, grad_norm=22.425459, loss=32.874107
I0406 03:16:47.494684 140342066173760 submission.py:296] 1) loss = 32.874, grad_norm = 22.425
I0406 03:16:47.495547 140342066173760 submission_runner.py:352] After update parameters step 1: RAM USED (GB) 45.324423168
I0406 03:16:48.434547 140311204456192 logging_writer.py:48] [2] global_step=2, grad_norm=22.960770, loss=33.363586
I0406 03:16:48.437603 140342066173760 submission.py:296] 2) loss = 33.364, grad_norm = 22.961
I0406 03:16:49.249063 140311196063488 logging_writer.py:48] [3] global_step=3, grad_norm=21.771061, loss=33.499409
I0406 03:16:49.251967 140342066173760 submission.py:296] 3) loss = 33.499, grad_norm = 21.771
I0406 03:16:50.065670 140311204456192 logging_writer.py:48] [4] global_step=4, grad_norm=22.063108, loss=32.990074
I0406 03:16:50.068575 140342066173760 submission.py:296] 4) loss = 32.990, grad_norm = 22.063
I0406 03:16:50.884735 140311196063488 logging_writer.py:48] [5] global_step=5, grad_norm=23.377247, loss=33.213299
I0406 03:16:50.887742 140342066173760 submission.py:296] 5) loss = 33.213, grad_norm = 23.377
I0406 03:16:51.696011 140311204456192 logging_writer.py:48] [6] global_step=6, grad_norm=24.646954, loss=33.309723
I0406 03:16:51.699079 140342066173760 submission.py:296] 6) loss = 33.310, grad_norm = 24.647
I0406 03:16:52.523055 140311196063488 logging_writer.py:48] [7] global_step=7, grad_norm=25.234316, loss=32.366127
I0406 03:16:52.526067 140342066173760 submission.py:296] 7) loss = 32.366, grad_norm = 25.234
I0406 03:16:53.335095 140311204456192 logging_writer.py:48] [8] global_step=8, grad_norm=26.674763, loss=32.787251
I0406 03:16:53.338104 140342066173760 submission.py:296] 8) loss = 32.787, grad_norm = 26.675
I0406 03:16:54.167520 140311196063488 logging_writer.py:48] [9] global_step=9, grad_norm=26.533398, loss=32.407852
I0406 03:16:54.170711 140342066173760 submission.py:296] 9) loss = 32.408, grad_norm = 26.533
I0406 03:16:54.978625 140311204456192 logging_writer.py:48] [10] global_step=10, grad_norm=27.294224, loss=32.268757
I0406 03:16:54.981594 140342066173760 submission.py:296] 10) loss = 32.269, grad_norm = 27.294
I0406 03:16:55.787206 140311196063488 logging_writer.py:48] [11] global_step=11, grad_norm=29.922464, loss=32.523647
I0406 03:16:55.790283 140342066173760 submission.py:296] 11) loss = 32.524, grad_norm = 29.922
I0406 03:16:56.598812 140311204456192 logging_writer.py:48] [12] global_step=12, grad_norm=31.482029, loss=32.639210
I0406 03:16:56.601734 140342066173760 submission.py:296] 12) loss = 32.639, grad_norm = 31.482
I0406 03:16:57.405703 140311196063488 logging_writer.py:48] [13] global_step=13, grad_norm=32.401604, loss=32.131664
I0406 03:16:57.408750 140342066173760 submission.py:296] 13) loss = 32.132, grad_norm = 32.402
I0406 03:16:58.214201 140311204456192 logging_writer.py:48] [14] global_step=14, grad_norm=34.618080, loss=31.945337
I0406 03:16:58.217258 140342066173760 submission.py:296] 14) loss = 31.945, grad_norm = 34.618
I0406 03:16:59.020288 140311196063488 logging_writer.py:48] [15] global_step=15, grad_norm=34.675339, loss=31.040531
I0406 03:16:59.023261 140342066173760 submission.py:296] 15) loss = 31.041, grad_norm = 34.675
I0406 03:16:59.826888 140311204456192 logging_writer.py:48] [16] global_step=16, grad_norm=37.635349, loss=31.542431
I0406 03:16:59.829958 140342066173760 submission.py:296] 16) loss = 31.542, grad_norm = 37.635
I0406 03:17:00.636243 140311196063488 logging_writer.py:48] [17] global_step=17, grad_norm=38.061752, loss=31.098391
I0406 03:17:00.639428 140342066173760 submission.py:296] 17) loss = 31.098, grad_norm = 38.062
I0406 03:17:01.444977 140311204456192 logging_writer.py:48] [18] global_step=18, grad_norm=39.135696, loss=30.863209
I0406 03:17:01.448041 140342066173760 submission.py:296] 18) loss = 30.863, grad_norm = 39.136
I0406 03:17:02.252325 140311196063488 logging_writer.py:48] [19] global_step=19, grad_norm=40.420589, loss=30.136097
I0406 03:17:02.255580 140342066173760 submission.py:296] 19) loss = 30.136, grad_norm = 40.421
I0406 03:17:03.062360 140311204456192 logging_writer.py:48] [20] global_step=20, grad_norm=38.165375, loss=29.602999
I0406 03:17:03.065583 140342066173760 submission.py:296] 20) loss = 29.603, grad_norm = 38.165
I0406 03:17:03.878963 140311196063488 logging_writer.py:48] [21] global_step=21, grad_norm=39.893848, loss=29.607260
I0406 03:17:03.882011 140342066173760 submission.py:296] 21) loss = 29.607, grad_norm = 39.894
I0406 03:17:04.687703 140311204456192 logging_writer.py:48] [22] global_step=22, grad_norm=41.345573, loss=29.633986
I0406 03:17:04.690726 140342066173760 submission.py:296] 22) loss = 29.634, grad_norm = 41.346
I0406 03:17:05.495407 140311196063488 logging_writer.py:48] [23] global_step=23, grad_norm=39.339409, loss=28.687222
I0406 03:17:05.498364 140342066173760 submission.py:296] 23) loss = 28.687, grad_norm = 39.339
I0406 03:17:06.306977 140311204456192 logging_writer.py:48] [24] global_step=24, grad_norm=41.320145, loss=28.742188
I0406 03:17:06.309970 140342066173760 submission.py:296] 24) loss = 28.742, grad_norm = 41.320
I0406 03:17:07.116200 140311196063488 logging_writer.py:48] [25] global_step=25, grad_norm=40.462887, loss=28.352791
I0406 03:17:07.119206 140342066173760 submission.py:296] 25) loss = 28.353, grad_norm = 40.463
I0406 03:17:07.942305 140311204456192 logging_writer.py:48] [26] global_step=26, grad_norm=39.919659, loss=27.929628
I0406 03:17:07.945600 140342066173760 submission.py:296] 26) loss = 27.930, grad_norm = 39.920
I0406 03:17:08.756750 140311196063488 logging_writer.py:48] [27] global_step=27, grad_norm=40.562721, loss=27.602160
I0406 03:17:08.760156 140342066173760 submission.py:296] 27) loss = 27.602, grad_norm = 40.563
I0406 03:17:09.569459 140311204456192 logging_writer.py:48] [28] global_step=28, grad_norm=39.132607, loss=27.066975
I0406 03:17:09.572461 140342066173760 submission.py:296] 28) loss = 27.067, grad_norm = 39.133
I0406 03:17:10.382435 140311196063488 logging_writer.py:48] [29] global_step=29, grad_norm=39.034187, loss=26.285290
I0406 03:17:10.385479 140342066173760 submission.py:296] 29) loss = 26.285, grad_norm = 39.034
I0406 03:17:11.200056 140311204456192 logging_writer.py:48] [30] global_step=30, grad_norm=39.356812, loss=25.707106
I0406 03:17:11.203155 140342066173760 submission.py:296] 30) loss = 25.707, grad_norm = 39.357
I0406 03:17:12.005518 140311196063488 logging_writer.py:48] [31] global_step=31, grad_norm=39.367935, loss=25.565960
I0406 03:17:12.008648 140342066173760 submission.py:296] 31) loss = 25.566, grad_norm = 39.368
I0406 03:17:12.813951 140311204456192 logging_writer.py:48] [32] global_step=32, grad_norm=37.325539, loss=25.120378
I0406 03:17:12.817405 140342066173760 submission.py:296] 32) loss = 25.120, grad_norm = 37.326
I0406 03:17:13.623532 140311196063488 logging_writer.py:48] [33] global_step=33, grad_norm=37.975254, loss=24.931454
I0406 03:17:13.626901 140342066173760 submission.py:296] 33) loss = 24.931, grad_norm = 37.975
I0406 03:17:14.431525 140311204456192 logging_writer.py:48] [34] global_step=34, grad_norm=36.607838, loss=24.645075
I0406 03:17:14.434630 140342066173760 submission.py:296] 34) loss = 24.645, grad_norm = 36.608
I0406 03:17:15.242320 140311196063488 logging_writer.py:48] [35] global_step=35, grad_norm=36.960697, loss=23.975056
I0406 03:17:15.245427 140342066173760 submission.py:296] 35) loss = 23.975, grad_norm = 36.961
I0406 03:17:16.046993 140311204456192 logging_writer.py:48] [36] global_step=36, grad_norm=35.005901, loss=23.480894
I0406 03:17:16.049910 140342066173760 submission.py:296] 36) loss = 23.481, grad_norm = 35.006
I0406 03:17:16.868737 140311196063488 logging_writer.py:48] [37] global_step=37, grad_norm=33.612999, loss=22.662371
I0406 03:17:16.871793 140342066173760 submission.py:296] 37) loss = 22.662, grad_norm = 33.613
I0406 03:17:17.678913 140311204456192 logging_writer.py:48] [38] global_step=38, grad_norm=33.569012, loss=22.649786
I0406 03:17:17.682102 140342066173760 submission.py:296] 38) loss = 22.650, grad_norm = 33.569
I0406 03:17:18.485651 140311196063488 logging_writer.py:48] [39] global_step=39, grad_norm=32.959316, loss=22.201271
I0406 03:17:18.489123 140342066173760 submission.py:296] 39) loss = 22.201, grad_norm = 32.959
I0406 03:17:19.293154 140311204456192 logging_writer.py:48] [40] global_step=40, grad_norm=31.994059, loss=21.738779
I0406 03:17:19.296280 140342066173760 submission.py:296] 40) loss = 21.739, grad_norm = 31.994
I0406 03:17:20.099973 140311196063488 logging_writer.py:48] [41] global_step=41, grad_norm=30.263390, loss=21.333382
I0406 03:17:20.102994 140342066173760 submission.py:296] 41) loss = 21.333, grad_norm = 30.263
I0406 03:17:20.917924 140311204456192 logging_writer.py:48] [42] global_step=42, grad_norm=29.704586, loss=20.815218
I0406 03:17:20.921035 140342066173760 submission.py:296] 42) loss = 20.815, grad_norm = 29.705
I0406 03:17:21.724795 140311196063488 logging_writer.py:48] [43] global_step=43, grad_norm=28.566484, loss=20.386944
I0406 03:17:21.728291 140342066173760 submission.py:296] 43) loss = 20.387, grad_norm = 28.566
I0406 03:17:22.538228 140311204456192 logging_writer.py:48] [44] global_step=44, grad_norm=27.616423, loss=19.904345
I0406 03:17:22.541295 140342066173760 submission.py:296] 44) loss = 19.904, grad_norm = 27.616
I0406 03:17:23.346887 140311196063488 logging_writer.py:48] [45] global_step=45, grad_norm=26.324303, loss=19.500090
I0406 03:17:23.349984 140342066173760 submission.py:296] 45) loss = 19.500, grad_norm = 26.324
I0406 03:17:24.162864 140311204456192 logging_writer.py:48] [46] global_step=46, grad_norm=24.989994, loss=18.850874
I0406 03:17:24.165944 140342066173760 submission.py:296] 46) loss = 18.851, grad_norm = 24.990
I0406 03:17:24.988315 140311196063488 logging_writer.py:48] [47] global_step=47, grad_norm=24.480446, loss=18.881132
I0406 03:17:24.991360 140342066173760 submission.py:296] 47) loss = 18.881, grad_norm = 24.480
I0406 03:17:25.795717 140311204456192 logging_writer.py:48] [48] global_step=48, grad_norm=24.244011, loss=18.902069
I0406 03:17:25.799026 140342066173760 submission.py:296] 48) loss = 18.902, grad_norm = 24.244
I0406 03:17:26.600117 140311196063488 logging_writer.py:48] [49] global_step=49, grad_norm=23.261608, loss=18.342264
I0406 03:17:26.603083 140342066173760 submission.py:296] 49) loss = 18.342, grad_norm = 23.262
I0406 03:17:27.409402 140311204456192 logging_writer.py:48] [50] global_step=50, grad_norm=21.831579, loss=17.717461
I0406 03:17:27.412527 140342066173760 submission.py:296] 50) loss = 17.717, grad_norm = 21.832
I0406 03:17:28.219348 140311196063488 logging_writer.py:48] [51] global_step=51, grad_norm=21.355066, loss=17.171646
I0406 03:17:28.222256 140342066173760 submission.py:296] 51) loss = 17.172, grad_norm = 21.355
I0406 03:17:29.028137 140311204456192 logging_writer.py:48] [52] global_step=52, grad_norm=20.168980, loss=16.799135
I0406 03:17:29.031313 140342066173760 submission.py:296] 52) loss = 16.799, grad_norm = 20.169
I0406 03:17:29.839621 140311196063488 logging_writer.py:48] [53] global_step=53, grad_norm=19.623280, loss=16.728935
I0406 03:17:29.842827 140342066173760 submission.py:296] 53) loss = 16.729, grad_norm = 19.623
I0406 03:17:30.650178 140311204456192 logging_writer.py:48] [54] global_step=54, grad_norm=19.127403, loss=16.767147
I0406 03:17:30.653029 140342066173760 submission.py:296] 54) loss = 16.767, grad_norm = 19.127
I0406 03:17:31.456990 140311196063488 logging_writer.py:48] [55] global_step=55, grad_norm=18.601696, loss=16.684284
I0406 03:17:31.459966 140342066173760 submission.py:296] 55) loss = 16.684, grad_norm = 18.602
I0406 03:17:32.281134 140311204456192 logging_writer.py:48] [56] global_step=56, grad_norm=17.252895, loss=16.266102
I0406 03:17:32.284400 140342066173760 submission.py:296] 56) loss = 16.266, grad_norm = 17.253
I0406 03:17:33.091227 140311196063488 logging_writer.py:48] [57] global_step=57, grad_norm=17.048195, loss=16.111959
I0406 03:17:33.094554 140342066173760 submission.py:296] 57) loss = 16.112, grad_norm = 17.048
I0406 03:17:33.901383 140311204456192 logging_writer.py:48] [58] global_step=58, grad_norm=16.444666, loss=15.583251
I0406 03:17:33.904569 140342066173760 submission.py:296] 58) loss = 15.583, grad_norm = 16.445
I0406 03:17:34.713304 140311196063488 logging_writer.py:48] [59] global_step=59, grad_norm=15.951999, loss=15.427247
I0406 03:17:34.716504 140342066173760 submission.py:296] 59) loss = 15.427, grad_norm = 15.952
I0406 03:17:35.522951 140311204456192 logging_writer.py:48] [60] global_step=60, grad_norm=15.086042, loss=15.431756
I0406 03:17:35.525903 140342066173760 submission.py:296] 60) loss = 15.432, grad_norm = 15.086
I0406 03:17:36.332411 140311196063488 logging_writer.py:48] [61] global_step=61, grad_norm=14.336658, loss=14.783695
I0406 03:17:36.335572 140342066173760 submission.py:296] 61) loss = 14.784, grad_norm = 14.337
I0406 03:17:37.144882 140311204456192 logging_writer.py:48] [62] global_step=62, grad_norm=14.269910, loss=14.870566
I0406 03:17:37.148024 140342066173760 submission.py:296] 62) loss = 14.871, grad_norm = 14.270
I0406 03:17:37.960677 140311196063488 logging_writer.py:48] [63] global_step=63, grad_norm=13.992414, loss=14.821925
I0406 03:17:37.963633 140342066173760 submission.py:296] 63) loss = 14.822, grad_norm = 13.992
I0406 03:17:38.770231 140311204456192 logging_writer.py:48] [64] global_step=64, grad_norm=12.955120, loss=14.312023
I0406 03:17:38.773753 140342066173760 submission.py:296] 64) loss = 14.312, grad_norm = 12.955
I0406 03:17:39.586037 140311196063488 logging_writer.py:48] [65] global_step=65, grad_norm=12.700900, loss=14.184966
I0406 03:17:39.589171 140342066173760 submission.py:296] 65) loss = 14.185, grad_norm = 12.701
I0406 03:17:40.392600 140311204456192 logging_writer.py:48] [66] global_step=66, grad_norm=12.244076, loss=14.056851
I0406 03:17:40.395664 140342066173760 submission.py:296] 66) loss = 14.057, grad_norm = 12.244
I0406 03:17:41.201118 140311196063488 logging_writer.py:48] [67] global_step=67, grad_norm=11.450438, loss=13.424771
I0406 03:17:41.204229 140342066173760 submission.py:296] 67) loss = 13.425, grad_norm = 11.450
I0406 03:17:42.009596 140311204456192 logging_writer.py:48] [68] global_step=68, grad_norm=11.078292, loss=13.245165
I0406 03:17:42.012830 140342066173760 submission.py:296] 68) loss = 13.245, grad_norm = 11.078
I0406 03:17:42.824987 140311196063488 logging_writer.py:48] [69] global_step=69, grad_norm=10.924384, loss=13.691457
I0406 03:17:42.828484 140342066173760 submission.py:296] 69) loss = 13.691, grad_norm = 10.924
I0406 03:17:43.644587 140311204456192 logging_writer.py:48] [70] global_step=70, grad_norm=10.844792, loss=13.207465
I0406 03:17:43.647751 140342066173760 submission.py:296] 70) loss = 13.207, grad_norm = 10.845
I0406 03:17:44.459368 140311196063488 logging_writer.py:48] [71] global_step=71, grad_norm=10.662852, loss=13.387226
I0406 03:17:44.462414 140342066173760 submission.py:296] 71) loss = 13.387, grad_norm = 10.663
I0406 03:17:45.279982 140311204456192 logging_writer.py:48] [72] global_step=72, grad_norm=9.700525, loss=12.620739
I0406 03:17:45.282963 140342066173760 submission.py:296] 72) loss = 12.621, grad_norm = 9.701
I0406 03:17:46.091544 140311196063488 logging_writer.py:48] [73] global_step=73, grad_norm=9.946720, loss=12.876595
I0406 03:17:46.094727 140342066173760 submission.py:296] 73) loss = 12.877, grad_norm = 9.947
I0406 03:17:46.914313 140311204456192 logging_writer.py:48] [74] global_step=74, grad_norm=9.805167, loss=12.734152
I0406 03:17:46.917419 140342066173760 submission.py:296] 74) loss = 12.734, grad_norm = 9.805
I0406 03:17:47.755592 140311196063488 logging_writer.py:48] [75] global_step=75, grad_norm=9.708385, loss=12.793230
I0406 03:17:47.758813 140342066173760 submission.py:296] 75) loss = 12.793, grad_norm = 9.708
I0406 03:17:48.577014 140311204456192 logging_writer.py:48] [76] global_step=76, grad_norm=8.811737, loss=12.147604
I0406 03:17:48.580600 140342066173760 submission.py:296] 76) loss = 12.148, grad_norm = 8.812
I0406 03:17:49.407375 140311196063488 logging_writer.py:48] [77] global_step=77, grad_norm=8.818494, loss=12.441871
I0406 03:17:49.410391 140342066173760 submission.py:296] 77) loss = 12.442, grad_norm = 8.818
I0406 03:17:50.221881 140311204456192 logging_writer.py:48] [78] global_step=78, grad_norm=8.929392, loss=12.064178
I0406 03:17:50.224959 140342066173760 submission.py:296] 78) loss = 12.064, grad_norm = 8.929
I0406 03:17:51.049496 140311196063488 logging_writer.py:48] [79] global_step=79, grad_norm=8.432991, loss=11.871593
I0406 03:17:51.052870 140342066173760 submission.py:296] 79) loss = 11.872, grad_norm = 8.433
I0406 03:17:51.861612 140311204456192 logging_writer.py:48] [80] global_step=80, grad_norm=8.359204, loss=12.103433
I0406 03:17:51.864703 140342066173760 submission.py:296] 80) loss = 12.103, grad_norm = 8.359
I0406 03:17:52.675944 140311196063488 logging_writer.py:48] [81] global_step=81, grad_norm=9.048809, loss=11.923846
I0406 03:17:52.679630 140342066173760 submission.py:296] 81) loss = 11.924, grad_norm = 9.049
I0406 03:17:53.498801 140311204456192 logging_writer.py:48] [82] global_step=82, grad_norm=8.440309, loss=11.790795
I0406 03:17:53.501804 140342066173760 submission.py:296] 82) loss = 11.791, grad_norm = 8.440
I0406 03:17:54.310847 140311196063488 logging_writer.py:48] [83] global_step=83, grad_norm=8.629465, loss=11.876447
I0406 03:17:54.313858 140342066173760 submission.py:296] 83) loss = 11.876, grad_norm = 8.629
I0406 03:17:55.122780 140311204456192 logging_writer.py:48] [84] global_step=84, grad_norm=8.069377, loss=11.433393
I0406 03:17:55.125743 140342066173760 submission.py:296] 84) loss = 11.433, grad_norm = 8.069
I0406 03:17:55.937801 140311196063488 logging_writer.py:48] [85] global_step=85, grad_norm=8.315935, loss=11.574041
I0406 03:17:55.940890 140342066173760 submission.py:296] 85) loss = 11.574, grad_norm = 8.316
I0406 03:17:56.775848 140311204456192 logging_writer.py:48] [86] global_step=86, grad_norm=7.859817, loss=11.026339
I0406 03:17:56.779419 140342066173760 submission.py:296] 86) loss = 11.026, grad_norm = 7.860
I0406 03:17:57.582892 140311196063488 logging_writer.py:48] [87] global_step=87, grad_norm=7.486700, loss=10.853969
I0406 03:17:57.585970 140342066173760 submission.py:296] 87) loss = 10.854, grad_norm = 7.487
I0406 03:17:58.399485 140311204456192 logging_writer.py:48] [88] global_step=88, grad_norm=7.698077, loss=10.860916
I0406 03:17:58.403356 140342066173760 submission.py:296] 88) loss = 10.861, grad_norm = 7.698
I0406 03:17:59.216976 140311196063488 logging_writer.py:48] [89] global_step=89, grad_norm=8.031176, loss=11.079535
I0406 03:17:59.220339 140342066173760 submission.py:296] 89) loss = 11.080, grad_norm = 8.031
I0406 03:18:00.027741 140311204456192 logging_writer.py:48] [90] global_step=90, grad_norm=7.296475, loss=10.559731
I0406 03:18:00.031215 140342066173760 submission.py:296] 90) loss = 10.560, grad_norm = 7.296
I0406 03:18:00.837002 140311196063488 logging_writer.py:48] [91] global_step=91, grad_norm=7.853468, loss=10.766257
I0406 03:18:00.840363 140342066173760 submission.py:296] 91) loss = 10.766, grad_norm = 7.853
I0406 03:18:01.650306 140311204456192 logging_writer.py:48] [92] global_step=92, grad_norm=8.142730, loss=10.661500
I0406 03:18:01.653340 140342066173760 submission.py:296] 92) loss = 10.661, grad_norm = 8.143
I0406 03:18:02.465620 140311196063488 logging_writer.py:48] [93] global_step=93, grad_norm=8.090514, loss=10.513587
I0406 03:18:02.468750 140342066173760 submission.py:296] 93) loss = 10.514, grad_norm = 8.091
I0406 03:18:03.280630 140311204456192 logging_writer.py:48] [94] global_step=94, grad_norm=7.385321, loss=10.135962
I0406 03:18:03.283760 140342066173760 submission.py:296] 94) loss = 10.136, grad_norm = 7.385
I0406 03:18:04.102648 140311196063488 logging_writer.py:48] [95] global_step=95, grad_norm=7.909678, loss=10.154419
I0406 03:18:04.105622 140342066173760 submission.py:296] 95) loss = 10.154, grad_norm = 7.910
I0406 03:18:04.920306 140311204456192 logging_writer.py:48] [96] global_step=96, grad_norm=8.811621, loss=10.131314
I0406 03:18:04.923224 140342066173760 submission.py:296] 96) loss = 10.131, grad_norm = 8.812
I0406 03:18:05.740370 140311196063488 logging_writer.py:48] [97] global_step=97, grad_norm=8.095626, loss=10.050792
I0406 03:18:05.743401 140342066173760 submission.py:296] 97) loss = 10.051, grad_norm = 8.096
I0406 03:18:06.566930 140311204456192 logging_writer.py:48] [98] global_step=98, grad_norm=8.034986, loss=9.922084
I0406 03:18:06.570236 140342066173760 submission.py:296] 98) loss = 9.922, grad_norm = 8.035
I0406 03:18:07.373878 140311196063488 logging_writer.py:48] [99] global_step=99, grad_norm=8.539824, loss=9.787367
I0406 03:18:07.376932 140342066173760 submission.py:296] 99) loss = 9.787, grad_norm = 8.540
I0406 03:18:08.191051 140311204456192 logging_writer.py:48] [100] global_step=100, grad_norm=8.241416, loss=9.473742
I0406 03:18:08.194069 140342066173760 submission.py:296] 100) loss = 9.474, grad_norm = 8.241
I0406 03:23:29.947054 140311196063488 logging_writer.py:48] [500] global_step=500, grad_norm=0.371145, loss=5.809686
I0406 03:23:29.951723 140342066173760 submission.py:296] 500) loss = 5.810, grad_norm = 0.371
I0406 03:30:12.040034 140311204456192 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.569986, loss=5.304151
I0406 03:30:12.047184 140342066173760 submission.py:296] 1000) loss = 5.304, grad_norm = 0.570
I0406 03:36:55.781729 140311204456192 logging_writer.py:48] [1500] global_step=1500, grad_norm=1.398419, loss=3.685803
I0406 03:36:55.788412 140342066173760 submission.py:296] 1500) loss = 3.686, grad_norm = 1.398
I0406 03:43:38.004162 140311196063488 logging_writer.py:48] [2000] global_step=2000, grad_norm=1.975642, loss=3.070499
I0406 03:43:38.009580 140342066173760 submission.py:296] 2000) loss = 3.070, grad_norm = 1.976
I0406 03:50:20.270261 140311204456192 logging_writer.py:48] [2500] global_step=2500, grad_norm=3.779886, loss=2.716094
I0406 03:50:20.277913 140342066173760 submission.py:296] 2500) loss = 2.716, grad_norm = 3.780
I0406 03:56:46.876928 140342066173760 submission_runner.py:373] Before eval at step 2984: RAM USED (GB) 43.137261568
I0406 03:56:46.877141 140342066173760 spec.py:298] Evaluating on the training split.
I0406 03:56:56.467627 140342066173760 spec.py:310] Evaluating on the validation split.
I0406 03:57:05.266179 140342066173760 spec.py:326] Evaluating on the test split.
I0406 03:57:10.265422 140342066173760 submission_runner.py:382] Time since start: 2445.10s, 	Step: 2984, 	{'train/ctc_loss': 5.0843788079967505, 'train/wer': 0.920011761374774, 'validation/ctc_loss': 4.998652787196102, 'validation/wer': 0.8804422343455801, 'validation/num_examples': 5348, 'test/ctc_loss': 4.757078682495645, 'test/wer': 0.8742103873418235, 'test/num_examples': 2472}
I0406 03:57:10.266190 140342066173760 submission_runner.py:396] After eval at step 2984: RAM USED (GB) 41.692491776
I0406 03:57:10.282943 140311204456192 logging_writer.py:48] [2984] global_step=2984, preemption_count=0, score=1496.698987, test/ctc_loss=4.757079, test/num_examples=2472, test/wer=0.874210, total_duration=2445.101853, train/ctc_loss=5.084379, train/wer=0.920012, validation/ctc_loss=4.998653, validation/num_examples=5348, validation/wer=0.880442
I0406 03:57:10.561210 140342066173760 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v2/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/checkpoint_2984.
I0406 03:57:10.561726 140342066173760 submission_runner.py:416] After logging and checkpointing eval at step 2984: RAM USED (GB) 41.698684928
I0406 03:57:24.157750 140311196063488 logging_writer.py:48] [3000] global_step=3000, grad_norm=2.842042, loss=2.524135
I0406 03:57:24.161020 140342066173760 submission.py:296] 3000) loss = 2.524, grad_norm = 2.842
I0406 04:04:06.683299 140311204456192 logging_writer.py:48] [3500] global_step=3500, grad_norm=3.998158, loss=2.375077
I0406 04:04:06.695703 140342066173760 submission.py:296] 3500) loss = 2.375, grad_norm = 3.998
I0406 04:10:48.495099 140311196063488 logging_writer.py:48] [4000] global_step=4000, grad_norm=2.420480, loss=2.220109
I0406 04:10:48.500384 140342066173760 submission.py:296] 4000) loss = 2.220, grad_norm = 2.420
I0406 04:17:31.607172 140311204456192 logging_writer.py:48] [4500] global_step=4500, grad_norm=4.366028, loss=2.134085
I0406 04:17:31.614281 140342066173760 submission.py:296] 4500) loss = 2.134, grad_norm = 4.366
I0406 04:24:11.347071 140311196063488 logging_writer.py:48] [5000] global_step=5000, grad_norm=2.448435, loss=2.010007
I0406 04:24:11.351453 140342066173760 submission.py:296] 5000) loss = 2.010, grad_norm = 2.448
I0406 04:30:51.751412 140311204456192 logging_writer.py:48] [5500] global_step=5500, grad_norm=2.636263, loss=2.047972
I0406 04:30:51.757459 140342066173760 submission.py:296] 5500) loss = 2.048, grad_norm = 2.636
I0406 04:37:11.599464 140342066173760 submission_runner.py:373] Before eval at step 5975: RAM USED (GB) 41.729028096
I0406 04:37:11.599762 140342066173760 spec.py:298] Evaluating on the training split.
I0406 04:37:22.367047 140342066173760 spec.py:310] Evaluating on the validation split.
I0406 04:37:31.688851 140342066173760 spec.py:326] Evaluating on the test split.
I0406 04:37:36.967826 140342066173760 submission_runner.py:382] Time since start: 4869.82s, 	Step: 5975, 	{'train/ctc_loss': 0.9012964042270684, 'train/wer': 0.2884150458475813, 'validation/ctc_loss': 1.1655881704277176, 'validation/wer': 0.325930575001207, 'validation/num_examples': 5348, 'test/ctc_loss': 0.7975067443867346, 'test/wer': 0.25793674974102737, 'test/num_examples': 2472}
I0406 04:37:36.968650 140342066173760 submission_runner.py:396] After eval at step 5975: RAM USED (GB) 41.595826176
I0406 04:37:36.987253 140311204456192 logging_writer.py:48] [5975] global_step=5975, preemption_count=0, score=2955.594886, test/ctc_loss=0.797507, test/num_examples=2472, test/wer=0.257937, total_duration=4869.823567, train/ctc_loss=0.901296, train/wer=0.288415, validation/ctc_loss=1.165588, validation/num_examples=5348, validation/wer=0.325931
I0406 04:37:37.269819 140342066173760 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v2/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/checkpoint_5975.
I0406 04:37:37.270377 140342066173760 submission_runner.py:416] After logging and checkpointing eval at step 5975: RAM USED (GB) 41.605128192
I0406 04:37:58.049890 140311196063488 logging_writer.py:48] [6000] global_step=6000, grad_norm=2.888395, loss=2.035372
I0406 04:37:58.053265 140342066173760 submission.py:296] 6000) loss = 2.035, grad_norm = 2.888
I0406 04:44:40.572755 140311204456192 logging_writer.py:48] [6500] global_step=6500, grad_norm=3.150754, loss=1.880786
I0406 04:44:40.579665 140342066173760 submission.py:296] 6500) loss = 1.881, grad_norm = 3.151
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
I0406 04:51:20.735157 140311196063488 logging_writer.py:48] [7000] global_step=7000, grad_norm=1.933714, loss=1.795471
I0406 04:51:20.740159 140342066173760 submission.py:296] 7000) loss = 1.795, grad_norm = 1.934
I0406 04:58:02.622148 140311204456192 logging_writer.py:48] [7500] global_step=7500, grad_norm=2.817503, loss=1.869739
I0406 04:58:02.628907 140342066173760 submission.py:296] 7500) loss = 1.870, grad_norm = 2.818
I0406 05:04:40.935677 140342066173760 submission_runner.py:373] Before eval at step 8000: RAM USED (GB) 41.739907072
I0406 05:04:40.935928 140342066173760 spec.py:298] Evaluating on the training split.
I0406 05:04:51.662899 140342066173760 spec.py:310] Evaluating on the validation split.
I0406 05:05:00.818028 140342066173760 spec.py:326] Evaluating on the test split.
I0406 05:05:06.023016 140342066173760 submission_runner.py:382] Time since start: 6519.16s, 	Step: 8000, 	{'train/ctc_loss': 0.7077802493608539, 'train/wer': 0.22973885391936924, 'validation/ctc_loss': 0.9724098038476994, 'validation/wer': 0.2725148457490465, 'validation/num_examples': 5348, 'test/ctc_loss': 0.6204237470965869, 'test/wer': 0.20055653728190442, 'test/num_examples': 2472}
I0406 05:05:06.023783 140342066173760 submission_runner.py:396] After eval at step 8000: RAM USED (GB) 41.566728192
I0406 05:05:06.044541 140311204456192 logging_writer.py:48] [8000] global_step=8000, preemption_count=0, score=3942.109643, test/ctc_loss=0.620424, test/num_examples=2472, test/wer=0.200557, total_duration=6519.159876, train/ctc_loss=0.707780, train/wer=0.229739, validation/ctc_loss=0.972410, validation/num_examples=5348, validation/wer=0.272515
I0406 05:05:06.327324 140342066173760 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v2/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/checkpoint_8000.
I0406 05:05:06.327836 140342066173760 submission_runner.py:416] After logging and checkpointing eval at step 8000: RAM USED (GB) 41.57284352
I0406 05:05:06.340240 140311196063488 logging_writer.py:48] [8000] global_step=8000, preemption_count=0, score=3942.109643
I0406 05:05:06.872049 140342066173760 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v2/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/checkpoint_8000.
I0406 05:05:07.046247 140342066173760 submission_runner.py:550] Tuning trial 1/1
I0406 05:05:07.046531 140342066173760 submission_runner.py:551] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.045677535963609565, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0406 05:05:07.047138 140342066173760 submission_runner.py:552] Metrics: {'eval_results': [(1, {'train/ctc_loss': 31.87422901399124, 'train/wer': 4.423790647529022, 'validation/ctc_loss': 30.719431258790436, 'validation/wer': 4.163626707864626, 'validation/num_examples': 5348, 'test/ctc_loss': 30.883860249048325, 'test/wer': 4.299636422724595, 'test/num_examples': 2472, 'score': 8.886389970779419, 'total_duration': 8.888576030731201, 'global_step': 1, 'preemption_count': 0}), (2984, {'train/ctc_loss': 5.0843788079967505, 'train/wer': 0.920011761374774, 'validation/ctc_loss': 4.998652787196102, 'validation/wer': 0.8804422343455801, 'validation/num_examples': 5348, 'test/ctc_loss': 4.757078682495645, 'test/wer': 0.8742103873418235, 'test/num_examples': 2472, 'score': 1496.698986530304, 'total_duration': 2445.1018528938293, 'global_step': 2984, 'preemption_count': 0}), (5975, {'train/ctc_loss': 0.9012964042270684, 'train/wer': 0.2884150458475813, 'validation/ctc_loss': 1.1655881704277176, 'validation/wer': 0.325930575001207, 'validation/num_examples': 5348, 'test/ctc_loss': 0.7975067443867346, 'test/wer': 0.25793674974102737, 'test/num_examples': 2472, 'score': 2955.594886302948, 'total_duration': 4869.823566675186, 'global_step': 5975, 'preemption_count': 0}), (8000, {'train/ctc_loss': 0.7077802493608539, 'train/wer': 0.22973885391936924, 'validation/ctc_loss': 0.9724098038476994, 'validation/wer': 0.2725148457490465, 'validation/num_examples': 5348, 'test/ctc_loss': 0.6204237470965869, 'test/wer': 0.20055653728190442, 'test/num_examples': 2472, 'score': 3942.1096427440643, 'total_duration': 6519.159875869751, 'global_step': 8000, 'preemption_count': 0})], 'global_step': 8000}
I0406 05:05:07.047286 140342066173760 submission_runner.py:553] Timing: 3942.1096427440643
I0406 05:05:07.047389 140342066173760 submission_runner.py:554] ====================
I0406 05:05:07.047599 140342066173760 submission_runner.py:613] Final librispeech_deepspeech score: 3942.1096427440643
