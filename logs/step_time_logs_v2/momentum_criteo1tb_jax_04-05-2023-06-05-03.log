I0405 06:05:21.716297 140634420852544 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_momentum_v2/criteo1tb_jax.
I0405 06:05:22.077165 140634420852544 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0405 06:05:22.943944 140634420852544 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter Host CUDA
I0405 06:05:22.945371 140634420852544 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0405 06:05:22.951032 140634420852544 submission_runner.py:511] Using RNG seed 1844112941
I0405 06:05:25.304561 140634420852544 submission_runner.py:520] --- Tuning run 1/1 ---
I0405 06:05:25.304750 140634420852544 submission_runner.py:525] Creating tuning directory at /experiment_runs/timing_momentum_v2/criteo1tb_jax/trial_1.
I0405 06:05:25.304916 140634420852544 logger_utils.py:84] Saving hparams to /experiment_runs/timing_momentum_v2/criteo1tb_jax/trial_1/hparams.json.
I0405 06:05:25.431406 140634420852544 submission_runner.py:230] Starting train once: RAM USED (GB) 4.34694144
I0405 06:05:25.431574 140634420852544 submission_runner.py:231] Initializing dataset.
I0405 06:05:25.431733 140634420852544 submission_runner.py:239] After Initializing dataset: RAM USED (GB) 4.34694144
I0405 06:05:25.431791 140634420852544 submission_runner.py:240] Initializing model.
I0405 06:05:31.454976 140634420852544 submission_runner.py:251] After Initializing model: RAM USED (GB) 8.139599872
I0405 06:05:31.455192 140634420852544 submission_runner.py:252] Initializing optimizer.
I0405 06:05:33.273237 140634420852544 submission_runner.py:260] After Initializing metrics bundle: RAM USED (GB) 8.14116864
I0405 06:05:33.273442 140634420852544 submission_runner.py:261] Initializing metrics bundle.
I0405 06:05:33.273500 140634420852544 submission_runner.py:276] Initializing checkpoint and logger.
I0405 06:05:33.274438 140634420852544 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_momentum_v2/criteo1tb_jax/trial_1 with prefix checkpoint_
I0405 06:05:33.274686 140634420852544 logger_utils.py:231] Unable to record workload.train_mean information. Continuing without it.
I0405 06:05:33.274745 140634420852544 logger_utils.py:231] Unable to record workload.train_stddev information. Continuing without it.
I0405 06:05:34.149924 140634420852544 submission_runner.py:297] Saving meta data to /experiment_runs/timing_momentum_v2/criteo1tb_jax/trial_1/meta_data_0.json.
I0405 06:05:34.150866 140634420852544 submission_runner.py:300] Saving flags to /experiment_runs/timing_momentum_v2/criteo1tb_jax/trial_1/flags_0.json.
I0405 06:05:34.198096 140634420852544 submission_runner.py:305] After checkpoint and logger metrics bundle: RAM USED (GB) 8.184864768
I0405 06:05:34.198333 140634420852544 submission_runner.py:312] Before starting training loop and logger metrics bundle: RAM USED (GB) 8.184864768
I0405 06:05:34.198399 140634420852544 submission_runner.py:313] Starting training loop.
I0405 06:07:56.180490 140634420852544 submission_runner.py:335] After dataselection batch at step 0: RAM USED (GB) 46.19051008
I0405 06:08:17.413784 140428872505088 logging_writer.py:48] [0] global_step=0, grad_norm=8.342931747436523, loss=2.0500359535217285
I0405 06:08:17.424501 140634420852544 submission_runner.py:352] After update parameters step 0: RAM USED (GB) 54.473863168
I0405 06:08:17.424795 140634420852544 submission_runner.py:373] Before eval at step 1: RAM USED (GB) 54.473863168
I0405 06:08:17.424884 140634420852544 spec.py:298] Evaluating on the training split.
I0405 06:18:16.510776 140634420852544 spec.py:310] Evaluating on the validation split.
I0405 06:22:48.915705 140634420852544 spec.py:326] Evaluating on the test split.
I0405 06:26:27.609777 140634420852544 submission_runner.py:382] Time since start: 163.23s, 	Step: 1, 	{'train/loss': 2.0516193044633004, 'validation/loss': 2.043297617977528, 'validation/num_examples': 89000000, 'test/loss': 2.0475290871247114, 'test/num_examples': 89274637}
I0405 06:26:27.610456 140634420852544 submission_runner.py:396] After eval at step 1: RAM USED (GB) 97.54374144
I0405 06:26:27.621018 140370326382336 logging_writer.py:48] [1] global_step=1, preemption_count=0, score=163.029944, test/loss=2.047529, test/num_examples=89274637, total_duration=163.226425, train/loss=2.051619, validation/loss=2.043298, validation/num_examples=89000000
I0405 06:26:32.651698 140634420852544 checkpoints.py:356] Saving checkpoint at step: 1
I0405 06:27:01.778481 140634420852544 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_momentum_v2/criteo1tb_jax/trial_1/checkpoint_1
I0405 06:27:02.118912 140634420852544 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum_v2/criteo1tb_jax/trial_1/checkpoint_1.
I0405 06:27:02.468536 140634420852544 submission_runner.py:416] After logging and checkpointing eval at step 1: RAM USED (GB) 97.602215936
I0405 06:27:02.471635 140634420852544 submission_runner.py:335] After dataselection batch at step 1: RAM USED (GB) 97.560805376
I0405 06:27:02.507281 140634420852544 submission_runner.py:352] After update parameters step 1: RAM USED (GB) 97.560272896
I0405 06:28:30.679900 140370317989632 logging_writer.py:48] [100] global_step=100, grad_norm=0.007732414174824953, loss=0.13951081037521362
I0405 06:30:36.837259 140370284418816 logging_writer.py:48] [200] global_step=200, grad_norm=0.016555942595005035, loss=0.13834010064601898
I0405 06:32:30.730977 140370317989632 logging_writer.py:48] [300] global_step=300, grad_norm=0.04712335020303726, loss=0.13741934299468994
I0405 06:34:47.749142 140370284418816 logging_writer.py:48] [400] global_step=400, grad_norm=0.10203946381807327, loss=0.1362631469964981
I0405 06:36:02.793310 140634420852544 submission_runner.py:373] Before eval at step 466: RAM USED (GB) 104.76015616
I0405 06:36:02.793524 140634420852544 spec.py:298] Evaluating on the training split.
I0405 06:46:31.512929 140634420852544 spec.py:310] Evaluating on the validation split.
I0405 06:50:56.520752 140634420852544 spec.py:326] Evaluating on the test split.
I0405 06:55:20.347173 140634420852544 submission_runner.py:382] Time since start: 1828.59s, 	Step: 466, 	{'train/loss': 0.1364789433651237, 'validation/loss': 0.13651758426966293, 'validation/num_examples': 89000000, 'test/loss': 0.13976108354268638, 'test/num_examples': 89274637}
I0405 06:55:20.347654 140634420852544 submission_runner.py:396] After eval at step 466: RAM USED (GB) 109.264289792
I0405 06:55:20.354734 140367668156160 logging_writer.py:48] [466] global_step=466, preemption_count=0, score=701.489072, test/loss=0.139761, test/num_examples=89274637, total_duration=1828.594742, train/loss=0.136479, validation/loss=0.136518, validation/num_examples=89000000
I0405 06:55:24.544502 140634420852544 checkpoints.py:356] Saving checkpoint at step: 466
I0405 06:55:48.736553 140634420852544 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_momentum_v2/criteo1tb_jax/trial_1/checkpoint_466
I0405 06:55:49.081661 140634420852544 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum_v2/criteo1tb_jax/trial_1/checkpoint_466.
I0405 06:55:49.430144 140634420852544 submission_runner.py:416] After logging and checkpointing eval at step 466: RAM USED (GB) 109.270933504
I0405 06:56:01.423575 140367584294656 logging_writer.py:48] [500] global_step=500, grad_norm=0.02211773954331875, loss=0.1373344212770462
I0405 06:57:53.893410 140367542331136 logging_writer.py:48] [600] global_step=600, grad_norm=0.04799797758460045, loss=0.13692216575145721
I0405 06:59:51.288597 140367584294656 logging_writer.py:48] [700] global_step=700, grad_norm=0.021091213449835777, loss=0.13475534319877625
I0405 07:01:42.954112 140634420852544 submission_runner.py:373] Before eval at step 800: RAM USED (GB) 110.697877504
I0405 07:01:42.954310 140634420852544 spec.py:298] Evaluating on the training split.
I0405 07:12:13.674183 140634420852544 spec.py:310] Evaluating on the validation split.
I0405 07:16:43.262535 140634420852544 spec.py:326] Evaluating on the test split.
I0405 07:20:59.994590 140634420852544 submission_runner.py:382] Time since start: 3368.76s, 	Step: 800, 	{'train/loss': 0.13723521341375783, 'validation/loss': 0.13692270786516855, 'validation/num_examples': 89000000, 'test/loss': 0.14017226415605588, 'test/num_examples': 89274637}
I0405 07:20:59.995056 140634420852544 submission_runner.py:396] After eval at step 800: RAM USED (GB) 113.901768704
I0405 07:21:00.002086 140367542331136 logging_writer.py:48] [800] global_step=800, preemption_count=0, score=1052.873469, test/loss=0.140172, test/num_examples=89274637, total_duration=3368.755517, train/loss=0.137235, validation/loss=0.136923, validation/num_examples=89000000
I0405 07:21:04.285641 140634420852544 checkpoints.py:356] Saving checkpoint at step: 800
I0405 07:21:28.039228 140634420852544 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_momentum_v2/criteo1tb_jax/trial_1/checkpoint_800
I0405 07:21:28.374936 140634420852544 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum_v2/criteo1tb_jax/trial_1/checkpoint_800.
I0405 07:21:28.708281 140634420852544 submission_runner.py:416] After logging and checkpointing eval at step 800: RAM USED (GB) 113.874722816
I0405 07:21:28.714221 140367584294656 logging_writer.py:48] [800] global_step=800, preemption_count=0, score=1052.873469
I0405 07:21:32.663961 140634420852544 checkpoints.py:356] Saving checkpoint at step: 800
I0405 07:22:05.189253 140634420852544 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_momentum_v2/criteo1tb_jax/trial_1/checkpoint_800
I0405 07:22:05.529039 140634420852544 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum_v2/criteo1tb_jax/trial_1/checkpoint_800.
I0405 07:23:39.628778 140634420852544 submission_runner.py:550] Tuning trial 1/1
I0405 07:23:39.629025 140634420852544 submission_runner.py:551] Hyperparameters: Hyperparameters(learning_rate=0.4394877561366806, one_minus_beta1=0.07113602458522507, warmup_factor=0.05, weight_decay=9.611851572925426e-07, label_smoothing=0.2, dropout_rate=0.0, decay_steps_factor=0.9, end_factor=0.001)
I0405 07:23:39.630367 140634420852544 submission_runner.py:552] Metrics: {'eval_results': [(1, {'train/loss': 2.0516193044633004, 'validation/loss': 2.043297617977528, 'validation/num_examples': 89000000, 'test/loss': 2.0475290871247114, 'test/num_examples': 89274637, 'score': 163.02994418144226, 'total_duration': 163.22642469406128, 'global_step': 1, 'preemption_count': 0}), (466, {'train/loss': 0.1364789433651237, 'validation/loss': 0.13651758426966293, 'validation/num_examples': 89000000, 'test/loss': 0.13976108354268638, 'test/num_examples': 89274637, 'score': 701.4890723228455, 'total_duration': 1828.5947420597076, 'global_step': 466, 'preemption_count': 0}), (800, {'train/loss': 0.13723521341375783, 'validation/loss': 0.13692270786516855, 'validation/num_examples': 89000000, 'test/loss': 0.14017226415605588, 'test/num_examples': 89274637, 'score': 1052.873468875885, 'total_duration': 3368.755516767502, 'global_step': 800, 'preemption_count': 0})], 'global_step': 800}
I0405 07:23:39.630512 140634420852544 submission_runner.py:553] Timing: 1052.873468875885
I0405 07:23:39.630567 140634420852544 submission_runner.py:554] ====================
I0405 07:23:39.630670 140634420852544 submission_runner.py:613] Final criteo1tb score: 1052.873468875885
