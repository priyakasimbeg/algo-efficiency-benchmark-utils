I0418 06:51:02.411078 139806287599424 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax.
I0418 06:51:02.478540 139806287599424 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0418 06:51:03.308330 139806287599424 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Host Interpreter CUDA
I0418 06:51:03.309109 139806287599424 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0418 06:51:03.313620 139806287599424 submission_runner.py:528] Using RNG seed 3655443431
I0418 06:51:05.994592 139806287599424 submission_runner.py:537] --- Tuning run 1/1 ---
I0418 06:51:05.994813 139806287599424 submission_runner.py:542] Creating tuning directory at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1.
I0418 06:51:05.995123 139806287599424 logger_utils.py:83] Saving hparams to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/hparams.json.
I0418 06:51:06.124449 139806287599424 submission_runner.py:232] Initializing dataset.
I0418 06:51:06.136469 139806287599424 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0418 06:51:06.143482 139806287599424 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0418 06:51:06.143597 139806287599424 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0418 06:51:06.409814 139806287599424 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0418 06:51:07.474418 139806287599424 submission_runner.py:239] Initializing model.
I0418 06:51:18.827986 139806287599424 submission_runner.py:249] Initializing optimizer.
I0418 06:51:19.773449 139806287599424 submission_runner.py:256] Initializing metrics bundle.
I0418 06:51:19.773626 139806287599424 submission_runner.py:273] Initializing checkpoint and logger.
I0418 06:51:19.774545 139806287599424 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1 with prefix checkpoint_
I0418 06:51:20.548302 139806287599424 submission_runner.py:294] Saving meta data to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/meta_data_0.json.
I0418 06:51:20.549215 139806287599424 submission_runner.py:297] Saving flags to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/flags_0.json.
I0418 06:51:20.554351 139806287599424 submission_runner.py:309] Starting training loop.
I0418 06:52:05.829242 139629814589184 logging_writer.py:48] [0] global_step=0, grad_norm=0.5518832206726074, loss=6.921898365020752
I0418 06:52:05.845276 139806287599424 spec.py:298] Evaluating on the training split.
I0418 06:52:06.348767 139806287599424 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0418 06:52:06.356038 139806287599424 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0418 06:52:06.356177 139806287599424 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0418 06:52:06.420745 139806287599424 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0418 06:52:18.096724 139806287599424 spec.py:310] Evaluating on the validation split.
I0418 06:52:18.774356 139806287599424 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0418 06:52:18.793942 139806287599424 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0418 06:52:18.794257 139806287599424 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0418 06:52:18.857391 139806287599424 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0418 06:52:36.536061 139806287599424 spec.py:326] Evaluating on the test split.
I0418 06:52:36.944090 139806287599424 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0418 06:52:36.949193 139806287599424 dataset_builder.py:510] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0418 06:52:36.979305 139806287599424 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0418 06:52:46.412662 139806287599424 submission_runner.py:406] Time since start: 85.86s, 	Step: 1, 	{'train/accuracy': 0.000498246168717742, 'train/loss': 6.912087917327881, 'validation/accuracy': 0.0007200000109151006, 'validation/loss': 6.91201114654541, 'validation/num_examples': 50000, 'test/accuracy': 0.0010999999940395355, 'test/loss': 6.91159725189209, 'test/num_examples': 10000, 'score': 45.290754079818726, 'total_duration': 85.85825777053833, 'accumulated_submission_time': 45.290754079818726, 'accumulated_eval_time': 40.567352533340454, 'accumulated_logging_time': 0}
I0418 06:52:46.433058 139598827079424 logging_writer.py:48] [1] accumulated_eval_time=40.567353, accumulated_logging_time=0, accumulated_submission_time=45.290754, global_step=1, preemption_count=0, score=45.290754, test/accuracy=0.001100, test/loss=6.911597, test/num_examples=10000, total_duration=85.858258, train/accuracy=0.000498, train/loss=6.912088, validation/accuracy=0.000720, validation/loss=6.912011, validation/num_examples=50000
I0418 06:52:46.562663 139806287599424 checkpoints.py:356] Saving checkpoint at step: 1
I0418 06:52:47.039978 139806287599424 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_1
I0418 06:52:47.041005 139806287599424 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_1.
I0418 06:53:20.585350 139598835472128 logging_writer.py:48] [100] global_step=100, grad_norm=0.5482761263847351, loss=6.8806867599487305
I0418 06:53:54.357215 139598978082560 logging_writer.py:48] [200] global_step=200, grad_norm=0.5608622431755066, loss=6.8055949211120605
I0418 06:54:27.889958 139598835472128 logging_writer.py:48] [300] global_step=300, grad_norm=0.6164282560348511, loss=6.6678996086120605
I0418 06:55:01.596795 139598978082560 logging_writer.py:48] [400] global_step=400, grad_norm=0.6357890367507935, loss=6.593734264373779
I0418 06:55:35.331957 139598835472128 logging_writer.py:48] [500] global_step=500, grad_norm=0.6798760294914246, loss=6.520267486572266
I0418 06:56:09.008072 139598978082560 logging_writer.py:48] [600] global_step=600, grad_norm=0.6353742480278015, loss=6.4713897705078125
I0418 06:56:42.785976 139598835472128 logging_writer.py:48] [700] global_step=700, grad_norm=0.8111631274223328, loss=6.4287495613098145
I0418 06:57:16.513168 139598978082560 logging_writer.py:48] [800] global_step=800, grad_norm=0.7370208501815796, loss=6.4038777351379395
I0418 06:57:50.187965 139598835472128 logging_writer.py:48] [900] global_step=900, grad_norm=0.7839468121528625, loss=6.299976348876953
I0418 06:58:23.746707 139598978082560 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.8773003220558167, loss=6.29144811630249
I0418 06:58:57.415405 139598835472128 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.7425953149795532, loss=6.1965250968933105
I0418 06:59:31.086493 139598978082560 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.8058832287788391, loss=6.179166793823242
I0418 07:00:04.853266 139598835472128 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.7538452744483948, loss=6.0932464599609375
I0418 07:00:38.481176 139598978082560 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.8089520335197449, loss=6.016618251800537
I0418 07:01:12.067106 139598835472128 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.763491153717041, loss=6.0753889083862305
I0418 07:01:17.170955 139806287599424 spec.py:298] Evaluating on the training split.
I0418 07:01:24.288779 139806287599424 spec.py:310] Evaluating on the validation split.
I0418 07:01:31.879076 139806287599424 spec.py:326] Evaluating on the test split.
I0418 07:01:33.897145 139806287599424 submission_runner.py:406] Time since start: 613.34s, 	Step: 1517, 	{'train/accuracy': 0.06804049760103226, 'train/loss': 5.495658874511719, 'validation/accuracy': 0.06165999919176102, 'validation/loss': 5.570715427398682, 'validation/num_examples': 50000, 'test/accuracy': 0.04750000312924385, 'test/loss': 5.7846598625183105, 'test/num_examples': 10000, 'score': 555.3963661193848, 'total_duration': 613.3427405357361, 'accumulated_submission_time': 555.3963661193848, 'accumulated_eval_time': 57.29352331161499, 'accumulated_logging_time': 0.6328208446502686}
I0418 07:01:33.905950 139599070336768 logging_writer.py:48] [1517] accumulated_eval_time=57.293523, accumulated_logging_time=0.632821, accumulated_submission_time=555.396366, global_step=1517, preemption_count=0, score=555.396366, test/accuracy=0.047500, test/loss=5.784660, test/num_examples=10000, total_duration=613.342741, train/accuracy=0.068040, train/loss=5.495659, validation/accuracy=0.061660, validation/loss=5.570715, validation/num_examples=50000
I0418 07:01:34.026808 139806287599424 checkpoints.py:356] Saving checkpoint at step: 1517
I0418 07:01:34.466952 139806287599424 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_1517
I0418 07:01:34.467792 139806287599424 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_1517.
I0418 07:02:02.770933 139599078729472 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.8424103260040283, loss=5.99918794631958
I0418 07:02:36.406751 139629915236096 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.8007538914680481, loss=5.941282749176025
I0418 07:03:10.064055 139599078729472 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.8075352311134338, loss=5.917960166931152
I0418 07:03:43.640625 139629915236096 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.9203903079032898, loss=5.796394348144531
I0418 07:04:17.337246 139599078729472 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.9192780256271362, loss=5.8144426345825195
I0418 07:04:50.940517 139629915236096 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.9141432046890259, loss=5.668828964233398
I0418 07:05:24.636125 139599078729472 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.9439048767089844, loss=5.6553168296813965
I0418 07:05:58.244479 139629915236096 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.9596708416938782, loss=5.5838117599487305
I0418 07:06:31.854149 139599078729472 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.906670868396759, loss=5.534878253936768
I0418 07:07:05.483937 139629915236096 logging_writer.py:48] [2500] global_step=2500, grad_norm=1.0177727937698364, loss=5.530496120452881
I0418 07:07:39.026732 139599078729472 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.8868845701217651, loss=5.421916484832764
I0418 07:08:12.616402 139629915236096 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.9896079897880554, loss=5.446877956390381
I0418 07:08:46.190658 139599078729472 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.8300177454948425, loss=5.338164329528809
I0418 07:09:19.754505 139629915236096 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.8342218399047852, loss=5.290741443634033
I0418 07:09:53.348059 139599078729472 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.8434287309646606, loss=5.2409491539001465
I0418 07:10:04.539772 139806287599424 spec.py:298] Evaluating on the training split.
I0418 07:10:11.327146 139806287599424 spec.py:310] Evaluating on the validation split.
I0418 07:10:19.045090 139806287599424 spec.py:326] Evaluating on the test split.
I0418 07:10:21.210327 139806287599424 submission_runner.py:406] Time since start: 1140.66s, 	Step: 3035, 	{'train/accuracy': 0.17629942297935486, 'train/loss': 4.2949748039245605, 'validation/accuracy': 0.16213999688625336, 'validation/loss': 4.408034801483154, 'validation/num_examples': 50000, 'test/accuracy': 0.11800000816583633, 'test/loss': 4.869681358337402, 'test/num_examples': 10000, 'score': 1065.445555448532, 'total_duration': 1140.6559178829193, 'accumulated_submission_time': 1065.445555448532, 'accumulated_eval_time': 73.96405172348022, 'accumulated_logging_time': 1.207042932510376}
I0418 07:10:21.218908 139629915236096 logging_writer.py:48] [3035] accumulated_eval_time=73.964052, accumulated_logging_time=1.207043, accumulated_submission_time=1065.445555, global_step=3035, preemption_count=0, score=1065.445555, test/accuracy=0.118000, test/loss=4.869681, test/num_examples=10000, total_duration=1140.655918, train/accuracy=0.176299, train/loss=4.294975, validation/accuracy=0.162140, validation/loss=4.408035, validation/num_examples=50000
I0418 07:10:21.331181 139806287599424 checkpoints.py:356] Saving checkpoint at step: 3035
I0418 07:10:21.767936 139806287599424 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_3035
I0418 07:10:21.768814 139806287599424 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_3035.
I0418 07:10:43.961265 139599078729472 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.7500239610671997, loss=5.069585800170898
I0418 07:11:17.429935 139629881665280 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.8232827186584473, loss=5.140710353851318
I0418 07:11:50.902154 139599078729472 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.8347134590148926, loss=5.080266952514648
I0418 07:12:24.381460 139629881665280 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.8412225842475891, loss=5.042006015777588
I0418 07:12:57.845562 139599078729472 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.7536492347717285, loss=5.0157976150512695
I0418 07:13:31.316100 139629881665280 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.7832197546958923, loss=4.951733589172363
I0418 07:14:04.849396 139599078729472 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.7813795804977417, loss=4.966694355010986
I0418 07:14:38.253187 139629881665280 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.7849035859107971, loss=4.888638973236084
I0418 07:15:11.621267 139599078729472 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.7676668167114258, loss=4.829634666442871
I0418 07:15:45.061853 139599078729472 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.7575512528419495, loss=4.781793117523193
I0418 07:16:18.615498 139629881665280 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.7353567481040955, loss=4.825493812561035
I0418 07:16:52.006683 139599078729472 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.7772866487503052, loss=4.811094284057617
I0418 07:17:25.370966 139629881665280 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.7695311903953552, loss=4.7766313552856445
I0418 07:17:58.808829 139599078729472 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.7463621497154236, loss=4.725172519683838
I0418 07:18:32.255656 139629881665280 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.7430127859115601, loss=4.670701026916504
I0418 07:18:52.035478 139806287599424 spec.py:298] Evaluating on the training split.
I0418 07:18:58.710555 139806287599424 spec.py:310] Evaluating on the validation split.
I0418 07:19:06.560462 139806287599424 spec.py:326] Evaluating on the test split.
I0418 07:19:08.603293 139806287599424 submission_runner.py:406] Time since start: 1668.05s, 	Step: 4561, 	{'train/accuracy': 0.28694993257522583, 'train/loss': 3.6841280460357666, 'validation/accuracy': 0.26589998602867126, 'validation/loss': 3.794222354888916, 'validation/num_examples': 50000, 'test/accuracy': 0.19380000233650208, 'test/loss': 4.308399200439453, 'test/num_examples': 10000, 'score': 1575.6886417865753, 'total_duration': 1668.0488846302032, 'accumulated_submission_time': 1575.6886417865753, 'accumulated_eval_time': 90.53183794021606, 'accumulated_logging_time': 1.7701473236083984}
I0418 07:19:08.610806 139599078729472 logging_writer.py:48] [4561] accumulated_eval_time=90.531838, accumulated_logging_time=1.770147, accumulated_submission_time=1575.688642, global_step=4561, preemption_count=0, score=1575.688642, test/accuracy=0.193800, test/loss=4.308399, test/num_examples=10000, total_duration=1668.048885, train/accuracy=0.286950, train/loss=3.684128, validation/accuracy=0.265900, validation/loss=3.794222, validation/num_examples=50000
I0418 07:19:08.751596 139806287599424 checkpoints.py:356] Saving checkpoint at step: 4561
I0418 07:19:09.325940 139806287599424 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_4561
I0418 07:19:09.326683 139806287599424 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_4561.
I0418 07:19:22.779613 139629881665280 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.7214353680610657, loss=4.676698684692383
I0418 07:19:56.747158 139629873272576 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.7540838122367859, loss=4.563953876495361
I0418 07:20:30.668859 139629881665280 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.7840480804443359, loss=4.563225746154785
I0418 07:21:04.335003 139629873272576 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.7477281093597412, loss=4.617591381072998
I0418 07:21:38.018527 139629881665280 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.6745039224624634, loss=4.535796642303467
I0418 07:22:11.881875 139629873272576 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.6670953631401062, loss=4.489156723022461
I0418 07:22:45.709401 139629881665280 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.6624823808670044, loss=4.501302719116211
I0418 07:23:19.562213 139629873272576 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.683521032333374, loss=4.396823406219482
I0418 07:23:53.549260 139629881665280 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.6775971055030823, loss=4.404347896575928
I0418 07:24:27.290598 139629873272576 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.6674606204032898, loss=4.363424777984619
I0418 07:25:00.914490 139629881665280 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.6430043578147888, loss=4.447941780090332
I0418 07:25:34.575302 139629873272576 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.646967351436615, loss=4.304460525512695
I0418 07:26:08.333036 139629881665280 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.6904386878013611, loss=4.421194553375244
I0418 07:26:41.974370 139629873272576 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.6399739384651184, loss=4.217041015625
I0418 07:27:15.807904 139629881665280 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.6725894212722778, loss=4.379202842712402
I0418 07:27:39.566537 139806287599424 spec.py:298] Evaluating on the training split.
I0418 07:27:46.253925 139806287599424 spec.py:310] Evaluating on the validation split.
I0418 07:27:53.974753 139806287599424 spec.py:326] Evaluating on the test split.
I0418 07:27:56.079285 139806287599424 submission_runner.py:406] Time since start: 2195.52s, 	Step: 6072, 	{'train/accuracy': 0.41153138875961304, 'train/loss': 2.84822678565979, 'validation/accuracy': 0.3870599865913391, 'validation/loss': 2.9815428256988525, 'validation/num_examples': 50000, 'test/accuracy': 0.2849000096321106, 'test/loss': 3.6075971126556396, 'test/num_examples': 10000, 'score': 2085.9054946899414, 'total_duration': 2195.524883747101, 'accumulated_submission_time': 2085.9054946899414, 'accumulated_eval_time': 107.04456520080566, 'accumulated_logging_time': 2.4978771209716797}
I0418 07:27:56.087123 139629873272576 logging_writer.py:48] [6072] accumulated_eval_time=107.044565, accumulated_logging_time=2.497877, accumulated_submission_time=2085.905495, global_step=6072, preemption_count=0, score=2085.905495, test/accuracy=0.284900, test/loss=3.607597, test/num_examples=10000, total_duration=2195.524884, train/accuracy=0.411531, train/loss=2.848227, validation/accuracy=0.387060, validation/loss=2.981543, validation/num_examples=50000
I0418 07:27:56.187859 139806287599424 checkpoints.py:356] Saving checkpoint at step: 6072
I0418 07:27:56.616577 139806287599424 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_6072
I0418 07:27:56.617475 139806287599424 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_6072.
I0418 07:28:06.449363 139629881665280 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.6620017290115356, loss=4.252418518066406
I0418 07:28:40.184236 139627105089280 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.6383252143859863, loss=4.227264881134033
I0418 07:29:13.792593 139629881665280 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.6439220309257507, loss=4.241462707519531
I0418 07:29:47.490591 139627105089280 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.660295307636261, loss=4.226624488830566
I0418 07:30:21.086588 139629881665280 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.6082310676574707, loss=4.265259265899658
I0418 07:30:54.808312 139627105089280 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.6280847787857056, loss=4.092622756958008
I0418 07:31:28.764460 139629881665280 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.586294412612915, loss=4.131948471069336
I0418 07:32:02.446026 139627105089280 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.6172401309013367, loss=4.120389938354492
I0418 07:32:36.023609 139629881665280 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.5838316082954407, loss=4.146642208099365
I0418 07:33:09.840690 139627105089280 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.572892427444458, loss=4.054154396057129
I0418 07:33:43.561691 139629881665280 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.6061940789222717, loss=4.112326145172119
I0418 07:34:17.525390 139627105089280 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.5839638710021973, loss=4.0739054679870605
I0418 07:34:51.119567 139629881665280 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.5745587348937988, loss=3.9857869148254395
I0418 07:35:24.848563 139627105089280 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.5746714472770691, loss=3.986738681793213
I0418 07:35:58.683998 139629881665280 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.5867283940315247, loss=4.066871166229248
I0418 07:36:26.891482 139806287599424 spec.py:298] Evaluating on the training split.
I0418 07:36:33.770598 139806287599424 spec.py:310] Evaluating on the validation split.
I0418 07:36:41.402574 139806287599424 spec.py:326] Evaluating on the test split.
I0418 07:36:43.511830 139806287599424 submission_runner.py:406] Time since start: 2722.96s, 	Step: 7585, 	{'train/accuracy': 0.4882214367389679, 'train/loss': 2.436321973800659, 'validation/accuracy': 0.4597399830818176, 'validation/loss': 2.57297682762146, 'validation/num_examples': 50000, 'test/accuracy': 0.34550002217292786, 'test/loss': 3.2313969135284424, 'test/num_examples': 10000, 'score': 2596.156266450882, 'total_duration': 2722.9574015140533, 'accumulated_submission_time': 2596.156266450882, 'accumulated_eval_time': 123.66486310958862, 'accumulated_logging_time': 3.0402286052703857}
I0418 07:36:43.521652 139627105089280 logging_writer.py:48] [7585] accumulated_eval_time=123.664863, accumulated_logging_time=3.040229, accumulated_submission_time=2596.156266, global_step=7585, preemption_count=0, score=2596.156266, test/accuracy=0.345500, test/loss=3.231397, test/num_examples=10000, total_duration=2722.957402, train/accuracy=0.488221, train/loss=2.436322, validation/accuracy=0.459740, validation/loss=2.572977, validation/num_examples=50000
I0418 07:36:43.653740 139806287599424 checkpoints.py:356] Saving checkpoint at step: 7585
I0418 07:36:44.348112 139806287599424 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_7585
I0418 07:36:44.358372 139806287599424 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_7585.
I0418 07:36:49.768671 139629881665280 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.55940181016922, loss=3.984276294708252
I0418 07:37:23.467846 139627042146048 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.5836414694786072, loss=4.021534442901611
I0418 07:37:57.098369 139629881665280 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.5493971705436707, loss=4.041460037231445
I0418 07:38:30.685493 139627042146048 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.5569943785667419, loss=3.9329214096069336
I0418 07:39:04.260093 139629881665280 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.5716512203216553, loss=4.005030155181885
I0418 07:39:37.790766 139627042146048 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.5609994530677795, loss=3.955579996109009
I0418 07:40:11.460234 139629881665280 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.5437020659446716, loss=3.9869437217712402
I0418 07:40:44.999618 139627042146048 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.5498050451278687, loss=3.9979805946350098
I0418 07:41:18.808350 139629881665280 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.5582191348075867, loss=3.919797658920288
I0418 07:41:52.378034 139627042146048 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.5384359359741211, loss=3.866478443145752
I0418 07:42:26.124659 139629881665280 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.5279917120933533, loss=3.8968729972839355
I0418 07:42:59.852195 139627042146048 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.5580834746360779, loss=3.9057037830352783
I0418 07:43:33.609736 139629881665280 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.5136523246765137, loss=3.860670804977417
I0418 07:44:07.318056 139627042146048 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.5311873555183411, loss=3.837360143661499
I0418 07:44:41.120876 139629881665280 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.5078689455986023, loss=3.889606475830078
I0418 07:45:14.794406 139627042146048 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.5340825319290161, loss=3.8497915267944336
I0418 07:45:14.801281 139806287599424 spec.py:298] Evaluating on the training split.
I0418 07:45:21.748438 139806287599424 spec.py:310] Evaluating on the validation split.
I0418 07:45:29.833597 139806287599424 spec.py:326] Evaluating on the test split.
I0418 07:45:35.165608 139806287599424 submission_runner.py:406] Time since start: 3254.61s, 	Step: 9101, 	{'train/accuracy': 0.5744778513908386, 'train/loss': 2.0647923946380615, 'validation/accuracy': 0.5044000148773193, 'validation/loss': 2.389333486557007, 'validation/num_examples': 50000, 'test/accuracy': 0.38690000772476196, 'test/loss': 3.043952465057373, 'test/num_examples': 10000, 'score': 3106.572959423065, 'total_duration': 3254.6111357212067, 'accumulated_submission_time': 3106.572959423065, 'accumulated_eval_time': 144.0290868282318, 'accumulated_logging_time': 3.894094228744507}
I0418 07:45:35.180452 139629881665280 logging_writer.py:48] [9101] accumulated_eval_time=144.029087, accumulated_logging_time=3.894094, accumulated_submission_time=3106.572959, global_step=9101, preemption_count=0, score=3106.572959, test/accuracy=0.386900, test/loss=3.043952, test/num_examples=10000, total_duration=3254.611136, train/accuracy=0.574478, train/loss=2.064792, validation/accuracy=0.504400, validation/loss=2.389333, validation/num_examples=50000
I0418 07:45:35.318253 139806287599424 checkpoints.py:356] Saving checkpoint at step: 9101
I0418 07:45:35.901718 139806287599424 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_9101
I0418 07:45:35.903081 139806287599424 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_9101.
I0418 07:46:09.658022 139627042146048 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.5061187148094177, loss=3.8270392417907715
I0418 07:46:43.115844 139627033753344 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.5285006165504456, loss=3.7949070930480957
I0418 07:47:16.863463 139627042146048 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.5019471049308777, loss=3.864265203475952
I0418 07:47:50.549329 139627033753344 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.48575982451438904, loss=3.8031699657440186
I0418 07:48:24.109363 139627042146048 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.5031613707542419, loss=3.7275655269622803
I0418 07:48:57.845442 139627033753344 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.5216137766838074, loss=3.867431163787842
I0418 07:49:31.483339 139627042146048 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.5073896646499634, loss=3.797773838043213
I0418 07:50:05.247023 139627033753344 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.5026700496673584, loss=3.787987232208252
I0418 07:50:38.809183 139627042146048 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.5145412087440491, loss=3.7667179107666016
I0418 07:51:12.489717 139627033753344 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.5271217226982117, loss=3.7716517448425293
I0418 07:51:46.158021 139627042146048 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.5030580759048462, loss=3.7133541107177734
I0418 07:52:19.726864 139627033753344 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.5001348853111267, loss=3.9020352363586426
I0418 07:52:53.473264 139627042146048 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.5078453421592712, loss=3.7634572982788086
I0418 07:53:27.277411 139627033753344 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.5089465975761414, loss=3.7919187545776367
I0418 07:54:00.844057 139627042146048 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.4916156530380249, loss=3.7230312824249268
I0418 07:54:05.990296 139806287599424 spec.py:298] Evaluating on the training split.
I0418 07:54:12.910761 139806287599424 spec.py:310] Evaluating on the validation split.
I0418 07:54:21.612022 139806287599424 spec.py:326] Evaluating on the test split.
I0418 07:54:23.712828 139806287599424 submission_runner.py:406] Time since start: 3783.16s, 	Step: 10617, 	{'train/accuracy': 0.5949258208274841, 'train/loss': 1.9082883596420288, 'validation/accuracy': 0.5393199920654297, 'validation/loss': 2.1746654510498047, 'validation/num_examples': 50000, 'test/accuracy': 0.42080003023147583, 'test/loss': 2.841557025909424, 'test/num_examples': 10000, 'score': 3616.634914159775, 'total_duration': 3783.1584243774414, 'accumulated_submission_time': 3616.634914159775, 'accumulated_eval_time': 161.75159120559692, 'accumulated_logging_time': 4.637449741363525}
I0418 07:54:23.721411 139627033753344 logging_writer.py:48] [10617] accumulated_eval_time=161.751591, accumulated_logging_time=4.637450, accumulated_submission_time=3616.634914, global_step=10617, preemption_count=0, score=3616.634914, test/accuracy=0.420800, test/loss=2.841557, test/num_examples=10000, total_duration=3783.158424, train/accuracy=0.594926, train/loss=1.908288, validation/accuracy=0.539320, validation/loss=2.174665, validation/num_examples=50000
I0418 07:54:23.891877 139806287599424 checkpoints.py:356] Saving checkpoint at step: 10617
I0418 07:54:24.563359 139806287599424 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_10617
I0418 07:54:24.572941 139806287599424 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_10617.
I0418 07:54:52.914402 139627042146048 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.483203262090683, loss=3.7114717960357666
I0418 07:55:26.532644 139629797803776 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.4904044568538666, loss=3.6455657482147217
I0418 07:56:00.183212 139627042146048 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.5035573840141296, loss=3.6278796195983887
I0418 07:56:34.040592 139629797803776 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.4792667031288147, loss=3.6752288341522217
I0418 07:57:07.808494 139627042146048 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.4686005115509033, loss=3.6146180629730225
I0418 07:57:41.526213 139629797803776 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.49974751472473145, loss=3.6205055713653564
I0418 07:58:15.254245 139627042146048 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.48179948329925537, loss=3.661216974258423
I0418 07:58:48.919946 139629797803776 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.48661375045776367, loss=3.682286024093628
I0418 07:59:22.558334 139627042146048 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.49070751667022705, loss=3.728668451309204
I0418 07:59:56.266244 139629797803776 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.48232534527778625, loss=3.6720163822174072
I0418 08:00:29.983644 139627042146048 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.47680893540382385, loss=3.5453271865844727
I0418 08:01:03.744139 139629797803776 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.45709890127182007, loss=3.6206159591674805
I0418 08:01:37.380158 139627042146048 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.4692882001399994, loss=3.620887041091919
I0418 08:02:10.953860 139629797803776 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.47398194670677185, loss=3.5562710762023926
I0418 08:02:44.693988 139627042146048 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.4601637125015259, loss=3.5356764793395996
I0418 08:02:54.899144 139806287599424 spec.py:298] Evaluating on the training split.
I0418 08:03:01.859213 139806287599424 spec.py:310] Evaluating on the validation split.
I0418 08:03:11.383153 139806287599424 spec.py:326] Evaluating on the test split.
I0418 08:03:13.483970 139806287599424 submission_runner.py:406] Time since start: 4312.93s, 	Step: 12132, 	{'train/accuracy': 0.6129224896430969, 'train/loss': 1.8483002185821533, 'validation/accuracy': 0.5625999569892883, 'validation/loss': 2.0832631587982178, 'validation/num_examples': 50000, 'test/accuracy': 0.4385000169277191, 'test/loss': 2.7482147216796875, 'test/num_examples': 10000, 'score': 4126.938717126846, 'total_duration': 4312.928356409073, 'accumulated_submission_time': 4126.938717126846, 'accumulated_eval_time': 180.33518075942993, 'accumulated_logging_time': 5.50101113319397}
I0418 08:03:13.493824 139629797803776 logging_writer.py:48] [12132] accumulated_eval_time=180.335181, accumulated_logging_time=5.501011, accumulated_submission_time=4126.938717, global_step=12132, preemption_count=0, score=4126.938717, test/accuracy=0.438500, test/loss=2.748215, test/num_examples=10000, total_duration=4312.928356, train/accuracy=0.612922, train/loss=1.848300, validation/accuracy=0.562600, validation/loss=2.083263, validation/num_examples=50000
I0418 08:03:13.670761 139806287599424 checkpoints.py:356] Saving checkpoint at step: 12132
I0418 08:03:14.342744 139806287599424 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_12132
I0418 08:03:14.351574 139806287599424 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_12132.
I0418 08:03:37.730634 139627042146048 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.4718376696109772, loss=3.5341508388519287
I0418 08:04:11.528033 139629764232960 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.5000680088996887, loss=3.637754201889038
I0418 08:04:45.119965 139627042146048 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.4829174876213074, loss=3.565995454788208
I0418 08:05:18.855475 139629764232960 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.4706477224826813, loss=3.6504318714141846
I0418 08:05:52.419484 139627042146048 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.46547576785087585, loss=3.612494468688965
I0418 08:06:26.077465 139629764232960 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.4645082354545593, loss=3.4641995429992676
I0418 08:06:59.904334 139627042146048 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.4812147319316864, loss=3.573910713195801
I0418 08:07:33.643647 139629764232960 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.4774247705936432, loss=3.5729331970214844
I0418 08:08:07.221829 139627042146048 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.4664432406425476, loss=3.510547399520874
I0418 08:08:40.718135 139629764232960 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.463207870721817, loss=3.484158992767334
I0418 08:09:14.319707 139627042146048 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.46589869260787964, loss=3.608445405960083
I0418 08:09:47.890339 139629764232960 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.45952388644218445, loss=3.4555578231811523
I0418 08:10:21.602374 139627042146048 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.47086796164512634, loss=3.5391199588775635
I0418 08:10:55.163961 139629764232960 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.47069329023361206, loss=3.5070295333862305
I0418 08:11:28.989836 139627042146048 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.4765695333480835, loss=3.560298204421997
I0418 08:11:44.553265 139806287599424 spec.py:298] Evaluating on the training split.
I0418 08:11:52.237816 139806287599424 spec.py:310] Evaluating on the validation split.
I0418 08:12:01.918044 139806287599424 spec.py:326] Evaluating on the test split.
I0418 08:12:03.990640 139806287599424 submission_runner.py:406] Time since start: 4843.44s, 	Step: 13648, 	{'train/accuracy': 0.6428571343421936, 'train/loss': 1.653601884841919, 'validation/accuracy': 0.5873399972915649, 'validation/loss': 1.9157840013504028, 'validation/num_examples': 50000, 'test/accuracy': 0.45920002460479736, 'test/loss': 2.585918426513672, 'test/num_examples': 10000, 'score': 4637.1129784584045, 'total_duration': 4843.43536567688, 'accumulated_submission_time': 4637.1129784584045, 'accumulated_eval_time': 199.77165699005127, 'accumulated_logging_time': 6.3766090869903564}
I0418 08:12:04.004038 139629764232960 logging_writer.py:48] [13648] accumulated_eval_time=199.771657, accumulated_logging_time=6.376609, accumulated_submission_time=4637.112978, global_step=13648, preemption_count=0, score=4637.112978, test/accuracy=0.459200, test/loss=2.585918, test/num_examples=10000, total_duration=4843.435366, train/accuracy=0.642857, train/loss=1.653602, validation/accuracy=0.587340, validation/loss=1.915784, validation/num_examples=50000
I0418 08:12:04.189606 139806287599424 checkpoints.py:356] Saving checkpoint at step: 13648
I0418 08:12:04.883828 139806287599424 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_13648
I0418 08:12:04.895704 139806287599424 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_13648.
I0418 08:12:22.825958 139627042146048 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.45734304189682007, loss=3.492292881011963
I0418 08:12:56.404046 139629755840256 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.4762054979801178, loss=3.5497584342956543
I0418 08:13:30.122482 139627042146048 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.4684657156467438, loss=3.5048205852508545
I0418 08:14:03.777396 139629755840256 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.46265652775764465, loss=3.454418897628784
I0418 08:14:37.538039 139627042146048 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.4834943413734436, loss=3.5047223567962646
I0418 08:15:11.072392 139629755840256 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.46417713165283203, loss=3.496408462524414
I0418 08:15:44.465692 139627042146048 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.46184906363487244, loss=3.433903217315674
I0418 08:16:18.077750 139629755840256 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.47335588932037354, loss=3.461200714111328
I0418 08:16:51.753250 139627042146048 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.46405845880508423, loss=3.475113868713379
I0418 08:17:25.346785 139629755840256 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.44942644238471985, loss=3.438275098800659
I0418 08:17:58.960968 139627042146048 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.46128976345062256, loss=3.4091718196868896
I0418 08:18:32.580694 139629755840256 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.46212393045425415, loss=3.481174945831299
I0418 08:19:06.267729 139627042146048 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.4587118625640869, loss=3.515054702758789
I0418 08:19:39.975201 139629755840256 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.45681509375572205, loss=3.497441053390503
I0418 08:20:13.657314 139627042146048 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.45348769426345825, loss=3.3809242248535156
I0418 08:20:35.034231 139806287599424 spec.py:298] Evaluating on the training split.
I0418 08:20:42.031707 139806287599424 spec.py:310] Evaluating on the validation split.
I0418 08:20:51.814641 139806287599424 spec.py:326] Evaluating on the test split.
I0418 08:20:53.918755 139806287599424 submission_runner.py:406] Time since start: 5373.36s, 	Step: 15165, 	{'train/accuracy': 0.6674705147743225, 'train/loss': 1.6089122295379639, 'validation/accuracy': 0.6066399812698364, 'validation/loss': 1.867356300354004, 'validation/num_examples': 50000, 'test/accuracy': 0.48580002784729004, 'test/loss': 2.506627321243286, 'test/num_examples': 10000, 'score': 5147.226816177368, 'total_duration': 5373.363177776337, 'accumulated_submission_time': 5147.226816177368, 'accumulated_eval_time': 218.6549837589264, 'accumulated_logging_time': 7.28728985786438}
I0418 08:20:53.927802 139629755840256 logging_writer.py:48] [15165] accumulated_eval_time=218.654984, accumulated_logging_time=7.287290, accumulated_submission_time=5147.226816, global_step=15165, preemption_count=0, score=5147.226816, test/accuracy=0.485800, test/loss=2.506627, test/num_examples=10000, total_duration=5373.363178, train/accuracy=0.667471, train/loss=1.608912, validation/accuracy=0.606640, validation/loss=1.867356, validation/num_examples=50000
I0418 08:20:54.079510 139806287599424 checkpoints.py:356] Saving checkpoint at step: 15165
I0418 08:20:54.760091 139806287599424 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_15165
I0418 08:20:54.768938 139806287599424 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_15165.
I0418 08:21:06.827044 139627042146048 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.47509703040122986, loss=3.575917959213257
I0418 08:21:40.274240 139629747447552 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.45658624172210693, loss=3.4202964305877686
I0418 08:22:13.826865 139627042146048 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.47139936685562134, loss=3.543700695037842
I0418 08:22:47.297820 139629747447552 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.44378146529197693, loss=3.4135921001434326
I0418 08:23:20.763420 139627042146048 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.4694140553474426, loss=3.402534008026123
I0418 08:23:54.124908 139629747447552 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.4508798122406006, loss=3.4267935752868652
I0418 08:24:27.499078 139627042146048 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.46792903542518616, loss=3.378946304321289
I0418 08:25:00.988515 139629747447552 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.44936126470565796, loss=3.435687303543091
I0418 08:25:34.427137 139627042146048 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.4479195773601532, loss=3.392547130584717
I0418 08:26:07.772989 139629747447552 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.45610931515693665, loss=3.400566339492798
I0418 08:26:41.240614 139627042146048 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.46304652094841003, loss=3.361429214477539
I0418 08:27:14.555083 139629747447552 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.4455863833427429, loss=3.3327767848968506
I0418 08:27:47.946920 139627042146048 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.44804561138153076, loss=3.4156150817871094
I0418 08:28:21.354005 139629747447552 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.4674312472343445, loss=3.3380613327026367
I0418 08:28:54.652008 139627042146048 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.4813251495361328, loss=3.4860341548919678
I0418 08:29:25.028991 139806287599424 spec.py:298] Evaluating on the training split.
I0418 08:29:32.790504 139806287599424 spec.py:310] Evaluating on the validation split.
I0418 08:29:42.916511 139806287599424 spec.py:326] Evaluating on the test split.
I0418 08:29:45.001280 139806287599424 submission_runner.py:406] Time since start: 5904.45s, 	Step: 16693, 	{'train/accuracy': 0.6827367544174194, 'train/loss': 1.546028733253479, 'validation/accuracy': 0.6244800090789795, 'validation/loss': 1.8056902885437012, 'validation/num_examples': 50000, 'test/accuracy': 0.4975000321865082, 'test/loss': 2.4646224975585938, 'test/num_examples': 10000, 'score': 5657.463678121567, 'total_duration': 5904.445741891861, 'accumulated_submission_time': 5657.463678121567, 'accumulated_eval_time': 238.62613463401794, 'accumulated_logging_time': 8.14136004447937}
I0418 08:29:45.015119 139629747447552 logging_writer.py:48] [16693] accumulated_eval_time=238.626135, accumulated_logging_time=8.141360, accumulated_submission_time=5657.463678, global_step=16693, preemption_count=0, score=5657.463678, test/accuracy=0.497500, test/loss=2.464622, test/num_examples=10000, total_duration=5904.445742, train/accuracy=0.682737, train/loss=1.546029, validation/accuracy=0.624480, validation/loss=1.805690, validation/num_examples=50000
I0418 08:29:45.188666 139806287599424 checkpoints.py:356] Saving checkpoint at step: 16693
I0418 08:29:45.883771 139806287599424 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_16693
I0418 08:29:45.894312 139806287599424 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_16693.
I0418 08:29:48.645371 139627042146048 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.45580583810806274, loss=3.3593404293060303
I0418 08:30:22.257771 139629739054848 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.4800380766391754, loss=3.4922826290130615
I0418 08:30:55.834815 139627042146048 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.4656233787536621, loss=3.433976173400879
I0418 08:31:29.351122 139629739054848 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.4510423541069031, loss=3.419766664505005
I0418 08:32:02.807065 139627042146048 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.45173177123069763, loss=3.366349935531616
I0418 08:32:36.423656 139629739054848 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.4683278799057007, loss=3.407963991165161
I0418 08:33:10.017702 139627042146048 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.4585583508014679, loss=3.3466756343841553
I0418 08:33:43.529342 139629739054848 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.4484293758869171, loss=3.3380701541900635
I0418 08:34:16.987341 139627042146048 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.4441656768321991, loss=3.353043556213379
I0418 08:34:50.591803 139629739054848 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.4437459111213684, loss=3.360860586166382
I0418 08:35:23.992910 139627042146048 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.4520972967147827, loss=3.305307388305664
I0418 08:35:57.435124 139629739054848 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.44637244939804077, loss=3.329692840576172
I0418 08:36:30.808263 139627042146048 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.4435480833053589, loss=3.2825634479522705
I0418 08:37:04.283422 139629739054848 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.42471548914909363, loss=3.2278575897216797
I0418 08:37:37.687728 139627042146048 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.44394928216934204, loss=3.378160238265991
I0418 08:38:11.037190 139629739054848 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.47062215209007263, loss=3.4327046871185303
I0418 08:38:16.103943 139806287599424 spec.py:298] Evaluating on the training split.
I0418 08:38:23.568913 139806287599424 spec.py:310] Evaluating on the validation split.
I0418 08:38:33.358574 139806287599424 spec.py:326] Evaluating on the test split.
I0418 08:38:35.278055 139806287599424 submission_runner.py:406] Time since start: 6434.72s, 	Step: 18217, 	{'train/accuracy': 0.7250677347183228, 'train/loss': 1.3594605922698975, 'validation/accuracy': 0.6313599944114685, 'validation/loss': 1.757285714149475, 'validation/num_examples': 50000, 'test/accuracy': 0.5005000233650208, 'test/loss': 2.428614854812622, 'test/num_examples': 10000, 'score': 6167.649668216705, 'total_duration': 6434.722566843033, 'accumulated_submission_time': 6167.649668216705, 'accumulated_eval_time': 257.7991318702698, 'accumulated_logging_time': 9.03877592086792}
I0418 08:38:35.288048 139627042146048 logging_writer.py:48] [18217] accumulated_eval_time=257.799132, accumulated_logging_time=9.038776, accumulated_submission_time=6167.649668, global_step=18217, preemption_count=0, score=6167.649668, test/accuracy=0.500500, test/loss=2.428615, test/num_examples=10000, total_duration=6434.722567, train/accuracy=0.725068, train/loss=1.359461, validation/accuracy=0.631360, validation/loss=1.757286, validation/num_examples=50000
I0418 08:38:35.446710 139806287599424 checkpoints.py:356] Saving checkpoint at step: 18217
I0418 08:38:36.129703 139806287599424 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_18217
I0418 08:38:36.141191 139806287599424 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_18217.
I0418 08:39:04.418364 139629739054848 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.44674378633499146, loss=3.335723876953125
I0418 08:39:38.003080 139629521008384 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.46668052673339844, loss=3.3311607837677
I0418 08:40:11.616573 139629739054848 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.4578205645084381, loss=3.2653424739837646
I0418 08:40:45.331959 139629521008384 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.44361722469329834, loss=3.3060803413391113
I0418 08:41:18.915927 139629739054848 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.45657122135162354, loss=3.319164752960205
I0418 08:41:52.584872 139629521008384 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.4332960844039917, loss=3.2885847091674805
I0418 08:42:26.277503 139629739054848 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.4764273166656494, loss=3.414945363998413
I0418 08:43:00.104537 139629521008384 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.45619362592697144, loss=3.336608409881592
I0418 08:43:33.738569 139629739054848 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.4594781696796417, loss=3.355567216873169
I0418 08:44:07.408068 139629521008384 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.4446585178375244, loss=3.262702465057373
I0418 08:44:41.096043 139629739054848 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.44455280900001526, loss=3.2430553436279297
I0418 08:45:14.662889 139629521008384 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.4636244773864746, loss=3.304508924484253
I0418 08:45:48.266530 139629739054848 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.4449988305568695, loss=3.1990325450897217
I0418 08:46:22.036400 139629521008384 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.4425341486930847, loss=3.2264814376831055
I0418 08:46:55.746903 139629739054848 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.4400967061519623, loss=3.248683214187622
I0418 08:47:06.190237 139806287599424 spec.py:298] Evaluating on the training split.
I0418 08:47:14.219035 139806287599424 spec.py:310] Evaluating on the validation split.
I0418 08:47:24.011512 139806287599424 spec.py:326] Evaluating on the test split.
I0418 08:47:25.892429 139806287599424 submission_runner.py:406] Time since start: 6965.34s, 	Step: 19733, 	{'train/accuracy': 0.7296516299247742, 'train/loss': 1.2972480058670044, 'validation/accuracy': 0.6425399780273438, 'validation/loss': 1.672454595565796, 'validation/num_examples': 50000, 'test/accuracy': 0.5199000239372253, 'test/loss': 2.3194291591644287, 'test/num_examples': 10000, 'score': 6677.67472743988, 'total_duration': 6965.337222576141, 'accumulated_submission_time': 6677.67472743988, 'accumulated_eval_time': 277.50049686431885, 'accumulated_logging_time': 9.906952857971191}
I0418 08:47:25.907056 139629521008384 logging_writer.py:48] [19733] accumulated_eval_time=277.500497, accumulated_logging_time=9.906953, accumulated_submission_time=6677.674727, global_step=19733, preemption_count=0, score=6677.674727, test/accuracy=0.519900, test/loss=2.319429, test/num_examples=10000, total_duration=6965.337223, train/accuracy=0.729652, train/loss=1.297248, validation/accuracy=0.642540, validation/loss=1.672455, validation/num_examples=50000
I0418 08:47:26.078590 139806287599424 checkpoints.py:356] Saving checkpoint at step: 19733
I0418 08:47:26.773697 139806287599424 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_19733
I0418 08:47:26.786353 139806287599424 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_19733.
I0418 08:47:49.601307 139629739054848 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.44273000955581665, loss=3.2978813648223877
I0418 08:48:23.075382 139629504222976 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.4576677083969116, loss=3.2891175746917725
I0418 08:48:56.785255 139629739054848 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.45338332653045654, loss=3.3003504276275635
I0418 08:49:30.438629 139629504222976 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.44354262948036194, loss=3.206798553466797
I0418 08:50:04.118935 139629739054848 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.4682309925556183, loss=3.358546733856201
I0418 08:50:37.692713 139629504222976 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.4466824233531952, loss=3.2462542057037354
I0418 08:51:11.305573 139629739054848 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.4489913582801819, loss=3.2887110710144043
I0418 08:51:44.826266 139629504222976 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.4291105568408966, loss=3.12595796585083
I0418 08:52:18.492724 139629739054848 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.46309924125671387, loss=3.316915988922119
I0418 08:52:51.993747 139629504222976 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.43184468150138855, loss=3.2422537803649902
I0418 08:53:25.724357 139629739054848 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.43466803431510925, loss=3.250729560852051
I0418 08:53:59.108873 139629504222976 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.44726619124412537, loss=3.2676563262939453
I0418 08:54:32.724251 139629739054848 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.44786038994789124, loss=3.300610303878784
I0418 08:55:06.374778 139629504222976 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.44209277629852295, loss=3.2759857177734375
I0418 08:55:40.105431 139629739054848 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.4517146348953247, loss=3.284238338470459
I0418 08:55:56.941978 139806287599424 spec.py:298] Evaluating on the training split.
I0418 08:56:04.469508 139806287599424 spec.py:310] Evaluating on the validation split.
I0418 08:56:14.644470 139806287599424 spec.py:326] Evaluating on the test split.
I0418 08:56:16.667872 139806287599424 submission_runner.py:406] Time since start: 7496.11s, 	Step: 21252, 	{'train/accuracy': 0.7234932780265808, 'train/loss': 1.3839640617370605, 'validation/accuracy': 0.6471799612045288, 'validation/loss': 1.7179194688796997, 'validation/num_examples': 50000, 'test/accuracy': 0.5135000348091125, 'test/loss': 2.377748966217041, 'test/num_examples': 10000, 'score': 7187.8064658641815, 'total_duration': 7496.112426042557, 'accumulated_submission_time': 7187.8064658641815, 'accumulated_eval_time': 297.22532987594604, 'accumulated_logging_time': 10.805881261825562}
I0418 08:56:16.678292 139629504222976 logging_writer.py:48] [21252] accumulated_eval_time=297.225330, accumulated_logging_time=10.805881, accumulated_submission_time=7187.806466, global_step=21252, preemption_count=0, score=7187.806466, test/accuracy=0.513500, test/loss=2.377749, test/num_examples=10000, total_duration=7496.112426, train/accuracy=0.723493, train/loss=1.383964, validation/accuracy=0.647180, validation/loss=1.717919, validation/num_examples=50000
I0418 08:56:16.851759 139806287599424 checkpoints.py:356] Saving checkpoint at step: 21252
I0418 08:56:17.538974 139806287599424 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_21252
I0418 08:56:17.549333 139806287599424 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_21252.
I0418 08:56:33.960551 139629739054848 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.4514101445674896, loss=3.27875018119812
I0418 08:57:07.506618 139629495830272 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.4533717930316925, loss=3.3143444061279297
I0418 08:57:41.187869 139629739054848 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.46126389503479004, loss=3.329930305480957
I0418 08:58:15.100376 139629495830272 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.4412810504436493, loss=3.141129493713379
I0418 08:58:48.615435 139629739054848 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.44449582695961, loss=3.2578330039978027
I0418 08:59:22.100856 139629495830272 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.45370835065841675, loss=3.277010679244995
I0418 08:59:55.536805 139629739054848 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.4400629997253418, loss=3.2253167629241943
I0418 09:00:29.096093 139629495830272 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.44449177384376526, loss=3.2461869716644287
I0418 09:01:02.709314 139629739054848 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.4567803740501404, loss=3.285487174987793
I0418 09:01:36.222073 139629495830272 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.43499329686164856, loss=3.2292981147766113
I0418 09:02:09.662509 139629739054848 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.43046507239341736, loss=3.1643333435058594
I0418 09:02:43.007325 139629495830272 logging_writer.py:48] [22400] global_step=22400, grad_norm=nan, loss=nan
I0418 09:03:15.697304 139629739054848 logging_writer.py:48] [22500] global_step=22500, grad_norm=nan, loss=nan
I0418 09:03:48.307075 139629495830272 logging_writer.py:48] [22600] global_step=22600, grad_norm=nan, loss=nan
I0418 09:04:21.225983 139629739054848 logging_writer.py:48] [22700] global_step=22700, grad_norm=nan, loss=nan
I0418 09:04:47.784225 139806287599424 spec.py:298] Evaluating on the training split.
I0418 09:04:55.682219 139806287599424 spec.py:310] Evaluating on the validation split.
I0418 09:05:05.861635 139806287599424 spec.py:326] Evaluating on the test split.
I0418 09:05:07.933805 139806287599424 submission_runner.py:406] Time since start: 8027.38s, 	Step: 22783, 	{'train/accuracy': 0.0008968430920504034, 'train/loss': nan, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': nan, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': nan, 'test/num_examples': 10000, 'score': 7698.015727043152, 'total_duration': 8027.378541231155, 'accumulated_submission_time': 7698.015727043152, 'accumulated_eval_time': 317.3740231990814, 'accumulated_logging_time': 11.693825483322144}
I0418 09:05:07.947429 139629495830272 logging_writer.py:48] [22783] accumulated_eval_time=317.374023, accumulated_logging_time=11.693825, accumulated_submission_time=7698.015727, global_step=22783, preemption_count=0, score=7698.015727, test/accuracy=0.001000, test/loss=nan, test/num_examples=10000, total_duration=8027.378541, train/accuracy=0.000897, train/loss=nan, validation/accuracy=0.001000, validation/loss=nan, validation/num_examples=50000
I0418 09:05:08.129114 139806287599424 checkpoints.py:356] Saving checkpoint at step: 22783
I0418 09:05:08.816783 139806287599424 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_22783
I0418 09:05:08.827714 139806287599424 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_22783.
I0418 09:05:14.720767 139629739054848 logging_writer.py:48] [22800] global_step=22800, grad_norm=nan, loss=nan
I0418 09:05:47.321571 139629042853632 logging_writer.py:48] [22900] global_step=22900, grad_norm=nan, loss=nan
I0418 09:06:19.820760 139629739054848 logging_writer.py:48] [23000] global_step=23000, grad_norm=nan, loss=nan
I0418 09:06:52.408203 139629042853632 logging_writer.py:48] [23100] global_step=23100, grad_norm=nan, loss=nan
I0418 09:07:24.906325 139629739054848 logging_writer.py:48] [23200] global_step=23200, grad_norm=nan, loss=nan
I0418 09:07:57.286089 139629042853632 logging_writer.py:48] [23300] global_step=23300, grad_norm=nan, loss=nan
I0418 09:08:29.781332 139629739054848 logging_writer.py:48] [23400] global_step=23400, grad_norm=nan, loss=nan
I0418 09:09:02.230047 139629042853632 logging_writer.py:48] [23500] global_step=23500, grad_norm=nan, loss=nan
I0418 09:09:34.801718 139629739054848 logging_writer.py:48] [23600] global_step=23600, grad_norm=nan, loss=nan
I0418 09:10:07.304870 139629042853632 logging_writer.py:48] [23700] global_step=23700, grad_norm=nan, loss=nan
I0418 09:10:39.710684 139629739054848 logging_writer.py:48] [23800] global_step=23800, grad_norm=nan, loss=nan
I0418 09:11:12.140686 139629042853632 logging_writer.py:48] [23900] global_step=23900, grad_norm=nan, loss=nan
I0418 09:11:44.559654 139629739054848 logging_writer.py:48] [24000] global_step=24000, grad_norm=nan, loss=nan
I0418 09:12:17.107468 139629042853632 logging_writer.py:48] [24100] global_step=24100, grad_norm=nan, loss=nan
I0418 09:12:49.637980 139629739054848 logging_writer.py:48] [24200] global_step=24200, grad_norm=nan, loss=nan
I0418 09:13:22.087552 139629042853632 logging_writer.py:48] [24300] global_step=24300, grad_norm=nan, loss=nan
I0418 09:13:38.851944 139806287599424 spec.py:298] Evaluating on the training split.
I0418 09:13:46.255405 139806287599424 spec.py:310] Evaluating on the validation split.
I0418 09:13:56.412724 139806287599424 spec.py:326] Evaluating on the test split.
I0418 09:13:58.475205 139806287599424 submission_runner.py:406] Time since start: 8557.92s, 	Step: 24353, 	{'train/accuracy': 0.0009765625, 'train/loss': nan, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': nan, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': nan, 'test/num_examples': 10000, 'score': 8208.012058734894, 'total_duration': 8557.919798851013, 'accumulated_submission_time': 8208.012058734894, 'accumulated_eval_time': 336.99625301361084, 'accumulated_logging_time': 12.596394300460815}
I0418 09:13:58.484569 139629739054848 logging_writer.py:48] [24353] accumulated_eval_time=336.996253, accumulated_logging_time=12.596394, accumulated_submission_time=8208.012059, global_step=24353, preemption_count=0, score=8208.012059, test/accuracy=0.001000, test/loss=nan, test/num_examples=10000, total_duration=8557.919799, train/accuracy=0.000977, train/loss=nan, validation/accuracy=0.001000, validation/loss=nan, validation/num_examples=50000
I0418 09:13:58.650144 139806287599424 checkpoints.py:356] Saving checkpoint at step: 24353
I0418 09:13:59.337369 139806287599424 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_24353
I0418 09:13:59.351426 139806287599424 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_24353.
I0418 09:14:14.947938 139629042853632 logging_writer.py:48] [24400] global_step=24400, grad_norm=nan, loss=nan
I0418 09:14:47.729742 139629034460928 logging_writer.py:48] [24500] global_step=24500, grad_norm=nan, loss=nan
I0418 09:15:20.490916 139629042853632 logging_writer.py:48] [24600] global_step=24600, grad_norm=nan, loss=nan
I0418 09:15:53.313736 139629034460928 logging_writer.py:48] [24700] global_step=24700, grad_norm=nan, loss=nan
I0418 09:16:26.067548 139629042853632 logging_writer.py:48] [24800] global_step=24800, grad_norm=nan, loss=nan
I0418 09:16:58.749266 139629034460928 logging_writer.py:48] [24900] global_step=24900, grad_norm=nan, loss=nan
I0418 09:17:31.372672 139629042853632 logging_writer.py:48] [25000] global_step=25000, grad_norm=nan, loss=nan
I0418 09:18:04.124333 139629034460928 logging_writer.py:48] [25100] global_step=25100, grad_norm=nan, loss=nan
I0418 09:18:36.795534 139629042853632 logging_writer.py:48] [25200] global_step=25200, grad_norm=nan, loss=nan
2023-04-18 09:18:50.979357: E external/org_tensorflow/tensorflow/compiler/xla/pjrt/pjrt_stream_executor_client.cc:2130] Execution of replica 0 failed: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED
in external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'
2023-04-18 09:18:50.987307: E external/org_tensorflow/tensorflow/compiler/xla/pjrt/pjrt_stream_executor_client.cc:2130] Execution of replica 7 failed: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED
in external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4839): 'status'
2023-04-18 09:18:50.987513: E external/org_tensorflow/tensorflow/compiler/xla/pjrt/pjrt_stream_executor_client.cc:2130] Execution of replica 2 failed: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED
in external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4839): 'status'
2023-04-18 09:18:50.987665: E external/org_tensorflow/tensorflow/compiler/xla/pjrt/pjrt_stream_executor_client.cc:2130] Execution of replica 3 failed: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED
in external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4839): 'status'
2023-04-18 09:18:50.987718: E external/org_tensorflow/tensorflow/compiler/xla/pjrt/pjrt_stream_executor_client.cc:2130] Execution of replica 1 failed: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED
in external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4839): 'status'
2023-04-18 09:18:50.987872: E external/org_tensorflow/tensorflow/compiler/xla/pjrt/pjrt_stream_executor_client.cc:2130] Execution of replica 4 failed: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED
in external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4839): 'status'
2023-04-18 09:18:50.987940: E external/org_tensorflow/tensorflow/compiler/xla/pjrt/pjrt_stream_executor_client.cc:2130] Execution of replica 6 failed: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED
in external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4839): 'status'
2023-04-18 09:18:50.988037: E external/org_tensorflow/tensorflow/compiler/xla/pjrt/pjrt_stream_executor_client.cc:2130] Execution of replica 5 failed: INTERNAL: Failed to launch CUDA kernel: reduce_4098 with block dimensions: 1024x1x1 and grid dimensions: 8x1x1: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
Traceback (most recent call last):
  File "submission_runner.py", line 647, in <module>
    app.run(main)
  File "/usr/local/lib/python3.8/dist-packages/absl/app.py", line 312, in run
    _run_main(main, args)
  File "/usr/local/lib/python3.8/dist-packages/absl/app.py", line 258, in _run_main
    sys.exit(main(argv))
  File "submission_runner.py", line 619, in main
    score = score_submission_on_workload(
  File "submission_runner.py", line 554, in score_submission_on_workload
    timing, metrics = train_once(workload, global_batch_size,
  File "submission_runner.py", line 335, in train_once
    optimizer_state, model_params, model_state = update_params(
  File "/algorithmic-efficiency/baselines/momentum/jax/submission.py", line 173, in update_params
    outputs = pmapped_train_step(workload,
ValueError: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED
in external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status': while running replica 0 and partition 0 of a replicated computation (other replicas may have failed as well).
2023-04-18 09:18:51.855548: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.857456: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9ead710: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.857528: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.857544: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9ead710: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.857553: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.857573: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:612] unable to add host callback: CUDA_ERROR_INVALID_HANDLE: invalid resource handle
2023-04-18 09:18:51.857593: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.857604: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9ea6690: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.857614: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.857625: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9ea6690: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.857633: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.857646: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:612] unable to add host callback: CUDA_ERROR_INVALID_HANDLE: invalid resource handle
2023-04-18 09:18:51.857660: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.857670: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e9f6e0: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.857679: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.857690: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e9f6e0: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.857699: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.857711: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:612] unable to add host callback: CUDA_ERROR_INVALID_HANDLE: invalid resource handle
2023-04-18 09:18:51.857724: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.857735: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e98730: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.857745: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.857760: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e98730: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.857769: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.857781: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:612] unable to add host callback: CUDA_ERROR_INVALID_HANDLE: invalid resource handle
2023-04-18 09:18:51.857795: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.857809: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e91780: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.857818: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.857828: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e91780: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.857837: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.857849: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:612] unable to add host callback: CUDA_ERROR_INVALID_HANDLE: invalid resource handle
2023-04-18 09:18:51.857865: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.857876: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e8a7d0: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.857902: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.857934: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e8a7d0: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.857945: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.857958: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:612] unable to add host callback: CUDA_ERROR_INVALID_HANDLE: invalid resource handle
2023-04-18 09:18:51.857978: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858023: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e83820: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858034: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858047: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e83820: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858057: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858072: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:612] unable to add host callback: CUDA_ERROR_INVALID_HANDLE: invalid resource handle
2023-04-18 09:18:51.858087: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858100: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e43150: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858110: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858126: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e43150: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858138: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858152: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:612] unable to add host callback: CUDA_ERROR_INVALID_HANDLE: invalid resource handle
2023-04-18 09:18:51.858176: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858192: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9ead710: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858202: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858214: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9ead710: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858224: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858240: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:612] unable to add host callback: CUDA_ERROR_INVALID_HANDLE: invalid resource handle
2023-04-18 09:18:51.858256: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858266: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9ea6690: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858277: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858288: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9ea6690: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858299: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858313: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:612] unable to add host callback: CUDA_ERROR_INVALID_HANDLE: invalid resource handle
2023-04-18 09:18:51.858327: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858338: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e9f6e0: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858348: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858360: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e9f6e0: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858372: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858388: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:612] unable to add host callback: CUDA_ERROR_INVALID_HANDLE: invalid resource handle
2023-04-18 09:18:51.858403: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858414: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e98730: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858424: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858440: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e98730: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858452: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858467: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:612] unable to add host callback: CUDA_ERROR_INVALID_HANDLE: invalid resource handle
2023-04-18 09:18:51.858481: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858492: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e91780: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858502: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858514: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e91780: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858524: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858538: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:612] unable to add host callback: CUDA_ERROR_INVALID_HANDLE: invalid resource handle
2023-04-18 09:18:51.858552: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858563: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e8a7d0: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858576: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858588: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e8a7d0: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858601: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858616: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:612] unable to add host callback: CUDA_ERROR_INVALID_HANDLE: invalid resource handle
2023-04-18 09:18:51.858630: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858643: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e83820: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858653: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858665: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e83820: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858675: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858690: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:612] unable to add host callback: CUDA_ERROR_INVALID_HANDLE: invalid resource handle
2023-04-18 09:18:51.858705: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858716: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e43150: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858727: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858743: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:693] could not allocate CUDA stream for context 0x9e43150: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2023-04-18 09:18:51.858753: E external/org_tensorflow/tensorflow/stream_executor/stream.cc:296] failed to allocate stream during initialization
2023-04-18 09:18:51.858768: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:612] unable to add host callback: CUDA_ERROR_INVALID_HANDLE: invalid resource handle
2023-04-18 09:18:51.902050: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:1041] could not synchronize on CUDA context: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure :: *** Begin stack trace ***
	
	
	
	
	
	
	
	
	
	
	PyDict_Clear
	
	
	_PyGC_CollectNoFail
	PyImport_Cleanup
	Py_FinalizeEx
	Py_RunMain
	Py_BytesMain
	__libc_start_main
	_start
*** End stack trace ***

2023-04-18 09:18:51.904172: F external/org_tensorflow/tensorflow/compiler/xla/service/gpu/gpu_executable.cc:382] Check failed: pair.first->SynchronizeAllActivity() 
Fatal Python error: Aborted

Current thread 0x00007f27301c1740 (most recent call first):
<no Python frame>
