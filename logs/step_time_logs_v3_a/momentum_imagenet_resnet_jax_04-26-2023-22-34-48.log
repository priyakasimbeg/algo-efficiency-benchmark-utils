I0426 22:35:10.381220 140061887473472 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax.
I0426 22:35:10.456414 140061887473472 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0426 22:35:11.328375 140061887473472 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter Host CUDA
I0426 22:35:11.329066 140061887473472 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0426 22:35:11.333092 140061887473472 submission_runner.py:528] Using RNG seed 183843509
I0426 22:35:14.073513 140061887473472 submission_runner.py:537] --- Tuning run 1/1 ---
I0426 22:35:14.073719 140061887473472 submission_runner.py:542] Creating tuning directory at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1.
I0426 22:35:14.074022 140061887473472 logger_utils.py:83] Saving hparams to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/hparams.json.
I0426 22:35:14.212409 140061887473472 submission_runner.py:232] Initializing dataset.
I0426 22:35:14.225790 140061887473472 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0426 22:35:14.233341 140061887473472 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0426 22:35:14.233476 140061887473472 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0426 22:35:14.497773 140061887473472 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0426 22:35:15.591738 140061887473472 submission_runner.py:239] Initializing model.
I0426 22:35:28.087528 140061887473472 submission_runner.py:249] Initializing optimizer.
I0426 22:35:29.054175 140061887473472 submission_runner.py:256] Initializing metrics bundle.
I0426 22:35:29.054364 140061887473472 submission_runner.py:273] Initializing checkpoint and logger.
I0426 22:35:29.055467 140061887473472 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1 with prefix checkpoint_
I0426 22:35:29.974616 140061887473472 submission_runner.py:294] Saving meta data to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/meta_data_0.json.
I0426 22:35:29.975710 140061887473472 submission_runner.py:297] Saving flags to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/flags_0.json.
I0426 22:35:29.981737 140061887473472 submission_runner.py:309] Starting training loop.
I0426 22:36:16.754692 139885230925568 logging_writer.py:48] [0] global_step=0, grad_norm=0.5291715264320374, loss=6.927515029907227
I0426 22:36:16.769257 140061887473472 spec.py:298] Evaluating on the training split.
I0426 22:36:17.257935 140061887473472 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0426 22:36:17.265014 140061887473472 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0426 22:36:17.265137 140061887473472 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0426 22:36:17.327668 140061887473472 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0426 22:36:29.039898 140061887473472 spec.py:310] Evaluating on the validation split.
I0426 22:36:29.889193 140061887473472 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0426 22:36:29.906526 140061887473472 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0426 22:36:29.906796 140061887473472 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0426 22:36:29.961473 140061887473472 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0426 22:36:47.503575 140061887473472 spec.py:326] Evaluating on the test split.
I0426 22:36:47.922284 140061887473472 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0426 22:36:47.926929 140061887473472 dataset_builder.py:510] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0426 22:36:47.958502 140061887473472 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0426 22:36:57.322623 140061887473472 submission_runner.py:406] Time since start: 87.34s, 	Step: 1, 	{'train/accuracy': 0.0012954400153830647, 'train/loss': 6.910459995269775, 'validation/accuracy': 0.0011399999493733048, 'validation/loss': 6.910703182220459, 'validation/num_examples': 50000, 'test/accuracy': 0.0010999999940395355, 'test/loss': 6.910574436187744, 'test/num_examples': 10000, 'score': 46.78730607032776, 'total_duration': 87.34082508087158, 'accumulated_submission_time': 46.78730607032776, 'accumulated_eval_time': 40.55333161354065, 'accumulated_logging_time': 0}
I0426 22:36:57.338629 139854931289856 logging_writer.py:48] [1] accumulated_eval_time=40.553332, accumulated_logging_time=0, accumulated_submission_time=46.787306, global_step=1, preemption_count=0, score=46.787306, test/accuracy=0.001100, test/loss=6.910574, test/num_examples=10000, total_duration=87.340825, train/accuracy=0.001295, train/loss=6.910460, validation/accuracy=0.001140, validation/loss=6.910703, validation/num_examples=50000
I0426 22:36:57.446917 140061887473472 checkpoints.py:356] Saving checkpoint at step: 1
I0426 22:36:57.942658 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_1
I0426 22:36:57.943650 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_1.
I0426 22:37:31.441817 139854939682560 logging_writer.py:48] [100] global_step=100, grad_norm=0.5291740894317627, loss=6.885984420776367
I0426 22:38:04.891382 139855359088384 logging_writer.py:48] [200] global_step=200, grad_norm=0.5454267859458923, loss=6.796802520751953
I0426 22:38:38.350091 139854939682560 logging_writer.py:48] [300] global_step=300, grad_norm=0.5955168008804321, loss=6.690902233123779
I0426 22:39:11.879985 139855359088384 logging_writer.py:48] [400] global_step=400, grad_norm=0.6244423985481262, loss=6.609606742858887
I0426 22:39:45.316512 139854939682560 logging_writer.py:48] [500] global_step=500, grad_norm=0.6884722113609314, loss=6.543577194213867
I0426 22:40:18.866867 139855359088384 logging_writer.py:48] [600] global_step=600, grad_norm=0.7560510635375977, loss=6.475439071655273
I0426 22:40:52.310919 139854939682560 logging_writer.py:48] [700] global_step=700, grad_norm=0.8318862915039062, loss=6.432938575744629
I0426 22:41:25.839121 139855359088384 logging_writer.py:48] [800] global_step=800, grad_norm=0.764996349811554, loss=6.355080604553223
I0426 22:41:59.394750 139854939682560 logging_writer.py:48] [900] global_step=900, grad_norm=0.8383921980857849, loss=6.2939772605896
I0426 22:42:32.886162 139855359088384 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.7377609014511108, loss=6.2613325119018555
I0426 22:43:06.360947 139854939682560 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.811874508857727, loss=6.272119998931885
I0426 22:43:39.880262 139855359088384 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.9005363583564758, loss=6.170479774475098
I0426 22:44:13.451420 139854939682560 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.7647966742515564, loss=6.138338565826416
I0426 22:44:47.041280 139855359088384 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.8168718218803406, loss=6.068082332611084
I0426 22:45:20.603581 139854939682560 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.8723070621490479, loss=6.104140281677246
I0426 22:45:28.054977 140061887473472 spec.py:298] Evaluating on the training split.
I0426 22:45:35.255525 140061887473472 spec.py:310] Evaluating on the validation split.
I0426 22:45:43.068500 140061887473472 spec.py:326] Evaluating on the test split.
I0426 22:45:45.165817 140061887473472 submission_runner.py:406] Time since start: 615.18s, 	Step: 1524, 	{'train/accuracy': 0.0679408460855484, 'train/loss': 5.441141605377197, 'validation/accuracy': 0.06137999892234802, 'validation/loss': 5.524351119995117, 'validation/num_examples': 50000, 'test/accuracy': 0.04180000349879265, 'test/loss': 5.737311363220215, 'test/num_examples': 10000, 'score': 556.8747472763062, 'total_duration': 615.1840131282806, 'accumulated_submission_time': 556.8747472763062, 'accumulated_eval_time': 57.66414165496826, 'accumulated_logging_time': 0.6250734329223633}
I0426 22:45:45.174551 139855375873792 logging_writer.py:48] [1524] accumulated_eval_time=57.664142, accumulated_logging_time=0.625073, accumulated_submission_time=556.874747, global_step=1524, preemption_count=0, score=556.874747, test/accuracy=0.041800, test/loss=5.737311, test/num_examples=10000, total_duration=615.184013, train/accuracy=0.067941, train/loss=5.441142, validation/accuracy=0.061380, validation/loss=5.524351, validation/num_examples=50000
I0426 22:45:45.300036 140061887473472 checkpoints.py:356] Saving checkpoint at step: 1524
I0426 22:45:45.803649 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_1524
I0426 22:45:45.804626 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_1524.
I0426 22:46:11.564338 139855384266496 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.7956072092056274, loss=6.033761501312256
I0426 22:46:45.124242 139885327378176 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.9393406510353088, loss=5.967339038848877
I0426 22:47:18.638303 139855384266496 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.802276611328125, loss=5.844582557678223
I0426 22:47:52.187435 139885327378176 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.8244673013687134, loss=5.850545883178711
I0426 22:48:25.726255 139855384266496 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.9823827743530273, loss=5.710479259490967
I0426 22:48:59.321600 139885327378176 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.9591554403305054, loss=5.726076126098633
I0426 22:49:32.841836 139855384266496 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.8708114624023438, loss=5.6770501136779785
I0426 22:50:06.476209 139885327378176 logging_writer.py:48] [2300] global_step=2300, grad_norm=1.0975236892700195, loss=5.613033294677734
I0426 22:50:40.055783 139855384266496 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.8062341213226318, loss=5.574572563171387
I0426 22:51:13.536108 139885327378176 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.823509156703949, loss=5.508886337280273
I0426 22:51:47.048326 139855384266496 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.8897215127944946, loss=5.399102210998535
I0426 22:52:20.542263 139885327378176 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.888784646987915, loss=5.363114356994629
I0426 22:52:53.993365 139855384266496 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.9302855730056763, loss=5.342126846313477
I0426 22:53:27.403530 139885327378176 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.8591949343681335, loss=5.293283939361572
I0426 22:54:00.872318 139855384266496 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.8337045311927795, loss=5.203693389892578
I0426 22:54:16.030101 140061887473472 spec.py:298] Evaluating on the training split.
I0426 22:54:23.172261 140061887473472 spec.py:310] Evaluating on the validation split.
I0426 22:54:31.049026 140061887473472 spec.py:326] Evaluating on the test split.
I0426 22:54:33.137370 140061887473472 submission_runner.py:406] Time since start: 1143.16s, 	Step: 3047, 	{'train/accuracy': 0.17442601919174194, 'train/loss': 4.409230709075928, 'validation/accuracy': 0.15838000178337097, 'validation/loss': 4.521397590637207, 'validation/num_examples': 50000, 'test/accuracy': 0.11670000851154327, 'test/loss': 4.950851917266846, 'test/num_examples': 10000, 'score': 1067.075849533081, 'total_duration': 1143.1555767059326, 'accumulated_submission_time': 1067.075849533081, 'accumulated_eval_time': 74.77139067649841, 'accumulated_logging_time': 1.2682819366455078}
I0426 22:54:33.145252 139885327378176 logging_writer.py:48] [3047] accumulated_eval_time=74.771391, accumulated_logging_time=1.268282, accumulated_submission_time=1067.075850, global_step=3047, preemption_count=0, score=1067.075850, test/accuracy=0.116700, test/loss=4.950852, test/num_examples=10000, total_duration=1143.155577, train/accuracy=0.174426, train/loss=4.409231, validation/accuracy=0.158380, validation/loss=4.521398, validation/num_examples=50000
I0426 22:54:33.286668 140061887473472 checkpoints.py:356] Saving checkpoint at step: 3047
I0426 22:54:33.755031 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_3047
I0426 22:54:33.755944 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_3047.
I0426 22:54:51.807134 139855384266496 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.8763176798820496, loss=5.218748092651367
I0426 22:55:25.310635 139885293807360 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.8992383480072021, loss=5.127498149871826
I0426 22:55:58.782361 139855384266496 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.7622853517532349, loss=5.091630935668945
I0426 22:56:32.284471 139885293807360 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.783109188079834, loss=5.000134468078613
I0426 22:57:05.777326 139855384266496 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.8422159552574158, loss=5.092046737670898
I0426 22:57:39.248746 139885293807360 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.775177001953125, loss=5.026724815368652
I0426 22:58:12.703554 139855384266496 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.8594413995742798, loss=4.9345622062683105
I0426 22:58:46.309406 139885293807360 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.7582628726959229, loss=4.856308937072754
I0426 22:59:19.714564 139855384266496 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.779474675655365, loss=4.862738132476807
I0426 22:59:53.289241 139885293807360 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.7841086983680725, loss=4.776848316192627
I0426 23:00:26.777905 139855384266496 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.8637590408325195, loss=4.820906162261963
I0426 23:01:00.248660 139885293807360 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.7016120553016663, loss=4.637787342071533
I0426 23:01:33.747232 139855384266496 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.8110034465789795, loss=4.741191387176514
I0426 23:02:07.183520 139885293807360 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.7118721604347229, loss=4.667036056518555
I0426 23:02:40.686784 139855384266496 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.680562436580658, loss=4.666814804077148
I0426 23:03:03.848341 140061887473472 spec.py:298] Evaluating on the training split.
I0426 23:03:10.782488 140061887473472 spec.py:310] Evaluating on the validation split.
I0426 23:03:18.641962 140061887473472 spec.py:326] Evaluating on the test split.
I0426 23:03:20.645678 140061887473472 submission_runner.py:406] Time since start: 1670.66s, 	Step: 4571, 	{'train/accuracy': 0.2869897782802582, 'train/loss': 3.5225231647491455, 'validation/accuracy': 0.26646000146865845, 'validation/loss': 3.648171901702881, 'validation/num_examples': 50000, 'test/accuracy': 0.1931000053882599, 'test/loss': 4.25665283203125, 'test/num_examples': 10000, 'score': 1577.1433110237122, 'total_duration': 1670.663868188858, 'accumulated_submission_time': 1577.1433110237122, 'accumulated_eval_time': 91.568692445755, 'accumulated_logging_time': 1.891874074935913}
I0426 23:03:20.653730 139885293807360 logging_writer.py:48] [4571] accumulated_eval_time=91.568692, accumulated_logging_time=1.891874, accumulated_submission_time=1577.143311, global_step=4571, preemption_count=0, score=1577.143311, test/accuracy=0.193100, test/loss=4.256653, test/num_examples=10000, total_duration=1670.663868, train/accuracy=0.286990, train/loss=3.522523, validation/accuracy=0.266460, validation/loss=3.648172, validation/num_examples=50000
I0426 23:03:20.787600 140061887473472 checkpoints.py:356] Saving checkpoint at step: 4571
I0426 23:03:21.266729 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_4571
I0426 23:03:21.267739 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_4571.
I0426 23:03:31.257118 139855384266496 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.7578893899917603, loss=4.657697677612305
I0426 23:04:04.737723 139885977515776 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.7041335105895996, loss=4.63539981842041
I0426 23:04:38.265172 139855384266496 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.6853190660476685, loss=4.542677402496338
I0426 23:05:11.693130 139885977515776 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.7480798363685608, loss=4.489906311035156
I0426 23:05:45.137086 139855384266496 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.6587246656417847, loss=4.4857048988342285
I0426 23:06:18.665660 139885977515776 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.7731034159660339, loss=4.564002513885498
I0426 23:06:52.152512 139855384266496 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.6879697442054749, loss=4.53840446472168
I0426 23:07:25.694116 139885977515776 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.7146895527839661, loss=4.475130081176758
I0426 23:07:59.358488 139855384266496 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.6704915165901184, loss=4.425565242767334
I0426 23:08:32.857706 139885977515776 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.6616717576980591, loss=4.408834457397461
I0426 23:09:06.448023 139855384266496 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.6617129445075989, loss=4.394564151763916
I0426 23:09:39.892007 139885977515776 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.6492161154747009, loss=4.312938690185547
I0426 23:10:13.413978 139855384266496 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.6294137239456177, loss=4.323683261871338
I0426 23:10:46.936107 139885977515776 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.6848425269126892, loss=4.303393363952637
I0426 23:11:20.406677 139855384266496 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.6503783464431763, loss=4.362494468688965
I0426 23:11:51.529849 140061887473472 spec.py:298] Evaluating on the training split.
I0426 23:11:58.551097 140061887473472 spec.py:310] Evaluating on the validation split.
I0426 23:12:06.587682 140061887473472 spec.py:326] Evaluating on the test split.
I0426 23:12:08.592676 140061887473472 submission_runner.py:406] Time since start: 2198.61s, 	Step: 6095, 	{'train/accuracy': 0.41555723547935486, 'train/loss': 2.781505584716797, 'validation/accuracy': 0.3933199942111969, 'validation/loss': 2.9008870124816895, 'validation/num_examples': 50000, 'test/accuracy': 0.2964000105857849, 'test/loss': 3.5172743797302246, 'test/num_examples': 10000, 'score': 2087.3816072940826, 'total_duration': 2198.6108644008636, 'accumulated_submission_time': 2087.3816072940826, 'accumulated_eval_time': 108.63148593902588, 'accumulated_logging_time': 2.5181524753570557}
I0426 23:12:08.602248 139885977515776 logging_writer.py:48] [6095] accumulated_eval_time=108.631486, accumulated_logging_time=2.518152, accumulated_submission_time=2087.381607, global_step=6095, preemption_count=0, score=2087.381607, test/accuracy=0.296400, test/loss=3.517274, test/num_examples=10000, total_duration=2198.610864, train/accuracy=0.415557, train/loss=2.781506, validation/accuracy=0.393320, validation/loss=2.900887, validation/num_examples=50000
I0426 23:12:08.720579 140061887473472 checkpoints.py:356] Saving checkpoint at step: 6095
I0426 23:12:09.378278 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_6095
I0426 23:12:09.390492 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_6095.
I0426 23:12:11.395547 139855384266496 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.6679540872573853, loss=4.281497001647949
I0426 23:12:45.025432 139885868476160 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.6183316111564636, loss=4.22431755065918
I0426 23:13:18.620257 139855384266496 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.6528573632240295, loss=4.260960578918457
I0426 23:13:52.120235 139885868476160 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.6321683526039124, loss=4.19635009765625
I0426 23:14:25.656522 139855384266496 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.6081448197364807, loss=4.28687858581543
I0426 23:14:59.233217 139885868476160 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.5822826027870178, loss=4.1166229248046875
I0426 23:15:32.820805 139855384266496 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.6471048593521118, loss=4.1850056648254395
I0426 23:16:06.326797 139885868476160 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.5857978463172913, loss=4.100775718688965
I0426 23:16:39.971271 139855384266496 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.6106698513031006, loss=4.16673469543457
I0426 23:17:13.525674 139885868476160 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.5995786190032959, loss=4.122198104858398
I0426 23:17:47.150034 139855384266496 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.5911284685134888, loss=4.050053596496582
I0426 23:18:20.854816 139885868476160 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.5730017423629761, loss=4.079281330108643
I0426 23:18:54.465035 139855384266496 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.5772809386253357, loss=4.0287556648254395
I0426 23:19:27.960864 139885868476160 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.5725287199020386, loss=4.099124908447266
I0426 23:20:01.526135 139855384266496 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.5799923539161682, loss=4.0290608406066895
I0426 23:20:35.109220 139885868476160 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.5775215029716492, loss=3.9516069889068604
I0426 23:20:39.508549 140061887473472 spec.py:298] Evaluating on the training split.
I0426 23:20:46.462696 140061887473472 spec.py:310] Evaluating on the validation split.
I0426 23:20:54.257324 140061887473472 spec.py:326] Evaluating on the test split.
I0426 23:20:56.695074 140061887473472 submission_runner.py:406] Time since start: 2726.71s, 	Step: 7615, 	{'train/accuracy': 0.47183912992477417, 'train/loss': 2.6564807891845703, 'validation/accuracy': 0.4442199766635895, 'validation/loss': 2.799440860748291, 'validation/num_examples': 50000, 'test/accuracy': 0.32990002632141113, 'test/loss': 3.4517064094543457, 'test/num_examples': 10000, 'score': 2597.4725244045258, 'total_duration': 2726.713265657425, 'accumulated_submission_time': 2597.4725244045258, 'accumulated_eval_time': 125.81799030303955, 'accumulated_logging_time': 3.323435068130493}
I0426 23:20:56.703918 139855384266496 logging_writer.py:48] [7615] accumulated_eval_time=125.817990, accumulated_logging_time=3.323435, accumulated_submission_time=2597.472524, global_step=7615, preemption_count=0, score=2597.472524, test/accuracy=0.329900, test/loss=3.451706, test/num_examples=10000, total_duration=2726.713266, train/accuracy=0.471839, train/loss=2.656481, validation/accuracy=0.444220, validation/loss=2.799441, validation/num_examples=50000
I0426 23:20:56.842672 140061887473472 checkpoints.py:356] Saving checkpoint at step: 7615
I0426 23:20:57.529109 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_7615
I0426 23:20:57.538124 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_7615.
I0426 23:21:26.331495 139885868476160 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.5637797117233276, loss=4.008455276489258
I0426 23:21:59.877779 139885860083456 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.5849402546882629, loss=4.009894371032715
I0426 23:22:33.475500 139885868476160 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.5448294878005981, loss=4.019892692565918
I0426 23:23:07.052399 139885860083456 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.5737728476524353, loss=3.9557180404663086
I0426 23:23:40.714871 139885868476160 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.5545443892478943, loss=3.896818161010742
I0426 23:24:14.291226 139885860083456 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.566913902759552, loss=3.9557392597198486
I0426 23:24:48.038201 139885868476160 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.5441771745681763, loss=3.9403610229492188
I0426 23:25:21.616968 139885860083456 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.5665656924247742, loss=3.994925022125244
I0426 23:25:55.270959 139885868476160 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.5598164796829224, loss=3.909353017807007
I0426 23:26:28.967673 139885860083456 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.5529896020889282, loss=3.864558696746826
I0426 23:27:02.705406 139885868476160 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.5408589243888855, loss=3.827685594558716
I0426 23:27:36.327932 139885860083456 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.5309312343597412, loss=3.88193678855896
I0426 23:28:09.939687 139885868476160 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.5294277667999268, loss=3.800593852996826
I0426 23:28:43.547831 139885860083456 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.5376436710357666, loss=3.9864935874938965
I0426 23:29:17.192699 139885868476160 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.5456476807594299, loss=3.782113552093506
I0426 23:29:27.656189 140061887473472 spec.py:298] Evaluating on the training split.
I0426 23:29:34.614282 140061887473472 spec.py:310] Evaluating on the validation split.
I0426 23:29:43.181031 140061887473472 spec.py:326] Evaluating on the test split.
I0426 23:29:47.347703 140061887473472 submission_runner.py:406] Time since start: 3257.37s, 	Step: 9133, 	{'train/accuracy': 0.5660275816917419, 'train/loss': 2.136199712753296, 'validation/accuracy': 0.4989199936389923, 'validation/loss': 2.4529521465301514, 'validation/num_examples': 50000, 'test/accuracy': 0.3822000324726105, 'test/loss': 3.086632251739502, 'test/num_examples': 10000, 'score': 3107.56387257576, 'total_duration': 3257.3658995628357, 'accumulated_submission_time': 3107.56387257576, 'accumulated_eval_time': 145.50947260856628, 'accumulated_logging_time': 4.1740882396698}
I0426 23:29:47.357006 139885860083456 logging_writer.py:48] [9133] accumulated_eval_time=145.509473, accumulated_logging_time=4.174088, accumulated_submission_time=3107.563873, global_step=9133, preemption_count=0, score=3107.563873, test/accuracy=0.382200, test/loss=3.086632, test/num_examples=10000, total_duration=3257.365900, train/accuracy=0.566028, train/loss=2.136200, validation/accuracy=0.498920, validation/loss=2.452952, validation/num_examples=50000
I0426 23:29:47.479356 140061887473472 checkpoints.py:356] Saving checkpoint at step: 9133
I0426 23:29:48.005091 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_9133
I0426 23:29:48.006332 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_9133.
I0426 23:30:10.751333 139885868476160 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.5088533163070679, loss=3.80537748336792
I0426 23:30:44.096845 139885843298048 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.5484026670455933, loss=3.9413623809814453
I0426 23:31:17.567478 139885868476160 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.534880518913269, loss=3.750826835632324
I0426 23:31:50.993674 139885843298048 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.5084306597709656, loss=3.7327370643615723
I0426 23:32:24.468978 139885868476160 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.496708482503891, loss=3.770714282989502
I0426 23:32:57.803777 139885843298048 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.5209075212478638, loss=3.8390867710113525
I0426 23:33:31.289476 139885868476160 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.5077340006828308, loss=3.7214913368225098
I0426 23:34:04.737604 139885843298048 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.5398206114768982, loss=3.8692967891693115
I0426 23:34:38.177067 139885868476160 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.5004925727844238, loss=3.740222215652466
I0426 23:35:11.598741 139885843298048 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.5083775520324707, loss=3.8473830223083496
I0426 23:35:45.155410 139885868476160 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.5121271014213562, loss=3.7575671672821045
I0426 23:36:18.594051 139885843298048 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.5041739344596863, loss=3.699145793914795
I0426 23:36:52.052851 139885868476160 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.4867780804634094, loss=3.7805466651916504
I0426 23:37:25.579740 139885843298048 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.5160397887229919, loss=3.702190637588501
I0426 23:37:58.980240 139885868476160 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.5048320293426514, loss=3.7586379051208496
I0426 23:38:18.144921 140061887473472 spec.py:298] Evaluating on the training split.
I0426 23:38:25.155311 140061887473472 spec.py:310] Evaluating on the validation split.
I0426 23:38:34.087314 140061887473472 spec.py:326] Evaluating on the test split.
I0426 23:38:36.310116 140061887473472 submission_runner.py:406] Time since start: 3786.33s, 	Step: 10659, 	{'train/accuracy': 0.5920758843421936, 'train/loss': 1.8975021839141846, 'validation/accuracy': 0.5415599942207336, 'validation/loss': 2.1408050060272217, 'validation/num_examples': 50000, 'test/accuracy': 0.42570000886917114, 'test/loss': 2.802159547805786, 'test/num_examples': 10000, 'score': 3617.6776809692383, 'total_duration': 3786.3283021450043, 'accumulated_submission_time': 3617.6776809692383, 'accumulated_eval_time': 163.67462801933289, 'accumulated_logging_time': 4.837895154953003}
I0426 23:38:36.320658 139885843298048 logging_writer.py:48] [10659] accumulated_eval_time=163.674628, accumulated_logging_time=4.837895, accumulated_submission_time=3617.677681, global_step=10659, preemption_count=0, score=3617.677681, test/accuracy=0.425700, test/loss=2.802160, test/num_examples=10000, total_duration=3786.328302, train/accuracy=0.592076, train/loss=1.897502, validation/accuracy=0.541560, validation/loss=2.140805, validation/num_examples=50000
I0426 23:38:36.519321 140061887473472 checkpoints.py:356] Saving checkpoint at step: 10659
I0426 23:38:37.211974 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_10659
I0426 23:38:37.221745 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_10659.
I0426 23:38:51.230468 139885868476160 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.49086499214172363, loss=3.6923954486846924
I0426 23:39:24.807940 139885700687616 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.4932587146759033, loss=3.7338881492614746
I0426 23:39:58.366377 139885868476160 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.47719791531562805, loss=3.631821870803833
I0426 23:40:32.071690 139885700687616 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.4891414940357208, loss=3.7207202911376953
I0426 23:41:05.632447 139885868476160 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.4801444411277771, loss=3.704127073287964
I0426 23:41:39.155186 139885700687616 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.5092509388923645, loss=3.661172866821289
I0426 23:42:12.805671 139885868476160 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.46757423877716064, loss=3.5942983627319336
I0426 23:42:46.293721 139885700687616 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.4745302200317383, loss=3.6416423320770264
I0426 23:43:19.823549 139885868476160 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.4819042682647705, loss=3.5563852787017822
I0426 23:43:53.381694 139885700687616 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.491425484418869, loss=3.5760140419006348
I0426 23:44:26.947071 139885868476160 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.4898994565010071, loss=3.6629228591918945
I0426 23:45:00.581570 139885700687616 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.49457040429115295, loss=3.584047794342041
I0426 23:45:34.203709 139885868476160 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.47848764061927795, loss=3.652851104736328
I0426 23:46:07.587862 139885700687616 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.4811580777168274, loss=3.615471124649048
I0426 23:46:41.166412 139885868476160 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.48034054040908813, loss=3.6620898246765137
I0426 23:47:07.456136 140061887473472 spec.py:298] Evaluating on the training split.
I0426 23:47:14.408681 140061887473472 spec.py:310] Evaluating on the validation split.
I0426 23:47:24.410236 140061887473472 spec.py:326] Evaluating on the test split.
I0426 23:47:26.617556 140061887473472 submission_runner.py:406] Time since start: 4316.64s, 	Step: 12180, 	{'train/accuracy': 0.6266741156578064, 'train/loss': 1.7987412214279175, 'validation/accuracy': 0.5748800039291382, 'validation/loss': 2.032064914703369, 'validation/num_examples': 50000, 'test/accuracy': 0.453000009059906, 'test/loss': 2.699096918106079, 'test/num_examples': 10000, 'score': 4127.888046979904, 'total_duration': 4316.635741472244, 'accumulated_submission_time': 4127.888046979904, 'accumulated_eval_time': 182.83601355552673, 'accumulated_logging_time': 5.753735542297363}
I0426 23:47:26.627866 139885700687616 logging_writer.py:48] [12180] accumulated_eval_time=182.836014, accumulated_logging_time=5.753736, accumulated_submission_time=4127.888047, global_step=12180, preemption_count=0, score=4127.888047, test/accuracy=0.453000, test/loss=2.699097, test/num_examples=10000, total_duration=4316.635741, train/accuracy=0.626674, train/loss=1.798741, validation/accuracy=0.574880, validation/loss=2.032065, validation/num_examples=50000
I0426 23:47:26.792014 140061887473472 checkpoints.py:356] Saving checkpoint at step: 12180
I0426 23:47:27.409823 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_12180
I0426 23:47:27.418226 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_12180.
I0426 23:47:34.492730 139885868476160 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.4601964056491852, loss=3.610630512237549
I0426 23:48:08.123025 139885692294912 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.4882095754146576, loss=3.543435573577881
I0426 23:48:41.648695 139885868476160 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.4716137945652008, loss=3.6247246265411377
I0426 23:49:15.128034 139885692294912 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.4591679871082306, loss=3.553452253341675
I0426 23:49:48.732130 139885868476160 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.4763186275959015, loss=3.557687997817993
I0426 23:50:22.141324 139885692294912 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.47470128536224365, loss=3.5027735233306885
I0426 23:50:55.691232 139885868476160 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.47908297181129456, loss=3.5886218547821045
I0426 23:51:29.286987 139885692294912 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.48073679208755493, loss=3.528438091278076
I0426 23:52:02.823327 139885868476160 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.4619502127170563, loss=3.494917869567871
I0426 23:52:36.513964 139885692294912 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.4714270830154419, loss=3.514354705810547
I0426 23:53:09.948227 139885868476160 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.4695581793785095, loss=3.5875751972198486
I0426 23:53:43.536036 139885692294912 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.4725944697856903, loss=3.516385078430176
I0426 23:54:16.947617 139885868476160 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.4687926769256592, loss=3.5025219917297363
I0426 23:54:50.528989 139885692294912 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.47230806946754456, loss=3.5565271377563477
I0426 23:55:24.059230 139885868476160 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.4641048014163971, loss=3.53464412689209
I0426 23:55:57.602575 139885692294912 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.4608002007007599, loss=3.465527296066284
I0426 23:55:57.611180 140061887473472 spec.py:298] Evaluating on the training split.
I0426 23:56:05.407228 140061887473472 spec.py:310] Evaluating on the validation split.
I0426 23:56:15.126421 140061887473472 spec.py:326] Evaluating on the test split.
I0426 23:56:17.207469 140061887473472 submission_runner.py:406] Time since start: 4847.22s, 	Step: 13701, 	{'train/accuracy': 0.6530811190605164, 'train/loss': 1.6705456972122192, 'validation/accuracy': 0.6001200079917908, 'validation/loss': 1.90455961227417, 'validation/num_examples': 50000, 'test/accuracy': 0.47780001163482666, 'test/loss': 2.553982973098755, 'test/num_examples': 10000, 'score': 4638.058752298355, 'total_duration': 4847.224492311478, 'accumulated_submission_time': 4638.058752298355, 'accumulated_eval_time': 202.43108248710632, 'accumulated_logging_time': 6.556999206542969}
I0426 23:56:17.223283 139885868476160 logging_writer.py:48] [13701] accumulated_eval_time=202.431082, accumulated_logging_time=6.556999, accumulated_submission_time=4638.058752, global_step=13701, preemption_count=0, score=4638.058752, test/accuracy=0.477800, test/loss=2.553983, test/num_examples=10000, total_duration=4847.224492, train/accuracy=0.653081, train/loss=1.670546, validation/accuracy=0.600120, validation/loss=1.904560, validation/num_examples=50000
I0426 23:56:17.355574 140061887473472 checkpoints.py:356] Saving checkpoint at step: 13701
I0426 23:56:18.073454 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_13701
I0426 23:56:18.084100 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_13701.
I0426 23:56:51.707109 139885692294912 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.458569198846817, loss=3.5151734352111816
I0426 23:57:25.507059 139885407106816 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.46569472551345825, loss=3.5024571418762207
I0426 23:57:59.087139 139885692294912 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.4702322781085968, loss=3.5903427600860596
I0426 23:58:32.628299 139885407106816 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.4763035774230957, loss=3.552473545074463
I0426 23:59:06.072232 139885692294912 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.48252078890800476, loss=3.523839235305786
I0426 23:59:39.607938 139885407106816 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.4686497747898102, loss=3.530468702316284
I0427 00:00:13.275206 139885692294912 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.4525752365589142, loss=3.4426794052124023
I0427 00:00:46.826498 139885407106816 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.4646921753883362, loss=3.451007604598999
I0427 00:01:20.547238 139885692294912 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.46328043937683105, loss=3.437265396118164
I0427 00:01:54.004229 139885407106816 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.4535905420780182, loss=3.4506688117980957
I0427 00:02:27.596014 139885692294912 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.4649551212787628, loss=3.4676969051361084
I0427 00:03:01.336801 139885407106816 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.460129976272583, loss=3.5082194805145264
I0427 00:03:34.707255 139885692294912 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.4537200629711151, loss=3.3699698448181152
I0427 00:04:08.274149 139885407106816 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.449484258890152, loss=3.4503047466278076
I0427 00:04:41.846181 139885692294912 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.46398574113845825, loss=3.4165291786193848
I0427 00:04:48.268906 140061887473472 spec.py:298] Evaluating on the training split.
I0427 00:04:55.370959 140061887473472 spec.py:310] Evaluating on the validation split.
I0427 00:05:05.399660 140061887473472 spec.py:326] Evaluating on the test split.
I0427 00:05:07.634723 140061887473472 submission_runner.py:406] Time since start: 5377.65s, 	Step: 15221, 	{'train/accuracy': 0.6716557741165161, 'train/loss': 1.5797724723815918, 'validation/accuracy': 0.6109600067138672, 'validation/loss': 1.837947964668274, 'validation/num_examples': 50000, 'test/accuracy': 0.48330003023147583, 'test/loss': 2.4912338256835938, 'test/num_examples': 10000, 'score': 5148.217989444733, 'total_duration': 5377.65149307251, 'accumulated_submission_time': 5148.217989444733, 'accumulated_eval_time': 221.79544138908386, 'accumulated_logging_time': 7.439279079437256}
I0427 00:05:07.644119 139885407106816 logging_writer.py:48] [15221] accumulated_eval_time=221.795441, accumulated_logging_time=7.439279, accumulated_submission_time=5148.217989, global_step=15221, preemption_count=0, score=5148.217989, test/accuracy=0.483300, test/loss=2.491234, test/num_examples=10000, total_duration=5377.651493, train/accuracy=0.671656, train/loss=1.579772, validation/accuracy=0.610960, validation/loss=1.837948, validation/num_examples=50000
I0427 00:05:07.806158 140061887473472 checkpoints.py:356] Saving checkpoint at step: 15221
I0427 00:05:08.492401 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_15221
I0427 00:05:08.501470 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_15221.
I0427 00:05:35.393685 139885692294912 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.4745485484600067, loss=3.487123966217041
I0427 00:06:09.086973 139885344163584 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.4723968505859375, loss=3.4372756481170654
I0427 00:06:42.580918 139885692294912 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.4548766613006592, loss=3.4392147064208984
I0427 00:07:16.316169 139885344163584 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.4645535349845886, loss=3.444333076477051
I0427 00:07:49.839926 139885692294912 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.45978662371635437, loss=3.4473507404327393
I0427 00:08:23.489146 139885344163584 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.4709688425064087, loss=3.439772367477417
I0427 00:08:56.983389 139885692294912 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.47344595193862915, loss=3.429473638534546
I0427 00:09:30.548539 139885344163584 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.46181365847587585, loss=3.487484931945801
I0427 00:10:04.080607 139885692294912 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.44239768385887146, loss=3.319774627685547
I0427 00:10:37.610740 139885344163584 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.44283223152160645, loss=3.3711910247802734
I0427 00:11:11.104056 139885692294912 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.4552991986274719, loss=3.455838441848755
I0427 00:11:44.621186 139885344163584 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.4543481171131134, loss=3.3395280838012695
I0427 00:12:18.294808 139885692294912 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.4513830840587616, loss=3.3931713104248047
I0427 00:12:51.768890 139885344163584 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.45154669880867004, loss=3.314356565475464
I0427 00:13:25.314157 139885692294912 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.45675161480903625, loss=3.319761037826538
I0427 00:13:38.807439 140061887473472 spec.py:298] Evaluating on the training split.
I0427 00:13:46.954270 140061887473472 spec.py:310] Evaluating on the validation split.
I0427 00:13:56.984758 140061887473472 spec.py:326] Evaluating on the test split.
I0427 00:13:59.217841 140061887473472 submission_runner.py:406] Time since start: 5909.24s, 	Step: 16742, 	{'train/accuracy': 0.6853475570678711, 'train/loss': 1.5177888870239258, 'validation/accuracy': 0.6274999976158142, 'validation/loss': 1.7792048454284668, 'validation/num_examples': 50000, 'test/accuracy': 0.49810001254081726, 'test/loss': 2.4317128658294678, 'test/num_examples': 10000, 'score': 5658.499128580093, 'total_duration': 5909.235126018524, 'accumulated_submission_time': 5658.499128580093, 'accumulated_eval_time': 242.2049024105072, 'accumulated_logging_time': 8.310751676559448}
I0427 00:13:59.234562 139885344163584 logging_writer.py:48] [16742] accumulated_eval_time=242.204902, accumulated_logging_time=8.310752, accumulated_submission_time=5658.499129, global_step=16742, preemption_count=0, score=5658.499129, test/accuracy=0.498100, test/loss=2.431713, test/num_examples=10000, total_duration=5909.235126, train/accuracy=0.685348, train/loss=1.517789, validation/accuracy=0.627500, validation/loss=1.779205, validation/num_examples=50000
I0427 00:13:59.404732 140061887473472 checkpoints.py:356] Saving checkpoint at step: 16742
I0427 00:14:00.131412 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_16742
I0427 00:14:00.142900 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_16742.
I0427 00:14:20.007668 139885692294912 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.4536172151565552, loss=3.391075372695923
I0427 00:14:53.567751 139885335770880 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.4434519410133362, loss=3.3593342304229736
I0427 00:15:27.163262 139885692294912 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.4397033452987671, loss=3.3593406677246094
I0427 00:16:00.795225 139885335770880 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.447964072227478, loss=3.3372089862823486
I0427 00:16:34.211417 139885692294912 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.44688552618026733, loss=3.336479663848877
I0427 00:17:07.698096 139885335770880 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.46985411643981934, loss=3.429692268371582
I0427 00:17:41.207158 139885692294912 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.45716455578804016, loss=3.2611546516418457
I0427 00:18:14.729517 139885335770880 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.45407217741012573, loss=3.348141670227051
I0427 00:18:48.235142 139885692294912 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.45398661494255066, loss=3.2760515213012695
I0427 00:19:21.837238 139885335770880 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.4450117349624634, loss=3.286771774291992
I0427 00:19:55.408985 139885692294912 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.4492766857147217, loss=3.4214298725128174
I0427 00:20:29.042660 139885335770880 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.4585215151309967, loss=3.365760326385498
I0427 00:21:02.564090 139885692294912 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.449689120054245, loss=3.3501813411712646
I0427 00:21:36.053940 139885335770880 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.4446243345737457, loss=3.3438897132873535
I0427 00:22:09.693943 139885692294912 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.4505995213985443, loss=3.406193494796753
I0427 00:22:30.149438 140061887473472 spec.py:298] Evaluating on the training split.
I0427 00:22:37.722550 140061887473472 spec.py:310] Evaluating on the validation split.
I0427 00:22:47.783794 140061887473472 spec.py:326] Evaluating on the test split.
I0427 00:22:49.857115 140061887473472 submission_runner.py:406] Time since start: 6439.87s, 	Step: 18263, 	{'train/accuracy': 0.7189692258834839, 'train/loss': 1.3828500509262085, 'validation/accuracy': 0.6315799951553345, 'validation/loss': 1.7566077709197998, 'validation/num_examples': 50000, 'test/accuracy': 0.503000020980835, 'test/loss': 2.424915075302124, 'test/num_examples': 10000, 'score': 6168.480010032654, 'total_duration': 6439.874213218689, 'accumulated_submission_time': 6168.480010032654, 'accumulated_eval_time': 261.9114623069763, 'accumulated_logging_time': 9.241178274154663}
I0427 00:22:49.867614 139885335770880 logging_writer.py:48] [18263] accumulated_eval_time=261.911462, accumulated_logging_time=9.241178, accumulated_submission_time=6168.480010, global_step=18263, preemption_count=0, score=6168.480010, test/accuracy=0.503000, test/loss=2.424915, test/num_examples=10000, total_duration=6439.874213, train/accuracy=0.718969, train/loss=1.382850, validation/accuracy=0.631580, validation/loss=1.756608, validation/num_examples=50000
I0427 00:22:50.036509 140061887473472 checkpoints.py:356] Saving checkpoint at step: 18263
I0427 00:22:50.738289 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_18263
I0427 00:22:50.748061 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_18263.
I0427 00:23:03.479534 139885692294912 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.4599927067756653, loss=3.326225757598877
I0427 00:23:36.924721 139885327378176 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.466443806886673, loss=3.391484022140503
I0427 00:24:10.334998 139885692294912 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.45390525460243225, loss=3.2869832515716553
I0427 00:24:43.941134 139885327378176 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.4485863447189331, loss=3.278975009918213
I0427 00:25:17.380377 139885692294912 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.44968682527542114, loss=3.3426995277404785
I0427 00:25:50.853256 139885327378176 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.45502886176109314, loss=3.2970211505889893
I0427 00:26:24.337653 139885692294912 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.4541682302951813, loss=3.275892734527588
I0427 00:26:57.713129 139885327378176 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.45265716314315796, loss=3.3626112937927246
I0427 00:27:31.163914 139885692294912 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.453340619802475, loss=3.293891429901123
I0427 00:28:04.605579 139885327378176 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.44616544246673584, loss=3.2584877014160156
I0427 00:28:38.015874 139885692294912 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.4530505836009979, loss=3.289384365081787
I0427 00:29:11.319382 139885327378176 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.46962660551071167, loss=3.355109453201294
I0427 00:29:44.830458 139885692294912 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.4459957480430603, loss=3.3003387451171875
I0427 00:30:18.271468 139885327378176 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.449674129486084, loss=3.2190005779266357
I0427 00:30:51.677048 139885692294912 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.4582509398460388, loss=3.35245418548584
I0427 00:31:20.910507 140061887473472 spec.py:298] Evaluating on the training split.
I0427 00:31:28.982769 140061887473472 spec.py:310] Evaluating on the validation split.
I0427 00:31:39.018250 140061887473472 spec.py:326] Evaluating on the test split.
I0427 00:31:41.251311 140061887473472 submission_runner.py:406] Time since start: 6971.27s, 	Step: 19789, 	{'train/accuracy': 0.72074294090271, 'train/loss': 1.372436285018921, 'validation/accuracy': 0.6401999592781067, 'validation/loss': 1.7329003810882568, 'validation/num_examples': 50000, 'test/accuracy': 0.5182999968528748, 'test/loss': 2.370762586593628, 'test/num_examples': 10000, 'score': 6678.618223428726, 'total_duration': 6971.268630743027, 'accumulated_submission_time': 6678.618223428726, 'accumulated_eval_time': 282.25138235092163, 'accumulated_logging_time': 10.136670112609863}
I0427 00:31:41.266346 139885327378176 logging_writer.py:48] [19789] accumulated_eval_time=282.251382, accumulated_logging_time=10.136670, accumulated_submission_time=6678.618223, global_step=19789, preemption_count=0, score=6678.618223, test/accuracy=0.518300, test/loss=2.370763, test/num_examples=10000, total_duration=6971.268631, train/accuracy=0.720743, train/loss=1.372436, validation/accuracy=0.640200, validation/loss=1.732900, validation/num_examples=50000
I0427 00:31:41.427398 140061887473472 checkpoints.py:356] Saving checkpoint at step: 19789
I0427 00:31:42.145858 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_19789
I0427 00:31:42.158941 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_19789.
I0427 00:31:46.228792 139885692294912 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.4474486708641052, loss=3.289602518081665
I0427 00:32:19.847920 139884719232768 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.4424796402454376, loss=3.2434751987457275
I0427 00:32:53.446238 139885692294912 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.43060362339019775, loss=3.1941587924957275
I0427 00:33:27.125270 139884719232768 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.4641420543193817, loss=3.364938259124756
I0427 00:34:00.790620 139885692294912 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.44954314827919006, loss=3.2044851779937744
I0427 00:34:34.349339 139884719232768 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.45547038316726685, loss=3.3256969451904297
I0427 00:35:07.889906 139885692294912 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.44496187567710876, loss=3.2839853763580322
I0427 00:35:41.584164 139884719232768 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.44774582982063293, loss=3.2604432106018066
I0427 00:36:15.244924 139885692294912 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.4418792724609375, loss=3.1730170249938965
I0427 00:36:49.119069 139884719232768 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.44571641087532043, loss=3.309925079345703
I0427 00:37:22.700562 139885692294912 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.47073689103126526, loss=3.3536758422851562
I0427 00:37:56.392265 139884719232768 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.44073954224586487, loss=3.252420425415039
I0427 00:38:29.961648 139885692294912 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.46101343631744385, loss=3.1998372077941895
I0427 00:39:03.485833 139884719232768 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.433415949344635, loss=3.224465847015381
I0427 00:39:37.026327 139885692294912 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.45474129915237427, loss=3.249727964401245
I0427 00:40:10.534648 139884719232768 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.43299925327301025, loss=3.242086887359619
I0427 00:40:12.283417 140061887473472 spec.py:298] Evaluating on the training split.
I0427 00:40:19.789541 140061887473472 spec.py:310] Evaluating on the validation split.
I0427 00:40:29.918081 140061887473472 spec.py:326] Evaluating on the test split.
I0427 00:40:31.903451 140061887473472 submission_runner.py:406] Time since start: 7501.92s, 	Step: 21307, 	{'train/accuracy': 0.72953200340271, 'train/loss': 1.3191723823547363, 'validation/accuracy': 0.6532399654388428, 'validation/loss': 1.6574610471725464, 'validation/num_examples': 50000, 'test/accuracy': 0.5200000405311584, 'test/loss': 2.311389446258545, 'test/num_examples': 10000, 'score': 7188.71585059166, 'total_duration': 7501.920667648315, 'accumulated_submission_time': 7188.71585059166, 'accumulated_eval_time': 301.8703987598419, 'accumulated_logging_time': 11.051347494125366}
I0427 00:40:31.916445 139885692294912 logging_writer.py:48] [21307] accumulated_eval_time=301.870399, accumulated_logging_time=11.051347, accumulated_submission_time=7188.715851, global_step=21307, preemption_count=0, score=7188.715851, test/accuracy=0.520000, test/loss=2.311389, test/num_examples=10000, total_duration=7501.920668, train/accuracy=0.729532, train/loss=1.319172, validation/accuracy=0.653240, validation/loss=1.657461, validation/num_examples=50000
I0427 00:40:32.138385 140061887473472 checkpoints.py:356] Saving checkpoint at step: 21307
I0427 00:40:32.909267 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_21307
I0427 00:40:32.919149 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_21307.
I0427 00:41:04.356615 139884719232768 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.4416228234767914, loss=3.237670421600342
I0427 00:41:37.925190 139884710840064 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.45010802149772644, loss=3.27347993850708
I0427 00:42:11.366356 139884719232768 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.4422914385795593, loss=3.2343029975891113
I0427 00:42:44.786401 139884710840064 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.4500153064727783, loss=3.2521421909332275
I0427 00:43:18.225046 139884719232768 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.4340457022190094, loss=3.180925130844116
I0427 00:43:51.764066 139884710840064 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.4447985887527466, loss=3.2179195880889893
I0427 00:44:25.229952 139884719232768 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.45608094334602356, loss=3.231027841567993
I0427 00:44:58.535399 139884710840064 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.4469115138053894, loss=3.2097296714782715
I0427 00:45:32.052688 139884719232768 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.44241446256637573, loss=3.16599440574646
I0427 00:46:05.438467 139884710840064 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.45810797810554504, loss=3.245389938354492
I0427 00:46:38.807196 139884719232768 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.43247824907302856, loss=3.1923067569732666
I0427 00:47:12.388307 139884710840064 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.4421153962612152, loss=3.209625720977783
I0427 00:47:45.944545 139884719232768 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.46429508924484253, loss=3.251464366912842
I0427 00:48:19.393039 139884710840064 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.4562445878982544, loss=3.245983600616455
I0427 00:48:52.752629 139884719232768 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.4478996694087982, loss=3.1251721382141113
I0427 00:49:03.272455 140061887473472 spec.py:298] Evaluating on the training split.
I0427 00:49:11.350976 140061887473472 spec.py:310] Evaluating on the validation split.
I0427 00:49:21.542550 140061887473472 spec.py:326] Evaluating on the test split.
I0427 00:49:23.784680 140061887473472 submission_runner.py:406] Time since start: 8033.80s, 	Step: 22833, 	{'train/accuracy': 0.7308274507522583, 'train/loss': 1.3269572257995605, 'validation/accuracy': 0.6522799730300903, 'validation/loss': 1.6742150783538818, 'validation/num_examples': 50000, 'test/accuracy': 0.5296000242233276, 'test/loss': 2.3113887310028076, 'test/num_examples': 10000, 'score': 7699.043363571167, 'total_duration': 8033.80197095871, 'accumulated_submission_time': 7699.043363571167, 'accumulated_eval_time': 322.3816909790039, 'accumulated_logging_time': 12.072904825210571}
I0427 00:49:23.802641 139884710840064 logging_writer.py:48] [22833] accumulated_eval_time=322.381691, accumulated_logging_time=12.072905, accumulated_submission_time=7699.043364, global_step=22833, preemption_count=0, score=7699.043364, test/accuracy=0.529600, test/loss=2.311389, test/num_examples=10000, total_duration=8033.801971, train/accuracy=0.730827, train/loss=1.326957, validation/accuracy=0.652280, validation/loss=1.674215, validation/num_examples=50000
I0427 00:49:24.011118 140061887473472 checkpoints.py:356] Saving checkpoint at step: 22833
I0427 00:49:24.751818 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_22833
I0427 00:49:24.766574 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_22833.
I0427 00:49:47.479170 139884719232768 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.43247586488723755, loss=3.101864814758301
I0427 00:50:20.939098 139884568229632 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.43430960178375244, loss=3.1497974395751953
I0427 00:50:54.313741 139884719232768 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.4372948706150055, loss=3.198002815246582
I0427 00:51:27.899106 139884568229632 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.4332454204559326, loss=3.188965320587158
I0427 00:52:01.339183 139884719232768 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.44149717688560486, loss=3.22894024848938
I0427 00:52:34.758907 139884568229632 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.45222559571266174, loss=3.2691707611083984
I0427 00:53:08.186785 139884719232768 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.44949543476104736, loss=3.223212242126465
I0427 00:53:41.720263 139884568229632 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.4482020437717438, loss=3.2163326740264893
I0427 00:54:15.113789 139884719232768 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.446212500333786, loss=3.157993793487549
I0427 00:54:48.588046 139884568229632 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.4521457254886627, loss=3.2426414489746094
I0427 00:55:22.029976 139884719232768 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.43344536423683167, loss=3.131192445755005
I0427 00:55:55.549268 139884568229632 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.44971996545791626, loss=3.1969261169433594
I0427 00:56:29.112092 139884719232768 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.43994781374931335, loss=3.219050884246826
I0427 00:57:02.534963 139884568229632 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.44004595279693604, loss=3.191288471221924
I0427 00:57:35.988091 139884719232768 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.4516279697418213, loss=3.190688371658325
I0427 00:57:55.081076 140061887473472 spec.py:298] Evaluating on the training split.
I0427 00:58:02.747340 140061887473472 spec.py:310] Evaluating on the validation split.
I0427 00:58:12.862200 140061887473472 spec.py:326] Evaluating on the test split.
I0427 00:58:14.953066 140061887473472 submission_runner.py:406] Time since start: 8564.97s, 	Step: 24359, 	{'train/accuracy': 0.72757887840271, 'train/loss': 1.3733404874801636, 'validation/accuracy': 0.6517399549484253, 'validation/loss': 1.7120484113693237, 'validation/num_examples': 50000, 'test/accuracy': 0.518500030040741, 'test/loss': 2.37831974029541, 'test/num_examples': 10000, 'score': 8209.32784152031, 'total_duration': 8564.96979355812, 'accumulated_submission_time': 8209.32784152031, 'accumulated_eval_time': 342.2521815299988, 'accumulated_logging_time': 13.06484341621399}
I0427 00:58:14.963819 139884568229632 logging_writer.py:48] [24359] accumulated_eval_time=342.252182, accumulated_logging_time=13.064843, accumulated_submission_time=8209.327842, global_step=24359, preemption_count=0, score=8209.327842, test/accuracy=0.518500, test/loss=2.378320, test/num_examples=10000, total_duration=8564.969794, train/accuracy=0.727579, train/loss=1.373340, validation/accuracy=0.651740, validation/loss=1.712048, validation/num_examples=50000
I0427 00:58:15.158516 140061887473472 checkpoints.py:356] Saving checkpoint at step: 24359
I0427 00:58:15.887280 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_24359
I0427 00:58:15.901477 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_24359.
I0427 00:58:30.070612 139884719232768 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.43038249015808105, loss=3.1752471923828125
I0427 00:59:03.643026 139884559836928 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.447917103767395, loss=3.204162359237671
I0427 00:59:37.223054 139884719232768 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.4404008388519287, loss=3.1956281661987305
I0427 01:00:10.884413 139884559836928 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.4294229745864868, loss=3.195913076400757
I0427 01:00:44.353222 139884719232768 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.4409973621368408, loss=3.1794562339782715
I0427 01:01:17.907790 139884559836928 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.45559626817703247, loss=3.1119394302368164
I0427 01:01:51.578326 139884719232768 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.4211427867412567, loss=3.1499152183532715
I0427 01:02:25.200142 139884559836928 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.45384401082992554, loss=3.2300820350646973
I0427 01:02:58.635842 139884719232768 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.4321620464324951, loss=3.1916871070861816
I0427 01:03:32.210488 139884559836928 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.43501999974250793, loss=3.1368675231933594
I0427 01:04:05.675775 139884719232768 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.4496097266674042, loss=3.2544171810150146
I0427 01:04:39.338440 139884559836928 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.4361775815486908, loss=3.0878727436065674
I0427 01:05:12.837446 139884719232768 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.44773438572883606, loss=3.2179832458496094
I0427 01:05:46.323526 139884559836928 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.4298778772354126, loss=3.0974531173706055
I0427 01:06:19.933367 139884719232768 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.4661928117275238, loss=3.2361345291137695
I0427 01:06:45.921991 140061887473472 spec.py:298] Evaluating on the training split.
I0427 01:06:53.659118 140061887473472 spec.py:310] Evaluating on the validation split.
I0427 01:07:03.931200 140061887473472 spec.py:326] Evaluating on the test split.
I0427 01:07:06.160077 140061887473472 submission_runner.py:406] Time since start: 9096.18s, 	Step: 25879, 	{'train/accuracy': 0.7679567933082581, 'train/loss': 1.2109427452087402, 'validation/accuracy': 0.6653800010681152, 'validation/loss': 1.642090916633606, 'validation/num_examples': 50000, 'test/accuracy': 0.5355000495910645, 'test/loss': 2.2904434204101562, 'test/num_examples': 10000, 'score': 8719.314158916473, 'total_duration': 9096.177446603775, 'accumulated_submission_time': 8719.314158916473, 'accumulated_eval_time': 362.48942732810974, 'accumulated_logging_time': 14.027581930160522}
I0427 01:07:06.170705 139884559836928 logging_writer.py:48] [25879] accumulated_eval_time=362.489427, accumulated_logging_time=14.027582, accumulated_submission_time=8719.314159, global_step=25879, preemption_count=0, score=8719.314159, test/accuracy=0.535500, test/loss=2.290443, test/num_examples=10000, total_duration=9096.177447, train/accuracy=0.767957, train/loss=1.210943, validation/accuracy=0.665380, validation/loss=1.642091, validation/num_examples=50000
I0427 01:07:06.372450 140061887473472 checkpoints.py:356] Saving checkpoint at step: 25879
I0427 01:07:07.092527 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_25879
I0427 01:07:07.106050 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_25879.
I0427 01:07:14.475096 139884719232768 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.43515366315841675, loss=3.118096113204956
I0427 01:07:47.842504 139884551444224 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.4219927191734314, loss=3.0489039421081543
I0427 01:08:21.278599 139884719232768 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.4375917315483093, loss=3.229691982269287
I0427 01:08:54.774723 139884551444224 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.4460030794143677, loss=3.1715197563171387
I0427 01:09:28.232986 139884719232768 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.4497438967227936, loss=3.071937084197998
I0427 01:10:01.648031 139884551444224 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.4455101788043976, loss=3.119154930114746
I0427 01:10:35.058062 139884719232768 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.447515070438385, loss=3.1381349563598633
I0427 01:11:08.539787 139884551444224 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.4497286379337311, loss=3.118086576461792
I0427 01:11:41.975057 139884719232768 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.4338356554508209, loss=3.1194701194763184
I0427 01:12:15.407346 139884551444224 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.45295462012290955, loss=3.185288429260254
I0427 01:12:48.896874 139884719232768 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.4252183437347412, loss=3.0909464359283447
I0427 01:13:22.384914 139884551444224 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.43653538823127747, loss=3.1399247646331787
I0427 01:13:55.734697 139884719232768 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.4415223002433777, loss=3.1304798126220703
I0427 01:14:29.296602 139884551444224 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.45049387216567993, loss=3.2029566764831543
I0427 01:15:02.705136 139884719232768 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.42944708466529846, loss=3.16597580909729
I0427 01:15:36.184673 139884551444224 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.44523248076438904, loss=3.1124184131622314
I0427 01:15:37.254848 140061887473472 spec.py:298] Evaluating on the training split.
I0427 01:15:45.029234 140061887473472 spec.py:310] Evaluating on the validation split.
I0427 01:15:55.538143 140061887473472 spec.py:326] Evaluating on the test split.
I0427 01:15:57.512001 140061887473472 submission_runner.py:406] Time since start: 9627.53s, 	Step: 27405, 	{'train/accuracy': 0.7732182741165161, 'train/loss': 1.1157804727554321, 'validation/accuracy': 0.670699954032898, 'validation/loss': 1.5561143159866333, 'validation/num_examples': 50000, 'test/accuracy': 0.5458000302314758, 'test/loss': 2.209757089614868, 'test/num_examples': 10000, 'score': 9229.433425426483, 'total_duration': 9627.528837442398, 'accumulated_submission_time': 9229.433425426483, 'accumulated_eval_time': 382.74518609046936, 'accumulated_logging_time': 14.982901096343994}
I0427 01:15:57.522493 139884719232768 logging_writer.py:48] [27405] accumulated_eval_time=382.745186, accumulated_logging_time=14.982901, accumulated_submission_time=9229.433425, global_step=27405, preemption_count=0, score=9229.433425, test/accuracy=0.545800, test/loss=2.209757, test/num_examples=10000, total_duration=9627.528837, train/accuracy=0.773218, train/loss=1.115780, validation/accuracy=0.670700, validation/loss=1.556114, validation/num_examples=50000
I0427 01:15:57.732788 140061887473472 checkpoints.py:356] Saving checkpoint at step: 27405
I0427 01:15:58.472266 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_27405
I0427 01:15:58.484842 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_27405.
I0427 01:16:30.565048 139884551444224 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.42839714884757996, loss=3.1320254802703857
I0427 01:17:04.172578 139884543051520 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.44225913286209106, loss=3.1507275104522705
I0427 01:17:37.659684 139884551444224 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.4372725486755371, loss=3.1302473545074463
I0427 01:18:11.120511 139884543051520 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.4426306188106537, loss=3.249760150909424
I0427 01:18:44.602529 139884551444224 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.44672608375549316, loss=3.217092990875244
I0427 01:19:17.466821 140061887473472 spec.py:298] Evaluating on the training split.
I0427 01:19:25.326993 140061887473472 spec.py:310] Evaluating on the validation split.
I0427 01:19:35.691511 140061887473472 spec.py:326] Evaluating on the test split.
I0427 01:19:37.775360 140061887473472 submission_runner.py:406] Time since start: 9847.79s, 	Step: 28000, 	{'train/accuracy': 0.7566764950752258, 'train/loss': 1.1579759120941162, 'validation/accuracy': 0.6671800017356873, 'validation/loss': 1.5538759231567383, 'validation/num_examples': 50000, 'test/accuracy': 0.5365000367164612, 'test/loss': 2.2229208946228027, 'test/num_examples': 10000, 'score': 9428.39398765564, 'total_duration': 9847.792346477509, 'accumulated_submission_time': 9428.39398765564, 'accumulated_eval_time': 403.05249071121216, 'accumulated_logging_time': 15.968958377838135}
I0427 01:19:37.786389 139884543051520 logging_writer.py:48] [28000] accumulated_eval_time=403.052491, accumulated_logging_time=15.968958, accumulated_submission_time=9428.393988, global_step=28000, preemption_count=0, score=9428.393988, test/accuracy=0.536500, test/loss=2.222921, test/num_examples=10000, total_duration=9847.792346, train/accuracy=0.756676, train/loss=1.157976, validation/accuracy=0.667180, validation/loss=1.553876, validation/num_examples=50000
I0427 01:19:37.968499 140061887473472 checkpoints.py:356] Saving checkpoint at step: 28000
I0427 01:19:38.709555 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_28000
I0427 01:19:38.722585 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_28000.
I0427 01:19:38.750191 139884551444224 logging_writer.py:48] [28000] global_step=28000, preemption_count=0, score=9428.393988
I0427 01:19:38.949046 140061887473472 checkpoints.py:356] Saving checkpoint at step: 28000
I0427 01:19:39.950016 140061887473472 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_28000
I0427 01:19:39.961501 140061887473472 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_resnet_jax/trial_1/checkpoint_28000.
I0427 01:19:40.371858 140061887473472 submission_runner.py:567] Tuning trial 1/1
I0427 01:19:40.374817 140061887473472 submission_runner.py:568] Hyperparameters: Hyperparameters(learning_rate=0.4394877561366806, one_minus_beta1=0.07113602458522507, warmup_factor=0.05, weight_decay=9.611851572925426e-07, label_smoothing=0.2, dropout_rate=0.0, decay_steps_factor=0.9, end_factor=0.001)
I0427 01:19:40.378469 140061887473472 submission_runner.py:569] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0012954400153830647, 'train/loss': 6.910459995269775, 'validation/accuracy': 0.0011399999493733048, 'validation/loss': 6.910703182220459, 'validation/num_examples': 50000, 'test/accuracy': 0.0010999999940395355, 'test/loss': 6.910574436187744, 'test/num_examples': 10000, 'score': 46.78730607032776, 'total_duration': 87.34082508087158, 'accumulated_submission_time': 46.78730607032776, 'accumulated_eval_time': 40.55333161354065, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (1524, {'train/accuracy': 0.0679408460855484, 'train/loss': 5.441141605377197, 'validation/accuracy': 0.06137999892234802, 'validation/loss': 5.524351119995117, 'validation/num_examples': 50000, 'test/accuracy': 0.04180000349879265, 'test/loss': 5.737311363220215, 'test/num_examples': 10000, 'score': 556.8747472763062, 'total_duration': 615.1840131282806, 'accumulated_submission_time': 556.8747472763062, 'accumulated_eval_time': 57.66414165496826, 'accumulated_logging_time': 0.6250734329223633, 'global_step': 1524, 'preemption_count': 0}), (3047, {'train/accuracy': 0.17442601919174194, 'train/loss': 4.409230709075928, 'validation/accuracy': 0.15838000178337097, 'validation/loss': 4.521397590637207, 'validation/num_examples': 50000, 'test/accuracy': 0.11670000851154327, 'test/loss': 4.950851917266846, 'test/num_examples': 10000, 'score': 1067.075849533081, 'total_duration': 1143.1555767059326, 'accumulated_submission_time': 1067.075849533081, 'accumulated_eval_time': 74.77139067649841, 'accumulated_logging_time': 1.2682819366455078, 'global_step': 3047, 'preemption_count': 0}), (4571, {'train/accuracy': 0.2869897782802582, 'train/loss': 3.5225231647491455, 'validation/accuracy': 0.26646000146865845, 'validation/loss': 3.648171901702881, 'validation/num_examples': 50000, 'test/accuracy': 0.1931000053882599, 'test/loss': 4.25665283203125, 'test/num_examples': 10000, 'score': 1577.1433110237122, 'total_duration': 1670.663868188858, 'accumulated_submission_time': 1577.1433110237122, 'accumulated_eval_time': 91.568692445755, 'accumulated_logging_time': 1.891874074935913, 'global_step': 4571, 'preemption_count': 0}), (6095, {'train/accuracy': 0.41555723547935486, 'train/loss': 2.781505584716797, 'validation/accuracy': 0.3933199942111969, 'validation/loss': 2.9008870124816895, 'validation/num_examples': 50000, 'test/accuracy': 0.2964000105857849, 'test/loss': 3.5172743797302246, 'test/num_examples': 10000, 'score': 2087.3816072940826, 'total_duration': 2198.6108644008636, 'accumulated_submission_time': 2087.3816072940826, 'accumulated_eval_time': 108.63148593902588, 'accumulated_logging_time': 2.5181524753570557, 'global_step': 6095, 'preemption_count': 0}), (7615, {'train/accuracy': 0.47183912992477417, 'train/loss': 2.6564807891845703, 'validation/accuracy': 0.4442199766635895, 'validation/loss': 2.799440860748291, 'validation/num_examples': 50000, 'test/accuracy': 0.32990002632141113, 'test/loss': 3.4517064094543457, 'test/num_examples': 10000, 'score': 2597.4725244045258, 'total_duration': 2726.713265657425, 'accumulated_submission_time': 2597.4725244045258, 'accumulated_eval_time': 125.81799030303955, 'accumulated_logging_time': 3.323435068130493, 'global_step': 7615, 'preemption_count': 0}), (9133, {'train/accuracy': 0.5660275816917419, 'train/loss': 2.136199712753296, 'validation/accuracy': 0.4989199936389923, 'validation/loss': 2.4529521465301514, 'validation/num_examples': 50000, 'test/accuracy': 0.3822000324726105, 'test/loss': 3.086632251739502, 'test/num_examples': 10000, 'score': 3107.56387257576, 'total_duration': 3257.3658995628357, 'accumulated_submission_time': 3107.56387257576, 'accumulated_eval_time': 145.50947260856628, 'accumulated_logging_time': 4.1740882396698, 'global_step': 9133, 'preemption_count': 0}), (10659, {'train/accuracy': 0.5920758843421936, 'train/loss': 1.8975021839141846, 'validation/accuracy': 0.5415599942207336, 'validation/loss': 2.1408050060272217, 'validation/num_examples': 50000, 'test/accuracy': 0.42570000886917114, 'test/loss': 2.802159547805786, 'test/num_examples': 10000, 'score': 3617.6776809692383, 'total_duration': 3786.3283021450043, 'accumulated_submission_time': 3617.6776809692383, 'accumulated_eval_time': 163.67462801933289, 'accumulated_logging_time': 4.837895154953003, 'global_step': 10659, 'preemption_count': 0}), (12180, {'train/accuracy': 0.6266741156578064, 'train/loss': 1.7987412214279175, 'validation/accuracy': 0.5748800039291382, 'validation/loss': 2.032064914703369, 'validation/num_examples': 50000, 'test/accuracy': 0.453000009059906, 'test/loss': 2.699096918106079, 'test/num_examples': 10000, 'score': 4127.888046979904, 'total_duration': 4316.635741472244, 'accumulated_submission_time': 4127.888046979904, 'accumulated_eval_time': 182.83601355552673, 'accumulated_logging_time': 5.753735542297363, 'global_step': 12180, 'preemption_count': 0}), (13701, {'train/accuracy': 0.6530811190605164, 'train/loss': 1.6705456972122192, 'validation/accuracy': 0.6001200079917908, 'validation/loss': 1.90455961227417, 'validation/num_examples': 50000, 'test/accuracy': 0.47780001163482666, 'test/loss': 2.553982973098755, 'test/num_examples': 10000, 'score': 4638.058752298355, 'total_duration': 4847.224492311478, 'accumulated_submission_time': 4638.058752298355, 'accumulated_eval_time': 202.43108248710632, 'accumulated_logging_time': 6.556999206542969, 'global_step': 13701, 'preemption_count': 0}), (15221, {'train/accuracy': 0.6716557741165161, 'train/loss': 1.5797724723815918, 'validation/accuracy': 0.6109600067138672, 'validation/loss': 1.837947964668274, 'validation/num_examples': 50000, 'test/accuracy': 0.48330003023147583, 'test/loss': 2.4912338256835938, 'test/num_examples': 10000, 'score': 5148.217989444733, 'total_duration': 5377.65149307251, 'accumulated_submission_time': 5148.217989444733, 'accumulated_eval_time': 221.79544138908386, 'accumulated_logging_time': 7.439279079437256, 'global_step': 15221, 'preemption_count': 0}), (16742, {'train/accuracy': 0.6853475570678711, 'train/loss': 1.5177888870239258, 'validation/accuracy': 0.6274999976158142, 'validation/loss': 1.7792048454284668, 'validation/num_examples': 50000, 'test/accuracy': 0.49810001254081726, 'test/loss': 2.4317128658294678, 'test/num_examples': 10000, 'score': 5658.499128580093, 'total_duration': 5909.235126018524, 'accumulated_submission_time': 5658.499128580093, 'accumulated_eval_time': 242.2049024105072, 'accumulated_logging_time': 8.310751676559448, 'global_step': 16742, 'preemption_count': 0}), (18263, {'train/accuracy': 0.7189692258834839, 'train/loss': 1.3828500509262085, 'validation/accuracy': 0.6315799951553345, 'validation/loss': 1.7566077709197998, 'validation/num_examples': 50000, 'test/accuracy': 0.503000020980835, 'test/loss': 2.424915075302124, 'test/num_examples': 10000, 'score': 6168.480010032654, 'total_duration': 6439.874213218689, 'accumulated_submission_time': 6168.480010032654, 'accumulated_eval_time': 261.9114623069763, 'accumulated_logging_time': 9.241178274154663, 'global_step': 18263, 'preemption_count': 0}), (19789, {'train/accuracy': 0.72074294090271, 'train/loss': 1.372436285018921, 'validation/accuracy': 0.6401999592781067, 'validation/loss': 1.7329003810882568, 'validation/num_examples': 50000, 'test/accuracy': 0.5182999968528748, 'test/loss': 2.370762586593628, 'test/num_examples': 10000, 'score': 6678.618223428726, 'total_duration': 6971.268630743027, 'accumulated_submission_time': 6678.618223428726, 'accumulated_eval_time': 282.25138235092163, 'accumulated_logging_time': 10.136670112609863, 'global_step': 19789, 'preemption_count': 0}), (21307, {'train/accuracy': 0.72953200340271, 'train/loss': 1.3191723823547363, 'validation/accuracy': 0.6532399654388428, 'validation/loss': 1.6574610471725464, 'validation/num_examples': 50000, 'test/accuracy': 0.5200000405311584, 'test/loss': 2.311389446258545, 'test/num_examples': 10000, 'score': 7188.71585059166, 'total_duration': 7501.920667648315, 'accumulated_submission_time': 7188.71585059166, 'accumulated_eval_time': 301.8703987598419, 'accumulated_logging_time': 11.051347494125366, 'global_step': 21307, 'preemption_count': 0}), (22833, {'train/accuracy': 0.7308274507522583, 'train/loss': 1.3269572257995605, 'validation/accuracy': 0.6522799730300903, 'validation/loss': 1.6742150783538818, 'validation/num_examples': 50000, 'test/accuracy': 0.5296000242233276, 'test/loss': 2.3113887310028076, 'test/num_examples': 10000, 'score': 7699.043363571167, 'total_duration': 8033.80197095871, 'accumulated_submission_time': 7699.043363571167, 'accumulated_eval_time': 322.3816909790039, 'accumulated_logging_time': 12.072904825210571, 'global_step': 22833, 'preemption_count': 0}), (24359, {'train/accuracy': 0.72757887840271, 'train/loss': 1.3733404874801636, 'validation/accuracy': 0.6517399549484253, 'validation/loss': 1.7120484113693237, 'validation/num_examples': 50000, 'test/accuracy': 0.518500030040741, 'test/loss': 2.37831974029541, 'test/num_examples': 10000, 'score': 8209.32784152031, 'total_duration': 8564.96979355812, 'accumulated_submission_time': 8209.32784152031, 'accumulated_eval_time': 342.2521815299988, 'accumulated_logging_time': 13.06484341621399, 'global_step': 24359, 'preemption_count': 0}), (25879, {'train/accuracy': 0.7679567933082581, 'train/loss': 1.2109427452087402, 'validation/accuracy': 0.6653800010681152, 'validation/loss': 1.642090916633606, 'validation/num_examples': 50000, 'test/accuracy': 0.5355000495910645, 'test/loss': 2.2904434204101562, 'test/num_examples': 10000, 'score': 8719.314158916473, 'total_duration': 9096.177446603775, 'accumulated_submission_time': 8719.314158916473, 'accumulated_eval_time': 362.48942732810974, 'accumulated_logging_time': 14.027581930160522, 'global_step': 25879, 'preemption_count': 0}), (27405, {'train/accuracy': 0.7732182741165161, 'train/loss': 1.1157804727554321, 'validation/accuracy': 0.670699954032898, 'validation/loss': 1.5561143159866333, 'validation/num_examples': 50000, 'test/accuracy': 0.5458000302314758, 'test/loss': 2.209757089614868, 'test/num_examples': 10000, 'score': 9229.433425426483, 'total_duration': 9627.528837442398, 'accumulated_submission_time': 9229.433425426483, 'accumulated_eval_time': 382.74518609046936, 'accumulated_logging_time': 14.982901096343994, 'global_step': 27405, 'preemption_count': 0}), (28000, {'train/accuracy': 0.7566764950752258, 'train/loss': 1.1579759120941162, 'validation/accuracy': 0.6671800017356873, 'validation/loss': 1.5538759231567383, 'validation/num_examples': 50000, 'test/accuracy': 0.5365000367164612, 'test/loss': 2.2229208946228027, 'test/num_examples': 10000, 'score': 9428.39398765564, 'total_duration': 9847.792346477509, 'accumulated_submission_time': 9428.39398765564, 'accumulated_eval_time': 403.05249071121216, 'accumulated_logging_time': 15.968958377838135, 'global_step': 28000, 'preemption_count': 0})], 'global_step': 28000}
I0427 01:19:40.378586 140061887473472 submission_runner.py:570] Timing: 9428.39398765564
I0427 01:19:40.378633 140061887473472 submission_runner.py:571] ====================
I0427 01:19:40.378755 140061887473472 submission_runner.py:631] Final imagenet_resnet score: 9428.39398765564
