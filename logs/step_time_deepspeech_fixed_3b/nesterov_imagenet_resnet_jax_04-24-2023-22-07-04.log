I0424 22:07:26.032729 139763077670720 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax.
I0424 22:07:26.096022 139763077670720 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0424 22:07:26.989155 139763077670720 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Host CUDA Interpreter
I0424 22:07:26.990175 139763077670720 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0424 22:07:26.994400 139763077670720 submission_runner.py:528] Using RNG seed 3927487234
I0424 22:07:29.642772 139763077670720 submission_runner.py:537] --- Tuning run 1/1 ---
I0424 22:07:29.643009 139763077670720 submission_runner.py:542] Creating tuning directory at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1.
I0424 22:07:29.643317 139763077670720 logger_utils.py:83] Saving hparams to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/hparams.json.
I0424 22:07:29.763541 139763077670720 submission_runner.py:232] Initializing dataset.
I0424 22:07:29.775460 139763077670720 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0424 22:07:29.783381 139763077670720 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0424 22:07:29.783494 139763077670720 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0424 22:07:30.035696 139763077670720 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0424 22:07:31.099009 139763077670720 submission_runner.py:239] Initializing model.
I0424 22:07:42.345393 139763077670720 submission_runner.py:249] Initializing optimizer.
I0424 22:07:43.271683 139763077670720 submission_runner.py:256] Initializing metrics bundle.
I0424 22:07:43.271852 139763077670720 submission_runner.py:273] Initializing checkpoint and logger.
I0424 22:07:43.272706 139763077670720 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1 with prefix checkpoint_
I0424 22:07:43.962204 139763077670720 submission_runner.py:294] Saving meta data to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/meta_data_0.json.
I0424 22:07:43.963060 139763077670720 submission_runner.py:297] Saving flags to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/flags_0.json.
I0424 22:07:43.967700 139763077670720 submission_runner.py:309] Starting training loop.
I0424 22:08:30.213425 139579071911680 logging_writer.py:48] [0] global_step=0, grad_norm=0.5367512106895447, loss=6.939493179321289
I0424 22:08:30.227241 139763077670720 spec.py:298] Evaluating on the training split.
I0424 22:08:30.694031 139763077670720 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0424 22:08:30.699876 139763077670720 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0424 22:08:30.700034 139763077670720 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0424 22:08:30.757962 139763077670720 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0424 22:08:42.283035 139763077670720 spec.py:310] Evaluating on the validation split.
I0424 22:08:43.008919 139763077670720 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0424 22:08:43.037233 139763077670720 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0424 22:08:43.037468 139763077670720 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0424 22:08:43.084084 139763077670720 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0424 22:09:00.702837 139763077670720 spec.py:326] Evaluating on the test split.
I0424 22:09:01.097278 139763077670720 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0424 22:09:01.101666 139763077670720 dataset_builder.py:510] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0424 22:09:01.129709 139763077670720 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0424 22:09:10.195088 139763077670720 submission_runner.py:406] Time since start: 86.23s, 	Step: 1, 	{'train/accuracy': 0.0010961415246129036, 'train/loss': 6.91009521484375, 'validation/accuracy': 0.0010999999940395355, 'validation/loss': 6.910689353942871, 'validation/num_examples': 50000, 'test/accuracy': 0.0010999999940395355, 'test/loss': 6.910574436187744, 'test/num_examples': 10000, 'score': 46.25933313369751, 'total_duration': 86.2273280620575, 'accumulated_submission_time': 46.25933313369751, 'accumulated_eval_time': 39.96780347824097, 'accumulated_logging_time': 0}
I0424 22:09:10.212404 139556326188800 logging_writer.py:48] [1] accumulated_eval_time=39.967803, accumulated_logging_time=0, accumulated_submission_time=46.259333, global_step=1, preemption_count=0, score=46.259333, test/accuracy=0.001100, test/loss=6.910574, test/num_examples=10000, total_duration=86.227328, train/accuracy=0.001096, train/loss=6.910095, validation/accuracy=0.001100, validation/loss=6.910689, validation/num_examples=50000
I0424 22:09:10.321997 139763077670720 checkpoints.py:356] Saving checkpoint at step: 1
I0424 22:09:10.749584 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_1
I0424 22:09:10.750436 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_1.
I0424 22:09:44.652478 139556334581504 logging_writer.py:48] [100] global_step=100, grad_norm=0.5484989285469055, loss=6.8880181312561035
I0424 22:10:18.379612 139557337016064 logging_writer.py:48] [200] global_step=200, grad_norm=0.5690404772758484, loss=6.802918910980225
I0424 22:10:52.332055 139556334581504 logging_writer.py:48] [300] global_step=300, grad_norm=0.6036586761474609, loss=6.671280860900879
I0424 22:11:26.051231 139557337016064 logging_writer.py:48] [400] global_step=400, grad_norm=0.6343953013420105, loss=6.59280252456665
I0424 22:11:59.877315 139556334581504 logging_writer.py:48] [500] global_step=500, grad_norm=0.6494849324226379, loss=6.521437644958496
I0424 22:12:33.947139 139557337016064 logging_writer.py:48] [600] global_step=600, grad_norm=0.7328636646270752, loss=6.477146148681641
I0424 22:13:07.861565 139556334581504 logging_writer.py:48] [700] global_step=700, grad_norm=0.7865789532661438, loss=6.421465873718262
I0424 22:13:41.686089 139557337016064 logging_writer.py:48] [800] global_step=800, grad_norm=0.7519909143447876, loss=6.36991548538208
I0424 22:14:15.491741 139556334581504 logging_writer.py:48] [900] global_step=900, grad_norm=0.7033570408821106, loss=6.3140950202941895
I0424 22:14:49.244956 139557337016064 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.5312812328338623, loss=6.303248405456543
I0424 22:15:23.102294 139556334581504 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.9603942632675171, loss=6.2257466316223145
I0424 22:15:56.888233 139557337016064 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.8150888085365295, loss=6.152383804321289
I0424 22:16:30.743956 139556334581504 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.7780577540397644, loss=6.096775531768799
I0424 22:17:04.358760 139557337016064 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.8898715972900391, loss=6.095135688781738
I0424 22:17:38.300667 139556334581504 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.8047043085098267, loss=5.985642433166504
I0424 22:17:41.049204 139763077670720 spec.py:298] Evaluating on the training split.
I0424 22:17:48.114905 139763077670720 spec.py:310] Evaluating on the validation split.
I0424 22:17:55.908937 139763077670720 spec.py:326] Evaluating on the test split.
I0424 22:17:57.993932 139763077670720 submission_runner.py:406] Time since start: 614.03s, 	Step: 1510, 	{'train/accuracy': 0.07499600946903229, 'train/loss': 5.420688629150391, 'validation/accuracy': 0.0674000009894371, 'validation/loss': 5.502216339111328, 'validation/num_examples': 50000, 'test/accuracy': 0.048500001430511475, 'test/loss': 5.727884769439697, 'test/num_examples': 10000, 'score': 556.5377888679504, 'total_duration': 614.0261564254761, 'accumulated_submission_time': 556.5377888679504, 'accumulated_eval_time': 56.912503480911255, 'accumulated_logging_time': 0.5584824085235596}
I0424 22:17:58.001312 139557353801472 logging_writer.py:48] [1510] accumulated_eval_time=56.912503, accumulated_logging_time=0.558482, accumulated_submission_time=556.537789, global_step=1510, preemption_count=0, score=556.537789, test/accuracy=0.048500, test/loss=5.727885, test/num_examples=10000, total_duration=614.026156, train/accuracy=0.074996, train/loss=5.420689, validation/accuracy=0.067400, validation/loss=5.502216, validation/num_examples=50000
I0424 22:17:58.124736 139763077670720 checkpoints.py:356] Saving checkpoint at step: 1510
I0424 22:17:58.543103 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_1510
I0424 22:17:58.543971 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_1510.
I0424 22:18:29.303942 139557362194176 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.9959395527839661, loss=5.979389190673828
I0424 22:19:02.907801 139582985193216 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.9053781628608704, loss=5.870058059692383
I0424 22:19:36.775159 139557362194176 logging_writer.py:48] [1800] global_step=1800, grad_norm=1.0918138027191162, loss=5.859346389770508
I0424 22:20:10.383689 139582985193216 logging_writer.py:48] [1900] global_step=1900, grad_norm=1.1601300239562988, loss=5.747348785400391
I0424 22:20:44.393857 139557362194176 logging_writer.py:48] [2000] global_step=2000, grad_norm=1.0597656965255737, loss=5.6567230224609375
I0424 22:21:18.095577 139582985193216 logging_writer.py:48] [2100] global_step=2100, grad_norm=1.0084692239761353, loss=5.657317161560059
I0424 22:21:51.814156 139557362194176 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.8939616680145264, loss=5.597456455230713
I0424 22:22:25.541793 139582985193216 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.948731005191803, loss=5.538265228271484
I0424 22:22:59.320814 139557362194176 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.9436348080635071, loss=5.407986164093018
I0424 22:23:32.962972 139582985193216 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.939361572265625, loss=5.418974876403809
I0424 22:24:06.607861 139557362194176 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.887410581111908, loss=5.29175329208374
I0424 22:24:40.176347 139582985193216 logging_writer.py:48] [2700] global_step=2700, grad_norm=1.0486942529678345, loss=5.196375370025635
I0424 22:25:13.988330 139557362194176 logging_writer.py:48] [2800] global_step=2800, grad_norm=1.0091869831085205, loss=5.23772668838501
I0424 22:25:47.659782 139582985193216 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.9365769624710083, loss=5.133529186248779
I0424 22:26:21.512012 139557362194176 logging_writer.py:48] [3000] global_step=3000, grad_norm=1.0229278802871704, loss=5.113658428192139
I0424 22:26:28.663403 139763077670720 spec.py:298] Evaluating on the training split.
I0424 22:26:35.472666 139763077670720 spec.py:310] Evaluating on the validation split.
I0424 22:26:43.343593 139763077670720 spec.py:326] Evaluating on the test split.
I0424 22:26:45.342885 139763077670720 submission_runner.py:406] Time since start: 1141.38s, 	Step: 3023, 	{'train/accuracy': 0.2230149805545807, 'train/loss': 4.002138614654541, 'validation/accuracy': 0.2015399932861328, 'validation/loss': 4.115724086761475, 'validation/num_examples': 50000, 'test/accuracy': 0.14680001139640808, 'test/loss': 4.599239826202393, 'test/num_examples': 10000, 'score': 1066.6351895332336, 'total_duration': 1141.3751361370087, 'accumulated_submission_time': 1066.6351895332336, 'accumulated_eval_time': 73.59198427200317, 'accumulated_logging_time': 1.113279104232788}
I0424 22:26:45.354702 139582985193216 logging_writer.py:48] [3023] accumulated_eval_time=73.591984, accumulated_logging_time=1.113279, accumulated_submission_time=1066.635190, global_step=3023, preemption_count=0, score=1066.635190, test/accuracy=0.146800, test/loss=4.599240, test/num_examples=10000, total_duration=1141.375136, train/accuracy=0.223015, train/loss=4.002139, validation/accuracy=0.201540, validation/loss=4.115724, validation/num_examples=50000
I0424 22:26:45.482326 139763077670720 checkpoints.py:356] Saving checkpoint at step: 3023
I0424 22:26:45.900290 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_3023
I0424 22:26:45.901168 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_3023.
I0424 22:27:12.131475 139557362194176 logging_writer.py:48] [3100] global_step=3100, grad_norm=1.0012189149856567, loss=5.133716583251953
I0424 22:27:45.990370 139582951622400 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.9178833961486816, loss=5.077058792114258
I0424 22:28:19.665702 139557362194176 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.9699426889419556, loss=5.027050018310547
I0424 22:28:53.477486 139582951622400 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.9135202765464783, loss=4.92324161529541
I0424 22:29:27.164820 139557362194176 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.9437423944473267, loss=4.938228130340576
I0424 22:30:00.970613 139582951622400 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.8847622275352478, loss=4.795968055725098
I0424 22:30:34.670996 139557362194176 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.9150195121765137, loss=4.830869674682617
I0424 22:31:08.382870 139582951622400 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.8323971033096313, loss=4.7641520500183105
I0424 22:31:42.076606 139557362194176 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.8202638030052185, loss=4.751317977905273
I0424 22:32:15.781311 139582951622400 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.8694136142730713, loss=4.725569248199463
I0424 22:32:49.602412 139557362194176 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.875299870967865, loss=4.705936431884766
I0424 22:33:23.388806 139582951622400 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.908515214920044, loss=4.60059928894043
I0424 22:33:56.905777 139557362194176 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.8365287780761719, loss=4.641447067260742
I0424 22:34:30.585426 139582951622400 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.7935614585876465, loss=4.505486965179443
I0424 22:35:04.228848 139557362194176 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.7918294668197632, loss=4.551506996154785
I0424 22:35:16.054058 139763077670720 spec.py:298] Evaluating on the training split.
I0424 22:35:22.813781 139763077670720 spec.py:310] Evaluating on the validation split.
I0424 22:35:30.617614 139763077670720 spec.py:326] Evaluating on the test split.
I0424 22:35:32.815024 139763077670720 submission_runner.py:406] Time since start: 1668.85s, 	Step: 4537, 	{'train/accuracy': 0.3521205186843872, 'train/loss': 3.1945250034332275, 'validation/accuracy': 0.3262999951839447, 'validation/loss': 3.331960916519165, 'validation/num_examples': 50000, 'test/accuracy': 0.23360000550746918, 'test/loss': 3.9342336654663086, 'test/num_examples': 10000, 'score': 1576.7663085460663, 'total_duration': 1668.8472757339478, 'accumulated_submission_time': 1576.7663085460663, 'accumulated_eval_time': 90.35292911529541, 'accumulated_logging_time': 1.6765480041503906}
I0424 22:35:32.823735 139582951622400 logging_writer.py:48] [4537] accumulated_eval_time=90.352929, accumulated_logging_time=1.676548, accumulated_submission_time=1576.766309, global_step=4537, preemption_count=0, score=1576.766309, test/accuracy=0.233600, test/loss=3.934234, test/num_examples=10000, total_duration=1668.847276, train/accuracy=0.352121, train/loss=3.194525, validation/accuracy=0.326300, validation/loss=3.331961, validation/num_examples=50000
I0424 22:35:32.974145 139763077670720 checkpoints.py:356] Saving checkpoint at step: 4537
I0424 22:35:33.550732 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_4537
I0424 22:35:33.551607 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_4537.
I0424 22:35:55.231953 139557362194176 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.7768189907073975, loss=4.5011491775512695
I0424 22:36:29.217510 139582943229696 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.7940449118614197, loss=4.5478901863098145
I0424 22:37:03.127516 139557362194176 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.7407803535461426, loss=4.495732307434082
I0424 22:37:36.897966 139582943229696 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.7647225856781006, loss=4.384377956390381
I0424 22:38:10.619650 139557362194176 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.7958995699882507, loss=4.452398777008057
I0424 22:38:44.423297 139582943229696 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.7551674246788025, loss=4.39572811126709
I0424 22:39:18.122357 139557362194176 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.7310152053833008, loss=4.314399719238281
I0424 22:39:51.722066 139582943229696 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.7479246258735657, loss=4.285736083984375
I0424 22:40:25.451117 139557362194176 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.7621804475784302, loss=4.398075103759766
I0424 22:40:59.040620 139582943229696 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.7755920886993408, loss=4.313734531402588
I0424 22:41:32.625167 139557362194176 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.706372857093811, loss=4.235095024108887
I0424 22:42:06.464733 139582943229696 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.7016581892967224, loss=4.224094390869141
I0424 22:42:40.295790 139557362194176 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.7490907311439514, loss=4.284232139587402
I0424 22:43:14.246507 139582943229696 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.7239667773246765, loss=4.170054912567139
I0424 22:43:47.901485 139557362194176 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.7108198404312134, loss=4.1317572593688965
I0424 22:44:03.558513 139763077670720 spec.py:298] Evaluating on the training split.
I0424 22:44:10.288436 139763077670720 spec.py:310] Evaluating on the validation split.
I0424 22:44:18.114776 139763077670720 spec.py:326] Evaluating on the test split.
I0424 22:44:20.165009 139763077670720 submission_runner.py:406] Time since start: 2196.20s, 	Step: 6048, 	{'train/accuracy': 0.43676260113716125, 'train/loss': 2.7329609394073486, 'validation/accuracy': 0.4122999906539917, 'validation/loss': 2.8591697216033936, 'validation/num_examples': 50000, 'test/accuracy': 0.31060001254081726, 'test/loss': 3.4983508586883545, 'test/num_examples': 10000, 'score': 2086.7512383461, 'total_duration': 2196.1972613334656, 'accumulated_submission_time': 2086.7512383461, 'accumulated_eval_time': 106.95940113067627, 'accumulated_logging_time': 2.4177310466766357}
I0424 22:44:20.172617 139582943229696 logging_writer.py:48] [6048] accumulated_eval_time=106.959401, accumulated_logging_time=2.417731, accumulated_submission_time=2086.751238, global_step=6048, preemption_count=0, score=2086.751238, test/accuracy=0.310600, test/loss=3.498351, test/num_examples=10000, total_duration=2196.197261, train/accuracy=0.436763, train/loss=2.732961, validation/accuracy=0.412300, validation/loss=2.859170, validation/num_examples=50000
I0424 22:44:20.293851 139763077670720 checkpoints.py:356] Saving checkpoint at step: 6048
I0424 22:44:20.716073 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_6048
I0424 22:44:20.716802 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_6048.
I0424 22:44:38.584119 139557362194176 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.697100818157196, loss=4.184643745422363
I0424 22:45:12.267174 139584541284096 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.7260491251945496, loss=4.133855819702148
I0424 22:45:45.918794 139557362194176 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.7029008865356445, loss=4.093364715576172
I0424 22:46:19.613215 139584541284096 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.6704946160316467, loss=4.141851425170898
I0424 22:46:53.254832 139557362194176 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.6552374958992004, loss=4.10013484954834
I0424 22:47:27.004884 139584541284096 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.6967951059341431, loss=4.062363624572754
I0424 22:48:00.601483 139557362194176 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.6339000463485718, loss=4.061662197113037
I0424 22:48:34.153210 139584541284096 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.7078856229782104, loss=4.125032901763916
I0424 22:49:07.654047 139557362194176 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.6392726302146912, loss=4.086798191070557
I0424 22:49:41.348749 139584541284096 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.6832340359687805, loss=4.103794097900391
I0424 22:50:14.949657 139557362194176 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.6428104043006897, loss=4.072539806365967
I0424 22:50:48.598402 139584541284096 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.6041072010993958, loss=3.926299571990967
I0424 22:51:22.214868 139557362194176 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.6345239877700806, loss=4.054696083068848
I0424 22:51:55.882052 139584541284096 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.6186332106590271, loss=3.9535751342773438
I0424 22:52:29.482613 139557362194176 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.627328634262085, loss=4.023937225341797
I0424 22:52:50.840620 139763077670720 spec.py:298] Evaluating on the training split.
I0424 22:52:57.579763 139763077670720 spec.py:310] Evaluating on the validation split.
I0424 22:53:05.479812 139763077670720 spec.py:326] Evaluating on the test split.
I0424 22:53:07.571354 139763077670720 submission_runner.py:406] Time since start: 2723.60s, 	Step: 7565, 	{'train/accuracy': 0.5222018361091614, 'train/loss': 2.283324718475342, 'validation/accuracy': 0.49091997742652893, 'validation/loss': 2.418644428253174, 'validation/num_examples': 50000, 'test/accuracy': 0.3830000162124634, 'test/loss': 3.0580906867980957, 'test/num_examples': 10000, 'score': 2596.852639436722, 'total_duration': 2723.603588581085, 'accumulated_submission_time': 2596.852639436722, 'accumulated_eval_time': 123.69010138511658, 'accumulated_logging_time': 2.974679708480835}
I0424 22:53:07.579766 139584541284096 logging_writer.py:48] [7565] accumulated_eval_time=123.690101, accumulated_logging_time=2.974680, accumulated_submission_time=2596.852639, global_step=7565, preemption_count=0, score=2596.852639, test/accuracy=0.383000, test/loss=3.058091, test/num_examples=10000, total_duration=2723.603589, train/accuracy=0.522202, train/loss=2.283325, validation/accuracy=0.490920, validation/loss=2.418644, validation/num_examples=50000
I0424 22:53:07.722469 139763077670720 checkpoints.py:356] Saving checkpoint at step: 7565
I0424 22:53:08.370267 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_7565
I0424 22:53:08.386298 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_7565.
I0424 22:53:20.614857 139557362194176 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.5940256118774414, loss=3.9557876586914062
I0424 22:53:54.238509 139584507713280 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.5999606847763062, loss=3.9619760513305664
I0424 22:54:28.167604 139557362194176 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.5808435678482056, loss=3.853362560272217
I0424 22:55:02.017917 139584507713280 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.5897071361541748, loss=3.9700350761413574
I0424 22:55:35.809374 139557362194176 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.589084267616272, loss=3.8999862670898438
I0424 22:56:09.419404 139584507713280 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.5873222351074219, loss=3.875694751739502
I0424 22:56:43.359864 139557362194176 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.5624187588691711, loss=3.815446376800537
I0424 22:57:17.106031 139584507713280 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.6575358510017395, loss=3.869537830352783
I0424 22:57:50.804358 139557362194176 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.5654677152633667, loss=3.8741400241851807
I0424 22:58:24.674930 139584507713280 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.5608985424041748, loss=3.8031983375549316
I0424 22:58:58.370201 139557362194176 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.5725051164627075, loss=3.7999613285064697
I0424 22:59:32.142206 139584507713280 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.5650132894515991, loss=3.9047327041625977
I0424 23:00:05.946648 139557362194176 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.5878534913063049, loss=3.9080591201782227
I0424 23:00:39.823641 139584507713280 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.559481680393219, loss=3.8536689281463623
I0424 23:01:13.625512 139557362194176 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.5559949278831482, loss=3.818237543106079
I0424 23:01:38.657508 139763077670720 spec.py:298] Evaluating on the training split.
I0424 23:01:45.636928 139763077670720 spec.py:310] Evaluating on the validation split.
I0424 23:01:54.213620 139763077670720 spec.py:326] Evaluating on the test split.
I0424 23:01:56.098493 139763077670720 submission_runner.py:406] Time since start: 3252.13s, 	Step: 9076, 	{'train/accuracy': 0.5859972834587097, 'train/loss': 2.029726982116699, 'validation/accuracy': 0.5260399580001831, 'validation/loss': 2.3124239444732666, 'validation/num_examples': 50000, 'test/accuracy': 0.4097000062465668, 'test/loss': 2.9572207927703857, 'test/num_examples': 10000, 'score': 3107.099504709244, 'total_duration': 3252.1307418346405, 'accumulated_submission_time': 3107.099504709244, 'accumulated_eval_time': 141.13106632232666, 'accumulated_logging_time': 3.7965238094329834}
I0424 23:01:56.106963 139584507713280 logging_writer.py:48] [9076] accumulated_eval_time=141.131066, accumulated_logging_time=3.796524, accumulated_submission_time=3107.099505, global_step=9076, preemption_count=0, score=3107.099505, test/accuracy=0.409700, test/loss=2.957221, test/num_examples=10000, total_duration=3252.130742, train/accuracy=0.585997, train/loss=2.029727, validation/accuracy=0.526040, validation/loss=2.312424, validation/num_examples=50000
I0424 23:01:56.259372 139763077670720 checkpoints.py:356] Saving checkpoint at step: 9076
I0424 23:01:56.910779 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_9076
I0424 23:01:56.920350 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_9076.
I0424 23:02:05.391848 139557362194176 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.5409624576568604, loss=3.7909927368164062
I0424 23:02:38.977446 139584423851776 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.5770998597145081, loss=3.846726655960083
I0424 23:03:12.566403 139557362194176 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.5437256693840027, loss=3.870500326156616
I0424 23:03:46.117798 139584423851776 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.5548633933067322, loss=3.7567548751831055
I0424 23:04:19.649417 139557362194176 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.5247618556022644, loss=3.6751832962036133
I0424 23:04:53.357673 139584423851776 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.5375887751579285, loss=3.694108009338379
I0424 23:05:26.838131 139557362194176 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.540141761302948, loss=3.7258846759796143
I0424 23:06:00.357190 139584423851776 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.5151161551475525, loss=3.6960763931274414
I0424 23:06:34.004279 139557362194176 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.5379233360290527, loss=3.757493257522583
I0424 23:07:07.516271 139584423851776 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.5130402445793152, loss=3.7313790321350098
I0424 23:07:41.032228 139557362194176 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.5154433250427246, loss=3.5964431762695312
I0424 23:08:14.627900 139584423851776 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.524705708026886, loss=3.7124767303466797
I0424 23:08:48.209515 139557362194176 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.5405304431915283, loss=3.649945020675659
I0424 23:09:21.760107 139584423851776 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.5365384817123413, loss=3.7633514404296875
I0424 23:09:55.271954 139557362194176 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.5081567764282227, loss=3.661001205444336
I0424 23:10:27.112419 139763077670720 spec.py:298] Evaluating on the training split.
I0424 23:10:34.165969 139763077670720 spec.py:310] Evaluating on the validation split.
I0424 23:10:43.646665 139763077670720 spec.py:326] Evaluating on the test split.
I0424 23:10:45.548549 139763077670720 submission_runner.py:406] Time since start: 3781.58s, 	Step: 10597, 	{'train/accuracy': 0.6100525856018066, 'train/loss': 1.9165980815887451, 'validation/accuracy': 0.551800012588501, 'validation/loss': 2.1876749992370605, 'validation/num_examples': 50000, 'test/accuracy': 0.4345000088214874, 'test/loss': 2.815077781677246, 'test/num_examples': 10000, 'score': 3617.2696194648743, 'total_duration': 3781.5808005332947, 'accumulated_submission_time': 3617.2696194648743, 'accumulated_eval_time': 159.56717991828918, 'accumulated_logging_time': 4.623153448104858}
I0424 23:10:45.556989 139584423851776 logging_writer.py:48] [10597] accumulated_eval_time=159.567180, accumulated_logging_time=4.623153, accumulated_submission_time=3617.269619, global_step=10597, preemption_count=0, score=3617.269619, test/accuracy=0.434500, test/loss=2.815078, test/num_examples=10000, total_duration=3781.580801, train/accuracy=0.610053, train/loss=1.916598, validation/accuracy=0.551800, validation/loss=2.187675, validation/num_examples=50000
I0424 23:10:45.699165 139763077670720 checkpoints.py:356] Saving checkpoint at step: 10597
I0424 23:10:46.327519 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_10597
I0424 23:10:46.336028 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_10597.
I0424 23:10:47.718758 139557362194176 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.5189670324325562, loss=3.675952196121216
I0424 23:11:21.345272 139584415459072 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.5091209411621094, loss=3.6744892597198486
I0424 23:11:54.866640 139557362194176 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.5262497067451477, loss=3.6633033752441406
I0424 23:12:28.395031 139584415459072 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.5554042458534241, loss=3.6682443618774414
I0424 23:13:02.014171 139557362194176 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.5245150923728943, loss=3.5786166191101074
I0424 23:13:35.669277 139584415459072 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.5035231113433838, loss=3.6151256561279297
I0424 23:14:09.239883 139557362194176 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.507831335067749, loss=3.579990863800049
I0424 23:14:42.764765 139584415459072 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.5257201790809631, loss=3.6452600955963135
I0424 23:15:16.517130 139557362194176 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.5211791396141052, loss=3.6169817447662354
I0424 23:15:49.928383 139584415459072 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.5118871331214905, loss=3.546142101287842
I0424 23:16:23.443271 139557362194176 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.4954470098018646, loss=3.5296685695648193
I0424 23:16:57.179730 139584415459072 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.5145120620727539, loss=3.6474976539611816
I0424 23:17:30.845478 139557362194176 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.5065429210662842, loss=3.61268949508667
I0424 23:18:04.475609 139584415459072 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.512353777885437, loss=3.6750993728637695
I0424 23:18:38.018776 139557362194176 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.5187340378761292, loss=3.529090642929077
I0424 23:19:11.546155 139584415459072 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.5051008462905884, loss=3.57720947265625
I0424 23:19:16.658044 139763077670720 spec.py:298] Evaluating on the training split.
I0424 23:19:23.783737 139763077670720 spec.py:310] Evaluating on the validation split.
I0424 23:19:33.374490 139763077670720 spec.py:326] Evaluating on the test split.
I0424 23:19:35.295694 139763077670720 submission_runner.py:406] Time since start: 4311.33s, 	Step: 12117, 	{'train/accuracy': 0.6346858739852905, 'train/loss': 1.7596992254257202, 'validation/accuracy': 0.5839200019836426, 'validation/loss': 2.000540018081665, 'validation/num_examples': 50000, 'test/accuracy': 0.45590001344680786, 'test/loss': 2.654935598373413, 'test/num_examples': 10000, 'score': 4127.567907810211, 'total_duration': 4311.3269510269165, 'accumulated_submission_time': 4127.567907810211, 'accumulated_eval_time': 178.20381355285645, 'accumulated_logging_time': 5.416542053222656}
I0424 23:19:35.309340 139557362194176 logging_writer.py:48] [12117] accumulated_eval_time=178.203814, accumulated_logging_time=5.416542, accumulated_submission_time=4127.567908, global_step=12117, preemption_count=0, score=4127.567908, test/accuracy=0.455900, test/loss=2.654936, test/num_examples=10000, total_duration=4311.326951, train/accuracy=0.634686, train/loss=1.759699, validation/accuracy=0.583920, validation/loss=2.000540, validation/num_examples=50000
I0424 23:19:35.470663 139763077670720 checkpoints.py:356] Saving checkpoint at step: 12117
I0424 23:19:36.127341 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_12117
I0424 23:19:36.136541 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_12117.
I0424 23:20:04.512391 139584415459072 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.5216060876846313, loss=3.588592529296875
I0424 23:20:38.027070 139586420332288 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.49419450759887695, loss=3.4756722450256348
I0424 23:21:11.643013 139584415459072 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.4981900453567505, loss=3.560190439224243
I0424 23:21:45.332199 139586420332288 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.5165280103683472, loss=3.6322574615478516
I0424 23:22:19.045136 139584415459072 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.516895055770874, loss=3.5000243186950684
I0424 23:22:52.683155 139586420332288 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.4917806386947632, loss=3.573214054107666
I0424 23:23:26.507805 139584415459072 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.4802854657173157, loss=3.5002970695495605
I0424 23:24:00.119823 139586420332288 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.49345093965530396, loss=3.4983057975769043
I0424 23:24:33.753821 139584415459072 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.48263683915138245, loss=3.512061834335327
I0424 23:25:07.388576 139586420332288 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.4760928750038147, loss=3.455322265625
I0424 23:25:40.999222 139584415459072 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.48947277665138245, loss=3.4642298221588135
I0424 23:26:14.631064 139586420332288 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.49239400029182434, loss=3.5214028358459473
I0424 23:26:48.179958 139584415459072 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.5096126794815063, loss=3.54848051071167
I0424 23:27:21.699651 139586420332288 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.46597298979759216, loss=3.357783555984497
I0424 23:27:55.260894 139584415459072 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.47998180985450745, loss=3.4709458351135254
I0424 23:28:06.376828 139763077670720 spec.py:298] Evaluating on the training split.
I0424 23:28:13.322317 139763077670720 spec.py:310] Evaluating on the validation split.
I0424 23:28:23.028798 139763077670720 spec.py:326] Evaluating on the test split.
I0424 23:28:24.924001 139763077670720 submission_runner.py:406] Time since start: 4840.96s, 	Step: 13635, 	{'train/accuracy': 0.6484773755073547, 'train/loss': 1.701664686203003, 'validation/accuracy': 0.5889399647712708, 'validation/loss': 1.9587898254394531, 'validation/num_examples': 50000, 'test/accuracy': 0.4613000154495239, 'test/loss': 2.6168885231018066, 'test/num_examples': 10000, 'score': 4637.782868862152, 'total_duration': 4840.956250905991, 'accumulated_submission_time': 4637.782868862152, 'accumulated_eval_time': 196.75096011161804, 'accumulated_logging_time': 6.265419960021973}
I0424 23:28:24.932783 139586420332288 logging_writer.py:48] [13635] accumulated_eval_time=196.750960, accumulated_logging_time=6.265420, accumulated_submission_time=4637.782869, global_step=13635, preemption_count=0, score=4637.782869, test/accuracy=0.461300, test/loss=2.616889, test/num_examples=10000, total_duration=4840.956251, train/accuracy=0.648477, train/loss=1.701665, validation/accuracy=0.588940, validation/loss=1.958790, validation/num_examples=50000
I0424 23:28:25.063193 139763077670720 checkpoints.py:356] Saving checkpoint at step: 13635
I0424 23:28:25.703882 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_13635
I0424 23:28:25.712442 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_13635.
I0424 23:28:47.925893 139584415459072 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.48565638065338135, loss=3.4848597049713135
I0424 23:29:21.722988 139586185434880 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.49699103832244873, loss=3.4572010040283203
I0424 23:29:55.335641 139584415459072 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.49159738421440125, loss=3.4589104652404785
I0424 23:30:28.914519 139586185434880 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.4829581379890442, loss=3.408773899078369
I0424 23:31:02.561676 139584415459072 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.4775654375553131, loss=3.4980974197387695
I0424 23:31:36.107941 139586185434880 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.4815933108329773, loss=3.4443628787994385
I0424 23:32:09.639301 139584415459072 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.49276837706565857, loss=3.4159791469573975
I0424 23:32:43.247506 139586185434880 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.5079768300056458, loss=3.524073839187622
I0424 23:33:16.940419 139584415459072 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.4866603910923004, loss=3.4191291332244873
I0424 23:33:50.519094 139586185434880 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.48577871918678284, loss=3.394681453704834
I0424 23:34:24.204092 139584415459072 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.47454139590263367, loss=3.475545644760132
I0424 23:34:57.766774 139586185434880 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.4635118544101715, loss=3.2520906925201416
I0424 23:35:31.429522 139584415459072 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.48190873861312866, loss=3.388347625732422
I0424 23:36:05.166679 139586185434880 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.4655742943286896, loss=3.4201674461364746
I0424 23:36:38.776450 139584415459072 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.47014138102531433, loss=3.3585968017578125
I0424 23:36:55.966001 139763077670720 spec.py:298] Evaluating on the training split.
I0424 23:37:03.591218 139763077670720 spec.py:310] Evaluating on the validation split.
I0424 23:37:13.585560 139763077670720 spec.py:326] Evaluating on the test split.
I0424 23:37:15.568690 139763077670720 submission_runner.py:406] Time since start: 5371.60s, 	Step: 15153, 	{'train/accuracy': 0.6792091727256775, 'train/loss': 1.5393463373184204, 'validation/accuracy': 0.6241599917411804, 'validation/loss': 1.7915846109390259, 'validation/num_examples': 50000, 'test/accuracy': 0.49320003390312195, 'test/loss': 2.4576618671417236, 'test/num_examples': 10000, 'score': 5148.011064529419, 'total_duration': 5371.600119590759, 'accumulated_submission_time': 5148.011064529419, 'accumulated_eval_time': 216.35280656814575, 'accumulated_logging_time': 7.061215400695801}
I0424 23:37:15.585075 139586185434880 logging_writer.py:48] [15153] accumulated_eval_time=216.352807, accumulated_logging_time=7.061215, accumulated_submission_time=5148.011065, global_step=15153, preemption_count=0, score=5148.011065, test/accuracy=0.493200, test/loss=2.457662, test/num_examples=10000, total_duration=5371.600120, train/accuracy=0.679209, train/loss=1.539346, validation/accuracy=0.624160, validation/loss=1.791585, validation/num_examples=50000
I0424 23:37:15.735126 139763077670720 checkpoints.py:356] Saving checkpoint at step: 15153
I0424 23:37:16.425362 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_15153
I0424 23:37:16.437278 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_15153.
I0424 23:37:32.692020 139584415459072 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.4761888384819031, loss=3.4177677631378174
I0424 23:38:06.571312 139585782781696 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.46455565094947815, loss=3.405233144760132
I0424 23:38:40.323284 139584415459072 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.5087894797325134, loss=3.404737949371338
I0424 23:39:14.042001 139585782781696 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.4801759719848633, loss=3.441152572631836
I0424 23:39:47.837402 139584415459072 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.4879937767982483, loss=3.365028142929077
I0424 23:40:21.690731 139585782781696 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.4848354458808899, loss=3.4077296257019043
I0424 23:40:55.590038 139584415459072 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.48485255241394043, loss=3.368303060531616
I0424 23:41:29.586425 139585782781696 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.4706355929374695, loss=3.357895612716675
I0424 23:42:03.310692 139584415459072 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.4768083095550537, loss=3.4197638034820557
I0424 23:42:37.123914 139585782781696 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.46790599822998047, loss=3.39418888092041
I0424 23:43:10.760643 139584415459072 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.4610922932624817, loss=3.385263442993164
I0424 23:43:44.543580 139585782781696 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.4804457128047943, loss=3.358785629272461
I0424 23:44:18.197832 139584415459072 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.4607963562011719, loss=3.3093035221099854
I0424 23:44:51.940396 139585782781696 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.46559810638427734, loss=3.3510868549346924
I0424 23:45:25.576348 139584415459072 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.4619215726852417, loss=3.36763334274292
I0424 23:45:46.550710 139763077670720 spec.py:298] Evaluating on the training split.
I0424 23:45:53.732728 139763077670720 spec.py:310] Evaluating on the validation split.
I0424 23:46:03.884344 139763077670720 spec.py:326] Evaluating on the test split.
I0424 23:46:05.780301 139763077670720 submission_runner.py:406] Time since start: 5901.81s, 	Step: 16664, 	{'train/accuracy': 0.6872209906578064, 'train/loss': 1.5227497816085815, 'validation/accuracy': 0.6283999681472778, 'validation/loss': 1.780399203300476, 'validation/num_examples': 50000, 'test/accuracy': 0.49960002303123474, 'test/loss': 2.4596431255340576, 'test/num_examples': 10000, 'score': 5658.099779129028, 'total_duration': 5901.811650276184, 'accumulated_submission_time': 5658.099779129028, 'accumulated_eval_time': 235.58148789405823, 'accumulated_logging_time': 7.937206745147705}
I0424 23:46:05.790486 139585782781696 logging_writer.py:48] [16664] accumulated_eval_time=235.581488, accumulated_logging_time=7.937207, accumulated_submission_time=5658.099779, global_step=16664, preemption_count=0, score=5658.099779, test/accuracy=0.499600, test/loss=2.459643, test/num_examples=10000, total_duration=5901.811650, train/accuracy=0.687221, train/loss=1.522750, validation/accuracy=0.628400, validation/loss=1.780399, validation/num_examples=50000
I0424 23:46:05.971415 139763077670720 checkpoints.py:356] Saving checkpoint at step: 16664
I0424 23:46:06.668532 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_16664
I0424 23:46:06.679329 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_16664.
I0424 23:46:19.267052 139584415459072 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.4603513181209564, loss=3.353135824203491
I0424 23:46:52.934578 139585363375872 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.4740058183670044, loss=3.38537335395813
I0424 23:47:26.609320 139584415459072 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.46769970655441284, loss=3.357527732849121
I0424 23:48:00.393844 139585363375872 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.4798373878002167, loss=3.36863374710083
I0424 23:48:34.098259 139584415459072 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.47713175415992737, loss=3.358757734298706
I0424 23:49:07.961165 139585363375872 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.48231226205825806, loss=3.3076114654541016
I0424 23:49:41.670445 139584415459072 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.4780949652194977, loss=3.3384017944335938
I0424 23:50:15.275809 139585363375872 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.4809895157814026, loss=3.3489577770233154
I0424 23:50:48.969956 139584415459072 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.4762914776802063, loss=3.3720834255218506
I0424 23:51:22.650734 139585363375872 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.4912073016166687, loss=3.4242966175079346
I0424 23:51:56.392148 139584415459072 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.4609900116920471, loss=3.316899299621582
I0424 23:52:30.203576 139585363375872 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.47045740485191345, loss=3.388667583465576
I0424 23:53:03.831160 139584415459072 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.4929485321044922, loss=3.4327492713928223
I0424 23:53:37.455126 139585363375872 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.4683910608291626, loss=3.3510942459106445
I0424 23:54:11.194653 139584415459072 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.49884268641471863, loss=3.4080142974853516
I0424 23:54:36.950825 139763077670720 spec.py:298] Evaluating on the training split.
I0424 23:54:44.940181 139763077670720 spec.py:310] Evaluating on the validation split.
I0424 23:54:54.989039 139763077670720 spec.py:326] Evaluating on the test split.
I0424 23:54:56.882753 139763077670720 submission_runner.py:406] Time since start: 6432.91s, 	Step: 18178, 	{'train/accuracy': 0.7389190196990967, 'train/loss': 1.2906590700149536, 'validation/accuracy': 0.6403999924659729, 'validation/loss': 1.722090482711792, 'validation/num_examples': 50000, 'test/accuracy': 0.515500009059906, 'test/loss': 2.3578999042510986, 'test/num_examples': 10000, 'score': 6168.3493230342865, 'total_duration': 6432.913976430893, 'accumulated_submission_time': 6168.3493230342865, 'accumulated_eval_time': 255.51238870620728, 'accumulated_logging_time': 8.840662956237793}
I0424 23:54:56.897057 139585363375872 logging_writer.py:48] [18178] accumulated_eval_time=255.512389, accumulated_logging_time=8.840663, accumulated_submission_time=6168.349323, global_step=18178, preemption_count=0, score=6168.349323, test/accuracy=0.515500, test/loss=2.357900, test/num_examples=10000, total_duration=6432.913976, train/accuracy=0.738919, train/loss=1.290659, validation/accuracy=0.640400, validation/loss=1.722090, validation/num_examples=50000
I0424 23:54:57.077246 139763077670720 checkpoints.py:356] Saving checkpoint at step: 18178
I0424 23:54:57.764834 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_18178
I0424 23:54:57.776220 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_18178.
I0424 23:55:05.489025 139584415459072 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.49823829531669617, loss=3.329256057739258
I0424 23:55:39.269939 139585715640064 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.48041680455207825, loss=3.3938567638397217
I0424 23:56:13.089625 139584415459072 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.47215333580970764, loss=3.3289244174957275
I0424 23:56:46.788977 139585715640064 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.46432673931121826, loss=3.3493576049804688
I0424 23:57:20.487328 139584415459072 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.465776264667511, loss=3.3421573638916016
I0424 23:57:54.063186 139585715640064 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.44778046011924744, loss=3.305238962173462
I0424 23:58:27.866746 139584415459072 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.4529518783092499, loss=3.2881786823272705
I0424 23:59:01.476376 139585715640064 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.46065059304237366, loss=3.2966084480285645
I0424 23:59:35.188844 139584415459072 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.48317453265190125, loss=3.2993216514587402
I0425 00:00:08.936214 139585715640064 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.46919161081314087, loss=3.2837884426116943
I0425 00:00:42.664940 139584415459072 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.4848294258117676, loss=3.3354830741882324
I0425 00:01:16.494291 139585715640064 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.4535350501537323, loss=3.26597261428833
I0425 00:01:50.137869 139584415459072 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.4626692533493042, loss=3.3317713737487793
I0425 00:02:23.841492 139585715640064 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.4527386724948883, loss=3.233621120452881
I0425 00:02:57.589921 139584415459072 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.4547771215438843, loss=3.199929714202881
I0425 00:03:27.970955 139763077670720 spec.py:298] Evaluating on the training split.
I0425 00:03:35.293348 139763077670720 spec.py:310] Evaluating on the validation split.
I0425 00:03:45.531127 139763077670720 spec.py:326] Evaluating on the test split.
I0425 00:03:47.425765 139763077670720 submission_runner.py:406] Time since start: 6963.46s, 	Step: 19692, 	{'train/accuracy': 0.7188894748687744, 'train/loss': 1.3887217044830322, 'validation/accuracy': 0.6352999806404114, 'validation/loss': 1.759264588356018, 'validation/num_examples': 50000, 'test/accuracy': 0.5123000144958496, 'test/loss': 2.4046480655670166, 'test/num_examples': 10000, 'score': 6678.5207986831665, 'total_duration': 6963.456977844238, 'accumulated_submission_time': 6678.5207986831665, 'accumulated_eval_time': 274.9661371707916, 'accumulated_logging_time': 9.73922324180603}
I0425 00:03:47.435792 139585715640064 logging_writer.py:48] [19692] accumulated_eval_time=274.966137, accumulated_logging_time=9.739223, accumulated_submission_time=6678.520799, global_step=19692, preemption_count=0, score=6678.520799, test/accuracy=0.512300, test/loss=2.404648, test/num_examples=10000, total_duration=6963.456978, train/accuracy=0.718889, train/loss=1.388722, validation/accuracy=0.635300, validation/loss=1.759265, validation/num_examples=50000
I0425 00:03:47.626724 139763077670720 checkpoints.py:356] Saving checkpoint at step: 19692
I0425 00:03:48.293562 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_19692
I0425 00:03:48.303114 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_19692.
I0425 00:03:51.312781 139584415459072 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.4424089193344116, loss=3.2059834003448486
I0425 00:04:25.043868 139584373495552 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.4559619426727295, loss=3.254007339477539
I0425 00:04:58.720665 139584415459072 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.45663556456565857, loss=3.290372848510742
I0425 00:05:32.338021 139584373495552 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.4796552360057831, loss=3.268035650253296
I0425 00:06:05.945410 139584415459072 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.44393742084503174, loss=3.2353692054748535
I0425 00:06:39.499582 139584373495552 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.4563799500465393, loss=3.2782087326049805
I0425 00:07:13.309247 139584415459072 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.46087881922721863, loss=3.2339563369750977
I0425 00:07:46.893748 139584373495552 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.4528607726097107, loss=3.2117369174957275
I0425 00:08:20.501228 139584415459072 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.479830265045166, loss=3.2724077701568604
I0425 00:08:54.189119 139584373495552 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.4646724760532379, loss=3.2907538414001465
I0425 00:09:27.958897 139584415459072 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.4504266381263733, loss=3.251328706741333
I0425 00:10:01.602880 139584373495552 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.457491934299469, loss=3.189309597015381
I0425 00:10:35.297616 139584415459072 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.47370290756225586, loss=3.292722463607788
I0425 00:11:09.092642 139584373495552 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.4907236695289612, loss=3.2379446029663086
I0425 00:11:42.703380 139584415459072 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.4685915410518646, loss=3.241389751434326
I0425 00:12:16.192303 139584373495552 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.43715253472328186, loss=3.1554131507873535
I0425 00:12:18.612298 139763077670720 spec.py:298] Evaluating on the training split.
I0425 00:12:26.786997 139763077670720 spec.py:310] Evaluating on the validation split.
I0425 00:12:36.952164 139763077670720 spec.py:326] Evaluating on the test split.
I0425 00:12:38.866343 139763077670720 submission_runner.py:406] Time since start: 7494.90s, 	Step: 21209, 	{'train/accuracy': 0.7323421239852905, 'train/loss': 1.2917200326919556, 'validation/accuracy': 0.6534799933433533, 'validation/loss': 1.6443893909454346, 'validation/num_examples': 50000, 'test/accuracy': 0.5164999961853027, 'test/loss': 2.31721830368042, 'test/num_examples': 10000, 'score': 7188.807301521301, 'total_duration': 7494.897300720215, 'accumulated_submission_time': 7188.807301521301, 'accumulated_eval_time': 295.2188708782196, 'accumulated_logging_time': 10.621732473373413}
I0425 00:12:38.880994 139584415459072 logging_writer.py:48] [21209] accumulated_eval_time=295.218871, accumulated_logging_time=10.621732, accumulated_submission_time=7188.807302, global_step=21209, preemption_count=0, score=7188.807302, test/accuracy=0.516500, test/loss=2.317218, test/num_examples=10000, total_duration=7494.897301, train/accuracy=0.732342, train/loss=1.291720, validation/accuracy=0.653480, validation/loss=1.644389, validation/num_examples=50000
I0425 00:12:39.029371 139763077670720 checkpoints.py:356] Saving checkpoint at step: 21209
I0425 00:12:39.714089 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_21209
I0425 00:12:39.726751 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_21209.
I0425 00:13:10.824074 139584373495552 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.4689410328865051, loss=3.2640817165374756
I0425 00:13:44.593159 139584230885120 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.45429524779319763, loss=3.143339157104492
I0425 00:14:18.292514 139584373495552 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.48855745792388916, loss=3.2893781661987305
I0425 00:14:52.005021 139584230885120 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.4531440734863281, loss=3.147249221801758
I0425 00:15:25.755490 139584373495552 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.4587433636188507, loss=3.2110965251922607
I0425 00:15:59.529285 139584230885120 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.4684182405471802, loss=3.2011618614196777
I0425 00:16:33.220112 139584373495552 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.4750046133995056, loss=3.266529083251953
I0425 00:17:06.803431 139584230885120 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.44584161043167114, loss=3.1754887104034424
I0425 00:17:40.512302 139584373495552 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.47076788544654846, loss=3.2595324516296387
I0425 00:18:14.318204 139584230885120 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.46640580892562866, loss=3.170625686645508
I0425 00:18:47.892697 139584373495552 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.4611593782901764, loss=3.190066337585449
I0425 00:19:21.438993 139584230885120 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.4483949840068817, loss=3.216059446334839
I0425 00:19:54.949113 139584373495552 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.4452052414417267, loss=3.20267391204834
I0425 00:20:28.566138 139584230885120 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.4552417993545532, loss=3.2147915363311768
I0425 00:21:02.228172 139584373495552 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.47708654403686523, loss=3.19879412651062
I0425 00:21:10.031655 139763077670720 spec.py:298] Evaluating on the training split.
I0425 00:21:17.410542 139763077670720 spec.py:310] Evaluating on the validation split.
I0425 00:21:27.654872 139763077670720 spec.py:326] Evaluating on the test split.
I0425 00:21:29.699577 139763077670720 submission_runner.py:406] Time since start: 8025.73s, 	Step: 22725, 	{'train/accuracy': 0.7314453125, 'train/loss': 1.2909939289093018, 'validation/accuracy': 0.6575199961662292, 'validation/loss': 1.6260364055633545, 'validation/num_examples': 50000, 'test/accuracy': 0.5267000198364258, 'test/loss': 2.2869460582733154, 'test/num_examples': 10000, 'score': 7699.087784767151, 'total_duration': 8025.730905532837, 'accumulated_submission_time': 7699.087784767151, 'accumulated_eval_time': 314.8858530521393, 'accumulated_logging_time': 11.489154577255249}
I0425 00:21:29.710263 139584230885120 logging_writer.py:48] [22725] accumulated_eval_time=314.885853, accumulated_logging_time=11.489155, accumulated_submission_time=7699.087785, global_step=22725, preemption_count=0, score=7699.087785, test/accuracy=0.526700, test/loss=2.286946, test/num_examples=10000, total_duration=8025.730906, train/accuracy=0.731445, train/loss=1.290994, validation/accuracy=0.657520, validation/loss=1.626036, validation/num_examples=50000
I0425 00:21:29.892534 139763077670720 checkpoints.py:356] Saving checkpoint at step: 22725
I0425 00:21:30.572714 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_22725
I0425 00:21:30.584073 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_22725.
I0425 00:21:56.158975 139584373495552 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.4637649655342102, loss=3.184589385986328
I0425 00:22:29.950927 139584222492416 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.45538824796676636, loss=3.206129550933838
I0425 00:23:03.682711 139584373495552 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.4593407213687897, loss=3.2081167697906494
I0425 00:23:37.413068 139584222492416 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.4572402238845825, loss=3.2058660984039307
I0425 00:24:11.091510 139584373495552 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.45818567276000977, loss=3.13008451461792
I0425 00:24:44.779828 139584222492416 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.45154285430908203, loss=3.117743730545044
I0425 00:25:18.539531 139584373495552 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.4514981806278229, loss=3.1422653198242188
I0425 00:25:52.205021 139584222492416 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.46996957063674927, loss=3.268528938293457
I0425 00:26:25.828638 139584373495552 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.46633726358413696, loss=3.208364486694336
I0425 00:26:59.516975 139584222492416 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.4513942301273346, loss=3.1425323486328125
I0425 00:27:33.265040 139584373495552 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.44649699330329895, loss=3.176851511001587
I0425 00:28:07.109739 139584222492416 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.4641685485839844, loss=3.2342326641082764
I0425 00:28:40.861212 139584373495552 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.4621230959892273, loss=3.186296224594116
I0425 00:29:14.510033 139584222492416 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.4773411452770233, loss=3.218111991882324
I0425 00:29:48.209062 139584373495552 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.44657427072525024, loss=3.1930103302001953
I0425 00:30:00.714196 139763077670720 spec.py:298] Evaluating on the training split.
I0425 00:30:08.321355 139763077670720 spec.py:310] Evaluating on the validation split.
I0425 00:30:18.510409 139763077670720 spec.py:326] Evaluating on the test split.
I0425 00:30:20.546924 139763077670720 submission_runner.py:406] Time since start: 8556.58s, 	Step: 24239, 	{'train/accuracy': 0.7496412396430969, 'train/loss': 1.2467530965805054, 'validation/accuracy': 0.6677199602127075, 'validation/loss': 1.6030244827270508, 'validation/num_examples': 50000, 'test/accuracy': 0.5382000207901001, 'test/loss': 2.262397289276123, 'test/num_examples': 10000, 'score': 8209.188942193985, 'total_duration': 8556.578177690506, 'accumulated_submission_time': 8209.188942193985, 'accumulated_eval_time': 334.71755719184875, 'accumulated_logging_time': 12.38545560836792}
I0425 00:30:20.563560 139584222492416 logging_writer.py:48] [24239] accumulated_eval_time=334.717557, accumulated_logging_time=12.385456, accumulated_submission_time=8209.188942, global_step=24239, preemption_count=0, score=8209.188942, test/accuracy=0.538200, test/loss=2.262397, test/num_examples=10000, total_duration=8556.578178, train/accuracy=0.749641, train/loss=1.246753, validation/accuracy=0.667720, validation/loss=1.603024, validation/num_examples=50000
I0425 00:30:20.769083 139763077670720 checkpoints.py:356] Saving checkpoint at step: 24239
I0425 00:30:21.573963 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_24239
I0425 00:30:21.587132 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_24239.
I0425 00:30:42.360176 139584373495552 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.45846083760261536, loss=3.243987560272217
I0425 00:31:15.957726 139584214099712 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.4779500365257263, loss=3.2159159183502197
I0425 00:31:49.869184 139584373495552 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.45078620314598083, loss=3.228365898132324
I0425 00:32:23.708955 139584214099712 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.4592345952987671, loss=3.2208099365234375
I0425 00:32:57.434736 139584373495552 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.4706762135028839, loss=3.191472053527832
I0425 00:33:30.945134 139584214099712 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.4611648917198181, loss=3.1196131706237793
I0425 00:34:04.540166 139584373495552 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.43484264612197876, loss=3.0942301750183105
I0425 00:34:38.345780 139584214099712 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.45713162422180176, loss=3.1817564964294434
I0425 00:35:12.114533 139584373495552 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.4535060226917267, loss=3.169644355773926
I0425 00:35:45.928547 139584214099712 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.45310184359550476, loss=3.13321590423584
I0425 00:36:19.791293 139584373495552 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.4411696493625641, loss=3.0980138778686523
I0425 00:36:53.652996 139584214099712 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.4523235559463501, loss=3.1461169719696045
I0425 00:37:27.419021 139584373495552 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.44953691959381104, loss=3.123220920562744
I0425 00:38:01.225034 139584214099712 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.4598778188228607, loss=3.1312265396118164
I0425 00:38:34.914700 139584373495552 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.44731900095939636, loss=3.1214492321014404
I0425 00:38:51.788465 139763077670720 spec.py:298] Evaluating on the training split.
I0425 00:38:59.221392 139763077670720 spec.py:310] Evaluating on the validation split.
I0425 00:39:09.604426 139763077670720 spec.py:326] Evaluating on the test split.
I0425 00:39:11.728147 139763077670720 submission_runner.py:406] Time since start: 9087.76s, 	Step: 25752, 	{'train/accuracy': 0.753926157951355, 'train/loss': 1.236625075340271, 'validation/accuracy': 0.6725199818611145, 'validation/loss': 1.5934807062149048, 'validation/num_examples': 50000, 'test/accuracy': 0.5383000373840332, 'test/loss': 2.2523090839385986, 'test/num_examples': 10000, 'score': 8719.362540960312, 'total_duration': 9087.759526968002, 'accumulated_submission_time': 8719.362540960312, 'accumulated_eval_time': 354.65634202957153, 'accumulated_logging_time': 13.435758590698242}
I0425 00:39:11.739474 139584214099712 logging_writer.py:48] [25752] accumulated_eval_time=354.656342, accumulated_logging_time=13.435759, accumulated_submission_time=8719.362541, global_step=25752, preemption_count=0, score=8719.362541, test/accuracy=0.538300, test/loss=2.252309, test/num_examples=10000, total_duration=9087.759527, train/accuracy=0.753926, train/loss=1.236625, validation/accuracy=0.672520, validation/loss=1.593481, validation/num_examples=50000
I0425 00:39:11.887138 139763077670720 checkpoints.py:356] Saving checkpoint at step: 25752
I0425 00:39:12.566975 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_25752
I0425 00:39:12.577509 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_25752.
I0425 00:39:28.944950 139584373495552 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.4567830562591553, loss=3.133484363555908
I0425 00:40:02.808957 139584205707008 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.45950570702552795, loss=3.1297671794891357
I0425 00:40:36.342476 139584373495552 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.481626957654953, loss=3.218604564666748
I0425 00:41:09.902582 139584205707008 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.45560741424560547, loss=3.1990113258361816
I0425 00:41:43.521544 139584373495552 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.4695647954940796, loss=3.1565606594085693
I0425 00:42:17.323104 139584205707008 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.44920825958251953, loss=3.077730655670166
I0425 00:42:50.969549 139584373495552 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.4520239531993866, loss=3.1763768196105957
I0425 00:43:24.651986 139584205707008 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.4488159716129303, loss=3.151339054107666
I0425 00:43:58.260430 139584373495552 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.44259530305862427, loss=3.1563215255737305
I0425 00:44:31.768422 139584205707008 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.45383358001708984, loss=3.1619362831115723
I0425 00:45:05.428814 139584373495552 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.44976434111595154, loss=3.0908594131469727
I0425 00:45:39.082917 139584205707008 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.4521765410900116, loss=3.0946686267852783
I0425 00:46:12.834119 139584373495552 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.4528100788593292, loss=3.1577937602996826
I0425 00:46:46.640718 139584205707008 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.44542738795280457, loss=3.110682964324951
I0425 00:47:20.335215 139584373495552 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.45033442974090576, loss=3.1478428840637207
I0425 00:47:42.689261 139763077670720 spec.py:298] Evaluating on the training split.
I0425 00:47:50.228544 139763077670720 spec.py:310] Evaluating on the validation split.
I0425 00:48:00.586626 139763077670720 spec.py:326] Evaluating on the test split.
I0425 00:48:02.471072 139763077670720 submission_runner.py:406] Time since start: 9618.50s, 	Step: 27268, 	{'train/accuracy': 0.7898796200752258, 'train/loss': 1.0813071727752686, 'validation/accuracy': 0.6738799810409546, 'validation/loss': 1.573690414428711, 'validation/num_examples': 50000, 'test/accuracy': 0.5461000204086304, 'test/loss': 2.222787618637085, 'test/num_examples': 10000, 'score': 9229.450891494751, 'total_duration': 9618.50238275528, 'accumulated_submission_time': 9229.450891494751, 'accumulated_eval_time': 374.4371933937073, 'accumulated_logging_time': 14.291338205337524}
I0425 00:48:02.480869 139584205707008 logging_writer.py:48] [27268] accumulated_eval_time=374.437193, accumulated_logging_time=14.291338, accumulated_submission_time=9229.450891, global_step=27268, preemption_count=0, score=9229.450891, test/accuracy=0.546100, test/loss=2.222788, test/num_examples=10000, total_duration=9618.502383, train/accuracy=0.789880, train/loss=1.081307, validation/accuracy=0.673880, validation/loss=1.573690, validation/num_examples=50000
I0425 00:48:02.664805 139763077670720 checkpoints.py:356] Saving checkpoint at step: 27268
I0425 00:48:03.337481 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_27268
I0425 00:48:03.351846 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_27268.
I0425 00:48:14.446200 139584373495552 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.44143596291542053, loss=3.1314947605133057
I0425 00:48:48.040740 139584197314304 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.45732295513153076, loss=3.159914255142212
I0425 00:49:21.766688 139584373495552 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.4563630223274231, loss=3.152047634124756
I0425 00:49:55.269572 139584197314304 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.45791006088256836, loss=3.1092944145202637
I0425 00:50:29.108104 139584373495552 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.46272748708724976, loss=3.1226565837860107
I0425 00:51:02.629493 139584197314304 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.46202316880226135, loss=3.1086645126342773
I0425 00:51:36.273734 139584373495552 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.46319282054901123, loss=3.2234320640563965
I0425 00:52:09.460971 139763077670720 spec.py:298] Evaluating on the training split.
I0425 00:52:17.135307 139763077670720 spec.py:310] Evaluating on the validation split.
I0425 00:52:27.391525 139763077670720 spec.py:326] Evaluating on the test split.
I0425 00:52:31.256639 139763077670720 submission_runner.py:406] Time since start: 9885.58s, 	Step: 28000, 	{'train/accuracy': 0.7613002061843872, 'train/loss': 1.1459882259368896, 'validation/accuracy': 0.6714199781417847, 'validation/loss': 1.5458728075027466, 'validation/num_examples': 50000, 'test/accuracy': 0.5414000153541565, 'test/loss': 2.2072529792785645, 'test/num_examples': 10000, 'score': 9475.542243719101, 'total_duration': 9885.575748205185, 'accumulated_submission_time': 9475.542243719101, 'accumulated_eval_time': 394.5197002887726, 'accumulated_logging_time': 15.181557178497314}
I0425 00:52:31.277575 139584197314304 logging_writer.py:48] [28000] accumulated_eval_time=394.519700, accumulated_logging_time=15.181557, accumulated_submission_time=9475.542244, global_step=28000, preemption_count=0, score=9475.542244, test/accuracy=0.541400, test/loss=2.207253, test/num_examples=10000, total_duration=9885.575748, train/accuracy=0.761300, train/loss=1.145988, validation/accuracy=0.671420, validation/loss=1.545873, validation/num_examples=50000
I0425 00:52:31.510816 139763077670720 checkpoints.py:356] Saving checkpoint at step: 28000
I0425 00:52:32.217091 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_28000
I0425 00:52:32.233643 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_28000.
I0425 00:52:32.255509 139584373495552 logging_writer.py:48] [28000] global_step=28000, preemption_count=0, score=9475.542244
I0425 00:52:32.394098 139763077670720 checkpoints.py:356] Saving checkpoint at step: 28000
I0425 00:52:33.292657 139763077670720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_28000
I0425 00:52:33.309144 139763077670720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_resnet_jax/trial_1/checkpoint_28000.
I0425 00:52:33.691479 139763077670720 submission_runner.py:567] Tuning trial 1/1
I0425 00:52:33.692314 139763077670720 submission_runner.py:568] Hyperparameters: Hyperparameters(learning_rate=0.4394877561366806, one_minus_beta1=0.07113602458522507, warmup_factor=0.05, weight_decay=9.611851572925426e-07, label_smoothing=0.2, dropout_rate=0.0, decay_steps_factor=0.9, end_factor=0.001)
I0425 00:52:33.695190 139763077670720 submission_runner.py:569] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0010961415246129036, 'train/loss': 6.91009521484375, 'validation/accuracy': 0.0010999999940395355, 'validation/loss': 6.910689353942871, 'validation/num_examples': 50000, 'test/accuracy': 0.0010999999940395355, 'test/loss': 6.910574436187744, 'test/num_examples': 10000, 'score': 46.25933313369751, 'total_duration': 86.2273280620575, 'accumulated_submission_time': 46.25933313369751, 'accumulated_eval_time': 39.96780347824097, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (1510, {'train/accuracy': 0.07499600946903229, 'train/loss': 5.420688629150391, 'validation/accuracy': 0.0674000009894371, 'validation/loss': 5.502216339111328, 'validation/num_examples': 50000, 'test/accuracy': 0.048500001430511475, 'test/loss': 5.727884769439697, 'test/num_examples': 10000, 'score': 556.5377888679504, 'total_duration': 614.0261564254761, 'accumulated_submission_time': 556.5377888679504, 'accumulated_eval_time': 56.912503480911255, 'accumulated_logging_time': 0.5584824085235596, 'global_step': 1510, 'preemption_count': 0}), (3023, {'train/accuracy': 0.2230149805545807, 'train/loss': 4.002138614654541, 'validation/accuracy': 0.2015399932861328, 'validation/loss': 4.115724086761475, 'validation/num_examples': 50000, 'test/accuracy': 0.14680001139640808, 'test/loss': 4.599239826202393, 'test/num_examples': 10000, 'score': 1066.6351895332336, 'total_duration': 1141.3751361370087, 'accumulated_submission_time': 1066.6351895332336, 'accumulated_eval_time': 73.59198427200317, 'accumulated_logging_time': 1.113279104232788, 'global_step': 3023, 'preemption_count': 0}), (4537, {'train/accuracy': 0.3521205186843872, 'train/loss': 3.1945250034332275, 'validation/accuracy': 0.3262999951839447, 'validation/loss': 3.331960916519165, 'validation/num_examples': 50000, 'test/accuracy': 0.23360000550746918, 'test/loss': 3.9342336654663086, 'test/num_examples': 10000, 'score': 1576.7663085460663, 'total_duration': 1668.8472757339478, 'accumulated_submission_time': 1576.7663085460663, 'accumulated_eval_time': 90.35292911529541, 'accumulated_logging_time': 1.6765480041503906, 'global_step': 4537, 'preemption_count': 0}), (6048, {'train/accuracy': 0.43676260113716125, 'train/loss': 2.7329609394073486, 'validation/accuracy': 0.4122999906539917, 'validation/loss': 2.8591697216033936, 'validation/num_examples': 50000, 'test/accuracy': 0.31060001254081726, 'test/loss': 3.4983508586883545, 'test/num_examples': 10000, 'score': 2086.7512383461, 'total_duration': 2196.1972613334656, 'accumulated_submission_time': 2086.7512383461, 'accumulated_eval_time': 106.95940113067627, 'accumulated_logging_time': 2.4177310466766357, 'global_step': 6048, 'preemption_count': 0}), (7565, {'train/accuracy': 0.5222018361091614, 'train/loss': 2.283324718475342, 'validation/accuracy': 0.49091997742652893, 'validation/loss': 2.418644428253174, 'validation/num_examples': 50000, 'test/accuracy': 0.3830000162124634, 'test/loss': 3.0580906867980957, 'test/num_examples': 10000, 'score': 2596.852639436722, 'total_duration': 2723.603588581085, 'accumulated_submission_time': 2596.852639436722, 'accumulated_eval_time': 123.69010138511658, 'accumulated_logging_time': 2.974679708480835, 'global_step': 7565, 'preemption_count': 0}), (9076, {'train/accuracy': 0.5859972834587097, 'train/loss': 2.029726982116699, 'validation/accuracy': 0.5260399580001831, 'validation/loss': 2.3124239444732666, 'validation/num_examples': 50000, 'test/accuracy': 0.4097000062465668, 'test/loss': 2.9572207927703857, 'test/num_examples': 10000, 'score': 3107.099504709244, 'total_duration': 3252.1307418346405, 'accumulated_submission_time': 3107.099504709244, 'accumulated_eval_time': 141.13106632232666, 'accumulated_logging_time': 3.7965238094329834, 'global_step': 9076, 'preemption_count': 0}), (10597, {'train/accuracy': 0.6100525856018066, 'train/loss': 1.9165980815887451, 'validation/accuracy': 0.551800012588501, 'validation/loss': 2.1876749992370605, 'validation/num_examples': 50000, 'test/accuracy': 0.4345000088214874, 'test/loss': 2.815077781677246, 'test/num_examples': 10000, 'score': 3617.2696194648743, 'total_duration': 3781.5808005332947, 'accumulated_submission_time': 3617.2696194648743, 'accumulated_eval_time': 159.56717991828918, 'accumulated_logging_time': 4.623153448104858, 'global_step': 10597, 'preemption_count': 0}), (12117, {'train/accuracy': 0.6346858739852905, 'train/loss': 1.7596992254257202, 'validation/accuracy': 0.5839200019836426, 'validation/loss': 2.000540018081665, 'validation/num_examples': 50000, 'test/accuracy': 0.45590001344680786, 'test/loss': 2.654935598373413, 'test/num_examples': 10000, 'score': 4127.567907810211, 'total_duration': 4311.3269510269165, 'accumulated_submission_time': 4127.567907810211, 'accumulated_eval_time': 178.20381355285645, 'accumulated_logging_time': 5.416542053222656, 'global_step': 12117, 'preemption_count': 0}), (13635, {'train/accuracy': 0.6484773755073547, 'train/loss': 1.701664686203003, 'validation/accuracy': 0.5889399647712708, 'validation/loss': 1.9587898254394531, 'validation/num_examples': 50000, 'test/accuracy': 0.4613000154495239, 'test/loss': 2.6168885231018066, 'test/num_examples': 10000, 'score': 4637.782868862152, 'total_duration': 4840.956250905991, 'accumulated_submission_time': 4637.782868862152, 'accumulated_eval_time': 196.75096011161804, 'accumulated_logging_time': 6.265419960021973, 'global_step': 13635, 'preemption_count': 0}), (15153, {'train/accuracy': 0.6792091727256775, 'train/loss': 1.5393463373184204, 'validation/accuracy': 0.6241599917411804, 'validation/loss': 1.7915846109390259, 'validation/num_examples': 50000, 'test/accuracy': 0.49320003390312195, 'test/loss': 2.4576618671417236, 'test/num_examples': 10000, 'score': 5148.011064529419, 'total_duration': 5371.600119590759, 'accumulated_submission_time': 5148.011064529419, 'accumulated_eval_time': 216.35280656814575, 'accumulated_logging_time': 7.061215400695801, 'global_step': 15153, 'preemption_count': 0}), (16664, {'train/accuracy': 0.6872209906578064, 'train/loss': 1.5227497816085815, 'validation/accuracy': 0.6283999681472778, 'validation/loss': 1.780399203300476, 'validation/num_examples': 50000, 'test/accuracy': 0.49960002303123474, 'test/loss': 2.4596431255340576, 'test/num_examples': 10000, 'score': 5658.099779129028, 'total_duration': 5901.811650276184, 'accumulated_submission_time': 5658.099779129028, 'accumulated_eval_time': 235.58148789405823, 'accumulated_logging_time': 7.937206745147705, 'global_step': 16664, 'preemption_count': 0}), (18178, {'train/accuracy': 0.7389190196990967, 'train/loss': 1.2906590700149536, 'validation/accuracy': 0.6403999924659729, 'validation/loss': 1.722090482711792, 'validation/num_examples': 50000, 'test/accuracy': 0.515500009059906, 'test/loss': 2.3578999042510986, 'test/num_examples': 10000, 'score': 6168.3493230342865, 'total_duration': 6432.913976430893, 'accumulated_submission_time': 6168.3493230342865, 'accumulated_eval_time': 255.51238870620728, 'accumulated_logging_time': 8.840662956237793, 'global_step': 18178, 'preemption_count': 0}), (19692, {'train/accuracy': 0.7188894748687744, 'train/loss': 1.3887217044830322, 'validation/accuracy': 0.6352999806404114, 'validation/loss': 1.759264588356018, 'validation/num_examples': 50000, 'test/accuracy': 0.5123000144958496, 'test/loss': 2.4046480655670166, 'test/num_examples': 10000, 'score': 6678.5207986831665, 'total_duration': 6963.456977844238, 'accumulated_submission_time': 6678.5207986831665, 'accumulated_eval_time': 274.9661371707916, 'accumulated_logging_time': 9.73922324180603, 'global_step': 19692, 'preemption_count': 0}), (21209, {'train/accuracy': 0.7323421239852905, 'train/loss': 1.2917200326919556, 'validation/accuracy': 0.6534799933433533, 'validation/loss': 1.6443893909454346, 'validation/num_examples': 50000, 'test/accuracy': 0.5164999961853027, 'test/loss': 2.31721830368042, 'test/num_examples': 10000, 'score': 7188.807301521301, 'total_duration': 7494.897300720215, 'accumulated_submission_time': 7188.807301521301, 'accumulated_eval_time': 295.2188708782196, 'accumulated_logging_time': 10.621732473373413, 'global_step': 21209, 'preemption_count': 0}), (22725, {'train/accuracy': 0.7314453125, 'train/loss': 1.2909939289093018, 'validation/accuracy': 0.6575199961662292, 'validation/loss': 1.6260364055633545, 'validation/num_examples': 50000, 'test/accuracy': 0.5267000198364258, 'test/loss': 2.2869460582733154, 'test/num_examples': 10000, 'score': 7699.087784767151, 'total_duration': 8025.730905532837, 'accumulated_submission_time': 7699.087784767151, 'accumulated_eval_time': 314.8858530521393, 'accumulated_logging_time': 11.489154577255249, 'global_step': 22725, 'preemption_count': 0}), (24239, {'train/accuracy': 0.7496412396430969, 'train/loss': 1.2467530965805054, 'validation/accuracy': 0.6677199602127075, 'validation/loss': 1.6030244827270508, 'validation/num_examples': 50000, 'test/accuracy': 0.5382000207901001, 'test/loss': 2.262397289276123, 'test/num_examples': 10000, 'score': 8209.188942193985, 'total_duration': 8556.578177690506, 'accumulated_submission_time': 8209.188942193985, 'accumulated_eval_time': 334.71755719184875, 'accumulated_logging_time': 12.38545560836792, 'global_step': 24239, 'preemption_count': 0}), (25752, {'train/accuracy': 0.753926157951355, 'train/loss': 1.236625075340271, 'validation/accuracy': 0.6725199818611145, 'validation/loss': 1.5934807062149048, 'validation/num_examples': 50000, 'test/accuracy': 0.5383000373840332, 'test/loss': 2.2523090839385986, 'test/num_examples': 10000, 'score': 8719.362540960312, 'total_duration': 9087.759526968002, 'accumulated_submission_time': 8719.362540960312, 'accumulated_eval_time': 354.65634202957153, 'accumulated_logging_time': 13.435758590698242, 'global_step': 25752, 'preemption_count': 0}), (27268, {'train/accuracy': 0.7898796200752258, 'train/loss': 1.0813071727752686, 'validation/accuracy': 0.6738799810409546, 'validation/loss': 1.573690414428711, 'validation/num_examples': 50000, 'test/accuracy': 0.5461000204086304, 'test/loss': 2.222787618637085, 'test/num_examples': 10000, 'score': 9229.450891494751, 'total_duration': 9618.50238275528, 'accumulated_submission_time': 9229.450891494751, 'accumulated_eval_time': 374.4371933937073, 'accumulated_logging_time': 14.291338205337524, 'global_step': 27268, 'preemption_count': 0}), (28000, {'train/accuracy': 0.7613002061843872, 'train/loss': 1.1459882259368896, 'validation/accuracy': 0.6714199781417847, 'validation/loss': 1.5458728075027466, 'validation/num_examples': 50000, 'test/accuracy': 0.5414000153541565, 'test/loss': 2.2072529792785645, 'test/num_examples': 10000, 'score': 9475.542243719101, 'total_duration': 9885.575748205185, 'accumulated_submission_time': 9475.542243719101, 'accumulated_eval_time': 394.5197002887726, 'accumulated_logging_time': 15.181557178497314, 'global_step': 28000, 'preemption_count': 0})], 'global_step': 28000}
I0425 00:52:33.695309 139763077670720 submission_runner.py:570] Timing: 9475.542243719101
I0425 00:52:33.695360 139763077670720 submission_runner.py:571] ====================
I0425 00:52:33.695482 139763077670720 submission_runner.py:631] Final imagenet_resnet score: 9475.542243719101
