I0427 05:41:47.282824 140421967972160 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax.
I0427 05:41:47.433545 140421967972160 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0427 05:41:48.361431 140421967972160 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Host CUDA Interpreter
I0427 05:41:48.362256 140421967972160 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0427 05:41:48.367823 140421967972160 submission_runner.py:528] Using RNG seed 2769295918
I0427 05:41:51.094912 140421967972160 submission_runner.py:537] --- Tuning run 1/1 ---
I0427 05:41:51.095141 140421967972160 submission_runner.py:542] Creating tuning directory at /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1.
I0427 05:41:51.095362 140421967972160 logger_utils.py:83] Saving hparams to /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/hparams.json.
I0427 05:41:51.226793 140421967972160 submission_runner.py:232] Initializing dataset.
I0427 05:41:51.226991 140421967972160 submission_runner.py:239] Initializing model.
I0427 05:41:57.804677 140421967972160 submission_runner.py:249] Initializing optimizer.
I0427 05:42:00.506545 140421967972160 submission_runner.py:256] Initializing metrics bundle.
I0427 05:42:00.506803 140421967972160 submission_runner.py:273] Initializing checkpoint and logger.
I0427 05:42:00.511414 140421967972160 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1 with prefix checkpoint_
I0427 05:42:00.511775 140421967972160 logger_utils.py:230] Unable to record workload.train_mean information. Continuing without it.
I0427 05:42:00.511858 140421967972160 logger_utils.py:230] Unable to record workload.train_stddev information. Continuing without it.
I0427 05:42:01.172050 140421967972160 submission_runner.py:294] Saving meta data to /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/meta_data_0.json.
I0427 05:42:01.173110 140421967972160 submission_runner.py:297] Saving flags to /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/flags_0.json.
I0427 05:42:01.228502 140421967972160 submission_runner.py:309] Starting training loop.
I0427 05:42:26.841594 140245732415232 logging_writer.py:48] [0] global_step=0, grad_norm=1.6707466840744019, loss=0.2735859751701355
I0427 05:42:26.849975 140421967972160 spec.py:298] Evaluating on the training split.
I0427 05:47:28.873773 140421967972160 spec.py:310] Evaluating on the validation split.
I0427 05:52:31.640694 140421967972160 spec.py:326] Evaluating on the test split.
I0427 05:57:26.522100 140421967972160 submission_runner.py:406] Time since start: 925.29s, 	Step: 1, 	{'train/loss': 0.27584169681147674, 'validation/loss': 0.27584591011235954, 'validation/num_examples': 89000000, 'test/loss': 0.2770583318081708, 'test/num_examples': 89274637, 'score': 25.621236562728882, 'total_duration': 925.2935175895691, 'accumulated_submission_time': 25.621236562728882, 'accumulated_eval_time': 899.6720387935638, 'accumulated_logging_time': 0}
I0427 05:57:26.538274 140233777579776 logging_writer.py:48] [1] accumulated_eval_time=899.672039, accumulated_logging_time=0, accumulated_submission_time=25.621237, global_step=1, preemption_count=0, score=25.621237, test/loss=0.277058, test/num_examples=89274637, total_duration=925.293518, train/loss=0.275842, validation/loss=0.275846, validation/num_examples=89000000
I0427 05:57:29.400542 140421967972160 checkpoints.py:356] Saving checkpoint at step: 1
I0427 05:57:47.772758 140421967972160 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_1
I0427 05:57:47.787306 140421967972160 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_1.
I0427 05:58:55.477893 140233769187072 logging_writer.py:48] [100] global_step=100, grad_norm=0.050382696092128754, loss=0.1266881376504898
I0427 05:59:47.804089 140421967972160 spec.py:298] Evaluating on the training split.
I0427 06:04:41.157946 140421967972160 spec.py:310] Evaluating on the validation split.
I0427 06:09:20.071511 140421967972160 spec.py:326] Evaluating on the test split.
I0427 06:14:01.777311 140421967972160 submission_runner.py:406] Time since start: 1920.55s, 	Step: 159, 	{'train/loss': 0.12917245355399765, 'validation/loss': 0.1297295393258427, 'validation/num_examples': 89000000, 'test/loss': 0.1330242989394625, 'test/num_examples': 89274637, 'score': 145.62026000022888, 'total_duration': 1920.5487258434296, 'accumulated_submission_time': 145.62026000022888, 'accumulated_eval_time': 1753.6451950073242, 'accumulated_logging_time': 21.281130075454712}
I0427 06:14:01.786536 140233735616256 logging_writer.py:48] [159] accumulated_eval_time=1753.645195, accumulated_logging_time=21.281130, accumulated_submission_time=145.620260, global_step=159, preemption_count=0, score=145.620260, test/loss=0.133024, test/num_examples=89274637, total_duration=1920.548726, train/loss=0.129172, validation/loss=0.129730, validation/num_examples=89000000
I0427 06:14:05.094204 140421967972160 checkpoints.py:356] Saving checkpoint at step: 159
I0427 06:14:27.701021 140421967972160 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_159
I0427 06:14:27.714504 140421967972160 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_159.
I0427 06:14:43.390336 140233769187072 logging_writer.py:48] [200] global_step=200, grad_norm=0.06240774318575859, loss=0.12054720520973206
I0427 06:16:15.178373 140245764921088 logging_writer.py:48] [300] global_step=300, grad_norm=0.0909089595079422, loss=0.13314533233642578
I0427 06:16:28.454005 140421967972160 spec.py:298] Evaluating on the training split.
I0427 06:21:27.515944 140421967972160 spec.py:310] Evaluating on the validation split.
I0427 06:26:06.197982 140421967972160 spec.py:326] Evaluating on the test split.
I0427 06:31:03.301858 140421967972160 submission_runner.py:406] Time since start: 2942.07s, 	Step: 315, 	{'train/loss': 0.12825788058631116, 'validation/loss': 0.1275568426966292, 'validation/num_examples': 89000000, 'test/loss': 0.13047665486447174, 'test/num_examples': 89274637, 'score': 266.343355178833, 'total_duration': 2942.0732760429382, 'accumulated_submission_time': 266.343355178833, 'accumulated_eval_time': 2628.492975950241, 'accumulated_logging_time': 47.23283267021179}
I0427 06:31:03.309940 140233769187072 logging_writer.py:48] [315] accumulated_eval_time=2628.492976, accumulated_logging_time=47.232833, accumulated_submission_time=266.343355, global_step=315, preemption_count=0, score=266.343355, test/loss=0.130477, test/num_examples=89274637, total_duration=2942.073276, train/loss=0.128258, validation/loss=0.127557, validation/num_examples=89000000
I0427 06:31:06.158592 140421967972160 checkpoints.py:356] Saving checkpoint at step: 315
I0427 06:31:23.551235 140421967972160 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_315
I0427 06:31:23.567716 140421967972160 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_315.
I0427 06:32:17.787648 140245764921088 logging_writer.py:48] [400] global_step=400, grad_norm=0.008821532130241394, loss=0.13292400538921356
I0427 06:33:23.618084 140421967972160 spec.py:298] Evaluating on the training split.
I0427 06:38:14.621845 140421967972160 spec.py:310] Evaluating on the validation split.
I0427 06:42:56.395699 140421967972160 spec.py:326] Evaluating on the test split.
I0427 06:47:37.024127 140421967972160 submission_runner.py:406] Time since start: 3935.80s, 	Step: 477, 	{'train/loss': 0.1285566564339588, 'validation/loss': 0.12663862921348315, 'validation/num_examples': 89000000, 'test/loss': 0.1293396241980799, 'test/num_examples': 89274637, 'score': 386.37515902519226, 'total_duration': 3935.79554104805, 'accumulated_submission_time': 386.37515902519226, 'accumulated_eval_time': 3481.898950815201, 'accumulated_logging_time': 67.5152735710144}
I0427 06:47:37.033693 140246092072704 logging_writer.py:48] [477] accumulated_eval_time=3481.898951, accumulated_logging_time=67.515274, accumulated_submission_time=386.375159, global_step=477, preemption_count=0, score=386.375159, test/loss=0.129340, test/num_examples=89274637, total_duration=3935.795541, train/loss=0.128557, validation/loss=0.126639, validation/num_examples=89000000
I0427 06:47:39.743147 140421967972160 checkpoints.py:356] Saving checkpoint at step: 477
I0427 06:47:58.831730 140421967972160 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_477
I0427 06:47:58.844690 140421967972160 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_477.
I0427 06:48:01.436900 140245764921088 logging_writer.py:48] [500] global_step=500, grad_norm=0.018003402277827263, loss=0.12356302887201309
I0427 06:49:25.294309 140245446162176 logging_writer.py:48] [600] global_step=600, grad_norm=0.007939539849758148, loss=0.12318151444196701
I0427 06:49:59.000869 140421967972160 spec.py:298] Evaluating on the training split.
I0427 06:55:07.131195 140421967972160 spec.py:310] Evaluating on the validation split.
I0427 06:59:48.450134 140421967972160 spec.py:326] Evaluating on the test split.
I0427 07:04:44.810203 140421967972160 submission_runner.py:406] Time since start: 4963.58s, 	Step: 640, 	{'train/loss': 0.12612726409440536, 'validation/loss': 0.1266700786516854, 'validation/num_examples': 89000000, 'test/loss': 0.1292432026354809, 'test/num_examples': 89274637, 'score': 506.5136637687683, 'total_duration': 4963.5815970897675, 'accumulated_submission_time': 506.5136637687683, 'accumulated_eval_time': 4367.708195209503, 'accumulated_logging_time': 89.35153818130493}
I0427 07:04:44.819131 140245764921088 logging_writer.py:48] [640] accumulated_eval_time=4367.708195, accumulated_logging_time=89.351538, accumulated_submission_time=506.513664, global_step=640, preemption_count=0, score=506.513664, test/loss=0.129243, test/num_examples=89274637, total_duration=4963.581597, train/loss=0.126127, validation/loss=0.126670, validation/num_examples=89000000
I0427 07:04:50.341634 140421967972160 checkpoints.py:356] Saving checkpoint at step: 640
I0427 07:05:15.171775 140421967972160 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_640
I0427 07:05:15.283351 140421967972160 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_640.
I0427 07:05:48.264868 140245446162176 logging_writer.py:48] [700] global_step=700, grad_norm=0.00775552773848176, loss=0.14156970381736755
I0427 07:07:14.641315 140245437769472 logging_writer.py:48] [800] global_step=800, grad_norm=0.026449723169207573, loss=0.11920829862356186
I0427 07:07:16.407054 140421967972160 spec.py:298] Evaluating on the training split.
I0427 07:12:06.784366 140421967972160 spec.py:310] Evaluating on the validation split.
I0427 07:16:48.104495 140421967972160 spec.py:326] Evaluating on the test split.
I0427 07:21:35.417161 140421967972160 submission_runner.py:406] Time since start: 5974.19s, 	Step: 803, 	{'train/loss': 0.12494317532638315, 'validation/loss': 0.12673134831460675, 'validation/num_examples': 89000000, 'test/loss': 0.12929631962547214, 'test/num_examples': 89274637, 'score': 627.4304776191711, 'total_duration': 5974.188564538956, 'accumulated_submission_time': 627.4304776191711, 'accumulated_eval_time': 5226.718227624893, 'accumulated_logging_time': 120.02936172485352}
I0427 07:21:35.426527 140245446162176 logging_writer.py:48] [803] accumulated_eval_time=5226.718228, accumulated_logging_time=120.029362, accumulated_submission_time=627.430478, global_step=803, preemption_count=0, score=627.430478, test/loss=0.129296, test/num_examples=89274637, total_duration=5974.188565, train/loss=0.124943, validation/loss=0.126731, validation/num_examples=89000000
I0427 07:21:38.987161 140421967972160 checkpoints.py:356] Saving checkpoint at step: 803
I0427 07:21:57.561933 140421967972160 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_803
I0427 07:21:57.596969 140421967972160 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_803.
I0427 07:23:02.951998 140245437769472 logging_writer.py:48] [900] global_step=900, grad_norm=0.006935772020369768, loss=0.13235078752040863
I0427 07:23:57.723686 140421967972160 spec.py:298] Evaluating on the training split.
I0427 07:28:42.931256 140421967972160 spec.py:310] Evaluating on the validation split.
I0427 07:33:22.012305 140421967972160 spec.py:326] Evaluating on the test split.
I0427 07:38:21.063917 140421967972160 submission_runner.py:406] Time since start: 6979.84s, 	Step: 964, 	{'train/loss': 0.125267416172996, 'validation/loss': 0.12653501123595506, 'validation/num_examples': 89000000, 'test/loss': 0.1289907681170409, 'test/num_examples': 89274637, 'score': 747.4908196926117, 'total_duration': 6979.835337162018, 'accumulated_submission_time': 747.4908196926117, 'accumulated_eval_time': 6090.058394670486, 'accumulated_logging_time': 142.27363324165344}
I0427 07:38:21.073352 140245764921088 logging_writer.py:48] [964] accumulated_eval_time=6090.058395, accumulated_logging_time=142.273633, accumulated_submission_time=747.490820, global_step=964, preemption_count=0, score=747.490820, test/loss=0.128991, test/num_examples=89274637, total_duration=6979.835337, train/loss=0.125267, validation/loss=0.126535, validation/num_examples=89000000
I0427 07:38:24.370433 140421967972160 checkpoints.py:356] Saving checkpoint at step: 964
I0427 07:38:42.252914 140421967972160 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_964
I0427 07:38:42.268489 140421967972160 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_964.
I0427 07:38:53.227301 140245437769472 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.006679309066385031, loss=0.1178753599524498
I0427 07:40:20.139976 140245890746112 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.010940470732748508, loss=0.1304028332233429
I0427 07:40:43.107815 140421967972160 spec.py:298] Evaluating on the training split.
I0427 07:45:37.577217 140421967972160 spec.py:310] Evaluating on the validation split.
I0427 07:50:16.453681 140421967972160 spec.py:326] Evaluating on the test split.
I0427 07:55:05.043900 140421967972160 submission_runner.py:406] Time since start: 7983.82s, 	Step: 1128, 	{'train/loss': 0.1252850889721015, 'validation/loss': 0.1260303820224719, 'validation/num_examples': 89000000, 'test/loss': 0.12842049416566095, 'test/num_examples': 89274637, 'score': 868.2760353088379, 'total_duration': 7983.815323352814, 'accumulated_submission_time': 868.2760353088379, 'accumulated_eval_time': 6951.994415283203, 'accumulated_logging_time': 163.53038239479065}
I0427 07:55:05.052312 140245437769472 logging_writer.py:48] [1128] accumulated_eval_time=6951.994415, accumulated_logging_time=163.530382, accumulated_submission_time=868.276035, global_step=1128, preemption_count=0, score=868.276035, test/loss=0.128420, test/num_examples=89274637, total_duration=7983.815323, train/loss=0.125285, validation/loss=0.126030, validation/num_examples=89000000
I0427 07:55:07.928174 140421967972160 checkpoints.py:356] Saving checkpoint at step: 1128
I0427 07:55:26.201913 140421967972160 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_1128
I0427 07:55:26.235278 140421967972160 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_1128.
I0427 07:56:08.318189 140245890746112 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.005097535438835621, loss=0.11861687153577805
I0427 07:57:26.626726 140421967972160 spec.py:298] Evaluating on the training split.
I0427 08:02:14.363470 140421967972160 spec.py:310] Evaluating on the validation split.
I0427 08:06:58.111831 140421967972160 spec.py:326] Evaluating on the test split.
I0427 08:11:57.385797 140421967972160 submission_runner.py:406] Time since start: 8996.16s, 	Step: 1290, 	{'train/loss': 0.1241928336372965, 'validation/loss': 0.12600539325842697, 'validation/num_examples': 89000000, 'test/loss': 0.12839395807344475, 'test/num_examples': 89274637, 'score': 988.650625705719, 'total_duration': 8996.157226800919, 'accumulated_submission_time': 988.650625705719, 'accumulated_eval_time': 7822.753444194794, 'accumulated_logging_time': 184.7366964817047}
I0427 08:11:57.394329 140246437041920 logging_writer.py:48] [1290] accumulated_eval_time=7822.753444, accumulated_logging_time=184.736696, accumulated_submission_time=988.650626, global_step=1290, preemption_count=0, score=988.650626, test/loss=0.128394, test/num_examples=89274637, total_duration=8996.157227, train/loss=0.124193, validation/loss=0.126005, validation/num_examples=89000000
I0427 08:12:00.548205 140421967972160 checkpoints.py:356] Saving checkpoint at step: 1290
I0427 08:12:21.588244 140421967972160 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_1290
I0427 08:12:21.670884 140421967972160 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_1290.
I0427 08:12:22.905730 140245890746112 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.005352740176022053, loss=0.12196226418018341
I0427 08:13:36.262163 140245177726720 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.02458392083644867, loss=0.13023628294467926
I0427 08:14:22.146687 140421967972160 spec.py:298] Evaluating on the training split.
I0427 08:19:15.373203 140421967972160 spec.py:310] Evaluating on the validation split.
I0427 08:23:57.574325 140421967972160 spec.py:326] Evaluating on the test split.
I0427 08:28:52.703510 140421967972160 submission_runner.py:406] Time since start: 10011.47s, 	Step: 1454, 	{'train/loss': 0.12491756436401996, 'validation/loss': 0.12568332584269662, 'validation/num_examples': 89000000, 'test/loss': 0.12811250075427358, 'test/num_examples': 89274637, 'score': 1109.0792934894562, 'total_duration': 10011.474930524826, 'accumulated_submission_time': 1109.0792934894562, 'accumulated_eval_time': 8693.310217380524, 'accumulated_logging_time': 209.06689047813416}
I0427 08:28:52.712345 140245890746112 logging_writer.py:48] [1454] accumulated_eval_time=8693.310217, accumulated_logging_time=209.066890, accumulated_submission_time=1109.079293, global_step=1454, preemption_count=0, score=1109.079293, test/loss=0.128113, test/num_examples=89274637, total_duration=10011.474931, train/loss=0.124918, validation/loss=0.125683, validation/num_examples=89000000
I0427 08:28:56.163895 140421967972160 checkpoints.py:356] Saving checkpoint at step: 1454
I0427 08:29:15.988452 140421967972160 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_1454
I0427 08:29:16.048064 140421967972160 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_1454.
I0427 08:29:35.453434 140245177726720 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.0080804992467165, loss=0.12290090322494507
I0427 08:30:59.375559 140421967972160 spec.py:298] Evaluating on the training split.
I0427 08:35:49.392352 140421967972160 spec.py:310] Evaluating on the validation split.
I0427 08:40:30.225402 140421967972160 spec.py:326] Evaluating on the test split.
I0427 08:45:23.242763 140421967972160 submission_runner.py:406] Time since start: 11002.01s, 	Step: 1600, 	{'train/loss': 0.12578126347354443, 'validation/loss': 0.12784575280898877, 'validation/num_examples': 89000000, 'test/loss': 0.1304663943915, 'test/num_examples': 89274637, 'score': 1212.3457698822021, 'total_duration': 11002.01418042183, 'accumulated_submission_time': 1212.3457698822021, 'accumulated_eval_time': 9557.177372455597, 'accumulated_logging_time': 232.47073888778687}
I0427 08:45:23.251956 140245899138816 logging_writer.py:48] [1600] accumulated_eval_time=9557.177372, accumulated_logging_time=232.470739, accumulated_submission_time=1212.345770, global_step=1600, preemption_count=0, score=1212.345770, test/loss=0.130466, test/num_examples=89274637, total_duration=11002.014180, train/loss=0.125781, validation/loss=0.127846, validation/num_examples=89000000
I0427 08:45:26.253771 140421967972160 checkpoints.py:356] Saving checkpoint at step: 1600
I0427 08:45:44.991084 140421967972160 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_1600
I0427 08:45:45.043473 140421967972160 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_1600.
I0427 08:45:45.083642 140245177726720 logging_writer.py:48] [1600] global_step=1600, preemption_count=0, score=1212.345770
I0427 08:45:47.893863 140421967972160 checkpoints.py:356] Saving checkpoint at step: 1600
I0427 08:46:14.267748 140421967972160 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_1600
I0427 08:46:14.328155 140421967972160 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b_redo/timing_adamw/criteo1tb_jax/trial_1/checkpoint_1600.
I0427 08:46:14.398980 140421967972160 submission_runner.py:567] Tuning trial 1/1
I0427 08:46:14.399209 140421967972160 submission_runner.py:568] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0427 08:46:14.400331 140421967972160 submission_runner.py:569] Metrics: {'eval_results': [(1, {'train/loss': 0.27584169681147674, 'validation/loss': 0.27584591011235954, 'validation/num_examples': 89000000, 'test/loss': 0.2770583318081708, 'test/num_examples': 89274637, 'score': 25.621236562728882, 'total_duration': 925.2935175895691, 'accumulated_submission_time': 25.621236562728882, 'accumulated_eval_time': 899.6720387935638, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (159, {'train/loss': 0.12917245355399765, 'validation/loss': 0.1297295393258427, 'validation/num_examples': 89000000, 'test/loss': 0.1330242989394625, 'test/num_examples': 89274637, 'score': 145.62026000022888, 'total_duration': 1920.5487258434296, 'accumulated_submission_time': 145.62026000022888, 'accumulated_eval_time': 1753.6451950073242, 'accumulated_logging_time': 21.281130075454712, 'global_step': 159, 'preemption_count': 0}), (315, {'train/loss': 0.12825788058631116, 'validation/loss': 0.1275568426966292, 'validation/num_examples': 89000000, 'test/loss': 0.13047665486447174, 'test/num_examples': 89274637, 'score': 266.343355178833, 'total_duration': 2942.0732760429382, 'accumulated_submission_time': 266.343355178833, 'accumulated_eval_time': 2628.492975950241, 'accumulated_logging_time': 47.23283267021179, 'global_step': 315, 'preemption_count': 0}), (477, {'train/loss': 0.1285566564339588, 'validation/loss': 0.12663862921348315, 'validation/num_examples': 89000000, 'test/loss': 0.1293396241980799, 'test/num_examples': 89274637, 'score': 386.37515902519226, 'total_duration': 3935.79554104805, 'accumulated_submission_time': 386.37515902519226, 'accumulated_eval_time': 3481.898950815201, 'accumulated_logging_time': 67.5152735710144, 'global_step': 477, 'preemption_count': 0}), (640, {'train/loss': 0.12612726409440536, 'validation/loss': 0.1266700786516854, 'validation/num_examples': 89000000, 'test/loss': 0.1292432026354809, 'test/num_examples': 89274637, 'score': 506.5136637687683, 'total_duration': 4963.5815970897675, 'accumulated_submission_time': 506.5136637687683, 'accumulated_eval_time': 4367.708195209503, 'accumulated_logging_time': 89.35153818130493, 'global_step': 640, 'preemption_count': 0}), (803, {'train/loss': 0.12494317532638315, 'validation/loss': 0.12673134831460675, 'validation/num_examples': 89000000, 'test/loss': 0.12929631962547214, 'test/num_examples': 89274637, 'score': 627.4304776191711, 'total_duration': 5974.188564538956, 'accumulated_submission_time': 627.4304776191711, 'accumulated_eval_time': 5226.718227624893, 'accumulated_logging_time': 120.02936172485352, 'global_step': 803, 'preemption_count': 0}), (964, {'train/loss': 0.125267416172996, 'validation/loss': 0.12653501123595506, 'validation/num_examples': 89000000, 'test/loss': 0.1289907681170409, 'test/num_examples': 89274637, 'score': 747.4908196926117, 'total_duration': 6979.835337162018, 'accumulated_submission_time': 747.4908196926117, 'accumulated_eval_time': 6090.058394670486, 'accumulated_logging_time': 142.27363324165344, 'global_step': 964, 'preemption_count': 0}), (1128, {'train/loss': 0.1252850889721015, 'validation/loss': 0.1260303820224719, 'validation/num_examples': 89000000, 'test/loss': 0.12842049416566095, 'test/num_examples': 89274637, 'score': 868.2760353088379, 'total_duration': 7983.815323352814, 'accumulated_submission_time': 868.2760353088379, 'accumulated_eval_time': 6951.994415283203, 'accumulated_logging_time': 163.53038239479065, 'global_step': 1128, 'preemption_count': 0}), (1290, {'train/loss': 0.1241928336372965, 'validation/loss': 0.12600539325842697, 'validation/num_examples': 89000000, 'test/loss': 0.12839395807344475, 'test/num_examples': 89274637, 'score': 988.650625705719, 'total_duration': 8996.157226800919, 'accumulated_submission_time': 988.650625705719, 'accumulated_eval_time': 7822.753444194794, 'accumulated_logging_time': 184.7366964817047, 'global_step': 1290, 'preemption_count': 0}), (1454, {'train/loss': 0.12491756436401996, 'validation/loss': 0.12568332584269662, 'validation/num_examples': 89000000, 'test/loss': 0.12811250075427358, 'test/num_examples': 89274637, 'score': 1109.0792934894562, 'total_duration': 10011.474930524826, 'accumulated_submission_time': 1109.0792934894562, 'accumulated_eval_time': 8693.310217380524, 'accumulated_logging_time': 209.06689047813416, 'global_step': 1454, 'preemption_count': 0}), (1600, {'train/loss': 0.12578126347354443, 'validation/loss': 0.12784575280898877, 'validation/num_examples': 89000000, 'test/loss': 0.1304663943915, 'test/num_examples': 89274637, 'score': 1212.3457698822021, 'total_duration': 11002.01418042183, 'accumulated_submission_time': 1212.3457698822021, 'accumulated_eval_time': 9557.177372455597, 'accumulated_logging_time': 232.47073888778687, 'global_step': 1600, 'preemption_count': 0})], 'global_step': 1600}
I0427 08:46:14.400439 140421967972160 submission_runner.py:570] Timing: 1212.3457698822021
I0427 08:46:14.400485 140421967972160 submission_runner.py:571] ====================
I0427 08:46:14.400598 140421967972160 submission_runner.py:631] Final criteo1tb score: 1212.3457698822021
