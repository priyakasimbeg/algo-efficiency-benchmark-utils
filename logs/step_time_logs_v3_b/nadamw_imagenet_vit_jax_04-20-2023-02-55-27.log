I0420 02:55:49.227262 140719775172416 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax.
I0420 02:55:49.303404 140719775172416 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0420 02:55:50.182541 140719775172416 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Host Interpreter
I0420 02:55:50.183171 140719775172416 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0420 02:55:50.186961 140719775172416 submission_runner.py:528] Using RNG seed 1697134755
I0420 02:55:52.791897 140719775172416 submission_runner.py:537] --- Tuning run 1/1 ---
I0420 02:55:52.792114 140719775172416 submission_runner.py:542] Creating tuning directory at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1.
I0420 02:55:52.792369 140719775172416 logger_utils.py:83] Saving hparams to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/hparams.json.
I0420 02:55:52.917407 140719775172416 submission_runner.py:232] Initializing dataset.
I0420 02:55:52.929770 140719775172416 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0420 02:55:52.937319 140719775172416 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0420 02:55:52.937426 140719775172416 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0420 02:55:53.204008 140719775172416 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0420 02:55:59.967755 140719775172416 submission_runner.py:239] Initializing model.
I0420 02:56:11.012102 140719775172416 submission_runner.py:249] Initializing optimizer.
I0420 02:56:11.653489 140719775172416 submission_runner.py:256] Initializing metrics bundle.
I0420 02:56:11.653681 140719775172416 submission_runner.py:273] Initializing checkpoint and logger.
I0420 02:56:11.654468 140719775172416 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1 with prefix checkpoint_
I0420 02:56:12.558506 140719775172416 submission_runner.py:294] Saving meta data to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/meta_data_0.json.
I0420 02:56:12.559474 140719775172416 submission_runner.py:297] Saving flags to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/flags_0.json.
I0420 02:56:12.564751 140719775172416 submission_runner.py:309] Starting training loop.
I0420 02:57:05.168373 140542964918016 logging_writer.py:48] [0] global_step=0, grad_norm=0.3343231678009033, loss=6.907756805419922
I0420 02:57:05.184395 140719775172416 spec.py:298] Evaluating on the training split.
I0420 02:57:05.190617 140719775172416 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0420 02:57:05.196565 140719775172416 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0420 02:57:05.196670 140719775172416 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0420 02:57:05.256294 140719775172416 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0420 02:57:25.669298 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 02:57:25.676902 140719775172416 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0420 02:57:25.691429 140719775172416 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0420 02:57:25.691601 140719775172416 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0420 02:57:25.752115 140719775172416 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0420 02:57:44.539495 140719775172416 spec.py:326] Evaluating on the test split.
I0420 02:57:44.546048 140719775172416 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0420 02:57:44.551286 140719775172416 dataset_builder.py:510] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0420 02:57:44.583761 140719775172416 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0420 02:57:55.073248 140719775172416 submission_runner.py:406] Time since start: 102.51s, 	Step: 1, 	{'train/accuracy': 0.001054687425494194, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 52.61946654319763, 'total_duration': 102.50843691825867, 'accumulated_submission_time': 52.61946654319763, 'accumulated_eval_time': 49.88882231712341, 'accumulated_logging_time': 0}
I0420 02:57:55.088574 140481820333824 logging_writer.py:48] [1] accumulated_eval_time=49.888822, accumulated_logging_time=0, accumulated_submission_time=52.619467, global_step=1, preemption_count=0, score=52.619467, test/accuracy=0.001000, test/loss=6.907757, test/num_examples=10000, total_duration=102.508437, train/accuracy=0.001055, train/loss=6.907756, validation/accuracy=0.001000, validation/loss=6.907756, validation/num_examples=50000
I0420 02:57:55.290510 140719775172416 checkpoints.py:356] Saving checkpoint at step: 1
I0420 02:57:55.865000 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_1
I0420 02:57:55.866075 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_1.
I0420 02:58:52.955502 140538472752896 logging_writer.py:48] [100] global_step=100, grad_norm=0.4417573809623718, loss=6.898793697357178
I0420 02:59:32.149360 140538481145600 logging_writer.py:48] [200] global_step=200, grad_norm=0.4056319296360016, loss=6.884022235870361
I0420 03:00:12.001691 140538472752896 logging_writer.py:48] [300] global_step=300, grad_norm=0.6450687050819397, loss=6.771578788757324
I0420 03:00:52.610736 140538481145600 logging_writer.py:48] [400] global_step=400, grad_norm=0.5731444358825684, loss=6.7633867263793945
I0420 03:01:33.477967 140538472752896 logging_writer.py:48] [500] global_step=500, grad_norm=1.5661306381225586, loss=6.67924165725708
I0420 03:02:14.370116 140538481145600 logging_writer.py:48] [600] global_step=600, grad_norm=1.085125207901001, loss=6.541794300079346
I0420 03:02:55.200145 140538472752896 logging_writer.py:48] [700] global_step=700, grad_norm=0.8114542961120605, loss=6.64005184173584
I0420 03:03:36.046948 140538481145600 logging_writer.py:48] [800] global_step=800, grad_norm=1.9509040117263794, loss=6.424049377441406
I0420 03:04:17.188125 140538472752896 logging_writer.py:48] [900] global_step=900, grad_norm=1.0578726530075073, loss=6.324122905731201
I0420 03:04:56.218203 140719775172416 spec.py:298] Evaluating on the training split.
I0420 03:05:07.243469 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 03:05:13.721386 140719775172416 spec.py:326] Evaluating on the test split.
I0420 03:05:15.607216 140719775172416 submission_runner.py:406] Time since start: 543.04s, 	Step: 998, 	{'train/accuracy': 0.034003905951976776, 'train/loss': 5.9408135414123535, 'validation/accuracy': 0.03240000084042549, 'validation/loss': 5.971524238586426, 'validation/num_examples': 50000, 'test/accuracy': 0.025600001215934753, 'test/loss': 6.076261520385742, 'test/num_examples': 10000, 'score': 472.94655442237854, 'total_duration': 543.0423657894135, 'accumulated_submission_time': 472.94655442237854, 'accumulated_eval_time': 69.27781105041504, 'accumulated_logging_time': 0.7944607734680176}
I0420 03:05:15.637978 140481988122368 logging_writer.py:48] [998] accumulated_eval_time=69.277811, accumulated_logging_time=0.794461, accumulated_submission_time=472.946554, global_step=998, preemption_count=0, score=472.946554, test/accuracy=0.025600, test/loss=6.076262, test/num_examples=10000, total_duration=543.042366, train/accuracy=0.034004, train/loss=5.940814, validation/accuracy=0.032400, validation/loss=5.971524, validation/num_examples=50000
I0420 03:05:17.183564 140719775172416 checkpoints.py:356] Saving checkpoint at step: 998
I0420 03:05:18.214150 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_998
I0420 03:05:18.215262 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_998.
I0420 03:05:19.406611 140481996515072 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.1663150787353516, loss=6.284666538238525
I0420 03:05:58.696213 140543594059520 logging_writer.py:48] [1100] global_step=1100, grad_norm=1.549525499343872, loss=6.334103107452393
I0420 03:06:38.163510 140481996515072 logging_writer.py:48] [1200] global_step=1200, grad_norm=1.4875587224960327, loss=6.154267311096191
I0420 03:07:18.869805 140543594059520 logging_writer.py:48] [1300] global_step=1300, grad_norm=1.8876017332077026, loss=6.107674598693848
I0420 03:07:59.322274 140481996515072 logging_writer.py:48] [1400] global_step=1400, grad_norm=1.1819685697555542, loss=6.1679887771606445
I0420 03:08:39.934046 140543594059520 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.9030004739761353, loss=6.586638450622559
I0420 03:09:20.872828 140481996515072 logging_writer.py:48] [1600] global_step=1600, grad_norm=1.2693184614181519, loss=6.027657508850098
I0420 03:10:01.523655 140543594059520 logging_writer.py:48] [1700] global_step=1700, grad_norm=1.1876095533370972, loss=6.044792652130127
I0420 03:10:42.306372 140481996515072 logging_writer.py:48] [1800] global_step=1800, grad_norm=1.367018461227417, loss=6.018189907073975
I0420 03:11:23.091452 140543594059520 logging_writer.py:48] [1900] global_step=1900, grad_norm=1.1545302867889404, loss=5.915638446807861
I0420 03:12:03.759469 140481996515072 logging_writer.py:48] [2000] global_step=2000, grad_norm=1.1661617755889893, loss=5.913952350616455
I0420 03:12:18.553441 140719775172416 spec.py:298] Evaluating on the training split.
I0420 03:12:29.416637 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 03:12:36.024438 140719775172416 spec.py:326] Evaluating on the test split.
I0420 03:12:37.745663 140719775172416 submission_runner.py:406] Time since start: 985.18s, 	Step: 2038, 	{'train/accuracy': 0.07462890446186066, 'train/loss': 5.287240505218506, 'validation/accuracy': 0.07245999574661255, 'validation/loss': 5.317380905151367, 'validation/num_examples': 50000, 'test/accuracy': 0.05690000206232071, 'test/loss': 5.516536235809326, 'test/num_examples': 10000, 'score': 893.2589406967163, 'total_duration': 985.1807990074158, 'accumulated_submission_time': 893.2589406967163, 'accumulated_eval_time': 88.46999216079712, 'accumulated_logging_time': 3.4042108058929443}
I0420 03:12:37.758743 140543594059520 logging_writer.py:48] [2038] accumulated_eval_time=88.469992, accumulated_logging_time=3.404211, accumulated_submission_time=893.258941, global_step=2038, preemption_count=0, score=893.258941, test/accuracy=0.056900, test/loss=5.516536, test/num_examples=10000, total_duration=985.180799, train/accuracy=0.074629, train/loss=5.287241, validation/accuracy=0.072460, validation/loss=5.317381, validation/num_examples=50000
I0420 03:12:38.364035 140719775172416 checkpoints.py:356] Saving checkpoint at step: 2038
I0420 03:12:41.120798 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_2038
I0420 03:12:41.141403 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_2038.
I0420 03:13:05.889845 140481996515072 logging_writer.py:48] [2100] global_step=2100, grad_norm=1.1617465019226074, loss=6.368034839630127
I0420 03:13:45.080522 140543560488704 logging_writer.py:48] [2200] global_step=2200, grad_norm=1.0078123807907104, loss=6.678350448608398
I0420 03:14:25.354774 140481996515072 logging_writer.py:48] [2300] global_step=2300, grad_norm=1.1414376497268677, loss=6.106988906860352
I0420 03:15:06.176623 140543560488704 logging_writer.py:48] [2400] global_step=2400, grad_norm=1.2717483043670654, loss=5.721961498260498
I0420 03:15:46.953265 140481996515072 logging_writer.py:48] [2500] global_step=2500, grad_norm=1.2111256122589111, loss=5.816024303436279
I0420 03:16:27.381778 140543560488704 logging_writer.py:48] [2600] global_step=2600, grad_norm=1.2573151588439941, loss=5.668720722198486
I0420 03:17:07.948674 140481996515072 logging_writer.py:48] [2700] global_step=2700, grad_norm=1.198788046836853, loss=5.674816608428955
I0420 03:17:48.713819 140543560488704 logging_writer.py:48] [2800] global_step=2800, grad_norm=1.3380897045135498, loss=5.931808948516846
I0420 03:18:29.448486 140481996515072 logging_writer.py:48] [2900] global_step=2900, grad_norm=1.149355173110962, loss=6.446775913238525
I0420 03:19:10.453273 140543560488704 logging_writer.py:48] [3000] global_step=3000, grad_norm=1.200127124786377, loss=5.648124694824219
I0420 03:19:41.480688 140719775172416 spec.py:298] Evaluating on the training split.
I0420 03:19:52.882709 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 03:19:59.840509 140719775172416 spec.py:326] Evaluating on the test split.
I0420 03:20:01.542072 140719775172416 submission_runner.py:406] Time since start: 1428.98s, 	Step: 3078, 	{'train/accuracy': 0.14386717975139618, 'train/loss': 4.635059356689453, 'validation/accuracy': 0.13346000015735626, 'validation/loss': 4.697714805603027, 'validation/num_examples': 50000, 'test/accuracy': 0.10290000587701797, 'test/loss': 4.998244285583496, 'test/num_examples': 10000, 'score': 1313.5718960762024, 'total_duration': 1428.9771900177002, 'accumulated_submission_time': 1313.5718960762024, 'accumulated_eval_time': 108.53130793571472, 'accumulated_logging_time': 6.802292823791504}
I0420 03:20:01.557204 140481996515072 logging_writer.py:48] [3078] accumulated_eval_time=108.531308, accumulated_logging_time=6.802293, accumulated_submission_time=1313.571896, global_step=3078, preemption_count=0, score=1313.571896, test/accuracy=0.102900, test/loss=4.998244, test/num_examples=10000, total_duration=1428.977190, train/accuracy=0.143867, train/loss=4.635059, validation/accuracy=0.133460, validation/loss=4.697715, validation/num_examples=50000
I0420 03:20:01.713677 140719775172416 checkpoints.py:356] Saving checkpoint at step: 3078
I0420 03:20:04.176935 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_3078
I0420 03:20:04.194547 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_3078.
I0420 03:20:13.349361 140543560488704 logging_writer.py:48] [3100] global_step=3100, grad_norm=1.255264401435852, loss=5.538407802581787
I0420 03:20:52.598541 140543141082880 logging_writer.py:48] [3200] global_step=3200, grad_norm=1.0613610744476318, loss=5.56197452545166
I0420 03:21:32.357164 140543560488704 logging_writer.py:48] [3300] global_step=3300, grad_norm=1.2941575050354004, loss=5.439496040344238
I0420 03:22:12.950508 140543141082880 logging_writer.py:48] [3400] global_step=3400, grad_norm=1.4338829517364502, loss=5.474143981933594
I0420 03:22:53.709141 140543560488704 logging_writer.py:48] [3500] global_step=3500, grad_norm=1.0794492959976196, loss=5.442244052886963
I0420 03:23:34.522103 140543141082880 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.8330878615379333, loss=6.416454792022705
I0420 03:24:15.776786 140543560488704 logging_writer.py:48] [3700] global_step=3700, grad_norm=1.1119141578674316, loss=5.358741760253906
I0420 03:24:56.591354 140543141082880 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.9343547224998474, loss=6.461737632751465
I0420 03:25:37.464537 140543560488704 logging_writer.py:48] [3900] global_step=3900, grad_norm=1.3704272508621216, loss=5.294495582580566
I0420 03:26:18.004348 140543141082880 logging_writer.py:48] [4000] global_step=4000, grad_norm=1.5079662799835205, loss=5.247746467590332
I0420 03:26:58.548832 140543560488704 logging_writer.py:48] [4100] global_step=4100, grad_norm=1.1408493518829346, loss=6.360414028167725
I0420 03:27:04.572822 140719775172416 spec.py:298] Evaluating on the training split.
I0420 03:27:16.055572 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 03:27:23.285139 140719775172416 spec.py:326] Evaluating on the test split.
I0420 03:27:24.956008 140719775172416 submission_runner.py:406] Time since start: 1872.39s, 	Step: 4116, 	{'train/accuracy': 0.2066992074251175, 'train/loss': 4.170814037322998, 'validation/accuracy': 0.18789999186992645, 'validation/loss': 4.295699596405029, 'validation/num_examples': 50000, 'test/accuracy': 0.14030000567436218, 'test/loss': 4.65855598449707, 'test/num_examples': 10000, 'score': 1733.924048423767, 'total_duration': 1872.3911664485931, 'accumulated_submission_time': 1733.924048423767, 'accumulated_eval_time': 128.91447472572327, 'accumulated_logging_time': 9.456857681274414}
I0420 03:27:24.968570 140543141082880 logging_writer.py:48] [4116] accumulated_eval_time=128.914475, accumulated_logging_time=9.456858, accumulated_submission_time=1733.924048, global_step=4116, preemption_count=0, score=1733.924048, test/accuracy=0.140300, test/loss=4.658556, test/num_examples=10000, total_duration=1872.391166, train/accuracy=0.206699, train/loss=4.170814, validation/accuracy=0.187900, validation/loss=4.295700, validation/num_examples=50000
I0420 03:27:25.120215 140719775172416 checkpoints.py:356] Saving checkpoint at step: 4116
I0420 03:27:27.267064 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_4116
I0420 03:27:27.281163 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_4116.
I0420 03:28:00.818210 140543560488704 logging_writer.py:48] [4200] global_step=4200, grad_norm=1.2099337577819824, loss=5.245412826538086
I0420 03:28:40.154008 140542939739904 logging_writer.py:48] [4300] global_step=4300, grad_norm=1.1772657632827759, loss=5.162065505981445
I0420 03:29:21.032729 140543560488704 logging_writer.py:48] [4400] global_step=4400, grad_norm=1.0500227212905884, loss=5.6531782150268555
I0420 03:30:01.865987 140542939739904 logging_writer.py:48] [4500] global_step=4500, grad_norm=1.2105737924575806, loss=5.051421642303467
I0420 03:30:42.574681 140543560488704 logging_writer.py:48] [4600] global_step=4600, grad_norm=1.0272148847579956, loss=5.074188232421875
I0420 03:31:23.144098 140542939739904 logging_writer.py:48] [4700] global_step=4700, grad_norm=1.1778215169906616, loss=4.986354827880859
I0420 03:32:03.933311 140543560488704 logging_writer.py:48] [4800] global_step=4800, grad_norm=1.0948792695999146, loss=4.986082077026367
I0420 03:32:44.902263 140542939739904 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.9967154264450073, loss=6.405889511108398
I0420 03:33:26.138826 140543560488704 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.9783661961555481, loss=4.9810991287231445
I0420 03:34:06.963481 140542939739904 logging_writer.py:48] [5100] global_step=5100, grad_norm=1.0491946935653687, loss=4.937379837036133
I0420 03:34:27.628274 140719775172416 spec.py:298] Evaluating on the training split.
I0420 03:34:39.190244 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 03:34:47.755380 140719775172416 spec.py:326] Evaluating on the test split.
I0420 03:34:49.425919 140719775172416 submission_runner.py:406] Time since start: 2316.86s, 	Step: 5152, 	{'train/accuracy': 0.24861328303813934, 'train/loss': 3.7793493270874023, 'validation/accuracy': 0.23307999968528748, 'validation/loss': 3.8655173778533936, 'validation/num_examples': 50000, 'test/accuracy': 0.1746000051498413, 'test/loss': 4.301485061645508, 'test/num_examples': 10000, 'score': 2154.2451586723328, 'total_duration': 2316.86106300354, 'accumulated_submission_time': 2154.2451586723328, 'accumulated_eval_time': 150.71208214759827, 'accumulated_logging_time': 11.783991813659668}
I0420 03:34:49.440851 140543560488704 logging_writer.py:48] [5152] accumulated_eval_time=150.712082, accumulated_logging_time=11.783992, accumulated_submission_time=2154.245159, global_step=5152, preemption_count=0, score=2154.245159, test/accuracy=0.174600, test/loss=4.301485, test/num_examples=10000, total_duration=2316.861063, train/accuracy=0.248613, train/loss=3.779349, validation/accuracy=0.233080, validation/loss=3.865517, validation/num_examples=50000
I0420 03:34:49.626708 140719775172416 checkpoints.py:356] Saving checkpoint at step: 5152
I0420 03:34:50.771745 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_5152
I0420 03:34:50.786207 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_5152.
I0420 03:35:10.167752 140542939739904 logging_writer.py:48] [5200] global_step=5200, grad_norm=1.205140471458435, loss=4.9261040687561035
I0420 03:35:49.470374 140542931347200 logging_writer.py:48] [5300] global_step=5300, grad_norm=1.3275421857833862, loss=5.005621433258057
I0420 03:36:29.735746 140542939739904 logging_writer.py:48] [5400] global_step=5400, grad_norm=1.0325194597244263, loss=4.841309070587158
I0420 03:37:10.740909 140542931347200 logging_writer.py:48] [5500] global_step=5500, grad_norm=1.3473588228225708, loss=4.933207988739014
I0420 03:37:51.690555 140542939739904 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.9944013953208923, loss=4.763171672821045
I0420 03:38:32.414245 140542931347200 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.9673745036125183, loss=4.704672336578369
I0420 03:39:13.231367 140542939739904 logging_writer.py:48] [5800] global_step=5800, grad_norm=1.1427979469299316, loss=4.87230110168457
I0420 03:39:54.410071 140542931347200 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.9211696982383728, loss=4.929518222808838
I0420 03:40:35.188490 140542939739904 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.9987186789512634, loss=5.088855743408203
I0420 03:41:16.098820 140542931347200 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.9024823307991028, loss=5.073427677154541
I0420 03:41:51.061122 140719775172416 spec.py:298] Evaluating on the training split.
I0420 03:42:04.447620 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 03:42:13.176621 140719775172416 spec.py:326] Evaluating on the test split.
I0420 03:42:14.828098 140719775172416 submission_runner.py:406] Time since start: 2762.26s, 	Step: 6187, 	{'train/accuracy': 0.30882811546325684, 'train/loss': 3.3946287631988525, 'validation/accuracy': 0.2844800055027008, 'validation/loss': 3.538059949874878, 'validation/num_examples': 50000, 'test/accuracy': 0.2199000120162964, 'test/loss': 4.01646089553833, 'test/num_examples': 10000, 'score': 2574.4878108501434, 'total_duration': 2762.263241291046, 'accumulated_submission_time': 2574.4878108501434, 'accumulated_eval_time': 174.47902750968933, 'accumulated_logging_time': 13.152902364730835}
I0420 03:42:14.842835 140542939739904 logging_writer.py:48] [6187] accumulated_eval_time=174.479028, accumulated_logging_time=13.152902, accumulated_submission_time=2574.487811, global_step=6187, preemption_count=0, score=2574.487811, test/accuracy=0.219900, test/loss=4.016461, test/num_examples=10000, total_duration=2762.263241, train/accuracy=0.308828, train/loss=3.394629, validation/accuracy=0.284480, validation/loss=3.538060, validation/num_examples=50000
I0420 03:42:15.011452 140719775172416 checkpoints.py:356] Saving checkpoint at step: 6187
I0420 03:42:16.160697 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_6187
I0420 03:42:16.177092 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_6187.
I0420 03:42:21.848653 140542931347200 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.7534786462783813, loss=6.217319965362549
I0420 03:43:01.165768 140542922954496 logging_writer.py:48] [6300] global_step=6300, grad_norm=1.031179666519165, loss=4.6501641273498535
I0420 03:43:41.717442 140542931347200 logging_writer.py:48] [6400] global_step=6400, grad_norm=1.1790391206741333, loss=4.7408552169799805
I0420 03:44:22.682035 140542922954496 logging_writer.py:48] [6500] global_step=6500, grad_norm=1.0335077047348022, loss=4.9587860107421875
I0420 03:45:03.551758 140542931347200 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.9391319155693054, loss=4.659643650054932
I0420 03:45:44.379685 140542922954496 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.8154416680335999, loss=4.977990627288818
I0420 03:46:25.339773 140542931347200 logging_writer.py:48] [6800] global_step=6800, grad_norm=1.0741511583328247, loss=4.666008472442627
I0420 03:47:05.965436 140542922954496 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.9040811657905579, loss=4.5480756759643555
I0420 03:47:46.856213 140542931347200 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.9017602801322937, loss=4.874893665313721
I0420 03:48:27.778609 140542922954496 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.9861679673194885, loss=4.531067848205566
I0420 03:49:08.639679 140542931347200 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.8052305579185486, loss=6.161365509033203
I0420 03:49:16.516849 140719775172416 spec.py:298] Evaluating on the training split.
I0420 03:49:30.301005 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 03:49:39.982433 140719775172416 spec.py:326] Evaluating on the test split.
I0420 03:49:41.661584 140719775172416 submission_runner.py:406] Time since start: 3209.10s, 	Step: 7221, 	{'train/accuracy': 0.35566404461860657, 'train/loss': 3.1111443042755127, 'validation/accuracy': 0.3284599781036377, 'validation/loss': 3.259812831878662, 'validation/num_examples': 50000, 'test/accuracy': 0.24960000813007355, 'test/loss': 3.777083396911621, 'test/num_examples': 10000, 'score': 2994.7988045215607, 'total_duration': 3209.0967061519623, 'accumulated_submission_time': 2994.7988045215607, 'accumulated_eval_time': 199.62368440628052, 'accumulated_logging_time': 14.508310079574585}
I0420 03:49:41.675584 140542922954496 logging_writer.py:48] [7221] accumulated_eval_time=199.623684, accumulated_logging_time=14.508310, accumulated_submission_time=2994.798805, global_step=7221, preemption_count=0, score=2994.798805, test/accuracy=0.249600, test/loss=3.777083, test/num_examples=10000, total_duration=3209.096706, train/accuracy=0.355664, train/loss=3.111144, validation/accuracy=0.328460, validation/loss=3.259813, validation/num_examples=50000
I0420 03:49:41.893719 140719775172416 checkpoints.py:356] Saving checkpoint at step: 7221
I0420 03:49:43.111192 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_7221
I0420 03:49:43.129716 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_7221.
I0420 03:50:14.685328 140542931347200 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.9662600755691528, loss=4.396781921386719
I0420 03:50:54.673870 140542914561792 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.6112971901893616, loss=5.9291276931762695
I0420 03:51:35.744350 140542931347200 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.833699643611908, loss=4.409786224365234
I0420 03:52:16.424799 140542914561792 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.838682234287262, loss=4.536212921142578
I0420 03:52:57.382636 140542931347200 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.9741730690002441, loss=4.413218975067139
I0420 03:53:38.142047 140542914561792 logging_writer.py:48] [7800] global_step=7800, grad_norm=1.0255719423294067, loss=4.873605251312256
I0420 03:54:19.270220 140542931347200 logging_writer.py:48] [7900] global_step=7900, grad_norm=1.0882424116134644, loss=4.351109981536865
I0420 03:54:59.932338 140542914561792 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.9315140247344971, loss=4.473355293273926
I0420 03:55:40.813518 140542931347200 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.9309825301170349, loss=4.360806941986084
I0420 03:56:21.590354 140542914561792 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.884146511554718, loss=4.266807556152344
I0420 03:56:43.455861 140719775172416 spec.py:298] Evaluating on the training split.
I0420 03:56:58.071272 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 03:57:08.252693 140719775172416 spec.py:326] Evaluating on the test split.
I0420 03:57:09.920895 140719775172416 submission_runner.py:406] Time since start: 3657.36s, 	Step: 8255, 	{'train/accuracy': 0.40166014432907104, 'train/loss': 2.8314285278320312, 'validation/accuracy': 0.3667199909687042, 'validation/loss': 2.9927611351013184, 'validation/num_examples': 50000, 'test/accuracy': 0.28280001878738403, 'test/loss': 3.5496041774749756, 'test/num_examples': 10000, 'score': 3415.093871831894, 'total_duration': 3657.3560252189636, 'accumulated_submission_time': 3415.093871831894, 'accumulated_eval_time': 226.08865237236023, 'accumulated_logging_time': 15.985587358474731}
I0420 03:57:09.931108 140542931347200 logging_writer.py:48] [8255] accumulated_eval_time=226.088652, accumulated_logging_time=15.985587, accumulated_submission_time=3415.093872, global_step=8255, preemption_count=0, score=3415.093872, test/accuracy=0.282800, test/loss=3.549604, test/num_examples=10000, total_duration=3657.356025, train/accuracy=0.401660, train/loss=2.831429, validation/accuracy=0.366720, validation/loss=2.992761, validation/num_examples=50000
I0420 03:57:10.124886 140719775172416 checkpoints.py:356] Saving checkpoint at step: 8255
I0420 03:57:11.399240 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_8255
I0420 03:57:11.419119 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_8255.
I0420 03:57:29.479550 140542914561792 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.8384017944335938, loss=4.695300102233887
I0420 03:58:09.324800 140542646126336 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.8388749957084656, loss=4.613667964935303
I0420 03:58:50.041660 140542914561792 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.6857650279998779, loss=5.9928083419799805
I0420 03:59:31.074660 140542646126336 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.9388967752456665, loss=4.193523406982422
I0420 04:00:12.023296 140542914561792 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.8877261281013489, loss=4.408817291259766
I0420 04:00:53.177514 140542646126336 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.9854410290718079, loss=4.360055446624756
I0420 04:01:33.950277 140542914561792 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.7288819551467896, loss=4.814094066619873
I0420 04:02:14.810073 140542646126336 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.7369697690010071, loss=4.970327377319336
I0420 04:02:55.562063 140542914561792 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.9288002848625183, loss=4.24437952041626
I0420 04:03:36.620741 140542646126336 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.7931565046310425, loss=4.1402130126953125
I0420 04:04:11.512984 140719775172416 spec.py:298] Evaluating on the training split.
I0420 04:04:26.462843 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 04:04:37.384207 140719775172416 spec.py:326] Evaluating on the test split.
I0420 04:04:39.036140 140719775172416 submission_runner.py:406] Time since start: 4106.47s, 	Step: 9286, 	{'train/accuracy': 0.4475195109844208, 'train/loss': 2.5673539638519287, 'validation/accuracy': 0.3967199921607971, 'validation/loss': 2.837702512741089, 'validation/num_examples': 50000, 'test/accuracy': 0.30730000138282776, 'test/loss': 3.408738374710083, 'test/num_examples': 10000, 'score': 3835.1536943912506, 'total_duration': 4106.47126865387, 'accumulated_submission_time': 3835.1536943912506, 'accumulated_eval_time': 253.61173748970032, 'accumulated_logging_time': 17.495925903320312}
I0420 04:04:39.049978 140542914561792 logging_writer.py:48] [9286] accumulated_eval_time=253.611737, accumulated_logging_time=17.495926, accumulated_submission_time=3835.153694, global_step=9286, preemption_count=0, score=3835.153694, test/accuracy=0.307300, test/loss=3.408738, test/num_examples=10000, total_duration=4106.471269, train/accuracy=0.447520, train/loss=2.567354, validation/accuracy=0.396720, validation/loss=2.837703, validation/num_examples=50000
I0420 04:04:39.345069 140719775172416 checkpoints.py:356] Saving checkpoint at step: 9286
I0420 04:04:40.640599 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_9286
I0420 04:04:40.659744 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_9286.
I0420 04:04:46.663827 140542646126336 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.9159306287765503, loss=4.174872875213623
I0420 04:05:26.615581 140542637733632 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.8534501791000366, loss=4.32171630859375
I0420 04:06:07.519658 140542646126336 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.6361586451530457, loss=5.174993991851807
I0420 04:06:48.293896 140542637733632 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.8349658250808716, loss=4.1226887702941895
I0420 04:07:29.315419 140542646126336 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.8466850519180298, loss=4.087677955627441
I0420 04:08:10.509066 140542637733632 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.6066498756408691, loss=6.005609512329102
I0420 04:08:51.325248 140542646126336 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.8970919251441956, loss=4.108782768249512
I0420 04:09:32.703786 140542637733632 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.8036874532699585, loss=4.203061580657959
I0420 04:10:13.718888 140542646126336 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.7205294370651245, loss=5.1663641929626465
I0420 04:10:54.456948 140542637733632 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.870089590549469, loss=4.051976203918457
I0420 04:11:36.065890 140542646126336 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.8205245137214661, loss=4.196969032287598
I0420 04:11:40.787695 140719775172416 spec.py:298] Evaluating on the training split.
I0420 04:11:55.154574 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 04:12:06.654206 140719775172416 spec.py:326] Evaluating on the test split.
I0420 04:12:08.298693 140719775172416 submission_runner.py:406] Time since start: 4555.73s, 	Step: 10313, 	{'train/accuracy': 0.46044921875, 'train/loss': 2.5133142471313477, 'validation/accuracy': 0.42805999517440796, 'validation/loss': 2.6601457595825195, 'validation/num_examples': 50000, 'test/accuracy': 0.33160001039505005, 'test/loss': 3.261354923248291, 'test/num_examples': 10000, 'score': 4255.246996641159, 'total_duration': 4555.733868122101, 'accumulated_submission_time': 4255.246996641159, 'accumulated_eval_time': 281.1227159500122, 'accumulated_logging_time': 19.13232159614563}
I0420 04:12:08.309040 140542637733632 logging_writer.py:48] [10313] accumulated_eval_time=281.122716, accumulated_logging_time=19.132322, accumulated_submission_time=4255.246997, global_step=10313, preemption_count=0, score=4255.246997, test/accuracy=0.331600, test/loss=3.261355, test/num_examples=10000, total_duration=4555.733868, train/accuracy=0.460449, train/loss=2.513314, validation/accuracy=0.428060, validation/loss=2.660146, validation/num_examples=50000
I0420 04:12:08.547640 140719775172416 checkpoints.py:356] Saving checkpoint at step: 10313
I0420 04:12:09.811864 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_10313
I0420 04:12:09.828256 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_10313.
I0420 04:12:44.449988 140542646126336 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.7603970766067505, loss=3.9741430282592773
I0420 04:13:25.342964 140542629340928 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.7457371950149536, loss=4.353842735290527
I0420 04:14:06.214608 140542646126336 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.7101969718933105, loss=3.9429030418395996
I0420 04:14:47.002419 140542629340928 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.7318398952484131, loss=4.783567428588867
I0420 04:15:28.078416 140542646126336 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.6765223741531372, loss=5.351407051086426
I0420 04:16:09.045852 140542629340928 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.7330986857414246, loss=3.9600915908813477
I0420 04:16:49.517699 140542646126336 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.8043584823608398, loss=3.891044855117798
I0420 04:17:30.231438 140542629340928 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.7510337829589844, loss=3.971555233001709
I0420 04:18:11.811603 140542646126336 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.8570160865783691, loss=4.016668796539307
I0420 04:18:53.768405 140542629340928 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.9922314286231995, loss=3.979692220687866
I0420 04:19:10.175717 140719775172416 spec.py:298] Evaluating on the training split.
I0420 04:19:24.407053 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 04:19:35.086886 140719775172416 spec.py:326] Evaluating on the test split.
I0420 04:19:36.744731 140719775172416 submission_runner.py:406] Time since start: 5004.18s, 	Step: 11341, 	{'train/accuracy': 0.48945310711860657, 'train/loss': 2.373080015182495, 'validation/accuracy': 0.4531799852848053, 'validation/loss': 2.5568807125091553, 'validation/num_examples': 50000, 'test/accuracy': 0.357200026512146, 'test/loss': 3.141570568084717, 'test/num_examples': 10000, 'score': 4675.56228017807, 'total_duration': 5004.179877996445, 'accumulated_submission_time': 4675.56228017807, 'accumulated_eval_time': 307.6916718482971, 'accumulated_logging_time': 20.672757625579834}
I0420 04:19:36.760045 140542646126336 logging_writer.py:48] [11341] accumulated_eval_time=307.691672, accumulated_logging_time=20.672758, accumulated_submission_time=4675.562280, global_step=11341, preemption_count=0, score=4675.562280, test/accuracy=0.357200, test/loss=3.141571, test/num_examples=10000, total_duration=5004.179878, train/accuracy=0.489453, train/loss=2.373080, validation/accuracy=0.453180, validation/loss=2.556881, validation/num_examples=50000
I0420 04:19:37.030288 140719775172416 checkpoints.py:356] Saving checkpoint at step: 11341
I0420 04:19:38.349660 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_11341
I0420 04:19:38.372702 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_11341.
I0420 04:20:01.948677 140542629340928 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.6212760210037231, loss=4.719778060913086
I0420 04:20:43.803432 140542620948224 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.8814449310302734, loss=3.907338857650757
I0420 04:21:25.635010 140542629340928 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.8224242329597473, loss=4.017613887786865
I0420 04:22:07.050464 140542620948224 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.689420759677887, loss=5.988592147827148
I0420 04:22:48.230352 140542629340928 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.760852575302124, loss=4.24365758895874
I0420 04:23:28.983545 140542620948224 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.8523762822151184, loss=3.77415132522583
I0420 04:24:09.687387 140542629340928 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.7875577211380005, loss=3.9057064056396484
I0420 04:24:50.789355 140542620948224 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.7721688747406006, loss=3.803455114364624
I0420 04:25:32.177190 140542629340928 logging_writer.py:48] [12200] global_step=12200, grad_norm=1.0415289402008057, loss=3.9352052211761475
I0420 04:26:13.997200 140542620948224 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.7553216218948364, loss=3.9030072689056396
I0420 04:26:38.725219 140719775172416 spec.py:298] Evaluating on the training split.
I0420 04:26:52.969890 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 04:27:04.369503 140719775172416 spec.py:326] Evaluating on the test split.
I0420 04:27:06.023260 140719775172416 submission_runner.py:406] Time since start: 5453.46s, 	Step: 12361, 	{'train/accuracy': 0.5169140696525574, 'train/loss': 2.220503807067871, 'validation/accuracy': 0.47901999950408936, 'validation/loss': 2.409569501876831, 'validation/num_examples': 50000, 'test/accuracy': 0.36730000376701355, 'test/loss': 3.042520523071289, 'test/num_examples': 10000, 'score': 5095.879371166229, 'total_duration': 5453.45840716362, 'accumulated_submission_time': 5095.879371166229, 'accumulated_eval_time': 334.989666223526, 'accumulated_logging_time': 22.315101385116577}
I0420 04:27:06.038764 140542629340928 logging_writer.py:48] [12361] accumulated_eval_time=334.989666, accumulated_logging_time=22.315101, accumulated_submission_time=5095.879371, global_step=12361, preemption_count=0, score=5095.879371, test/accuracy=0.367300, test/loss=3.042521, test/num_examples=10000, total_duration=5453.458407, train/accuracy=0.516914, train/loss=2.220504, validation/accuracy=0.479020, validation/loss=2.409570, validation/num_examples=50000
I0420 04:27:06.329031 140719775172416 checkpoints.py:356] Saving checkpoint at step: 12361
I0420 04:27:07.659456 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_12361
I0420 04:27:07.681688 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_12361.
I0420 04:27:23.393837 140542620948224 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.7755822539329529, loss=3.8298802375793457
I0420 04:28:04.777153 140542411261696 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.6638222336769104, loss=4.846869468688965
I0420 04:28:46.600737 140542620948224 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.6283209919929504, loss=5.018590927124023
I0420 04:29:27.477805 140542411261696 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.7696585059165955, loss=3.75559663772583
I0420 04:30:08.782905 140542620948224 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.7981037497520447, loss=3.7187769412994385
I0420 04:30:49.675995 140542411261696 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.7339136600494385, loss=5.444039821624756
I0420 04:31:30.994405 140542620948224 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.7656193971633911, loss=3.641479253768921
I0420 04:32:11.751014 140542411261696 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.7252789735794067, loss=3.7246265411376953
I0420 04:32:53.217451 140542620948224 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.6079444289207458, loss=4.428884029388428
I0420 04:33:34.915853 140542411261696 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.6993973851203918, loss=5.3880615234375
I0420 04:34:07.771432 140719775172416 spec.py:298] Evaluating on the training split.
I0420 04:34:22.384074 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 04:34:33.445353 140719775172416 spec.py:326] Evaluating on the test split.
I0420 04:34:35.119505 140719775172416 submission_runner.py:406] Time since start: 5902.55s, 	Step: 13380, 	{'train/accuracy': 0.5477148294448853, 'train/loss': 2.0735554695129395, 'validation/accuracy': 0.49747997522354126, 'validation/loss': 2.325396776199341, 'validation/num_examples': 50000, 'test/accuracy': 0.3863000273704529, 'test/loss': 2.93672513961792, 'test/num_examples': 10000, 'score': 5515.931526660919, 'total_duration': 5902.5546498298645, 'accumulated_submission_time': 5515.931526660919, 'accumulated_eval_time': 362.33769273757935, 'accumulated_logging_time': 23.989985942840576}
I0420 04:34:35.135881 140542620948224 logging_writer.py:48] [13380] accumulated_eval_time=362.337693, accumulated_logging_time=23.989986, accumulated_submission_time=5515.931527, global_step=13380, preemption_count=0, score=5515.931527, test/accuracy=0.386300, test/loss=2.936725, test/num_examples=10000, total_duration=5902.554650, train/accuracy=0.547715, train/loss=2.073555, validation/accuracy=0.497480, validation/loss=2.325397, validation/num_examples=50000
I0420 04:34:35.473216 140719775172416 checkpoints.py:356] Saving checkpoint at step: 13380
I0420 04:34:36.813640 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_13380
I0420 04:34:36.837245 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_13380.
I0420 04:34:45.036620 140542411261696 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.8110474348068237, loss=3.9805727005004883
I0420 04:35:26.450703 140542402868992 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.9367431402206421, loss=3.7982966899871826
I0420 04:36:09.103487 140542411261696 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.7498218417167664, loss=3.6529181003570557
I0420 04:36:52.039040 140542402868992 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.8509392738342285, loss=3.666034460067749
I0420 04:37:34.587394 140542411261696 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.7144908308982849, loss=3.6420578956604004
I0420 04:38:16.408972 140542402868992 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.7748836874961853, loss=3.5845274925231934
I0420 04:38:57.902791 140542411261696 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.6880529522895813, loss=5.1801042556762695
I0420 04:39:39.327562 140542402868992 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.716667652130127, loss=3.6014063358306885
I0420 04:40:21.046402 140542411261696 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.7663909196853638, loss=3.57979154586792
I0420 04:41:03.350150 140542402868992 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.5972808599472046, loss=5.700319290161133
I0420 04:41:36.950872 140719775172416 spec.py:298] Evaluating on the training split.
I0420 04:41:51.305279 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 04:42:02.534057 140719775172416 spec.py:326] Evaluating on the test split.
I0420 04:42:04.175829 140719775172416 submission_runner.py:406] Time since start: 6351.61s, 	Step: 14382, 	{'train/accuracy': 0.5437304377555847, 'train/loss': 2.1423070430755615, 'validation/accuracy': 0.5023399591445923, 'validation/loss': 2.327653408050537, 'validation/num_examples': 50000, 'test/accuracy': 0.3939000070095062, 'test/loss': 2.934194564819336, 'test/num_examples': 10000, 'score': 5936.002881526947, 'total_duration': 6351.610885620117, 'accumulated_submission_time': 5936.002881526947, 'accumulated_eval_time': 389.5625615119934, 'accumulated_logging_time': 25.729616403579712}
I0420 04:42:04.193531 140542411261696 logging_writer.py:48] [14382] accumulated_eval_time=389.562562, accumulated_logging_time=25.729616, accumulated_submission_time=5936.002882, global_step=14382, preemption_count=0, score=5936.002882, test/accuracy=0.393900, test/loss=2.934195, test/num_examples=10000, total_duration=6351.610886, train/accuracy=0.543730, train/loss=2.142307, validation/accuracy=0.502340, validation/loss=2.327653, validation/num_examples=50000
I0420 04:42:04.441892 140719775172416 checkpoints.py:356] Saving checkpoint at step: 14382
I0420 04:42:05.675526 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_14382
I0420 04:42:05.697347 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_14382.
I0420 04:42:13.252333 140542402868992 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.7380075454711914, loss=3.8398971557617188
I0420 04:42:53.905841 140542394476288 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.7934167981147766, loss=3.7123231887817383
I0420 04:43:35.353563 140542402868992 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.7767707109451294, loss=3.5767781734466553
I0420 04:44:18.019243 140542394476288 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.7855626940727234, loss=3.7908599376678467
I0420 04:44:59.903502 140542402868992 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.6569348573684692, loss=5.246820449829102
I0420 04:45:41.582220 140542394476288 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.8029708862304688, loss=3.641021728515625
I0420 04:46:23.668383 140542402868992 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.7763239741325378, loss=3.7038559913635254
I0420 04:47:05.733558 140542394476288 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.7268885374069214, loss=3.57212495803833
I0420 04:47:47.614393 140542402868992 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.655898928642273, loss=4.966407299041748
I0420 04:48:29.975879 140542394476288 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.6105333566665649, loss=5.542166709899902
I0420 04:49:05.975789 140719775172416 spec.py:298] Evaluating on the training split.
I0420 04:49:21.153764 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 04:49:32.027420 140719775172416 spec.py:326] Evaluating on the test split.
I0420 04:49:33.685714 140719775172416 submission_runner.py:406] Time since start: 6801.12s, 	Step: 15387, 	{'train/accuracy': 0.5631445050239563, 'train/loss': 1.9786957502365112, 'validation/accuracy': 0.5228599905967712, 'validation/loss': 2.1692867279052734, 'validation/num_examples': 50000, 'test/accuracy': 0.4091000258922577, 'test/loss': 2.8128459453582764, 'test/num_examples': 10000, 'score': 6356.244428634644, 'total_duration': 6801.120886325836, 'accumulated_submission_time': 6356.244428634644, 'accumulated_eval_time': 417.2724778652191, 'accumulated_logging_time': 27.26752543449402}
I0420 04:49:33.696637 140542402868992 logging_writer.py:48] [15387] accumulated_eval_time=417.272478, accumulated_logging_time=27.267525, accumulated_submission_time=6356.244429, global_step=15387, preemption_count=0, score=6356.244429, test/accuracy=0.409100, test/loss=2.812846, test/num_examples=10000, total_duration=6801.120886, train/accuracy=0.563145, train/loss=1.978696, validation/accuracy=0.522860, validation/loss=2.169287, validation/num_examples=50000
I0420 04:49:33.980823 140719775172416 checkpoints.py:356] Saving checkpoint at step: 15387
I0420 04:49:35.170318 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_15387
I0420 04:49:35.192247 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_15387.
I0420 04:49:40.755092 140542394476288 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.7657514214515686, loss=3.6561055183410645
I0420 04:50:20.729012 140542386083584 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.7750318050384521, loss=3.6678154468536377
I0420 04:51:02.215010 140542394476288 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.7909095287322998, loss=3.73982310295105
I0420 04:51:43.909371 140542386083584 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.7679744958877563, loss=3.5559937953948975
I0420 04:52:25.701092 140542394476288 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.8635621666908264, loss=3.4762821197509766
I0420 04:53:07.379537 140542386083584 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.7546337842941284, loss=3.8166465759277344
I0420 04:53:49.944151 140542394476288 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.709335446357727, loss=4.191588401794434
I0420 04:54:32.610065 140542386083584 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.6863194704055786, loss=4.788746356964111
I0420 04:55:14.773251 140542394476288 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.7624092698097229, loss=3.8965442180633545
I0420 04:55:56.806308 140542386083584 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.7689303755760193, loss=3.4286022186279297
I0420 04:56:35.623972 140719775172416 spec.py:298] Evaluating on the training split.
I0420 04:56:50.412968 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 04:57:01.814372 140719775172416 spec.py:326] Evaluating on the test split.
I0420 04:57:03.463210 140719775172416 submission_runner.py:406] Time since start: 7250.90s, 	Step: 16394, 	{'train/accuracy': 0.5840234160423279, 'train/loss': 1.8566808700561523, 'validation/accuracy': 0.5412999987602234, 'validation/loss': 2.0552399158477783, 'validation/num_examples': 50000, 'test/accuracy': 0.4212000072002411, 'test/loss': 2.701127529144287, 'test/num_examples': 10000, 'score': 6776.636913537979, 'total_duration': 7250.898334741592, 'accumulated_submission_time': 6776.636913537979, 'accumulated_eval_time': 445.1116576194763, 'accumulated_logging_time': 28.79277801513672}
I0420 04:57:03.480512 140542394476288 logging_writer.py:48] [16394] accumulated_eval_time=445.111658, accumulated_logging_time=28.792778, accumulated_submission_time=6776.636914, global_step=16394, preemption_count=0, score=6776.636914, test/accuracy=0.421200, test/loss=2.701128, test/num_examples=10000, total_duration=7250.898335, train/accuracy=0.584023, train/loss=1.856681, validation/accuracy=0.541300, validation/loss=2.055240, validation/num_examples=50000
I0420 04:57:03.754511 140719775172416 checkpoints.py:356] Saving checkpoint at step: 16394
I0420 04:57:05.000745 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_16394
I0420 04:57:05.024208 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_16394.
I0420 04:57:07.896573 140542386083584 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.763465940952301, loss=3.5371057987213135
I0420 04:57:47.657783 140542377690880 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.6892717480659485, loss=5.050163269042969
I0420 04:58:29.365241 140542386083584 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.82347172498703, loss=3.7789039611816406
I0420 04:59:10.852698 140542377690880 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.9536363482475281, loss=3.5432450771331787
I0420 04:59:52.752906 140542386083584 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.742432713508606, loss=4.547974586486816
I0420 05:00:34.807513 140542377690880 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.8466395735740662, loss=5.706333637237549
I0420 05:01:16.872233 140542386083584 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.7598354816436768, loss=3.960667371749878
I0420 05:01:58.992369 140542377690880 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.8241092562675476, loss=3.5329079627990723
I0420 05:02:40.851091 140542386083584 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.8169590830802917, loss=3.5046253204345703
I0420 05:03:23.048113 140542377690880 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.7522141933441162, loss=4.213834285736084
I0420 05:04:04.990206 140542386083584 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.7218374013900757, loss=4.997745990753174
I0420 05:04:05.133963 140719775172416 spec.py:298] Evaluating on the training split.
I0420 05:04:20.172900 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 05:04:32.028124 140719775172416 spec.py:326] Evaluating on the test split.
I0420 05:04:33.683198 140719775172416 submission_runner.py:406] Time since start: 7701.12s, 	Step: 17402, 	{'train/accuracy': 0.602343738079071, 'train/loss': 1.8499764204025269, 'validation/accuracy': 0.551539957523346, 'validation/loss': 2.088876962661743, 'validation/num_examples': 50000, 'test/accuracy': 0.43320003151893616, 'test/loss': 2.72625470161438, 'test/num_examples': 10000, 'score': 7196.712497472763, 'total_duration': 7701.118371248245, 'accumulated_submission_time': 7196.712497472763, 'accumulated_eval_time': 473.6608581542969, 'accumulated_logging_time': 30.367119312286377}
I0420 05:04:33.697656 140542377690880 logging_writer.py:48] [17402] accumulated_eval_time=473.660858, accumulated_logging_time=30.367119, accumulated_submission_time=7196.712497, global_step=17402, preemption_count=0, score=7196.712497, test/accuracy=0.433200, test/loss=2.726255, test/num_examples=10000, total_duration=7701.118371, train/accuracy=0.602344, train/loss=1.849976, validation/accuracy=0.551540, validation/loss=2.088877, validation/num_examples=50000
I0420 05:04:33.989003 140719775172416 checkpoints.py:356] Saving checkpoint at step: 17402
I0420 05:04:35.337590 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_17402
I0420 05:04:35.362698 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_17402.
I0420 05:05:15.454887 140542386083584 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.8150805830955505, loss=3.491306781768799
I0420 05:05:57.352537 140542369298176 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.6854912042617798, loss=4.286120414733887
I0420 05:06:39.534550 140542386083584 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.7049577832221985, loss=3.803642749786377
I0420 05:07:21.603373 140542369298176 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.9064211249351501, loss=5.627405643463135
I0420 05:08:04.268897 140542386083584 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.7228707075119019, loss=4.244129657745361
I0420 05:08:46.466157 140542369298176 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.7529120445251465, loss=3.7968409061431885
I0420 05:09:28.345545 140542386083584 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.8269587755203247, loss=3.554511070251465
I0420 05:10:10.592632 140542369298176 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.6867347359657288, loss=4.056984901428223
I0420 05:10:52.473778 140542386083584 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.6996280550956726, loss=4.852092266082764
I0420 05:11:34.662434 140542369298176 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.7016014456748962, loss=4.821691036224365
I0420 05:11:35.614734 140719775172416 spec.py:298] Evaluating on the training split.
I0420 05:11:50.266716 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 05:12:02.305934 140719775172416 spec.py:326] Evaluating on the test split.
I0420 05:12:03.969276 140719775172416 submission_runner.py:406] Time since start: 8151.40s, 	Step: 18404, 	{'train/accuracy': 0.6024999618530273, 'train/loss': 1.8264795541763306, 'validation/accuracy': 0.5568999648094177, 'validation/loss': 2.035423517227173, 'validation/num_examples': 50000, 'test/accuracy': 0.43400001525878906, 'test/loss': 2.672787666320801, 'test/num_examples': 10000, 'score': 7616.920893907547, 'total_duration': 8151.404447793961, 'accumulated_submission_time': 7616.920893907547, 'accumulated_eval_time': 502.01537442207336, 'accumulated_logging_time': 32.069884061813354}
I0420 05:12:03.979989 140542386083584 logging_writer.py:48] [18404] accumulated_eval_time=502.015374, accumulated_logging_time=32.069884, accumulated_submission_time=7616.920894, global_step=18404, preemption_count=0, score=7616.920894, test/accuracy=0.434000, test/loss=2.672788, test/num_examples=10000, total_duration=8151.404448, train/accuracy=0.602500, train/loss=1.826480, validation/accuracy=0.556900, validation/loss=2.035424, validation/num_examples=50000
I0420 05:12:04.242047 140719775172416 checkpoints.py:356] Saving checkpoint at step: 18404
I0420 05:12:05.625657 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_18404
I0420 05:12:05.651843 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_18404.
I0420 05:12:44.594347 140542369298176 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.9363946318626404, loss=3.405073642730713
I0420 05:13:26.646999 140542360905472 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.8767204880714417, loss=3.6420323848724365
I0420 05:14:08.808442 140542369298176 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.9129183292388916, loss=3.38901424407959
I0420 05:14:51.273946 140542360905472 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.8724492192268372, loss=3.4764535427093506
I0420 05:15:33.361783 140542369298176 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.7155009508132935, loss=3.8142569065093994
I0420 05:16:15.635214 140542360905472 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.755368173122406, loss=3.8397443294525146
I0420 05:16:57.626679 140542369298176 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.7280029654502869, loss=4.196446895599365
I0420 05:17:39.518702 140542360905472 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.8232824802398682, loss=3.2713165283203125
I0420 05:18:21.872104 140542369298176 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.7260953783988953, loss=4.19514274597168
I0420 05:19:04.019694 140542360905472 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.7561924457550049, loss=3.260957956314087
I0420 05:19:06.024412 140719775172416 spec.py:298] Evaluating on the training split.
I0420 05:19:20.350875 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 05:19:32.549548 140719775172416 spec.py:326] Evaluating on the test split.
I0420 05:19:34.230234 140719775172416 submission_runner.py:406] Time since start: 8601.67s, 	Step: 19406, 	{'train/accuracy': 0.61669921875, 'train/loss': 1.72581148147583, 'validation/accuracy': 0.573199987411499, 'validation/loss': 1.9379098415374756, 'validation/num_examples': 50000, 'test/accuracy': 0.450300008058548, 'test/loss': 2.5780045986175537, 'test/num_examples': 10000, 'score': 8037.250782012939, 'total_duration': 8601.665384292603, 'accumulated_submission_time': 8037.250782012939, 'accumulated_eval_time': 530.2211480140686, 'accumulated_logging_time': 33.77423930168152}
I0420 05:19:34.243241 140542369298176 logging_writer.py:48] [19406] accumulated_eval_time=530.221148, accumulated_logging_time=33.774239, accumulated_submission_time=8037.250782, global_step=19406, preemption_count=0, score=8037.250782, test/accuracy=0.450300, test/loss=2.578005, test/num_examples=10000, total_duration=8601.665384, train/accuracy=0.616699, train/loss=1.725811, validation/accuracy=0.573200, validation/loss=1.937910, validation/num_examples=50000
I0420 05:19:34.618137 140719775172416 checkpoints.py:356] Saving checkpoint at step: 19406
I0420 05:19:35.984359 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_19406
I0420 05:19:36.010787 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_19406.
I0420 05:20:14.130093 140542360905472 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.7538730502128601, loss=4.345256328582764
I0420 05:20:55.353094 140541580793600 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.789196789264679, loss=3.491187572479248
I0420 05:21:36.782022 140542360905472 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.758757472038269, loss=4.394069671630859
I0420 05:22:18.282609 140541580793600 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.9357253313064575, loss=4.325052261352539
I0420 05:23:00.134231 140542360905472 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.805639922618866, loss=3.3656740188598633
I0420 05:23:41.996325 140541580793600 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.865565836429596, loss=3.6532366275787354
I0420 05:24:24.565201 140542360905472 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.8678767085075378, loss=3.3627984523773193
I0420 05:25:06.485391 140541580793600 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.7223520874977112, loss=3.934241533279419
I0420 05:25:48.852385 140542360905472 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.7665542960166931, loss=3.357337713241577
I0420 05:26:31.023088 140541580793600 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.8436405658721924, loss=3.2931554317474365
I0420 05:26:36.123859 140719775172416 spec.py:298] Evaluating on the training split.
I0420 05:26:50.257861 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 05:27:03.103408 140719775172416 spec.py:326] Evaluating on the test split.
I0420 05:27:04.752237 140719775172416 submission_runner.py:406] Time since start: 9052.19s, 	Step: 20414, 	{'train/accuracy': 0.6299999952316284, 'train/loss': 1.6961746215820312, 'validation/accuracy': 0.5757200121879578, 'validation/loss': 1.931368350982666, 'validation/num_examples': 50000, 'test/accuracy': 0.45980003476142883, 'test/loss': 2.568157434463501, 'test/num_examples': 10000, 'score': 8457.319392442703, 'total_duration': 9052.187388181686, 'accumulated_submission_time': 8457.319392442703, 'accumulated_eval_time': 558.8494715690613, 'accumulated_logging_time': 35.57838320732117}
I0420 05:27:04.765259 140542360905472 logging_writer.py:48] [20414] accumulated_eval_time=558.849472, accumulated_logging_time=35.578383, accumulated_submission_time=8457.319392, global_step=20414, preemption_count=0, score=8457.319392, test/accuracy=0.459800, test/loss=2.568157, test/num_examples=10000, total_duration=9052.187388, train/accuracy=0.630000, train/loss=1.696175, validation/accuracy=0.575720, validation/loss=1.931368, validation/num_examples=50000
I0420 05:27:05.083206 140719775172416 checkpoints.py:356] Saving checkpoint at step: 20414
I0420 05:27:06.327158 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_20414
I0420 05:27:06.351463 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_20414.
I0420 05:27:41.575771 140541580793600 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.7332718372344971, loss=3.929347038269043
I0420 05:28:23.986356 140541572400896 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.761663019657135, loss=3.6325771808624268
I0420 05:29:05.996026 140541580793600 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.8553930521011353, loss=3.348583221435547
I0420 05:29:47.962437 140541572400896 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.7266616821289062, loss=3.4273765087127686
I0420 05:30:30.420107 140541580793600 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.8161216378211975, loss=4.158083915710449
I0420 05:31:12.930556 140541572400896 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.8021085262298584, loss=5.303192615509033
I0420 05:31:54.967247 140541580793600 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.8502138257026672, loss=5.4801154136657715
I0420 05:32:37.009243 140541572400896 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.7718467712402344, loss=5.305205345153809
I0420 05:33:19.985944 140541580793600 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.7271087169647217, loss=4.351836681365967
I0420 05:34:02.462591 140541572400896 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.8289552330970764, loss=3.240588903427124
I0420 05:34:06.724360 140719775172416 spec.py:298] Evaluating on the training split.
I0420 05:34:20.248708 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 05:34:33.304699 140719775172416 spec.py:326] Evaluating on the test split.
I0420 05:34:34.952590 140719775172416 submission_runner.py:406] Time since start: 9502.39s, 	Step: 21412, 	{'train/accuracy': 0.6368945240974426, 'train/loss': 1.6031042337417603, 'validation/accuracy': 0.5841799974441528, 'validation/loss': 1.853515863418579, 'validation/num_examples': 50000, 'test/accuracy': 0.4603000283241272, 'test/loss': 2.49900221824646, 'test/num_examples': 10000, 'score': 8877.649254322052, 'total_duration': 9502.38774061203, 'accumulated_submission_time': 8877.649254322052, 'accumulated_eval_time': 587.0776479244232, 'accumulated_logging_time': 37.200618267059326}
I0420 05:34:34.970020 140541580793600 logging_writer.py:48] [21412] accumulated_eval_time=587.077648, accumulated_logging_time=37.200618, accumulated_submission_time=8877.649254, global_step=21412, preemption_count=0, score=8877.649254, test/accuracy=0.460300, test/loss=2.499002, test/num_examples=10000, total_duration=9502.387741, train/accuracy=0.636895, train/loss=1.603104, validation/accuracy=0.584180, validation/loss=1.853516, validation/num_examples=50000
I0420 05:34:35.342256 140719775172416 checkpoints.py:356] Saving checkpoint at step: 21412
I0420 05:34:36.519222 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_21412
I0420 05:34:36.545985 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_21412.
I0420 05:35:12.408072 140541572400896 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.7133537530899048, loss=4.3982110023498535
I0420 05:35:54.750096 140541564008192 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.8367006778717041, loss=3.23905873298645
I0420 05:36:37.684303 140541572400896 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.8104153871536255, loss=3.3387393951416016
I0420 05:37:20.453289 140541564008192 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.8872413635253906, loss=3.375947952270508
I0420 05:38:03.477769 140541572400896 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.7551405429840088, loss=5.377261638641357
I0420 05:38:46.120048 140541564008192 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.8227625489234924, loss=3.253859043121338
I0420 05:39:29.093924 140541572400896 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.7448132634162903, loss=3.637627124786377
I0420 05:40:11.859811 140541564008192 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.77030348777771, loss=5.256750106811523
I0420 05:40:54.528609 140541572400896 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.791902482509613, loss=4.837767601013184
I0420 05:41:36.586229 140719775172416 spec.py:298] Evaluating on the training split.
I0420 05:41:50.570042 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 05:42:03.233350 140719775172416 spec.py:326] Evaluating on the test split.
I0420 05:42:04.883172 140719775172416 submission_runner.py:406] Time since start: 9952.32s, 	Step: 22400, 	{'train/accuracy': 0.6545507907867432, 'train/loss': 1.5771229267120361, 'validation/accuracy': 0.5920599699020386, 'validation/loss': 1.8457199335098267, 'validation/num_examples': 50000, 'test/accuracy': 0.4733000099658966, 'test/loss': 2.483369827270508, 'test/num_examples': 10000, 'score': 9297.645182847977, 'total_duration': 9952.31832575798, 'accumulated_submission_time': 9297.645182847977, 'accumulated_eval_time': 615.3745415210724, 'accumulated_logging_time': 38.818665504455566}
I0420 05:42:04.896756 140541564008192 logging_writer.py:48] [22400] accumulated_eval_time=615.374542, accumulated_logging_time=38.818666, accumulated_submission_time=9297.645183, global_step=22400, preemption_count=0, score=9297.645183, test/accuracy=0.473300, test/loss=2.483370, test/num_examples=10000, total_duration=9952.318326, train/accuracy=0.654551, train/loss=1.577123, validation/accuracy=0.592060, validation/loss=1.845720, validation/num_examples=50000
I0420 05:42:05.289366 140719775172416 checkpoints.py:356] Saving checkpoint at step: 22400
I0420 05:42:06.492355 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_22400
I0420 05:42:06.519160 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_22400.
I0420 05:42:06.981361 140541572400896 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.8248957991600037, loss=3.3176679611206055
I0420 05:42:48.063285 140541555615488 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.9915598630905151, loss=3.1542320251464844
I0420 05:43:31.403174 140541572400896 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.8349955081939697, loss=3.2772858142852783
I0420 05:44:14.726500 140541555615488 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.8471773266792297, loss=3.413134813308716
I0420 05:44:57.820364 140541555615488 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.7981573343276978, loss=3.2467970848083496
I0420 05:45:41.070078 140541572400896 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.7602764368057251, loss=4.707969665527344
I0420 05:46:24.421815 140541555615488 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.8167026042938232, loss=4.30241060256958
I0420 05:47:07.457522 140541572400896 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.8226532340049744, loss=3.1605658531188965
I0420 05:47:50.454629 140541555615488 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.8410226106643677, loss=4.285374641418457
I0420 05:48:33.758462 140541572400896 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.8681357502937317, loss=3.3200392723083496
I0420 05:49:06.797570 140719775172416 spec.py:298] Evaluating on the training split.
I0420 05:49:20.328122 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 05:49:32.870645 140719775172416 spec.py:326] Evaluating on the test split.
I0420 05:49:34.567832 140719775172416 submission_runner.py:406] Time since start: 10402.00s, 	Step: 23378, 	{'train/accuracy': 0.6487890481948853, 'train/loss': 1.570358395576477, 'validation/accuracy': 0.6013000011444092, 'validation/loss': 1.7876310348510742, 'validation/num_examples': 50000, 'test/accuracy': 0.47780001163482666, 'test/loss': 2.428392171859741, 'test/num_examples': 10000, 'score': 9717.88070654869, 'total_duration': 10402.002984523773, 'accumulated_submission_time': 9717.88070654869, 'accumulated_eval_time': 643.1447505950928, 'accumulated_logging_time': 40.47808837890625}
I0420 05:49:34.593557 140541555615488 logging_writer.py:48] [23378] accumulated_eval_time=643.144751, accumulated_logging_time=40.478088, accumulated_submission_time=9717.880707, global_step=23378, preemption_count=0, score=9717.880707, test/accuracy=0.477800, test/loss=2.428392, test/num_examples=10000, total_duration=10402.002985, train/accuracy=0.648789, train/loss=1.570358, validation/accuracy=0.601300, validation/loss=1.787631, validation/num_examples=50000
I0420 05:49:36.085100 140719775172416 checkpoints.py:356] Saving checkpoint at step: 23378
I0420 05:49:37.450610 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_23378
I0420 05:49:37.476888 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_23378.
I0420 05:49:46.533885 140541572400896 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.8398882746696472, loss=3.419368028640747
I0420 05:50:27.272351 140541547222784 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.7704724073410034, loss=3.958298444747925
I0420 05:51:09.045088 140541572400896 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.9731777906417847, loss=5.292646884918213
I0420 05:51:50.879356 140541547222784 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.7962256669998169, loss=4.220726013183594
I0420 05:52:33.111638 140541572400896 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.903489887714386, loss=3.1874356269836426
I0420 05:53:16.201810 140541547222784 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.8435662388801575, loss=3.1877174377441406
I0420 05:53:59.141812 140541572400896 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.9632925391197205, loss=3.237832546234131
I0420 05:54:41.535087 140541547222784 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.8305609822273254, loss=3.6409964561462402
I0420 05:55:23.858366 140541572400896 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.8422823548316956, loss=3.923069953918457
I0420 05:56:06.148055 140541547222784 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.7782854437828064, loss=5.090330600738525
I0420 05:56:37.754561 140719775172416 spec.py:298] Evaluating on the training split.
I0420 05:56:48.821000 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 05:57:01.790062 140719775172416 spec.py:326] Evaluating on the test split.
I0420 05:57:03.451714 140719775172416 submission_runner.py:406] Time since start: 10850.89s, 	Step: 24376, 	{'train/accuracy': 0.6585937142372131, 'train/loss': 1.5336097478866577, 'validation/accuracy': 0.6029999852180481, 'validation/loss': 1.7811565399169922, 'validation/num_examples': 50000, 'test/accuracy': 0.4856000244617462, 'test/loss': 2.4069578647613525, 'test/num_examples': 10000, 'score': 10138.136598110199, 'total_duration': 10850.886875391006, 'accumulated_submission_time': 10138.136598110199, 'accumulated_eval_time': 668.8418624401093, 'accumulated_logging_time': 43.38910245895386}
I0420 05:57:03.464740 140541572400896 logging_writer.py:48] [24376] accumulated_eval_time=668.841862, accumulated_logging_time=43.389102, accumulated_submission_time=10138.136598, global_step=24376, preemption_count=0, score=10138.136598, test/accuracy=0.485600, test/loss=2.406958, test/num_examples=10000, total_duration=10850.886875, train/accuracy=0.658594, train/loss=1.533610, validation/accuracy=0.603000, validation/loss=1.781157, validation/num_examples=50000
I0420 05:57:03.831051 140719775172416 checkpoints.py:356] Saving checkpoint at step: 24376
I0420 05:57:05.156586 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_24376
I0420 05:57:05.181013 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_24376.
I0420 05:57:14.998717 140541547222784 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.8645671606063843, loss=3.151063919067383
I0420 05:57:55.771546 140541194925824 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.8383023738861084, loss=3.156953811645508
I0420 05:58:37.860072 140541547222784 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.8232390284538269, loss=4.187371730804443
I0420 05:59:20.697754 140541194925824 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.831950306892395, loss=3.2645678520202637
I0420 06:00:02.632515 140541547222784 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.9287510514259338, loss=5.313309669494629
I0420 06:00:45.049682 140541194925824 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.7766357660293579, loss=3.097970724105835
I0420 06:01:27.940596 140541547222784 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.7710720300674438, loss=3.6962571144104004
I0420 06:02:10.582889 140541194925824 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.8240293264389038, loss=3.1189069747924805
I0420 06:02:52.987081 140541547222784 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.9076459407806396, loss=3.1980528831481934
I0420 06:03:34.998716 140541194925824 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.8201173543930054, loss=3.8496251106262207
I0420 06:04:05.476364 140719775172416 spec.py:298] Evaluating on the training split.
I0420 06:04:16.161109 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 06:04:29.161387 140719775172416 spec.py:326] Evaluating on the test split.
I0420 06:04:30.842203 140719775172416 submission_runner.py:406] Time since start: 11298.28s, 	Step: 25373, 	{'train/accuracy': 0.6704687476158142, 'train/loss': 1.4809117317199707, 'validation/accuracy': 0.6150599718093872, 'validation/loss': 1.7427363395690918, 'validation/num_examples': 50000, 'test/accuracy': 0.489300012588501, 'test/loss': 2.3795080184936523, 'test/num_examples': 10000, 'score': 10558.392251253128, 'total_duration': 11298.277344465256, 'accumulated_submission_time': 10558.392251253128, 'accumulated_eval_time': 694.2076387405396, 'accumulated_logging_time': 45.138142108917236}
I0420 06:04:30.858343 140541547222784 logging_writer.py:48] [25373] accumulated_eval_time=694.207639, accumulated_logging_time=45.138142, accumulated_submission_time=10558.392251, global_step=25373, preemption_count=0, score=10558.392251, test/accuracy=0.489300, test/loss=2.379508, test/num_examples=10000, total_duration=11298.277344, train/accuracy=0.670469, train/loss=1.480912, validation/accuracy=0.615060, validation/loss=1.742736, validation/num_examples=50000
I0420 06:04:31.289183 140719775172416 checkpoints.py:356] Saving checkpoint at step: 25373
I0420 06:04:32.552796 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_25373
I0420 06:04:32.578882 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_25373.
I0420 06:04:43.568394 140541194925824 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.830188512802124, loss=3.1353442668914795
I0420 06:05:24.002942 140541186533120 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.8693886995315552, loss=3.1098837852478027
I0420 06:06:05.821865 140541194925824 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.824550986289978, loss=3.743734121322632
I0420 06:06:48.322888 140541186533120 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.872756838798523, loss=3.1065640449523926
I0420 06:07:30.431659 140541194925824 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.803800106048584, loss=4.956745624542236
I0420 06:08:12.121507 140541186533120 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.8359354138374329, loss=3.863692283630371
I0420 06:08:54.380564 140541194925824 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.8466624617576599, loss=3.1503543853759766
I0420 06:09:36.513299 140541186533120 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.8644610047340393, loss=3.0495667457580566
I0420 06:10:18.848911 140541194925824 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.8208208084106445, loss=3.286414861679077
I0420 06:11:00.944014 140541186533120 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.7981782555580139, loss=3.2029566764831543
I0420 06:11:32.656332 140719775172416 spec.py:298] Evaluating on the training split.
I0420 06:11:43.105359 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 06:11:56.024016 140719775172416 spec.py:326] Evaluating on the test split.
I0420 06:11:57.686689 140719775172416 submission_runner.py:406] Time since start: 11745.12s, 	Step: 26377, 	{'train/accuracy': 0.6854101419448853, 'train/loss': 1.3595638275146484, 'validation/accuracy': 0.6162199974060059, 'validation/loss': 1.6763254404067993, 'validation/num_examples': 50000, 'test/accuracy': 0.49390003085136414, 'test/loss': 2.30999493598938, 'test/num_examples': 10000, 'score': 10978.425423383713, 'total_duration': 11745.121807336807, 'accumulated_submission_time': 10978.425423383713, 'accumulated_eval_time': 719.2379148006439, 'accumulated_logging_time': 46.898720264434814}
I0420 06:11:57.701952 140541194925824 logging_writer.py:48] [26377] accumulated_eval_time=719.237915, accumulated_logging_time=46.898720, accumulated_submission_time=10978.425423, global_step=26377, preemption_count=0, score=10978.425423, test/accuracy=0.493900, test/loss=2.309995, test/num_examples=10000, total_duration=11745.121807, train/accuracy=0.685410, train/loss=1.359564, validation/accuracy=0.616220, validation/loss=1.676325, validation/num_examples=50000
I0420 06:11:58.069416 140719775172416 checkpoints.py:356] Saving checkpoint at step: 26377
I0420 06:11:59.293493 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_26377
I0420 06:11:59.319461 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_26377.
I0420 06:12:08.761167 140541186533120 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.9064327478408813, loss=3.264099597930908
I0420 06:12:49.110651 140541178140416 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.7388868927955627, loss=4.088360786437988
I0420 06:13:30.798887 140541186533120 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.8822554349899292, loss=4.140015602111816
I0420 06:14:12.958894 140541178140416 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.7688940763473511, loss=3.826655387878418
I0420 06:14:55.364191 140541186533120 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.860970675945282, loss=3.195854902267456
I0420 06:15:37.301506 140541178140416 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.8919593691825867, loss=3.572357654571533
I0420 06:16:19.308439 140541186533120 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.828180730342865, loss=3.9924092292785645
I0420 06:17:01.407142 140541178140416 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.9558999538421631, loss=5.172598838806152
I0420 06:17:43.738093 140541186533120 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.8131208419799805, loss=4.165843963623047
I0420 06:18:25.658476 140541178140416 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.9134675860404968, loss=4.889115810394287
I0420 06:18:59.595712 140719775172416 spec.py:298] Evaluating on the training split.
I0420 06:19:10.063189 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 06:19:23.094091 140719775172416 spec.py:326] Evaluating on the test split.
I0420 06:19:24.762054 140719775172416 submission_runner.py:406] Time since start: 12192.20s, 	Step: 27384, 	{'train/accuracy': 0.6732421517372131, 'train/loss': 1.436805248260498, 'validation/accuracy': 0.6233999729156494, 'validation/loss': 1.663799524307251, 'validation/num_examples': 50000, 'test/accuracy': 0.4991000294685364, 'test/loss': 2.305880546569824, 'test/num_examples': 10000, 'score': 11398.65911912918, 'total_duration': 12192.197200775146, 'accumulated_submission_time': 11398.65911912918, 'accumulated_eval_time': 744.4042100906372, 'accumulated_logging_time': 48.553497314453125}
I0420 06:19:24.779813 140541186533120 logging_writer.py:48] [27384] accumulated_eval_time=744.404210, accumulated_logging_time=48.553497, accumulated_submission_time=11398.659119, global_step=27384, preemption_count=0, score=11398.659119, test/accuracy=0.499100, test/loss=2.305881, test/num_examples=10000, total_duration=12192.197201, train/accuracy=0.673242, train/loss=1.436805, validation/accuracy=0.623400, validation/loss=1.663800, validation/num_examples=50000
I0420 06:19:25.125722 140719775172416 checkpoints.py:356] Saving checkpoint at step: 27384
I0420 06:19:26.358506 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_27384
I0420 06:19:26.382668 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_27384.
I0420 06:19:33.067273 140541178140416 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.8844165205955505, loss=3.0883212089538574
I0420 06:20:14.111870 140541169747712 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.8777541518211365, loss=2.9860305786132812
I0420 06:20:56.797047 140541178140416 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.9602354168891907, loss=3.171138048171997
I0420 06:21:39.560185 140541169747712 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.8473538756370544, loss=3.0795795917510986
I0420 06:22:21.895300 140541178140416 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.8114011883735657, loss=3.465620994567871
I0420 06:23:04.489588 140541169747712 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.8880510330200195, loss=3.096240758895874
I0420 06:23:46.182526 140719775172416 spec.py:298] Evaluating on the training split.
I0420 06:23:56.603346 140719775172416 spec.py:310] Evaluating on the validation split.
I0420 06:24:09.847441 140719775172416 spec.py:326] Evaluating on the test split.
I0420 06:24:11.514435 140719775172416 submission_runner.py:406] Time since start: 12478.95s, 	Step: 28000, 	{'train/accuracy': 0.6856445074081421, 'train/loss': 1.3503183126449585, 'validation/accuracy': 0.6266799569129944, 'validation/loss': 1.6179777383804321, 'validation/num_examples': 50000, 'test/accuracy': 0.5070000290870667, 'test/loss': 2.264331102371216, 'test/num_examples': 10000, 'score': 11658.425700187683, 'total_duration': 12478.949511289597, 'accumulated_submission_time': 11658.425700187683, 'accumulated_eval_time': 769.7359969615936, 'accumulated_logging_time': 50.194902181625366}
I0420 06:24:11.533421 140541178140416 logging_writer.py:48] [28000] accumulated_eval_time=769.735997, accumulated_logging_time=50.194902, accumulated_submission_time=11658.425700, global_step=28000, preemption_count=0, score=11658.425700, test/accuracy=0.507000, test/loss=2.264331, test/num_examples=10000, total_duration=12478.949511, train/accuracy=0.685645, train/loss=1.350318, validation/accuracy=0.626680, validation/loss=1.617978, validation/num_examples=50000
I0420 06:24:11.854903 140719775172416 checkpoints.py:356] Saving checkpoint at step: 28000
I0420 06:24:13.119260 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_28000
I0420 06:24:13.147317 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_28000.
I0420 06:24:13.181930 140541169747712 logging_writer.py:48] [28000] global_step=28000, preemption_count=0, score=11658.425700
I0420 06:24:13.490121 140719775172416 checkpoints.py:356] Saving checkpoint at step: 28000
I0420 06:24:14.616705 140719775172416 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_28000
I0420 06:24:14.638502 140719775172416 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nadamw/imagenet_vit_jax/trial_1/checkpoint_28000.
I0420 06:24:15.645085 140719775172416 submission_runner.py:567] Tuning trial 1/1
I0420 06:24:15.646265 140719775172416 submission_runner.py:568] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.045677535963609565, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0420 06:24:15.650866 140719775172416 submission_runner.py:569] Metrics: {'eval_results': [(1, {'train/accuracy': 0.001054687425494194, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 52.61946654319763, 'total_duration': 102.50843691825867, 'accumulated_submission_time': 52.61946654319763, 'accumulated_eval_time': 49.88882231712341, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (998, {'train/accuracy': 0.034003905951976776, 'train/loss': 5.9408135414123535, 'validation/accuracy': 0.03240000084042549, 'validation/loss': 5.971524238586426, 'validation/num_examples': 50000, 'test/accuracy': 0.025600001215934753, 'test/loss': 6.076261520385742, 'test/num_examples': 10000, 'score': 472.94655442237854, 'total_duration': 543.0423657894135, 'accumulated_submission_time': 472.94655442237854, 'accumulated_eval_time': 69.27781105041504, 'accumulated_logging_time': 0.7944607734680176, 'global_step': 998, 'preemption_count': 0}), (2038, {'train/accuracy': 0.07462890446186066, 'train/loss': 5.287240505218506, 'validation/accuracy': 0.07245999574661255, 'validation/loss': 5.317380905151367, 'validation/num_examples': 50000, 'test/accuracy': 0.05690000206232071, 'test/loss': 5.516536235809326, 'test/num_examples': 10000, 'score': 893.2589406967163, 'total_duration': 985.1807990074158, 'accumulated_submission_time': 893.2589406967163, 'accumulated_eval_time': 88.46999216079712, 'accumulated_logging_time': 3.4042108058929443, 'global_step': 2038, 'preemption_count': 0}), (3078, {'train/accuracy': 0.14386717975139618, 'train/loss': 4.635059356689453, 'validation/accuracy': 0.13346000015735626, 'validation/loss': 4.697714805603027, 'validation/num_examples': 50000, 'test/accuracy': 0.10290000587701797, 'test/loss': 4.998244285583496, 'test/num_examples': 10000, 'score': 1313.5718960762024, 'total_duration': 1428.9771900177002, 'accumulated_submission_time': 1313.5718960762024, 'accumulated_eval_time': 108.53130793571472, 'accumulated_logging_time': 6.802292823791504, 'global_step': 3078, 'preemption_count': 0}), (4116, {'train/accuracy': 0.2066992074251175, 'train/loss': 4.170814037322998, 'validation/accuracy': 0.18789999186992645, 'validation/loss': 4.295699596405029, 'validation/num_examples': 50000, 'test/accuracy': 0.14030000567436218, 'test/loss': 4.65855598449707, 'test/num_examples': 10000, 'score': 1733.924048423767, 'total_duration': 1872.3911664485931, 'accumulated_submission_time': 1733.924048423767, 'accumulated_eval_time': 128.91447472572327, 'accumulated_logging_time': 9.456857681274414, 'global_step': 4116, 'preemption_count': 0}), (5152, {'train/accuracy': 0.24861328303813934, 'train/loss': 3.7793493270874023, 'validation/accuracy': 0.23307999968528748, 'validation/loss': 3.8655173778533936, 'validation/num_examples': 50000, 'test/accuracy': 0.1746000051498413, 'test/loss': 4.301485061645508, 'test/num_examples': 10000, 'score': 2154.2451586723328, 'total_duration': 2316.86106300354, 'accumulated_submission_time': 2154.2451586723328, 'accumulated_eval_time': 150.71208214759827, 'accumulated_logging_time': 11.783991813659668, 'global_step': 5152, 'preemption_count': 0}), (6187, {'train/accuracy': 0.30882811546325684, 'train/loss': 3.3946287631988525, 'validation/accuracy': 0.2844800055027008, 'validation/loss': 3.538059949874878, 'validation/num_examples': 50000, 'test/accuracy': 0.2199000120162964, 'test/loss': 4.01646089553833, 'test/num_examples': 10000, 'score': 2574.4878108501434, 'total_duration': 2762.263241291046, 'accumulated_submission_time': 2574.4878108501434, 'accumulated_eval_time': 174.47902750968933, 'accumulated_logging_time': 13.152902364730835, 'global_step': 6187, 'preemption_count': 0}), (7221, {'train/accuracy': 0.35566404461860657, 'train/loss': 3.1111443042755127, 'validation/accuracy': 0.3284599781036377, 'validation/loss': 3.259812831878662, 'validation/num_examples': 50000, 'test/accuracy': 0.24960000813007355, 'test/loss': 3.777083396911621, 'test/num_examples': 10000, 'score': 2994.7988045215607, 'total_duration': 3209.0967061519623, 'accumulated_submission_time': 2994.7988045215607, 'accumulated_eval_time': 199.62368440628052, 'accumulated_logging_time': 14.508310079574585, 'global_step': 7221, 'preemption_count': 0}), (8255, {'train/accuracy': 0.40166014432907104, 'train/loss': 2.8314285278320312, 'validation/accuracy': 0.3667199909687042, 'validation/loss': 2.9927611351013184, 'validation/num_examples': 50000, 'test/accuracy': 0.28280001878738403, 'test/loss': 3.5496041774749756, 'test/num_examples': 10000, 'score': 3415.093871831894, 'total_duration': 3657.3560252189636, 'accumulated_submission_time': 3415.093871831894, 'accumulated_eval_time': 226.08865237236023, 'accumulated_logging_time': 15.985587358474731, 'global_step': 8255, 'preemption_count': 0}), (9286, {'train/accuracy': 0.4475195109844208, 'train/loss': 2.5673539638519287, 'validation/accuracy': 0.3967199921607971, 'validation/loss': 2.837702512741089, 'validation/num_examples': 50000, 'test/accuracy': 0.30730000138282776, 'test/loss': 3.408738374710083, 'test/num_examples': 10000, 'score': 3835.1536943912506, 'total_duration': 4106.47126865387, 'accumulated_submission_time': 3835.1536943912506, 'accumulated_eval_time': 253.61173748970032, 'accumulated_logging_time': 17.495925903320312, 'global_step': 9286, 'preemption_count': 0}), (10313, {'train/accuracy': 0.46044921875, 'train/loss': 2.5133142471313477, 'validation/accuracy': 0.42805999517440796, 'validation/loss': 2.6601457595825195, 'validation/num_examples': 50000, 'test/accuracy': 0.33160001039505005, 'test/loss': 3.261354923248291, 'test/num_examples': 10000, 'score': 4255.246996641159, 'total_duration': 4555.733868122101, 'accumulated_submission_time': 4255.246996641159, 'accumulated_eval_time': 281.1227159500122, 'accumulated_logging_time': 19.13232159614563, 'global_step': 10313, 'preemption_count': 0}), (11341, {'train/accuracy': 0.48945310711860657, 'train/loss': 2.373080015182495, 'validation/accuracy': 0.4531799852848053, 'validation/loss': 2.5568807125091553, 'validation/num_examples': 50000, 'test/accuracy': 0.357200026512146, 'test/loss': 3.141570568084717, 'test/num_examples': 10000, 'score': 4675.56228017807, 'total_duration': 5004.179877996445, 'accumulated_submission_time': 4675.56228017807, 'accumulated_eval_time': 307.6916718482971, 'accumulated_logging_time': 20.672757625579834, 'global_step': 11341, 'preemption_count': 0}), (12361, {'train/accuracy': 0.5169140696525574, 'train/loss': 2.220503807067871, 'validation/accuracy': 0.47901999950408936, 'validation/loss': 2.409569501876831, 'validation/num_examples': 50000, 'test/accuracy': 0.36730000376701355, 'test/loss': 3.042520523071289, 'test/num_examples': 10000, 'score': 5095.879371166229, 'total_duration': 5453.45840716362, 'accumulated_submission_time': 5095.879371166229, 'accumulated_eval_time': 334.989666223526, 'accumulated_logging_time': 22.315101385116577, 'global_step': 12361, 'preemption_count': 0}), (13380, {'train/accuracy': 0.5477148294448853, 'train/loss': 2.0735554695129395, 'validation/accuracy': 0.49747997522354126, 'validation/loss': 2.325396776199341, 'validation/num_examples': 50000, 'test/accuracy': 0.3863000273704529, 'test/loss': 2.93672513961792, 'test/num_examples': 10000, 'score': 5515.931526660919, 'total_duration': 5902.5546498298645, 'accumulated_submission_time': 5515.931526660919, 'accumulated_eval_time': 362.33769273757935, 'accumulated_logging_time': 23.989985942840576, 'global_step': 13380, 'preemption_count': 0}), (14382, {'train/accuracy': 0.5437304377555847, 'train/loss': 2.1423070430755615, 'validation/accuracy': 0.5023399591445923, 'validation/loss': 2.327653408050537, 'validation/num_examples': 50000, 'test/accuracy': 0.3939000070095062, 'test/loss': 2.934194564819336, 'test/num_examples': 10000, 'score': 5936.002881526947, 'total_duration': 6351.610885620117, 'accumulated_submission_time': 5936.002881526947, 'accumulated_eval_time': 389.5625615119934, 'accumulated_logging_time': 25.729616403579712, 'global_step': 14382, 'preemption_count': 0}), (15387, {'train/accuracy': 0.5631445050239563, 'train/loss': 1.9786957502365112, 'validation/accuracy': 0.5228599905967712, 'validation/loss': 2.1692867279052734, 'validation/num_examples': 50000, 'test/accuracy': 0.4091000258922577, 'test/loss': 2.8128459453582764, 'test/num_examples': 10000, 'score': 6356.244428634644, 'total_duration': 6801.120886325836, 'accumulated_submission_time': 6356.244428634644, 'accumulated_eval_time': 417.2724778652191, 'accumulated_logging_time': 27.26752543449402, 'global_step': 15387, 'preemption_count': 0}), (16394, {'train/accuracy': 0.5840234160423279, 'train/loss': 1.8566808700561523, 'validation/accuracy': 0.5412999987602234, 'validation/loss': 2.0552399158477783, 'validation/num_examples': 50000, 'test/accuracy': 0.4212000072002411, 'test/loss': 2.701127529144287, 'test/num_examples': 10000, 'score': 6776.636913537979, 'total_duration': 7250.898334741592, 'accumulated_submission_time': 6776.636913537979, 'accumulated_eval_time': 445.1116576194763, 'accumulated_logging_time': 28.79277801513672, 'global_step': 16394, 'preemption_count': 0}), (17402, {'train/accuracy': 0.602343738079071, 'train/loss': 1.8499764204025269, 'validation/accuracy': 0.551539957523346, 'validation/loss': 2.088876962661743, 'validation/num_examples': 50000, 'test/accuracy': 0.43320003151893616, 'test/loss': 2.72625470161438, 'test/num_examples': 10000, 'score': 7196.712497472763, 'total_duration': 7701.118371248245, 'accumulated_submission_time': 7196.712497472763, 'accumulated_eval_time': 473.6608581542969, 'accumulated_logging_time': 30.367119312286377, 'global_step': 17402, 'preemption_count': 0}), (18404, {'train/accuracy': 0.6024999618530273, 'train/loss': 1.8264795541763306, 'validation/accuracy': 0.5568999648094177, 'validation/loss': 2.035423517227173, 'validation/num_examples': 50000, 'test/accuracy': 0.43400001525878906, 'test/loss': 2.672787666320801, 'test/num_examples': 10000, 'score': 7616.920893907547, 'total_duration': 8151.404447793961, 'accumulated_submission_time': 7616.920893907547, 'accumulated_eval_time': 502.01537442207336, 'accumulated_logging_time': 32.069884061813354, 'global_step': 18404, 'preemption_count': 0}), (19406, {'train/accuracy': 0.61669921875, 'train/loss': 1.72581148147583, 'validation/accuracy': 0.573199987411499, 'validation/loss': 1.9379098415374756, 'validation/num_examples': 50000, 'test/accuracy': 0.450300008058548, 'test/loss': 2.5780045986175537, 'test/num_examples': 10000, 'score': 8037.250782012939, 'total_duration': 8601.665384292603, 'accumulated_submission_time': 8037.250782012939, 'accumulated_eval_time': 530.2211480140686, 'accumulated_logging_time': 33.77423930168152, 'global_step': 19406, 'preemption_count': 0}), (20414, {'train/accuracy': 0.6299999952316284, 'train/loss': 1.6961746215820312, 'validation/accuracy': 0.5757200121879578, 'validation/loss': 1.931368350982666, 'validation/num_examples': 50000, 'test/accuracy': 0.45980003476142883, 'test/loss': 2.568157434463501, 'test/num_examples': 10000, 'score': 8457.319392442703, 'total_duration': 9052.187388181686, 'accumulated_submission_time': 8457.319392442703, 'accumulated_eval_time': 558.8494715690613, 'accumulated_logging_time': 35.57838320732117, 'global_step': 20414, 'preemption_count': 0}), (21412, {'train/accuracy': 0.6368945240974426, 'train/loss': 1.6031042337417603, 'validation/accuracy': 0.5841799974441528, 'validation/loss': 1.853515863418579, 'validation/num_examples': 50000, 'test/accuracy': 0.4603000283241272, 'test/loss': 2.49900221824646, 'test/num_examples': 10000, 'score': 8877.649254322052, 'total_duration': 9502.38774061203, 'accumulated_submission_time': 8877.649254322052, 'accumulated_eval_time': 587.0776479244232, 'accumulated_logging_time': 37.200618267059326, 'global_step': 21412, 'preemption_count': 0}), (22400, {'train/accuracy': 0.6545507907867432, 'train/loss': 1.5771229267120361, 'validation/accuracy': 0.5920599699020386, 'validation/loss': 1.8457199335098267, 'validation/num_examples': 50000, 'test/accuracy': 0.4733000099658966, 'test/loss': 2.483369827270508, 'test/num_examples': 10000, 'score': 9297.645182847977, 'total_duration': 9952.31832575798, 'accumulated_submission_time': 9297.645182847977, 'accumulated_eval_time': 615.3745415210724, 'accumulated_logging_time': 38.818665504455566, 'global_step': 22400, 'preemption_count': 0}), (23378, {'train/accuracy': 0.6487890481948853, 'train/loss': 1.570358395576477, 'validation/accuracy': 0.6013000011444092, 'validation/loss': 1.7876310348510742, 'validation/num_examples': 50000, 'test/accuracy': 0.47780001163482666, 'test/loss': 2.428392171859741, 'test/num_examples': 10000, 'score': 9717.88070654869, 'total_duration': 10402.002984523773, 'accumulated_submission_time': 9717.88070654869, 'accumulated_eval_time': 643.1447505950928, 'accumulated_logging_time': 40.47808837890625, 'global_step': 23378, 'preemption_count': 0}), (24376, {'train/accuracy': 0.6585937142372131, 'train/loss': 1.5336097478866577, 'validation/accuracy': 0.6029999852180481, 'validation/loss': 1.7811565399169922, 'validation/num_examples': 50000, 'test/accuracy': 0.4856000244617462, 'test/loss': 2.4069578647613525, 'test/num_examples': 10000, 'score': 10138.136598110199, 'total_duration': 10850.886875391006, 'accumulated_submission_time': 10138.136598110199, 'accumulated_eval_time': 668.8418624401093, 'accumulated_logging_time': 43.38910245895386, 'global_step': 24376, 'preemption_count': 0}), (25373, {'train/accuracy': 0.6704687476158142, 'train/loss': 1.4809117317199707, 'validation/accuracy': 0.6150599718093872, 'validation/loss': 1.7427363395690918, 'validation/num_examples': 50000, 'test/accuracy': 0.489300012588501, 'test/loss': 2.3795080184936523, 'test/num_examples': 10000, 'score': 10558.392251253128, 'total_duration': 11298.277344465256, 'accumulated_submission_time': 10558.392251253128, 'accumulated_eval_time': 694.2076387405396, 'accumulated_logging_time': 45.138142108917236, 'global_step': 25373, 'preemption_count': 0}), (26377, {'train/accuracy': 0.6854101419448853, 'train/loss': 1.3595638275146484, 'validation/accuracy': 0.6162199974060059, 'validation/loss': 1.6763254404067993, 'validation/num_examples': 50000, 'test/accuracy': 0.49390003085136414, 'test/loss': 2.30999493598938, 'test/num_examples': 10000, 'score': 10978.425423383713, 'total_duration': 11745.121807336807, 'accumulated_submission_time': 10978.425423383713, 'accumulated_eval_time': 719.2379148006439, 'accumulated_logging_time': 46.898720264434814, 'global_step': 26377, 'preemption_count': 0}), (27384, {'train/accuracy': 0.6732421517372131, 'train/loss': 1.436805248260498, 'validation/accuracy': 0.6233999729156494, 'validation/loss': 1.663799524307251, 'validation/num_examples': 50000, 'test/accuracy': 0.4991000294685364, 'test/loss': 2.305880546569824, 'test/num_examples': 10000, 'score': 11398.65911912918, 'total_duration': 12192.197200775146, 'accumulated_submission_time': 11398.65911912918, 'accumulated_eval_time': 744.4042100906372, 'accumulated_logging_time': 48.553497314453125, 'global_step': 27384, 'preemption_count': 0}), (28000, {'train/accuracy': 0.6856445074081421, 'train/loss': 1.3503183126449585, 'validation/accuracy': 0.6266799569129944, 'validation/loss': 1.6179777383804321, 'validation/num_examples': 50000, 'test/accuracy': 0.5070000290870667, 'test/loss': 2.264331102371216, 'test/num_examples': 10000, 'score': 11658.425700187683, 'total_duration': 12478.949511289597, 'accumulated_submission_time': 11658.425700187683, 'accumulated_eval_time': 769.7359969615936, 'accumulated_logging_time': 50.194902181625366, 'global_step': 28000, 'preemption_count': 0})], 'global_step': 28000}
I0420 06:24:15.650998 140719775172416 submission_runner.py:570] Timing: 11658.425700187683
I0420 06:24:15.651043 140719775172416 submission_runner.py:571] ====================
I0420 06:24:15.651155 140719775172416 submission_runner.py:631] Final imagenet_vit score: 11658.425700187683
