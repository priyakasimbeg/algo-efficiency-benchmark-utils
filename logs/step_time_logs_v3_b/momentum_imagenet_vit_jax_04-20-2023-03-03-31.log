I0420 03:03:53.728677 140094836827968 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax.
I0420 03:03:53.790683 140094836827968 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0420 03:03:54.672251 140094836827968 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0420 03:03:54.673141 140094836827968 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0420 03:03:54.678128 140094836827968 submission_runner.py:528] Using RNG seed 952799493
I0420 03:03:57.453024 140094836827968 submission_runner.py:537] --- Tuning run 1/1 ---
I0420 03:03:57.453256 140094836827968 submission_runner.py:542] Creating tuning directory at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1.
I0420 03:03:57.453490 140094836827968 logger_utils.py:83] Saving hparams to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/hparams.json.
I0420 03:03:57.573498 140094836827968 submission_runner.py:232] Initializing dataset.
I0420 03:03:57.585665 140094836827968 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0420 03:03:57.593528 140094836827968 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0420 03:03:57.593658 140094836827968 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0420 03:03:57.869252 140094836827968 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0420 03:04:04.520683 140094836827968 submission_runner.py:239] Initializing model.
I0420 03:04:15.248795 140094836827968 submission_runner.py:249] Initializing optimizer.
I0420 03:04:15.729058 140094836827968 submission_runner.py:256] Initializing metrics bundle.
I0420 03:04:15.729247 140094836827968 submission_runner.py:273] Initializing checkpoint and logger.
I0420 03:04:15.730116 140094836827968 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1 with prefix checkpoint_
I0420 03:04:16.471572 140094836827968 submission_runner.py:294] Saving meta data to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/meta_data_0.json.
I0420 03:04:16.472603 140094836827968 submission_runner.py:297] Saving flags to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/flags_0.json.
I0420 03:04:16.477330 140094836827968 submission_runner.py:309] Starting training loop.
I0420 03:05:03.246457 139917954889472 logging_writer.py:48] [0] global_step=0, grad_norm=0.2983264625072479, loss=6.9077534675598145
I0420 03:05:03.258617 140094836827968 spec.py:298] Evaluating on the training split.
I0420 03:05:03.264382 140094836827968 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0420 03:05:03.270256 140094836827968 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0420 03:05:03.270381 140094836827968 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0420 03:05:03.330128 140094836827968 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0420 03:05:24.201621 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 03:05:24.210602 140094836827968 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0420 03:05:24.227142 140094836827968 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0420 03:05:24.227552 140094836827968 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0420 03:05:24.291970 140094836827968 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0420 03:05:42.768751 140094836827968 spec.py:326] Evaluating on the test split.
I0420 03:05:42.775537 140094836827968 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0420 03:05:42.779977 140094836827968 dataset_builder.py:510] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0420 03:05:42.814725 140094836827968 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0420 03:05:53.658564 140094836827968 submission_runner.py:406] Time since start: 97.18s, 	Step: 1, 	{'train/accuracy': 0.0009179687476716936, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 46.78114318847656, 'total_duration': 97.18116211891174, 'accumulated_submission_time': 46.78114318847656, 'accumulated_eval_time': 50.399887561798096, 'accumulated_logging_time': 0}
I0420 03:05:53.675118 139852641195776 logging_writer.py:48] [1] accumulated_eval_time=50.399888, accumulated_logging_time=0, accumulated_submission_time=46.781143, global_step=1, preemption_count=0, score=46.781143, test/accuracy=0.001000, test/loss=6.907757, test/num_examples=10000, total_duration=97.181162, train/accuracy=0.000918, train/loss=6.907756, validation/accuracy=0.001000, validation/loss=6.907756, validation/num_examples=50000
I0420 03:05:53.795098 140094836827968 checkpoints.py:356] Saving checkpoint at step: 1
I0420 03:05:54.139091 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_1
I0420 03:05:54.139884 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_1.
I0420 03:06:45.994026 139917208282880 logging_writer.py:48] [100] global_step=100, grad_norm=0.27537792921066284, loss=6.906202793121338
I0420 03:07:25.177043 139917216675584 logging_writer.py:48] [200] global_step=200, grad_norm=0.27316218614578247, loss=6.900252819061279
I0420 03:08:04.475805 139917208282880 logging_writer.py:48] [300] global_step=300, grad_norm=0.3132714629173279, loss=6.874277114868164
I0420 03:08:45.344545 139917216675584 logging_writer.py:48] [400] global_step=400, grad_norm=0.4562930166721344, loss=6.838042736053467
I0420 03:09:26.400101 139917208282880 logging_writer.py:48] [500] global_step=500, grad_norm=1.1121704578399658, loss=6.791650295257568
I0420 03:10:07.368072 139917216675584 logging_writer.py:48] [600] global_step=600, grad_norm=0.8003108501434326, loss=6.708083629608154
I0420 03:10:48.494501 139917208282880 logging_writer.py:48] [700] global_step=700, grad_norm=0.6700130105018616, loss=6.803196430206299
I0420 03:11:29.468458 139917216675584 logging_writer.py:48] [800] global_step=800, grad_norm=0.8297554850578308, loss=6.614492416381836
I0420 03:12:10.689682 139917208282880 logging_writer.py:48] [900] global_step=900, grad_norm=1.0219871997833252, loss=6.623969078063965
I0420 03:12:52.152657 139917216675584 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.8623178601264954, loss=6.551379680633545
I0420 03:12:54.332913 140094836827968 spec.py:298] Evaluating on the training split.
I0420 03:13:05.260361 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 03:13:11.747290 140094836827968 spec.py:326] Evaluating on the test split.
I0420 03:13:13.710663 140094836827968 submission_runner.py:406] Time since start: 537.23s, 	Step: 1007, 	{'train/accuracy': 0.028535155579447746, 'train/loss': 6.192429542541504, 'validation/accuracy': 0.026920000091195107, 'validation/loss': 6.218790054321289, 'validation/num_examples': 50000, 'test/accuracy': 0.022200001403689384, 'test/loss': 6.311334609985352, 'test/num_examples': 10000, 'score': 466.95301580429077, 'total_duration': 537.2331731319427, 'accumulated_submission_time': 466.95301580429077, 'accumulated_eval_time': 69.77760243415833, 'accumulated_logging_time': 0.48229146003723145}
I0420 03:13:13.735625 139854134376192 logging_writer.py:48] [1007] accumulated_eval_time=69.777602, accumulated_logging_time=0.482291, accumulated_submission_time=466.953016, global_step=1007, preemption_count=0, score=466.953016, test/accuracy=0.022200, test/loss=6.311335, test/num_examples=10000, total_duration=537.233173, train/accuracy=0.028535, train/loss=6.192430, validation/accuracy=0.026920, validation/loss=6.218790, validation/num_examples=50000
I0420 03:13:15.337348 140094836827968 checkpoints.py:356] Saving checkpoint at step: 1007
I0420 03:13:16.202057 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_1007
I0420 03:13:16.203793 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_1007.
I0420 03:13:53.082422 139854218237696 logging_writer.py:48] [1100] global_step=1100, grad_norm=1.0155493021011353, loss=6.516530513763428
I0420 03:14:32.376366 139917267031808 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.7194779515266418, loss=6.4683403968811035
I0420 03:15:13.413150 139854218237696 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.778249979019165, loss=6.472830295562744
I0420 03:15:54.376889 139917267031808 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.9908841848373413, loss=6.437332630157471
I0420 03:16:35.392788 139854218237696 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.6774728894233704, loss=6.689985752105713
I0420 03:17:16.207248 139917267031808 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.8748626112937927, loss=6.409207820892334
I0420 03:17:57.098685 139854218237696 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.7765458226203918, loss=6.4320969581604
I0420 03:18:37.639714 139917267031808 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.7841259241104126, loss=6.350106239318848
I0420 03:19:18.708531 139854218237696 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.7680212259292603, loss=6.335366249084473
I0420 03:19:59.763856 139917267031808 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.7798298597335815, loss=6.291128158569336
I0420 03:20:16.700660 140094836827968 spec.py:298] Evaluating on the training split.
I0420 03:20:27.517030 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 03:20:34.106903 140094836827968 spec.py:326] Evaluating on the test split.
I0420 03:20:35.853446 140094836827968 submission_runner.py:406] Time since start: 979.38s, 	Step: 2043, 	{'train/accuracy': 0.057207029312849045, 'train/loss': 5.71145486831665, 'validation/accuracy': 0.05384000018239021, 'validation/loss': 5.752144813537598, 'validation/num_examples': 50000, 'test/accuracy': 0.04010000079870224, 'test/loss': 5.913881778717041, 'test/num_examples': 10000, 'score': 887.4281833171844, 'total_duration': 979.376002073288, 'accumulated_submission_time': 887.4281833171844, 'accumulated_eval_time': 88.93034267425537, 'accumulated_logging_time': 2.976855516433716}
I0420 03:20:35.873933 139854218237696 logging_writer.py:48] [2043] accumulated_eval_time=88.930343, accumulated_logging_time=2.976856, accumulated_submission_time=887.428183, global_step=2043, preemption_count=0, score=887.428183, test/accuracy=0.040100, test/loss=5.913882, test/num_examples=10000, total_duration=979.376002, train/accuracy=0.057207, train/loss=5.711455, validation/accuracy=0.053840, validation/loss=5.752145, validation/num_examples=50000
I0420 03:20:35.977222 140094836827968 checkpoints.py:356] Saving checkpoint at step: 2043
I0420 03:20:38.739634 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_2043
I0420 03:20:38.749603 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_2043.
I0420 03:21:01.515291 139917267031808 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.5975415110588074, loss=6.704127311706543
I0420 03:21:40.742438 139917233460992 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.8717604279518127, loss=6.314528465270996
I0420 03:22:20.761572 139917267031808 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.7017560601234436, loss=6.222629547119141
I0420 03:23:01.671418 139917233460992 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.8064543604850769, loss=6.169629096984863
I0420 03:23:42.316105 139917267031808 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.716353714466095, loss=6.312870979309082
I0420 03:24:23.383741 139917233460992 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.673442006111145, loss=6.238707542419434
I0420 03:25:04.389147 139917267031808 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.6744393110275269, loss=6.212403774261475
I0420 03:25:45.251851 139917233460992 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.7291190028190613, loss=6.285730838775635
I0420 03:26:26.360451 139917267031808 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.7158127427101135, loss=6.172370910644531
I0420 03:27:07.106704 139917233460992 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.662448525428772, loss=6.704587459564209
I0420 03:27:38.788983 140094836827968 spec.py:298] Evaluating on the training split.
I0420 03:27:49.806471 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 03:27:56.646619 140094836827968 spec.py:326] Evaluating on the test split.
I0420 03:27:58.367507 140094836827968 submission_runner.py:406] Time since start: 1421.89s, 	Step: 3079, 	{'train/accuracy': 0.08738280832767487, 'train/loss': 5.327775001525879, 'validation/accuracy': 0.08033999800682068, 'validation/loss': 5.377453804016113, 'validation/num_examples': 50000, 'test/accuracy': 0.05920000374317169, 'test/loss': 5.599483013153076, 'test/num_examples': 10000, 'score': 1307.446447610855, 'total_duration': 1421.8900785446167, 'accumulated_submission_time': 1307.446447610855, 'accumulated_eval_time': 108.50885581970215, 'accumulated_logging_time': 5.874029636383057}
I0420 03:27:58.379328 139917267031808 logging_writer.py:48] [3079] accumulated_eval_time=108.508856, accumulated_logging_time=5.874030, accumulated_submission_time=1307.446448, global_step=3079, preemption_count=0, score=1307.446448, test/accuracy=0.059200, test/loss=5.599483, test/num_examples=10000, total_duration=1421.890079, train/accuracy=0.087383, train/loss=5.327775, validation/accuracy=0.080340, validation/loss=5.377454, validation/num_examples=50000
I0420 03:27:58.905090 140094836827968 checkpoints.py:356] Saving checkpoint at step: 3079
I0420 03:28:01.271399 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_3079
I0420 03:28:01.283509 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_3079.
I0420 03:28:10.009574 139917233460992 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.5732532143592834, loss=6.405844211578369
I0420 03:28:49.164320 139916067464960 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.6550589799880981, loss=6.223924160003662
I0420 03:29:29.230701 139917233460992 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.6153595447540283, loss=6.145921230316162
I0420 03:30:10.439164 139916067464960 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.6512225270271301, loss=6.335270881652832
I0420 03:30:51.539087 139917233460992 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.6230144500732422, loss=6.12477445602417
I0420 03:31:32.741826 139916067464960 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.6501842141151428, loss=6.019778251647949
I0420 03:32:14.026781 139917233460992 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.6411347985267639, loss=6.150443077087402
I0420 03:32:55.373193 139916067464960 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.5923089385032654, loss=6.0695366859436035
I0420 03:33:36.318711 139917233460992 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.5968793630599976, loss=5.996000289916992
I0420 03:34:17.391477 139916067464960 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.6509367227554321, loss=6.030472278594971
I0420 03:34:58.399600 139917233460992 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.503119945526123, loss=6.419785499572754
I0420 03:35:01.368425 140094836827968 spec.py:298] Evaluating on the training split.
I0420 03:35:12.415407 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 03:35:19.410155 140094836827968 spec.py:326] Evaluating on the test split.
I0420 03:35:21.109286 140094836827968 submission_runner.py:406] Time since start: 1864.63s, 	Step: 4109, 	{'train/accuracy': 0.10595703125, 'train/loss': 5.055850505828857, 'validation/accuracy': 0.09685999900102615, 'validation/loss': 5.135804653167725, 'validation/num_examples': 50000, 'test/accuracy': 0.07690000534057617, 'test/loss': 5.394585132598877, 'test/num_examples': 10000, 'score': 1727.5094561576843, 'total_duration': 1864.631887435913, 'accumulated_submission_time': 1727.5094561576843, 'accumulated_eval_time': 128.2497136592865, 'accumulated_logging_time': 8.79192590713501}
I0420 03:35:21.120405 139916067464960 logging_writer.py:48] [4109] accumulated_eval_time=128.249714, accumulated_logging_time=8.791926, accumulated_submission_time=1727.509456, global_step=4109, preemption_count=0, score=1727.509456, test/accuracy=0.076900, test/loss=5.394585, test/num_examples=10000, total_duration=1864.631887, train/accuracy=0.105957, train/loss=5.055851, validation/accuracy=0.096860, validation/loss=5.135805, validation/num_examples=50000
I0420 03:35:21.232762 140094836827968 checkpoints.py:356] Saving checkpoint at step: 4109
I0420 03:35:24.209810 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_4109
I0420 03:35:24.222569 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_4109.
I0420 03:36:00.420472 139917233460992 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.6559362411499023, loss=6.015972137451172
I0420 03:36:39.883717 139916059072256 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.6339887976646423, loss=5.952727317810059
I0420 03:37:20.954772 139917233460992 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.5858868956565857, loss=6.029469013214111
I0420 03:38:02.011203 139916059072256 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.6520174145698547, loss=6.0096964836120605
I0420 03:38:43.190547 139917233460992 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.6640447974205017, loss=5.912359237670898
I0420 03:39:24.234080 139916059072256 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.6198269128799438, loss=5.9440999031066895
I0420 03:40:05.517292 139917233460992 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.5935090184211731, loss=6.0467610359191895
I0420 03:40:46.253184 139916059072256 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.5396619439125061, loss=6.629683971405029
I0420 03:41:27.655463 139917233460992 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.7074219584465027, loss=6.015712738037109
I0420 03:42:08.975687 139916059072256 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.6645125150680542, loss=5.922118186950684
I0420 03:42:24.348469 140094836827968 spec.py:298] Evaluating on the training split.
I0420 03:42:35.338033 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 03:42:42.435001 140094836827968 spec.py:326] Evaluating on the test split.
I0420 03:42:44.158946 140094836827968 submission_runner.py:406] Time since start: 2307.68s, 	Step: 5139, 	{'train/accuracy': 0.13242186605930328, 'train/loss': 4.8840227127075195, 'validation/accuracy': 0.12373999506235123, 'validation/loss': 4.9516072273254395, 'validation/num_examples': 50000, 'test/accuracy': 0.09260000288486481, 'test/loss': 5.232926845550537, 'test/num_examples': 10000, 'score': 2147.612490415573, 'total_duration': 2307.6815207004547, 'accumulated_submission_time': 2147.612490415573, 'accumulated_eval_time': 148.06018733978271, 'accumulated_logging_time': 11.907721519470215}
I0420 03:42:44.171485 139917233460992 logging_writer.py:48] [5139] accumulated_eval_time=148.060187, accumulated_logging_time=11.907722, accumulated_submission_time=2147.612490, global_step=5139, preemption_count=0, score=2147.612490, test/accuracy=0.092600, test/loss=5.232927, test/num_examples=10000, total_duration=2307.681521, train/accuracy=0.132422, train/loss=4.884023, validation/accuracy=0.123740, validation/loss=4.951607, validation/num_examples=50000
I0420 03:42:44.282166 140094836827968 checkpoints.py:356] Saving checkpoint at step: 5139
I0420 03:42:46.660179 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_5139
I0420 03:42:46.669682 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_5139.
I0420 03:43:11.008446 139916059072256 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.5793530344963074, loss=6.654788494110107
I0420 03:43:50.539618 139915505432320 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.507570743560791, loss=6.172021865844727
I0420 03:44:31.432555 139916059072256 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.5581151247024536, loss=5.803071975708008
I0420 03:45:12.295893 139915505432320 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.5845705270767212, loss=5.782166004180908
I0420 03:45:53.106860 139916059072256 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.5318655371665955, loss=6.5370965003967285
I0420 03:46:34.016952 139915505432320 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.5252276062965393, loss=5.766416549682617
I0420 03:47:14.878662 139916059072256 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.549260139465332, loss=5.894632339477539
I0420 03:47:55.937271 139915505432320 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.4653226435184479, loss=6.630707740783691
I0420 03:48:37.631443 139916059072256 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.6305221319198608, loss=5.738659858703613
I0420 03:49:18.773077 139915505432320 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.589739978313446, loss=5.777565956115723
I0420 03:49:46.840902 140094836827968 spec.py:298] Evaluating on the training split.
I0420 03:49:58.347273 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 03:50:06.750770 140094836827968 spec.py:326] Evaluating on the test split.
I0420 03:50:08.429600 140094836827968 submission_runner.py:406] Time since start: 2751.95s, 	Step: 6170, 	{'train/accuracy': 0.17093749344348907, 'train/loss': 4.554319858551025, 'validation/accuracy': 0.15765999257564545, 'validation/loss': 4.644810676574707, 'validation/num_examples': 50000, 'test/accuracy': 0.1145000085234642, 'test/loss': 4.976757526397705, 'test/num_examples': 10000, 'score': 2567.7626695632935, 'total_duration': 2751.9521605968475, 'accumulated_submission_time': 2567.7626695632935, 'accumulated_eval_time': 169.64891242980957, 'accumulated_logging_time': 14.419824123382568}
I0420 03:50:08.443323 139916059072256 logging_writer.py:48] [6170] accumulated_eval_time=169.648912, accumulated_logging_time=14.419824, accumulated_submission_time=2567.762670, global_step=6170, preemption_count=0, score=2567.762670, test/accuracy=0.114500, test/loss=4.976758, test/num_examples=10000, total_duration=2751.952161, train/accuracy=0.170937, train/loss=4.554320, validation/accuracy=0.157660, validation/loss=4.644811, validation/num_examples=50000
I0420 03:50:08.795298 140094836827968 checkpoints.py:356] Saving checkpoint at step: 6170
I0420 03:50:10.730419 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_6170
I0420 03:50:10.741651 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_6170.
I0420 03:50:23.041151 139915505432320 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.5594262480735779, loss=5.854727745056152
I0420 03:51:02.318681 139915497039616 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.7082433104515076, loss=5.715559482574463
I0420 03:51:42.976581 139915505432320 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.6014522910118103, loss=5.807288646697998
I0420 03:52:24.140806 139915497039616 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.5092383027076721, loss=6.182491779327393
I0420 03:53:05.211353 139915505432320 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.49544936418533325, loss=6.595677852630615
I0420 03:53:46.278875 139915497039616 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.6140161156654358, loss=5.916971683502197
I0420 03:54:27.407435 139915505432320 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.4626571536064148, loss=6.3525285720825195
I0420 03:55:08.739206 139915497039616 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.6711443066596985, loss=5.619006156921387
I0420 03:55:50.542270 139915505432320 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.5303938984870911, loss=5.772460460662842
I0420 03:56:31.601882 139915497039616 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.4497091770172119, loss=6.1826491355896
I0420 03:57:10.937990 140094836827968 spec.py:298] Evaluating on the training split.
I0420 03:57:23.275640 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 03:57:32.572666 140094836827968 spec.py:326] Evaluating on the test split.
I0420 03:57:34.241207 140094836827968 submission_runner.py:406] Time since start: 3197.76s, 	Step: 7197, 	{'train/accuracy': 0.19384765625, 'train/loss': 4.4271674156188965, 'validation/accuracy': 0.17853999137878418, 'validation/loss': 4.522009372711182, 'validation/num_examples': 50000, 'test/accuracy': 0.14030000567436218, 'test/loss': 4.860133171081543, 'test/num_examples': 10000, 'score': 2987.937479019165, 'total_duration': 3197.763764858246, 'accumulated_submission_time': 2987.937479019165, 'accumulated_eval_time': 192.95207858085632, 'accumulated_logging_time': 16.733586311340332}
I0420 03:57:34.254039 139915505432320 logging_writer.py:48] [7197] accumulated_eval_time=192.952079, accumulated_logging_time=16.733586, accumulated_submission_time=2987.937479, global_step=7197, preemption_count=0, score=2987.937479, test/accuracy=0.140300, test/loss=4.860133, test/num_examples=10000, total_duration=3197.763765, train/accuracy=0.193848, train/loss=4.427167, validation/accuracy=0.178540, validation/loss=4.522009, validation/num_examples=50000
I0420 03:57:34.353257 140094836827968 checkpoints.py:356] Saving checkpoint at step: 7197
I0420 03:57:35.615018 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_7197
I0420 03:57:35.625941 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_7197.
I0420 03:57:37.239786 139915497039616 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.4110836684703827, loss=6.479955673217773
I0420 03:58:16.724146 139915488646912 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.5881498456001282, loss=5.650068283081055
I0420 03:58:57.687643 139915497039616 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.5079396963119507, loss=6.571094512939453
I0420 03:59:39.205452 139915488646912 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.5384235978126526, loss=5.567192554473877
I0420 04:00:20.559000 139915497039616 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.788870632648468, loss=5.625002861022949
I0420 04:01:01.424960 139915488646912 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.5277106165885925, loss=5.634084701538086
I0420 04:01:42.599893 139915497039616 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.5392813682556152, loss=5.567089080810547
I0420 04:02:23.302383 139915488646912 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.5368640422821045, loss=5.636019229888916
I0420 04:03:04.254845 139915497039616 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.68443363904953, loss=5.520864486694336
I0420 04:03:45.771052 139915488646912 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.6387031078338623, loss=5.59716796875
I0420 04:04:27.392446 139915497039616 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.5688692927360535, loss=6.480586051940918
I0420 04:04:35.888646 140094836827968 spec.py:298] Evaluating on the training split.
I0420 04:04:51.820068 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 04:05:00.853942 140094836827968 spec.py:326] Evaluating on the test split.
I0420 04:05:02.554311 140094836827968 submission_runner.py:406] Time since start: 3646.08s, 	Step: 8223, 	{'train/accuracy': 0.23136718571186066, 'train/loss': 4.137267589569092, 'validation/accuracy': 0.21213999390602112, 'validation/loss': 4.246388912200928, 'validation/num_examples': 50000, 'test/accuracy': 0.1583000123500824, 'test/loss': 4.63227653503418, 'test/num_examples': 10000, 'score': 3408.1773903369904, 'total_duration': 3646.076869249344, 'accumulated_submission_time': 3408.1773903369904, 'accumulated_eval_time': 219.61770153045654, 'accumulated_logging_time': 18.120813608169556}
I0420 04:05:02.567432 139915488646912 logging_writer.py:48] [8223] accumulated_eval_time=219.617702, accumulated_logging_time=18.120814, accumulated_submission_time=3408.177390, global_step=8223, preemption_count=0, score=3408.177390, test/accuracy=0.158300, test/loss=4.632277, test/num_examples=10000, total_duration=3646.076869, train/accuracy=0.231367, train/loss=4.137268, validation/accuracy=0.212140, validation/loss=4.246389, validation/num_examples=50000
I0420 04:05:02.666666 140094836827968 checkpoints.py:356] Saving checkpoint at step: 8223
I0420 04:05:04.273664 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_8223
I0420 04:05:04.286481 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_8223.
I0420 04:05:35.032476 139915497039616 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.46686801314353943, loss=5.775786876678467
I0420 04:06:16.030544 139913257285376 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.5275135040283203, loss=5.639714241027832
I0420 04:06:57.511644 139915497039616 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.5707806944847107, loss=5.35498046875
I0420 04:07:38.493220 139913257285376 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.6476992964744568, loss=5.556519985198975
I0420 04:08:19.453404 139915497039616 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.60210120677948, loss=5.391656398773193
I0420 04:09:00.966291 139913257285376 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.6105736494064331, loss=5.378608703613281
I0420 04:09:42.189167 139915497039616 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.5941653251647949, loss=5.492765426635742
I0420 04:10:23.422364 139913257285376 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.5356855988502502, loss=5.382110595703125
I0420 04:11:04.733237 139915497039616 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.6072475910186768, loss=5.318640232086182
I0420 04:11:46.455918 139913257285376 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.5334336161613464, loss=5.364157199859619
I0420 04:12:04.626921 140094836827968 spec.py:298] Evaluating on the training split.
I0420 04:12:18.333972 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 04:12:28.239111 140094836827968 spec.py:326] Evaluating on the test split.
I0420 04:12:29.910531 140094836827968 submission_runner.py:406] Time since start: 4093.43s, 	Step: 9246, 	{'train/accuracy': 0.26513671875, 'train/loss': 3.8392834663391113, 'validation/accuracy': 0.23479999601840973, 'validation/loss': 4.026276111602783, 'validation/num_examples': 50000, 'test/accuracy': 0.17430001497268677, 'test/loss': 4.452797889709473, 'test/num_examples': 10000, 'score': 3828.495933532715, 'total_duration': 4093.4331278800964, 'accumulated_submission_time': 3828.495933532715, 'accumulated_eval_time': 244.90129280090332, 'accumulated_logging_time': 19.855334281921387}
I0420 04:12:29.921817 139915497039616 logging_writer.py:48] [9246] accumulated_eval_time=244.901293, accumulated_logging_time=19.855334, accumulated_submission_time=3828.495934, global_step=9246, preemption_count=0, score=3828.495934, test/accuracy=0.174300, test/loss=4.452798, test/num_examples=10000, total_duration=4093.433128, train/accuracy=0.265137, train/loss=3.839283, validation/accuracy=0.234800, validation/loss=4.026276, validation/num_examples=50000
I0420 04:12:30.021989 140094836827968 checkpoints.py:356] Saving checkpoint at step: 9246
I0420 04:12:30.751334 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_9246
I0420 04:12:30.761528 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_9246.
I0420 04:12:52.498029 139913257285376 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.4169117212295532, loss=6.453380584716797
I0420 04:13:33.073888 139916059072256 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.557951033115387, loss=5.854042053222656
I0420 04:14:14.793850 139913257285376 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.5038302540779114, loss=6.127671718597412
I0420 04:14:55.605947 139916059072256 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.3636820912361145, loss=6.375394821166992
I0420 04:15:36.739153 139913257285376 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.539729654788971, loss=5.4721999168396
I0420 04:16:17.803563 139916059072256 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.5561017394065857, loss=5.41413688659668
I0420 04:16:58.624261 139913257285376 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.5958575010299683, loss=5.396533489227295
I0420 04:17:40.332035 139916059072256 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.6337751746177673, loss=5.370294570922852
I0420 04:18:21.144024 139913257285376 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.5033848285675049, loss=5.749021530151367
I0420 04:19:02.663122 139916059072256 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.5861814022064209, loss=5.450349807739258
I0420 04:19:31.116983 140094836827968 spec.py:298] Evaluating on the training split.
I0420 04:19:44.771675 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 04:19:55.394823 140094836827968 spec.py:326] Evaluating on the test split.
I0420 04:19:57.044916 140094836827968 submission_runner.py:406] Time since start: 4540.57s, 	Step: 10270, 	{'train/accuracy': 0.2894921898841858, 'train/loss': 3.6266701221466064, 'validation/accuracy': 0.2663799822330475, 'validation/loss': 3.748098850250244, 'validation/num_examples': 50000, 'test/accuracy': 0.20410001277923584, 'test/loss': 4.210958957672119, 'test/num_examples': 10000, 'score': 4248.830755472183, 'total_duration': 4540.567483663559, 'accumulated_submission_time': 4248.830755472183, 'accumulated_eval_time': 270.8291711807251, 'accumulated_logging_time': 20.70771312713623}
I0420 04:19:57.060837 139913257285376 logging_writer.py:48] [10270] accumulated_eval_time=270.829171, accumulated_logging_time=20.707713, accumulated_submission_time=4248.830755, global_step=10270, preemption_count=0, score=4248.830755, test/accuracy=0.204100, test/loss=4.210959, test/num_examples=10000, total_duration=4540.567484, train/accuracy=0.289492, train/loss=3.626670, validation/accuracy=0.266380, validation/loss=3.748099, validation/num_examples=50000
I0420 04:19:57.168215 140094836827968 checkpoints.py:356] Saving checkpoint at step: 10270
I0420 04:19:58.014130 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_10270
I0420 04:19:58.025561 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_10270.
I0420 04:20:10.357793 139916059072256 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.604110836982727, loss=5.237827777862549
I0420 04:20:50.558370 139913525720832 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.4553808271884918, loss=6.172420501708984
I0420 04:21:31.837538 139916059072256 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.48895955085754395, loss=5.524486541748047
I0420 04:22:12.599619 139913525720832 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.5249133706092834, loss=5.576119422912598
I0420 04:22:53.585042 139916059072256 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.5463117361068726, loss=5.050400733947754
I0420 04:23:34.796010 139913525720832 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.4599689543247223, loss=6.075960636138916
I0420 04:24:16.038783 139916059072256 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.5585786700248718, loss=5.117504119873047
I0420 04:24:57.381689 139913525720832 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.6122771501541138, loss=5.182028293609619
I0420 04:25:39.110029 139916059072256 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.6162601709365845, loss=5.234511375427246
I0420 04:26:20.793046 139913525720832 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.6152762174606323, loss=5.214828968048096
I0420 04:26:58.320212 140094836827968 spec.py:298] Evaluating on the training split.
I0420 04:27:12.295226 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 04:27:22.363819 140094836827968 spec.py:326] Evaluating on the test split.
I0420 04:27:24.030047 140094836827968 submission_runner.py:406] Time since start: 4987.55s, 	Step: 11293, 	{'train/accuracy': 0.31166014075279236, 'train/loss': 3.5010058879852295, 'validation/accuracy': 0.28591999411582947, 'validation/loss': 3.6350536346435547, 'validation/num_examples': 50000, 'test/accuracy': 0.22040000557899475, 'test/loss': 4.112656593322754, 'test/num_examples': 10000, 'score': 4669.104925632477, 'total_duration': 4987.552630186081, 'accumulated_submission_time': 4669.104925632477, 'accumulated_eval_time': 296.5389955043793, 'accumulated_logging_time': 21.68957543373108}
I0420 04:27:24.041845 139916059072256 logging_writer.py:48] [11293] accumulated_eval_time=296.538996, accumulated_logging_time=21.689575, accumulated_submission_time=4669.104926, global_step=11293, preemption_count=0, score=4669.104926, test/accuracy=0.220400, test/loss=4.112657, test/num_examples=10000, total_duration=4987.552630, train/accuracy=0.311660, train/loss=3.501006, validation/accuracy=0.285920, validation/loss=3.635054, validation/num_examples=50000
I0420 04:27:24.179456 140094836827968 checkpoints.py:356] Saving checkpoint at step: 11293
I0420 04:27:25.546128 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_11293
I0420 04:27:25.565865 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_11293.
I0420 04:27:28.838590 139913525720832 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.4609208106994629, loss=5.8408308029174805
I0420 04:28:08.731768 139913508935424 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.46359169483184814, loss=5.960555553436279
I0420 04:28:49.654542 139913525720832 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.6180039644241333, loss=5.116418838500977
I0420 04:29:30.626468 139913508935424 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.5825769901275635, loss=5.375255107879639
I0420 04:30:11.661675 139913525720832 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.5544807314872742, loss=5.135826110839844
I0420 04:30:52.956373 139913508935424 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.5533648133277893, loss=5.021337985992432
I0420 04:31:34.326038 139913525720832 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.6826928853988647, loss=5.123749732971191
I0420 04:32:15.231278 139913508935424 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.6047207117080688, loss=5.052704811096191
I0420 04:32:57.333954 139913525720832 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.49333491921424866, loss=5.442188262939453
I0420 04:33:39.460086 139913508935424 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.6674634218215942, loss=5.075850486755371
I0420 04:34:21.800150 139913525720832 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.551606297492981, loss=5.043091297149658
I0420 04:34:25.749297 140094836827968 spec.py:298] Evaluating on the training split.
I0420 04:34:39.885149 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 04:34:50.812252 140094836827968 spec.py:326] Evaluating on the test split.
I0420 04:34:52.484862 140094836827968 submission_runner.py:406] Time since start: 5436.01s, 	Step: 12311, 	{'train/accuracy': 0.3434765636920929, 'train/loss': 3.2385761737823486, 'validation/accuracy': 0.31463998556137085, 'validation/loss': 3.407524347305298, 'validation/num_examples': 50000, 'test/accuracy': 0.23910000920295715, 'test/loss': 3.9382693767547607, 'test/num_examples': 10000, 'score': 5089.267431497574, 'total_duration': 5436.007448911667, 'accumulated_submission_time': 5089.267431497574, 'accumulated_eval_time': 323.2745454311371, 'accumulated_logging_time': 23.227117776870728}
I0420 04:34:52.500096 139913508935424 logging_writer.py:48] [12311] accumulated_eval_time=323.274545, accumulated_logging_time=23.227118, accumulated_submission_time=5089.267431, global_step=12311, preemption_count=0, score=5089.267431, test/accuracy=0.239100, test/loss=3.938269, test/num_examples=10000, total_duration=5436.007449, train/accuracy=0.343477, train/loss=3.238576, validation/accuracy=0.314640, validation/loss=3.407524, validation/num_examples=50000
I0420 04:34:52.588268 140094836827968 checkpoints.py:356] Saving checkpoint at step: 12311
I0420 04:34:53.456316 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_12311
I0420 04:34:53.468838 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_12311.
I0420 04:35:29.803797 139913525720832 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.5714744329452515, loss=5.081942081451416
I0420 04:36:10.987150 139913500542720 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.5674153566360474, loss=4.99207878112793
I0420 04:36:52.211596 139913525720832 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.5207927227020264, loss=5.726210594177246
I0420 04:37:33.684026 139913500542720 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.5828108191490173, loss=4.960511207580566
I0420 04:38:15.038641 139913525720832 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.463226318359375, loss=6.394687652587891
I0420 04:38:57.191444 139913500542720 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.6035574674606323, loss=4.971651077270508
I0420 04:39:38.801219 139913525720832 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.5428235530853271, loss=4.976006507873535
I0420 04:40:20.428936 139913500542720 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.5707205533981323, loss=4.973896503448486
I0420 04:41:02.386098 139913525720832 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.6476282477378845, loss=4.8484978675842285
I0420 04:41:44.087762 139913500542720 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.5990357995033264, loss=4.974124908447266
I0420 04:41:53.605815 140094836827968 spec.py:298] Evaluating on the training split.
I0420 04:42:08.040272 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 04:42:18.844014 140094836827968 spec.py:326] Evaluating on the test split.
I0420 04:42:20.498134 140094836827968 submission_runner.py:406] Time since start: 5884.02s, 	Step: 13324, 	{'train/accuracy': 0.37892577052116394, 'train/loss': 3.1049678325653076, 'validation/accuracy': 0.33653998374938965, 'validation/loss': 3.3175368309020996, 'validation/num_examples': 50000, 'test/accuracy': 0.2572000026702881, 'test/loss': 3.860860824584961, 'test/num_examples': 10000, 'score': 5509.384072542191, 'total_duration': 5884.020733118057, 'accumulated_submission_time': 5509.384072542191, 'accumulated_eval_time': 350.16688299179077, 'accumulated_logging_time': 24.212648391723633}
I0420 04:42:20.514347 139913525720832 logging_writer.py:48] [13324] accumulated_eval_time=350.166883, accumulated_logging_time=24.212648, accumulated_submission_time=5509.384073, global_step=13324, preemption_count=0, score=5509.384073, test/accuracy=0.257200, test/loss=3.860861, test/num_examples=10000, total_duration=5884.020733, train/accuracy=0.378926, train/loss=3.104968, validation/accuracy=0.336540, validation/loss=3.317537, validation/num_examples=50000
I0420 04:42:20.616318 140094836827968 checkpoints.py:356] Saving checkpoint at step: 13324
I0420 04:42:21.697435 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_13324
I0420 04:42:21.709119 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_13324.
I0420 04:42:52.103400 139913500542720 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.537737250328064, loss=6.316264629364014
I0420 04:43:33.540565 139913492150016 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.5705553293228149, loss=4.852200508117676
I0420 04:44:15.736538 139913500542720 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.5993705987930298, loss=5.370273590087891
I0420 04:44:57.449668 139913492150016 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.5844554901123047, loss=4.8706512451171875
I0420 04:45:38.862574 139913500542720 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.45828697085380554, loss=5.645174503326416
I0420 04:46:21.750881 139913492150016 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.5740584135055542, loss=5.174829006195068
I0420 04:47:04.405696 139913500542720 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.5403675436973572, loss=5.222633361816406
I0420 04:47:46.987238 139913492150016 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.538212776184082, loss=5.253070831298828
I0420 04:48:29.370780 139913500542720 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.6184003353118896, loss=4.82830810546875
I0420 04:49:11.752885 139913492150016 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.5142354965209961, loss=5.406080722808838
I0420 04:49:21.951191 140094836827968 spec.py:298] Evaluating on the training split.
I0420 04:49:36.115782 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 04:49:46.901102 140094836827968 spec.py:326] Evaluating on the test split.
I0420 04:49:48.589483 140094836827968 submission_runner.py:406] Time since start: 6332.11s, 	Step: 14327, 	{'train/accuracy': 0.3790820240974426, 'train/loss': 3.164557933807373, 'validation/accuracy': 0.35005998611450195, 'validation/loss': 3.307191848754883, 'validation/num_examples': 50000, 'test/accuracy': 0.2696000039577484, 'test/loss': 3.83420729637146, 'test/num_examples': 10000, 'score': 5929.605890512466, 'total_duration': 6332.11203622818, 'accumulated_submission_time': 5929.605890512466, 'accumulated_eval_time': 376.8051118850708, 'accumulated_logging_time': 25.425471544265747}
I0420 04:49:48.602128 139913500542720 logging_writer.py:48] [14327] accumulated_eval_time=376.805112, accumulated_logging_time=25.425472, accumulated_submission_time=5929.605891, global_step=14327, preemption_count=0, score=5929.605891, test/accuracy=0.269600, test/loss=3.834207, test/num_examples=10000, total_duration=6332.112036, train/accuracy=0.379082, train/loss=3.164558, validation/accuracy=0.350060, validation/loss=3.307192, validation/num_examples=50000
I0420 04:49:48.700446 140094836827968 checkpoints.py:356] Saving checkpoint at step: 14327
I0420 04:49:49.618501 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_14327
I0420 04:49:49.632561 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_14327.
I0420 04:50:19.111531 139913492150016 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.5989919900894165, loss=4.977010726928711
I0420 04:51:00.454564 139913483757312 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.5891185402870178, loss=4.808904647827148
I0420 04:51:42.270796 139913492150016 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.6479040384292603, loss=4.832007884979248
I0420 04:52:24.132746 139913483757312 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.5341554284095764, loss=4.832569122314453
I0420 04:53:06.125777 139913492150016 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.6006330847740173, loss=4.884751796722412
I0420 04:53:48.445321 139913483757312 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.6365652084350586, loss=4.8527655601501465
I0420 04:54:31.104217 139913492150016 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.6006486415863037, loss=4.914448261260986
I0420 04:55:13.356160 139913483757312 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.5776427388191223, loss=4.894445419311523
I0420 04:55:55.542693 139913492150016 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.7062954902648926, loss=4.8382062911987305
I0420 04:56:37.932800 139913483757312 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.643756091594696, loss=4.725625038146973
I0420 04:56:49.932203 140094836827968 spec.py:298] Evaluating on the training split.
I0420 04:57:04.205153 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 04:57:15.019939 140094836827968 spec.py:326] Evaluating on the test split.
I0420 04:57:16.672739 140094836827968 submission_runner.py:406] Time since start: 6780.20s, 	Step: 15330, 	{'train/accuracy': 0.40625, 'train/loss': 2.917762279510498, 'validation/accuracy': 0.3741599917411804, 'validation/loss': 3.0799543857574463, 'validation/num_examples': 50000, 'test/accuracy': 0.2873000204563141, 'test/loss': 3.6400604248046875, 'test/num_examples': 10000, 'score': 6349.8853504657745, 'total_duration': 6780.195335626602, 'accumulated_submission_time': 6349.8853504657745, 'accumulated_eval_time': 403.5460202693939, 'accumulated_logging_time': 26.469919443130493}
I0420 04:57:16.687072 139913492150016 logging_writer.py:48] [15330] accumulated_eval_time=403.546020, accumulated_logging_time=26.469919, accumulated_submission_time=6349.885350, global_step=15330, preemption_count=0, score=6349.885350, test/accuracy=0.287300, test/loss=3.640060, test/num_examples=10000, total_duration=6780.195336, train/accuracy=0.406250, train/loss=2.917762, validation/accuracy=0.374160, validation/loss=3.079954, validation/num_examples=50000
I0420 04:57:16.794778 140094836827968 checkpoints.py:356] Saving checkpoint at step: 15330
I0420 04:57:17.660060 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_15330
I0420 04:57:17.676589 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_15330.
I0420 04:57:45.820591 139913483757312 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.5562859177589417, loss=4.768576145172119
I0420 04:58:28.022110 139913475364608 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.5507490038871765, loss=4.744006633758545
I0420 04:59:09.067852 139913483757312 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.6147327423095703, loss=5.069194793701172
I0420 04:59:50.803542 139913475364608 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.6075954437255859, loss=4.748782157897949
I0420 05:00:33.250967 139913483757312 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.6078113317489624, loss=5.116571426391602
I0420 05:01:15.341659 139913475364608 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.4951038956642151, loss=6.032189846038818
I0420 05:01:57.396150 139913483757312 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.5279361605644226, loss=5.073065757751465
I0420 05:02:39.230781 139913475364608 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.5776886940002441, loss=4.6803059577941895
I0420 05:03:20.916577 139913483757312 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.49918368458747864, loss=5.436649799346924
I0420 05:04:03.036005 139913475364608 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.5606988668441772, loss=4.68937873840332
I0420 05:04:17.709938 140094836827968 spec.py:298] Evaluating on the training split.
I0420 05:04:32.035732 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 05:04:43.146697 140094836827968 spec.py:326] Evaluating on the test split.
I0420 05:04:44.816171 140094836827968 submission_runner.py:406] Time since start: 7228.34s, 	Step: 16337, 	{'train/accuracy': 0.4143163859844208, 'train/loss': 2.9450790882110596, 'validation/accuracy': 0.38047999143600464, 'validation/loss': 3.1194698810577393, 'validation/num_examples': 50000, 'test/accuracy': 0.2921999990940094, 'test/loss': 3.6614508628845215, 'test/num_examples': 10000, 'score': 6769.899214267731, 'total_duration': 7228.338685035706, 'accumulated_submission_time': 6769.899214267731, 'accumulated_eval_time': 430.65218138694763, 'accumulated_logging_time': 27.474753856658936}
I0420 05:04:44.833971 139913483757312 logging_writer.py:48] [16337] accumulated_eval_time=430.652181, accumulated_logging_time=27.474754, accumulated_submission_time=6769.899214, global_step=16337, preemption_count=0, score=6769.899214, test/accuracy=0.292200, test/loss=3.661451, test/num_examples=10000, total_duration=7228.338685, train/accuracy=0.414316, train/loss=2.945079, validation/accuracy=0.380480, validation/loss=3.119470, validation/num_examples=50000
I0420 05:04:44.944845 140094836827968 checkpoints.py:356] Saving checkpoint at step: 16337
I0420 05:04:45.789367 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_16337
I0420 05:04:45.804163 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_16337.
I0420 05:05:11.102450 139913475364608 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.5551115274429321, loss=4.998411655426025
I0420 05:05:53.295697 139913257285376 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.5699454545974731, loss=4.849690914154053
I0420 05:06:35.149269 139913475364608 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.5689425468444824, loss=4.670768737792969
I0420 05:07:17.402840 139913257285376 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.6287769079208374, loss=4.774860382080078
I0420 05:08:00.005936 139913475364608 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.5638846755027771, loss=4.995319843292236
I0420 05:08:42.021107 139913257285376 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.612115740776062, loss=4.682149410247803
I0420 05:09:24.757185 139913475364608 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.626539945602417, loss=4.654429912567139
I0420 05:10:07.107191 139913257285376 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.6402144432067871, loss=4.654486656188965
I0420 05:10:49.385510 139913475364608 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.5060462355613708, loss=6.288032531738281
I0420 05:11:32.457072 139913257285376 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.4939051568508148, loss=5.503744125366211
I0420 05:11:45.879104 140094836827968 spec.py:298] Evaluating on the training split.
I0420 05:12:00.391318 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 05:12:11.381434 140094836827968 spec.py:326] Evaluating on the test split.
I0420 05:12:13.062398 140094836827968 submission_runner.py:406] Time since start: 7676.58s, 	Step: 17333, 	{'train/accuracy': 0.43644529581069946, 'train/loss': 2.7953410148620605, 'validation/accuracy': 0.39337998628616333, 'validation/loss': 3.0140624046325684, 'validation/num_examples': 50000, 'test/accuracy': 0.302700012922287, 'test/loss': 3.5815353393554688, 'test/num_examples': 10000, 'score': 7189.954411506653, 'total_duration': 7676.584993600845, 'accumulated_submission_time': 7189.954411506653, 'accumulated_eval_time': 457.8354597091675, 'accumulated_logging_time': 28.464375019073486}
I0420 05:12:13.076925 139913475364608 logging_writer.py:48] [17333] accumulated_eval_time=457.835460, accumulated_logging_time=28.464375, accumulated_submission_time=7189.954412, global_step=17333, preemption_count=0, score=7189.954412, test/accuracy=0.302700, test/loss=3.581535, test/num_examples=10000, total_duration=7676.584994, train/accuracy=0.436445, train/loss=2.795341, validation/accuracy=0.393380, validation/loss=3.014062, validation/num_examples=50000
I0420 05:12:13.197398 140094836827968 checkpoints.py:356] Saving checkpoint at step: 17333
I0420 05:12:14.130188 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_17333
I0420 05:12:14.146002 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_17333.
I0420 05:12:40.997778 139913257285376 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.525056004524231, loss=5.002378463745117
I0420 05:13:23.241906 139913248892672 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.44486528635025024, loss=6.187901973724365
I0420 05:14:05.752512 139913257285376 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.6003170013427734, loss=4.588971138000488
I0420 05:14:47.938981 139913248892672 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.4827274978160858, loss=5.486930847167969
I0420 05:15:30.490844 139913257285376 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.43042925000190735, loss=6.02548360824585
I0420 05:16:13.205019 139913248892672 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.5922711491584778, loss=4.657092571258545
I0420 05:16:55.519306 139913257285376 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.4916016161441803, loss=5.832339286804199
I0420 05:17:37.579488 139913248892672 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.4631645977497101, loss=6.265865802764893
I0420 05:18:19.509747 139913257285376 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.6184157729148865, loss=4.6897783279418945
I0420 05:19:02.036132 139913248892672 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.660914957523346, loss=4.651120185852051
I0420 05:19:14.502301 140094836827968 spec.py:298] Evaluating on the training split.
I0420 05:19:28.758015 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 05:19:40.298114 140094836827968 spec.py:326] Evaluating on the test split.
I0420 05:19:41.961759 140094836827968 submission_runner.py:406] Time since start: 8125.48s, 	Step: 18332, 	{'train/accuracy': 0.43156248331069946, 'train/loss': 2.8852272033691406, 'validation/accuracy': 0.40167999267578125, 'validation/loss': 3.041515350341797, 'validation/num_examples': 50000, 'test/accuracy': 0.30070000886917114, 'test/loss': 3.632918119430542, 'test/num_examples': 10000, 'score': 7610.282356500626, 'total_duration': 8125.484335422516, 'accumulated_submission_time': 7610.282356500626, 'accumulated_eval_time': 485.2948799133301, 'accumulated_logging_time': 29.558119773864746}
I0420 05:19:41.976806 139913257285376 logging_writer.py:48] [18332] accumulated_eval_time=485.294880, accumulated_logging_time=29.558120, accumulated_submission_time=7610.282357, global_step=18332, preemption_count=0, score=7610.282357, test/accuracy=0.300700, test/loss=3.632918, test/num_examples=10000, total_duration=8125.484335, train/accuracy=0.431562, train/loss=2.885227, validation/accuracy=0.401680, validation/loss=3.041515, validation/num_examples=50000
I0420 05:19:42.150078 140094836827968 checkpoints.py:356] Saving checkpoint at step: 18332
I0420 05:19:43.102616 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_18332
I0420 05:19:43.116331 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_18332.
I0420 05:20:10.700206 139913248892672 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.6043475866317749, loss=4.673932075500488
I0420 05:20:52.750105 139913206929152 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.5675444602966309, loss=4.9754228591918945
I0420 05:21:34.676277 139913248892672 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.6591564416885376, loss=4.739292621612549
I0420 05:22:16.452713 139913206929152 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.5971617698669434, loss=4.5703864097595215
I0420 05:22:58.221668 139913248892672 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.45970064401626587, loss=6.200286388397217
I0420 05:23:39.824702 139913206929152 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.5809738039970398, loss=4.625978469848633
I0420 05:24:22.136496 139913248892672 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.48829251527786255, loss=5.85218620300293
I0420 05:25:03.802477 139913206929152 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.5770118236541748, loss=4.592289447784424
I0420 05:25:46.132413 139913248892672 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.6407842040061951, loss=4.666528224945068
I0420 05:26:28.580412 139913206929152 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.4903428852558136, loss=6.142785549163818
I0420 05:26:43.159611 140094836827968 spec.py:298] Evaluating on the training split.
I0420 05:26:57.326832 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 05:27:09.303222 140094836827968 spec.py:326] Evaluating on the test split.
I0420 05:27:10.946982 140094836827968 submission_runner.py:406] Time since start: 8574.47s, 	Step: 19336, 	{'train/accuracy': 0.46101561188697815, 'train/loss': 2.6670875549316406, 'validation/accuracy': 0.4240399897098541, 'validation/loss': 2.8486483097076416, 'validation/num_examples': 50000, 'test/accuracy': 0.326200008392334, 'test/loss': 3.4360971450805664, 'test/num_examples': 10000, 'score': 8030.305867910385, 'total_duration': 8574.469529628754, 'accumulated_submission_time': 8030.305867910385, 'accumulated_eval_time': 513.0822043418884, 'accumulated_logging_time': 30.7141854763031}
I0420 05:27:10.966226 139913248892672 logging_writer.py:48] [19336] accumulated_eval_time=513.082204, accumulated_logging_time=30.714185, accumulated_submission_time=8030.305868, global_step=19336, preemption_count=0, score=8030.305868, test/accuracy=0.326200, test/loss=3.436097, test/num_examples=10000, total_duration=8574.469530, train/accuracy=0.461016, train/loss=2.667088, validation/accuracy=0.424040, validation/loss=2.848648, validation/num_examples=50000
I0420 05:27:11.132821 140094836827968 checkpoints.py:356] Saving checkpoint at step: 19336
I0420 05:27:12.094362 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_19336
I0420 05:27:12.110065 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_19336.
I0420 05:27:37.825886 139913206929152 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.5528836250305176, loss=4.761984348297119
I0420 05:28:19.640453 139912770737920 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.6099164485931396, loss=4.627335071563721
I0420 05:29:01.352674 139913206929152 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.6125145554542542, loss=4.508908271789551
I0420 05:29:43.503871 139912770737920 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.45906156301498413, loss=5.480332374572754
I0420 05:30:25.117933 139913206929152 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.4769725799560547, loss=6.0104289054870605
I0420 05:31:07.177138 139912770737920 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.6589788794517517, loss=4.591403007507324
I0420 05:31:48.826538 139913206929152 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.6096071600914001, loss=4.583518981933594
I0420 05:32:32.173149 139912770737920 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.637195348739624, loss=4.533024311065674
I0420 05:33:14.875001 139913206929152 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.5695017576217651, loss=4.75380802154541
I0420 05:33:56.944083 139912770737920 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.642218828201294, loss=4.532217979431152
I0420 05:34:12.327333 140094836827968 spec.py:298] Evaluating on the training split.
I0420 05:34:26.936667 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 05:34:38.517806 140094836827968 spec.py:326] Evaluating on the test split.
I0420 05:34:40.192174 140094836827968 submission_runner.py:406] Time since start: 9023.71s, 	Step: 20338, 	{'train/accuracy': 0.4696093499660492, 'train/loss': 2.628263473510742, 'validation/accuracy': 0.429099977016449, 'validation/loss': 2.819188117980957, 'validation/num_examples': 50000, 'test/accuracy': 0.33250001072883606, 'test/loss': 3.4020957946777344, 'test/num_examples': 10000, 'score': 8450.50317645073, 'total_duration': 9023.714770555496, 'accumulated_submission_time': 8450.50317645073, 'accumulated_eval_time': 540.9470338821411, 'accumulated_logging_time': 31.878835439682007}
I0420 05:34:40.203603 139913206929152 logging_writer.py:48] [20338] accumulated_eval_time=540.947034, accumulated_logging_time=31.878835, accumulated_submission_time=8450.503176, global_step=20338, preemption_count=0, score=8450.503176, test/accuracy=0.332500, test/loss=3.402096, test/num_examples=10000, total_duration=9023.714771, train/accuracy=0.469609, train/loss=2.628263, validation/accuracy=0.429100, validation/loss=2.819188, validation/num_examples=50000
I0420 05:34:40.363164 140094836827968 checkpoints.py:356] Saving checkpoint at step: 20338
I0420 05:34:41.327776 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_20338
I0420 05:34:41.344751 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_20338.
I0420 05:35:06.113725 139912770737920 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.48813867568969727, loss=5.7020673751831055
I0420 05:35:46.801004 139912493909760 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.5978505611419678, loss=4.480976581573486
I0420 05:36:28.043800 139912770737920 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.4981450140476227, loss=6.026834011077881
I0420 05:37:09.028000 139912493909760 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.6001059412956238, loss=4.512948036193848
I0420 05:37:51.244497 139912770737920 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.5269315838813782, loss=5.3537397384643555
I0420 05:38:33.748100 139912493909760 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.43584638833999634, loss=6.067816734313965
I0420 05:39:16.315109 139912770737920 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.5241206884384155, loss=5.228445053100586
I0420 05:39:58.435580 139912493909760 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.6205312609672546, loss=4.491401195526123
I0420 05:40:39.535582 139912770737920 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.6275396943092346, loss=4.484276294708252
I0420 05:41:22.292752 139912493909760 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.49419307708740234, loss=6.145262241363525
I0420 05:41:41.479363 140094836827968 spec.py:298] Evaluating on the training split.
I0420 05:41:55.670166 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 05:42:08.001713 140094836827968 spec.py:326] Evaluating on the test split.
I0420 05:42:09.674063 140094836827968 submission_runner.py:406] Time since start: 9473.20s, 	Step: 21348, 	{'train/accuracy': 0.48847654461860657, 'train/loss': 2.5223329067230225, 'validation/accuracy': 0.44443997740745544, 'validation/loss': 2.7400784492492676, 'validation/num_examples': 50000, 'test/accuracy': 0.3460000157356262, 'test/loss': 3.3298966884613037, 'test/num_examples': 10000, 'score': 8870.616674661636, 'total_duration': 9473.196656227112, 'accumulated_submission_time': 8870.616674661636, 'accumulated_eval_time': 569.1417417526245, 'accumulated_logging_time': 33.03311324119568}
I0420 05:42:09.686284 139912770737920 logging_writer.py:48] [21348] accumulated_eval_time=569.141742, accumulated_logging_time=33.033113, accumulated_submission_time=8870.616675, global_step=21348, preemption_count=0, score=8870.616675, test/accuracy=0.346000, test/loss=3.329897, test/num_examples=10000, total_duration=9473.196656, train/accuracy=0.488477, train/loss=2.522333, validation/accuracy=0.444440, validation/loss=2.740078, validation/num_examples=50000
I0420 05:42:09.859415 140094836827968 checkpoints.py:356] Saving checkpoint at step: 21348
I0420 05:42:10.812699 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_21348
I0420 05:42:10.827164 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_21348.
I0420 05:42:31.646034 139912493909760 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.6101993322372437, loss=4.484829425811768
I0420 05:43:13.156389 139912485517056 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.5764733552932739, loss=4.590637683868408
I0420 05:43:54.648107 139912493909760 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.6294179558753967, loss=4.599322319030762
I0420 05:44:36.412757 139912485517056 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.5901504755020142, loss=4.606858730316162
I0420 05:45:17.852468 139912493909760 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.5043334364891052, loss=5.000894069671631
I0420 05:45:59.412380 139912485517056 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.5891819000244141, loss=4.622074127197266
I0420 05:46:41.057708 139912493909760 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.6361262798309326, loss=4.505441188812256
I0420 05:47:22.533175 139912485517056 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.45381224155426025, loss=6.116960525512695
I0420 05:48:04.159984 139912493909760 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.6844956874847412, loss=4.467996120452881
I0420 05:48:46.630276 139912485517056 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.48999568819999695, loss=6.058185577392578
I0420 05:49:11.170736 140094836827968 spec.py:298] Evaluating on the training split.
I0420 05:49:24.455718 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 05:49:36.688488 140094836827968 spec.py:326] Evaluating on the test split.
I0420 05:49:38.357166 140094836827968 submission_runner.py:406] Time since start: 9921.88s, 	Step: 22360, 	{'train/accuracy': 0.4928320348262787, 'train/loss': 2.4906363487243652, 'validation/accuracy': 0.4560199975967407, 'validation/loss': 2.6669840812683105, 'validation/num_examples': 50000, 'test/accuracy': 0.3505000174045563, 'test/loss': 3.270718812942505, 'test/num_examples': 10000, 'score': 9290.939936637878, 'total_duration': 9921.879735708237, 'accumulated_submission_time': 9290.939936637878, 'accumulated_eval_time': 596.3281471729279, 'accumulated_logging_time': 34.18768882751465}
I0420 05:49:38.369588 139912493909760 logging_writer.py:48] [22360] accumulated_eval_time=596.328147, accumulated_logging_time=34.187689, accumulated_submission_time=9290.939937, global_step=22360, preemption_count=0, score=9290.939937, test/accuracy=0.350500, test/loss=3.270719, test/num_examples=10000, total_duration=9921.879736, train/accuracy=0.492832, train/loss=2.490636, validation/accuracy=0.456020, validation/loss=2.666984, validation/num_examples=50000
I0420 05:49:38.792593 140094836827968 checkpoints.py:356] Saving checkpoint at step: 22360
I0420 05:49:39.610005 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_22360
I0420 05:49:39.623723 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_22360.
I0420 05:49:55.927115 139912485517056 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.6027423739433289, loss=4.672640800476074
I0420 05:50:38.720491 139912477124352 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.6171416640281677, loss=4.402923583984375
I0420 05:51:21.997031 139912485517056 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.6243727803230286, loss=4.490999221801758
I0420 05:52:04.389795 139912477124352 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.6016269326210022, loss=4.614620208740234
I0420 05:52:46.569324 139912485517056 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.5352930426597595, loss=4.709039211273193
I0420 05:53:28.396744 139912477124352 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.47105681896209717, loss=6.000059604644775
I0420 05:54:11.250573 139912485517056 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.6386713981628418, loss=4.372572898864746
I0420 05:54:53.757343 139912477124352 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.5670909285545349, loss=5.221748352050781
I0420 05:55:36.610822 139912485517056 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.646217405796051, loss=5.0393385887146
I0420 05:56:19.656663 139912477124352 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.7086395025253296, loss=4.395292282104492
I0420 05:56:39.840744 140094836827968 spec.py:298] Evaluating on the training split.
I0420 05:56:53.541047 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 05:57:05.372501 140094836827968 spec.py:326] Evaluating on the test split.
I0420 05:57:07.070244 140094836827968 submission_runner.py:406] Time since start: 10370.59s, 	Step: 23350, 	{'train/accuracy': 0.5103320479393005, 'train/loss': 2.357052803039551, 'validation/accuracy': 0.46823999285697937, 'validation/loss': 2.565847873687744, 'validation/num_examples': 50000, 'test/accuracy': 0.3612000048160553, 'test/loss': 3.198045253753662, 'test/num_examples': 10000, 'score': 9711.138109445572, 'total_duration': 10370.592807769775, 'accumulated_submission_time': 9711.138109445572, 'accumulated_eval_time': 623.5575816631317, 'accumulated_logging_time': 35.45534086227417}
I0420 05:57:07.088912 139912485517056 logging_writer.py:48] [23350] accumulated_eval_time=623.557582, accumulated_logging_time=35.455341, accumulated_submission_time=9711.138109, global_step=23350, preemption_count=0, score=9711.138109, test/accuracy=0.361200, test/loss=3.198045, test/num_examples=10000, total_duration=10370.592808, train/accuracy=0.510332, train/loss=2.357053, validation/accuracy=0.468240, validation/loss=2.565848, validation/num_examples=50000
I0420 05:57:07.807035 140094836827968 checkpoints.py:356] Saving checkpoint at step: 23350
I0420 05:57:09.143098 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_23350
I0420 05:57:09.160083 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_23350.
I0420 05:57:29.293533 139912477124352 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.5084682106971741, loss=5.626880645751953
I0420 05:58:10.175909 139912334513920 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.49356475472450256, loss=5.519693851470947
I0420 05:58:51.963132 139912477124352 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.578389048576355, loss=4.492515563964844
I0420 05:59:33.296483 139912334513920 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.5304185152053833, loss=5.028467178344727
I0420 06:00:15.506145 139912477124352 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.620911180973053, loss=4.393165588378906
I0420 06:00:57.314851 139912334513920 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.5072787404060364, loss=5.918619632720947
I0420 06:01:39.241800 139912477124352 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.4441283941268921, loss=5.537792205810547
I0420 06:02:21.338732 139912334513920 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.49749335646629333, loss=4.998456954956055
I0420 06:03:03.059579 139912477124352 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.5306362509727478, loss=5.636284351348877
I0420 06:03:44.970747 139912334513920 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.6510922312736511, loss=4.4626312255859375
I0420 06:04:09.353175 140094836827968 spec.py:298] Evaluating on the training split.
I0420 06:04:19.235681 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 06:04:32.854652 140094836827968 spec.py:326] Evaluating on the test split.
I0420 06:04:34.533210 140094836827968 submission_runner.py:406] Time since start: 10818.06s, 	Step: 24360, 	{'train/accuracy': 0.5230468511581421, 'train/loss': 2.2979137897491455, 'validation/accuracy': 0.4780399799346924, 'validation/loss': 2.5138795375823975, 'validation/num_examples': 50000, 'test/accuracy': 0.37050002813339233, 'test/loss': 3.1437458992004395, 'test/num_examples': 10000, 'score': 10131.298212528229, 'total_duration': 10818.055797338486, 'accumulated_submission_time': 10131.298212528229, 'accumulated_eval_time': 648.7376034259796, 'accumulated_logging_time': 37.559751749038696}
I0420 06:04:34.545692 139912477124352 logging_writer.py:48] [24360] accumulated_eval_time=648.737603, accumulated_logging_time=37.559752, accumulated_submission_time=10131.298213, global_step=24360, preemption_count=0, score=10131.298213, test/accuracy=0.370500, test/loss=3.143746, test/num_examples=10000, total_duration=10818.055797, train/accuracy=0.523047, train/loss=2.297914, validation/accuracy=0.478040, validation/loss=2.513880, validation/num_examples=50000
I0420 06:04:34.725168 140094836827968 checkpoints.py:356] Saving checkpoint at step: 24360
I0420 06:04:35.660027 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_24360
I0420 06:04:35.675928 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_24360.
I0420 06:04:51.794296 139912334513920 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.5641583800315857, loss=5.089526176452637
I0420 06:05:32.224294 139912183543552 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.46815866231918335, loss=5.724122047424316
I0420 06:06:13.789248 139912334513920 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.5858654379844666, loss=4.338752746582031
I0420 06:06:55.514081 139912183543552 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.6394462585449219, loss=4.300829887390137
I0420 06:07:37.094773 139912334513920 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.6770040988922119, loss=4.347135543823242
I0420 06:08:18.601437 139912183543552 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.6284030675888062, loss=4.324933052062988
I0420 06:09:00.396894 139912334513920 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.54182368516922, loss=4.846460819244385
I0420 06:09:42.001915 139912183543552 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.5336197018623352, loss=6.128482341766357
I0420 06:10:24.008314 139912334513920 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.643752932548523, loss=4.368633270263672
I0420 06:11:05.668665 139912183543552 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.7427856922149658, loss=4.3623528480529785
I0420 06:11:35.782623 140094836827968 spec.py:298] Evaluating on the training split.
I0420 06:11:45.412666 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 06:11:58.932081 140094836827968 spec.py:326] Evaluating on the test split.
I0420 06:12:00.595016 140094836827968 submission_runner.py:406] Time since start: 11264.12s, 	Step: 25374, 	{'train/accuracy': 0.5304882526397705, 'train/loss': 2.2565011978149414, 'validation/accuracy': 0.48607999086380005, 'validation/loss': 2.4824860095977783, 'validation/num_examples': 50000, 'test/accuracy': 0.37320002913475037, 'test/loss': 3.126579523086548, 'test/num_examples': 10000, 'score': 10551.384824037552, 'total_duration': 11264.117563724518, 'accumulated_submission_time': 10551.384824037552, 'accumulated_eval_time': 673.549925327301, 'accumulated_logging_time': 38.70399308204651}
I0420 06:12:00.612063 139912334513920 logging_writer.py:48] [25374] accumulated_eval_time=673.549925, accumulated_logging_time=38.703993, accumulated_submission_time=10551.384824, global_step=25374, preemption_count=0, score=10551.384824, test/accuracy=0.373200, test/loss=3.126580, test/num_examples=10000, total_duration=11264.117564, train/accuracy=0.530488, train/loss=2.256501, validation/accuracy=0.486080, validation/loss=2.482486, validation/num_examples=50000
I0420 06:12:00.817584 140094836827968 checkpoints.py:356] Saving checkpoint at step: 25374
I0420 06:12:01.707578 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_25374
I0420 06:12:01.722879 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_25374.
I0420 06:12:12.360503 139912183543552 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.5518965125083923, loss=5.377368927001953
I0420 06:12:52.728923 139912175150848 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.47099727392196655, loss=5.836928367614746
I0420 06:13:34.014585 139912183543552 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.5066022872924805, loss=6.0328850746154785
I0420 06:14:16.128864 139912175150848 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.5937127470970154, loss=4.352185249328613
I0420 06:14:57.508389 139912183543552 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.6438971757888794, loss=4.304516315460205
I0420 06:15:39.465293 139912175150848 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.49280884861946106, loss=6.042212963104248
I0420 06:16:20.897481 139912183543552 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.6730190515518188, loss=4.2628068923950195
I0420 06:17:01.902724 139912175150848 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.6004394292831421, loss=4.666134834289551
I0420 06:17:43.310437 139912183543552 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.6338310837745667, loss=4.255568981170654
I0420 06:18:25.235338 139912175150848 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.5893386006355286, loss=4.275085926055908
I0420 06:19:01.958581 140094836827968 spec.py:298] Evaluating on the training split.
I0420 06:19:11.632961 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 06:19:25.553416 140094836827968 spec.py:326] Evaluating on the test split.
I0420 06:19:27.222280 140094836827968 submission_runner.py:406] Time since start: 11710.74s, 	Step: 26389, 	{'train/accuracy': 0.5671484470367432, 'train/loss': 2.089872360229492, 'validation/accuracy': 0.49719998240470886, 'validation/loss': 2.400921106338501, 'validation/num_examples': 50000, 'test/accuracy': 0.38600000739097595, 'test/loss': 3.049140214920044, 'test/num_examples': 10000, 'score': 10971.601137161255, 'total_duration': 11710.744876384735, 'accumulated_submission_time': 10971.601137161255, 'accumulated_eval_time': 698.8136067390442, 'accumulated_logging_time': 39.832908153533936}
I0420 06:19:27.234215 139912183543552 logging_writer.py:48] [26389] accumulated_eval_time=698.813607, accumulated_logging_time=39.832908, accumulated_submission_time=10971.601137, global_step=26389, preemption_count=0, score=10971.601137, test/accuracy=0.386000, test/loss=3.049140, test/num_examples=10000, total_duration=11710.744876, train/accuracy=0.567148, train/loss=2.089872, validation/accuracy=0.497200, validation/loss=2.400921, validation/num_examples=50000
I0420 06:19:27.466151 140094836827968 checkpoints.py:356] Saving checkpoint at step: 26389
I0420 06:19:28.502164 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_26389
I0420 06:19:28.520634 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_26389.
I0420 06:19:33.290558 139912175150848 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.6456655263900757, loss=4.39181661605835
I0420 06:20:13.504915 139912166758144 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.48289620876312256, loss=5.4658918380737305
I0420 06:20:55.377937 139912175150848 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.5635029673576355, loss=4.665663242340088
I0420 06:21:37.047451 139912166758144 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.44938600063323975, loss=6.0682549476623535
I0420 06:22:18.690992 139912175150848 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.46712785959243774, loss=6.087417125701904
I0420 06:23:00.166271 139912166758144 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.6122147440910339, loss=4.2455644607543945
I0420 06:23:42.112433 139912175150848 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.555949330329895, loss=4.753118515014648
I0420 06:24:23.746852 139912166758144 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.4624776840209961, loss=6.0126566886901855
I0420 06:25:06.244056 139912175150848 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.5978474020957947, loss=4.492559432983398
I0420 06:25:47.761137 139912166758144 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.5030084252357483, loss=5.394350051879883
I0420 06:26:28.872029 140094836827968 spec.py:298] Evaluating on the training split.
I0420 06:26:38.036939 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 06:26:51.667924 140094836827968 spec.py:326] Evaluating on the test split.
I0420 06:26:53.340945 140094836827968 submission_runner.py:406] Time since start: 12156.86s, 	Step: 27400, 	{'train/accuracy': 0.5447461009025574, 'train/loss': 2.2115330696105957, 'validation/accuracy': 0.49949997663497925, 'validation/loss': 2.416468620300293, 'validation/num_examples': 50000, 'test/accuracy': 0.39100003242492676, 'test/loss': 3.0406293869018555, 'test/num_examples': 10000, 'score': 11391.919004917145, 'total_duration': 12156.863492012024, 'accumulated_submission_time': 11391.919004917145, 'accumulated_eval_time': 723.2824618816376, 'accumulated_logging_time': 41.14699125289917}
I0420 06:26:53.360538 139912175150848 logging_writer.py:48] [27400] accumulated_eval_time=723.282462, accumulated_logging_time=41.146991, accumulated_submission_time=11391.919005, global_step=27400, preemption_count=0, score=11391.919005, test/accuracy=0.391000, test/loss=3.040629, test/num_examples=10000, total_duration=12156.863492, train/accuracy=0.544746, train/loss=2.211533, validation/accuracy=0.499500, validation/loss=2.416469, validation/num_examples=50000
I0420 06:26:53.593826 140094836827968 checkpoints.py:356] Saving checkpoint at step: 27400
I0420 06:26:54.548435 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_27400
I0420 06:26:54.564375 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_27400.
I0420 06:26:54.979848 139912166758144 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.6450590491294861, loss=4.299770832061768
I0420 06:27:34.573980 139912158365440 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.520721971988678, loss=4.87653923034668
I0420 06:28:16.467648 139912166758144 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.5890617966651917, loss=4.138230800628662
I0420 06:28:58.322072 139912158365440 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.490899920463562, loss=5.7433061599731445
I0420 06:29:40.320752 139912166758144 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.47138917446136475, loss=5.9702582359313965
I0420 06:30:21.863317 139912158365440 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.5735143423080444, loss=4.185227394104004
I0420 06:31:03.238767 140094836827968 spec.py:298] Evaluating on the training split.
I0420 06:31:12.761743 140094836827968 spec.py:310] Evaluating on the validation split.
I0420 06:31:26.527561 140094836827968 spec.py:326] Evaluating on the test split.
I0420 06:31:28.188165 140094836827968 submission_runner.py:406] Time since start: 12431.71s, 	Step: 28000, 	{'train/accuracy': 0.5612695217132568, 'train/loss': 2.1791670322418213, 'validation/accuracy': 0.5083199739456177, 'validation/loss': 2.42812442779541, 'validation/num_examples': 50000, 'test/accuracy': 0.3992000222206116, 'test/loss': 3.04585862159729, 'test/num_examples': 10000, 'score': 11640.580857515335, 'total_duration': 12431.710727930069, 'accumulated_submission_time': 11640.580857515335, 'accumulated_eval_time': 748.2318212985992, 'accumulated_logging_time': 42.37189030647278}
I0420 06:31:28.200948 139912166758144 logging_writer.py:48] [28000] accumulated_eval_time=748.231821, accumulated_logging_time=42.371890, accumulated_submission_time=11640.580858, global_step=28000, preemption_count=0, score=11640.580858, test/accuracy=0.399200, test/loss=3.045859, test/num_examples=10000, total_duration=12431.710728, train/accuracy=0.561270, train/loss=2.179167, validation/accuracy=0.508320, validation/loss=2.428124, validation/num_examples=50000
I0420 06:31:28.413002 140094836827968 checkpoints.py:356] Saving checkpoint at step: 28000
I0420 06:31:29.371502 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_28000
I0420 06:31:29.386177 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_28000.
I0420 06:31:29.397786 139912158365440 logging_writer.py:48] [28000] global_step=28000, preemption_count=0, score=11640.580858
I0420 06:31:29.493543 140094836827968 checkpoints.py:356] Saving checkpoint at step: 28000
I0420 06:31:30.541014 140094836827968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_28000
I0420 06:31:30.553524 140094836827968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_28000.
I0420 06:31:31.365938 140094836827968 submission_runner.py:567] Tuning trial 1/1
I0420 06:31:31.368347 140094836827968 submission_runner.py:568] Hyperparameters: Hyperparameters(learning_rate=0.4394877561366806, one_minus_beta1=0.07113602458522507, warmup_factor=0.05, weight_decay=9.611851572925426e-07, label_smoothing=0.2, dropout_rate=0.0, decay_steps_factor=0.9, end_factor=0.001)
I0420 06:31:31.372623 140094836827968 submission_runner.py:569] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0009179687476716936, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 46.78114318847656, 'total_duration': 97.18116211891174, 'accumulated_submission_time': 46.78114318847656, 'accumulated_eval_time': 50.399887561798096, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (1007, {'train/accuracy': 0.028535155579447746, 'train/loss': 6.192429542541504, 'validation/accuracy': 0.026920000091195107, 'validation/loss': 6.218790054321289, 'validation/num_examples': 50000, 'test/accuracy': 0.022200001403689384, 'test/loss': 6.311334609985352, 'test/num_examples': 10000, 'score': 466.95301580429077, 'total_duration': 537.2331731319427, 'accumulated_submission_time': 466.95301580429077, 'accumulated_eval_time': 69.77760243415833, 'accumulated_logging_time': 0.48229146003723145, 'global_step': 1007, 'preemption_count': 0}), (2043, {'train/accuracy': 0.057207029312849045, 'train/loss': 5.71145486831665, 'validation/accuracy': 0.05384000018239021, 'validation/loss': 5.752144813537598, 'validation/num_examples': 50000, 'test/accuracy': 0.04010000079870224, 'test/loss': 5.913881778717041, 'test/num_examples': 10000, 'score': 887.4281833171844, 'total_duration': 979.376002073288, 'accumulated_submission_time': 887.4281833171844, 'accumulated_eval_time': 88.93034267425537, 'accumulated_logging_time': 2.976855516433716, 'global_step': 2043, 'preemption_count': 0}), (3079, {'train/accuracy': 0.08738280832767487, 'train/loss': 5.327775001525879, 'validation/accuracy': 0.08033999800682068, 'validation/loss': 5.377453804016113, 'validation/num_examples': 50000, 'test/accuracy': 0.05920000374317169, 'test/loss': 5.599483013153076, 'test/num_examples': 10000, 'score': 1307.446447610855, 'total_duration': 1421.8900785446167, 'accumulated_submission_time': 1307.446447610855, 'accumulated_eval_time': 108.50885581970215, 'accumulated_logging_time': 5.874029636383057, 'global_step': 3079, 'preemption_count': 0}), (4109, {'train/accuracy': 0.10595703125, 'train/loss': 5.055850505828857, 'validation/accuracy': 0.09685999900102615, 'validation/loss': 5.135804653167725, 'validation/num_examples': 50000, 'test/accuracy': 0.07690000534057617, 'test/loss': 5.394585132598877, 'test/num_examples': 10000, 'score': 1727.5094561576843, 'total_duration': 1864.631887435913, 'accumulated_submission_time': 1727.5094561576843, 'accumulated_eval_time': 128.2497136592865, 'accumulated_logging_time': 8.79192590713501, 'global_step': 4109, 'preemption_count': 0}), (5139, {'train/accuracy': 0.13242186605930328, 'train/loss': 4.8840227127075195, 'validation/accuracy': 0.12373999506235123, 'validation/loss': 4.9516072273254395, 'validation/num_examples': 50000, 'test/accuracy': 0.09260000288486481, 'test/loss': 5.232926845550537, 'test/num_examples': 10000, 'score': 2147.612490415573, 'total_duration': 2307.6815207004547, 'accumulated_submission_time': 2147.612490415573, 'accumulated_eval_time': 148.06018733978271, 'accumulated_logging_time': 11.907721519470215, 'global_step': 5139, 'preemption_count': 0}), (6170, {'train/accuracy': 0.17093749344348907, 'train/loss': 4.554319858551025, 'validation/accuracy': 0.15765999257564545, 'validation/loss': 4.644810676574707, 'validation/num_examples': 50000, 'test/accuracy': 0.1145000085234642, 'test/loss': 4.976757526397705, 'test/num_examples': 10000, 'score': 2567.7626695632935, 'total_duration': 2751.9521605968475, 'accumulated_submission_time': 2567.7626695632935, 'accumulated_eval_time': 169.64891242980957, 'accumulated_logging_time': 14.419824123382568, 'global_step': 6170, 'preemption_count': 0}), (7197, {'train/accuracy': 0.19384765625, 'train/loss': 4.4271674156188965, 'validation/accuracy': 0.17853999137878418, 'validation/loss': 4.522009372711182, 'validation/num_examples': 50000, 'test/accuracy': 0.14030000567436218, 'test/loss': 4.860133171081543, 'test/num_examples': 10000, 'score': 2987.937479019165, 'total_duration': 3197.763764858246, 'accumulated_submission_time': 2987.937479019165, 'accumulated_eval_time': 192.95207858085632, 'accumulated_logging_time': 16.733586311340332, 'global_step': 7197, 'preemption_count': 0}), (8223, {'train/accuracy': 0.23136718571186066, 'train/loss': 4.137267589569092, 'validation/accuracy': 0.21213999390602112, 'validation/loss': 4.246388912200928, 'validation/num_examples': 50000, 'test/accuracy': 0.1583000123500824, 'test/loss': 4.63227653503418, 'test/num_examples': 10000, 'score': 3408.1773903369904, 'total_duration': 3646.076869249344, 'accumulated_submission_time': 3408.1773903369904, 'accumulated_eval_time': 219.61770153045654, 'accumulated_logging_time': 18.120813608169556, 'global_step': 8223, 'preemption_count': 0}), (9246, {'train/accuracy': 0.26513671875, 'train/loss': 3.8392834663391113, 'validation/accuracy': 0.23479999601840973, 'validation/loss': 4.026276111602783, 'validation/num_examples': 50000, 'test/accuracy': 0.17430001497268677, 'test/loss': 4.452797889709473, 'test/num_examples': 10000, 'score': 3828.495933532715, 'total_duration': 4093.4331278800964, 'accumulated_submission_time': 3828.495933532715, 'accumulated_eval_time': 244.90129280090332, 'accumulated_logging_time': 19.855334281921387, 'global_step': 9246, 'preemption_count': 0}), (10270, {'train/accuracy': 0.2894921898841858, 'train/loss': 3.6266701221466064, 'validation/accuracy': 0.2663799822330475, 'validation/loss': 3.748098850250244, 'validation/num_examples': 50000, 'test/accuracy': 0.20410001277923584, 'test/loss': 4.210958957672119, 'test/num_examples': 10000, 'score': 4248.830755472183, 'total_duration': 4540.567483663559, 'accumulated_submission_time': 4248.830755472183, 'accumulated_eval_time': 270.8291711807251, 'accumulated_logging_time': 20.70771312713623, 'global_step': 10270, 'preemption_count': 0}), (11293, {'train/accuracy': 0.31166014075279236, 'train/loss': 3.5010058879852295, 'validation/accuracy': 0.28591999411582947, 'validation/loss': 3.6350536346435547, 'validation/num_examples': 50000, 'test/accuracy': 0.22040000557899475, 'test/loss': 4.112656593322754, 'test/num_examples': 10000, 'score': 4669.104925632477, 'total_duration': 4987.552630186081, 'accumulated_submission_time': 4669.104925632477, 'accumulated_eval_time': 296.5389955043793, 'accumulated_logging_time': 21.68957543373108, 'global_step': 11293, 'preemption_count': 0}), (12311, {'train/accuracy': 0.3434765636920929, 'train/loss': 3.2385761737823486, 'validation/accuracy': 0.31463998556137085, 'validation/loss': 3.407524347305298, 'validation/num_examples': 50000, 'test/accuracy': 0.23910000920295715, 'test/loss': 3.9382693767547607, 'test/num_examples': 10000, 'score': 5089.267431497574, 'total_duration': 5436.007448911667, 'accumulated_submission_time': 5089.267431497574, 'accumulated_eval_time': 323.2745454311371, 'accumulated_logging_time': 23.227117776870728, 'global_step': 12311, 'preemption_count': 0}), (13324, {'train/accuracy': 0.37892577052116394, 'train/loss': 3.1049678325653076, 'validation/accuracy': 0.33653998374938965, 'validation/loss': 3.3175368309020996, 'validation/num_examples': 50000, 'test/accuracy': 0.2572000026702881, 'test/loss': 3.860860824584961, 'test/num_examples': 10000, 'score': 5509.384072542191, 'total_duration': 5884.020733118057, 'accumulated_submission_time': 5509.384072542191, 'accumulated_eval_time': 350.16688299179077, 'accumulated_logging_time': 24.212648391723633, 'global_step': 13324, 'preemption_count': 0}), (14327, {'train/accuracy': 0.3790820240974426, 'train/loss': 3.164557933807373, 'validation/accuracy': 0.35005998611450195, 'validation/loss': 3.307191848754883, 'validation/num_examples': 50000, 'test/accuracy': 0.2696000039577484, 'test/loss': 3.83420729637146, 'test/num_examples': 10000, 'score': 5929.605890512466, 'total_duration': 6332.11203622818, 'accumulated_submission_time': 5929.605890512466, 'accumulated_eval_time': 376.8051118850708, 'accumulated_logging_time': 25.425471544265747, 'global_step': 14327, 'preemption_count': 0}), (15330, {'train/accuracy': 0.40625, 'train/loss': 2.917762279510498, 'validation/accuracy': 0.3741599917411804, 'validation/loss': 3.0799543857574463, 'validation/num_examples': 50000, 'test/accuracy': 0.2873000204563141, 'test/loss': 3.6400604248046875, 'test/num_examples': 10000, 'score': 6349.8853504657745, 'total_duration': 6780.195335626602, 'accumulated_submission_time': 6349.8853504657745, 'accumulated_eval_time': 403.5460202693939, 'accumulated_logging_time': 26.469919443130493, 'global_step': 15330, 'preemption_count': 0}), (16337, {'train/accuracy': 0.4143163859844208, 'train/loss': 2.9450790882110596, 'validation/accuracy': 0.38047999143600464, 'validation/loss': 3.1194698810577393, 'validation/num_examples': 50000, 'test/accuracy': 0.2921999990940094, 'test/loss': 3.6614508628845215, 'test/num_examples': 10000, 'score': 6769.899214267731, 'total_duration': 7228.338685035706, 'accumulated_submission_time': 6769.899214267731, 'accumulated_eval_time': 430.65218138694763, 'accumulated_logging_time': 27.474753856658936, 'global_step': 16337, 'preemption_count': 0}), (17333, {'train/accuracy': 0.43644529581069946, 'train/loss': 2.7953410148620605, 'validation/accuracy': 0.39337998628616333, 'validation/loss': 3.0140624046325684, 'validation/num_examples': 50000, 'test/accuracy': 0.302700012922287, 'test/loss': 3.5815353393554688, 'test/num_examples': 10000, 'score': 7189.954411506653, 'total_duration': 7676.584993600845, 'accumulated_submission_time': 7189.954411506653, 'accumulated_eval_time': 457.8354597091675, 'accumulated_logging_time': 28.464375019073486, 'global_step': 17333, 'preemption_count': 0}), (18332, {'train/accuracy': 0.43156248331069946, 'train/loss': 2.8852272033691406, 'validation/accuracy': 0.40167999267578125, 'validation/loss': 3.041515350341797, 'validation/num_examples': 50000, 'test/accuracy': 0.30070000886917114, 'test/loss': 3.632918119430542, 'test/num_examples': 10000, 'score': 7610.282356500626, 'total_duration': 8125.484335422516, 'accumulated_submission_time': 7610.282356500626, 'accumulated_eval_time': 485.2948799133301, 'accumulated_logging_time': 29.558119773864746, 'global_step': 18332, 'preemption_count': 0}), (19336, {'train/accuracy': 0.46101561188697815, 'train/loss': 2.6670875549316406, 'validation/accuracy': 0.4240399897098541, 'validation/loss': 2.8486483097076416, 'validation/num_examples': 50000, 'test/accuracy': 0.326200008392334, 'test/loss': 3.4360971450805664, 'test/num_examples': 10000, 'score': 8030.305867910385, 'total_duration': 8574.469529628754, 'accumulated_submission_time': 8030.305867910385, 'accumulated_eval_time': 513.0822043418884, 'accumulated_logging_time': 30.7141854763031, 'global_step': 19336, 'preemption_count': 0}), (20338, {'train/accuracy': 0.4696093499660492, 'train/loss': 2.628263473510742, 'validation/accuracy': 0.429099977016449, 'validation/loss': 2.819188117980957, 'validation/num_examples': 50000, 'test/accuracy': 0.33250001072883606, 'test/loss': 3.4020957946777344, 'test/num_examples': 10000, 'score': 8450.50317645073, 'total_duration': 9023.714770555496, 'accumulated_submission_time': 8450.50317645073, 'accumulated_eval_time': 540.9470338821411, 'accumulated_logging_time': 31.878835439682007, 'global_step': 20338, 'preemption_count': 0}), (21348, {'train/accuracy': 0.48847654461860657, 'train/loss': 2.5223329067230225, 'validation/accuracy': 0.44443997740745544, 'validation/loss': 2.7400784492492676, 'validation/num_examples': 50000, 'test/accuracy': 0.3460000157356262, 'test/loss': 3.3298966884613037, 'test/num_examples': 10000, 'score': 8870.616674661636, 'total_duration': 9473.196656227112, 'accumulated_submission_time': 8870.616674661636, 'accumulated_eval_time': 569.1417417526245, 'accumulated_logging_time': 33.03311324119568, 'global_step': 21348, 'preemption_count': 0}), (22360, {'train/accuracy': 0.4928320348262787, 'train/loss': 2.4906363487243652, 'validation/accuracy': 0.4560199975967407, 'validation/loss': 2.6669840812683105, 'validation/num_examples': 50000, 'test/accuracy': 0.3505000174045563, 'test/loss': 3.270718812942505, 'test/num_examples': 10000, 'score': 9290.939936637878, 'total_duration': 9921.879735708237, 'accumulated_submission_time': 9290.939936637878, 'accumulated_eval_time': 596.3281471729279, 'accumulated_logging_time': 34.18768882751465, 'global_step': 22360, 'preemption_count': 0}), (23350, {'train/accuracy': 0.5103320479393005, 'train/loss': 2.357052803039551, 'validation/accuracy': 0.46823999285697937, 'validation/loss': 2.565847873687744, 'validation/num_examples': 50000, 'test/accuracy': 0.3612000048160553, 'test/loss': 3.198045253753662, 'test/num_examples': 10000, 'score': 9711.138109445572, 'total_duration': 10370.592807769775, 'accumulated_submission_time': 9711.138109445572, 'accumulated_eval_time': 623.5575816631317, 'accumulated_logging_time': 35.45534086227417, 'global_step': 23350, 'preemption_count': 0}), (24360, {'train/accuracy': 0.5230468511581421, 'train/loss': 2.2979137897491455, 'validation/accuracy': 0.4780399799346924, 'validation/loss': 2.5138795375823975, 'validation/num_examples': 50000, 'test/accuracy': 0.37050002813339233, 'test/loss': 3.1437458992004395, 'test/num_examples': 10000, 'score': 10131.298212528229, 'total_duration': 10818.055797338486, 'accumulated_submission_time': 10131.298212528229, 'accumulated_eval_time': 648.7376034259796, 'accumulated_logging_time': 37.559751749038696, 'global_step': 24360, 'preemption_count': 0}), (25374, {'train/accuracy': 0.5304882526397705, 'train/loss': 2.2565011978149414, 'validation/accuracy': 0.48607999086380005, 'validation/loss': 2.4824860095977783, 'validation/num_examples': 50000, 'test/accuracy': 0.37320002913475037, 'test/loss': 3.126579523086548, 'test/num_examples': 10000, 'score': 10551.384824037552, 'total_duration': 11264.117563724518, 'accumulated_submission_time': 10551.384824037552, 'accumulated_eval_time': 673.549925327301, 'accumulated_logging_time': 38.70399308204651, 'global_step': 25374, 'preemption_count': 0}), (26389, {'train/accuracy': 0.5671484470367432, 'train/loss': 2.089872360229492, 'validation/accuracy': 0.49719998240470886, 'validation/loss': 2.400921106338501, 'validation/num_examples': 50000, 'test/accuracy': 0.38600000739097595, 'test/loss': 3.049140214920044, 'test/num_examples': 10000, 'score': 10971.601137161255, 'total_duration': 11710.744876384735, 'accumulated_submission_time': 10971.601137161255, 'accumulated_eval_time': 698.8136067390442, 'accumulated_logging_time': 39.832908153533936, 'global_step': 26389, 'preemption_count': 0}), (27400, {'train/accuracy': 0.5447461009025574, 'train/loss': 2.2115330696105957, 'validation/accuracy': 0.49949997663497925, 'validation/loss': 2.416468620300293, 'validation/num_examples': 50000, 'test/accuracy': 0.39100003242492676, 'test/loss': 3.0406293869018555, 'test/num_examples': 10000, 'score': 11391.919004917145, 'total_duration': 12156.863492012024, 'accumulated_submission_time': 11391.919004917145, 'accumulated_eval_time': 723.2824618816376, 'accumulated_logging_time': 41.14699125289917, 'global_step': 27400, 'preemption_count': 0}), (28000, {'train/accuracy': 0.5612695217132568, 'train/loss': 2.1791670322418213, 'validation/accuracy': 0.5083199739456177, 'validation/loss': 2.42812442779541, 'validation/num_examples': 50000, 'test/accuracy': 0.3992000222206116, 'test/loss': 3.04585862159729, 'test/num_examples': 10000, 'score': 11640.580857515335, 'total_duration': 12431.710727930069, 'accumulated_submission_time': 11640.580857515335, 'accumulated_eval_time': 748.2318212985992, 'accumulated_logging_time': 42.37189030647278, 'global_step': 28000, 'preemption_count': 0})], 'global_step': 28000}
I0420 06:31:31.372745 140094836827968 submission_runner.py:570] Timing: 11640.580857515335
I0420 06:31:31.372810 140094836827968 submission_runner.py:571] ====================
I0420 06:31:31.372982 140094836827968 submission_runner.py:631] Final imagenet_vit score: 11640.580857515335
