I0420 06:33:36.756850 140269983426368 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax.
I0420 06:33:36.914535 140269983426368 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0420 06:33:37.848686 140269983426368 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0420 06:33:37.849614 140269983426368 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0420 06:33:37.854052 140269983426368 submission_runner.py:528] Using RNG seed 1477327536
I0420 06:33:40.546065 140269983426368 submission_runner.py:537] --- Tuning run 1/1 ---
I0420 06:33:40.546262 140269983426368 submission_runner.py:542] Creating tuning directory at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1.
I0420 06:33:40.546445 140269983426368 logger_utils.py:83] Saving hparams to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/hparams.json.
I0420 06:33:40.669731 140269983426368 submission_runner.py:232] Initializing dataset.
I0420 06:33:44.752623 140269983426368 submission_runner.py:239] Initializing model.
I0420 06:33:51.450840 140269983426368 submission_runner.py:249] Initializing optimizer.
I0420 06:33:51.888841 140269983426368 submission_runner.py:256] Initializing metrics bundle.
I0420 06:33:51.889017 140269983426368 submission_runner.py:273] Initializing checkpoint and logger.
I0420 06:33:51.891262 140269983426368 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1 with prefix checkpoint_
I0420 06:33:51.891471 140269983426368 logger_utils.py:230] Unable to record workload.train_mean information. Continuing without it.
I0420 06:33:51.891533 140269983426368 logger_utils.py:230] Unable to record workload.train_stddev information. Continuing without it.
I0420 06:33:52.633676 140269983426368 submission_runner.py:294] Saving meta data to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/meta_data_0.json.
I0420 06:33:52.634668 140269983426368 submission_runner.py:297] Saving flags to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/flags_0.json.
I0420 06:33:52.640436 140269983426368 submission_runner.py:309] Starting training loop.
I0420 06:34:55.660418 140093805291264 logging_writer.py:48] [0] global_step=0, grad_norm=4.320585250854492, loss=1.0250800848007202
I0420 06:34:55.669224 140269983426368 spec.py:298] Evaluating on the training split.
I0420 06:36:23.731827 140269983426368 spec.py:310] Evaluating on the validation split.
I0420 06:37:28.106770 140269983426368 spec.py:326] Evaluating on the test split.
I0420 06:38:29.734923 140269983426368 submission_runner.py:406] Time since start: 277.09s, 	Step: 1, 	{'train/ssim': 0.22237358774457658, 'train/loss': 1.0081768717084612, 'validation/ssim': 0.2122730433303584, 'validation/loss': 1.024953658619689, 'validation/num_examples': 3554, 'test/ssim': 0.23517962095957834, 'test/loss': 1.021425197657777, 'test/num_examples': 3581, 'score': 63.02863001823425, 'total_duration': 277.0943830013275, 'accumulated_submission_time': 63.02863001823425, 'accumulated_eval_time': 214.06560730934143, 'accumulated_logging_time': 0}
I0420 06:38:29.753082 140064814245632 logging_writer.py:48] [1] accumulated_eval_time=214.065607, accumulated_logging_time=0, accumulated_submission_time=63.028630, global_step=1, preemption_count=0, score=63.028630, test/loss=1.021425, test/num_examples=3581, test/ssim=0.235180, total_duration=277.094383, train/loss=1.008177, train/ssim=0.222374, validation/loss=1.024954, validation/num_examples=3554, validation/ssim=0.212273
I0420 06:38:29.791260 140269983426368 checkpoints.py:356] Saving checkpoint at step: 1
I0420 06:38:30.002757 140269983426368 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_1
I0420 06:38:30.003384 140269983426368 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_1.
I0420 06:38:51.540674 140064805852928 logging_writer.py:48] [100] global_step=100, grad_norm=0.2714962363243103, loss=0.24001440405845642
I0420 06:39:15.089614 140064696813312 logging_writer.py:48] [200] global_step=200, grad_norm=0.2551860809326172, loss=0.3334912061691284
I0420 06:39:38.994384 140064805852928 logging_writer.py:48] [300] global_step=300, grad_norm=0.2898341715335846, loss=0.32860425114631653
I0420 06:39:50.312415 140269983426368 spec.py:298] Evaluating on the training split.
I0420 06:39:52.312960 140269983426368 spec.py:310] Evaluating on the validation split.
I0420 06:39:53.674417 140269983426368 spec.py:326] Evaluating on the test split.
I0420 06:39:55.037508 140269983426368 submission_runner.py:406] Time since start: 362.40s, 	Step: 330, 	{'train/ssim': 0.7087178911481585, 'train/loss': 0.2989368438720703, 'validation/ssim': 0.6848020194015546, 'validation/loss': 0.32355660270557823, 'validation/num_examples': 3554, 'test/ssim': 0.7026804881667132, 'test/loss': 0.32581231128700083, 'test/num_examples': 3581, 'score': 143.33351397514343, 'total_duration': 362.3969476222992, 'accumulated_submission_time': 143.33351397514343, 'accumulated_eval_time': 218.79062390327454, 'accumulated_logging_time': 0.2686309814453125}
I0420 06:39:55.047040 140064696813312 logging_writer.py:48] [330] accumulated_eval_time=218.790624, accumulated_logging_time=0.268631, accumulated_submission_time=143.333514, global_step=330, preemption_count=0, score=143.333514, test/loss=0.325812, test/num_examples=3581, test/ssim=0.702680, total_duration=362.396948, train/loss=0.298937, train/ssim=0.708718, validation/loss=0.323557, validation/num_examples=3554, validation/ssim=0.684802
I0420 06:39:55.125123 140269983426368 checkpoints.py:356] Saving checkpoint at step: 330
I0420 06:39:55.356322 140269983426368 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_330
I0420 06:39:55.356966 140269983426368 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_330.
I0420 06:40:17.153245 140064805852928 logging_writer.py:48] [400] global_step=400, grad_norm=0.19335900247097015, loss=0.3503231108188629
I0420 06:40:55.139278 140064688420608 logging_writer.py:48] [500] global_step=500, grad_norm=0.2807515561580658, loss=0.221190944314003
I0420 06:41:15.711142 140269983426368 spec.py:298] Evaluating on the training split.
I0420 06:41:17.130898 140269983426368 spec.py:310] Evaluating on the validation split.
I0420 06:41:18.493966 140269983426368 spec.py:326] Evaluating on the test split.
I0420 06:41:19.860231 140269983426368 submission_runner.py:406] Time since start: 447.22s, 	Step: 558, 	{'train/ssim': 0.7212587084089007, 'train/loss': 0.2869987487792969, 'validation/ssim': 0.6982649254141461, 'validation/loss': 0.3106050249828538, 'validation/num_examples': 3554, 'test/ssim': 0.715526198382086, 'test/loss': 0.3130299371902053, 'test/num_examples': 3581, 'score': 223.68480491638184, 'total_duration': 447.21972370147705, 'accumulated_submission_time': 223.68480491638184, 'accumulated_eval_time': 222.93967056274414, 'accumulated_logging_time': 0.5882134437561035}
I0420 06:41:19.869094 140064805852928 logging_writer.py:48] [558] accumulated_eval_time=222.939671, accumulated_logging_time=0.588213, accumulated_submission_time=223.684805, global_step=558, preemption_count=0, score=223.684805, test/loss=0.313030, test/num_examples=3581, test/ssim=0.715526, total_duration=447.219724, train/loss=0.286999, train/ssim=0.721259, validation/loss=0.310605, validation/num_examples=3554, validation/ssim=0.698265
I0420 06:41:19.946278 140269983426368 checkpoints.py:356] Saving checkpoint at step: 558
I0420 06:41:20.194074 140269983426368 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_558
I0420 06:41:20.194634 140269983426368 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_558.
I0420 06:41:32.285137 140064688420608 logging_writer.py:48] [600] global_step=600, grad_norm=0.37458986043930054, loss=0.2884294390678406
I0420 06:42:09.330357 140060955502336 logging_writer.py:48] [700] global_step=700, grad_norm=0.396802693605423, loss=0.24255456030368805
I0420 06:42:40.325865 140269983426368 spec.py:298] Evaluating on the training split.
I0420 06:42:41.746675 140269983426368 spec.py:310] Evaluating on the validation split.
I0420 06:42:43.106714 140269983426368 spec.py:326] Evaluating on the test split.
I0420 06:42:44.468029 140269983426368 submission_runner.py:406] Time since start: 531.83s, 	Step: 784, 	{'train/ssim': 0.7251437732151577, 'train/loss': 0.2837006705147879, 'validation/ssim': 0.7018791546496905, 'validation/loss': 0.3073904953045864, 'validation/num_examples': 3554, 'test/ssim': 0.7189578024643954, 'test/loss': 0.30973997012225984, 'test/num_examples': 3581, 'score': 303.813316822052, 'total_duration': 531.827525138855, 'accumulated_submission_time': 303.813316822052, 'accumulated_eval_time': 227.08179998397827, 'accumulated_logging_time': 0.9228718280792236}
I0420 06:42:44.477925 140064688420608 logging_writer.py:48] [784] accumulated_eval_time=227.081800, accumulated_logging_time=0.922872, accumulated_submission_time=303.813317, global_step=784, preemption_count=0, score=303.813317, test/loss=0.309740, test/num_examples=3581, test/ssim=0.718958, total_duration=531.827525, train/loss=0.283701, train/ssim=0.725144, validation/loss=0.307390, validation/num_examples=3554, validation/ssim=0.701879
I0420 06:42:44.552642 140269983426368 checkpoints.py:356] Saving checkpoint at step: 784
I0420 06:42:44.773288 140269983426368 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_784
I0420 06:42:44.773854 140269983426368 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_784.
I0420 06:42:47.370584 140060955502336 logging_writer.py:48] [800] global_step=800, grad_norm=0.24037860333919525, loss=0.2186288684606552
I0420 06:43:24.444766 140039992358656 logging_writer.py:48] [900] global_step=900, grad_norm=0.24879369139671326, loss=0.2704131305217743
I0420 06:43:56.637505 140060955502336 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.18142934143543243, loss=0.2057311236858368
I0420 06:44:04.915327 140269983426368 spec.py:298] Evaluating on the training split.
I0420 06:44:06.331386 140269983426368 spec.py:310] Evaluating on the validation split.
I0420 06:44:07.696420 140269983426368 spec.py:326] Evaluating on the test split.
I0420 06:44:09.058555 140269983426368 submission_runner.py:406] Time since start: 616.42s, 	Step: 1036, 	{'train/ssim': 0.7320364543369838, 'train/loss': 0.28047687666756765, 'validation/ssim': 0.709623097434229, 'validation/loss': 0.3037673701177371, 'validation/num_examples': 3554, 'test/ssim': 0.7262585002661617, 'test/loss': 0.30614729867704554, 'test/num_examples': 3581, 'score': 383.9516577720642, 'total_duration': 616.418051481247, 'accumulated_submission_time': 383.9516577720642, 'accumulated_eval_time': 231.22499299049377, 'accumulated_logging_time': 1.228916883468628}
I0420 06:44:09.066528 140039992358656 logging_writer.py:48] [1036] accumulated_eval_time=231.224993, accumulated_logging_time=1.228917, accumulated_submission_time=383.951658, global_step=1036, preemption_count=0, score=383.951658, test/loss=0.306147, test/num_examples=3581, test/ssim=0.726259, total_duration=616.418051, train/loss=0.280477, train/ssim=0.732036, validation/loss=0.303767, validation/num_examples=3554, validation/ssim=0.709623
I0420 06:44:09.119142 140269983426368 checkpoints.py:356] Saving checkpoint at step: 1036
I0420 06:44:09.324840 140269983426368 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_1036
I0420 06:44:09.325332 140269983426368 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_1036.
I0420 06:44:22.499634 140060955502336 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.13957835733890533, loss=0.3340213894844055
I0420 06:44:45.580047 140021344487168 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.0965486615896225, loss=0.2328561395406723
I0420 06:45:09.022888 140060955502336 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.264561265707016, loss=0.3116079568862915
I0420 06:45:29.327332 140269983426368 spec.py:298] Evaluating on the training split.
I0420 06:45:30.746496 140269983426368 spec.py:310] Evaluating on the validation split.
I0420 06:45:32.106007 140269983426368 spec.py:326] Evaluating on the test split.
I0420 06:45:33.473565 140269983426368 submission_runner.py:406] Time since start: 700.83s, 	Step: 1388, 	{'train/ssim': 0.734501838684082, 'train/loss': 0.275228704724993, 'validation/ssim': 0.7106316716200056, 'validation/loss': 0.2988583849733575, 'validation/num_examples': 3554, 'test/ssim': 0.7276623259040771, 'test/loss': 0.3009730991255934, 'test/num_examples': 3581, 'score': 463.94929599761963, 'total_duration': 700.8330421447754, 'accumulated_submission_time': 463.94929599761963, 'accumulated_eval_time': 235.37118077278137, 'accumulated_logging_time': 1.495898723602295}
I0420 06:45:33.481663 140021344487168 logging_writer.py:48] [1388] accumulated_eval_time=235.371181, accumulated_logging_time=1.495899, accumulated_submission_time=463.949296, global_step=1388, preemption_count=0, score=463.949296, test/loss=0.300973, test/num_examples=3581, test/ssim=0.727662, total_duration=700.833042, train/loss=0.275229, train/ssim=0.734502, validation/loss=0.298858, validation/num_examples=3554, validation/ssim=0.710632
I0420 06:45:33.520761 140269983426368 checkpoints.py:356] Saving checkpoint at step: 1388
I0420 06:45:33.714704 140269983426368 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_1388
I0420 06:45:33.715232 140269983426368 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_1388.
I0420 06:45:34.671101 140060955502336 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.1467401683330536, loss=0.2967461943626404
I0420 06:45:58.044161 140021182867200 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.38078975677490234, loss=0.28393134474754333
I0420 06:46:21.703461 140060955502336 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.14055372774600983, loss=0.23405934870243073
I0420 06:46:45.214911 140021182867200 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.1166355088353157, loss=0.34055590629577637
I0420 06:46:53.770560 140269983426368 spec.py:298] Evaluating on the training split.
I0420 06:46:55.189358 140269983426368 spec.py:310] Evaluating on the validation split.
I0420 06:46:56.555947 140269983426368 spec.py:326] Evaluating on the test split.
I0420 06:46:57.919259 140269983426368 submission_runner.py:406] Time since start: 785.28s, 	Step: 1738, 	{'train/ssim': 0.7278127670288086, 'train/loss': 0.27640909808022635, 'validation/ssim': 0.7069100727173607, 'validation/loss': 0.29943026755724184, 'validation/num_examples': 3554, 'test/ssim': 0.7233564924907497, 'test/loss': 0.30136562625445057, 'test/num_examples': 3581, 'score': 544.0002746582031, 'total_duration': 785.2787530422211, 'accumulated_submission_time': 544.0002746582031, 'accumulated_eval_time': 239.51984572410583, 'accumulated_logging_time': 1.7377841472625732}
I0420 06:46:57.927175 140060955502336 logging_writer.py:48] [1738] accumulated_eval_time=239.519846, accumulated_logging_time=1.737784, accumulated_submission_time=544.000275, global_step=1738, preemption_count=0, score=544.000275, test/loss=0.301366, test/num_examples=3581, test/ssim=0.723356, total_duration=785.278753, train/loss=0.276409, train/ssim=0.727813, validation/loss=0.299430, validation/num_examples=3554, validation/ssim=0.706910
I0420 06:46:57.964257 140269983426368 checkpoints.py:356] Saving checkpoint at step: 1738
I0420 06:46:58.157897 140269983426368 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_1738
I0420 06:46:58.158382 140269983426368 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_1738.
I0420 06:47:10.755201 140021182867200 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.10980004817247391, loss=0.19743436574935913
I0420 06:47:34.508497 140021076051712 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.13664178550243378, loss=0.30491364002227783
I0420 06:47:58.457931 140021182867200 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.14185257256031036, loss=0.41889262199401855
I0420 06:48:18.413074 140269983426368 spec.py:298] Evaluating on the training split.
I0420 06:48:19.833039 140269983426368 spec.py:310] Evaluating on the validation split.
I0420 06:48:21.197022 140269983426368 spec.py:326] Evaluating on the test split.
I0420 06:48:22.559437 140269983426368 submission_runner.py:406] Time since start: 869.92s, 	Step: 2084, 	{'train/ssim': 0.7402248382568359, 'train/loss': 0.2711426871163504, 'validation/ssim': 0.7160981821758934, 'validation/loss': 0.2950582337902715, 'validation/num_examples': 3554, 'test/ssim': 0.7333602585695337, 'test/loss': 0.29665628926975707, 'test/num_examples': 3581, 'score': 624.2505633831024, 'total_duration': 869.9189350605011, 'accumulated_submission_time': 624.2505633831024, 'accumulated_eval_time': 243.6661822795868, 'accumulated_logging_time': 1.9771230220794678}
I0420 06:48:22.567238 140021076051712 logging_writer.py:48] [2084] accumulated_eval_time=243.666182, accumulated_logging_time=1.977123, accumulated_submission_time=624.250563, global_step=2084, preemption_count=0, score=624.250563, test/loss=0.296656, test/num_examples=3581, test/ssim=0.733360, total_duration=869.918935, train/loss=0.271143, train/ssim=0.740225, validation/loss=0.295058, validation/num_examples=3554, validation/ssim=0.716098
I0420 06:48:22.603916 140269983426368 checkpoints.py:356] Saving checkpoint at step: 2084
I0420 06:48:22.796802 140269983426368 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_2084
I0420 06:48:22.797307 140269983426368 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_2084.
I0420 06:48:24.593186 140021182867200 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.09758240729570389, loss=0.3322621285915375
I0420 06:48:48.182360 140021067659008 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.3941986858844757, loss=0.31490200757980347
I0420 06:49:12.097631 140021182867200 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.2609277069568634, loss=0.33513855934143066
I0420 06:49:35.457907 140021067659008 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.0778234675526619, loss=0.255987286567688
I0420 06:49:42.824485 140269983426368 spec.py:298] Evaluating on the training split.
I0420 06:49:44.246173 140269983426368 spec.py:310] Evaluating on the validation split.
I0420 06:49:45.613518 140269983426368 spec.py:326] Evaluating on the test split.
I0420 06:49:46.979222 140269983426368 submission_runner.py:406] Time since start: 954.34s, 	Step: 2433, 	{'train/ssim': 0.7395342418125698, 'train/loss': 0.2706655434199742, 'validation/ssim': 0.7152826398292417, 'validation/loss': 0.2945360517528665, 'validation/num_examples': 3554, 'test/ssim': 0.732353084748499, 'test/loss': 0.29622132216908686, 'test/num_examples': 3581, 'score': 704.2732915878296, 'total_duration': 954.3387186527252, 'accumulated_submission_time': 704.2732915878296, 'accumulated_eval_time': 247.82087802886963, 'accumulated_logging_time': 2.2151942253112793}
I0420 06:49:46.988322 140021182867200 logging_writer.py:48] [2433] accumulated_eval_time=247.820878, accumulated_logging_time=2.215194, accumulated_submission_time=704.273292, global_step=2433, preemption_count=0, score=704.273292, test/loss=0.296221, test/num_examples=3581, test/ssim=0.732353, total_duration=954.338719, train/loss=0.270666, train/ssim=0.739534, validation/loss=0.294536, validation/num_examples=3554, validation/ssim=0.715283
I0420 06:49:47.025672 140269983426368 checkpoints.py:356] Saving checkpoint at step: 2433
I0420 06:49:47.219073 140269983426368 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_2433
I0420 06:49:47.219571 140269983426368 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_2433.
I0420 06:50:00.911340 140021067659008 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.10383698344230652, loss=0.314399391412735
I0420 06:50:24.587730 140021059266304 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.11924820393323898, loss=0.31498855352401733
I0420 06:50:48.156629 140021067659008 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.11946076154708862, loss=0.2760540246963501
I0420 06:51:07.220661 140269983426368 spec.py:298] Evaluating on the training split.
I0420 06:51:08.637043 140269983426368 spec.py:310] Evaluating on the validation split.
I0420 06:51:10.000460 140269983426368 spec.py:326] Evaluating on the test split.
I0420 06:51:11.364708 140269983426368 submission_runner.py:406] Time since start: 1038.72s, 	Step: 2782, 	{'train/ssim': 0.7421323912484306, 'train/loss': 0.2686373506273542, 'validation/ssim': 0.7184971351602069, 'validation/loss': 0.2920898368805395, 'validation/num_examples': 3554, 'test/ssim': 0.7356256326794192, 'test/loss': 0.29369970607677676, 'test/num_examples': 3581, 'score': 784.2697751522064, 'total_duration': 1038.7242033481598, 'accumulated_submission_time': 784.2697751522064, 'accumulated_eval_time': 251.96490049362183, 'accumulated_logging_time': 2.455798864364624}
I0420 06:51:11.372790 140021059266304 logging_writer.py:48] [2782] accumulated_eval_time=251.964900, accumulated_logging_time=2.455799, accumulated_submission_time=784.269775, global_step=2782, preemption_count=0, score=784.269775, test/loss=0.293700, test/num_examples=3581, test/ssim=0.735626, total_duration=1038.724203, train/loss=0.268637, train/ssim=0.742132, validation/loss=0.292090, validation/num_examples=3554, validation/ssim=0.718497
I0420 06:51:11.409866 140269983426368 checkpoints.py:356] Saving checkpoint at step: 2782
I0420 06:51:11.601768 140269983426368 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_2782
I0420 06:51:11.602261 140269983426368 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_2782.
I0420 06:51:13.856907 140021067659008 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.197332501411438, loss=0.34894517064094543
I0420 06:51:37.487520 140021050873600 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.159428671002388, loss=0.23084327578544617
I0420 06:52:01.159288 140021067659008 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.11111963540315628, loss=0.3107936680316925
I0420 06:52:24.833970 140021050873600 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.18288740515708923, loss=0.27717602252960205
I0420 06:52:31.619252 140269983426368 spec.py:298] Evaluating on the training split.
I0420 06:52:33.039937 140269983426368 spec.py:310] Evaluating on the validation split.
I0420 06:52:34.400854 140269983426368 spec.py:326] Evaluating on the test split.
I0420 06:52:35.768795 140269983426368 submission_runner.py:406] Time since start: 1123.13s, 	Step: 3129, 	{'train/ssim': 0.7419440405709403, 'train/loss': 0.26812493801116943, 'validation/ssim': 0.7176237519564224, 'validation/loss': 0.29175920974825903, 'validation/num_examples': 3554, 'test/ssim': 0.7348199208932561, 'test/loss': 0.2934406006745672, 'test/num_examples': 3581, 'score': 864.2824242115021, 'total_duration': 1123.1282923221588, 'accumulated_submission_time': 864.2824242115021, 'accumulated_eval_time': 256.11439847946167, 'accumulated_logging_time': 2.6936118602752686}
I0420 06:52:35.776840 140021067659008 logging_writer.py:48] [3129] accumulated_eval_time=256.114398, accumulated_logging_time=2.693612, accumulated_submission_time=864.282424, global_step=3129, preemption_count=0, score=864.282424, test/loss=0.293441, test/num_examples=3581, test/ssim=0.734820, total_duration=1123.128292, train/loss=0.268125, train/ssim=0.741944, validation/loss=0.291759, validation/num_examples=3554, validation/ssim=0.717624
I0420 06:52:35.813817 140269983426368 checkpoints.py:356] Saving checkpoint at step: 3129
I0420 06:52:36.004692 140269983426368 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_3129
I0420 06:52:36.005242 140269983426368 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_3129.
I0420 06:52:50.701896 140021050873600 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.08356094360351562, loss=0.2401907742023468
I0420 06:53:14.191324 140020967012096 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.25077927112579346, loss=0.24027594923973083
I0420 06:53:37.686253 140021050873600 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.08033492416143417, loss=0.2873585522174835
I0420 06:53:56.136758 140269983426368 spec.py:298] Evaluating on the training split.
I0420 06:53:57.554875 140269983426368 spec.py:310] Evaluating on the validation split.
I0420 06:53:58.919491 140269983426368 spec.py:326] Evaluating on the test split.
I0420 06:54:00.283467 140269983426368 submission_runner.py:406] Time since start: 1207.64s, 	Step: 3479, 	{'train/ssim': 0.7430182184491839, 'train/loss': 0.2667991944721767, 'validation/ssim': 0.7188471341710045, 'validation/loss': 0.29044518500281374, 'validation/num_examples': 3554, 'test/ssim': 0.7360002634346202, 'test/loss': 0.2921262228166015, 'test/num_examples': 3581, 'score': 944.4095344543457, 'total_duration': 1207.642961025238, 'accumulated_submission_time': 944.4095344543457, 'accumulated_eval_time': 260.2610650062561, 'accumulated_logging_time': 2.9303038120269775}
I0420 06:54:00.292264 140020967012096 logging_writer.py:48] [3479] accumulated_eval_time=260.261065, accumulated_logging_time=2.930304, accumulated_submission_time=944.409534, global_step=3479, preemption_count=0, score=944.409534, test/loss=0.292126, test/num_examples=3581, test/ssim=0.736000, total_duration=1207.642961, train/loss=0.266799, train/ssim=0.743018, validation/loss=0.290445, validation/num_examples=3554, validation/ssim=0.718847
I0420 06:54:00.325453 140269983426368 checkpoints.py:356] Saving checkpoint at step: 3479
I0420 06:54:00.574472 140269983426368 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_3479
I0420 06:54:00.575094 140269983426368 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_3479.
I0420 06:54:03.455743 140021050873600 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.1041380763053894, loss=0.34276536107063293
I0420 06:54:27.184383 140020958619392 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.08004659414291382, loss=0.27563974261283875
I0420 06:54:50.555277 140021050873600 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.05881639942526817, loss=0.23802705109119415
I0420 06:55:14.131461 140020958619392 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.09098362177610397, loss=0.24349445104599
I0420 06:55:20.680955 140269983426368 spec.py:298] Evaluating on the training split.
I0420 06:55:22.101989 140269983426368 spec.py:310] Evaluating on the validation split.
I0420 06:55:23.467297 140269983426368 spec.py:326] Evaluating on the test split.
I0420 06:55:24.836662 140269983426368 submission_runner.py:406] Time since start: 1292.20s, 	Step: 3829, 	{'train/ssim': 0.7389513424464634, 'train/loss': 0.2685278994696481, 'validation/ssim': 0.7157819122159891, 'validation/loss': 0.29178778670380207, 'validation/num_examples': 3554, 'test/ssim': 0.733137729946244, 'test/loss': 0.293279567399993, 'test/num_examples': 3581, 'score': 1024.510910987854, 'total_duration': 1292.1961581707, 'accumulated_submission_time': 1024.510910987854, 'accumulated_eval_time': 264.4167368412018, 'accumulated_logging_time': 3.222219467163086}
I0420 06:55:24.844857 140021050873600 logging_writer.py:48] [3829] accumulated_eval_time=264.416737, accumulated_logging_time=3.222219, accumulated_submission_time=1024.510911, global_step=3829, preemption_count=0, score=1024.510911, test/loss=0.293280, test/num_examples=3581, test/ssim=0.733138, total_duration=1292.196158, train/loss=0.268528, train/ssim=0.738951, validation/loss=0.291788, validation/num_examples=3554, validation/ssim=0.715782
I0420 06:55:24.881514 140269983426368 checkpoints.py:356] Saving checkpoint at step: 3829
I0420 06:55:25.076792 140269983426368 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_3829
I0420 06:55:25.077291 140269983426368 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_3829.
I0420 06:55:39.384755 140020958619392 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.13781072199344635, loss=0.2641986906528473
I0420 06:56:02.951854 140020950226688 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.4386913776397705, loss=0.21663892269134521
I0420 06:56:26.566848 140020958619392 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.0609431117773056, loss=0.3794535994529724
I0420 06:56:45.269036 140269983426368 spec.py:298] Evaluating on the training split.
I0420 06:56:46.687181 140269983426368 spec.py:310] Evaluating on the validation split.
I0420 06:56:48.054380 140269983426368 spec.py:326] Evaluating on the test split.
I0420 06:56:49.424656 140269983426368 submission_runner.py:406] Time since start: 1376.78s, 	Step: 4180, 	{'train/ssim': 0.743509156363351, 'train/loss': 0.26638451644352507, 'validation/ssim': 0.7193884476558103, 'validation/loss': 0.2901254116180712, 'validation/num_examples': 3554, 'test/ssim': 0.7366640314114423, 'test/loss': 0.29160351235252024, 'test/num_examples': 3581, 'score': 1104.6982884407043, 'total_duration': 1376.7841517925262, 'accumulated_submission_time': 1104.6982884407043, 'accumulated_eval_time': 268.5723156929016, 'accumulated_logging_time': 3.4630513191223145}
I0420 06:56:49.433133 140020950226688 logging_writer.py:48] [4180] accumulated_eval_time=268.572316, accumulated_logging_time=3.463051, accumulated_submission_time=1104.698288, global_step=4180, preemption_count=0, score=1104.698288, test/loss=0.291604, test/num_examples=3581, test/ssim=0.736664, total_duration=1376.784152, train/loss=0.266385, train/ssim=0.743509, validation/loss=0.290125, validation/num_examples=3554, validation/ssim=0.719388
I0420 06:56:49.470090 140269983426368 checkpoints.py:356] Saving checkpoint at step: 4180
I0420 06:56:49.665131 140269983426368 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_4180
I0420 06:56:49.665600 140269983426368 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_4180.
I0420 06:56:52.311224 140020958619392 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.08737949281930923, loss=0.2575552463531494
I0420 06:57:16.055042 140020941833984 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.09371981024742126, loss=0.4021419584751129
I0420 06:57:39.584509 140020958619392 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.10694310814142227, loss=0.31627723574638367
I0420 06:58:03.120732 140020941833984 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.19221945106983185, loss=0.29186147451400757
I0420 06:58:09.746703 140269983426368 spec.py:298] Evaluating on the training split.
I0420 06:58:11.163853 140269983426368 spec.py:310] Evaluating on the validation split.
I0420 06:58:12.533087 140269983426368 spec.py:326] Evaluating on the test split.
I0420 06:58:13.901750 140269983426368 submission_runner.py:406] Time since start: 1461.26s, 	Step: 4530, 	{'train/ssim': 0.7472671100071498, 'train/loss': 0.26527861186436247, 'validation/ssim': 0.7225720304146737, 'validation/loss': 0.2896819879449212, 'validation/num_examples': 3554, 'test/ssim': 0.7395939916180885, 'test/loss': 0.2912728214556863, 'test/num_examples': 3581, 'score': 1184.7749314308167, 'total_duration': 1461.2612402439117, 'accumulated_submission_time': 1184.7749314308167, 'accumulated_eval_time': 272.727331161499, 'accumulated_logging_time': 3.7042057514190674}
I0420 06:58:13.909930 140020958619392 logging_writer.py:48] [4530] accumulated_eval_time=272.727331, accumulated_logging_time=3.704206, accumulated_submission_time=1184.774931, global_step=4530, preemption_count=0, score=1184.774931, test/loss=0.291273, test/num_examples=3581, test/ssim=0.739594, total_duration=1461.261240, train/loss=0.265279, train/ssim=0.747267, validation/loss=0.289682, validation/num_examples=3554, validation/ssim=0.722572
I0420 06:58:13.946934 140269983426368 checkpoints.py:356] Saving checkpoint at step: 4530
I0420 06:58:14.139788 140269983426368 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_4530
I0420 06:58:14.140314 140269983426368 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_4530.
I0420 06:58:28.532293 140020941833984 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.21088145673274994, loss=0.27226951718330383
I0420 06:58:51.965672 140020933441280 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.07203400880098343, loss=0.25683853030204773
I0420 06:59:15.536041 140020941833984 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.14165881276130676, loss=0.22800543904304504
I0420 06:59:34.276583 140269983426368 spec.py:298] Evaluating on the training split.
I0420 06:59:35.695436 140269983426368 spec.py:310] Evaluating on the validation split.
I0420 06:59:37.060703 140269983426368 spec.py:326] Evaluating on the test split.
I0420 06:59:38.426295 140269983426368 submission_runner.py:406] Time since start: 1545.79s, 	Step: 4880, 	{'train/ssim': 0.7455227715628487, 'train/loss': 0.2655775376728603, 'validation/ssim': 0.720841063766179, 'validation/loss': 0.2896425572418402, 'validation/num_examples': 3554, 'test/ssim': 0.7380642436862958, 'test/loss': 0.2912220298428337, 'test/num_examples': 3581, 'score': 1264.9068269729614, 'total_duration': 1545.785789012909, 'accumulated_submission_time': 1264.9068269729614, 'accumulated_eval_time': 276.8770022392273, 'accumulated_logging_time': 3.9429640769958496}
I0420 06:59:38.434683 140020933441280 logging_writer.py:48] [4880] accumulated_eval_time=276.877002, accumulated_logging_time=3.942964, accumulated_submission_time=1264.906827, global_step=4880, preemption_count=0, score=1264.906827, test/loss=0.291222, test/num_examples=3581, test/ssim=0.738064, total_duration=1545.785789, train/loss=0.265578, train/ssim=0.745523, validation/loss=0.289643, validation/num_examples=3554, validation/ssim=0.720841
I0420 06:59:38.471380 140269983426368 checkpoints.py:356] Saving checkpoint at step: 4880
I0420 06:59:38.664783 140269983426368 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_4880
I0420 06:59:38.665251 140269983426368 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_4880.
I0420 06:59:41.381838 140020941833984 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.0336027629673481, loss=0.2741244435310364
I0420 07:00:05.041471 140020925048576 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.14678546786308289, loss=0.34598609805107117
I0420 07:00:28.445103 140020941833984 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.1479046493768692, loss=0.25050079822540283
I0420 07:00:52.178320 140020925048576 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.08380492031574249, loss=0.2317296862602234
I0420 07:00:58.666227 140269983426368 spec.py:298] Evaluating on the training split.
I0420 07:01:00.085368 140269983426368 spec.py:310] Evaluating on the validation split.
I0420 07:01:01.457418 140269983426368 spec.py:326] Evaluating on the test split.
I0420 07:01:02.820493 140269983426368 submission_runner.py:406] Time since start: 1630.18s, 	Step: 5228, 	{'train/ssim': 0.7440733909606934, 'train/loss': 0.2657365117754255, 'validation/ssim': 0.7208659999076744, 'validation/loss': 0.28932113518658553, 'validation/num_examples': 3554, 'test/ssim': 0.7377862874371683, 'test/loss': 0.2908787944402751, 'test/num_examples': 3581, 'score': 1344.9032814502716, 'total_duration': 1630.1799845695496, 'accumulated_submission_time': 1344.9032814502716, 'accumulated_eval_time': 281.0312626361847, 'accumulated_logging_time': 4.182111740112305}
I0420 07:01:02.828861 140020941833984 logging_writer.py:48] [5228] accumulated_eval_time=281.031263, accumulated_logging_time=4.182112, accumulated_submission_time=1344.903281, global_step=5228, preemption_count=0, score=1344.903281, test/loss=0.290879, test/num_examples=3581, test/ssim=0.737786, total_duration=1630.179985, train/loss=0.265737, train/ssim=0.744073, validation/loss=0.289321, validation/num_examples=3554, validation/ssim=0.720866
I0420 07:01:02.865954 140269983426368 checkpoints.py:356] Saving checkpoint at step: 5228
I0420 07:01:03.061089 140269983426368 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_5228
I0420 07:01:03.061586 140269983426368 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_5228.
I0420 07:01:18.460303 140020925048576 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.16330938041210175, loss=0.27239570021629333
I0420 07:01:42.064910 140021092837120 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.03899896889925003, loss=0.37170130014419556
I0420 07:01:48.402661 140269983426368 spec.py:298] Evaluating on the training split.
I0420 07:01:49.824556 140269983426368 spec.py:310] Evaluating on the validation split.
I0420 07:01:51.186938 140269983426368 spec.py:326] Evaluating on the test split.
I0420 07:01:52.551984 140269983426368 submission_runner.py:406] Time since start: 1679.91s, 	Step: 5428, 	{'train/ssim': 0.74585907799857, 'train/loss': 0.26501435892922537, 'validation/ssim': 0.72212311117315, 'validation/loss': 0.28872672077236916, 'validation/num_examples': 3554, 'test/ssim': 0.7391971352712231, 'test/loss': 0.29021976474143046, 'test/num_examples': 3581, 'score': 1390.2416779994965, 'total_duration': 1679.9114792346954, 'accumulated_submission_time': 1390.2416779994965, 'accumulated_eval_time': 285.18053793907166, 'accumulated_logging_time': 4.423405170440674}
I0420 07:01:52.561434 140020925048576 logging_writer.py:48] [5428] accumulated_eval_time=285.180538, accumulated_logging_time=4.423405, accumulated_submission_time=1390.241678, global_step=5428, preemption_count=0, score=1390.241678, test/loss=0.290220, test/num_examples=3581, test/ssim=0.739197, total_duration=1679.911479, train/loss=0.265014, train/ssim=0.745859, validation/loss=0.288727, validation/num_examples=3554, validation/ssim=0.722123
I0420 07:01:52.599084 140269983426368 checkpoints.py:356] Saving checkpoint at step: 5428
I0420 07:01:52.795495 140269983426368 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_5428
I0420 07:01:52.795993 140269983426368 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_5428.
I0420 07:01:52.803452 140021092837120 logging_writer.py:48] [5428] global_step=5428, preemption_count=0, score=1390.241678
I0420 07:01:52.835478 140269983426368 checkpoints.py:356] Saving checkpoint at step: 5428
I0420 07:01:53.123756 140269983426368 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_5428
I0420 07:01:53.124231 140269983426368 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_adamw/fastmri_jax/trial_1/checkpoint_5428.
I0420 07:01:53.724056 140269983426368 submission_runner.py:567] Tuning trial 1/1
I0420 07:01:53.724265 140269983426368 submission_runner.py:568] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0420 07:01:53.729316 140269983426368 submission_runner.py:569] Metrics: {'eval_results': [(1, {'train/ssim': 0.22237358774457658, 'train/loss': 1.0081768717084612, 'validation/ssim': 0.2122730433303584, 'validation/loss': 1.024953658619689, 'validation/num_examples': 3554, 'test/ssim': 0.23517962095957834, 'test/loss': 1.021425197657777, 'test/num_examples': 3581, 'score': 63.02863001823425, 'total_duration': 277.0943830013275, 'accumulated_submission_time': 63.02863001823425, 'accumulated_eval_time': 214.06560730934143, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (330, {'train/ssim': 0.7087178911481585, 'train/loss': 0.2989368438720703, 'validation/ssim': 0.6848020194015546, 'validation/loss': 0.32355660270557823, 'validation/num_examples': 3554, 'test/ssim': 0.7026804881667132, 'test/loss': 0.32581231128700083, 'test/num_examples': 3581, 'score': 143.33351397514343, 'total_duration': 362.3969476222992, 'accumulated_submission_time': 143.33351397514343, 'accumulated_eval_time': 218.79062390327454, 'accumulated_logging_time': 0.2686309814453125, 'global_step': 330, 'preemption_count': 0}), (558, {'train/ssim': 0.7212587084089007, 'train/loss': 0.2869987487792969, 'validation/ssim': 0.6982649254141461, 'validation/loss': 0.3106050249828538, 'validation/num_examples': 3554, 'test/ssim': 0.715526198382086, 'test/loss': 0.3130299371902053, 'test/num_examples': 3581, 'score': 223.68480491638184, 'total_duration': 447.21972370147705, 'accumulated_submission_time': 223.68480491638184, 'accumulated_eval_time': 222.93967056274414, 'accumulated_logging_time': 0.5882134437561035, 'global_step': 558, 'preemption_count': 0}), (784, {'train/ssim': 0.7251437732151577, 'train/loss': 0.2837006705147879, 'validation/ssim': 0.7018791546496905, 'validation/loss': 0.3073904953045864, 'validation/num_examples': 3554, 'test/ssim': 0.7189578024643954, 'test/loss': 0.30973997012225984, 'test/num_examples': 3581, 'score': 303.813316822052, 'total_duration': 531.827525138855, 'accumulated_submission_time': 303.813316822052, 'accumulated_eval_time': 227.08179998397827, 'accumulated_logging_time': 0.9228718280792236, 'global_step': 784, 'preemption_count': 0}), (1036, {'train/ssim': 0.7320364543369838, 'train/loss': 0.28047687666756765, 'validation/ssim': 0.709623097434229, 'validation/loss': 0.3037673701177371, 'validation/num_examples': 3554, 'test/ssim': 0.7262585002661617, 'test/loss': 0.30614729867704554, 'test/num_examples': 3581, 'score': 383.9516577720642, 'total_duration': 616.418051481247, 'accumulated_submission_time': 383.9516577720642, 'accumulated_eval_time': 231.22499299049377, 'accumulated_logging_time': 1.228916883468628, 'global_step': 1036, 'preemption_count': 0}), (1388, {'train/ssim': 0.734501838684082, 'train/loss': 0.275228704724993, 'validation/ssim': 0.7106316716200056, 'validation/loss': 0.2988583849733575, 'validation/num_examples': 3554, 'test/ssim': 0.7276623259040771, 'test/loss': 0.3009730991255934, 'test/num_examples': 3581, 'score': 463.94929599761963, 'total_duration': 700.8330421447754, 'accumulated_submission_time': 463.94929599761963, 'accumulated_eval_time': 235.37118077278137, 'accumulated_logging_time': 1.495898723602295, 'global_step': 1388, 'preemption_count': 0}), (1738, {'train/ssim': 0.7278127670288086, 'train/loss': 0.27640909808022635, 'validation/ssim': 0.7069100727173607, 'validation/loss': 0.29943026755724184, 'validation/num_examples': 3554, 'test/ssim': 0.7233564924907497, 'test/loss': 0.30136562625445057, 'test/num_examples': 3581, 'score': 544.0002746582031, 'total_duration': 785.2787530422211, 'accumulated_submission_time': 544.0002746582031, 'accumulated_eval_time': 239.51984572410583, 'accumulated_logging_time': 1.7377841472625732, 'global_step': 1738, 'preemption_count': 0}), (2084, {'train/ssim': 0.7402248382568359, 'train/loss': 0.2711426871163504, 'validation/ssim': 0.7160981821758934, 'validation/loss': 0.2950582337902715, 'validation/num_examples': 3554, 'test/ssim': 0.7333602585695337, 'test/loss': 0.29665628926975707, 'test/num_examples': 3581, 'score': 624.2505633831024, 'total_duration': 869.9189350605011, 'accumulated_submission_time': 624.2505633831024, 'accumulated_eval_time': 243.6661822795868, 'accumulated_logging_time': 1.9771230220794678, 'global_step': 2084, 'preemption_count': 0}), (2433, {'train/ssim': 0.7395342418125698, 'train/loss': 0.2706655434199742, 'validation/ssim': 0.7152826398292417, 'validation/loss': 0.2945360517528665, 'validation/num_examples': 3554, 'test/ssim': 0.732353084748499, 'test/loss': 0.29622132216908686, 'test/num_examples': 3581, 'score': 704.2732915878296, 'total_duration': 954.3387186527252, 'accumulated_submission_time': 704.2732915878296, 'accumulated_eval_time': 247.82087802886963, 'accumulated_logging_time': 2.2151942253112793, 'global_step': 2433, 'preemption_count': 0}), (2782, {'train/ssim': 0.7421323912484306, 'train/loss': 0.2686373506273542, 'validation/ssim': 0.7184971351602069, 'validation/loss': 0.2920898368805395, 'validation/num_examples': 3554, 'test/ssim': 0.7356256326794192, 'test/loss': 0.29369970607677676, 'test/num_examples': 3581, 'score': 784.2697751522064, 'total_duration': 1038.7242033481598, 'accumulated_submission_time': 784.2697751522064, 'accumulated_eval_time': 251.96490049362183, 'accumulated_logging_time': 2.455798864364624, 'global_step': 2782, 'preemption_count': 0}), (3129, {'train/ssim': 0.7419440405709403, 'train/loss': 0.26812493801116943, 'validation/ssim': 0.7176237519564224, 'validation/loss': 0.29175920974825903, 'validation/num_examples': 3554, 'test/ssim': 0.7348199208932561, 'test/loss': 0.2934406006745672, 'test/num_examples': 3581, 'score': 864.2824242115021, 'total_duration': 1123.1282923221588, 'accumulated_submission_time': 864.2824242115021, 'accumulated_eval_time': 256.11439847946167, 'accumulated_logging_time': 2.6936118602752686, 'global_step': 3129, 'preemption_count': 0}), (3479, {'train/ssim': 0.7430182184491839, 'train/loss': 0.2667991944721767, 'validation/ssim': 0.7188471341710045, 'validation/loss': 0.29044518500281374, 'validation/num_examples': 3554, 'test/ssim': 0.7360002634346202, 'test/loss': 0.2921262228166015, 'test/num_examples': 3581, 'score': 944.4095344543457, 'total_duration': 1207.642961025238, 'accumulated_submission_time': 944.4095344543457, 'accumulated_eval_time': 260.2610650062561, 'accumulated_logging_time': 2.9303038120269775, 'global_step': 3479, 'preemption_count': 0}), (3829, {'train/ssim': 0.7389513424464634, 'train/loss': 0.2685278994696481, 'validation/ssim': 0.7157819122159891, 'validation/loss': 0.29178778670380207, 'validation/num_examples': 3554, 'test/ssim': 0.733137729946244, 'test/loss': 0.293279567399993, 'test/num_examples': 3581, 'score': 1024.510910987854, 'total_duration': 1292.1961581707, 'accumulated_submission_time': 1024.510910987854, 'accumulated_eval_time': 264.4167368412018, 'accumulated_logging_time': 3.222219467163086, 'global_step': 3829, 'preemption_count': 0}), (4180, {'train/ssim': 0.743509156363351, 'train/loss': 0.26638451644352507, 'validation/ssim': 0.7193884476558103, 'validation/loss': 0.2901254116180712, 'validation/num_examples': 3554, 'test/ssim': 0.7366640314114423, 'test/loss': 0.29160351235252024, 'test/num_examples': 3581, 'score': 1104.6982884407043, 'total_duration': 1376.7841517925262, 'accumulated_submission_time': 1104.6982884407043, 'accumulated_eval_time': 268.5723156929016, 'accumulated_logging_time': 3.4630513191223145, 'global_step': 4180, 'preemption_count': 0}), (4530, {'train/ssim': 0.7472671100071498, 'train/loss': 0.26527861186436247, 'validation/ssim': 0.7225720304146737, 'validation/loss': 0.2896819879449212, 'validation/num_examples': 3554, 'test/ssim': 0.7395939916180885, 'test/loss': 0.2912728214556863, 'test/num_examples': 3581, 'score': 1184.7749314308167, 'total_duration': 1461.2612402439117, 'accumulated_submission_time': 1184.7749314308167, 'accumulated_eval_time': 272.727331161499, 'accumulated_logging_time': 3.7042057514190674, 'global_step': 4530, 'preemption_count': 0}), (4880, {'train/ssim': 0.7455227715628487, 'train/loss': 0.2655775376728603, 'validation/ssim': 0.720841063766179, 'validation/loss': 0.2896425572418402, 'validation/num_examples': 3554, 'test/ssim': 0.7380642436862958, 'test/loss': 0.2912220298428337, 'test/num_examples': 3581, 'score': 1264.9068269729614, 'total_duration': 1545.785789012909, 'accumulated_submission_time': 1264.9068269729614, 'accumulated_eval_time': 276.8770022392273, 'accumulated_logging_time': 3.9429640769958496, 'global_step': 4880, 'preemption_count': 0}), (5228, {'train/ssim': 0.7440733909606934, 'train/loss': 0.2657365117754255, 'validation/ssim': 0.7208659999076744, 'validation/loss': 0.28932113518658553, 'validation/num_examples': 3554, 'test/ssim': 0.7377862874371683, 'test/loss': 0.2908787944402751, 'test/num_examples': 3581, 'score': 1344.9032814502716, 'total_duration': 1630.1799845695496, 'accumulated_submission_time': 1344.9032814502716, 'accumulated_eval_time': 281.0312626361847, 'accumulated_logging_time': 4.182111740112305, 'global_step': 5228, 'preemption_count': 0}), (5428, {'train/ssim': 0.74585907799857, 'train/loss': 0.26501435892922537, 'validation/ssim': 0.72212311117315, 'validation/loss': 0.28872672077236916, 'validation/num_examples': 3554, 'test/ssim': 0.7391971352712231, 'test/loss': 0.29021976474143046, 'test/num_examples': 3581, 'score': 1390.2416779994965, 'total_duration': 1679.9114792346954, 'accumulated_submission_time': 1390.2416779994965, 'accumulated_eval_time': 285.18053793907166, 'accumulated_logging_time': 4.423405170440674, 'global_step': 5428, 'preemption_count': 0})], 'global_step': 5428}
I0420 07:01:53.729473 140269983426368 submission_runner.py:570] Timing: 1390.2416779994965
I0420 07:01:53.729516 140269983426368 submission_runner.py:571] ====================
I0420 07:01:53.729629 140269983426368 submission_runner.py:631] Final fastmri score: 1390.2416779994965
