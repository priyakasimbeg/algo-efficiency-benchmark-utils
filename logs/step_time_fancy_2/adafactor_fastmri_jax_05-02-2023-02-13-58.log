python3 submission_runner.py --framework=jax --workload=fastmri --submission_path=baselines/adafactor/jax/submission.py --tuning_search_space=baselines/adafactor/tuning_search_space.json --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_fancy_2/timing_adafactor --overwrite=True --save_checkpoints=False --max_global_steps=5428 2>&1 | tee -a /logs/fastmri_jax_05-02-2023-02-13-58.log
I0502 02:14:18.862162 140031580710720 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_fancy_2/timing_adafactor/fastmri_jax.
I0502 02:14:19.010492 140031580710720 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0502 02:14:19.876094 140031580710720 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter Host
I0502 02:14:19.876813 140031580710720 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0502 02:14:19.881709 140031580710720 submission_runner.py:538] Using RNG seed 405126583
I0502 02:14:22.499188 140031580710720 submission_runner.py:547] --- Tuning run 1/1 ---
I0502 02:14:22.499397 140031580710720 submission_runner.py:552] Creating tuning directory at /experiment_runs/timing_fancy_2/timing_adafactor/fastmri_jax/trial_1.
I0502 02:14:22.499594 140031580710720 logger_utils.py:92] Saving hparams to /experiment_runs/timing_fancy_2/timing_adafactor/fastmri_jax/trial_1/hparams.json.
I0502 02:14:22.635983 140031580710720 submission_runner.py:241] Initializing dataset.
I0502 02:14:27.735958 140031580710720 submission_runner.py:248] Initializing model.
I0502 02:14:35.072017 140031580710720 submission_runner.py:258] Initializing optimizer.
I0502 02:14:36.946763 140031580710720 submission_runner.py:265] Initializing metrics bundle.
I0502 02:14:36.946974 140031580710720 submission_runner.py:282] Initializing checkpoint and logger.
I0502 02:14:36.949033 140031580710720 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_fancy_2/timing_adafactor/fastmri_jax/trial_1 with prefix checkpoint_
I0502 02:14:36.949300 140031580710720 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0502 02:14:36.949367 140031580710720 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0502 02:14:37.924052 140031580710720 submission_runner.py:303] Saving meta data to /experiment_runs/timing_fancy_2/timing_adafactor/fastmri_jax/trial_1/meta_data_0.json.
I0502 02:14:37.924938 140031580710720 submission_runner.py:306] Saving flags to /experiment_runs/timing_fancy_2/timing_adafactor/fastmri_jax/trial_1/flags_0.json.
I0502 02:14:37.931339 140031580710720 submission_runner.py:318] Starting training loop.
I0502 02:15:51.244305 139854906128128 logging_writer.py:48] [0] global_step=0, grad_norm=6.1694536209106445, loss=1.0004838705062866
I0502 02:15:51.255695 140031580710720 spec.py:298] Evaluating on the training split.
I0502 02:17:23.726186 140031580710720 spec.py:310] Evaluating on the validation split.
I0502 02:18:30.002412 140031580710720 spec.py:326] Evaluating on the test split.
I0502 02:19:31.351679 140031580710720 submission_runner.py:415] Time since start: 293.42s, 	Step: 1, 	{'train/ssim': 0.20050651686532156, 'train/loss': 1.0283419745309013, 'validation/ssim': 0.19542869692380066, 'validation/loss': 1.0300793065472003, 'validation/num_examples': 3554, 'test/ssim': 0.21877159495754503, 'test/loss': 1.0275458256248255, 'test/num_examples': 3581, 'score': 73.32415652275085, 'total_duration': 293.4202513694763, 'accumulated_submission_time': 73.32415652275085, 'accumulated_eval_time': 220.09592533111572, 'accumulated_logging_time': 0}
I0502 02:19:31.371926 139826066085632 logging_writer.py:48] [1] accumulated_eval_time=220.095925, accumulated_logging_time=0, accumulated_submission_time=73.324157, global_step=1, preemption_count=0, score=73.324157, test/loss=1.027546, test/num_examples=3581, test/ssim=0.218772, total_duration=293.420251, train/loss=1.028342, train/ssim=0.200507, validation/loss=1.030079, validation/num_examples=3554, validation/ssim=0.195429
I0502 02:19:53.512016 139826057692928 logging_writer.py:48] [100] global_step=100, grad_norm=0.2575407028198242, loss=0.2744661569595337
I0502 02:20:18.091878 139826066085632 logging_writer.py:48] [200] global_step=200, grad_norm=0.26085686683654785, loss=0.4114321172237396
I0502 02:20:42.833497 139826057692928 logging_writer.py:48] [300] global_step=300, grad_norm=0.42115843296051025, loss=0.41610899567604065
I0502 02:20:51.739909 140031580710720 spec.py:298] Evaluating on the training split.
I0502 02:20:53.487166 140031580710720 spec.py:310] Evaluating on the validation split.
I0502 02:20:54.843887 140031580710720 spec.py:326] Evaluating on the test split.
I0502 02:20:56.199697 140031580710720 submission_runner.py:415] Time since start: 378.27s, 	Step: 322, 	{'train/ssim': 0.7096435683114188, 'train/loss': 0.3015522616250174, 'validation/ssim': 0.6865028978132034, 'validation/loss': 0.32172448325170583, 'validation/num_examples': 3554, 'test/ssim': 0.7043581794540631, 'test/loss': 0.3239068417734222, 'test/num_examples': 3581, 'score': 153.6789789199829, 'total_duration': 378.26827239990234, 'accumulated_submission_time': 153.6789789199829, 'accumulated_eval_time': 224.555659532547, 'accumulated_logging_time': 0.029248476028442383}
I0502 02:20:56.214024 139826066085632 logging_writer.py:48] [322] accumulated_eval_time=224.555660, accumulated_logging_time=0.029248, accumulated_submission_time=153.678979, global_step=322, preemption_count=0, score=153.678979, test/loss=0.323907, test/num_examples=3581, test/ssim=0.704358, total_duration=378.268272, train/loss=0.301552, train/ssim=0.709644, validation/loss=0.321724, validation/num_examples=3554, validation/ssim=0.686503
I0502 02:21:21.408822 139826057692928 logging_writer.py:48] [400] global_step=400, grad_norm=0.4952734112739563, loss=0.293732225894928
I0502 02:21:59.083495 139826066085632 logging_writer.py:48] [500] global_step=500, grad_norm=0.43582063913345337, loss=0.21788616478443146
I0502 02:22:16.436737 140031580710720 spec.py:298] Evaluating on the training split.
I0502 02:22:17.842238 140031580710720 spec.py:310] Evaluating on the validation split.
I0502 02:22:19.198519 140031580710720 spec.py:326] Evaluating on the test split.
I0502 02:22:20.557051 140031580710720 submission_runner.py:415] Time since start: 462.63s, 	Step: 548, 	{'train/ssim': 0.7250825337001255, 'train/loss': 0.2864013058798654, 'validation/ssim': 0.7023152966947454, 'validation/loss': 0.3059409017568233, 'validation/num_examples': 3554, 'test/ssim': 0.7195926635367216, 'test/loss': 0.3080310198355906, 'test/num_examples': 3581, 'score': 233.886616230011, 'total_duration': 462.6256408691406, 'accumulated_submission_time': 233.886616230011, 'accumulated_eval_time': 228.67593550682068, 'accumulated_logging_time': 0.05579543113708496}
I0502 02:22:20.567792 139826057692928 logging_writer.py:48] [548] accumulated_eval_time=228.675936, accumulated_logging_time=0.055795, accumulated_submission_time=233.886616, global_step=548, preemption_count=0, score=233.886616, test/loss=0.308031, test/num_examples=3581, test/ssim=0.719593, total_duration=462.625641, train/loss=0.286401, train/ssim=0.725083, validation/loss=0.305941, validation/num_examples=3554, validation/ssim=0.702315
I0502 02:22:36.930706 139826066085632 logging_writer.py:48] [600] global_step=600, grad_norm=0.1170726791024208, loss=0.3353322744369507
I0502 02:23:14.868263 139826057692928 logging_writer.py:48] [700] global_step=700, grad_norm=0.3089425563812256, loss=0.24730083346366882
I0502 02:23:40.796622 140031580710720 spec.py:298] Evaluating on the training split.
I0502 02:23:42.198147 140031580710720 spec.py:310] Evaluating on the validation split.
I0502 02:23:43.553260 140031580710720 spec.py:326] Evaluating on the test split.
I0502 02:23:44.909155 140031580710720 submission_runner.py:415] Time since start: 546.98s, 	Step: 774, 	{'train/ssim': 0.728870119367327, 'train/loss': 0.2814938340868269, 'validation/ssim': 0.7059769252075127, 'validation/loss': 0.3010681873637099, 'validation/num_examples': 3554, 'test/ssim': 0.7231243509581821, 'test/loss': 0.30311490303642485, 'test/num_examples': 3581, 'score': 314.09842824935913, 'total_duration': 546.9777436256409, 'accumulated_submission_time': 314.09842824935913, 'accumulated_eval_time': 232.7884590625763, 'accumulated_logging_time': 0.08072662353515625}
I0502 02:23:44.921323 139826066085632 logging_writer.py:48] [774] accumulated_eval_time=232.788459, accumulated_logging_time=0.080727, accumulated_submission_time=314.098428, global_step=774, preemption_count=0, score=314.098428, test/loss=0.303115, test/num_examples=3581, test/ssim=0.723124, total_duration=546.977744, train/loss=0.281494, train/ssim=0.728870, validation/loss=0.301068, validation/num_examples=3554, validation/ssim=0.705977
I0502 02:23:51.478442 139826057692928 logging_writer.py:48] [800] global_step=800, grad_norm=0.2593325674533844, loss=0.2610344886779785
I0502 02:24:30.143855 139826066085632 logging_writer.py:48] [900] global_step=900, grad_norm=0.14782015979290009, loss=0.30242353677749634
I0502 02:25:03.197192 139826057692928 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.2528141438961029, loss=0.2170570194721222
I0502 02:25:04.947890 140031580710720 spec.py:298] Evaluating on the training split.
I0502 02:25:06.352453 140031580710720 spec.py:310] Evaluating on the validation split.
I0502 02:25:07.702924 140031580710720 spec.py:326] Evaluating on the test split.
I0502 02:25:09.054864 140031580710720 submission_runner.py:415] Time since start: 631.12s, 	Step: 1008, 	{'train/ssim': 0.7355506079537528, 'train/loss': 0.2778822524206979, 'validation/ssim': 0.7128436378904052, 'validation/loss': 0.29775858435257807, 'validation/num_examples': 3554, 'test/ssim': 0.7297875969744834, 'test/loss': 0.29961290655106815, 'test/num_examples': 3581, 'score': 394.1107244491577, 'total_duration': 631.1234483718872, 'accumulated_submission_time': 394.1107244491577, 'accumulated_eval_time': 236.89538550376892, 'accumulated_logging_time': 0.1042485237121582}
I0502 02:25:09.064773 139826066085632 logging_writer.py:48] [1008] accumulated_eval_time=236.895386, accumulated_logging_time=0.104249, accumulated_submission_time=394.110724, global_step=1008, preemption_count=0, score=394.110724, test/loss=0.299613, test/num_examples=3581, test/ssim=0.729788, total_duration=631.123448, train/loss=0.277882, train/ssim=0.735551, validation/loss=0.297759, validation/num_examples=3554, validation/ssim=0.712844
I0502 02:25:29.636061 139826057692928 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.2755803167819977, loss=0.2914162278175354
I0502 02:25:53.919362 139826066085632 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.13011740148067474, loss=0.24058039486408234
I0502 02:26:18.125463 139826057692928 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.1778319925069809, loss=0.3462010622024536
I0502 02:26:29.208415 140031580710720 spec.py:298] Evaluating on the training split.
I0502 02:26:30.618228 140031580710720 spec.py:310] Evaluating on the validation split.
I0502 02:26:31.971100 140031580710720 spec.py:326] Evaluating on the test split.
I0502 02:26:33.323765 140031580710720 submission_runner.py:415] Time since start: 715.39s, 	Step: 1347, 	{'train/ssim': 0.7363805089678083, 'train/loss': 0.2752942868641445, 'validation/ssim': 0.7125140411771947, 'validation/loss': 0.2955011766011888, 'validation/num_examples': 3554, 'test/ssim': 0.7296067924680606, 'test/loss': 0.2972753674449351, 'test/num_examples': 3581, 'score': 474.2412693500519, 'total_duration': 715.3923006057739, 'accumulated_submission_time': 474.2412693500519, 'accumulated_eval_time': 241.010644197464, 'accumulated_logging_time': 0.12264800071716309}
I0502 02:26:33.335315 139826066085632 logging_writer.py:48] [1347] accumulated_eval_time=241.010644, accumulated_logging_time=0.122648, accumulated_submission_time=474.241269, global_step=1347, preemption_count=0, score=474.241269, test/loss=0.297275, test/num_examples=3581, test/ssim=0.729607, total_duration=715.392301, train/loss=0.275294, train/ssim=0.736381, validation/loss=0.295501, validation/num_examples=3554, validation/ssim=0.712514
I0502 02:26:44.122860 139826057692928 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.25785553455352783, loss=0.32338282465934753
I0502 02:27:08.399950 139826066085632 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.05897655710577965, loss=0.3510807752609253
I0502 02:27:32.334280 139826057692928 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.24292771518230438, loss=0.20038744807243347
I0502 02:27:53.414704 140031580710720 spec.py:298] Evaluating on the training split.
I0502 02:27:54.821694 140031580710720 spec.py:310] Evaluating on the validation split.
I0502 02:27:56.177429 140031580710720 spec.py:326] Evaluating on the test split.
I0502 02:27:57.531888 140031580710720 submission_runner.py:415] Time since start: 799.60s, 	Step: 1689, 	{'train/ssim': 0.7417901584080288, 'train/loss': 0.273313045501709, 'validation/ssim': 0.7190531492904122, 'validation/loss': 0.2934021099135657, 'validation/num_examples': 3554, 'test/ssim': 0.7359654251605696, 'test/loss': 0.2950301736268675, 'test/num_examples': 3581, 'score': 554.3071203231812, 'total_duration': 799.6004576683044, 'accumulated_submission_time': 554.3071203231812, 'accumulated_eval_time': 245.12777423858643, 'accumulated_logging_time': 0.14302635192871094}
I0502 02:27:57.541615 139826066085632 logging_writer.py:48] [1689] accumulated_eval_time=245.127774, accumulated_logging_time=0.143026, accumulated_submission_time=554.307120, global_step=1689, preemption_count=0, score=554.307120, test/loss=0.295030, test/num_examples=3581, test/ssim=0.735965, total_duration=799.600458, train/loss=0.273313, train/ssim=0.741790, validation/loss=0.293402, validation/num_examples=3554, validation/ssim=0.719053
I0502 02:27:58.459055 139826057692928 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.13788916170597076, loss=0.31157800555229187
I0502 02:28:22.261667 139826066085632 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.08495722711086273, loss=0.23063212633132935
I0502 02:28:46.309745 139826057692928 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.15736143290996552, loss=0.30507349967956543
I0502 02:29:10.827470 139826066085632 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.10587850213050842, loss=0.3074016273021698
I0502 02:29:17.644692 140031580710720 spec.py:298] Evaluating on the training split.
I0502 02:29:19.046952 140031580710720 spec.py:310] Evaluating on the validation split.
I0502 02:29:20.401054 140031580710720 spec.py:326] Evaluating on the test split.
I0502 02:29:21.755041 140031580710720 submission_runner.py:415] Time since start: 883.82s, 	Step: 2028, 	{'train/ssim': 0.7392536572047642, 'train/loss': 0.2730604921068464, 'validation/ssim': 0.716629534943022, 'validation/loss': 0.2928896138154192, 'validation/num_examples': 3554, 'test/ssim': 0.7339081943983873, 'test/loss': 0.29442725332047615, 'test/num_examples': 3581, 'score': 634.3975329399109, 'total_duration': 883.8236210346222, 'accumulated_submission_time': 634.3975329399109, 'accumulated_eval_time': 249.23808073997498, 'accumulated_logging_time': 0.16106462478637695}
I0502 02:29:21.765435 139826057692928 logging_writer.py:48] [2028] accumulated_eval_time=249.238081, accumulated_logging_time=0.161065, accumulated_submission_time=634.397533, global_step=2028, preemption_count=0, score=634.397533, test/loss=0.294427, test/num_examples=3581, test/ssim=0.733908, total_duration=883.823621, train/loss=0.273060, train/ssim=0.739254, validation/loss=0.292890, validation/num_examples=3554, validation/ssim=0.716630
I0502 02:29:37.194757 139826066085632 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.2410803884267807, loss=0.32377803325653076
I0502 02:30:01.101646 139826057692928 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.09970453381538391, loss=0.2810054421424866
I0502 02:30:25.272032 139826066085632 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.11078161746263504, loss=0.22857894003391266
I0502 02:30:41.868832 140031580710720 spec.py:298] Evaluating on the training split.
I0502 02:30:43.272185 140031580710720 spec.py:310] Evaluating on the validation split.
I0502 02:30:44.629102 140031580710720 spec.py:326] Evaluating on the test split.
I0502 02:30:45.985187 140031580710720 submission_runner.py:415] Time since start: 968.05s, 	Step: 2370, 	{'train/ssim': 0.7435637882777623, 'train/loss': 0.2710515430995396, 'validation/ssim': 0.7197148157226013, 'validation/loss': 0.29157713469857904, 'validation/num_examples': 3554, 'test/ssim': 0.7366434420596552, 'test/loss': 0.29321292471333077, 'test/num_examples': 3581, 'score': 714.4862902164459, 'total_duration': 968.0537667274475, 'accumulated_submission_time': 714.4862902164459, 'accumulated_eval_time': 253.35439085960388, 'accumulated_logging_time': 0.18141889572143555}
I0502 02:30:45.994590 139826057692928 logging_writer.py:48] [2370] accumulated_eval_time=253.354391, accumulated_logging_time=0.181419, accumulated_submission_time=714.486290, global_step=2370, preemption_count=0, score=714.486290, test/loss=0.293213, test/num_examples=3581, test/ssim=0.736643, total_duration=968.053767, train/loss=0.271052, train/ssim=0.743564, validation/loss=0.291577, validation/num_examples=3554, validation/ssim=0.719715
I0502 02:30:51.264827 139826066085632 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.13314054906368256, loss=0.24295546114444733
I0502 02:31:15.735935 139826057692928 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.09458661824464798, loss=0.28823184967041016
I0502 02:31:39.990752 139826066085632 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.12072174996137619, loss=0.24059855937957764
I0502 02:32:04.105815 139826057692928 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.3370788097381592, loss=0.28534334897994995
I0502 02:32:06.027598 140031580710720 spec.py:298] Evaluating on the training split.
I0502 02:32:07.435063 140031580710720 spec.py:310] Evaluating on the validation split.
I0502 02:32:08.794753 140031580710720 spec.py:326] Evaluating on the test split.
I0502 02:32:10.147474 140031580710720 submission_runner.py:415] Time since start: 1052.22s, 	Step: 2709, 	{'train/ssim': 0.7388818604605538, 'train/loss': 0.27191104207720074, 'validation/ssim': 0.7147138485025676, 'validation/loss': 0.2924825982827448, 'validation/num_examples': 3554, 'test/ssim': 0.7319724544470818, 'test/loss': 0.29404829334726684, 'test/num_examples': 3581, 'score': 794.5064721107483, 'total_duration': 1052.2160592079163, 'accumulated_submission_time': 794.5064721107483, 'accumulated_eval_time': 257.4742250442505, 'accumulated_logging_time': 0.19916677474975586}
I0502 02:32:10.158000 139826066085632 logging_writer.py:48] [2709] accumulated_eval_time=257.474225, accumulated_logging_time=0.199167, accumulated_submission_time=794.506472, global_step=2709, preemption_count=0, score=794.506472, test/loss=0.294048, test/num_examples=3581, test/ssim=0.731972, total_duration=1052.216059, train/loss=0.271911, train/ssim=0.738882, validation/loss=0.292483, validation/num_examples=3554, validation/ssim=0.714714
I0502 02:32:30.358821 139826057692928 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.11462198942899704, loss=0.39104774594306946
I0502 02:32:54.525420 139826066085632 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.2378855049610138, loss=0.2829573452472687
I0502 02:33:18.800698 139826057692928 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.23602153360843658, loss=0.24648751318454742
I0502 02:33:30.262227 140031580710720 spec.py:298] Evaluating on the training split.
I0502 02:33:31.667258 140031580710720 spec.py:310] Evaluating on the validation split.
I0502 02:33:33.022125 140031580710720 spec.py:326] Evaluating on the test split.
I0502 02:33:34.380280 140031580710720 submission_runner.py:415] Time since start: 1136.45s, 	Step: 3048, 	{'train/ssim': 0.7434813635689872, 'train/loss': 0.26947225843157085, 'validation/ssim': 0.7197617341375915, 'validation/loss': 0.2897470073882421, 'validation/num_examples': 3554, 'test/ssim': 0.7369811892409592, 'test/loss': 0.2912203595146258, 'test/num_examples': 3581, 'score': 874.5979068279266, 'total_duration': 1136.4488279819489, 'accumulated_submission_time': 874.5979068279266, 'accumulated_eval_time': 261.5922203063965, 'accumulated_logging_time': 0.21789312362670898}
I0502 02:33:34.396746 139826066085632 logging_writer.py:48] [3048] accumulated_eval_time=261.592220, accumulated_logging_time=0.217893, accumulated_submission_time=874.597907, global_step=3048, preemption_count=0, score=874.597907, test/loss=0.291220, test/num_examples=3581, test/ssim=0.736981, total_duration=1136.448828, train/loss=0.269472, train/ssim=0.743481, validation/loss=0.289747, validation/num_examples=3554, validation/ssim=0.719762
I0502 02:33:45.044190 139826057692928 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.061205312609672546, loss=0.27415671944618225
I0502 02:34:09.598013 139826066085632 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.09768840670585632, loss=0.2786228656768799
I0502 02:34:33.827680 139826057692928 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.10442230105400085, loss=0.25483882427215576
I0502 02:34:54.566534 140031580710720 spec.py:298] Evaluating on the training split.
I0502 02:34:55.973349 140031580710720 spec.py:310] Evaluating on the validation split.
I0502 02:34:57.326365 140031580710720 spec.py:326] Evaluating on the test split.
I0502 02:34:58.680702 140031580710720 submission_runner.py:415] Time since start: 1220.75s, 	Step: 3387, 	{'train/ssim': 0.745591572352818, 'train/loss': 0.2686913864953177, 'validation/ssim': 0.7218521796523284, 'validation/loss': 0.289545251334324, 'validation/num_examples': 3554, 'test/ssim': 0.7389294736979893, 'test/loss': 0.29110974288126573, 'test/num_examples': 3581, 'score': 954.7546010017395, 'total_duration': 1220.749272108078, 'accumulated_submission_time': 954.7546010017395, 'accumulated_eval_time': 265.70633602142334, 'accumulated_logging_time': 0.2430281639099121}
I0502 02:34:58.690412 139826066085632 logging_writer.py:48] [3387] accumulated_eval_time=265.706336, accumulated_logging_time=0.243028, accumulated_submission_time=954.754601, global_step=3387, preemption_count=0, score=954.754601, test/loss=0.291110, test/num_examples=3581, test/ssim=0.738929, total_duration=1220.749272, train/loss=0.268691, train/ssim=0.745592, validation/loss=0.289545, validation/num_examples=3554, validation/ssim=0.721852
I0502 02:34:59.842416 139826057692928 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.2299441397190094, loss=0.25239840149879456
I0502 02:35:23.851040 139826066085632 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.07897897064685822, loss=0.27515923976898193
I0502 02:35:47.796747 139826057692928 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.035613879561424255, loss=0.3592763841152191
I0502 02:36:12.139959 139826066085632 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.10764700919389725, loss=0.3145367205142975
I0502 02:36:18.847129 140031580710720 spec.py:298] Evaluating on the training split.
I0502 02:36:20.254898 140031580710720 spec.py:310] Evaluating on the validation split.
I0502 02:36:21.611282 140031580710720 spec.py:326] Evaluating on the test split.
I0502 02:36:22.963659 140031580710720 submission_runner.py:415] Time since start: 1305.03s, 	Step: 3729, 	{'train/ssim': 0.7428217615400042, 'train/loss': 0.269426737512861, 'validation/ssim': 0.7200728520021454, 'validation/loss': 0.28943125263787284, 'validation/num_examples': 3554, 'test/ssim': 0.7372236936260821, 'test/loss': 0.2908532963688565, 'test/num_examples': 3581, 'score': 1034.8984303474426, 'total_duration': 1305.0322425365448, 'accumulated_submission_time': 1034.8984303474426, 'accumulated_eval_time': 269.8228290081024, 'accumulated_logging_time': 0.26107311248779297}
I0502 02:36:22.973560 139826057692928 logging_writer.py:48] [3729] accumulated_eval_time=269.822829, accumulated_logging_time=0.261073, accumulated_submission_time=1034.898430, global_step=3729, preemption_count=0, score=1034.898430, test/loss=0.290853, test/num_examples=3581, test/ssim=0.737224, total_duration=1305.032243, train/loss=0.269427, train/ssim=0.742822, validation/loss=0.289431, validation/num_examples=3554, validation/ssim=0.720073
I0502 02:36:37.986242 139826066085632 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.07808787375688553, loss=0.2631220519542694
I0502 02:37:02.098883 139826057692928 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.15881334245204926, loss=0.31673377752304077
I0502 02:37:26.819748 139826066085632 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.04570216313004494, loss=0.2310146540403366
I0502 02:37:43.126268 140031580710720 spec.py:298] Evaluating on the training split.
I0502 02:37:44.537084 140031580710720 spec.py:310] Evaluating on the validation split.
I0502 02:37:45.894788 140031580710720 spec.py:326] Evaluating on the test split.
I0502 02:37:47.253705 140031580710720 submission_runner.py:415] Time since start: 1389.32s, 	Step: 4068, 	{'train/ssim': 0.7431887899126325, 'train/loss': 0.2690412998199463, 'validation/ssim': 0.7193499099825901, 'validation/loss': 0.2892321069789322, 'validation/num_examples': 3554, 'test/ssim': 0.736620875584683, 'test/loss': 0.29075222446811294, 'test/num_examples': 3581, 'score': 1115.0386271476746, 'total_duration': 1389.3222982883453, 'accumulated_submission_time': 1115.0386271476746, 'accumulated_eval_time': 273.95022535324097, 'accumulated_logging_time': 0.2789762020111084}
I0502 02:37:47.263302 139826057692928 logging_writer.py:48] [4068] accumulated_eval_time=273.950225, accumulated_logging_time=0.278976, accumulated_submission_time=1115.038627, global_step=4068, preemption_count=0, score=1115.038627, test/loss=0.290752, test/num_examples=3581, test/ssim=0.736621, total_duration=1389.322298, train/loss=0.269041, train/ssim=0.743189, validation/loss=0.289232, validation/num_examples=3554, validation/ssim=0.719350
I0502 02:37:52.939502 139826066085632 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.16750897467136383, loss=0.312890887260437
I0502 02:38:17.379377 139826057692928 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.09742531925439835, loss=0.2680560350418091
I0502 02:38:41.403944 139826066085632 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.05005266144871712, loss=0.3841015100479126
I0502 02:39:05.750522 139826057692928 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.03846799209713936, loss=0.2941914498806
I0502 02:39:07.344053 140031580710720 spec.py:298] Evaluating on the training split.
I0502 02:39:08.757645 140031580710720 spec.py:310] Evaluating on the validation split.
I0502 02:39:10.109988 140031580710720 spec.py:326] Evaluating on the test split.
I0502 02:39:11.466759 140031580710720 submission_runner.py:415] Time since start: 1473.54s, 	Step: 4408, 	{'train/ssim': 0.7460047858101981, 'train/loss': 0.26742076873779297, 'validation/ssim': 0.721702837581774, 'validation/loss': 0.28821735027873524, 'validation/num_examples': 3554, 'test/ssim': 0.7388756141353672, 'test/loss': 0.28965536424881316, 'test/num_examples': 3581, 'score': 1195.1059675216675, 'total_duration': 1473.5353474617004, 'accumulated_submission_time': 1195.1059675216675, 'accumulated_eval_time': 278.0728986263275, 'accumulated_logging_time': 0.29775309562683105}
I0502 02:39:11.476305 139826066085632 logging_writer.py:48] [4408] accumulated_eval_time=278.072899, accumulated_logging_time=0.297753, accumulated_submission_time=1195.105968, global_step=4408, preemption_count=0, score=1195.105968, test/loss=0.289655, test/num_examples=3581, test/ssim=0.738876, total_duration=1473.535347, train/loss=0.267421, train/ssim=0.746005, validation/loss=0.288217, validation/num_examples=3554, validation/ssim=0.721703
I0502 02:39:31.754347 139826057692928 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.08033615350723267, loss=0.2276088297367096
I0502 02:39:55.863160 139826066085632 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.18301624059677124, loss=0.29791972041130066
I0502 02:40:19.858471 139826057692928 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.0733010470867157, loss=0.28694579005241394
I0502 02:40:31.681421 140031580710720 spec.py:298] Evaluating on the training split.
I0502 02:40:33.086972 140031580710720 spec.py:310] Evaluating on the validation split.
I0502 02:40:34.441253 140031580710720 spec.py:326] Evaluating on the test split.
I0502 02:40:35.803641 140031580710720 submission_runner.py:415] Time since start: 1557.87s, 	Step: 4750, 	{'train/ssim': 0.7461673191615513, 'train/loss': 0.2675542320523943, 'validation/ssim': 0.7223200586047411, 'validation/loss': 0.2882507358566052, 'validation/num_examples': 3554, 'test/ssim': 0.7395538355644373, 'test/loss': 0.28965018282253563, 'test/num_examples': 3581, 'score': 1275.2983531951904, 'total_duration': 1557.8722372055054, 'accumulated_submission_time': 1275.2983531951904, 'accumulated_eval_time': 282.19510293006897, 'accumulated_logging_time': 0.3156743049621582}
I0502 02:40:35.814375 139826066085632 logging_writer.py:48] [4750] accumulated_eval_time=282.195103, accumulated_logging_time=0.315674, accumulated_submission_time=1275.298353, global_step=4750, preemption_count=0, score=1275.298353, test/loss=0.289650, test/num_examples=3581, test/ssim=0.739554, total_duration=1557.872237, train/loss=0.267554, train/ssim=0.746167, validation/loss=0.288251, validation/num_examples=3554, validation/ssim=0.722320
I0502 02:40:45.846279 139826057692928 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.07394890487194061, loss=0.17251655459403992
I0502 02:41:10.020401 139826066085632 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.04130065068602562, loss=0.3610991835594177
I0502 02:41:34.397933 139826057692928 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.1443951427936554, loss=0.3579084873199463
I0502 02:41:55.880805 140031580710720 spec.py:298] Evaluating on the training split.
I0502 02:41:57.290156 140031580710720 spec.py:310] Evaluating on the validation split.
I0502 02:41:58.644245 140031580710720 spec.py:326] Evaluating on the test split.
I0502 02:42:00.004560 140031580710720 submission_runner.py:415] Time since start: 1642.07s, 	Step: 5090, 	{'train/ssim': 0.7440851075308663, 'train/loss': 0.26737758091517855, 'validation/ssim': 0.7200313604609243, 'validation/loss': 0.2878920298046655, 'validation/num_examples': 3554, 'test/ssim': 0.7373673418519617, 'test/loss': 0.2892657687164025, 'test/num_examples': 3581, 'score': 1355.351772069931, 'total_duration': 1642.0731530189514, 'accumulated_submission_time': 1355.351772069931, 'accumulated_eval_time': 286.31881523132324, 'accumulated_logging_time': 0.3352386951446533}
I0502 02:42:00.014208 139826066085632 logging_writer.py:48] [5090] accumulated_eval_time=286.318815, accumulated_logging_time=0.335239, accumulated_submission_time=1355.351772, global_step=5090, preemption_count=0, score=1355.351772, test/loss=0.289266, test/num_examples=3581, test/ssim=0.737367, total_duration=1642.073153, train/loss=0.267378, train/ssim=0.744085, validation/loss=0.287892, validation/num_examples=3554, validation/ssim=0.720031
I0502 02:42:00.854483 139826057692928 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.1521744430065155, loss=0.27016040682792664
I0502 02:42:24.612254 139826066085632 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.15478035807609558, loss=0.3017268776893616
I0502 02:42:49.028874 139826057692928 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.19510981440544128, loss=0.1964702308177948
I0502 02:43:13.267925 139826066085632 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.15962104499340057, loss=0.28738126158714294
I0502 02:43:19.687825 140031580710720 spec.py:298] Evaluating on the training split.
I0502 02:43:21.099279 140031580710720 spec.py:310] Evaluating on the validation split.
I0502 02:43:22.461673 140031580710720 spec.py:326] Evaluating on the test split.
I0502 02:43:23.818760 140031580710720 submission_runner.py:415] Time since start: 1725.89s, 	Step: 5428, 	{'train/ssim': 0.7435485976082938, 'train/loss': 0.2674126284463065, 'validation/ssim': 0.7196351986757878, 'validation/loss': 0.2878337252589512, 'validation/num_examples': 3554, 'test/ssim': 0.7369648950188494, 'test/loss': 0.2892000123263404, 'test/num_examples': 3581, 'score': 1435.0136234760284, 'total_duration': 1725.887350320816, 'accumulated_submission_time': 1435.0136234760284, 'accumulated_eval_time': 290.4497010707855, 'accumulated_logging_time': 0.35250067710876465}
I0502 02:43:23.828498 139826057692928 logging_writer.py:48] [5428] accumulated_eval_time=290.449701, accumulated_logging_time=0.352501, accumulated_submission_time=1435.013623, global_step=5428, preemption_count=0, score=1435.013623, test/loss=0.289200, test/num_examples=3581, test/ssim=0.736965, total_duration=1725.887350, train/loss=0.267413, train/ssim=0.743549, validation/loss=0.287834, validation/num_examples=3554, validation/ssim=0.719635
I0502 02:43:23.843331 139826066085632 logging_writer.py:48] [5428] global_step=5428, preemption_count=0, score=1435.013623
I0502 02:43:23.873067 140031580710720 checkpoints.py:356] Saving checkpoint at step: 5428
I0502 02:43:24.016286 140031580710720 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_fancy_2/timing_adafactor/fastmri_jax/trial_1/checkpoint_5428
I0502 02:43:24.016728 140031580710720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_fancy_2/timing_adafactor/fastmri_jax/trial_1/checkpoint_5428.
I0502 02:43:24.826568 140031580710720 submission_runner.py:578] Tuning trial 1/1
I0502 02:43:24.826787 140031580710720 submission_runner.py:579] Hyperparameters: Hyperparameters(learning_rate=0.0032594519610942875, one_minus_beta1=0.03999478140191344, warmup_factor=0.05, weight_decay=0.002578922011395245, label_smoothing=0.1, dropout_rate=0.0)
I0502 02:43:24.830399 140031580710720 submission_runner.py:580] Metrics: {'eval_results': [(1, {'train/ssim': 0.20050651686532156, 'train/loss': 1.0283419745309013, 'validation/ssim': 0.19542869692380066, 'validation/loss': 1.0300793065472003, 'validation/num_examples': 3554, 'test/ssim': 0.21877159495754503, 'test/loss': 1.0275458256248255, 'test/num_examples': 3581, 'score': 73.32415652275085, 'total_duration': 293.4202513694763, 'accumulated_submission_time': 73.32415652275085, 'accumulated_eval_time': 220.09592533111572, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (322, {'train/ssim': 0.7096435683114188, 'train/loss': 0.3015522616250174, 'validation/ssim': 0.6865028978132034, 'validation/loss': 0.32172448325170583, 'validation/num_examples': 3554, 'test/ssim': 0.7043581794540631, 'test/loss': 0.3239068417734222, 'test/num_examples': 3581, 'score': 153.6789789199829, 'total_duration': 378.26827239990234, 'accumulated_submission_time': 153.6789789199829, 'accumulated_eval_time': 224.555659532547, 'accumulated_logging_time': 0.029248476028442383, 'global_step': 322, 'preemption_count': 0}), (548, {'train/ssim': 0.7250825337001255, 'train/loss': 0.2864013058798654, 'validation/ssim': 0.7023152966947454, 'validation/loss': 0.3059409017568233, 'validation/num_examples': 3554, 'test/ssim': 0.7195926635367216, 'test/loss': 0.3080310198355906, 'test/num_examples': 3581, 'score': 233.886616230011, 'total_duration': 462.6256408691406, 'accumulated_submission_time': 233.886616230011, 'accumulated_eval_time': 228.67593550682068, 'accumulated_logging_time': 0.05579543113708496, 'global_step': 548, 'preemption_count': 0}), (774, {'train/ssim': 0.728870119367327, 'train/loss': 0.2814938340868269, 'validation/ssim': 0.7059769252075127, 'validation/loss': 0.3010681873637099, 'validation/num_examples': 3554, 'test/ssim': 0.7231243509581821, 'test/loss': 0.30311490303642485, 'test/num_examples': 3581, 'score': 314.09842824935913, 'total_duration': 546.9777436256409, 'accumulated_submission_time': 314.09842824935913, 'accumulated_eval_time': 232.7884590625763, 'accumulated_logging_time': 0.08072662353515625, 'global_step': 774, 'preemption_count': 0}), (1008, {'train/ssim': 0.7355506079537528, 'train/loss': 0.2778822524206979, 'validation/ssim': 0.7128436378904052, 'validation/loss': 0.29775858435257807, 'validation/num_examples': 3554, 'test/ssim': 0.7297875969744834, 'test/loss': 0.29961290655106815, 'test/num_examples': 3581, 'score': 394.1107244491577, 'total_duration': 631.1234483718872, 'accumulated_submission_time': 394.1107244491577, 'accumulated_eval_time': 236.89538550376892, 'accumulated_logging_time': 0.1042485237121582, 'global_step': 1008, 'preemption_count': 0}), (1347, {'train/ssim': 0.7363805089678083, 'train/loss': 0.2752942868641445, 'validation/ssim': 0.7125140411771947, 'validation/loss': 0.2955011766011888, 'validation/num_examples': 3554, 'test/ssim': 0.7296067924680606, 'test/loss': 0.2972753674449351, 'test/num_examples': 3581, 'score': 474.2412693500519, 'total_duration': 715.3923006057739, 'accumulated_submission_time': 474.2412693500519, 'accumulated_eval_time': 241.010644197464, 'accumulated_logging_time': 0.12264800071716309, 'global_step': 1347, 'preemption_count': 0}), (1689, {'train/ssim': 0.7417901584080288, 'train/loss': 0.273313045501709, 'validation/ssim': 0.7190531492904122, 'validation/loss': 0.2934021099135657, 'validation/num_examples': 3554, 'test/ssim': 0.7359654251605696, 'test/loss': 0.2950301736268675, 'test/num_examples': 3581, 'score': 554.3071203231812, 'total_duration': 799.6004576683044, 'accumulated_submission_time': 554.3071203231812, 'accumulated_eval_time': 245.12777423858643, 'accumulated_logging_time': 0.14302635192871094, 'global_step': 1689, 'preemption_count': 0}), (2028, {'train/ssim': 0.7392536572047642, 'train/loss': 0.2730604921068464, 'validation/ssim': 0.716629534943022, 'validation/loss': 0.2928896138154192, 'validation/num_examples': 3554, 'test/ssim': 0.7339081943983873, 'test/loss': 0.29442725332047615, 'test/num_examples': 3581, 'score': 634.3975329399109, 'total_duration': 883.8236210346222, 'accumulated_submission_time': 634.3975329399109, 'accumulated_eval_time': 249.23808073997498, 'accumulated_logging_time': 0.16106462478637695, 'global_step': 2028, 'preemption_count': 0}), (2370, {'train/ssim': 0.7435637882777623, 'train/loss': 0.2710515430995396, 'validation/ssim': 0.7197148157226013, 'validation/loss': 0.29157713469857904, 'validation/num_examples': 3554, 'test/ssim': 0.7366434420596552, 'test/loss': 0.29321292471333077, 'test/num_examples': 3581, 'score': 714.4862902164459, 'total_duration': 968.0537667274475, 'accumulated_submission_time': 714.4862902164459, 'accumulated_eval_time': 253.35439085960388, 'accumulated_logging_time': 0.18141889572143555, 'global_step': 2370, 'preemption_count': 0}), (2709, {'train/ssim': 0.7388818604605538, 'train/loss': 0.27191104207720074, 'validation/ssim': 0.7147138485025676, 'validation/loss': 0.2924825982827448, 'validation/num_examples': 3554, 'test/ssim': 0.7319724544470818, 'test/loss': 0.29404829334726684, 'test/num_examples': 3581, 'score': 794.5064721107483, 'total_duration': 1052.2160592079163, 'accumulated_submission_time': 794.5064721107483, 'accumulated_eval_time': 257.4742250442505, 'accumulated_logging_time': 0.19916677474975586, 'global_step': 2709, 'preemption_count': 0}), (3048, {'train/ssim': 0.7434813635689872, 'train/loss': 0.26947225843157085, 'validation/ssim': 0.7197617341375915, 'validation/loss': 0.2897470073882421, 'validation/num_examples': 3554, 'test/ssim': 0.7369811892409592, 'test/loss': 0.2912203595146258, 'test/num_examples': 3581, 'score': 874.5979068279266, 'total_duration': 1136.4488279819489, 'accumulated_submission_time': 874.5979068279266, 'accumulated_eval_time': 261.5922203063965, 'accumulated_logging_time': 0.21789312362670898, 'global_step': 3048, 'preemption_count': 0}), (3387, {'train/ssim': 0.745591572352818, 'train/loss': 0.2686913864953177, 'validation/ssim': 0.7218521796523284, 'validation/loss': 0.289545251334324, 'validation/num_examples': 3554, 'test/ssim': 0.7389294736979893, 'test/loss': 0.29110974288126573, 'test/num_examples': 3581, 'score': 954.7546010017395, 'total_duration': 1220.749272108078, 'accumulated_submission_time': 954.7546010017395, 'accumulated_eval_time': 265.70633602142334, 'accumulated_logging_time': 0.2430281639099121, 'global_step': 3387, 'preemption_count': 0}), (3729, {'train/ssim': 0.7428217615400042, 'train/loss': 0.269426737512861, 'validation/ssim': 0.7200728520021454, 'validation/loss': 0.28943125263787284, 'validation/num_examples': 3554, 'test/ssim': 0.7372236936260821, 'test/loss': 0.2908532963688565, 'test/num_examples': 3581, 'score': 1034.8984303474426, 'total_duration': 1305.0322425365448, 'accumulated_submission_time': 1034.8984303474426, 'accumulated_eval_time': 269.8228290081024, 'accumulated_logging_time': 0.26107311248779297, 'global_step': 3729, 'preemption_count': 0}), (4068, {'train/ssim': 0.7431887899126325, 'train/loss': 0.2690412998199463, 'validation/ssim': 0.7193499099825901, 'validation/loss': 0.2892321069789322, 'validation/num_examples': 3554, 'test/ssim': 0.736620875584683, 'test/loss': 0.29075222446811294, 'test/num_examples': 3581, 'score': 1115.0386271476746, 'total_duration': 1389.3222982883453, 'accumulated_submission_time': 1115.0386271476746, 'accumulated_eval_time': 273.95022535324097, 'accumulated_logging_time': 0.2789762020111084, 'global_step': 4068, 'preemption_count': 0}), (4408, {'train/ssim': 0.7460047858101981, 'train/loss': 0.26742076873779297, 'validation/ssim': 0.721702837581774, 'validation/loss': 0.28821735027873524, 'validation/num_examples': 3554, 'test/ssim': 0.7388756141353672, 'test/loss': 0.28965536424881316, 'test/num_examples': 3581, 'score': 1195.1059675216675, 'total_duration': 1473.5353474617004, 'accumulated_submission_time': 1195.1059675216675, 'accumulated_eval_time': 278.0728986263275, 'accumulated_logging_time': 0.29775309562683105, 'global_step': 4408, 'preemption_count': 0}), (4750, {'train/ssim': 0.7461673191615513, 'train/loss': 0.2675542320523943, 'validation/ssim': 0.7223200586047411, 'validation/loss': 0.2882507358566052, 'validation/num_examples': 3554, 'test/ssim': 0.7395538355644373, 'test/loss': 0.28965018282253563, 'test/num_examples': 3581, 'score': 1275.2983531951904, 'total_duration': 1557.8722372055054, 'accumulated_submission_time': 1275.2983531951904, 'accumulated_eval_time': 282.19510293006897, 'accumulated_logging_time': 0.3156743049621582, 'global_step': 4750, 'preemption_count': 0}), (5090, {'train/ssim': 0.7440851075308663, 'train/loss': 0.26737758091517855, 'validation/ssim': 0.7200313604609243, 'validation/loss': 0.2878920298046655, 'validation/num_examples': 3554, 'test/ssim': 0.7373673418519617, 'test/loss': 0.2892657687164025, 'test/num_examples': 3581, 'score': 1355.351772069931, 'total_duration': 1642.0731530189514, 'accumulated_submission_time': 1355.351772069931, 'accumulated_eval_time': 286.31881523132324, 'accumulated_logging_time': 0.3352386951446533, 'global_step': 5090, 'preemption_count': 0}), (5428, {'train/ssim': 0.7435485976082938, 'train/loss': 0.2674126284463065, 'validation/ssim': 0.7196351986757878, 'validation/loss': 0.2878337252589512, 'validation/num_examples': 3554, 'test/ssim': 0.7369648950188494, 'test/loss': 0.2892000123263404, 'test/num_examples': 3581, 'score': 1435.0136234760284, 'total_duration': 1725.887350320816, 'accumulated_submission_time': 1435.0136234760284, 'accumulated_eval_time': 290.4497010707855, 'accumulated_logging_time': 0.35250067710876465, 'global_step': 5428, 'preemption_count': 0})], 'global_step': 5428}
I0502 02:43:24.830544 140031580710720 submission_runner.py:581] Timing: 1435.0136234760284
I0502 02:43:24.830605 140031580710720 submission_runner.py:582] ====================
I0502 02:43:24.830730 140031580710720 submission_runner.py:645] Final fastmri score: 1435.0136234760284
