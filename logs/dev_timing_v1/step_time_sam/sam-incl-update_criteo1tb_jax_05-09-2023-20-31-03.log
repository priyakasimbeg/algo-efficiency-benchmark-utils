python3 submission_runner.py --framework=jax --workload=criteo1tb --submission_path=baselines/sam/jax/submission.py --tuning_search_space=baselines/sam/tuning_search_space.json --data_dir=/data/criteo1tb --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_fancy_verify/timing_sam --overwrite=True --save_checkpoints=False --max_global_steps=1600 2>&1 | tee -a /logs/criteo1tb_jax_05-09-2023-20-31-03.log
I0509 20:31:24.130629 139838966134592 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_fancy_verify/timing_sam/criteo1tb_jax.
I0509 20:31:24.276321 139838966134592 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0509 20:31:25.136031 139838966134592 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0509 20:31:25.136822 139838966134592 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0509 20:31:25.142917 139838966134592 submission_runner.py:547] Using RNG seed 2562360995
I0509 20:31:27.909225 139838966134592 submission_runner.py:556] --- Tuning run 1/1 ---
I0509 20:31:27.909413 139838966134592 submission_runner.py:561] Creating tuning directory at /experiment_runs/timing_fancy_verify/timing_sam/criteo1tb_jax/trial_1.
I0509 20:31:27.909595 139838966134592 logger_utils.py:92] Saving hparams to /experiment_runs/timing_fancy_verify/timing_sam/criteo1tb_jax/trial_1/hparams.json.
I0509 20:31:28.042715 139838966134592 submission_runner.py:241] Initializing dataset.
I0509 20:31:28.042947 139838966134592 submission_runner.py:248] Initializing model.
I0509 20:31:34.139881 139838966134592 submission_runner.py:258] Initializing optimizer.
I0509 20:31:36.827492 139838966134592 submission_runner.py:265] Initializing metrics bundle.
I0509 20:31:36.827699 139838966134592 submission_runner.py:283] Initializing checkpoint and logger.
I0509 20:31:36.832411 139838966134592 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_fancy_verify/timing_sam/criteo1tb_jax/trial_1 with prefix checkpoint_
I0509 20:31:36.832674 139838966134592 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0509 20:31:36.832739 139838966134592 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0509 20:31:37.529893 139838966134592 submission_runner.py:304] Saving meta data to /experiment_runs/timing_fancy_verify/timing_sam/criteo1tb_jax/trial_1/meta_data_0.json.
I0509 20:31:37.530879 139838966134592 submission_runner.py:307] Saving flags to /experiment_runs/timing_fancy_verify/timing_sam/criteo1tb_jax/trial_1/flags_0.json.
I0509 20:31:37.586133 139838966134592 submission_runner.py:319] Starting training loop.
I0509 20:32:04.189463 139662966384384 logging_writer.py:48] [0] global_step=0, grad_norm=10.654784202575684, loss=1.2167656421661377
I0509 20:32:04.198351 139838966134592 spec.py:298] Evaluating on the training split.
I0509 20:37:03.215993 139838966134592 spec.py:310] Evaluating on the validation split.
I0509 20:41:58.906833 139838966134592 spec.py:326] Evaluating on the test split.
I0509 20:47:08.241487 139838966134592 submission_runner.py:424] Time since start: 930.66s, 	Step: 1, 	{'train/loss': 1.2197986908744942, 'validation/loss': 1.227337168539326, 'validation/num_examples': 89000000, 'test/loss': 1.2223179580108514, 'test/num_examples': 89274637, 'score': 26.611990451812744, 'total_duration': 930.6552302837372, 'accumulated_submission_time': 26.611990451812744, 'accumulated_data_selection_time': 4.144645690917969, 'accumulated_eval_time': 904.0430338382721, 'accumulated_logging_time': 0}
I0509 20:47:08.258718 139650215520000 logging_writer.py:48] [1] accumulated_data_selection_time=4.144646, accumulated_eval_time=904.043034, accumulated_logging_time=0, accumulated_submission_time=26.611990, global_step=1, preemption_count=0, score=26.611990, test/loss=1.222318, test/num_examples=89274637, total_duration=930.655230, train/loss=1.219799, validation/loss=1.227337, validation/num_examples=89000000
I0509 20:48:13.433093 139650207127296 logging_writer.py:48] [100] global_step=100, grad_norm=0.272116482257843, loss=0.13122349977493286
I0509 20:49:08.956644 139838966134592 spec.py:298] Evaluating on the training split.
I0509 20:54:08.239142 139838966134592 spec.py:310] Evaluating on the validation split.
I0509 20:58:53.185937 139838966134592 spec.py:326] Evaluating on the test split.
I0509 21:03:39.391358 139838966134592 submission_runner.py:424] Time since start: 1921.81s, 	Step: 162, 	{'train/loss': 0.1296246706167506, 'validation/loss': 0.13003868539325844, 'validation/num_examples': 89000000, 'test/loss': 0.13340141612673262, 'test/num_examples': 89274637, 'score': 147.30008006095886, 'total_duration': 1921.8051104545593, 'accumulated_submission_time': 147.30008006095886, 'accumulated_data_selection_time': 119.18021535873413, 'accumulated_eval_time': 1774.4776725769043, 'accumulated_logging_time': 0.024899005889892578}
I0509 21:03:39.399640 139650215520000 logging_writer.py:48] [162] accumulated_data_selection_time=119.180215, accumulated_eval_time=1774.477673, accumulated_logging_time=0.024899, accumulated_submission_time=147.300080, global_step=162, preemption_count=0, score=147.300080, test/loss=0.133401, test/num_examples=89274637, total_duration=1921.805110, train/loss=0.129625, validation/loss=0.130039, validation/num_examples=89000000
I0509 21:03:53.057788 139650207127296 logging_writer.py:48] [200] global_step=200, grad_norm=0.137533500790596, loss=0.12660396099090576
I0509 21:05:27.154034 139650215520000 logging_writer.py:48] [300] global_step=300, grad_norm=0.12411808222532272, loss=0.12714390456676483
I0509 21:05:40.089607 139838966134592 spec.py:298] Evaluating on the training split.
I0509 21:10:42.128109 139838966134592 spec.py:310] Evaluating on the validation split.
I0509 21:15:27.458647 139838966134592 spec.py:326] Evaluating on the test split.
I0509 21:20:25.485398 139838966134592 submission_runner.py:424] Time since start: 2927.90s, 	Step: 315, 	{'train/loss': 0.12823039455568203, 'validation/loss': 0.12839149438202246, 'validation/num_examples': 89000000, 'test/loss': 0.1312880723334669, 'test/num_examples': 89274637, 'score': 267.9809651374817, 'total_duration': 2927.8991522789, 'accumulated_submission_time': 267.9809651374817, 'accumulated_data_selection_time': 234.02901530265808, 'accumulated_eval_time': 2659.8733892440796, 'accumulated_logging_time': 0.040032386779785156}
I0509 21:20:25.494659 139650207127296 logging_writer.py:48] [315] accumulated_data_selection_time=234.029015, accumulated_eval_time=2659.873389, accumulated_logging_time=0.040032, accumulated_submission_time=267.980965, global_step=315, preemption_count=0, score=267.980965, test/loss=0.131288, test/num_examples=89274637, total_duration=2927.899152, train/loss=0.128230, validation/loss=0.128391, validation/num_examples=89000000
I0509 21:21:20.518845 139650215520000 logging_writer.py:48] [400] global_step=400, grad_norm=0.0443953238427639, loss=0.12435644865036011
I0509 21:22:25.883737 139838966134592 spec.py:298] Evaluating on the training split.
I0509 21:27:25.384447 139838966134592 spec.py:310] Evaluating on the validation split.
I0509 21:32:10.435210 139838966134592 spec.py:326] Evaluating on the test split.
I0509 21:37:07.657380 139838966134592 submission_runner.py:424] Time since start: 3930.07s, 	Step: 472, 	{'train/loss': 0.12687284513112812, 'validation/loss': 0.12751601123595505, 'validation/num_examples': 89000000, 'test/loss': 0.13035830098082618, 'test/num_examples': 89274637, 'score': 388.3604702949524, 'total_duration': 3930.071148633957, 'accumulated_submission_time': 388.3604702949524, 'accumulated_data_selection_time': 348.7487795352936, 'accumulated_eval_time': 3541.6469638347626, 'accumulated_logging_time': 0.056565046310424805}
I0509 21:37:07.665529 139650207127296 logging_writer.py:48] [472] accumulated_data_selection_time=348.748780, accumulated_eval_time=3541.646964, accumulated_logging_time=0.056565, accumulated_submission_time=388.360470, global_step=472, preemption_count=0, score=388.360470, test/loss=0.130358, test/num_examples=89274637, total_duration=3930.071149, train/loss=0.126873, validation/loss=0.127516, validation/num_examples=89000000
I0509 21:37:13.006596 139650215520000 logging_writer.py:48] [500] global_step=500, grad_norm=0.034085165709257126, loss=0.1236504316329956
I0509 21:38:39.782333 139650207127296 logging_writer.py:48] [600] global_step=600, grad_norm=0.05459127575159073, loss=0.12361183762550354
I0509 21:39:07.900098 139838966134592 spec.py:298] Evaluating on the training split.
I0509 21:44:00.606489 139838966134592 spec.py:310] Evaluating on the validation split.
I0509 21:48:47.109810 139838966134592 spec.py:326] Evaluating on the test split.
I0509 21:53:34.701514 139838966134592 submission_runner.py:424] Time since start: 4917.12s, 	Step: 631, 	{'train/loss': 0.12657708960302266, 'validation/loss': 0.12723747191011237, 'validation/num_examples': 89000000, 'test/loss': 0.13022955220753235, 'test/num_examples': 89274637, 'score': 508.58462929725647, 'total_duration': 4917.115268468857, 'accumulated_submission_time': 508.58462929725647, 'accumulated_data_selection_time': 462.42064905166626, 'accumulated_eval_time': 4408.44829416275, 'accumulated_logging_time': 0.07303452491760254}
I0509 21:53:34.710830 139650215520000 logging_writer.py:48] [631] accumulated_data_selection_time=462.420649, accumulated_eval_time=4408.448294, accumulated_logging_time=0.073035, accumulated_submission_time=508.584629, global_step=631, preemption_count=0, score=508.584629, test/loss=0.130230, test/num_examples=89274637, total_duration=4917.115268, train/loss=0.126577, validation/loss=0.127237, validation/num_examples=89000000
I0509 21:54:15.220477 139650207127296 logging_writer.py:48] [700] global_step=700, grad_norm=0.058282896876335144, loss=0.12683933973312378
I0509 21:55:35.615424 139838966134592 spec.py:298] Evaluating on the training split.
I0509 22:00:33.514585 139838966134592 spec.py:310] Evaluating on the validation split.
I0509 22:05:15.941508 139838966134592 spec.py:326] Evaluating on the test split.
I0509 22:10:10.185555 139838966134592 submission_runner.py:424] Time since start: 5912.60s, 	Step: 787, 	{'train/loss': 0.12607881547424002, 'validation/loss': 0.1272241011235955, 'validation/num_examples': 89000000, 'test/loss': 0.13100147357642014, 'test/num_examples': 89274637, 'score': 629.4797487258911, 'total_duration': 5912.599316596985, 'accumulated_submission_time': 629.4797487258911, 'accumulated_data_selection_time': 577.8099946975708, 'accumulated_eval_time': 5283.018367052078, 'accumulated_logging_time': 0.08967351913452148}
I0509 22:10:10.194729 139650215520000 logging_writer.py:48] [787] accumulated_data_selection_time=577.809995, accumulated_eval_time=5283.018367, accumulated_logging_time=0.089674, accumulated_submission_time=629.479749, global_step=787, preemption_count=0, score=629.479749, test/loss=0.131001, test/num_examples=89274637, total_duration=5912.599317, train/loss=0.126079, validation/loss=0.127224, validation/num_examples=89000000
I0509 22:10:12.778799 139650207127296 logging_writer.py:48] [800] global_step=800, grad_norm=0.02852172963321209, loss=0.12077884376049042
I0509 22:11:34.405130 139650215520000 logging_writer.py:48] [900] global_step=900, grad_norm=0.017990246415138245, loss=0.1268291175365448
I0509 22:12:10.554846 139838966134592 spec.py:298] Evaluating on the training split.
I0509 22:17:10.671971 139838966134592 spec.py:310] Evaluating on the validation split.
I0509 22:21:54.731741 139838966134592 spec.py:326] Evaluating on the test split.
I0509 22:26:49.264213 139838966134592 submission_runner.py:424] Time since start: 6911.68s, 	Step: 940, 	{'train/loss': 0.1262633918049232, 'validation/loss': 0.12609652808988764, 'validation/num_examples': 89000000, 'test/loss': 0.1286651325168648, 'test/num_examples': 89274637, 'score': 749.8298985958099, 'total_duration': 6911.677984237671, 'accumulated_submission_time': 749.8298985958099, 'accumulated_data_selection_time': 692.6591494083405, 'accumulated_eval_time': 6161.727686405182, 'accumulated_logging_time': 0.10664200782775879}
I0509 22:26:49.273135 139650207127296 logging_writer.py:48] [940] accumulated_data_selection_time=692.659149, accumulated_eval_time=6161.727686, accumulated_logging_time=0.106642, accumulated_submission_time=749.829899, global_step=940, preemption_count=0, score=749.829899, test/loss=0.128665, test/num_examples=89274637, total_duration=6911.677984, train/loss=0.126263, validation/loss=0.126097, validation/num_examples=89000000
I0509 22:27:22.738564 139650215520000 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.031519562005996704, loss=0.12311413884162903
I0509 22:28:49.263515 139650207127296 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.03264151141047478, loss=0.12860068678855896
I0509 22:28:49.858876 139838966134592 spec.py:298] Evaluating on the training split.
I0509 22:33:42.145832 139838966134592 spec.py:310] Evaluating on the validation split.
I0509 22:38:24.354064 139838966134592 spec.py:326] Evaluating on the test split.
I0509 22:43:13.145455 139838966134592 submission_runner.py:424] Time since start: 7895.56s, 	Step: 1102, 	{'train/loss': 0.12381924593422323, 'validation/loss': 0.1260196629213483, 'validation/num_examples': 89000000, 'test/loss': 0.12855781200208072, 'test/num_examples': 89274637, 'score': 870.4063367843628, 'total_duration': 7895.55922460556, 'accumulated_submission_time': 870.4063367843628, 'accumulated_data_selection_time': 807.3780338764191, 'accumulated_eval_time': 7025.014199018478, 'accumulated_logging_time': 0.12267780303955078}
I0509 22:43:13.154828 139650215520000 logging_writer.py:48] [1102] accumulated_data_selection_time=807.378034, accumulated_eval_time=7025.014199, accumulated_logging_time=0.122678, accumulated_submission_time=870.406337, global_step=1102, preemption_count=0, score=870.406337, test/loss=0.128558, test/num_examples=89274637, total_duration=7895.559225, train/loss=0.123819, validation/loss=0.126020, validation/num_examples=89000000
I0509 22:44:21.468575 139650207127296 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.016146548092365265, loss=0.1296362280845642
I0509 22:45:13.769447 139838966134592 spec.py:298] Evaluating on the training split.
I0509 22:50:13.570436 139838966134592 spec.py:310] Evaluating on the validation split.
I0509 22:54:58.487437 139838966134592 spec.py:326] Evaluating on the test split.
I0509 22:59:54.082154 139838966134592 submission_runner.py:424] Time since start: 8896.50s, 	Step: 1258, 	{'train/loss': 0.12742582185028054, 'validation/loss': 0.1259612808988764, 'validation/num_examples': 89000000, 'test/loss': 0.1284949386016546, 'test/num_examples': 89274637, 'score': 991.0120124816895, 'total_duration': 8896.49592590332, 'accumulated_submission_time': 991.0120124816895, 'accumulated_data_selection_time': 922.3906142711639, 'accumulated_eval_time': 7905.326838493347, 'accumulated_logging_time': 0.1389920711517334}
I0509 22:59:54.090721 139650215520000 logging_writer.py:48] [1258] accumulated_data_selection_time=922.390614, accumulated_eval_time=7905.326838, accumulated_logging_time=0.138992, accumulated_submission_time=991.012012, global_step=1258, preemption_count=0, score=991.012012, test/loss=0.128495, test/num_examples=89274637, total_duration=8896.495926, train/loss=0.127426, validation/loss=0.125961, validation/num_examples=89000000
I0509 23:00:11.631035 139650207127296 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.015405802056193352, loss=0.11756026744842529
I0509 23:01:43.676966 139650215520000 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.019820479676127434, loss=0.12138538062572479
I0509 23:01:54.551185 139838966134592 spec.py:298] Evaluating on the training split.
I0509 23:06:53.263405 139838966134592 spec.py:310] Evaluating on the validation split.
I0509 23:11:30.101065 139838966134592 spec.py:326] Evaluating on the test split.
I0509 23:16:16.681891 139838966134592 submission_runner.py:424] Time since start: 9879.10s, 	Step: 1413, 	{'train/loss': 0.12323103589639671, 'validation/loss': 0.12545250561797752, 'validation/num_examples': 89000000, 'test/loss': 0.12810147858680176, 'test/num_examples': 89274637, 'score': 1111.4638118743896, 'total_duration': 9879.095665216446, 'accumulated_submission_time': 1111.4638118743896, 'accumulated_data_selection_time': 1037.1965544223785, 'accumulated_eval_time': 8767.457487821579, 'accumulated_logging_time': 0.154282808303833}
I0509 23:16:16.698524 139650207127296 logging_writer.py:48] [1413] accumulated_data_selection_time=1037.196554, accumulated_eval_time=8767.457488, accumulated_logging_time=0.154283, accumulated_submission_time=1111.463812, global_step=1413, preemption_count=0, score=1111.463812, test/loss=0.128101, test/num_examples=89274637, total_duration=9879.095665, train/loss=0.123231, validation/loss=0.125453, validation/num_examples=89000000
I0509 23:17:14.400725 139650215520000 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.05125050246715546, loss=0.12993235886096954
I0509 23:18:16.827647 139838966134592 spec.py:298] Evaluating on the training split.
I0509 23:23:04.758200 139838966134592 spec.py:310] Evaluating on the validation split.
I0509 23:27:45.505513 139838966134592 spec.py:326] Evaluating on the test split.
I0509 23:32:40.550553 139838966134592 submission_runner.py:424] Time since start: 10862.96s, 	Step: 1570, 	{'train/loss': 0.12430233986961921, 'validation/loss': 0.12551312359550562, 'validation/num_examples': 89000000, 'test/loss': 0.1280141189484758, 'test/num_examples': 89274637, 'score': 1231.5838642120361, 'total_duration': 10862.96432685852, 'accumulated_submission_time': 1231.5838642120361, 'accumulated_data_selection_time': 1151.7134227752686, 'accumulated_eval_time': 9631.180330753326, 'accumulated_logging_time': 0.17802047729492188}
I0509 23:32:40.558926 139650207127296 logging_writer.py:48] [1570] accumulated_data_selection_time=1151.713423, accumulated_eval_time=9631.180331, accumulated_logging_time=0.178020, accumulated_submission_time=1231.583864, global_step=1570, preemption_count=0, score=1231.583864, test/loss=0.128014, test/num_examples=89274637, total_duration=10862.964327, train/loss=0.124302, validation/loss=0.125513, validation/num_examples=89000000
I0509 23:32:45.528826 139838966134592 spec.py:298] Evaluating on the training split.
I0509 23:37:41.671257 139838966134592 spec.py:310] Evaluating on the validation split.
I0509 23:42:19.411571 139838966134592 spec.py:326] Evaluating on the test split.
I0509 23:47:12.890797 139838966134592 submission_runner.py:424] Time since start: 11735.30s, 	Step: 1600, 	{'train/loss': 0.12465643584508945, 'validation/loss': 0.12641678651685392, 'validation/num_examples': 89000000, 'test/loss': 0.12908343721408802, 'test/num_examples': 89274637, 'score': 1236.5459456443787, 'total_duration': 11735.30456662178, 'accumulated_submission_time': 1236.5459456443787, 'accumulated_data_selection_time': 1152.3154575824738, 'accumulated_eval_time': 10498.542232513428, 'accumulated_logging_time': 0.19356918334960938}
I0509 23:47:12.899520 139650215520000 logging_writer.py:48] [1600] accumulated_data_selection_time=1152.315458, accumulated_eval_time=10498.542233, accumulated_logging_time=0.193569, accumulated_submission_time=1236.545946, global_step=1600, preemption_count=0, score=1236.545946, test/loss=0.129083, test/num_examples=89274637, total_duration=11735.304567, train/loss=0.124656, validation/loss=0.126417, validation/num_examples=89000000
I0509 23:47:12.913060 139650207127296 logging_writer.py:48] [1600] global_step=1600, preemption_count=0, score=1236.545946
I0509 23:47:17.433877 139838966134592 checkpoints.py:356] Saving checkpoint at step: 1600
I0509 23:47:40.349992 139838966134592 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_fancy_verify/timing_sam/criteo1tb_jax/trial_1/checkpoint_1600
I0509 23:47:40.452810 139838966134592 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_fancy_verify/timing_sam/criteo1tb_jax/trial_1/checkpoint_1600.
I0509 23:47:40.672126 139838966134592 submission_runner.py:587] Tuning trial 1/1
I0509 23:47:40.672350 139838966134592 submission_runner.py:588] Hyperparameters: Hyperparameters(learning_rate=0.0013159053452895648, one_minus_beta1=0.2018302260773442, beta2=0.999, warmup_factor=0.05, weight_decay=0.07935861128365443, label_smoothing=0.1, dropout_rate=0.0, rho=0.01)
I0509 23:47:40.673690 139838966134592 submission_runner.py:589] Metrics: {'eval_results': [(1, {'train/loss': 1.2197986908744942, 'validation/loss': 1.227337168539326, 'validation/num_examples': 89000000, 'test/loss': 1.2223179580108514, 'test/num_examples': 89274637, 'score': 26.611990451812744, 'total_duration': 930.6552302837372, 'accumulated_submission_time': 26.611990451812744, 'accumulated_data_selection_time': 4.144645690917969, 'accumulated_eval_time': 904.0430338382721, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (162, {'train/loss': 0.1296246706167506, 'validation/loss': 0.13003868539325844, 'validation/num_examples': 89000000, 'test/loss': 0.13340141612673262, 'test/num_examples': 89274637, 'score': 147.30008006095886, 'total_duration': 1921.8051104545593, 'accumulated_submission_time': 147.30008006095886, 'accumulated_data_selection_time': 119.18021535873413, 'accumulated_eval_time': 1774.4776725769043, 'accumulated_logging_time': 0.024899005889892578, 'global_step': 162, 'preemption_count': 0}), (315, {'train/loss': 0.12823039455568203, 'validation/loss': 0.12839149438202246, 'validation/num_examples': 89000000, 'test/loss': 0.1312880723334669, 'test/num_examples': 89274637, 'score': 267.9809651374817, 'total_duration': 2927.8991522789, 'accumulated_submission_time': 267.9809651374817, 'accumulated_data_selection_time': 234.02901530265808, 'accumulated_eval_time': 2659.8733892440796, 'accumulated_logging_time': 0.040032386779785156, 'global_step': 315, 'preemption_count': 0}), (472, {'train/loss': 0.12687284513112812, 'validation/loss': 0.12751601123595505, 'validation/num_examples': 89000000, 'test/loss': 0.13035830098082618, 'test/num_examples': 89274637, 'score': 388.3604702949524, 'total_duration': 3930.071148633957, 'accumulated_submission_time': 388.3604702949524, 'accumulated_data_selection_time': 348.7487795352936, 'accumulated_eval_time': 3541.6469638347626, 'accumulated_logging_time': 0.056565046310424805, 'global_step': 472, 'preemption_count': 0}), (631, {'train/loss': 0.12657708960302266, 'validation/loss': 0.12723747191011237, 'validation/num_examples': 89000000, 'test/loss': 0.13022955220753235, 'test/num_examples': 89274637, 'score': 508.58462929725647, 'total_duration': 4917.115268468857, 'accumulated_submission_time': 508.58462929725647, 'accumulated_data_selection_time': 462.42064905166626, 'accumulated_eval_time': 4408.44829416275, 'accumulated_logging_time': 0.07303452491760254, 'global_step': 631, 'preemption_count': 0}), (787, {'train/loss': 0.12607881547424002, 'validation/loss': 0.1272241011235955, 'validation/num_examples': 89000000, 'test/loss': 0.13100147357642014, 'test/num_examples': 89274637, 'score': 629.4797487258911, 'total_duration': 5912.599316596985, 'accumulated_submission_time': 629.4797487258911, 'accumulated_data_selection_time': 577.8099946975708, 'accumulated_eval_time': 5283.018367052078, 'accumulated_logging_time': 0.08967351913452148, 'global_step': 787, 'preemption_count': 0}), (940, {'train/loss': 0.1262633918049232, 'validation/loss': 0.12609652808988764, 'validation/num_examples': 89000000, 'test/loss': 0.1286651325168648, 'test/num_examples': 89274637, 'score': 749.8298985958099, 'total_duration': 6911.677984237671, 'accumulated_submission_time': 749.8298985958099, 'accumulated_data_selection_time': 692.6591494083405, 'accumulated_eval_time': 6161.727686405182, 'accumulated_logging_time': 0.10664200782775879, 'global_step': 940, 'preemption_count': 0}), (1102, {'train/loss': 0.12381924593422323, 'validation/loss': 0.1260196629213483, 'validation/num_examples': 89000000, 'test/loss': 0.12855781200208072, 'test/num_examples': 89274637, 'score': 870.4063367843628, 'total_duration': 7895.55922460556, 'accumulated_submission_time': 870.4063367843628, 'accumulated_data_selection_time': 807.3780338764191, 'accumulated_eval_time': 7025.014199018478, 'accumulated_logging_time': 0.12267780303955078, 'global_step': 1102, 'preemption_count': 0}), (1258, {'train/loss': 0.12742582185028054, 'validation/loss': 0.1259612808988764, 'validation/num_examples': 89000000, 'test/loss': 0.1284949386016546, 'test/num_examples': 89274637, 'score': 991.0120124816895, 'total_duration': 8896.49592590332, 'accumulated_submission_time': 991.0120124816895, 'accumulated_data_selection_time': 922.3906142711639, 'accumulated_eval_time': 7905.326838493347, 'accumulated_logging_time': 0.1389920711517334, 'global_step': 1258, 'preemption_count': 0}), (1413, {'train/loss': 0.12323103589639671, 'validation/loss': 0.12545250561797752, 'validation/num_examples': 89000000, 'test/loss': 0.12810147858680176, 'test/num_examples': 89274637, 'score': 1111.4638118743896, 'total_duration': 9879.095665216446, 'accumulated_submission_time': 1111.4638118743896, 'accumulated_data_selection_time': 1037.1965544223785, 'accumulated_eval_time': 8767.457487821579, 'accumulated_logging_time': 0.154282808303833, 'global_step': 1413, 'preemption_count': 0}), (1570, {'train/loss': 0.12430233986961921, 'validation/loss': 0.12551312359550562, 'validation/num_examples': 89000000, 'test/loss': 0.1280141189484758, 'test/num_examples': 89274637, 'score': 1231.5838642120361, 'total_duration': 10862.96432685852, 'accumulated_submission_time': 1231.5838642120361, 'accumulated_data_selection_time': 1151.7134227752686, 'accumulated_eval_time': 9631.180330753326, 'accumulated_logging_time': 0.17802047729492188, 'global_step': 1570, 'preemption_count': 0}), (1600, {'train/loss': 0.12465643584508945, 'validation/loss': 0.12641678651685392, 'validation/num_examples': 89000000, 'test/loss': 0.12908343721408802, 'test/num_examples': 89274637, 'score': 1236.5459456443787, 'total_duration': 11735.30456662178, 'accumulated_submission_time': 1236.5459456443787, 'accumulated_data_selection_time': 1152.3154575824738, 'accumulated_eval_time': 10498.542232513428, 'accumulated_logging_time': 0.19356918334960938, 'global_step': 1600, 'preemption_count': 0})], 'global_step': 1600}
I0509 23:47:40.673787 139838966134592 submission_runner.py:590] Timing: 1236.5459456443787
I0509 23:47:40.673835 139838966134592 submission_runner.py:591] ====================
I0509 23:47:40.673937 139838966134592 submission_runner.py:654] Final criteo1tb score: 1236.5459456443787
