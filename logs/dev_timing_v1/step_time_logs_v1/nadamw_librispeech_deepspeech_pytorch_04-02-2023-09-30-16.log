WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
I0402 09:30:31.506706 140687865599808 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 4
I0402 09:30:31.506741 140261856704320 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 2
I0402 09:30:31.507759 139927194412864 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 6
I0402 09:30:31.507793 139752857884480 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 7
I0402 09:30:31.507859 140691275056960 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 5
I0402 09:30:31.507848 139889236358976 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 1
I0402 09:30:31.508133 139927194412864 distributed_c10d.py:353] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0402 09:30:31.507945 140448112781120 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 3
I0402 09:30:31.508156 139752857884480 distributed_c10d.py:353] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0402 09:30:31.508175 140691275056960 distributed_c10d.py:353] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0402 09:30:31.508175 140568157718336 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 0
I0402 09:30:31.508290 139889236358976 distributed_c10d.py:353] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0402 09:30:31.508339 140448112781120 distributed_c10d.py:353] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0402 09:30:31.508515 140568157718336 distributed_c10d.py:353] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0402 09:30:31.517360 140687865599808 distributed_c10d.py:353] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0402 09:30:31.517393 140261856704320 distributed_c10d.py:353] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0402 09:30:31.885892 140568157718336 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_nadamw/librispeech_deepspeech_pytorch.
W0402 09:30:31.896976 140687865599808 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0402 09:30:31.898095 139752857884480 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0402 09:30:31.898343 140261856704320 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0402 09:30:31.898568 139927194412864 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0402 09:30:31.900036 140691275056960 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0402 09:30:31.919320 140568157718336 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0402 09:30:31.923020 140568157718336 submission_runner.py:511] Using RNG seed 2167728655
I0402 09:30:31.924134 140568157718336 submission_runner.py:520] --- Tuning run 1/1 ---
I0402 09:30:31.924257 140568157718336 submission_runner.py:525] Creating tuning directory at /experiment_runs/timing_nadamw/librispeech_deepspeech_pytorch/trial_1.
I0402 09:30:31.924465 140568157718336 logger_utils.py:84] Saving hparams to /experiment_runs/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/hparams.json.
I0402 09:30:31.925399 140568157718336 submission_runner.py:230] Starting train once: RAM USED (GB) 5.806137344
I0402 09:30:31.925494 140568157718336 submission_runner.py:231] Initializing dataset.
I0402 09:30:31.925579 140568157718336 input_pipeline.py:20] Loading split = train-clean-100
W0402 09:30:31.934110 140448112781120 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0402 09:30:31.935240 139889236358976 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0402 09:30:31.956313 140568157718336 input_pipeline.py:20] Loading split = train-clean-360
I0402 09:30:32.277223 140568157718336 input_pipeline.py:20] Loading split = train-other-500
I0402 09:30:32.702629 140568157718336 submission_runner.py:239] After Initializing dataset: RAM USED (GB) 6.14127616
I0402 09:30:32.702794 140568157718336 submission_runner.py:240] Initializing model.
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
I0402 09:30:39.826855 140568157718336 submission_runner.py:251] After Initializing model: RAM USED (GB) 21.449371648
I0402 09:30:39.827035 140568157718336 submission_runner.py:252] Initializing optimizer.
I0402 09:30:39.827731 140568157718336 submission_runner.py:260] After Initializing metrics bundle: RAM USED (GB) 21.449371648
I0402 09:30:39.827848 140568157718336 submission_runner.py:261] Initializing metrics bundle.
I0402 09:30:39.827898 140568157718336 submission_runner.py:276] Initializing checkpoint and logger.
I0402 09:30:39.829201 140568157718336 logger_utils.py:231] Unable to record workload.train_mean information. Continuing without it.
I0402 09:30:39.829305 140568157718336 logger_utils.py:231] Unable to record workload.train_stddev information. Continuing without it.
I0402 09:30:40.674787 140568157718336 submission_runner.py:297] Saving meta data to /experiment_runs/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/meta_data_0.json.
I0402 09:30:40.675736 140568157718336 submission_runner.py:300] Saving flags to /experiment_runs/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/flags_0.json.
I0402 09:30:40.678969 140568157718336 submission_runner.py:305] After checkpoint and logger metrics bundle: RAM USED (GB) 21.451771904
I0402 09:30:40.679984 140568157718336 submission_runner.py:312] Before starting training loop and logger metrics bundle: RAM USED (GB) 21.451771904
I0402 09:30:40.680083 140568157718336 submission_runner.py:313] Starting training loop.
I0402 09:30:43.092349 140568157718336 submission_runner.py:335] After dataselection batch at step 0: RAM USED (GB) 25.945432064
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
I0402 09:30:49.543548 140541655512832 logging_writer.py:48] [0] global_step=0, grad_norm=24.539379, loss=33.533714
I0402 09:30:49.553167 140568157718336 submission.py:296] 0) loss = 33.534, grad_norm = 24.539
I0402 09:30:49.553878 140568157718336 submission_runner.py:352] After update parameters step 0: RAM USED (GB) 31.717470208
I0402 09:30:49.554467 140568157718336 submission_runner.py:373] Before eval at step 1: RAM USED (GB) 31.717986304
I0402 09:30:49.554585 140568157718336 spec.py:298] Evaluating on the training split.
I0402 09:30:49.555388 140568157718336 input_pipeline.py:20] Loading split = train-clean-100
I0402 09:30:49.583567 140568157718336 input_pipeline.py:20] Loading split = train-clean-360
I0402 09:30:49.992385 140568157718336 input_pipeline.py:20] Loading split = train-other-500
I0402 09:31:05.540281 140568157718336 spec.py:310] Evaluating on the validation split.
I0402 09:31:05.541411 140568157718336 input_pipeline.py:20] Loading split = dev-clean
I0402 09:31:05.544641 140568157718336 input_pipeline.py:20] Loading split = dev-other
I0402 09:31:16.755021 140568157718336 spec.py:326] Evaluating on the test split.
I0402 09:31:16.756271 140568157718336 input_pipeline.py:20] Loading split = test-clean
I0402 09:31:23.596364 140568157718336 submission_runner.py:382] Time since start: 8.87s, 	Step: 1, 	{'train/ctc_loss': 32.169664992474594, 'train/wer': 3.50590178901376, 'validation/ctc_loss': 31.201392028330318, 'validation/wer': 3.277506879737363, 'validation/num_examples': 5348, 'test/ctc_loss': 31.254771275566167, 'test/wer': 3.4408425243231164, 'test/num_examples': 2472}
I0402 09:31:23.597101 140568157718336 submission_runner.py:396] After eval at step 1: RAM USED (GB) 45.564534784
I0402 09:31:23.609826 140538804168448 logging_writer.py:48] [1] global_step=1, preemption_count=0, score=8.873028, test/ctc_loss=31.254771, test/num_examples=2472, test/wer=3.440843, total_duration=8.874912, train/ctc_loss=32.169665, train/wer=3.505902, validation/ctc_loss=31.201392, validation/num_examples=5348, validation/wer=3.277507
I0402 09:31:23.887137 140568157718336 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/checkpoint_1.
I0402 09:31:23.887633 140568157718336 submission_runner.py:416] After logging and checkpointing eval at step 1: RAM USED (GB) 45.593628672
I0402 09:31:23.890704 140568157718336 submission_runner.py:335] After dataselection batch at step 1: RAM USED (GB) 45.597466624
I0402 09:31:23.926541 140568157718336 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0402 09:31:23.926843 140448112781120 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0402 09:31:23.926903 140261856704320 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0402 09:31:23.927752 139752857884480 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0402 09:31:23.928024 139927194412864 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0402 09:31:23.928590 140687865599808 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0402 09:31:23.928612 139889236358976 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0402 09:31:23.929280 140691275056960 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0402 09:31:25.011323 140538795775744 logging_writer.py:48] [1] global_step=1, grad_norm=21.600601, loss=32.952045
I0402 09:31:25.015058 140568157718336 submission.py:296] 1) loss = 32.952, grad_norm = 21.601
I0402 09:31:25.015946 140568157718336 submission_runner.py:352] After update parameters step 1: RAM USED (GB) 45.783855104
I0402 09:31:25.950599 140538804168448 logging_writer.py:48] [2] global_step=2, grad_norm=21.751791, loss=33.507534
I0402 09:31:25.953817 140568157718336 submission.py:296] 2) loss = 33.508, grad_norm = 21.752
I0402 09:31:26.786627 140538795775744 logging_writer.py:48] [3] global_step=3, grad_norm=24.057087, loss=33.455868
I0402 09:31:26.789957 140568157718336 submission.py:296] 3) loss = 33.456, grad_norm = 24.057
I0402 09:31:27.605610 140538804168448 logging_writer.py:48] [4] global_step=4, grad_norm=27.754051, loss=33.047508
I0402 09:31:27.608707 140568157718336 submission.py:296] 4) loss = 33.048, grad_norm = 27.754
I0402 09:31:28.423181 140538795775744 logging_writer.py:48] [5] global_step=5, grad_norm=31.747780, loss=33.219185
I0402 09:31:28.427011 140568157718336 submission.py:296] 5) loss = 33.219, grad_norm = 31.748
I0402 09:31:29.235869 140538804168448 logging_writer.py:48] [6] global_step=6, grad_norm=36.547470, loss=33.417713
I0402 09:31:29.239020 140568157718336 submission.py:296] 6) loss = 33.418, grad_norm = 36.547
I0402 09:31:30.041298 140538795775744 logging_writer.py:48] [7] global_step=7, grad_norm=44.579823, loss=32.273991
I0402 09:31:30.044461 140568157718336 submission.py:296] 7) loss = 32.274, grad_norm = 44.580
I0402 09:31:30.852028 140538804168448 logging_writer.py:48] [8] global_step=8, grad_norm=54.474903, loss=32.653900
I0402 09:31:30.855295 140568157718336 submission.py:296] 8) loss = 32.654, grad_norm = 54.475
I0402 09:31:31.679141 140538795775744 logging_writer.py:48] [9] global_step=9, grad_norm=55.587379, loss=32.171253
I0402 09:31:31.682338 140568157718336 submission.py:296] 9) loss = 32.171, grad_norm = 55.587
I0402 09:31:32.488698 140538804168448 logging_writer.py:48] [10] global_step=10, grad_norm=60.121025, loss=31.928965
I0402 09:31:32.492459 140568157718336 submission.py:296] 10) loss = 31.929, grad_norm = 60.121
I0402 09:31:33.297439 140538795775744 logging_writer.py:48] [11] global_step=11, grad_norm=61.360989, loss=31.902317
I0402 09:31:33.300832 140568157718336 submission.py:296] 11) loss = 31.902, grad_norm = 61.361
I0402 09:31:34.110502 140538804168448 logging_writer.py:48] [12] global_step=12, grad_norm=61.342522, loss=31.807268
I0402 09:31:34.113598 140568157718336 submission.py:296] 12) loss = 31.807, grad_norm = 61.343
I0402 09:31:34.921130 140538795775744 logging_writer.py:48] [13] global_step=13, grad_norm=58.751072, loss=31.245409
I0402 09:31:34.924514 140568157718336 submission.py:296] 13) loss = 31.245, grad_norm = 58.751
I0402 09:31:35.726516 140538804168448 logging_writer.py:48] [14] global_step=14, grad_norm=56.422146, loss=30.892723
I0402 09:31:35.729595 140568157718336 submission.py:296] 14) loss = 30.893, grad_norm = 56.422
I0402 09:31:36.535467 140538795775744 logging_writer.py:48] [15] global_step=15, grad_norm=53.365269, loss=29.920774
I0402 09:31:36.538955 140568157718336 submission.py:296] 15) loss = 29.921, grad_norm = 53.365
I0402 09:31:37.342376 140538804168448 logging_writer.py:48] [16] global_step=16, grad_norm=52.463875, loss=30.196712
I0402 09:31:37.345737 140568157718336 submission.py:296] 16) loss = 30.197, grad_norm = 52.464
I0402 09:31:38.152161 140538795775744 logging_writer.py:48] [17] global_step=17, grad_norm=49.135765, loss=29.789291
I0402 09:31:38.155505 140568157718336 submission.py:296] 17) loss = 29.789, grad_norm = 49.136
I0402 09:31:38.967730 140538804168448 logging_writer.py:48] [18] global_step=18, grad_norm=46.369217, loss=29.377359
I0402 09:31:38.971691 140568157718336 submission.py:296] 18) loss = 29.377, grad_norm = 46.369
I0402 09:31:39.773599 140538795775744 logging_writer.py:48] [19] global_step=19, grad_norm=40.468410, loss=28.854031
I0402 09:31:39.776740 140568157718336 submission.py:296] 19) loss = 28.854, grad_norm = 40.468
I0402 09:31:40.587802 140538804168448 logging_writer.py:48] [20] global_step=20, grad_norm=39.765491, loss=28.155638
I0402 09:31:40.590970 140568157718336 submission.py:296] 20) loss = 28.156, grad_norm = 39.765
I0402 09:31:41.406187 140538795775744 logging_writer.py:48] [21] global_step=21, grad_norm=36.481495, loss=28.252237
I0402 09:31:41.409247 140568157718336 submission.py:296] 21) loss = 28.252, grad_norm = 36.481
I0402 09:31:42.213837 140538804168448 logging_writer.py:48] [22] global_step=22, grad_norm=36.470024, loss=28.502605
I0402 09:31:42.216804 140568157718336 submission.py:296] 22) loss = 28.503, grad_norm = 36.470
I0402 09:31:43.034726 140538795775744 logging_writer.py:48] [23] global_step=23, grad_norm=32.770020, loss=27.598337
I0402 09:31:43.037763 140568157718336 submission.py:296] 23) loss = 27.598, grad_norm = 32.770
I0402 09:31:43.852117 140538804168448 logging_writer.py:48] [24] global_step=24, grad_norm=33.412823, loss=27.698763
I0402 09:31:43.855254 140568157718336 submission.py:296] 24) loss = 27.699, grad_norm = 33.413
I0402 09:31:44.661914 140538795775744 logging_writer.py:48] [25] global_step=25, grad_norm=31.062151, loss=27.597906
I0402 09:31:44.664986 140568157718336 submission.py:296] 25) loss = 27.598, grad_norm = 31.062
I0402 09:31:45.475732 140538804168448 logging_writer.py:48] [26] global_step=26, grad_norm=31.625763, loss=27.165535
I0402 09:31:45.478861 140568157718336 submission.py:296] 26) loss = 27.166, grad_norm = 31.626
I0402 09:31:46.295921 140538795775744 logging_writer.py:48] [27] global_step=27, grad_norm=28.801416, loss=27.306154
I0402 09:31:46.299472 140568157718336 submission.py:296] 27) loss = 27.306, grad_norm = 28.801
I0402 09:31:47.120072 140538804168448 logging_writer.py:48] [28] global_step=28, grad_norm=28.999506, loss=26.824709
I0402 09:31:47.123233 140568157718336 submission.py:296] 28) loss = 26.825, grad_norm = 29.000
I0402 09:31:47.929258 140538795775744 logging_writer.py:48] [29] global_step=29, grad_norm=27.470417, loss=26.275360
I0402 09:31:47.932533 140568157718336 submission.py:296] 29) loss = 26.275, grad_norm = 27.470
I0402 09:31:48.758291 140538804168448 logging_writer.py:48] [30] global_step=30, grad_norm=26.985748, loss=26.067713
I0402 09:31:48.761479 140568157718336 submission.py:296] 30) loss = 26.068, grad_norm = 26.986
I0402 09:31:49.582900 140538795775744 logging_writer.py:48] [31] global_step=31, grad_norm=26.810097, loss=26.128197
I0402 09:31:49.585898 140568157718336 submission.py:296] 31) loss = 26.128, grad_norm = 26.810
I0402 09:31:50.405006 140538804168448 logging_writer.py:48] [32] global_step=32, grad_norm=26.296112, loss=25.642931
I0402 09:31:50.408361 140568157718336 submission.py:296] 32) loss = 25.643, grad_norm = 26.296
I0402 09:31:51.230499 140538795775744 logging_writer.py:48] [33] global_step=33, grad_norm=26.714685, loss=25.899199
I0402 09:31:51.233775 140568157718336 submission.py:296] 33) loss = 25.899, grad_norm = 26.715
I0402 09:31:52.046727 140538804168448 logging_writer.py:48] [34] global_step=34, grad_norm=25.053486, loss=25.703894
I0402 09:31:52.049757 140568157718336 submission.py:296] 34) loss = 25.704, grad_norm = 25.053
I0402 09:31:52.865935 140538795775744 logging_writer.py:48] [35] global_step=35, grad_norm=25.217241, loss=25.333601
I0402 09:31:52.869038 140568157718336 submission.py:296] 35) loss = 25.334, grad_norm = 25.217
I0402 09:31:53.679027 140538804168448 logging_writer.py:48] [36] global_step=36, grad_norm=25.177404, loss=24.980896
I0402 09:31:53.682912 140568157718336 submission.py:296] 36) loss = 24.981, grad_norm = 25.177
I0402 09:31:54.494974 140538795775744 logging_writer.py:48] [37] global_step=37, grad_norm=25.039797, loss=24.473051
I0402 09:31:54.498057 140568157718336 submission.py:296] 37) loss = 24.473, grad_norm = 25.040
I0402 09:31:55.311394 140538804168448 logging_writer.py:48] [38] global_step=38, grad_norm=24.700672, loss=24.533094
I0402 09:31:55.314553 140568157718336 submission.py:296] 38) loss = 24.533, grad_norm = 24.701
I0402 09:31:56.131340 140538795775744 logging_writer.py:48] [39] global_step=39, grad_norm=25.059639, loss=24.235943
I0402 09:31:56.134619 140568157718336 submission.py:296] 39) loss = 24.236, grad_norm = 25.060
I0402 09:31:56.950468 140538804168448 logging_writer.py:48] [40] global_step=40, grad_norm=25.305489, loss=23.866745
I0402 09:31:56.953682 140568157718336 submission.py:296] 40) loss = 23.867, grad_norm = 25.305
I0402 09:31:57.789057 140538795775744 logging_writer.py:48] [41] global_step=41, grad_norm=24.866545, loss=23.257423
I0402 09:31:57.792259 140568157718336 submission.py:296] 41) loss = 23.257, grad_norm = 24.867
I0402 09:31:58.607369 140538804168448 logging_writer.py:48] [42] global_step=42, grad_norm=24.439093, loss=23.375994
I0402 09:31:58.610516 140568157718336 submission.py:296] 42) loss = 23.376, grad_norm = 24.439
I0402 09:31:59.437455 140538795775744 logging_writer.py:48] [43] global_step=43, grad_norm=24.164291, loss=22.819223
I0402 09:31:59.441314 140568157718336 submission.py:296] 43) loss = 22.819, grad_norm = 24.164
I0402 09:32:00.250634 140538804168448 logging_writer.py:48] [44] global_step=44, grad_norm=24.691811, loss=22.308289
I0402 09:32:00.254290 140568157718336 submission.py:296] 44) loss = 22.308, grad_norm = 24.692
I0402 09:32:01.075783 140538795775744 logging_writer.py:48] [45] global_step=45, grad_norm=23.831240, loss=22.022871
I0402 09:32:01.079061 140568157718336 submission.py:296] 45) loss = 22.023, grad_norm = 23.831
I0402 09:32:01.900491 140538804168448 logging_writer.py:48] [46] global_step=46, grad_norm=24.573259, loss=21.443594
I0402 09:32:01.903991 140568157718336 submission.py:296] 46) loss = 21.444, grad_norm = 24.573
I0402 09:32:02.724677 140538795775744 logging_writer.py:48] [47] global_step=47, grad_norm=24.221325, loss=21.450207
I0402 09:32:02.727766 140568157718336 submission.py:296] 47) loss = 21.450, grad_norm = 24.221
I0402 09:32:03.553478 140538804168448 logging_writer.py:48] [48] global_step=48, grad_norm=24.241552, loss=21.446676
I0402 09:32:03.556590 140568157718336 submission.py:296] 48) loss = 21.447, grad_norm = 24.242
I0402 09:32:04.361732 140538795775744 logging_writer.py:48] [49] global_step=49, grad_norm=23.103426, loss=21.187073
I0402 09:32:04.365116 140568157718336 submission.py:296] 49) loss = 21.187, grad_norm = 23.103
I0402 09:32:05.173270 140538804168448 logging_writer.py:48] [50] global_step=50, grad_norm=23.035660, loss=20.565990
I0402 09:32:05.176492 140568157718336 submission.py:296] 50) loss = 20.566, grad_norm = 23.036
I0402 09:32:06.011874 140538795775744 logging_writer.py:48] [51] global_step=51, grad_norm=23.177757, loss=19.779203
I0402 09:32:06.015047 140568157718336 submission.py:296] 51) loss = 19.779, grad_norm = 23.178
I0402 09:32:06.835808 140538804168448 logging_writer.py:48] [52] global_step=52, grad_norm=22.304913, loss=19.493080
I0402 09:32:06.839494 140568157718336 submission.py:296] 52) loss = 19.493, grad_norm = 22.305
I0402 09:32:07.654166 140538795775744 logging_writer.py:48] [53] global_step=53, grad_norm=22.075300, loss=18.955320
I0402 09:32:07.657634 140568157718336 submission.py:296] 53) loss = 18.955, grad_norm = 22.075
I0402 09:32:08.466063 140538804168448 logging_writer.py:48] [54] global_step=54, grad_norm=23.967148, loss=19.197289
I0402 09:32:08.469556 140568157718336 submission.py:296] 54) loss = 19.197, grad_norm = 23.967
I0402 09:32:09.300681 140538795775744 logging_writer.py:48] [55] global_step=55, grad_norm=22.969522, loss=19.130360
I0402 09:32:09.304179 140568157718336 submission.py:296] 55) loss = 19.130, grad_norm = 22.970
I0402 09:32:10.125001 140538804168448 logging_writer.py:48] [56] global_step=56, grad_norm=22.492050, loss=18.096048
I0402 09:32:10.128429 140568157718336 submission.py:296] 56) loss = 18.096, grad_norm = 22.492
I0402 09:32:10.950344 140538795775744 logging_writer.py:48] [57] global_step=57, grad_norm=22.517302, loss=18.355225
I0402 09:32:10.954077 140568157718336 submission.py:296] 57) loss = 18.355, grad_norm = 22.517
I0402 09:32:11.766869 140538804168448 logging_writer.py:48] [58] global_step=58, grad_norm=20.952690, loss=17.518538
I0402 09:32:11.769997 140568157718336 submission.py:296] 58) loss = 17.519, grad_norm = 20.953
I0402 09:32:12.586742 140538795775744 logging_writer.py:48] [59] global_step=59, grad_norm=20.795078, loss=17.233160
I0402 09:32:12.589918 140568157718336 submission.py:296] 59) loss = 17.233, grad_norm = 20.795
I0402 09:32:13.413524 140538804168448 logging_writer.py:48] [60] global_step=60, grad_norm=20.053179, loss=17.155289
I0402 09:32:13.416868 140568157718336 submission.py:296] 60) loss = 17.155, grad_norm = 20.053
I0402 09:32:14.236117 140538795775744 logging_writer.py:48] [61] global_step=61, grad_norm=19.590443, loss=16.723814
I0402 09:32:14.239368 140568157718336 submission.py:296] 61) loss = 16.724, grad_norm = 19.590
I0402 09:32:15.058943 140538804168448 logging_writer.py:48] [62] global_step=62, grad_norm=19.010653, loss=16.613314
I0402 09:32:15.062066 140568157718336 submission.py:296] 62) loss = 16.613, grad_norm = 19.011
I0402 09:32:15.872443 140538795775744 logging_writer.py:48] [63] global_step=63, grad_norm=19.326092, loss=16.245579
I0402 09:32:15.875620 140568157718336 submission.py:296] 63) loss = 16.246, grad_norm = 19.326
I0402 09:32:16.691478 140538804168448 logging_writer.py:48] [64] global_step=64, grad_norm=18.226196, loss=15.981636
I0402 09:32:16.694669 140568157718336 submission.py:296] 64) loss = 15.982, grad_norm = 18.226
I0402 09:32:17.506831 140538795775744 logging_writer.py:48] [65] global_step=65, grad_norm=17.847666, loss=15.837159
I0402 09:32:17.509950 140568157718336 submission.py:296] 65) loss = 15.837, grad_norm = 17.848
I0402 09:32:18.328542 140538804168448 logging_writer.py:48] [66] global_step=66, grad_norm=17.278675, loss=15.413527
I0402 09:32:18.332580 140568157718336 submission.py:296] 66) loss = 15.414, grad_norm = 17.279
I0402 09:32:19.148666 140538795775744 logging_writer.py:48] [67] global_step=67, grad_norm=16.272156, loss=15.016862
I0402 09:32:19.152203 140568157718336 submission.py:296] 67) loss = 15.017, grad_norm = 16.272
I0402 09:32:19.964510 140538804168448 logging_writer.py:48] [68] global_step=68, grad_norm=15.576298, loss=14.231544
I0402 09:32:19.967655 140568157718336 submission.py:296] 68) loss = 14.232, grad_norm = 15.576
I0402 09:32:20.778944 140538795775744 logging_writer.py:48] [69] global_step=69, grad_norm=15.779198, loss=15.141209
I0402 09:32:20.782045 140568157718336 submission.py:296] 69) loss = 15.141, grad_norm = 15.779
I0402 09:32:21.592126 140538804168448 logging_writer.py:48] [70] global_step=70, grad_norm=15.398905, loss=14.077682
I0402 09:32:21.595484 140568157718336 submission.py:296] 70) loss = 14.078, grad_norm = 15.399
I0402 09:32:22.407497 140538795775744 logging_writer.py:48] [71] global_step=71, grad_norm=15.532272, loss=14.536599
I0402 09:32:22.411039 140568157718336 submission.py:296] 71) loss = 14.537, grad_norm = 15.532
I0402 09:32:23.232495 140538804168448 logging_writer.py:48] [72] global_step=72, grad_norm=13.623838, loss=13.540189
I0402 09:32:23.236104 140568157718336 submission.py:296] 72) loss = 13.540, grad_norm = 13.624
I0402 09:32:24.043367 140538795775744 logging_writer.py:48] [73] global_step=73, grad_norm=13.382317, loss=13.352433
I0402 09:32:24.046514 140568157718336 submission.py:296] 73) loss = 13.352, grad_norm = 13.382
I0402 09:32:24.874537 140538804168448 logging_writer.py:48] [74] global_step=74, grad_norm=12.498195, loss=13.282885
I0402 09:32:24.877588 140568157718336 submission.py:296] 74) loss = 13.283, grad_norm = 12.498
I0402 09:32:25.691044 140538795775744 logging_writer.py:48] [75] global_step=75, grad_norm=12.844225, loss=13.231102
I0402 09:32:25.694773 140568157718336 submission.py:296] 75) loss = 13.231, grad_norm = 12.844
I0402 09:32:26.515033 140538804168448 logging_writer.py:48] [76] global_step=76, grad_norm=11.705774, loss=12.966569
I0402 09:32:26.518872 140568157718336 submission.py:296] 76) loss = 12.967, grad_norm = 11.706
I0402 09:32:27.340418 140538795775744 logging_writer.py:48] [77] global_step=77, grad_norm=11.866685, loss=12.553115
I0402 09:32:27.344327 140568157718336 submission.py:296] 77) loss = 12.553, grad_norm = 11.867
I0402 09:32:28.176212 140538804168448 logging_writer.py:48] [78] global_step=78, grad_norm=10.839085, loss=12.345469
I0402 09:32:28.179351 140568157718336 submission.py:296] 78) loss = 12.345, grad_norm = 10.839
I0402 09:32:28.994557 140538795775744 logging_writer.py:48] [79] global_step=79, grad_norm=13.721117, loss=12.290113
I0402 09:32:28.997968 140568157718336 submission.py:296] 79) loss = 12.290, grad_norm = 13.721
I0402 09:32:29.814287 140538804168448 logging_writer.py:48] [80] global_step=80, grad_norm=11.163658, loss=12.303708
I0402 09:32:29.817319 140568157718336 submission.py:296] 80) loss = 12.304, grad_norm = 11.164
I0402 09:32:30.633686 140538795775744 logging_writer.py:48] [81] global_step=81, grad_norm=11.216975, loss=12.064061
I0402 09:32:30.637336 140568157718336 submission.py:296] 81) loss = 12.064, grad_norm = 11.217
I0402 09:32:31.455279 140538804168448 logging_writer.py:48] [82] global_step=82, grad_norm=12.814386, loss=11.774319
I0402 09:32:31.458737 140568157718336 submission.py:296] 82) loss = 11.774, grad_norm = 12.814
I0402 09:32:32.271589 140538795775744 logging_writer.py:48] [83] global_step=83, grad_norm=9.934140, loss=11.757623
I0402 09:32:32.274678 140568157718336 submission.py:296] 83) loss = 11.758, grad_norm = 9.934
I0402 09:32:33.097812 140538804168448 logging_writer.py:48] [84] global_step=84, grad_norm=8.820364, loss=11.395703
I0402 09:32:33.101659 140568157718336 submission.py:296] 84) loss = 11.396, grad_norm = 8.820
I0402 09:32:33.911404 140538795775744 logging_writer.py:48] [85] global_step=85, grad_norm=10.710822, loss=11.818809
I0402 09:32:33.915210 140568157718336 submission.py:296] 85) loss = 11.819, grad_norm = 10.711
I0402 09:32:34.739060 140538804168448 logging_writer.py:48] [86] global_step=86, grad_norm=11.725448, loss=10.988503
I0402 09:32:34.742809 140568157718336 submission.py:296] 86) loss = 10.989, grad_norm = 11.725
I0402 09:32:35.547602 140538795775744 logging_writer.py:48] [87] global_step=87, grad_norm=11.035379, loss=11.027478
I0402 09:32:35.550761 140568157718336 submission.py:296] 87) loss = 11.027, grad_norm = 11.035
I0402 09:32:36.353829 140538804168448 logging_writer.py:48] [88] global_step=88, grad_norm=9.868519, loss=10.921372
I0402 09:32:36.357062 140568157718336 submission.py:296] 88) loss = 10.921, grad_norm = 9.869
I0402 09:32:37.165612 140538795775744 logging_writer.py:48] [89] global_step=89, grad_norm=10.611120, loss=11.035037
I0402 09:32:37.168656 140568157718336 submission.py:296] 89) loss = 11.035, grad_norm = 10.611
I0402 09:32:37.984530 140538804168448 logging_writer.py:48] [90] global_step=90, grad_norm=9.876185, loss=10.488017
I0402 09:32:37.987560 140568157718336 submission.py:296] 90) loss = 10.488, grad_norm = 9.876
I0402 09:32:38.793181 140538795775744 logging_writer.py:48] [91] global_step=91, grad_norm=9.064082, loss=10.559031
I0402 09:32:38.796683 140568157718336 submission.py:296] 91) loss = 10.559, grad_norm = 9.064
I0402 09:32:39.608727 140538804168448 logging_writer.py:48] [92] global_step=92, grad_norm=8.199316, loss=10.184097
I0402 09:32:39.611788 140568157718336 submission.py:296] 92) loss = 10.184, grad_norm = 8.199
I0402 09:32:40.423060 140538795775744 logging_writer.py:48] [93] global_step=93, grad_norm=7.628617, loss=10.123816
I0402 09:32:40.426283 140568157718336 submission.py:296] 93) loss = 10.124, grad_norm = 7.629
I0402 09:32:41.235394 140538804168448 logging_writer.py:48] [94] global_step=94, grad_norm=6.702904, loss=9.899435
I0402 09:32:41.238522 140568157718336 submission.py:296] 94) loss = 9.899, grad_norm = 6.703
I0402 09:32:42.048490 140538795775744 logging_writer.py:48] [95] global_step=95, grad_norm=7.276441, loss=9.912449
I0402 09:32:42.051598 140568157718336 submission.py:296] 95) loss = 9.912, grad_norm = 7.276
I0402 09:32:42.868965 140538804168448 logging_writer.py:48] [96] global_step=96, grad_norm=6.927465, loss=9.847276
I0402 09:32:42.872402 140568157718336 submission.py:296] 96) loss = 9.847, grad_norm = 6.927
I0402 09:32:43.678625 140538795775744 logging_writer.py:48] [97] global_step=97, grad_norm=5.939262, loss=9.804353
I0402 09:32:43.681675 140568157718336 submission.py:296] 97) loss = 9.804, grad_norm = 5.939
I0402 09:32:44.491281 140538804168448 logging_writer.py:48] [98] global_step=98, grad_norm=5.827161, loss=9.470285
I0402 09:32:44.495071 140568157718336 submission.py:296] 98) loss = 9.470, grad_norm = 5.827
I0402 09:32:45.314444 140538795775744 logging_writer.py:48] [99] global_step=99, grad_norm=5.733026, loss=9.326265
I0402 09:32:45.317629 140568157718336 submission.py:296] 99) loss = 9.326, grad_norm = 5.733
I0402 09:32:46.125635 140538804168448 logging_writer.py:48] [100] global_step=100, grad_norm=4.993785, loss=9.466602
I0402 09:32:46.129285 140568157718336 submission.py:296] 100) loss = 9.467, grad_norm = 4.994
I0402 09:38:09.404239 140538795775744 logging_writer.py:48] [500] global_step=500, grad_norm=0.556526, loss=5.766938
I0402 09:38:09.409259 140568157718336 submission.py:296] 500) loss = 5.767, grad_norm = 0.557
I0402 09:44:52.837222 140538804168448 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.817413, loss=4.854445
I0402 09:44:52.841029 140568157718336 submission.py:296] 1000) loss = 4.854, grad_norm = 0.817
I0402 09:51:36.905603 140538804168448 logging_writer.py:48] [1500] global_step=1500, grad_norm=4.710023, loss=3.710645
I0402 09:51:36.917991 140568157718336 submission.py:296] 1500) loss = 3.711, grad_norm = 4.710
I0402 09:58:21.056245 140538795775744 logging_writer.py:48] [2000] global_step=2000, grad_norm=2.783219, loss=3.031913
I0402 09:58:21.061661 140568157718336 submission.py:296] 2000) loss = 3.032, grad_norm = 2.783
I0402 10:05:05.667860 140538804168448 logging_writer.py:48] [2500] global_step=2500, grad_norm=2.450327, loss=2.764908
I0402 10:05:05.674825 140568157718336 submission.py:296] 2500) loss = 2.765, grad_norm = 2.450
I0402 10:11:24.850827 140568157718336 submission_runner.py:373] Before eval at step 2971: RAM USED (GB) 43.499728896
I0402 10:11:24.855575 140568157718336 spec.py:298] Evaluating on the training split.
I0402 10:11:34.765012 140568157718336 spec.py:310] Evaluating on the validation split.
I0402 10:11:43.609145 140568157718336 spec.py:326] Evaluating on the test split.
I0402 10:11:48.640651 140568157718336 submission_runner.py:382] Time since start: 2443.85s, 	Step: 2971, 	{'train/ctc_loss': 5.241692033213265, 'train/wer': 0.9200812990457145, 'validation/ctc_loss': 5.172564499824191, 'validation/wer': 0.8813981557475982, 'validation/num_examples': 5348, 'test/ctc_loss': 4.9767009161881415, 'test/wer': 0.8792476590904474, 'test/num_examples': 2472}
I0402 10:11:48.641483 140568157718336 submission_runner.py:396] After eval at step 2971: RAM USED (GB) 41.835593728
I0402 10:11:48.675113 140538804168448 logging_writer.py:48] [2971] global_step=2971, preemption_count=0, score=1500.425703, test/ctc_loss=4.976701, test/num_examples=2472, test/wer=0.879248, total_duration=2443.853613, train/ctc_loss=5.241692, train/wer=0.920081, validation/ctc_loss=5.172564, validation/num_examples=5348, validation/wer=0.881398
I0402 10:11:48.967180 140568157718336 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/checkpoint_2971.
I0402 10:11:48.967707 140568157718336 submission_runner.py:416] After logging and checkpointing eval at step 2971: RAM USED (GB) 41.840627712
I0402 10:12:13.068272 140538795775744 logging_writer.py:48] [3000] global_step=3000, grad_norm=3.773912, loss=2.552432
I0402 10:12:13.071546 140568157718336 submission.py:296] 3000) loss = 2.552, grad_norm = 3.774
I0402 10:18:57.381994 140538804168448 logging_writer.py:48] [3500] global_step=3500, grad_norm=2.901509, loss=2.384974
I0402 10:18:57.388417 140568157718336 submission.py:296] 3500) loss = 2.385, grad_norm = 2.902
I0402 10:25:39.025198 140538795775744 logging_writer.py:48] [4000] global_step=4000, grad_norm=3.314337, loss=2.277715
I0402 10:25:39.029186 140568157718336 submission.py:296] 4000) loss = 2.278, grad_norm = 3.314
I0402 10:32:22.593516 140538804168448 logging_writer.py:48] [4500] global_step=4500, grad_norm=4.913593, loss=2.145668
I0402 10:32:22.599609 140568157718336 submission.py:296] 4500) loss = 2.146, grad_norm = 4.914
I0402 10:39:04.179560 140538795775744 logging_writer.py:48] [5000] global_step=5000, grad_norm=3.745217, loss=2.061004
I0402 10:39:04.183622 140568157718336 submission.py:296] 5000) loss = 2.061, grad_norm = 3.745
I0402 10:45:47.945595 140538804168448 logging_writer.py:48] [5500] global_step=5500, grad_norm=3.256714, loss=2.011354
I0402 10:45:47.952169 140568157718336 submission.py:296] 5500) loss = 2.011, grad_norm = 3.257
I0402 10:51:49.852739 140568157718336 submission_runner.py:373] Before eval at step 5952: RAM USED (GB) 41.808613376
I0402 10:51:49.852968 140568157718336 spec.py:298] Evaluating on the training split.
I0402 10:52:00.661131 140568157718336 spec.py:310] Evaluating on the validation split.
I0402 10:52:10.007886 140568157718336 spec.py:326] Evaluating on the test split.
I0402 10:52:15.307029 140568157718336 submission_runner.py:382] Time since start: 4868.87s, 	Step: 5952, 	{'train/ctc_loss': 0.8957585020208683, 'train/wer': 0.2890354976849336, 'validation/ctc_loss': 1.1607007468731163, 'validation/wer': 0.32268623569738814, 'validation/num_examples': 5348, 'test/ctc_loss': 0.7933757319020582, 'test/wer': 0.2546868969999797, 'test/num_examples': 2472}
I0402 10:52:15.307804 140568157718336 submission_runner.py:396] After eval at step 5952: RAM USED (GB) 41.603588096
I0402 10:52:15.324640 140538804168448 logging_writer.py:48] [5952] global_step=5952, preemption_count=0, score=2962.771208, test/ctc_loss=0.793376, test/num_examples=2472, test/wer=0.254687, total_duration=4868.865504, train/ctc_loss=0.895759, train/wer=0.289035, validation/ctc_loss=1.160701, validation/num_examples=5348, validation/wer=0.322686
I0402 10:52:15.613127 140568157718336 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/checkpoint_5952.
I0402 10:52:15.613669 140568157718336 submission_runner.py:416] After logging and checkpointing eval at step 5952: RAM USED (GB) 41.609142272
I0402 10:52:54.789625 140538795775744 logging_writer.py:48] [6000] global_step=6000, grad_norm=2.865999, loss=1.988863
I0402 10:52:54.794123 140568157718336 submission.py:296] 6000) loss = 1.989, grad_norm = 2.866
I0402 10:59:38.323671 140538804168448 logging_writer.py:48] [6500] global_step=6500, grad_norm=2.903666, loss=1.825194
I0402 10:59:38.330569 140568157718336 submission.py:296] 6500) loss = 1.825, grad_norm = 2.904
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
I0402 11:06:19.491775 140538795775744 logging_writer.py:48] [7000] global_step=7000, grad_norm=3.612369, loss=1.909395
I0402 11:06:19.497885 140568157718336 submission.py:296] 7000) loss = 1.909, grad_norm = 3.612
I0402 11:13:01.727044 140538804168448 logging_writer.py:48] [7500] global_step=7500, grad_norm=4.910978, loss=1.848913
I0402 11:13:01.733831 140568157718336 submission.py:296] 7500) loss = 1.849, grad_norm = 4.911
I0402 11:19:42.310824 140568157718336 submission_runner.py:373] Before eval at step 8000: RAM USED (GB) 41.75345664
I0402 11:19:42.311077 140568157718336 spec.py:298] Evaluating on the training split.
I0402 11:19:53.071948 140568157718336 spec.py:310] Evaluating on the validation split.
I0402 11:20:02.502634 140568157718336 spec.py:326] Evaluating on the test split.
I0402 11:20:07.801112 140568157718336 submission_runner.py:382] Time since start: 6541.32s, 	Step: 8000, 	{'train/ctc_loss': 0.7204786244567332, 'train/wer': 0.2388105123578897, 'validation/ctc_loss': 0.9847895043763814, 'validation/wer': 0.27871385120455755, 'validation/num_examples': 5348, 'test/ctc_loss': 0.6274517710820053, 'test/wer': 0.20595941746389618, 'test/num_examples': 2472}
I0402 11:20:07.801893 140568157718336 submission_runner.py:396] After eval at step 8000: RAM USED (GB) 41.650163712
I0402 11:20:07.817513 140538804168448 logging_writer.py:48] [8000] global_step=8000, preemption_count=0, score=3965.397709, test/ctc_loss=0.627452, test/num_examples=2472, test/wer=0.205959, total_duration=6541.321913, train/ctc_loss=0.720479, train/wer=0.238811, validation/ctc_loss=0.984790, validation/num_examples=5348, validation/wer=0.278714
I0402 11:20:08.106540 140568157718336 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/checkpoint_8000.
I0402 11:20:08.107110 140568157718336 submission_runner.py:416] After logging and checkpointing eval at step 8000: RAM USED (GB) 41.655205888
I0402 11:20:08.118963 140538795775744 logging_writer.py:48] [8000] global_step=8000, preemption_count=0, score=3965.397709
I0402 11:20:08.641947 140568157718336 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw/librispeech_deepspeech_pytorch/trial_1/checkpoint_8000.
I0402 11:20:08.813717 140568157718336 submission_runner.py:550] Tuning trial 1/1
I0402 11:20:08.813951 140568157718336 submission_runner.py:551] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.045677535963609565, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0402 11:20:08.814389 140568157718336 submission_runner.py:552] Metrics: {'eval_results': [(1, {'train/ctc_loss': 32.169664992474594, 'train/wer': 3.50590178901376, 'validation/ctc_loss': 31.201392028330318, 'validation/wer': 3.277506879737363, 'validation/num_examples': 5348, 'test/ctc_loss': 31.254771275566167, 'test/wer': 3.4408425243231164, 'test/num_examples': 2472, 'score': 8.873027801513672, 'total_duration': 8.874911546707153, 'global_step': 1, 'preemption_count': 0}), (2971, {'train/ctc_loss': 5.241692033213265, 'train/wer': 0.9200812990457145, 'validation/ctc_loss': 5.172564499824191, 'validation/wer': 0.8813981557475982, 'validation/num_examples': 5348, 'test/ctc_loss': 4.9767009161881415, 'test/wer': 0.8792476590904474, 'test/num_examples': 2472, 'score': 1500.425703048706, 'total_duration': 2443.8536133766174, 'global_step': 2971, 'preemption_count': 0}), (5952, {'train/ctc_loss': 0.8957585020208683, 'train/wer': 0.2890354976849336, 'validation/ctc_loss': 1.1607007468731163, 'validation/wer': 0.32268623569738814, 'validation/num_examples': 5348, 'test/ctc_loss': 0.7933757319020582, 'test/wer': 0.2546868969999797, 'test/num_examples': 2472, 'score': 2962.7712075710297, 'total_duration': 4868.865503787994, 'global_step': 5952, 'preemption_count': 0}), (8000, {'train/ctc_loss': 0.7204786244567332, 'train/wer': 0.2388105123578897, 'validation/ctc_loss': 0.9847895043763814, 'validation/wer': 0.27871385120455755, 'validation/num_examples': 5348, 'test/ctc_loss': 0.6274517710820053, 'test/wer': 0.20595941746389618, 'test/num_examples': 2472, 'score': 3965.397709131241, 'total_duration': 6541.321913480759, 'global_step': 8000, 'preemption_count': 0})], 'global_step': 8000}
I0402 11:20:08.814514 140568157718336 submission_runner.py:553] Timing: 3965.397709131241
I0402 11:20:08.814572 140568157718336 submission_runner.py:554] ====================
I0402 11:20:08.814730 140568157718336 submission_runner.py:613] Final librispeech_deepspeech score: 3965.397709131241
