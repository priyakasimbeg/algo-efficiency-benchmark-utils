WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
I0401 05:06:08.497482 139782363899712 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 3
I0401 05:06:08.497515 140157815146304 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 5
I0401 05:06:08.498373 140347502098240 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 7
I0401 05:06:09.450795 139758227142464 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 2
I0401 05:06:09.450820 139884332463936 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 6
I0401 05:06:09.451273 140271759042368 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 1
I0401 05:06:09.451582 139951654442816 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 4
I0401 05:06:09.460878 140718929688384 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 0
I0401 05:06:09.461303 140718929688384 distributed_c10d.py:353] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0401 05:06:09.461368 139758227142464 distributed_c10d.py:353] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0401 05:06:09.461457 139884332463936 distributed_c10d.py:353] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0401 05:06:09.461844 140271759042368 distributed_c10d.py:353] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0401 05:06:09.462148 139951654442816 distributed_c10d.py:353] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0401 05:06:09.470141 139782363899712 distributed_c10d.py:353] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0401 05:06:09.470206 140347502098240 distributed_c10d.py:353] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0401 05:06:09.470375 140157815146304 distributed_c10d.py:353] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0401 05:06:09.831391 140718929688384 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_adamw/librispeech_deepspeech_pytorch.
W0401 05:06:09.844008 140271759042368 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0401 05:06:09.844012 140157815146304 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0401 05:06:09.845663 139951654442816 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0401 05:06:09.846202 139884332463936 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0401 05:06:09.846462 139758227142464 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0401 05:06:09.863146 140718929688384 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0401 05:06:09.866791 140718929688384 submission_runner.py:504] Using RNG seed 2401901273
I0401 05:06:09.867880 140718929688384 submission_runner.py:513] --- Tuning run 1/1 ---
I0401 05:06:09.868000 140718929688384 submission_runner.py:518] Creating tuning directory at /experiment_runs/timing_adamw/librispeech_deepspeech_pytorch/trial_1.
I0401 05:06:09.868197 140718929688384 logger_utils.py:84] Saving hparams to /experiment_runs/timing_adamw/librispeech_deepspeech_pytorch/trial_1/hparams.json.
I0401 05:06:09.869164 140718929688384 submission_runner.py:230] Starting train once: RAM USED (GB) 5.769191424
I0401 05:06:09.869277 140718929688384 submission_runner.py:231] Initializing dataset.
I0401 05:06:09.869367 140718929688384 input_pipeline.py:20] Loading split = train-clean-100
W0401 05:06:09.877763 140347502098240 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0401 05:06:09.878067 139782363899712 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0401 05:06:09.899188 140718929688384 input_pipeline.py:20] Loading split = train-clean-360
I0401 05:06:10.213464 140718929688384 input_pipeline.py:20] Loading split = train-other-500
I0401 05:06:10.626573 140718929688384 submission_runner.py:239] After Initializing dataset: RAM USED (GB) 6.118453248
I0401 05:06:10.626755 140718929688384 submission_runner.py:240] Initializing model.
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
I0401 05:06:17.824497 140718929688384 submission_runner.py:251] After Initializing model: RAM USED (GB) 22.46965248
I0401 05:06:17.824696 140718929688384 submission_runner.py:252] Initializing optimizer.
I0401 05:06:17.825455 140718929688384 submission_runner.py:260] After Initializing metrics bundle: RAM USED (GB) 22.262034432
I0401 05:06:17.825573 140718929688384 submission_runner.py:261] Initializing metrics bundle.
I0401 05:06:17.825623 140718929688384 submission_runner.py:275] Initializing checkpoint and logger.
I0401 05:06:17.827008 140718929688384 logger_utils.py:231] Unable to record workload.train_mean information. Continuing without it.
I0401 05:06:17.827129 140718929688384 logger_utils.py:231] Unable to record workload.train_stddev information. Continuing without it.
I0401 05:06:18.767183 140718929688384 submission_runner.py:296] Saving meta data to /experiment_runs/timing_adamw/librispeech_deepspeech_pytorch/trial_1/meta_data_0.json.
I0401 05:06:18.768084 140718929688384 submission_runner.py:299] Saving flags to /experiment_runs/timing_adamw/librispeech_deepspeech_pytorch/trial_1/flags_0.json.
I0401 05:06:18.771131 140718929688384 submission_runner.py:304] After checkpoint and logger metrics bundle: RAM USED (GB) 21.394051072
I0401 05:06:18.772058 140718929688384 submission_runner.py:311] Before starting training loop and logger metrics bundle: RAM USED (GB) 21.394051072
I0401 05:06:18.772147 140718929688384 submission_runner.py:312] Starting training loop.
I0401 05:06:21.139357 140718929688384 submission_runner.py:333] After dataselection batch at step 0: RAM USED (GB) 25.952677888
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
I0401 05:06:27.787709 140692659631872 logging_writer.py:48] [0] global_step=0, grad_norm=31.843988, loss=33.286072
I0401 05:06:27.798809 140718929688384 submission.py:119] 0) loss = 33.286, grad_norm = 31.844
I0401 05:06:27.799687 140718929688384 submission_runner.py:350] After update parameters step 0: RAM USED (GB) 31.67145984
I0401 05:06:27.800307 140718929688384 submission_runner.py:371] Before eval at step 1: RAM USED (GB) 31.67145984
I0401 05:06:27.800430 140718929688384 spec.py:298] Evaluating on the training split.
I0401 05:06:27.801253 140718929688384 input_pipeline.py:20] Loading split = train-clean-100
I0401 05:06:27.831858 140718929688384 input_pipeline.py:20] Loading split = train-clean-360
I0401 05:06:28.295711 140718929688384 input_pipeline.py:20] Loading split = train-other-500
I0401 05:06:42.260868 140718929688384 spec.py:310] Evaluating on the validation split.
I0401 05:06:42.262149 140718929688384 input_pipeline.py:20] Loading split = dev-clean
I0401 05:06:42.265941 140718929688384 input_pipeline.py:20] Loading split = dev-other
I0401 05:06:52.960331 140718929688384 spec.py:326] Evaluating on the test split.
I0401 05:06:52.961802 140718929688384 input_pipeline.py:20] Loading split = test-clean
I0401 05:06:59.381736 140718929688384 submission_runner.py:380] Time since start: 9.03s, 	Step: 1, 	{'train/ctc_loss': 32.24138303109594, 'train/wer': 2.1884054840678004, 'validation/ctc_loss': 31.08715717299578, 'validation/wer': 1.9390720803360209, 'validation/num_examples': 5348, 'test/ctc_loss': 31.119017355958448, 'test/wer': 2.222960209615502, 'test/num_examples': 2472}
I0401 05:06:59.382583 140718929688384 submission_runner.py:390] After eval at step 1: RAM USED (GB) 46.074789888
I0401 05:06:59.394967 140689933330176 logging_writer.py:48] [1] global_step=1, preemption_count=0, score=9.026770, test/ctc_loss=31.119017, test/num_examples=2472, test/wer=2.222960, total_duration=9.028583, train/ctc_loss=32.241383, train/wer=2.188405, validation/ctc_loss=31.087157, validation/num_examples=5348, validation/wer=1.939072
I0401 05:06:59.665233 140718929688384 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw/librispeech_deepspeech_pytorch/trial_1/checkpoint_1.
I0401 05:06:59.665743 140718929688384 submission_runner.py:409] After logging and checkpointing eval at step 1: RAM USED (GB) 46.104014848
I0401 05:06:59.668658 140718929688384 submission_runner.py:333] After dataselection batch at step 1: RAM USED (GB) 46.10512896
I0401 05:06:59.700515 140271759042368 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0401 05:06:59.701305 140718929688384 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0401 05:06:59.701374 139758227142464 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0401 05:06:59.701414 139782363899712 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0401 05:06:59.701570 139884332463936 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0401 05:06:59.701668 140157815146304 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0401 05:06:59.701655 140347502098240 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0401 05:06:59.702340 139951654442816 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0401 05:07:00.794577 140689924937472 logging_writer.py:48] [1] global_step=1, grad_norm=30.268524, loss=32.770325
I0401 05:07:00.797931 140718929688384 submission.py:119] 1) loss = 32.770, grad_norm = 30.269
I0401 05:07:00.798738 140718929688384 submission_runner.py:350] After update parameters step 1: RAM USED (GB) 46.297391104
I0401 05:07:01.745265 140689933330176 logging_writer.py:48] [2] global_step=2, grad_norm=29.352024, loss=33.283081
I0401 05:07:01.748409 140718929688384 submission.py:119] 2) loss = 33.283, grad_norm = 29.352
I0401 05:07:02.585464 140689924937472 logging_writer.py:48] [3] global_step=3, grad_norm=31.582802, loss=33.288742
I0401 05:07:02.588572 140718929688384 submission.py:119] 3) loss = 33.289, grad_norm = 31.583
I0401 05:07:03.420281 140689933330176 logging_writer.py:48] [4] global_step=4, grad_norm=32.363461, loss=32.781334
I0401 05:07:03.423523 140718929688384 submission.py:119] 4) loss = 32.781, grad_norm = 32.363
I0401 05:07:04.243314 140689924937472 logging_writer.py:48] [5] global_step=5, grad_norm=32.858299, loss=33.102306
I0401 05:07:04.246756 140718929688384 submission.py:119] 5) loss = 33.102, grad_norm = 32.858
I0401 05:07:05.062047 140689933330176 logging_writer.py:48] [6] global_step=6, grad_norm=33.168118, loss=33.203823
I0401 05:07:05.065259 140718929688384 submission.py:119] 6) loss = 33.204, grad_norm = 33.168
I0401 05:07:05.891623 140689924937472 logging_writer.py:48] [7] global_step=7, grad_norm=33.634998, loss=32.108326
I0401 05:07:05.895828 140718929688384 submission.py:119] 7) loss = 32.108, grad_norm = 33.635
I0401 05:07:06.718021 140689933330176 logging_writer.py:48] [8] global_step=8, grad_norm=35.985413, loss=32.574291
I0401 05:07:06.720999 140718929688384 submission.py:119] 8) loss = 32.574, grad_norm = 35.985
I0401 05:07:07.540388 140689924937472 logging_writer.py:48] [9] global_step=9, grad_norm=35.755497, loss=32.171783
I0401 05:07:07.543737 140718929688384 submission.py:119] 9) loss = 32.172, grad_norm = 35.755
I0401 05:07:08.371272 140689933330176 logging_writer.py:48] [10] global_step=10, grad_norm=37.702728, loss=31.998491
I0401 05:07:08.375045 140718929688384 submission.py:119] 10) loss = 31.998, grad_norm = 37.703
I0401 05:07:09.195930 140689924937472 logging_writer.py:48] [11] global_step=11, grad_norm=40.194508, loss=32.076035
I0401 05:07:09.199935 140718929688384 submission.py:119] 11) loss = 32.076, grad_norm = 40.195
I0401 05:07:10.022859 140689933330176 logging_writer.py:48] [12] global_step=12, grad_norm=40.898891, loss=32.145241
I0401 05:07:10.026595 140718929688384 submission.py:119] 12) loss = 32.145, grad_norm = 40.899
I0401 05:07:10.839113 140689924937472 logging_writer.py:48] [13] global_step=13, grad_norm=43.396404, loss=31.614685
I0401 05:07:10.842803 140718929688384 submission.py:119] 13) loss = 31.615, grad_norm = 43.396
I0401 05:07:11.670264 140689933330176 logging_writer.py:48] [14] global_step=14, grad_norm=41.941929, loss=31.362350
I0401 05:07:11.674298 140718929688384 submission.py:119] 14) loss = 31.362, grad_norm = 41.942
I0401 05:07:12.482324 140689924937472 logging_writer.py:48] [15] global_step=15, grad_norm=43.701077, loss=30.300428
I0401 05:07:12.486025 140718929688384 submission.py:119] 15) loss = 30.300, grad_norm = 43.701
I0401 05:07:13.299422 140689933330176 logging_writer.py:48] [16] global_step=16, grad_norm=45.076424, loss=30.674421
I0401 05:07:13.303320 140718929688384 submission.py:119] 16) loss = 30.674, grad_norm = 45.076
I0401 05:07:14.122804 140689924937472 logging_writer.py:48] [17] global_step=17, grad_norm=45.001179, loss=30.099882
I0401 05:07:14.126583 140718929688384 submission.py:119] 17) loss = 30.100, grad_norm = 45.001
I0401 05:07:14.944932 140689933330176 logging_writer.py:48] [18] global_step=18, grad_norm=45.137512, loss=29.749918
I0401 05:07:14.948660 140718929688384 submission.py:119] 18) loss = 29.750, grad_norm = 45.138
I0401 05:07:15.765364 140689924937472 logging_writer.py:48] [19] global_step=19, grad_norm=44.684666, loss=28.976610
I0401 05:07:15.768926 140718929688384 submission.py:119] 19) loss = 28.977, grad_norm = 44.685
I0401 05:07:16.588559 140689933330176 logging_writer.py:48] [20] global_step=20, grad_norm=44.595535, loss=28.259039
I0401 05:07:16.592306 140718929688384 submission.py:119] 20) loss = 28.259, grad_norm = 44.596
I0401 05:07:17.423283 140689924937472 logging_writer.py:48] [21] global_step=21, grad_norm=44.730366, loss=28.022192
I0401 05:07:17.426975 140718929688384 submission.py:119] 21) loss = 28.022, grad_norm = 44.730
I0401 05:07:18.242580 140689933330176 logging_writer.py:48] [22] global_step=22, grad_norm=44.932281, loss=27.995651
I0401 05:07:18.246399 140718929688384 submission.py:119] 22) loss = 27.996, grad_norm = 44.932
I0401 05:07:19.065064 140689924937472 logging_writer.py:48] [23] global_step=23, grad_norm=42.833538, loss=26.996260
I0401 05:07:19.069007 140718929688384 submission.py:119] 23) loss = 26.996, grad_norm = 42.834
I0401 05:07:19.886108 140689933330176 logging_writer.py:48] [24] global_step=24, grad_norm=43.113556, loss=26.787399
I0401 05:07:19.889894 140718929688384 submission.py:119] 24) loss = 26.787, grad_norm = 43.114
I0401 05:07:20.715870 140689924937472 logging_writer.py:48] [25] global_step=25, grad_norm=41.629398, loss=26.245333
I0401 05:07:20.719486 140718929688384 submission.py:119] 25) loss = 26.245, grad_norm = 41.629
I0401 05:07:21.540064 140689933330176 logging_writer.py:48] [26] global_step=26, grad_norm=41.918400, loss=25.603369
I0401 05:07:21.543717 140718929688384 submission.py:119] 26) loss = 25.603, grad_norm = 41.918
I0401 05:07:22.362094 140689924937472 logging_writer.py:48] [27] global_step=27, grad_norm=41.252438, loss=25.231409
I0401 05:07:22.365647 140718929688384 submission.py:119] 27) loss = 25.231, grad_norm = 41.252
I0401 05:07:23.184990 140689933330176 logging_writer.py:48] [28] global_step=28, grad_norm=38.827042, loss=24.561123
I0401 05:07:23.188625 140718929688384 submission.py:119] 28) loss = 24.561, grad_norm = 38.827
I0401 05:07:24.008596 140689924937472 logging_writer.py:48] [29] global_step=29, grad_norm=37.618107, loss=23.754162
I0401 05:07:24.012267 140718929688384 submission.py:119] 29) loss = 23.754, grad_norm = 37.618
I0401 05:07:24.829875 140689933330176 logging_writer.py:48] [30] global_step=30, grad_norm=37.051235, loss=23.191509
I0401 05:07:24.833384 140718929688384 submission.py:119] 30) loss = 23.192, grad_norm = 37.051
I0401 05:07:25.652128 140689924937472 logging_writer.py:48] [31] global_step=31, grad_norm=36.634254, loss=22.851843
I0401 05:07:25.655919 140718929688384 submission.py:119] 31) loss = 22.852, grad_norm = 36.634
I0401 05:07:26.483994 140689933330176 logging_writer.py:48] [32] global_step=32, grad_norm=35.123184, loss=22.195141
I0401 05:07:26.487877 140718929688384 submission.py:119] 32) loss = 22.195, grad_norm = 35.123
I0401 05:07:27.319029 140689924937472 logging_writer.py:48] [33] global_step=33, grad_norm=34.961548, loss=21.975462
I0401 05:07:27.322816 140718929688384 submission.py:119] 33) loss = 21.975, grad_norm = 34.962
I0401 05:07:28.148321 140689933330176 logging_writer.py:48] [34] global_step=34, grad_norm=33.826401, loss=21.586655
I0401 05:07:28.151900 140718929688384 submission.py:119] 34) loss = 21.587, grad_norm = 33.826
I0401 05:07:28.980045 140689924937472 logging_writer.py:48] [35] global_step=35, grad_norm=33.704693, loss=20.873669
I0401 05:07:28.983608 140718929688384 submission.py:119] 35) loss = 20.874, grad_norm = 33.705
I0401 05:07:29.811872 140689933330176 logging_writer.py:48] [36] global_step=36, grad_norm=30.770016, loss=20.629494
I0401 05:07:29.815714 140718929688384 submission.py:119] 36) loss = 20.629, grad_norm = 30.770
I0401 05:07:30.634878 140689924937472 logging_writer.py:48] [37] global_step=37, grad_norm=29.769922, loss=19.686586
I0401 05:07:30.638447 140718929688384 submission.py:119] 37) loss = 19.687, grad_norm = 29.770
I0401 05:07:31.462586 140689933330176 logging_writer.py:48] [38] global_step=38, grad_norm=28.568104, loss=19.598158
I0401 05:07:31.466353 140718929688384 submission.py:119] 38) loss = 19.598, grad_norm = 28.568
I0401 05:07:32.286829 140689924937472 logging_writer.py:48] [39] global_step=39, grad_norm=28.755175, loss=19.273962
I0401 05:07:32.290748 140718929688384 submission.py:119] 39) loss = 19.274, grad_norm = 28.755
I0401 05:07:33.112802 140689933330176 logging_writer.py:48] [40] global_step=40, grad_norm=27.163950, loss=18.790695
I0401 05:07:33.116468 140718929688384 submission.py:119] 40) loss = 18.791, grad_norm = 27.164
I0401 05:07:33.932536 140689924937472 logging_writer.py:48] [41] global_step=41, grad_norm=26.084320, loss=17.870598
I0401 05:07:33.936239 140718929688384 submission.py:119] 41) loss = 17.871, grad_norm = 26.084
I0401 05:07:34.748556 140689933330176 logging_writer.py:48] [42] global_step=42, grad_norm=25.211916, loss=17.429472
I0401 05:07:34.752192 140718929688384 submission.py:119] 42) loss = 17.429, grad_norm = 25.212
I0401 05:07:35.573065 140689924937472 logging_writer.py:48] [43] global_step=43, grad_norm=23.671543, loss=17.308989
I0401 05:07:35.576686 140718929688384 submission.py:119] 43) loss = 17.309, grad_norm = 23.672
I0401 05:07:36.392009 140689933330176 logging_writer.py:48] [44] global_step=44, grad_norm=23.926104, loss=17.009954
I0401 05:07:36.395543 140718929688384 submission.py:119] 44) loss = 17.010, grad_norm = 23.926
I0401 05:07:37.212201 140689924937472 logging_writer.py:48] [45] global_step=45, grad_norm=22.580585, loss=16.270704
I0401 05:07:37.216014 140718929688384 submission.py:119] 45) loss = 16.271, grad_norm = 22.581
I0401 05:07:38.035853 140689933330176 logging_writer.py:48] [46] global_step=46, grad_norm=22.220823, loss=15.851621
I0401 05:07:38.039737 140718929688384 submission.py:119] 46) loss = 15.852, grad_norm = 22.221
I0401 05:07:38.857431 140689924937472 logging_writer.py:48] [47] global_step=47, grad_norm=21.616610, loss=15.614801
I0401 05:07:38.861213 140718929688384 submission.py:119] 47) loss = 15.615, grad_norm = 21.617
I0401 05:07:39.673798 140689933330176 logging_writer.py:48] [48] global_step=48, grad_norm=21.095869, loss=15.692379
I0401 05:07:39.677534 140718929688384 submission.py:119] 48) loss = 15.692, grad_norm = 21.096
I0401 05:07:40.494159 140689924937472 logging_writer.py:48] [49] global_step=49, grad_norm=20.470423, loss=15.268455
I0401 05:07:40.497878 140718929688384 submission.py:119] 49) loss = 15.268, grad_norm = 20.470
I0401 05:07:41.303810 140689933330176 logging_writer.py:48] [50] global_step=50, grad_norm=20.386204, loss=14.771633
I0401 05:07:41.307620 140718929688384 submission.py:119] 50) loss = 14.772, grad_norm = 20.386
I0401 05:07:42.119883 140689924937472 logging_writer.py:48] [51] global_step=51, grad_norm=18.992619, loss=14.092661
I0401 05:07:42.123980 140718929688384 submission.py:119] 51) loss = 14.093, grad_norm = 18.993
I0401 05:07:42.935002 140689933330176 logging_writer.py:48] [52] global_step=52, grad_norm=17.992756, loss=13.527107
I0401 05:07:42.939014 140718929688384 submission.py:119] 52) loss = 13.527, grad_norm = 17.993
I0401 05:07:43.754436 140689924937472 logging_writer.py:48] [53] global_step=53, grad_norm=17.151169, loss=13.534685
I0401 05:07:43.758245 140718929688384 submission.py:119] 53) loss = 13.535, grad_norm = 17.151
I0401 05:07:44.571694 140689933330176 logging_writer.py:48] [54] global_step=54, grad_norm=17.176342, loss=13.730280
I0401 05:07:44.575139 140718929688384 submission.py:119] 54) loss = 13.730, grad_norm = 17.176
I0401 05:07:45.389215 140689924937472 logging_writer.py:48] [55] global_step=55, grad_norm=16.673273, loss=13.588156
I0401 05:07:45.392784 140718929688384 submission.py:119] 55) loss = 13.588, grad_norm = 16.673
I0401 05:07:46.212195 140689933330176 logging_writer.py:48] [56] global_step=56, grad_norm=16.012222, loss=12.983451
I0401 05:07:46.215651 140718929688384 submission.py:119] 56) loss = 12.983, grad_norm = 16.012
I0401 05:07:47.029042 140689924937472 logging_writer.py:48] [57] global_step=57, grad_norm=16.900938, loss=12.970196
I0401 05:07:47.032438 140718929688384 submission.py:119] 57) loss = 12.970, grad_norm = 16.901
I0401 05:07:47.843603 140689933330176 logging_writer.py:48] [58] global_step=58, grad_norm=15.580347, loss=12.326666
I0401 05:07:47.846917 140718929688384 submission.py:119] 58) loss = 12.327, grad_norm = 15.580
I0401 05:07:48.661956 140689924937472 logging_writer.py:48] [59] global_step=59, grad_norm=15.056912, loss=12.246261
I0401 05:07:48.665373 140718929688384 submission.py:119] 59) loss = 12.246, grad_norm = 15.057
I0401 05:07:49.478532 140689933330176 logging_writer.py:48] [60] global_step=60, grad_norm=14.563692, loss=12.184640
I0401 05:07:49.482023 140718929688384 submission.py:119] 60) loss = 12.185, grad_norm = 14.564
I0401 05:07:50.302651 140689924937472 logging_writer.py:48] [61] global_step=61, grad_norm=14.131831, loss=11.748362
I0401 05:07:50.306008 140718929688384 submission.py:119] 61) loss = 11.748, grad_norm = 14.132
I0401 05:07:51.122807 140689933330176 logging_writer.py:48] [62] global_step=62, grad_norm=14.301309, loss=11.579731
I0401 05:07:51.126270 140718929688384 submission.py:119] 62) loss = 11.580, grad_norm = 14.301
I0401 05:07:51.943423 140689924937472 logging_writer.py:48] [63] global_step=63, grad_norm=13.631835, loss=11.575032
I0401 05:07:51.947009 140718929688384 submission.py:119] 63) loss = 11.575, grad_norm = 13.632
I0401 05:07:52.764590 140689933330176 logging_writer.py:48] [64] global_step=64, grad_norm=12.970961, loss=11.257806
I0401 05:07:52.767887 140718929688384 submission.py:119] 64) loss = 11.258, grad_norm = 12.971
I0401 05:07:53.587932 140689924937472 logging_writer.py:48] [65] global_step=65, grad_norm=12.932746, loss=10.819351
I0401 05:07:53.591618 140718929688384 submission.py:119] 65) loss = 10.819, grad_norm = 12.933
I0401 05:07:54.403132 140689933330176 logging_writer.py:48] [66] global_step=66, grad_norm=12.636036, loss=10.853764
I0401 05:07:54.406547 140718929688384 submission.py:119] 66) loss = 10.854, grad_norm = 12.636
I0401 05:07:55.233988 140689924937472 logging_writer.py:48] [67] global_step=67, grad_norm=12.458064, loss=10.501524
I0401 05:07:55.238034 140718929688384 submission.py:119] 67) loss = 10.502, grad_norm = 12.458
I0401 05:07:56.051192 140689933330176 logging_writer.py:48] [68] global_step=68, grad_norm=12.017737, loss=10.210638
I0401 05:07:56.054652 140718929688384 submission.py:119] 68) loss = 10.211, grad_norm = 12.018
I0401 05:07:56.869814 140689924937472 logging_writer.py:48] [69] global_step=69, grad_norm=13.304695, loss=10.573416
I0401 05:07:56.873186 140718929688384 submission.py:119] 69) loss = 10.573, grad_norm = 13.305
I0401 05:07:57.686135 140689933330176 logging_writer.py:48] [70] global_step=70, grad_norm=11.835329, loss=9.953603
I0401 05:07:57.689477 140718929688384 submission.py:119] 70) loss = 9.954, grad_norm = 11.835
I0401 05:07:58.507040 140689924937472 logging_writer.py:48] [71] global_step=71, grad_norm=13.040182, loss=10.023666
I0401 05:07:58.510517 140718929688384 submission.py:119] 71) loss = 10.024, grad_norm = 13.040
I0401 05:07:59.327817 140689933330176 logging_writer.py:48] [72] global_step=72, grad_norm=11.244579, loss=9.632687
I0401 05:07:59.331362 140718929688384 submission.py:119] 72) loss = 9.633, grad_norm = 11.245
I0401 05:08:00.151882 140689924937472 logging_writer.py:48] [73] global_step=73, grad_norm=10.548724, loss=9.374601
I0401 05:08:00.155380 140718929688384 submission.py:119] 73) loss = 9.375, grad_norm = 10.549
I0401 05:08:00.973078 140689933330176 logging_writer.py:48] [74] global_step=74, grad_norm=10.594216, loss=9.479359
I0401 05:08:00.976528 140718929688384 submission.py:119] 74) loss = 9.479, grad_norm = 10.594
I0401 05:08:01.790812 140689924937472 logging_writer.py:48] [75] global_step=75, grad_norm=10.377336, loss=9.224716
I0401 05:08:01.794214 140718929688384 submission.py:119] 75) loss = 9.225, grad_norm = 10.377
I0401 05:08:02.615786 140689933330176 logging_writer.py:48] [76] global_step=76, grad_norm=9.696930, loss=9.105162
I0401 05:08:02.619403 140718929688384 submission.py:119] 76) loss = 9.105, grad_norm = 9.697
I0401 05:08:03.437037 140689924937472 logging_writer.py:48] [77] global_step=77, grad_norm=8.574037, loss=8.895741
I0401 05:08:03.440845 140718929688384 submission.py:119] 77) loss = 8.896, grad_norm = 8.574
I0401 05:08:04.258575 140689933330176 logging_writer.py:48] [78] global_step=78, grad_norm=7.696964, loss=8.735589
I0401 05:08:04.262223 140718929688384 submission.py:119] 78) loss = 8.736, grad_norm = 7.697
I0401 05:08:05.080312 140689924937472 logging_writer.py:48] [79] global_step=79, grad_norm=8.068035, loss=8.776966
I0401 05:08:05.084116 140718929688384 submission.py:119] 79) loss = 8.777, grad_norm = 8.068
I0401 05:08:05.899446 140689933330176 logging_writer.py:48] [80] global_step=80, grad_norm=7.386203, loss=8.659712
I0401 05:08:05.902963 140718929688384 submission.py:119] 80) loss = 8.660, grad_norm = 7.386
I0401 05:08:06.721603 140689924937472 logging_writer.py:48] [81] global_step=81, grad_norm=6.781777, loss=8.570520
I0401 05:08:06.725118 140718929688384 submission.py:119] 81) loss = 8.571, grad_norm = 6.782
I0401 05:08:07.544640 140689933330176 logging_writer.py:48] [82] global_step=82, grad_norm=6.553776, loss=8.489272
I0401 05:08:07.547992 140718929688384 submission.py:119] 82) loss = 8.489, grad_norm = 6.554
I0401 05:08:08.359504 140689924937472 logging_writer.py:48] [83] global_step=83, grad_norm=6.431340, loss=8.478290
I0401 05:08:08.362907 140718929688384 submission.py:119] 83) loss = 8.478, grad_norm = 6.431
I0401 05:08:09.178237 140689933330176 logging_writer.py:48] [84] global_step=84, grad_norm=6.129673, loss=8.326278
I0401 05:08:09.181893 140718929688384 submission.py:119] 84) loss = 8.326, grad_norm = 6.130
I0401 05:08:10.000445 140689924937472 logging_writer.py:48] [85] global_step=85, grad_norm=5.944568, loss=8.212193
I0401 05:08:10.004237 140718929688384 submission.py:119] 85) loss = 8.212, grad_norm = 5.945
I0401 05:08:10.821706 140689933330176 logging_writer.py:48] [86] global_step=86, grad_norm=5.504062, loss=8.129523
I0401 05:08:10.825135 140718929688384 submission.py:119] 86) loss = 8.130, grad_norm = 5.504
I0401 05:08:11.638690 140689924937472 logging_writer.py:48] [87] global_step=87, grad_norm=5.269577, loss=8.039458
I0401 05:08:11.642331 140718929688384 submission.py:119] 87) loss = 8.039, grad_norm = 5.270
I0401 05:08:12.453809 140689933330176 logging_writer.py:48] [88] global_step=88, grad_norm=5.273628, loss=8.070557
I0401 05:08:12.457302 140718929688384 submission.py:119] 88) loss = 8.071, grad_norm = 5.274
I0401 05:08:13.270132 140689924937472 logging_writer.py:48] [89] global_step=89, grad_norm=5.175366, loss=8.051925
I0401 05:08:13.273597 140718929688384 submission.py:119] 89) loss = 8.052, grad_norm = 5.175
I0401 05:08:14.092467 140689933330176 logging_writer.py:48] [90] global_step=90, grad_norm=4.521145, loss=7.885987
I0401 05:08:14.095709 140718929688384 submission.py:119] 90) loss = 7.886, grad_norm = 4.521
I0401 05:08:14.909963 140689924937472 logging_writer.py:48] [91] global_step=91, grad_norm=4.749660, loss=7.960785
I0401 05:08:14.913323 140718929688384 submission.py:119] 91) loss = 7.961, grad_norm = 4.750
I0401 05:08:15.736330 140689933330176 logging_writer.py:48] [92] global_step=92, grad_norm=4.751201, loss=7.886431
I0401 05:08:15.739763 140718929688384 submission.py:119] 92) loss = 7.886, grad_norm = 4.751
I0401 05:08:16.557747 140689924937472 logging_writer.py:48] [93] global_step=93, grad_norm=4.413388, loss=7.853837
I0401 05:08:16.560974 140718929688384 submission.py:119] 93) loss = 7.854, grad_norm = 4.413
I0401 05:08:17.377887 140689933330176 logging_writer.py:48] [94] global_step=94, grad_norm=4.318536, loss=7.702448
I0401 05:08:17.381607 140718929688384 submission.py:119] 94) loss = 7.702, grad_norm = 4.319
I0401 05:08:18.204501 140689924937472 logging_writer.py:48] [95] global_step=95, grad_norm=3.991098, loss=7.683004
I0401 05:08:18.208090 140718929688384 submission.py:119] 95) loss = 7.683, grad_norm = 3.991
I0401 05:08:19.025223 140689933330176 logging_writer.py:48] [96] global_step=96, grad_norm=3.890329, loss=7.701625
I0401 05:08:19.028782 140718929688384 submission.py:119] 96) loss = 7.702, grad_norm = 3.890
I0401 05:08:19.848264 140689924937472 logging_writer.py:48] [97] global_step=97, grad_norm=3.854542, loss=7.678182
I0401 05:08:19.851924 140718929688384 submission.py:119] 97) loss = 7.678, grad_norm = 3.855
I0401 05:08:20.683135 140689933330176 logging_writer.py:48] [98] global_step=98, grad_norm=3.821113, loss=7.591877
I0401 05:08:20.686714 140718929688384 submission.py:119] 98) loss = 7.592, grad_norm = 3.821
I0401 05:08:21.502098 140689924937472 logging_writer.py:48] [99] global_step=99, grad_norm=4.023423, loss=7.615294
I0401 05:08:21.505657 140718929688384 submission.py:119] 99) loss = 7.615, grad_norm = 4.023
I0401 05:08:22.319427 140689933330176 logging_writer.py:48] [100] global_step=100, grad_norm=3.982723, loss=7.499486
I0401 05:08:22.322877 140718929688384 submission.py:119] 100) loss = 7.499, grad_norm = 3.983
I0401 05:13:48.114928 140689924937472 logging_writer.py:48] [500] global_step=500, grad_norm=0.881366, loss=5.784536
I0401 05:13:48.119092 140718929688384 submission.py:119] 500) loss = 5.785, grad_norm = 0.881
I0401 05:20:34.421404 140689933330176 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.160789, loss=4.546435
I0401 05:20:34.429065 140718929688384 submission.py:119] 1000) loss = 4.546, grad_norm = 1.161
I0401 05:27:22.017919 140689933330176 logging_writer.py:48] [1500] global_step=1500, grad_norm=3.178318, loss=3.639101
I0401 05:27:22.025602 140718929688384 submission.py:119] 1500) loss = 3.639, grad_norm = 3.178
I0401 05:34:08.055166 140689924937472 logging_writer.py:48] [2000] global_step=2000, grad_norm=2.177600, loss=3.040196
I0401 05:34:08.059942 140718929688384 submission.py:119] 2000) loss = 3.040, grad_norm = 2.178
I0401 05:40:55.209796 140689933330176 logging_writer.py:48] [2500] global_step=2500, grad_norm=3.533411, loss=2.749635
I0401 05:40:55.216396 140718929688384 submission.py:119] 2500) loss = 2.750, grad_norm = 3.533
I0401 05:47:00.698005 140718929688384 submission_runner.py:371] Before eval at step 2952: RAM USED (GB) 44.097818624
I0401 05:47:00.698221 140718929688384 spec.py:298] Evaluating on the training split.
I0401 05:47:10.370365 140718929688384 spec.py:310] Evaluating on the validation split.
I0401 05:47:19.352174 140718929688384 spec.py:326] Evaluating on the test split.
I0401 05:47:24.636054 140718929688384 submission_runner.py:380] Time since start: 2441.61s, 	Step: 2952, 	{'train/ctc_loss': 5.312465016218987, 'train/wer': 0.9106166066385516, 'validation/ctc_loss': 5.2672983222825, 'validation/wer': 0.87870419543282, 'validation/num_examples': 5348, 'test/ctc_loss': 5.030315665526808, 'test/wer': 0.8721589177990372, 'test/num_examples': 2472}
I0401 05:47:24.637156 140718929688384 submission_runner.py:390] After eval at step 2952: RAM USED (GB) 42.211295232
I0401 05:47:24.661006 140689933330176 logging_writer.py:48] [2952] global_step=2952, preemption_count=0, score=1494.979810, test/ctc_loss=5.030316, test/num_examples=2472, test/wer=0.872159, total_duration=2441.606578, train/ctc_loss=5.312465, train/wer=0.910617, validation/ctc_loss=5.267298, validation/num_examples=5348, validation/wer=0.878704
I0401 05:47:24.970951 140718929688384 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw/librispeech_deepspeech_pytorch/trial_1/checkpoint_2952.
I0401 05:47:24.971587 140718929688384 submission_runner.py:409] After logging and checkpointing eval at step 2952: RAM USED (GB) 42.216476672
I0401 05:48:04.729819 140689924937472 logging_writer.py:48] [3000] global_step=3000, grad_norm=3.122447, loss=2.593671
I0401 05:48:04.733291 140718929688384 submission.py:119] 3000) loss = 2.594, grad_norm = 3.122
I0401 05:54:51.769654 140689933330176 logging_writer.py:48] [3500] global_step=3500, grad_norm=2.716466, loss=2.358038
I0401 05:54:51.796010 140718929688384 submission.py:119] 3500) loss = 2.358, grad_norm = 2.716
I0401 06:01:36.549430 140689924937472 logging_writer.py:48] [4000] global_step=4000, grad_norm=2.780597, loss=2.286073
I0401 06:01:36.711278 140718929688384 submission.py:119] 4000) loss = 2.286, grad_norm = 2.781
I0401 06:08:24.256462 140689933330176 logging_writer.py:48] [4500] global_step=4500, grad_norm=3.342221, loss=2.148965
I0401 06:08:24.262915 140718929688384 submission.py:119] 4500) loss = 2.149, grad_norm = 3.342
I0401 06:15:10.045686 140689924937472 logging_writer.py:48] [5000] global_step=5000, grad_norm=2.295028, loss=2.104599
I0401 06:15:10.050759 140718929688384 submission.py:119] 5000) loss = 2.105, grad_norm = 2.295
I0401 06:21:56.477653 140689933330176 logging_writer.py:48] [5500] global_step=5500, grad_norm=2.180227, loss=2.098037
I0401 06:21:56.484332 140718929688384 submission.py:119] 5500) loss = 2.098, grad_norm = 2.180
I0401 06:27:25.805218 140718929688384 submission_runner.py:371] Before eval at step 5908: RAM USED (GB) 42.220183552
I0401 06:27:25.805443 140718929688384 spec.py:298] Evaluating on the training split.
I0401 06:27:37.142739 140718929688384 spec.py:310] Evaluating on the validation split.
I0401 06:27:46.592473 140718929688384 spec.py:326] Evaluating on the test split.
I0401 06:27:51.658091 140718929688384 submission_runner.py:380] Time since start: 4866.71s, 	Step: 5908, 	{'train/ctc_loss': 0.8091209039471821, 'train/wer': 0.2747217737363047, 'validation/ctc_loss': 1.0700674273533253, 'validation/wer': 0.3149905856225559, 'validation/num_examples': 5348, 'test/ctc_loss': 0.7139200512936319, 'test/wer': 0.2416062397172628, 'test/num_examples': 2472}
I0401 06:27:51.658859 140718929688384 submission_runner.py:390] After eval at step 5908: RAM USED (GB) 41.939464192
I0401 06:27:51.674479 140689933330176 logging_writer.py:48] [5908] global_step=5908, preemption_count=0, score=2950.563640, test/ctc_loss=0.713920, test/num_examples=2472, test/wer=0.241606, total_duration=4866.712886, train/ctc_loss=0.809121, train/wer=0.274722, validation/ctc_loss=1.070067, validation/num_examples=5348, validation/wer=0.314991
I0401 06:27:51.968286 140718929688384 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw/librispeech_deepspeech_pytorch/trial_1/checkpoint_5908.
I0401 06:27:51.968811 140718929688384 submission_runner.py:409] After logging and checkpointing eval at step 5908: RAM USED (GB) 41.944047616
I0401 06:29:07.206478 140689924937472 logging_writer.py:48] [6000] global_step=6000, grad_norm=1.624785, loss=1.918885
I0401 06:29:07.210052 140718929688384 submission.py:119] 6000) loss = 1.919, grad_norm = 1.625
I0401 06:35:54.101213 140689933330176 logging_writer.py:48] [6500] global_step=6500, grad_norm=1.978843, loss=1.880020
I0401 06:35:54.119410 140718929688384 submission.py:119] 6500) loss = 1.880, grad_norm = 1.979
I0401 06:42:38.666402 140689924937472 logging_writer.py:48] [7000] global_step=7000, grad_norm=1.823185, loss=1.885194
I0401 06:42:38.671040 140718929688384 submission.py:119] 7000) loss = 1.885, grad_norm = 1.823
I0401 06:49:25.370810 140689933330176 logging_writer.py:48] [7500] global_step=7500, grad_norm=2.103565, loss=1.876532
I0401 06:49:25.377930 140718929688384 submission.py:119] 7500) loss = 1.877, grad_norm = 2.104
I0401 06:56:09.415707 140718929688384 submission_runner.py:371] Before eval at step 8000: RAM USED (GB) 42.01463808
I0401 06:56:09.415974 140718929688384 spec.py:298] Evaluating on the training split.
I0401 06:56:20.364369 140718929688384 spec.py:310] Evaluating on the validation split.
I0401 06:56:29.647512 140718929688384 spec.py:326] Evaluating on the test split.
I0401 06:56:34.809545 140718929688384 submission_runner.py:380] Time since start: 6590.32s, 	Step: 8000, 	{'train/ctc_loss': 0.6446495573497973, 'train/wer': 0.22173863740678543, 'validation/ctc_loss': 0.91477073836523, 'validation/wer': 0.26754212330420507, 'validation/num_examples': 5348, 'test/ctc_loss': 0.576687054406736, 'test/wer': 0.19379278126459895, 'test/num_examples': 2472}
I0401 06:56:34.810303 140718929688384 submission_runner.py:390] After eval at step 8000: RAM USED (GB) 41.853591552
I0401 06:56:34.827547 140689933330176 logging_writer.py:48] [8000] global_step=8000, preemption_count=0, score=3980.319156, test/ctc_loss=0.576687, test/num_examples=2472, test/wer=0.193793, total_duration=6590.324217, train/ctc_loss=0.644650, train/wer=0.221739, validation/ctc_loss=0.914771, validation/num_examples=5348, validation/wer=0.267542
I0401 06:56:35.119338 140718929688384 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw/librispeech_deepspeech_pytorch/trial_1/checkpoint_8000.
I0401 06:56:35.119868 140718929688384 submission_runner.py:409] After logging and checkpointing eval at step 8000: RAM USED (GB) 41.858469888
I0401 06:56:35.132238 140689924937472 logging_writer.py:48] [8000] global_step=8000, preemption_count=0, score=3980.319156
I0401 06:56:35.632580 140718929688384 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_adamw/librispeech_deepspeech_pytorch/trial_1/checkpoint_8000.
I0401 06:56:35.764242 140718929688384 submission_runner.py:543] Tuning trial 1/1
I0401 06:56:35.764445 140718929688384 submission_runner.py:544] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0401 06:56:35.764855 140718929688384 submission_runner.py:545] Metrics: {'eval_results': [(1, {'train/ctc_loss': 32.24138303109594, 'train/wer': 2.1884054840678004, 'validation/ctc_loss': 31.08715717299578, 'validation/wer': 1.9390720803360209, 'validation/num_examples': 5348, 'test/ctc_loss': 31.119017355958448, 'test/wer': 2.222960209615502, 'test/num_examples': 2472, 'score': 9.026770114898682, 'total_duration': 9.02858304977417, 'global_step': 1, 'preemption_count': 0}), (2952, {'train/ctc_loss': 5.312465016218987, 'train/wer': 0.9106166066385516, 'validation/ctc_loss': 5.2672983222825, 'validation/wer': 0.87870419543282, 'validation/num_examples': 5348, 'test/ctc_loss': 5.030315665526808, 'test/wer': 0.8721589177990372, 'test/num_examples': 2472, 'score': 1494.979810476303, 'total_duration': 2441.6065781116486, 'global_step': 2952, 'preemption_count': 0}), (5908, {'train/ctc_loss': 0.8091209039471821, 'train/wer': 0.2747217737363047, 'validation/ctc_loss': 1.0700674273533253, 'validation/wer': 0.3149905856225559, 'validation/num_examples': 5348, 'test/ctc_loss': 0.7139200512936319, 'test/wer': 0.2416062397172628, 'test/num_examples': 2472, 'score': 2950.5636398792267, 'total_duration': 4866.712886095047, 'global_step': 5908, 'preemption_count': 0}), (8000, {'train/ctc_loss': 0.6446495573497973, 'train/wer': 0.22173863740678543, 'validation/ctc_loss': 0.91477073836523, 'validation/wer': 0.26754212330420507, 'validation/num_examples': 5348, 'test/ctc_loss': 0.576687054406736, 'test/wer': 0.19379278126459895, 'test/num_examples': 2472, 'score': 3980.31915640831, 'total_duration': 6590.32421708107, 'global_step': 8000, 'preemption_count': 0})], 'global_step': 8000}
I0401 06:56:35.764943 140718929688384 submission_runner.py:546] Timing: 3980.31915640831
I0401 06:56:35.764986 140718929688384 submission_runner.py:547] ====================
I0401 06:56:35.765156 140718929688384 submission_runner.py:606] Final librispeech_deepspeech score: 3980.31915640831
