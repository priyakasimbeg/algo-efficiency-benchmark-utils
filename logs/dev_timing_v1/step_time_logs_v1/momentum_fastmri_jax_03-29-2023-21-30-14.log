I0329 21:30:33.342106 140268179547968 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_momentum/fastmri_jax.
I0329 21:30:33.718847 140268179547968 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0329 21:30:34.542984 140268179547968 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0329 21:30:34.543610 140268179547968 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0329 21:30:34.550820 140268179547968 submission_runner.py:504] Using RNG seed 981273839
I0329 21:30:37.290436 140268179547968 submission_runner.py:513] --- Tuning run 1/1 ---
I0329 21:30:37.290651 140268179547968 submission_runner.py:518] Creating tuning directory at /experiment_runs/timing_momentum/fastmri_jax/trial_1.
I0329 21:30:37.290849 140268179547968 logger_utils.py:84] Saving hparams to /experiment_runs/timing_momentum/fastmri_jax/trial_1/hparams.json.
I0329 21:30:37.426475 140268179547968 submission_runner.py:230] Starting train once: RAM USED (GB) 4.559929344
I0329 21:30:37.426642 140268179547968 submission_runner.py:231] Initializing dataset.
I0329 21:30:42.381865 140268179547968 submission_runner.py:239] After Initializing dataset: RAM USED (GB) 4.644524032
I0329 21:30:42.382064 140268179547968 submission_runner.py:240] Initializing model.
I0329 21:30:49.682575 140268179547968 submission_runner.py:251] After Initializing model: RAM USED (GB) 8.577056768
I0329 21:30:49.682784 140268179547968 submission_runner.py:252] Initializing optimizer.
I0329 21:30:50.138603 140268179547968 submission_runner.py:260] After Initializing metrics bundle: RAM USED (GB) 8.580214784
I0329 21:30:50.138778 140268179547968 submission_runner.py:261] Initializing metrics bundle.
I0329 21:30:50.138830 140268179547968 submission_runner.py:275] Initializing checkpoint and logger.
I0329 21:30:50.139690 140268179547968 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_momentum/fastmri_jax/trial_1 with prefix checkpoint_
I0329 21:30:50.139939 140268179547968 logger_utils.py:231] Unable to record workload.train_mean information. Continuing without it.
I0329 21:30:50.140007 140268179547968 logger_utils.py:231] Unable to record workload.train_stddev information. Continuing without it.
I0329 21:30:50.897543 140268179547968 submission_runner.py:296] Saving meta data to /experiment_runs/timing_momentum/fastmri_jax/trial_1/meta_data_0.json.
I0329 21:30:50.898494 140268179547968 submission_runner.py:299] Saving flags to /experiment_runs/timing_momentum/fastmri_jax/trial_1/flags_0.json.
I0329 21:30:50.903137 140268179547968 submission_runner.py:304] After checkpoint and logger metrics bundle: RAM USED (GB) 8.579657728
I0329 21:30:50.903341 140268179547968 submission_runner.py:311] Before starting training loop and logger metrics bundle: RAM USED (GB) 8.579657728
I0329 21:30:50.903403 140268179547968 submission_runner.py:312] Starting training loop.
I0329 21:31:12.305422 140268179547968 submission_runner.py:333] After dataselection batch at step 0: RAM USED (GB) 18.07202304
I0329 21:31:39.066947 140091859134208 logging_writer.py:48] [0] global_step=0, grad_norm=4.710033416748047, loss=0.7454157471656799
I0329 21:31:39.075362 140268179547968 submission_runner.py:350] After update parameters step 0: RAM USED (GB) 23.479332864
I0329 21:31:39.075623 140268179547968 submission_runner.py:371] Before eval at step 1: RAM USED (GB) 23.478816768
I0329 21:31:39.075725 140268179547968 spec.py:298] Evaluating on the training split.
I0329 21:32:55.701672 140268179547968 spec.py:310] Evaluating on the validation split.
I0329 21:33:40.353114 140268179547968 spec.py:326] Evaluating on the test split.
I0329 21:34:21.628743 140268179547968 submission_runner.py:380] Time since start: 48.17s, 	Step: 1, 	{'train/ssim': 0.24509545734950475, 'train/loss': 0.7624429294041225, 'validation/ssim': 0.23672924997032394, 'validation/loss': 0.7751661310319359, 'validation/num_examples': 3554, 'test/ssim': 0.26100727540426033, 'test/loss': 0.7728417041547403, 'test/num_examples': 3581}
I0329 21:34:21.629243 140268179547968 submission_runner.py:390] After eval at step 1: RAM USED (GB) 62.560468992
I0329 21:34:21.640546 140063111378688 logging_writer.py:48] [1] global_step=1, preemption_count=0, score=48.024601, test/loss=0.772842, test/num_examples=3581, test/ssim=0.261007, total_duration=48.172247, train/loss=0.762443, train/ssim=0.245095, validation/loss=0.775166, validation/num_examples=3554, validation/ssim=0.236729
I0329 21:34:21.664837 140268179547968 checkpoints.py:356] Saving checkpoint at step: 1
I0329 21:34:21.806724 140268179547968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_1
I0329 21:34:21.807260 140268179547968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_1.
I0329 21:34:21.807855 140268179547968 submission_runner.py:409] After logging and checkpointing eval at step 1: RAM USED (GB) 62.560792576
I0329 21:34:21.810261 140268179547968 submission_runner.py:333] After dataselection batch at step 1: RAM USED (GB) 62.560792576
I0329 21:34:21.830265 140268179547968 submission_runner.py:350] After update parameters step 1: RAM USED (GB) 62.574985216
I0329 21:34:44.218173 140063102985984 logging_writer.py:48] [100] global_step=100, grad_norm=0.22703547775745392, loss=0.2964191138744354
I0329 21:35:09.151351 140063069415168 logging_writer.py:48] [200] global_step=200, grad_norm=0.3952607214450836, loss=0.3158288896083832
I0329 21:35:34.185932 140063102985984 logging_writer.py:48] [300] global_step=300, grad_norm=0.31086495518684387, loss=0.3348497152328491
I0329 21:35:41.827034 140268179547968 submission_runner.py:371] Before eval at step 332: RAM USED (GB) 87.277133824
I0329 21:35:41.827268 140268179547968 spec.py:298] Evaluating on the training split.
I0329 21:35:43.528171 140268179547968 spec.py:310] Evaluating on the validation split.
I0329 21:35:49.096475 140268179547968 spec.py:326] Evaluating on the test split.
I0329 21:35:50.450971 140268179547968 submission_runner.py:380] Time since start: 290.92s, 	Step: 332, 	{'train/ssim': 0.7112719672066825, 'train/loss': 0.2954414572034563, 'validation/ssim': 0.6882391539462578, 'validation/loss': 0.31929458334798816, 'validation/num_examples': 3554, 'test/ssim': 0.7060443928241064, 'test/loss': 0.32105225086611633, 'test/num_examples': 3581}
I0329 21:35:50.451700 140268179547968 submission_runner.py:390] After eval at step 332: RAM USED (GB) 88.319225856
I0329 21:35:50.462285 140063069415168 logging_writer.py:48] [332] global_step=332, preemption_count=0, score=127.580975, test/loss=0.321052, test/num_examples=3581, test/ssim=0.706044, total_duration=290.923105, train/loss=0.295441, train/ssim=0.711272, validation/loss=0.319295, validation/num_examples=3554, validation/ssim=0.688239
I0329 21:35:50.523705 140268179547968 checkpoints.py:356] Saving checkpoint at step: 332
I0329 21:35:50.722780 140268179547968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_332
I0329 21:35:50.723451 140268179547968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_332.
I0329 21:35:50.726714 140268179547968 submission_runner.py:409] After logging and checkpointing eval at step 332: RAM USED (GB) 88.332582912
I0329 21:36:05.019928 140063102985984 logging_writer.py:48] [400] global_step=400, grad_norm=0.3522387444972992, loss=0.3330845832824707
I0329 21:36:40.169545 140082598090496 logging_writer.py:48] [500] global_step=500, grad_norm=0.413242906332016, loss=0.2556043267250061
I0329 21:37:10.876750 140268179547968 submission_runner.py:371] Before eval at step 587: RAM USED (GB) 106.54216192
I0329 21:37:10.877326 140268179547968 spec.py:298] Evaluating on the training split.
I0329 21:37:12.275650 140268179547968 spec.py:310] Evaluating on the validation split.
I0329 21:37:14.530229 140268179547968 spec.py:326] Evaluating on the test split.
I0329 21:37:15.876747 140268179547968 submission_runner.py:380] Time since start: 379.97s, 	Step: 587, 	{'train/ssim': 0.718620845249721, 'train/loss': 0.286379337310791, 'validation/ssim': 0.6958755209798818, 'validation/loss': 0.30962066564522367, 'validation/num_examples': 3554, 'test/ssim': 0.7134140854073583, 'test/loss': 0.3113395991321384, 'test/num_examples': 3581}
I0329 21:37:15.877431 140268179547968 submission_runner.py:390] After eval at step 587: RAM USED (GB) 107.614765056
I0329 21:37:15.888804 140063102985984 logging_writer.py:48] [587] global_step=587, preemption_count=0, score=207.371362, test/loss=0.311340, test/num_examples=3581, test/ssim=0.713414, total_duration=379.972890, train/loss=0.286379, train/ssim=0.718621, validation/loss=0.309621, validation/num_examples=3554, validation/ssim=0.695876
I0329 21:37:15.949359 140268179547968 checkpoints.py:356] Saving checkpoint at step: 587
I0329 21:37:16.150492 140268179547968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_587
I0329 21:37:16.151230 140268179547968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_587.
I0329 21:37:16.151974 140268179547968 submission_runner.py:409] After logging and checkpointing eval at step 587: RAM USED (GB) 107.72391936
I0329 21:37:17.654511 140082598090496 logging_writer.py:48] [600] global_step=600, grad_norm=0.2299351990222931, loss=0.3161419630050659
I0329 21:37:53.733093 140058558678784 logging_writer.py:48] [700] global_step=700, grad_norm=0.46896860003471375, loss=0.37568747997283936
I0329 21:38:28.885614 140082598090496 logging_writer.py:48] [800] global_step=800, grad_norm=0.2715260982513428, loss=0.20946331322193146
I0329 21:38:36.406619 140268179547968 submission_runner.py:371] Before eval at step 823: RAM USED (GB) 125.685190656
I0329 21:38:36.406843 140268179547968 spec.py:298] Evaluating on the training split.
I0329 21:38:37.809609 140268179547968 spec.py:310] Evaluating on the validation split.
I0329 21:38:40.200565 140268179547968 spec.py:326] Evaluating on the test split.
I0329 21:38:41.549615 140268179547968 submission_runner.py:380] Time since start: 465.50s, 	Step: 823, 	{'train/ssim': 0.6883796283176967, 'train/loss': 0.29256510734558105, 'validation/ssim': 0.6748287993062394, 'validation/loss': 0.31424054954584624, 'validation/num_examples': 3554, 'test/ssim': 0.6899615865418179, 'test/loss': 0.3160857515140673, 'test/num_examples': 3581}
I0329 21:38:41.551958 140268179547968 submission_runner.py:390] After eval at step 823: RAM USED (GB) 126.678147072
I0329 21:38:41.562658 140058558678784 logging_writer.py:48] [823] global_step=823, preemption_count=0, score=287.303889, test/loss=0.316086, test/num_examples=3581, test/ssim=0.689962, total_duration=465.502745, train/loss=0.292565, train/ssim=0.688380, validation/loss=0.314241, validation/num_examples=3554, validation/ssim=0.674829
I0329 21:38:41.631302 140268179547968 checkpoints.py:356] Saving checkpoint at step: 823
I0329 21:38:41.837167 140268179547968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_823
I0329 21:38:41.837660 140268179547968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_823.
I0329 21:38:41.838942 140268179547968 submission_runner.py:409] After logging and checkpointing eval at step 823: RAM USED (GB) 126.813282304
I0329 21:39:07.867024 140082598090496 logging_writer.py:48] [900] global_step=900, grad_norm=0.2681449353694916, loss=0.3097422122955322
I0329 21:39:40.782821 140036049716992 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.3637388050556183, loss=0.24303698539733887
I0329 21:40:02.032232 140268179547968 submission_runner.py:371] Before eval at step 1087: RAM USED (GB) 140.261158912
I0329 21:40:02.032449 140268179547968 spec.py:298] Evaluating on the training split.
I0329 21:40:03.436771 140268179547968 spec.py:310] Evaluating on the validation split.
I0329 21:40:07.232672 140268179547968 spec.py:326] Evaluating on the test split.
I0329 21:40:08.580124 140268179547968 submission_runner.py:380] Time since start: 551.13s, 	Step: 1087, 	{'train/ssim': 0.7235063144138881, 'train/loss': 0.2805770124707903, 'validation/ssim': 0.7008369201076252, 'validation/loss': 0.3036465363081211, 'validation/num_examples': 3554, 'test/ssim': 0.7183692333452597, 'test/loss': 0.30515938476289795, 'test/num_examples': 3581}
I0329 21:40:08.580847 140268179547968 submission_runner.py:390] After eval at step 1087: RAM USED (GB) 140.501680128
I0329 21:40:08.589208 140082598090496 logging_writer.py:48] [1087] global_step=1087, preemption_count=0, score=367.173719, test/loss=0.305159, test/num_examples=3581, test/ssim=0.718369, total_duration=551.128510, train/loss=0.280577, train/ssim=0.723506, validation/loss=0.303647, validation/num_examples=3554, validation/ssim=0.700837
I0329 21:40:08.638440 140268179547968 checkpoints.py:356] Saving checkpoint at step: 1087
I0329 21:40:08.837026 140268179547968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_1087
I0329 21:40:08.837496 140268179547968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_1087.
I0329 21:40:08.838177 140268179547968 submission_runner.py:409] After logging and checkpointing eval at step 1087: RAM USED (GB) 140.600594432
I0329 21:40:09.949786 140036049716992 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.4366396367549896, loss=0.2890297472476959
I0329 21:40:34.376306 140016244213504 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.21204498410224915, loss=0.27437809109687805
I0329 21:40:58.859519 140036049716992 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.15562814474105835, loss=0.3220142126083374
I0329 21:41:23.295378 140016244213504 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.5079601407051086, loss=0.2609860897064209
I0329 21:41:28.996009 140268179547968 submission_runner.py:371] Before eval at step 1425: RAM USED (GB) 140.476207104
I0329 21:41:28.996209 140268179547968 spec.py:298] Evaluating on the training split.
I0329 21:41:30.403756 140268179547968 spec.py:310] Evaluating on the validation split.
I0329 21:41:32.590975 140268179547968 spec.py:326] Evaluating on the test split.
I0329 21:41:33.940349 140268179547968 submission_runner.py:380] Time since start: 638.09s, 	Step: 1425, 	{'train/ssim': 0.7280800683157784, 'train/loss': 0.2826246363776071, 'validation/ssim': 0.7043532595315138, 'validation/loss': 0.3061332809972038, 'validation/num_examples': 3554, 'test/ssim': 0.7217745894128735, 'test/loss': 0.30763037968400936, 'test/num_examples': 3581}
I0329 21:41:33.941062 140268179547968 submission_runner.py:390] After eval at step 1425: RAM USED (GB) 140.693622784
I0329 21:41:33.949328 140036049716992 logging_writer.py:48] [1425] global_step=1425, preemption_count=0, score=446.987407, test/loss=0.307630, test/num_examples=3581, test/ssim=0.721775, total_duration=638.092343, train/loss=0.282625, train/ssim=0.728080, validation/loss=0.306133, validation/num_examples=3554, validation/ssim=0.704353
I0329 21:41:33.975441 140268179547968 checkpoints.py:356] Saving checkpoint at step: 1425
I0329 21:41:34.154624 140268179547968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_1425
I0329 21:41:34.155146 140268179547968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_1425.
I0329 21:41:34.155896 140268179547968 submission_runner.py:409] After logging and checkpointing eval at step 1425: RAM USED (GB) 140.703588352
I0329 21:41:50.284975 140016244213504 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.12232591956853867, loss=0.2804517447948456
I0329 21:42:14.596613 140016090986240 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.4002331793308258, loss=0.26354867219924927
I0329 21:42:39.230695 140016244213504 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.09480689465999603, loss=0.3306023180484772
I0329 21:42:54.205284 140268179547968 submission_runner.py:371] Before eval at step 1763: RAM USED (GB) 140.528128
I0329 21:42:54.205503 140268179547968 spec.py:298] Evaluating on the training split.
I0329 21:42:55.609516 140268179547968 spec.py:310] Evaluating on the validation split.
I0329 21:42:56.959047 140268179547968 spec.py:326] Evaluating on the test split.
I0329 21:42:58.307347 140268179547968 submission_runner.py:380] Time since start: 723.30s, 	Step: 1763, 	{'train/ssim': 0.7335514341081891, 'train/loss': 0.27586248942783903, 'validation/ssim': 0.7102191605189575, 'validation/loss': 0.2997911890101822, 'validation/num_examples': 3554, 'test/ssim': 0.7271514100024434, 'test/loss': 0.3017015326658929, 'test/num_examples': 3581}
I0329 21:42:58.308313 140268179547968 submission_runner.py:390] After eval at step 1763: RAM USED (GB) 140.752211968
I0329 21:42:58.317021 140016090986240 logging_writer.py:48] [1763] global_step=1763, preemption_count=0, score=526.687977, test/loss=0.301702, test/num_examples=3581, test/ssim=0.727151, total_duration=723.301643, train/loss=0.275862, train/ssim=0.733551, validation/loss=0.299791, validation/num_examples=3554, validation/ssim=0.710219
I0329 21:42:58.343792 140268179547968 checkpoints.py:356] Saving checkpoint at step: 1763
I0329 21:42:58.523666 140268179547968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_1763
I0329 21:42:58.524140 140268179547968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_1763.
I0329 21:42:58.524864 140268179547968 submission_runner.py:409] After logging and checkpointing eval at step 1763: RAM USED (GB) 140.755959808
I0329 21:43:05.446877 140016244213504 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.154539093375206, loss=0.2186083346605301
I0329 21:43:30.124550 140015925454592 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.2899259924888611, loss=0.31441962718963623
I0329 21:43:55.267977 140016244213504 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.1158810406923294, loss=0.23664627969264984
I0329 21:44:18.552564 140268179547968 submission_runner.py:371] Before eval at step 2094: RAM USED (GB) 140.626571264
I0329 21:44:18.552784 140268179547968 spec.py:298] Evaluating on the training split.
I0329 21:44:19.959649 140268179547968 spec.py:310] Evaluating on the validation split.
I0329 21:44:21.311038 140268179547968 spec.py:326] Evaluating on the test split.
I0329 21:44:22.661584 140268179547968 submission_runner.py:380] Time since start: 807.65s, 	Step: 2094, 	{'train/ssim': 0.7307938848223005, 'train/loss': 0.2745998927525112, 'validation/ssim': 0.7086627468609313, 'validation/loss': 0.2975657242499648, 'validation/num_examples': 3554, 'test/ssim': 0.7257901266013335, 'test/loss': 0.2991201597297368, 'test/num_examples': 3581}
I0329 21:44:22.662310 140268179547968 submission_runner.py:390] After eval at step 2094: RAM USED (GB) 140.832043008
I0329 21:44:22.670618 140015925454592 logging_writer.py:48] [2094] global_step=2094, preemption_count=0, score=606.375176, test/loss=0.299120, test/num_examples=3581, test/ssim=0.725790, total_duration=807.648890, train/loss=0.274600, train/ssim=0.730794, validation/loss=0.297566, validation/num_examples=3554, validation/ssim=0.708663
I0329 21:44:22.696699 140268179547968 checkpoints.py:356] Saving checkpoint at step: 2094
I0329 21:44:22.870110 140268179547968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_2094
I0329 21:44:22.870613 140268179547968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_2094.
I0329 21:44:22.871359 140268179547968 submission_runner.py:409] After logging and checkpointing eval at step 2094: RAM USED (GB) 140.833660928
I0329 21:44:23.387444 140016244213504 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.07175720483064651, loss=0.25289005041122437
I0329 21:44:47.204348 140015782844160 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.19962170720100403, loss=0.3151894211769104
I0329 21:45:11.814119 140016244213504 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.15402525663375854, loss=0.2730492949485779
I0329 21:45:36.230911 140015782844160 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.06862996518611908, loss=0.2862160801887512
I0329 21:45:42.931041 140268179547968 submission_runner.py:371] Before eval at step 2428: RAM USED (GB) 140.606595072
I0329 21:45:42.931277 140268179547968 spec.py:298] Evaluating on the training split.
I0329 21:45:44.339487 140268179547968 spec.py:310] Evaluating on the validation split.
I0329 21:45:45.687843 140268179547968 spec.py:326] Evaluating on the test split.
I0329 21:45:47.040297 140268179547968 submission_runner.py:380] Time since start: 892.03s, 	Step: 2428, 	{'train/ssim': 0.7376785278320312, 'train/loss': 0.2699604204722813, 'validation/ssim': 0.713805431050401, 'validation/loss': 0.2938495865683913, 'validation/num_examples': 3554, 'test/ssim': 0.7309680758691707, 'test/loss': 0.2955066262260891, 'test/num_examples': 3581}
I0329 21:45:47.041194 140268179547968 submission_runner.py:390] After eval at step 2428: RAM USED (GB) 140.83497984
I0329 21:45:47.050368 140016244213504 logging_writer.py:48] [2428] global_step=2428, preemption_count=0, score=686.095856, test/loss=0.295507, test/num_examples=3581, test/ssim=0.730968, total_duration=892.027422, train/loss=0.269960, train/ssim=0.737679, validation/loss=0.293850, validation/num_examples=3554, validation/ssim=0.713805
I0329 21:45:47.077947 140268179547968 checkpoints.py:356] Saving checkpoint at step: 2428
I0329 21:45:47.253392 140268179547968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_2428
I0329 21:45:47.253912 140268179547968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_2428.
I0329 21:45:47.254651 140268179547968 submission_runner.py:409] After logging and checkpointing eval at step 2428: RAM USED (GB) 140.833726464
I0329 21:46:02.601588 140015782844160 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.2075849175453186, loss=0.276777058839798
I0329 21:46:27.210091 140015883491072 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.1292184442281723, loss=0.2954652011394501
I0329 21:46:51.802013 140015782844160 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.0900828018784523, loss=0.264747679233551
I0329 21:46:54.893202 140268179547968 submission_runner.py:371] Before eval at step 2714: RAM USED (GB) 140.633915392
I0329 21:46:54.893408 140268179547968 spec.py:298] Evaluating on the training split.
I0329 21:46:56.297767 140268179547968 spec.py:310] Evaluating on the validation split.
I0329 21:46:57.647343 140268179547968 spec.py:326] Evaluating on the test split.
I0329 21:46:58.992917 140268179547968 submission_runner.py:380] Time since start: 963.99s, 	Step: 2714, 	{'train/ssim': 0.7373608180454799, 'train/loss': 0.2705425705228533, 'validation/ssim': 0.7129909191228193, 'validation/loss': 0.2942890259544703, 'validation/num_examples': 3554, 'test/ssim': 0.7303179432246579, 'test/loss': 0.29586520137749583, 'test/num_examples': 3581}
I0329 21:46:58.993638 140268179547968 submission_runner.py:390] After eval at step 2714: RAM USED (GB) 140.855742464
I0329 21:46:59.001996 140015883491072 logging_writer.py:48] [2714] global_step=2714, preemption_count=0, score=753.445911, test/loss=0.295865, test/num_examples=3581, test/ssim=0.730318, total_duration=963.989527, train/loss=0.270543, train/ssim=0.737361, validation/loss=0.294289, validation/num_examples=3554, validation/ssim=0.712991
I0329 21:46:59.028318 140268179547968 checkpoints.py:356] Saving checkpoint at step: 2714
I0329 21:46:59.208201 140268179547968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_2714
I0329 21:46:59.208661 140268179547968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_2714.
I0329 21:46:59.209360 140268179547968 submission_runner.py:409] After logging and checkpointing eval at step 2714: RAM USED (GB) 140.795650048
I0329 21:46:59.216463 140015782844160 logging_writer.py:48] [2714] global_step=2714, preemption_count=0, score=753.445911
I0329 21:46:59.238721 140268179547968 checkpoints.py:356] Saving checkpoint at step: 2714
I0329 21:46:59.480853 140268179547968 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_2714
I0329 21:46:59.481378 140268179547968 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/fastmri_jax/trial_1/checkpoint_2714.
I0329 21:47:00.310032 140268179547968 submission_runner.py:543] Tuning trial 1/1
I0329 21:47:00.310295 140268179547968 submission_runner.py:544] Hyperparameters: Hyperparameters(learning_rate=0.4394877561366806, one_minus_beta1=0.07113602458522507, warmup_factor=0.05, weight_decay=9.611851572925426e-07, label_smoothing=0.2, dropout_rate=0.0, decay_steps_factor=0.9, end_factor=0.001)
I0329 21:47:00.315240 140268179547968 submission_runner.py:545] Metrics: {'eval_results': [(1, {'train/ssim': 0.24509545734950475, 'train/loss': 0.7624429294041225, 'validation/ssim': 0.23672924997032394, 'validation/loss': 0.7751661310319359, 'validation/num_examples': 3554, 'test/ssim': 0.26100727540426033, 'test/loss': 0.7728417041547403, 'test/num_examples': 3581, 'score': 48.024601459503174, 'total_duration': 48.17224669456482, 'global_step': 1, 'preemption_count': 0}), (332, {'train/ssim': 0.7112719672066825, 'train/loss': 0.2954414572034563, 'validation/ssim': 0.6882391539462578, 'validation/loss': 0.31929458334798816, 'validation/num_examples': 3554, 'test/ssim': 0.7060443928241064, 'test/loss': 0.32105225086611633, 'test/num_examples': 3581, 'score': 127.58097505569458, 'total_duration': 290.923104763031, 'global_step': 332, 'preemption_count': 0}), (587, {'train/ssim': 0.718620845249721, 'train/loss': 0.286379337310791, 'validation/ssim': 0.6958755209798818, 'validation/loss': 0.30962066564522367, 'validation/num_examples': 3554, 'test/ssim': 0.7134140854073583, 'test/loss': 0.3113395991321384, 'test/num_examples': 3581, 'score': 207.3713619709015, 'total_duration': 379.97288966178894, 'global_step': 587, 'preemption_count': 0}), (823, {'train/ssim': 0.6883796283176967, 'train/loss': 0.29256510734558105, 'validation/ssim': 0.6748287993062394, 'validation/loss': 0.31424054954584624, 'validation/num_examples': 3554, 'test/ssim': 0.6899615865418179, 'test/loss': 0.3160857515140673, 'test/num_examples': 3581, 'score': 287.30388855934143, 'total_duration': 465.5027449131012, 'global_step': 823, 'preemption_count': 0}), (1087, {'train/ssim': 0.7235063144138881, 'train/loss': 0.2805770124707903, 'validation/ssim': 0.7008369201076252, 'validation/loss': 0.3036465363081211, 'validation/num_examples': 3554, 'test/ssim': 0.7183692333452597, 'test/loss': 0.30515938476289795, 'test/num_examples': 3581, 'score': 367.1737186908722, 'total_duration': 551.1285104751587, 'global_step': 1087, 'preemption_count': 0}), (1425, {'train/ssim': 0.7280800683157784, 'train/loss': 0.2826246363776071, 'validation/ssim': 0.7043532595315138, 'validation/loss': 0.3061332809972038, 'validation/num_examples': 3554, 'test/ssim': 0.7217745894128735, 'test/loss': 0.30763037968400936, 'test/num_examples': 3581, 'score': 446.987407207489, 'total_duration': 638.0923433303833, 'global_step': 1425, 'preemption_count': 0}), (1763, {'train/ssim': 0.7335514341081891, 'train/loss': 0.27586248942783903, 'validation/ssim': 0.7102191605189575, 'validation/loss': 0.2997911890101822, 'validation/num_examples': 3554, 'test/ssim': 0.7271514100024434, 'test/loss': 0.3017015326658929, 'test/num_examples': 3581, 'score': 526.6879773139954, 'total_duration': 723.3016428947449, 'global_step': 1763, 'preemption_count': 0}), (2094, {'train/ssim': 0.7307938848223005, 'train/loss': 0.2745998927525112, 'validation/ssim': 0.7086627468609313, 'validation/loss': 0.2975657242499648, 'validation/num_examples': 3554, 'test/ssim': 0.7257901266013335, 'test/loss': 0.2991201597297368, 'test/num_examples': 3581, 'score': 606.3751757144928, 'total_duration': 807.648889541626, 'global_step': 2094, 'preemption_count': 0}), (2428, {'train/ssim': 0.7376785278320312, 'train/loss': 0.2699604204722813, 'validation/ssim': 0.713805431050401, 'validation/loss': 0.2938495865683913, 'validation/num_examples': 3554, 'test/ssim': 0.7309680758691707, 'test/loss': 0.2955066262260891, 'test/num_examples': 3581, 'score': 686.0958557128906, 'total_duration': 892.0274221897125, 'global_step': 2428, 'preemption_count': 0}), (2714, {'train/ssim': 0.7373608180454799, 'train/loss': 0.2705425705228533, 'validation/ssim': 0.7129909191228193, 'validation/loss': 0.2942890259544703, 'validation/num_examples': 3554, 'test/ssim': 0.7303179432246579, 'test/loss': 0.29586520137749583, 'test/num_examples': 3581, 'score': 753.4459114074707, 'total_duration': 963.9895269870758, 'global_step': 2714, 'preemption_count': 0})], 'global_step': 2714}
I0329 21:47:00.315379 140268179547968 submission_runner.py:546] Timing: 753.4459114074707
I0329 21:47:00.315430 140268179547968 submission_runner.py:547] ====================
I0329 21:47:00.315538 140268179547968 submission_runner.py:606] Final fastmri score: 753.4459114074707
