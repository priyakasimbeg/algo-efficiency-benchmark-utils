python3 submission_runner.py --framework=jax --workload=fastmri --submission_path=baselines/adamw/jax/submission.py --tuning_search_space=baselines/adamw/tuning_search_space.json --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_jax_upgrade_preliminary/adamw --overwrite=True --save_checkpoints=False --max_global_steps=2714 2>&1 | tee -a /logs/fastmri_jax_08-07-2023-23-54-42.log
2023-08-07 23:54:46.955321: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0807 23:55:03.761548 139718829606720 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_jax_upgrade_preliminary/adamw/fastmri_jax.
I0807 23:55:05.299860 139718829606720 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Host CUDA Interpreter
I0807 23:55:05.300593 139718829606720 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0807 23:55:05.300722 139718829606720 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0807 23:55:05.306670 139718829606720 submission_runner.py:490] Using RNG seed 3767608544
I0807 23:55:10.514772 139718829606720 submission_runner.py:499] --- Tuning run 1/1 ---
I0807 23:55:10.514989 139718829606720 submission_runner.py:504] Creating tuning directory at /experiment_runs/timing_jax_upgrade_preliminary/adamw/fastmri_jax/trial_1.
I0807 23:55:10.516789 139718829606720 logger_utils.py:92] Saving hparams to /experiment_runs/timing_jax_upgrade_preliminary/adamw/fastmri_jax/trial_1/hparams.json.
I0807 23:55:10.695569 139718829606720 submission_runner.py:176] Initializing dataset.
I0807 23:55:17.092386 139718829606720 submission_runner.py:183] Initializing model.
I0807 23:55:23.652735 139718829606720 submission_runner.py:217] Initializing optimizer.
I0807 23:55:24.493535 139718829606720 submission_runner.py:224] Initializing metrics bundle.
I0807 23:55:24.493759 139718829606720 submission_runner.py:242] Initializing checkpoint and logger.
I0807 23:55:24.494624 139718829606720 checkpoints.py:915] Found no checkpoint files in /experiment_runs/timing_jax_upgrade_preliminary/adamw/fastmri_jax/trial_1 with prefix checkpoint_
I0807 23:55:24.494886 139718829606720 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0807 23:55:24.494956 139718829606720 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
I0807 23:55:25.351570 139718829606720 submission_runner.py:263] Saving meta data to /experiment_runs/timing_jax_upgrade_preliminary/adamw/fastmri_jax/trial_1/meta_data_0.json.
I0807 23:55:25.353845 139718829606720 submission_runner.py:266] Saving flags to /experiment_runs/timing_jax_upgrade_preliminary/adamw/fastmri_jax/trial_1/flags_0.json.
I0807 23:55:25.362494 139718829606720 submission_runner.py:276] Starting training loop.
2023-08-07 23:56:30.742486: E external/xla/xla/service/rendezvous.cc:31] This thread has been waiting for 10 seconds and may be stuck:
2023-08-07 23:56:33.240175: E external/xla/xla/service/rendezvous.cc:36] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.
I0807 23:56:34.746640 139554518460160 logging_writer.py:48] [0] global_step=0, grad_norm=4.876565933227539, loss=1.0356887578964233
I0807 23:56:34.760154 139718829606720 spec.py:320] Evaluating on the training split.
I0807 23:57:59.918485 139718829606720 spec.py:332] Evaluating on the validation split.
I0807 23:59:00.892622 139718829606720 spec.py:348] Evaluating on the test split.
I0807 23:59:55.957048 139718829606720 submission_runner.py:364] Time since start: 270.59s, 	Step: 1, 	{'train/ssim': 0.2338651418685913, 'train/loss': 1.0364270891462053, 'validation/ssim': 0.2233507696268729, 'validation/loss': 1.0434360793955755, 'validation/num_examples': 3554, 'test/ssim': 0.2470794481726473, 'test/loss': 1.0412431305195826, 'test/num_examples': 3581, 'score': 69.39761543273926, 'total_duration': 270.59446477890015, 'accumulated_submission_time': 69.39761543273926, 'accumulated_eval_time': 201.19682478904724, 'accumulated_logging_time': 0}
I0807 23:59:55.978875 139523052779264 logging_writer.py:48] [1] accumulated_eval_time=201.196825, accumulated_logging_time=0, accumulated_submission_time=69.397615, global_step=1, preemption_count=0, score=69.397615, test/loss=1.041243, test/num_examples=3581, test/ssim=0.247079, total_duration=270.594465, train/loss=1.036427, train/ssim=0.233865, validation/loss=1.043436, validation/num_examples=3554, validation/ssim=0.223351
I0808 00:00:17.260760 139523044386560 logging_writer.py:48] [100] global_step=100, grad_norm=0.2567683458328247, loss=0.2506166100502014
I0808 00:00:41.057934 139523052779264 logging_writer.py:48] [200] global_step=200, grad_norm=0.10439091175794601, loss=0.354772686958313
I0808 00:01:04.891873 139523044386560 logging_writer.py:48] [300] global_step=300, grad_norm=0.4237171709537506, loss=0.3000200092792511
I0808 00:01:16.290732 139718829606720 spec.py:320] Evaluating on the training split.
I0808 00:01:18.005225 139718829606720 spec.py:332] Evaluating on the validation split.
I0808 00:01:19.321599 139718829606720 spec.py:348] Evaluating on the test split.
I0808 00:01:20.640571 139718829606720 submission_runner.py:364] Time since start: 355.28s, 	Step: 338, 	{'train/ssim': 0.7048215866088867, 'train/loss': 0.3009888104030064, 'validation/ssim': 0.6841471537352279, 'validation/loss': 0.3212408388875211, 'validation/num_examples': 3554, 'test/ssim': 0.7017407410639486, 'test/loss': 0.32334298669409733, 'test/num_examples': 3581, 'score': 149.69472670555115, 'total_duration': 355.27800464630127, 'accumulated_submission_time': 149.69472670555115, 'accumulated_eval_time': 205.54662156105042, 'accumulated_logging_time': 0.03069615364074707}
I0808 00:01:20.660417 139523052779264 logging_writer.py:48] [338] accumulated_eval_time=205.546622, accumulated_logging_time=0.030696, accumulated_submission_time=149.694727, global_step=338, preemption_count=0, score=149.694727, test/loss=0.323343, test/num_examples=3581, test/ssim=0.701741, total_duration=355.278005, train/loss=0.300989, train/ssim=0.704822, validation/loss=0.321241, validation/num_examples=3554, validation/ssim=0.684147
I0808 00:01:38.617214 139523044386560 logging_writer.py:48] [400] global_step=400, grad_norm=0.3084721863269806, loss=0.28446170687675476
I0808 00:02:15.405045 139523052779264 logging_writer.py:48] [500] global_step=500, grad_norm=0.3603757917881012, loss=0.2690810263156891
I0808 00:02:40.770448 139718829606720 spec.py:320] Evaluating on the training split.
I0808 00:02:42.141983 139718829606720 spec.py:332] Evaluating on the validation split.
I0808 00:02:43.463875 139718829606720 spec.py:348] Evaluating on the test split.
I0808 00:02:44.785485 139718829606720 submission_runner.py:364] Time since start: 439.42s, 	Step: 574, 	{'train/ssim': 0.7069426264081683, 'train/loss': 0.29256071363176617, 'validation/ssim': 0.6892767172552055, 'validation/loss': 0.3116772447198579, 'validation/num_examples': 3554, 'test/ssim': 0.7058157964779391, 'test/loss': 0.3138954399085451, 'test/num_examples': 3581, 'score': 229.77963185310364, 'total_duration': 439.42290353775024, 'accumulated_submission_time': 229.77963185310364, 'accumulated_eval_time': 209.56160473823547, 'accumulated_logging_time': 0.07171869277954102}
I0808 00:02:44.807559 139523044386560 logging_writer.py:48] [574] accumulated_eval_time=209.561605, accumulated_logging_time=0.071719, accumulated_submission_time=229.779632, global_step=574, preemption_count=0, score=229.779632, test/loss=0.313895, test/num_examples=3581, test/ssim=0.705816, total_duration=439.422904, train/loss=0.292561, train/ssim=0.706943, validation/loss=0.311677, validation/num_examples=3554, validation/ssim=0.689277
I0808 00:02:51.157981 139523052779264 logging_writer.py:48] [600] global_step=600, grad_norm=0.22437964379787445, loss=0.30548760294914246
I0808 00:03:26.900958 139523044386560 logging_writer.py:48] [700] global_step=700, grad_norm=0.3512894809246063, loss=0.21923990547657013
I0808 00:04:01.947256 139523052779264 logging_writer.py:48] [800] global_step=800, grad_norm=0.6170037984848022, loss=0.22862771153450012
I0808 00:04:05.178609 139718829606720 spec.py:320] Evaluating on the training split.
I0808 00:04:06.551390 139718829606720 spec.py:332] Evaluating on the validation split.
I0808 00:04:07.872483 139718829606720 spec.py:348] Evaluating on the test split.
I0808 00:04:09.196565 139718829606720 submission_runner.py:364] Time since start: 523.83s, 	Step: 810, 	{'train/ssim': 0.7249974523271833, 'train/loss': 0.28401197705950054, 'validation/ssim': 0.7039154001213421, 'validation/loss': 0.3034273318246166, 'validation/num_examples': 3554, 'test/ssim': 0.7211862248237224, 'test/loss': 0.3056755161791399, 'test/num_examples': 3581, 'score': 310.12858963012695, 'total_duration': 523.8339803218842, 'accumulated_submission_time': 310.12858963012695, 'accumulated_eval_time': 213.57949566841125, 'accumulated_logging_time': 0.11197161674499512}
I0808 00:04:09.214035 139523044386560 logging_writer.py:48] [810] accumulated_eval_time=213.579496, accumulated_logging_time=0.111972, accumulated_submission_time=310.128590, global_step=810, preemption_count=0, score=310.128590, test/loss=0.305676, test/num_examples=3581, test/ssim=0.721186, total_duration=523.833980, train/loss=0.284012, train/ssim=0.724997, validation/loss=0.303427, validation/num_examples=3554, validation/ssim=0.703915
I0808 00:04:39.206695 139523052779264 logging_writer.py:48] [900] global_step=900, grad_norm=0.1480502486228943, loss=0.31570321321487427
I0808 00:05:10.794455 139523044386560 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.22524461150169373, loss=0.23912975192070007
I0808 00:05:29.444228 139718829606720 spec.py:320] Evaluating on the training split.
I0808 00:05:30.820311 139718829606720 spec.py:332] Evaluating on the validation split.
I0808 00:05:32.143352 139718829606720 spec.py:348] Evaluating on the test split.
I0808 00:05:33.464729 139718829606720 submission_runner.py:364] Time since start: 608.10s, 	Step: 1080, 	{'train/ssim': 0.7299665042332241, 'train/loss': 0.27906411034720285, 'validation/ssim': 0.708557850199599, 'validation/loss': 0.2987517365996061, 'validation/num_examples': 3554, 'test/ssim': 0.7257562428005445, 'test/loss': 0.30075179768221166, 'test/num_examples': 3581, 'score': 390.34405994415283, 'total_duration': 608.1021573543549, 'accumulated_submission_time': 390.34405994415283, 'accumulated_eval_time': 217.59995222091675, 'accumulated_logging_time': 0.13967680931091309}
I0808 00:05:33.479728 139523052779264 logging_writer.py:48] [1080] accumulated_eval_time=217.599952, accumulated_logging_time=0.139677, accumulated_submission_time=390.344060, global_step=1080, preemption_count=0, score=390.344060, test/loss=0.300752, test/num_examples=3581, test/ssim=0.725756, total_duration=608.102157, train/loss=0.279064, train/ssim=0.729967, validation/loss=0.298752, validation/num_examples=3554, validation/ssim=0.708558
I0808 00:05:36.186532 139523044386560 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.1831861287355423, loss=0.2644309401512146
I0808 00:05:59.688792 139523052779264 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.1716362088918686, loss=0.2735384702682495
I0808 00:06:22.952627 139523044386560 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.2397817224264145, loss=0.3138781785964966
I0808 00:06:45.985405 139523052779264 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.22476565837860107, loss=0.26745304465293884
I0808 00:06:53.587507 139718829606720 spec.py:320] Evaluating on the training split.
I0808 00:06:54.960655 139718829606720 spec.py:332] Evaluating on the validation split.
I0808 00:06:56.284772 139718829606720 spec.py:348] Evaluating on the test split.
I0808 00:06:57.607395 139718829606720 submission_runner.py:364] Time since start: 692.24s, 	Step: 1433, 	{'train/ssim': 0.7316596167428153, 'train/loss': 0.27809131145477295, 'validation/ssim': 0.7102967854222355, 'validation/loss': 0.2977945116308209, 'validation/num_examples': 3554, 'test/ssim': 0.7274185943390463, 'test/loss': 0.29968643508054665, 'test/num_examples': 3581, 'score': 470.43666911125183, 'total_duration': 692.2447936534882, 'accumulated_submission_time': 470.43666911125183, 'accumulated_eval_time': 221.61976075172424, 'accumulated_logging_time': 0.16385626792907715}
I0808 00:06:57.624969 139523044386560 logging_writer.py:48] [1433] accumulated_eval_time=221.619761, accumulated_logging_time=0.163856, accumulated_submission_time=470.436669, global_step=1433, preemption_count=0, score=470.436669, test/loss=0.299686, test/num_examples=3581, test/ssim=0.727419, total_duration=692.244794, train/loss=0.278091, train/ssim=0.731660, validation/loss=0.297795, validation/num_examples=3554, validation/ssim=0.710297
I0808 00:07:11.315701 139523052779264 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.1563158631324768, loss=0.38632771372795105
I0808 00:07:34.666087 139523044386560 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.2302338182926178, loss=0.204689621925354
I0808 00:07:57.756821 139523052779264 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.1151428148150444, loss=0.4050804674625397
I0808 00:08:17.611425 139718829606720 spec.py:320] Evaluating on the training split.
I0808 00:08:18.986645 139718829606720 spec.py:332] Evaluating on the validation split.
I0808 00:08:20.308207 139718829606720 spec.py:348] Evaluating on the test split.
I0808 00:08:21.630519 139718829606720 submission_runner.py:364] Time since start: 776.27s, 	Step: 1786, 	{'train/ssim': 0.7336192812238421, 'train/loss': 0.27610158920288086, 'validation/ssim': 0.7127223919131612, 'validation/loss': 0.29563097505671426, 'validation/num_examples': 3554, 'test/ssim': 0.7296378128490645, 'test/loss': 0.2972899231621754, 'test/num_examples': 3581, 'score': 550.4069769382477, 'total_duration': 776.2679259777069, 'accumulated_submission_time': 550.4069769382477, 'accumulated_eval_time': 225.6387975215912, 'accumulated_logging_time': 0.19145464897155762}
I0808 00:08:21.646902 139523044386560 logging_writer.py:48] [1786] accumulated_eval_time=225.638798, accumulated_logging_time=0.191455, accumulated_submission_time=550.406977, global_step=1786, preemption_count=0, score=550.406977, test/loss=0.297290, test/num_examples=3581, test/ssim=0.729638, total_duration=776.267926, train/loss=0.276102, train/ssim=0.733619, validation/loss=0.295631, validation/num_examples=3554, validation/ssim=0.712722
I0808 00:08:22.883632 139523052779264 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.41166719794273376, loss=0.25168371200561523
I0808 00:08:45.975340 139523044386560 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.1420433670282364, loss=0.26085203886032104
I0808 00:09:09.556155 139523052779264 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.09374748170375824, loss=0.3612116575241089
I0808 00:09:33.392371 139523044386560 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.12265569716691971, loss=0.3007703125476837
I0808 00:09:41.656084 139718829606720 spec.py:320] Evaluating on the training split.
I0808 00:09:43.029715 139718829606720 spec.py:332] Evaluating on the validation split.
I0808 00:09:44.349765 139718829606720 spec.py:348] Evaluating on the test split.
I0808 00:09:45.673657 139718829606720 submission_runner.py:364] Time since start: 860.31s, 	Step: 2137, 	{'train/ssim': 0.7304231779915946, 'train/loss': 0.2767672538757324, 'validation/ssim': 0.7111809536789533, 'validation/loss': 0.2961479363041643, 'validation/num_examples': 3554, 'test/ssim': 0.7275387897933538, 'test/loss': 0.29776330781162735, 'test/num_examples': 3581, 'score': 630.4007074832916, 'total_duration': 860.311062335968, 'accumulated_submission_time': 630.4007074832916, 'accumulated_eval_time': 229.65632033348083, 'accumulated_logging_time': 0.21738076210021973}
I0808 00:09:45.688054 139523052779264 logging_writer.py:48] [2137] accumulated_eval_time=229.656320, accumulated_logging_time=0.217381, accumulated_submission_time=630.400707, global_step=2137, preemption_count=0, score=630.400707, test/loss=0.297763, test/num_examples=3581, test/ssim=0.727539, total_duration=860.311062, train/loss=0.276767, train/ssim=0.730423, validation/loss=0.296148, validation/num_examples=3554, validation/ssim=0.711181
I0808 00:09:58.504964 139523044386560 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.15517085790634155, loss=0.3397544026374817
I0808 00:10:22.112651 139523052779264 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.05788575857877731, loss=0.3308335542678833
I0808 00:10:45.592342 139523044386560 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.0530739426612854, loss=0.26234641671180725
I0808 00:11:05.875731 139718829606720 spec.py:320] Evaluating on the training split.
I0808 00:11:07.249809 139718829606720 spec.py:332] Evaluating on the validation split.
I0808 00:11:08.572875 139718829606720 spec.py:348] Evaluating on the test split.
I0808 00:11:09.896696 139718829606720 submission_runner.py:364] Time since start: 944.53s, 	Step: 2487, 	{'train/ssim': 0.7308564867292132, 'train/loss': 0.28337228298187256, 'validation/ssim': 0.7096454231807471, 'validation/loss': 0.3037147157032569, 'validation/num_examples': 3554, 'test/ssim': 0.7260722416268152, 'test/loss': 0.305635769185458, 'test/num_examples': 3581, 'score': 710.5739088058472, 'total_duration': 944.5341274738312, 'accumulated_submission_time': 710.5739088058472, 'accumulated_eval_time': 233.67724585533142, 'accumulated_logging_time': 0.24026083946228027}
I0808 00:11:09.911408 139523052779264 logging_writer.py:48] [2487] accumulated_eval_time=233.677246, accumulated_logging_time=0.240261, accumulated_submission_time=710.573909, global_step=2487, preemption_count=0, score=710.573909, test/loss=0.305636, test/num_examples=3581, test/ssim=0.726072, total_duration=944.534127, train/loss=0.283372, train/ssim=0.730856, validation/loss=0.303715, validation/num_examples=3554, validation/ssim=0.709645
I0808 00:11:10.934369 139523044386560 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.13237318396568298, loss=0.25956234335899353
I0808 00:11:34.405940 139523052779264 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.30016985535621643, loss=0.2602057158946991
I0808 00:11:57.646397 139523044386560 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.1562650054693222, loss=0.2813318967819214
I0808 00:12:00.658592 139718829606720 spec.py:320] Evaluating on the training split.
I0808 00:12:02.032503 139718829606720 spec.py:332] Evaluating on the validation split.
I0808 00:12:03.358664 139718829606720 spec.py:348] Evaluating on the test split.
I0808 00:12:04.683903 139718829606720 submission_runner.py:364] Time since start: 999.32s, 	Step: 2714, 	{'train/ssim': 0.7397720473153251, 'train/loss': 0.271163923399789, 'validation/ssim': 0.7176969117103967, 'validation/loss': 0.291276561455842, 'validation/num_examples': 3554, 'test/ssim': 0.7348147394669785, 'test/loss': 0.2928942329089291, 'test/num_examples': 3581, 'score': 761.3082842826843, 'total_duration': 999.3213269710541, 'accumulated_submission_time': 761.3082842826843, 'accumulated_eval_time': 237.70250344276428, 'accumulated_logging_time': 0.2638845443725586}
I0808 00:12:04.698485 139523052779264 logging_writer.py:48] [2714] accumulated_eval_time=237.702503, accumulated_logging_time=0.263885, accumulated_submission_time=761.308284, global_step=2714, preemption_count=0, score=761.308284, test/loss=0.292894, test/num_examples=3581, test/ssim=0.734815, total_duration=999.321327, train/loss=0.271164, train/ssim=0.739772, validation/loss=0.291277, validation/num_examples=3554, validation/ssim=0.717697
I0808 00:12:04.712657 139523044386560 logging_writer.py:48] [2714] global_step=2714, preemption_count=0, score=761.308284
I0808 00:12:04.767242 139718829606720 checkpoints.py:490] Saving checkpoint at step: 2714
I0808 00:12:04.989861 139718829606720 checkpoints.py:422] Saved checkpoint at /experiment_runs/timing_jax_upgrade_preliminary/adamw/fastmri_jax/trial_1/checkpoint_2714
I0808 00:12:04.991255 139718829606720 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_jax_upgrade_preliminary/adamw/fastmri_jax/trial_1/checkpoint_2714.
I0808 00:12:05.729279 139718829606720 submission_runner.py:530] Tuning trial 1/1
I0808 00:12:05.729540 139718829606720 submission_runner.py:531] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0808 00:12:05.734587 139718829606720 submission_runner.py:532] Metrics: {'eval_results': [(1, {'train/ssim': 0.2338651418685913, 'train/loss': 1.0364270891462053, 'validation/ssim': 0.2233507696268729, 'validation/loss': 1.0434360793955755, 'validation/num_examples': 3554, 'test/ssim': 0.2470794481726473, 'test/loss': 1.0412431305195826, 'test/num_examples': 3581, 'score': 69.39761543273926, 'total_duration': 270.59446477890015, 'accumulated_submission_time': 69.39761543273926, 'accumulated_eval_time': 201.19682478904724, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (338, {'train/ssim': 0.7048215866088867, 'train/loss': 0.3009888104030064, 'validation/ssim': 0.6841471537352279, 'validation/loss': 0.3212408388875211, 'validation/num_examples': 3554, 'test/ssim': 0.7017407410639486, 'test/loss': 0.32334298669409733, 'test/num_examples': 3581, 'score': 149.69472670555115, 'total_duration': 355.27800464630127, 'accumulated_submission_time': 149.69472670555115, 'accumulated_eval_time': 205.54662156105042, 'accumulated_logging_time': 0.03069615364074707, 'global_step': 338, 'preemption_count': 0}), (574, {'train/ssim': 0.7069426264081683, 'train/loss': 0.29256071363176617, 'validation/ssim': 0.6892767172552055, 'validation/loss': 0.3116772447198579, 'validation/num_examples': 3554, 'test/ssim': 0.7058157964779391, 'test/loss': 0.3138954399085451, 'test/num_examples': 3581, 'score': 229.77963185310364, 'total_duration': 439.42290353775024, 'accumulated_submission_time': 229.77963185310364, 'accumulated_eval_time': 209.56160473823547, 'accumulated_logging_time': 0.07171869277954102, 'global_step': 574, 'preemption_count': 0}), (810, {'train/ssim': 0.7249974523271833, 'train/loss': 0.28401197705950054, 'validation/ssim': 0.7039154001213421, 'validation/loss': 0.3034273318246166, 'validation/num_examples': 3554, 'test/ssim': 0.7211862248237224, 'test/loss': 0.3056755161791399, 'test/num_examples': 3581, 'score': 310.12858963012695, 'total_duration': 523.8339803218842, 'accumulated_submission_time': 310.12858963012695, 'accumulated_eval_time': 213.57949566841125, 'accumulated_logging_time': 0.11197161674499512, 'global_step': 810, 'preemption_count': 0}), (1080, {'train/ssim': 0.7299665042332241, 'train/loss': 0.27906411034720285, 'validation/ssim': 0.708557850199599, 'validation/loss': 0.2987517365996061, 'validation/num_examples': 3554, 'test/ssim': 0.7257562428005445, 'test/loss': 0.30075179768221166, 'test/num_examples': 3581, 'score': 390.34405994415283, 'total_duration': 608.1021573543549, 'accumulated_submission_time': 390.34405994415283, 'accumulated_eval_time': 217.59995222091675, 'accumulated_logging_time': 0.13967680931091309, 'global_step': 1080, 'preemption_count': 0}), (1433, {'train/ssim': 0.7316596167428153, 'train/loss': 0.27809131145477295, 'validation/ssim': 0.7102967854222355, 'validation/loss': 0.2977945116308209, 'validation/num_examples': 3554, 'test/ssim': 0.7274185943390463, 'test/loss': 0.29968643508054665, 'test/num_examples': 3581, 'score': 470.43666911125183, 'total_duration': 692.2447936534882, 'accumulated_submission_time': 470.43666911125183, 'accumulated_eval_time': 221.61976075172424, 'accumulated_logging_time': 0.16385626792907715, 'global_step': 1433, 'preemption_count': 0}), (1786, {'train/ssim': 0.7336192812238421, 'train/loss': 0.27610158920288086, 'validation/ssim': 0.7127223919131612, 'validation/loss': 0.29563097505671426, 'validation/num_examples': 3554, 'test/ssim': 0.7296378128490645, 'test/loss': 0.2972899231621754, 'test/num_examples': 3581, 'score': 550.4069769382477, 'total_duration': 776.2679259777069, 'accumulated_submission_time': 550.4069769382477, 'accumulated_eval_time': 225.6387975215912, 'accumulated_logging_time': 0.19145464897155762, 'global_step': 1786, 'preemption_count': 0}), (2137, {'train/ssim': 0.7304231779915946, 'train/loss': 0.2767672538757324, 'validation/ssim': 0.7111809536789533, 'validation/loss': 0.2961479363041643, 'validation/num_examples': 3554, 'test/ssim': 0.7275387897933538, 'test/loss': 0.29776330781162735, 'test/num_examples': 3581, 'score': 630.4007074832916, 'total_duration': 860.311062335968, 'accumulated_submission_time': 630.4007074832916, 'accumulated_eval_time': 229.65632033348083, 'accumulated_logging_time': 0.21738076210021973, 'global_step': 2137, 'preemption_count': 0}), (2487, {'train/ssim': 0.7308564867292132, 'train/loss': 0.28337228298187256, 'validation/ssim': 0.7096454231807471, 'validation/loss': 0.3037147157032569, 'validation/num_examples': 3554, 'test/ssim': 0.7260722416268152, 'test/loss': 0.305635769185458, 'test/num_examples': 3581, 'score': 710.5739088058472, 'total_duration': 944.5341274738312, 'accumulated_submission_time': 710.5739088058472, 'accumulated_eval_time': 233.67724585533142, 'accumulated_logging_time': 0.24026083946228027, 'global_step': 2487, 'preemption_count': 0}), (2714, {'train/ssim': 0.7397720473153251, 'train/loss': 0.271163923399789, 'validation/ssim': 0.7176969117103967, 'validation/loss': 0.291276561455842, 'validation/num_examples': 3554, 'test/ssim': 0.7348147394669785, 'test/loss': 0.2928942329089291, 'test/num_examples': 3581, 'score': 761.3082842826843, 'total_duration': 999.3213269710541, 'accumulated_submission_time': 761.3082842826843, 'accumulated_eval_time': 237.70250344276428, 'accumulated_logging_time': 0.2638845443725586, 'global_step': 2714, 'preemption_count': 0})], 'global_step': 2714}
I0808 00:12:05.734749 139718829606720 submission_runner.py:533] Timing: 761.3082842826843
I0808 00:12:05.734800 139718829606720 submission_runner.py:535] Total number of evals: 10
I0808 00:12:05.734843 139718829606720 submission_runner.py:536] ====================
I0808 00:12:05.734963 139718829606720 submission_runner.py:604] Final fastmri score: 761.3082842826843
