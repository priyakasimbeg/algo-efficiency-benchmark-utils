torchrun --redirects 1:0,2:0,3:0,4:0,5:0,6:0,7:0 --standalone --nnodes=1 --nproc_per_node=8 submission_runner.py --framework=pytorch --workload=librispeech_deepspeech --submission_path=baselines/adamw/pytorch/submission.py --tuning_search_space=baselines/adamw/tuning_search_space.json --data_dir=/data/librispeech --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=test_today/adamw --overwrite=True --save_checkpoints=False --max_global_steps=10 --librispeech_tokenizer_vocab_path=/data/librispeech/spm_model.vocab 2>&1 | tee -a /logs/librispeech_deepspeech_pytorch_06-27-2023-23-10-40.log
master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-06-27 23:10:44.503454: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 23:10:44.503454: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 23:10:44.503454: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 23:10:44.503454: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 23:10:44.503892: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 23:10:44.507775: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 23:10:44.510137: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 23:10:44.539202: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0627 23:10:57.203201 140651975923520 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 5
I0627 23:10:58.197344 140049374967616 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 7
I0627 23:10:58.198523 139831354599232 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
I0627 23:10:58.198555 140331632416576 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 4
I0627 23:10:58.198668 139848115185472 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
I0627 23:10:58.199421 140662777579328 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 6
I0627 23:10:58.199445 140198864066368 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
I0627 23:10:58.208736 140625856329536 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
I0627 23:10:58.209092 140625856329536 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 23:10:58.209073 140331632416576 distributed_c10d.py:476] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 23:10:58.209115 139831354599232 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 23:10:58.209259 139848115185472 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 23:10:58.209974 140662777579328 distributed_c10d.py:476] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 23:10:58.209998 140198864066368 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 23:10:58.217913 140651975923520 distributed_c10d.py:476] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 23:10:58.218286 140049374967616 distributed_c10d.py:476] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 23:10:58.709500 140625856329536 logger_utils.py:61] Removing existing experiment directory /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch because --overwrite was set.
I0627 23:10:58.710256 140625856329536 logger_utils.py:76] Creating experiment directory at /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch.
W0627 23:10:58.710957 139831354599232 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 23:10:58.712028 140651975923520 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 23:10:58.712522 140331632416576 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 23:10:58.713228 140662777579328 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 23:10:58.713516 140198864066368 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 23:10:58.713789 139848115185472 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 23:10:58.713969 140049374967616 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 23:10:58.737705 140625856329536 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0627 23:10:58.742509 140625856329536 submission_runner.py:547] Using RNG seed 3546267004
I0627 23:10:58.743789 140625856329536 submission_runner.py:556] --- Tuning run 1/1 ---
I0627 23:10:58.743904 140625856329536 submission_runner.py:561] Creating tuning directory at /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch/trial_1.
I0627 23:10:58.744146 140625856329536 logger_utils.py:92] Saving hparams to /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch/trial_1/hparams.json.
I0627 23:10:58.744891 140625856329536 submission_runner.py:249] Initializing dataset.
I0627 23:10:58.745009 140625856329536 input_pipeline.py:20] Loading split = train-clean-100
I0627 23:10:58.780465 140625856329536 input_pipeline.py:20] Loading split = train-clean-360
I0627 23:10:59.204208 140625856329536 input_pipeline.py:20] Loading split = train-other-500
I0627 23:10:59.724017 140625856329536 submission_runner.py:256] Initializing model.
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
I0627 23:11:08.417533 140625856329536 submission_runner.py:268] Initializing optimizer.
I0627 23:11:08.418535 140625856329536 submission_runner.py:275] Initializing metrics bundle.
I0627 23:11:08.418650 140625856329536 submission_runner.py:292] Initializing checkpoint and logger.
I0627 23:11:08.419366 140625856329536 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0627 23:11:08.419466 140625856329536 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0627 23:11:09.316911 140625856329536 submission_runner.py:313] Saving meta data to /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch/trial_1/meta_data_0.json.
I0627 23:11:09.317941 140625856329536 submission_runner.py:316] Saving flags to /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch/trial_1/flags_0.json.
I0627 23:11:09.326550 140625856329536 submission_runner.py:328] Starting training loop.
I0627 23:11:39.788953 140599289349888 logging_writer.py:48] [0] global_step=0, grad_norm=31.713581, loss=33.315773
I0627 23:11:39.811036 140625856329536 submission.py:119] 0) loss = 33.316, grad_norm = 31.714
I0627 23:11:39.813597 140625856329536 spec.py:298] Evaluating on the training split.
I0627 23:11:39.814879 140625856329536 input_pipeline.py:20] Loading split = train-clean-100
I0627 23:11:39.851687 140625856329536 input_pipeline.py:20] Loading split = train-clean-360
I0627 23:11:40.368932 140625856329536 input_pipeline.py:20] Loading split = train-other-500
I0627 23:12:01.741371 140625856329536 spec.py:310] Evaluating on the validation split.
I0627 23:12:01.743479 140625856329536 input_pipeline.py:20] Loading split = dev-clean
I0627 23:12:01.747626 140625856329536 input_pipeline.py:20] Loading split = dev-other
I0627 23:12:16.863610 140625856329536 spec.py:326] Evaluating on the test split.
I0627 23:12:16.865127 140625856329536 input_pipeline.py:20] Loading split = test-clean
I0627 23:12:25.870927 140625856329536 submission_runner.py:424] Time since start: 76.54s, 	Step: 1, 	{'train/ctc_loss': 32.38689137682173, 'train/wer': 4.102084537138994, 'validation/ctc_loss': 31.0248643761302, 'validation/wer': 3.797344662772172, 'validation/num_examples': 5348, 'test/ctc_loss': 31.13697657913414, 'test/wer': 4.140170211037312, 'test/num_examples': 2472, 'score': 30.48616600036621, 'total_duration': 76.54451823234558, 'accumulated_submission_time': 30.48616600036621, 'accumulated_eval_time': 46.05684208869934, 'accumulated_logging_time': 0}
I0627 23:12:25.887428 140596226578176 logging_writer.py:48] [1] accumulated_eval_time=46.056842, accumulated_logging_time=0, accumulated_submission_time=30.486166, global_step=1, preemption_count=0, score=30.486166, test/ctc_loss=31.136977, test/num_examples=2472, test/wer=4.140170, total_duration=76.544518, train/ctc_loss=32.386891, train/wer=4.102085, validation/ctc_loss=31.024864, validation/num_examples=5348, validation/wer=3.797345
I0627 23:12:25.936173 140625856329536 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 23:12:25.936502 140331632416576 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 23:12:25.936514 140662777579328 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 23:12:25.936559 139831354599232 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 23:12:25.936547 139848115185472 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 23:12:25.936573 140049374967616 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 23:12:25.936911 140198864066368 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 23:12:25.937474 140651975923520 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 23:12:27.101812 140596218185472 logging_writer.py:48] [1] global_step=1, grad_norm=28.305624, loss=32.675129
I0627 23:12:27.105709 140625856329536 submission.py:119] 1) loss = 32.675, grad_norm = 28.306
I0627 23:12:28.375212 140596226578176 logging_writer.py:48] [2] global_step=2, grad_norm=29.984499, loss=33.211956
I0627 23:12:28.378763 140625856329536 submission.py:119] 2) loss = 33.212, grad_norm = 29.984
I0627 23:12:29.376677 140596218185472 logging_writer.py:48] [3] global_step=3, grad_norm=33.053524, loss=33.241768
I0627 23:12:29.380074 140625856329536 submission.py:119] 3) loss = 33.242, grad_norm = 33.054
I0627 23:12:30.296448 140596226578176 logging_writer.py:48] [4] global_step=4, grad_norm=36.041992, loss=32.809063
I0627 23:12:30.300183 140625856329536 submission.py:119] 4) loss = 32.809, grad_norm = 36.042
I0627 23:12:31.227457 140596218185472 logging_writer.py:48] [5] global_step=5, grad_norm=40.587151, loss=32.989906
I0627 23:12:31.231277 140625856329536 submission.py:119] 5) loss = 32.990, grad_norm = 40.587
I0627 23:12:32.157476 140596226578176 logging_writer.py:48] [6] global_step=6, grad_norm=51.397755, loss=33.087280
I0627 23:12:32.161120 140625856329536 submission.py:119] 6) loss = 33.087, grad_norm = 51.398
I0627 23:12:33.080280 140596218185472 logging_writer.py:48] [7] global_step=7, grad_norm=54.259201, loss=31.949535
I0627 23:12:33.083991 140625856329536 submission.py:119] 7) loss = 31.950, grad_norm = 54.259
I0627 23:12:34.007206 140596226578176 logging_writer.py:48] [8] global_step=8, grad_norm=66.290672, loss=32.316956
I0627 23:12:34.011168 140625856329536 submission.py:119] 8) loss = 32.317, grad_norm = 66.291
I0627 23:12:34.932744 140596218185472 logging_writer.py:48] [9] global_step=9, grad_norm=61.448479, loss=31.772715
I0627 23:12:34.936622 140625856329536 submission.py:119] 9) loss = 31.773, grad_norm = 61.448
I0627 23:12:34.938249 140625856329536 spec.py:298] Evaluating on the training split.
I0627 23:12:54.775004 140625856329536 spec.py:310] Evaluating on the validation split.
I0627 23:13:08.036100 140625856329536 spec.py:326] Evaluating on the test split.
I0627 23:13:14.934081 140625856329536 submission_runner.py:424] Time since start: 125.61s, 	Step: 10, 	{'train/ctc_loss': 32.44944192125135, 'train/wer': 4.116819118432672, 'validation/ctc_loss': 31.100964436407473, 'validation/wer': 3.7935306329358376, 'validation/num_examples': 5348, 'test/ctc_loss': 31.194519001225885, 'test/wer': 4.155667946296184, 'test/num_examples': 2472, 'score': 39.521336793899536, 'total_duration': 125.60777592658997, 'accumulated_submission_time': 39.521336793899536, 'accumulated_eval_time': 86.05236458778381, 'accumulated_logging_time': 0.02763080596923828}
I0627 23:13:14.947238 140596226578176 logging_writer.py:48] [10] accumulated_eval_time=86.052365, accumulated_logging_time=0.027631, accumulated_submission_time=39.521337, global_step=10, preemption_count=0, score=39.521337, test/ctc_loss=31.194519, test/num_examples=2472, test/wer=4.155668, total_duration=125.607776, train/ctc_loss=32.449442, train/wer=4.116819, validation/ctc_loss=31.100964, validation/num_examples=5348, validation/wer=3.793531
I0627 23:13:14.981242 140596218185472 logging_writer.py:48] [10] global_step=10, preemption_count=0, score=39.521337
I0627 23:13:15.386429 140625856329536 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch/trial_1/checkpoint_10.
I0627 23:13:15.536762 140625856329536 submission_runner.py:587] Tuning trial 1/1
I0627 23:13:15.537034 140625856329536 submission_runner.py:588] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0627 23:13:15.537525 140625856329536 submission_runner.py:589] Metrics: {'eval_results': [(1, {'train/ctc_loss': 32.38689137682173, 'train/wer': 4.102084537138994, 'validation/ctc_loss': 31.0248643761302, 'validation/wer': 3.797344662772172, 'validation/num_examples': 5348, 'test/ctc_loss': 31.13697657913414, 'test/wer': 4.140170211037312, 'test/num_examples': 2472, 'score': 30.48616600036621, 'total_duration': 76.54451823234558, 'accumulated_submission_time': 30.48616600036621, 'accumulated_eval_time': 46.05684208869934, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (10, {'train/ctc_loss': 32.44944192125135, 'train/wer': 4.116819118432672, 'validation/ctc_loss': 31.100964436407473, 'validation/wer': 3.7935306329358376, 'validation/num_examples': 5348, 'test/ctc_loss': 31.194519001225885, 'test/wer': 4.155667946296184, 'test/num_examples': 2472, 'score': 39.521336793899536, 'total_duration': 125.60777592658997, 'accumulated_submission_time': 39.521336793899536, 'accumulated_eval_time': 86.05236458778381, 'accumulated_logging_time': 0.02763080596923828, 'global_step': 10, 'preemption_count': 0})], 'global_step': 10}
I0627 23:13:15.537624 140625856329536 submission_runner.py:590] Timing: 39.521336793899536
I0627 23:13:15.537699 140625856329536 submission_runner.py:591] ====================
I0627 23:13:15.537852 140625856329536 submission_runner.py:659] Final librispeech_deepspeech score: 39.521336793899536
