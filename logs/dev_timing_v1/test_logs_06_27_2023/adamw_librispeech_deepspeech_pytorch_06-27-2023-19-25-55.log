torchrun --redirects 1:0,2:0,3:0,4:0,5:0,6:0,7:0 --standalone --nnodes=1 --nproc_per_node=8 submission_runner.py --framework=pytorch --workload=librispeech_deepspeech --submission_path=baselines/adamw/pytorch/submission.py --tuning_search_space=baselines/adamw/tuning_search_space.json --data_dir=/data/librispeech --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=test_today/adamw --overwrite=True --save_checkpoints=False --max_global_steps=10 --librispeech_tokenizer_vocab_path=/data/librispeech/spm_model.vocab 2>&1 | tee -a /logs/librispeech_deepspeech_pytorch_06-27-2023-19-25-55.log
master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-06-27 19:26:00.795277: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 19:26:00.795277: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 19:26:00.795277: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 19:26:00.795277: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 19:26:00.795277: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 19:26:00.795277: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 19:26:00.795277: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-27 19:26:00.795277: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0627 19:26:14.277201 140345262556992 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 4
I0627 19:26:14.277266 140298133927744 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 6
I0627 19:26:14.278313 139689609873216 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
I0627 19:26:14.278272 140579195426624 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
I0627 19:26:14.278578 140254103746368 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
I0627 19:26:14.278772 139904974591808 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 5
I0627 19:26:14.278823 140391351826240 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 7
I0627 19:26:14.288637 140182611101504 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
I0627 19:26:14.288900 139689609873216 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 19:26:14.289014 140182611101504 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 19:26:14.289061 140579195426624 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 19:26:14.289224 140254103746368 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 19:26:14.289305 140391351826240 distributed_c10d.py:476] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 19:26:14.289476 139904974591808 distributed_c10d.py:476] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 19:26:14.298127 140345262556992 distributed_c10d.py:476] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 19:26:14.298162 140298133927744 distributed_c10d.py:476] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0627 19:26:14.640233 140182611101504 logger_utils.py:76] Creating experiment directory at /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch.
W0627 19:26:14.643598 139689609873216 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 19:26:14.644527 140254103746368 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 19:26:14.644803 140345262556992 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 19:26:14.644843 140298133927744 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 19:26:14.644941 140391351826240 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 19:26:14.645714 140579195426624 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 19:26:14.646132 139904974591808 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0627 19:26:14.670135 140182611101504 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0627 19:26:14.674797 140182611101504 submission_runner.py:547] Using RNG seed 2402844456
I0627 19:26:14.676545 140182611101504 submission_runner.py:556] --- Tuning run 1/1 ---
I0627 19:26:14.676679 140182611101504 submission_runner.py:561] Creating tuning directory at /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch/trial_1.
I0627 19:26:14.677044 140182611101504 logger_utils.py:92] Saving hparams to /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch/trial_1/hparams.json.
I0627 19:26:14.678003 140182611101504 submission_runner.py:249] Initializing dataset.
I0627 19:26:14.678147 140182611101504 input_pipeline.py:20] Loading split = train-clean-100
I0627 19:26:14.713248 140182611101504 input_pipeline.py:20] Loading split = train-clean-360
I0627 19:26:15.134133 140182611101504 input_pipeline.py:20] Loading split = train-other-500
I0627 19:26:15.649709 140182611101504 submission_runner.py:256] Initializing model.
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
I0627 19:26:23.594851 140182611101504 submission_runner.py:268] Initializing optimizer.
I0627 19:26:23.595886 140182611101504 submission_runner.py:275] Initializing metrics bundle.
I0627 19:26:23.596078 140182611101504 submission_runner.py:292] Initializing checkpoint and logger.
I0627 19:26:23.596961 140182611101504 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0627 19:26:23.597081 140182611101504 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0627 19:26:24.489565 140182611101504 submission_runner.py:313] Saving meta data to /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch/trial_1/meta_data_0.json.
I0627 19:26:24.491164 140182611101504 submission_runner.py:316] Saving flags to /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch/trial_1/flags_0.json.
I0627 19:26:24.499845 140182611101504 submission_runner.py:328] Starting training loop.
I0627 19:26:55.158544 140157013432064 logging_writer.py:48] [0] global_step=0, grad_norm=19.788193, loss=33.532928
I0627 19:26:55.177654 140182611101504 submission.py:119] 0) loss = 33.533, grad_norm = 19.788
I0627 19:26:55.183321 140182611101504 spec.py:298] Evaluating on the training split.
I0627 19:26:55.184561 140182611101504 input_pipeline.py:20] Loading split = train-clean-100
I0627 19:26:55.222429 140182611101504 input_pipeline.py:20] Loading split = train-clean-360
I0627 19:26:55.738658 140182611101504 input_pipeline.py:20] Loading split = train-other-500
I0627 19:27:15.257948 140182611101504 spec.py:310] Evaluating on the validation split.
I0627 19:27:15.259578 140182611101504 input_pipeline.py:20] Loading split = dev-clean
I0627 19:27:15.263537 140182611101504 input_pipeline.py:20] Loading split = dev-other
I0627 19:27:29.822523 140182611101504 spec.py:326] Evaluating on the test split.
I0627 19:27:29.823921 140182611101504 input_pipeline.py:20] Loading split = test-clean
I0627 19:27:38.396520 140182611101504 submission_runner.py:424] Time since start: 73.90s, 	Step: 1, 	{'train/ctc_loss': 31.97001882317765, 'train/wer': 3.159130604584558, 'validation/ctc_loss': 30.81801913803496, 'validation/wer': 2.9459566455848982, 'validation/num_examples': 5348, 'test/ctc_loss': 30.963694431898833, 'test/wer': 3.070318688684419, 'test/num_examples': 2472, 'score': 30.68262553215027, 'total_duration': 73.89682078361511, 'accumulated_submission_time': 30.68262553215027, 'accumulated_eval_time': 43.21271848678589, 'accumulated_logging_time': 0}
I0627 19:27:38.410581 140154505258752 logging_writer.py:48] [1] accumulated_eval_time=43.212718, accumulated_logging_time=0, accumulated_submission_time=30.682626, global_step=1, preemption_count=0, score=30.682626, test/ctc_loss=30.963694, test/num_examples=2472, test/wer=3.070319, total_duration=73.896821, train/ctc_loss=31.970019, train/wer=3.159131, validation/ctc_loss=30.818019, validation/num_examples=5348, validation/wer=2.945957
I0627 19:27:38.466029 140579195426624 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 19:27:38.466105 139689609873216 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 19:27:38.466238 140391351826240 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 19:27:38.466262 139904974591808 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 19:27:38.466251 140345262556992 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 19:27:38.466713 140254103746368 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 19:27:38.467147 140298133927744 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 19:27:38.469033 140182611101504 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0627 19:27:39.624222 140154496866048 logging_writer.py:48] [1] global_step=1, grad_norm=22.064129, loss=32.911102
I0627 19:27:39.627907 140182611101504 submission.py:119] 1) loss = 32.911, grad_norm = 22.064
I0627 19:27:40.903565 140154505258752 logging_writer.py:48] [2] global_step=2, grad_norm=20.870171, loss=33.476036
I0627 19:27:40.907360 140182611101504 submission.py:119] 2) loss = 33.476, grad_norm = 20.870
I0627 19:27:41.921044 140154496866048 logging_writer.py:48] [3] global_step=3, grad_norm=21.377172, loss=33.532558
I0627 19:27:41.924563 140182611101504 submission.py:119] 3) loss = 33.533, grad_norm = 21.377
I0627 19:27:42.850858 140154505258752 logging_writer.py:48] [4] global_step=4, grad_norm=23.261211, loss=32.999725
I0627 19:27:42.854621 140182611101504 submission.py:119] 4) loss = 33.000, grad_norm = 23.261
I0627 19:27:43.790578 140154496866048 logging_writer.py:48] [5] global_step=5, grad_norm=24.550856, loss=33.311493
I0627 19:27:43.794051 140182611101504 submission.py:119] 5) loss = 33.311, grad_norm = 24.551
I0627 19:27:44.720093 140154505258752 logging_writer.py:48] [6] global_step=6, grad_norm=26.602476, loss=33.399025
I0627 19:27:44.724307 140182611101504 submission.py:119] 6) loss = 33.399, grad_norm = 26.602
I0627 19:27:45.651249 140154496866048 logging_writer.py:48] [7] global_step=7, grad_norm=30.323915, loss=32.316620
I0627 19:27:45.655158 140182611101504 submission.py:119] 7) loss = 32.317, grad_norm = 30.324
I0627 19:27:46.584905 140154505258752 logging_writer.py:48] [8] global_step=8, grad_norm=33.343002, loss=32.767181
I0627 19:27:46.588728 140182611101504 submission.py:119] 8) loss = 32.767, grad_norm = 33.343
I0627 19:27:47.511282 140154496866048 logging_writer.py:48] [9] global_step=9, grad_norm=31.590544, loss=32.428280
I0627 19:27:47.515053 140182611101504 submission.py:119] 9) loss = 32.428, grad_norm = 31.591
I0627 19:27:47.516915 140182611101504 spec.py:298] Evaluating on the training split.
I0627 19:28:05.100921 140182611101504 spec.py:310] Evaluating on the validation split.
I0627 19:28:17.493605 140182611101504 spec.py:326] Evaluating on the test split.
I0627 19:28:24.051420 140182611101504 submission_runner.py:424] Time since start: 119.55s, 	Step: 10, 	{'train/ctc_loss': 31.961239203854333, 'train/wer': 3.163817138393777, 'validation/ctc_loss': 30.792464084790033, 'validation/wer': 2.9284603871964467, 'validation/num_examples': 5348, 'test/ctc_loss': 30.95180979418027, 'test/wer': 3.051632035423395, 'test/num_examples': 2472, 'score': 39.77383899688721, 'total_duration': 119.55183601379395, 'accumulated_submission_time': 39.77383899688721, 'accumulated_eval_time': 79.74688744544983, 'accumulated_logging_time': 0.024220705032348633}
I0627 19:28:24.064301 140154505258752 logging_writer.py:48] [10] accumulated_eval_time=79.746887, accumulated_logging_time=0.024221, accumulated_submission_time=39.773839, global_step=10, preemption_count=0, score=39.773839, test/ctc_loss=30.951810, test/num_examples=2472, test/wer=3.051632, total_duration=119.551836, train/ctc_loss=31.961239, train/wer=3.163817, validation/ctc_loss=30.792464, validation/num_examples=5348, validation/wer=2.928460
I0627 19:28:24.082048 140154496866048 logging_writer.py:48] [10] global_step=10, preemption_count=0, score=39.773839
I0627 19:28:24.503848 140182611101504 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/test_today/adamw/librispeech_deepspeech_pytorch/trial_1/checkpoint_10.
I0627 19:28:24.626967 140182611101504 submission_runner.py:587] Tuning trial 1/1
I0627 19:28:24.627173 140182611101504 submission_runner.py:588] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0627 19:28:24.627565 140182611101504 submission_runner.py:589] Metrics: {'eval_results': [(1, {'train/ctc_loss': 31.97001882317765, 'train/wer': 3.159130604584558, 'validation/ctc_loss': 30.81801913803496, 'validation/wer': 2.9459566455848982, 'validation/num_examples': 5348, 'test/ctc_loss': 30.963694431898833, 'test/wer': 3.070318688684419, 'test/num_examples': 2472, 'score': 30.68262553215027, 'total_duration': 73.89682078361511, 'accumulated_submission_time': 30.68262553215027, 'accumulated_eval_time': 43.21271848678589, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (10, {'train/ctc_loss': 31.961239203854333, 'train/wer': 3.163817138393777, 'validation/ctc_loss': 30.792464084790033, 'validation/wer': 2.9284603871964467, 'validation/num_examples': 5348, 'test/ctc_loss': 30.95180979418027, 'test/wer': 3.051632035423395, 'test/num_examples': 2472, 'score': 39.77383899688721, 'total_duration': 119.55183601379395, 'accumulated_submission_time': 39.77383899688721, 'accumulated_eval_time': 79.74688744544983, 'accumulated_logging_time': 0.024220705032348633, 'global_step': 10, 'preemption_count': 0})], 'global_step': 10}
I0627 19:28:24.627654 140182611101504 submission_runner.py:590] Timing: 39.77383899688721
I0627 19:28:24.627728 140182611101504 submission_runner.py:591] ====================
I0627 19:28:24.627934 140182611101504 submission_runner.py:659] Final librispeech_deepspeech score: 39.77383899688721
