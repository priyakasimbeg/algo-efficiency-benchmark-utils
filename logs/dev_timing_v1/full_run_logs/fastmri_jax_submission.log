I0302 01:31:48.579208 139915712112448 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing/fastmri_jax.
I0302 01:31:48.657953 139915712112448 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0302 01:31:49.543977 139915712112448 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0302 01:31:49.544596 139915712112448 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0302 01:31:49.547587 139915712112448 submission_runner.py:481] Using RNG seed 2124103339
I0302 01:31:50.767681 139915712112448 submission_runner.py:490] --- Tuning run 1/1 ---
I0302 01:31:50.767866 139915712112448 submission_runner.py:495] Creating tuning directory at /experiment_runs/timing/fastmri_jax/trial_1.
I0302 01:31:50.768049 139915712112448 logger_utils.py:84] Saving hparams to /experiment_runs/timing/fastmri_jax/trial_1/hparams.json.
I0302 01:31:50.887196 139915712112448 submission_runner.py:226] Initializing dataset.
I0302 01:31:54.652904 139915712112448 submission_runner.py:233] Initializing model.
I0302 01:32:01.379393 139915712112448 submission_runner.py:243] Initializing optimizer.
I0302 01:32:01.796166 139915712112448 submission_runner.py:250] Initializing metrics bundle.
I0302 01:32:01.796351 139915712112448 submission_runner.py:265] Initializing checkpoint and logger.
I0302 01:32:01.797208 139915712112448 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing/fastmri_jax/trial_1 with prefix checkpoint_
I0302 01:32:02.487923 139915712112448 submission_runner.py:286] Saving meta data to /experiment_runs/timing/fastmri_jax/trial_1/meta_data_0.json.
I0302 01:32:02.488815 139915712112448 submission_runner.py:289] Saving flags to /experiment_runs/timing/fastmri_jax/trial_1/flags_0.json.
I0302 01:32:02.491211 139915712112448 submission_runner.py:299] Starting training loop.
I0302 01:32:44.005433 139739336271616 logging_writer.py:48] [0] global_step=0, grad_norm=4.724625587463379, loss=1.0947084426879883
I0302 01:32:44.011789 139915712112448 spec.py:298] Evaluating on the training split.
I0302 01:33:57.446532 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 01:34:53.517427 139915712112448 spec.py:326] Evaluating on the test split.
I0302 01:35:33.380645 139915712112448 submission_runner.py:359] Time since start: 41.52s, 	Step: 1, 	{'train/ssim': 0.18789427621023996, 'train/loss': 1.0984931673322404, 'validation/ssim': 0.1809655631199001, 'validation/loss': 1.1008112558033203, 'validation/num_examples': 3554, 'test/ssim': 0.20369739420618369, 'test/loss': 1.0969732562046217, 'test/num_examples': 3581}
I0302 01:35:33.389345 139711091816192 logging_writer.py:48] [1] global_step=1, preemption_count=0, score=41.398505, test/loss=1.096973, test/num_examples=3581, test/ssim=0.203697, total_duration=41.520550, train/loss=1.098493, train/ssim=0.187894, validation/loss=1.100811, validation/num_examples=3554, validation/ssim=0.180966
I0302 01:35:33.449509 139915712112448 checkpoints.py:356] Saving checkpoint at step: 1
I0302 01:35:33.657526 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_1
I0302 01:35:33.658077 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_1.
I0302 01:35:55.208473 139711083423488 logging_writer.py:48] [100] global_step=100, grad_norm=0.3215099573135376, loss=0.3659107983112335
I0302 01:36:19.525495 139710822201088 logging_writer.py:48] [200] global_step=200, grad_norm=0.2164546698331833, loss=0.46204620599746704
I0302 01:36:43.501445 139711083423488 logging_writer.py:48] [300] global_step=300, grad_norm=0.15548571944236755, loss=0.360183984041214
I0302 01:36:53.738649 139915712112448 spec.py:298] Evaluating on the training split.
I0302 01:37:03.202710 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 01:37:05.003441 139915712112448 spec.py:326] Evaluating on the test split.
I0302 01:37:06.463751 139915712112448 submission_runner.py:359] Time since start: 291.25s, 	Step: 344, 	{'train/ssim': 0.6813851084027972, 'train/loss': 0.333465508052281, 'validation/ssim': 0.6676634024822383, 'validation/loss': 0.34051345370093555, 'validation/num_examples': 3554, 'test/ssim': 0.6866580864065555, 'test/loss': 0.3416468181679349, 'test/num_examples': 3581}
I0302 01:37:06.473262 139710822201088 logging_writer.py:48] [344] global_step=344, preemption_count=0, score=121.070852, test/loss=0.341647, test/num_examples=3581, test/ssim=0.686658, total_duration=291.247388, train/loss=0.333466, train/ssim=0.681385, validation/loss=0.340513, validation/num_examples=3554, validation/ssim=0.667663
I0302 01:37:06.538227 139915712112448 checkpoints.py:356] Saving checkpoint at step: 344
I0302 01:37:06.727987 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_344
I0302 01:37:06.728467 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_344.
I0302 01:37:22.057370 139711083423488 logging_writer.py:48] [400] global_step=400, grad_norm=0.09263643622398376, loss=0.3032943606376648
I0302 01:37:48.485013 139700715120384 logging_writer.py:48] [500] global_step=500, grad_norm=0.09978706389665604, loss=0.2779179513454437
I0302 01:38:12.418231 139711083423488 logging_writer.py:48] [600] global_step=600, grad_norm=0.3154352605342865, loss=0.3129750192165375
I0302 01:38:26.740819 139915712112448 spec.py:298] Evaluating on the training split.
I0302 01:38:35.375138 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 01:38:37.262275 139915712112448 spec.py:326] Evaluating on the test split.
I0302 01:38:38.616363 139915712112448 submission_runner.py:359] Time since start: 384.25s, 	Step: 652, 	{'train/ssim': 0.6940059661865234, 'train/loss': 0.318281888961792, 'validation/ssim': 0.6903933480541291, 'validation/loss': 0.3168203067296532, 'validation/num_examples': 3554, 'test/ssim': 0.7082901320554663, 'test/loss': 0.31852964621221375, 'test/num_examples': 3581}
I0302 01:38:38.626224 139700715120384 logging_writer.py:48] [652] global_step=652, preemption_count=0, score=200.652184, test/loss=0.318530, test/num_examples=3581, test/ssim=0.708290, total_duration=384.249550, train/loss=0.318282, train/ssim=0.694006, validation/loss=0.316820, validation/num_examples=3554, validation/ssim=0.690393
I0302 01:38:38.684924 139915712112448 checkpoints.py:356] Saving checkpoint at step: 652
I0302 01:38:38.854497 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_652
I0302 01:38:38.854956 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_652.
I0302 01:38:50.500773 139711083423488 logging_writer.py:48] [700] global_step=700, grad_norm=0.27566027641296387, loss=0.3167898952960968
I0302 01:39:38.992830 139674909853440 logging_writer.py:48] [800] global_step=800, grad_norm=0.12768210470676422, loss=0.26872313022613525
I0302 01:39:58.975688 139915712112448 spec.py:298] Evaluating on the training split.
I0302 01:40:07.640925 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 01:40:09.298471 139915712112448 spec.py:326] Evaluating on the test split.
I0302 01:40:10.942797 139915712112448 submission_runner.py:359] Time since start: 476.48s, 	Step: 846, 	{'train/ssim': 0.7104338918413434, 'train/loss': 0.30027481487819124, 'validation/ssim': 0.6968724170828644, 'validation/loss': 0.30940688803548816, 'validation/num_examples': 3554, 'test/ssim': 0.7146659452666853, 'test/loss': 0.3110776984868054, 'test/num_examples': 3581}
I0302 01:40:10.952278 139711083423488 logging_writer.py:48] [846] global_step=846, preemption_count=0, score=280.513033, test/loss=0.311078, test/num_examples=3581, test/ssim=0.714666, total_duration=476.484423, train/loss=0.300275, train/ssim=0.710434, validation/loss=0.309407, validation/num_examples=3554, validation/ssim=0.696872
I0302 01:40:11.010005 139915712112448 checkpoints.py:356] Saving checkpoint at step: 846
I0302 01:40:11.218264 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_846
I0302 01:40:11.221903 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_846.
I0302 01:40:26.530640 139674909853440 logging_writer.py:48] [900] global_step=900, grad_norm=0.13918861746788025, loss=0.3285793662071228
I0302 01:41:11.689117 139641994864384 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.4126991331577301, loss=0.3837794363498688
I0302 01:41:31.389509 139915712112448 spec.py:298] Evaluating on the training split.
I0302 01:41:40.163067 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 01:41:41.841557 139915712112448 spec.py:326] Evaluating on the test split.
I0302 01:41:43.191473 139915712112448 submission_runner.py:359] Time since start: 568.90s, 	Step: 1084, 	{'train/ssim': 0.7154936790466309, 'train/loss': 0.2975177764892578, 'validation/ssim': 0.7006745947567882, 'validation/loss': 0.30375400901712857, 'validation/num_examples': 3554, 'test/ssim': 0.7179700589919017, 'test/loss': 0.30548782582990086, 'test/num_examples': 3581}
I0302 01:41:43.204324 139674909853440 logging_writer.py:48] [1084] global_step=1084, preemption_count=0, score=360.376569, test/loss=0.305488, test/num_examples=3581, test/ssim=0.717970, total_duration=568.898223, train/loss=0.297518, train/ssim=0.715494, validation/loss=0.303754, validation/num_examples=3554, validation/ssim=0.700675
I0302 01:41:43.264855 139915712112448 checkpoints.py:356] Saving checkpoint at step: 1084
I0302 01:41:43.446221 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_1084
I0302 01:41:43.446655 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_1084.
I0302 01:41:45.699260 139641994864384 logging_writer.py:48] [1100] global_step=1100, grad_norm=1.373895525932312, loss=0.2555817663669586
I0302 01:42:14.496945 139614664771328 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.325560986995697, loss=0.21919694542884827
I0302 01:42:38.274365 139641994864384 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.15293319523334503, loss=0.34291931986808777
I0302 01:43:01.907871 139614664771328 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.55659419298172, loss=0.2914845943450928
I0302 01:43:03.555489 139915712112448 spec.py:298] Evaluating on the training split.
I0302 01:43:12.354833 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 01:43:14.133416 139915712112448 spec.py:326] Evaluating on the test split.
I0302 01:43:15.987237 139915712112448 submission_runner.py:359] Time since start: 661.06s, 	Step: 1408, 	{'train/ssim': 0.7248620305742536, 'train/loss': 0.29473400115966797, 'validation/ssim': 0.7081991269740081, 'validation/loss': 0.30017725268843204, 'validation/num_examples': 3554, 'test/ssim': 0.7252759382199455, 'test/loss': 0.30199162436077565, 'test/num_examples': 3581}
I0302 01:43:16.000798 139641994864384 logging_writer.py:48] [1408] global_step=1408, preemption_count=0, score=440.156047, test/loss=0.301992, test/num_examples=3581, test/ssim=0.725276, total_duration=661.064222, train/loss=0.294734, train/ssim=0.724862, validation/loss=0.300177, validation/num_examples=3554, validation/ssim=0.708199
I0302 01:43:16.064487 139915712112448 checkpoints.py:356] Saving checkpoint at step: 1408
I0302 01:43:16.241157 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_1408
I0302 01:43:16.241597 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_1408.
I0302 01:43:41.596984 139614664771328 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.20560096204280853, loss=0.3059006929397583
I0302 01:44:05.461894 139606049658624 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.48704543709754944, loss=0.22230157256126404
I0302 01:44:29.229185 139614664771328 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.11914732307195663, loss=0.4454297423362732
I0302 01:44:36.351650 139915712112448 spec.py:298] Evaluating on the training split.
I0302 01:44:45.250408 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 01:44:46.995907 139915712112448 spec.py:326] Evaluating on the test split.
I0302 01:44:48.351674 139915712112448 submission_runner.py:359] Time since start: 753.86s, 	Step: 1732, 	{'train/ssim': 0.7268259865897042, 'train/loss': 0.27910947799682617, 'validation/ssim': 0.7102113293340251, 'validation/loss': 0.29668100643640966, 'validation/num_examples': 3554, 'test/ssim': 0.7273779610487643, 'test/loss': 0.2983653759097494, 'test/num_examples': 3581}
I0302 01:44:48.361450 139606049658624 logging_writer.py:48] [1732] global_step=1732, preemption_count=0, score=519.932938, test/loss=0.298365, test/num_examples=3581, test/ssim=0.727378, total_duration=753.860393, train/loss=0.279109, train/ssim=0.726826, validation/loss=0.296681, validation/num_examples=3554, validation/ssim=0.710211
I0302 01:44:48.434389 139915712112448 checkpoints.py:356] Saving checkpoint at step: 1732
I0302 01:44:48.697289 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_1732
I0302 01:44:48.697846 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_1732.
I0302 01:45:07.863809 139614664771328 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.6713811755180359, loss=0.22356674075126648
I0302 01:45:32.739759 139597635905280 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.12706220149993896, loss=0.2740820050239563
I0302 01:45:56.872559 139614664771328 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.11952491104602814, loss=0.25548890233039856
I0302 01:46:08.824337 139915712112448 spec.py:298] Evaluating on the training split.
I0302 01:46:17.457326 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 01:46:19.311546 139915712112448 spec.py:326] Evaluating on the test split.
I0302 01:46:21.145608 139915712112448 submission_runner.py:359] Time since start: 846.33s, 	Step: 2050, 	{'train/ssim': 0.7077398300170898, 'train/loss': 0.2864923817770822, 'validation/ssim': 0.6934004543735931, 'validation/loss': 0.30792775580771664, 'validation/num_examples': 3554, 'test/ssim': 0.7095427418580704, 'test/loss': 0.3093622373289584, 'test/num_examples': 3581}
I0302 01:46:21.177755 139597635905280 logging_writer.py:48] [2050] global_step=2050, preemption_count=0, score=599.718240, test/loss=0.309362, test/num_examples=3581, test/ssim=0.709543, total_duration=846.333077, train/loss=0.286492, train/ssim=0.707740, validation/loss=0.307928, validation/num_examples=3554, validation/ssim=0.693400
I0302 01:46:21.215051 139915712112448 checkpoints.py:356] Saving checkpoint at step: 2050
I0302 01:46:21.395726 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_2050
I0302 01:46:21.396191 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_2050.
I0302 01:46:34.400596 139614664771328 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.10326901078224182, loss=0.27623921632766724
I0302 01:46:58.926655 139591940044544 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.7686420679092407, loss=0.25416022539138794
I0302 01:47:22.855117 139614664771328 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.1910349726676941, loss=0.2538009285926819
I0302 01:47:41.492834 139915712112448 spec.py:298] Evaluating on the training split.
I0302 01:47:42.907717 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 01:47:44.809783 139915712112448 spec.py:326] Evaluating on the test split.
I0302 01:47:46.159194 139915712112448 submission_runner.py:359] Time since start: 939.00s, 	Step: 2380, 	{'train/ssim': 0.73947845186506, 'train/loss': 0.2753781591142927, 'validation/ssim': 0.7155793318268149, 'validation/loss': 0.29323116338984245, 'validation/num_examples': 3554, 'test/ssim': 0.7324267837196314, 'test/loss': 0.29507735187665807, 'test/num_examples': 3581}
I0302 01:47:46.166781 139591940044544 logging_writer.py:48] [2380] global_step=2380, preemption_count=0, score=679.497545, test/loss=0.295077, test/num_examples=3581, test/ssim=0.732427, total_duration=939.001545, train/loss=0.275378, train/ssim=0.739478, validation/loss=0.293231, validation/num_examples=3554, validation/ssim=0.715579
I0302 01:47:46.194428 139915712112448 checkpoints.py:356] Saving checkpoint at step: 2380
I0302 01:47:46.388645 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_2380
I0302 01:47:46.389128 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_2380.
I0302 01:47:49.041981 139614664771328 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.38953229784965515, loss=0.1951175183057785
I0302 01:48:12.982970 139591310886656 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.5364287495613098, loss=0.25537610054016113
I0302 01:48:36.694509 139614664771328 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.09764023125171661, loss=0.28475263714790344
I0302 01:49:00.696965 139591310886656 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.2509832978248596, loss=0.2759125828742981
I0302 01:49:06.538396 139915712112448 spec.py:298] Evaluating on the training split.
I0302 01:49:08.006216 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 01:49:09.361223 139915712112448 spec.py:326] Evaluating on the test split.
I0302 01:49:10.715062 139915712112448 submission_runner.py:359] Time since start: 1024.05s, 	Step: 2726, 	{'train/ssim': 0.722844123840332, 'train/loss': 0.2736499309539795, 'validation/ssim': 0.7170002110298256, 'validation/loss': 0.29189144686225027, 'validation/num_examples': 3554, 'test/ssim': 0.7340125046905543, 'test/loss': 0.29353669567901775, 'test/num_examples': 3581}
I0302 01:49:10.723313 139614664771328 logging_writer.py:48] [2726] global_step=2726, preemption_count=0, score=759.302621, test/loss=0.293537, test/num_examples=3581, test/ssim=0.734013, total_duration=1024.047142, train/loss=0.273650, train/ssim=0.722844, validation/loss=0.291891, validation/num_examples=3554, validation/ssim=0.717000
I0302 01:49:10.750142 139915712112448 checkpoints.py:356] Saving checkpoint at step: 2726
I0302 01:49:10.891478 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_2726
I0302 01:49:10.891899 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_2726.
I0302 01:49:26.323829 139591310886656 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.22833065688610077, loss=0.27142810821533203
I0302 01:49:50.230630 139591101167360 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.2605641186237335, loss=0.23395618796348572
I0302 01:50:13.990335 139591310886656 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.17624641954898834, loss=0.3049587607383728
I0302 01:50:31.029793 139915712112448 spec.py:298] Evaluating on the training split.
I0302 01:50:32.442079 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 01:50:33.795944 139915712112448 spec.py:326] Evaluating on the test split.
I0302 01:50:35.156141 139915712112448 submission_runner.py:359] Time since start: 1108.54s, 	Step: 3072, 	{'train/ssim': 0.7383990968976702, 'train/loss': 0.27230184418814524, 'validation/ssim': 0.7176478637626618, 'validation/loss': 0.2917685522144942, 'validation/num_examples': 3554, 'test/ssim': 0.7349857947108001, 'test/loss': 0.29323317318181025, 'test/num_examples': 3581}
I0302 01:50:35.164194 139591101167360 logging_writer.py:48] [3072] global_step=3072, preemption_count=0, score=839.099493, test/loss=0.293233, test/num_examples=3581, test/ssim=0.734986, total_duration=1108.538522, train/loss=0.272302, train/ssim=0.738399, validation/loss=0.291769, validation/num_examples=3554, validation/ssim=0.717648
I0302 01:50:35.193136 139915712112448 checkpoints.py:356] Saving checkpoint at step: 3072
I0302 01:50:35.334712 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_3072
I0302 01:50:35.335130 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_3072.
I0302 01:50:39.919969 139591310886656 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.4992941915988922, loss=0.2058439552783966
I0302 01:51:04.104490 139591092774656 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.3617804944515228, loss=0.24624988436698914
I0302 01:51:28.347897 139591310886656 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.2916021943092346, loss=0.2834004759788513
I0302 01:51:52.152901 139591092774656 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.1939607858657837, loss=0.2575395703315735
I0302 01:51:55.363476 139915712112448 spec.py:298] Evaluating on the training split.
I0302 01:51:56.777744 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 01:51:58.136515 139915712112448 spec.py:326] Evaluating on the test split.
I0302 01:51:59.500574 139915712112448 submission_runner.py:359] Time since start: 1192.87s, 	Step: 3415, 	{'train/ssim': 0.7267757143293109, 'train/loss': 0.28714026723589214, 'validation/ssim': 0.7185622576454347, 'validation/loss': 0.29108802911332304, 'validation/num_examples': 3554, 'test/ssim': 0.7357952562133482, 'test/loss': 0.29249246784243227, 'test/num_examples': 3581}
I0302 01:51:59.508256 139591310886656 logging_writer.py:48] [3415] global_step=3415, preemption_count=0, score=918.792775, test/loss=0.292492, test/num_examples=3581, test/ssim=0.735795, total_duration=1192.872223, train/loss=0.287140, train/ssim=0.726776, validation/loss=0.291088, validation/num_examples=3554, validation/ssim=0.718562
I0302 01:51:59.535112 139915712112448 checkpoints.py:356] Saving checkpoint at step: 3415
I0302 01:51:59.678066 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_3415
I0302 01:51:59.678525 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_3415.
I0302 01:52:17.652504 139591092774656 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.16036877036094666, loss=0.2523375451564789
I0302 01:52:41.197893 139591084381952 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.2824276089668274, loss=0.2728307247161865
I0302 01:53:05.011518 139591092774656 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.5045804381370544, loss=0.29703664779663086
I0302 01:53:19.856931 139915712112448 spec.py:298] Evaluating on the training split.
I0302 01:53:21.268777 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 01:53:23.002044 139915712112448 spec.py:326] Evaluating on the test split.
I0302 01:53:24.354591 139915712112448 submission_runner.py:359] Time since start: 1277.37s, 	Step: 3764, 	{'train/ssim': 0.7187568119594029, 'train/loss': 0.2959432601928711, 'validation/ssim': 0.7168086217773987, 'validation/loss': 0.2923096252681837, 'validation/num_examples': 3554, 'test/ssim': 0.733796998263404, 'test/loss': 0.2939709128364109, 'test/num_examples': 3581}
I0302 01:53:24.363446 139591084381952 logging_writer.py:48] [3764] global_step=3764, preemption_count=0, score=998.642434, test/loss=0.293971, test/num_examples=3581, test/ssim=0.733797, total_duration=1277.365666, train/loss=0.295943, train/ssim=0.718757, validation/loss=0.292310, validation/num_examples=3554, validation/ssim=0.716809
I0302 01:53:24.389832 139915712112448 checkpoints.py:356] Saving checkpoint at step: 3764
I0302 01:53:24.530221 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_3764
I0302 01:53:24.530643 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_3764.
I0302 01:53:31.044855 139591092774656 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.4156077802181244, loss=0.3433320224285126
I0302 01:53:55.070369 139591000520448 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.22970086336135864, loss=0.26111945509910583
I0302 01:54:18.955002 139591092774656 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.39560431241989136, loss=0.2871769070625305
I0302 01:54:42.623726 139591000520448 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.14553405344486237, loss=0.21766458451747894
I0302 01:54:44.769111 139915712112448 spec.py:298] Evaluating on the training split.
I0302 01:54:46.181061 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 01:54:47.535177 139915712112448 spec.py:326] Evaluating on the test split.
I0302 01:54:48.892869 139915712112448 submission_runner.py:359] Time since start: 1362.28s, 	Step: 4110, 	{'train/ssim': 0.7413531712123326, 'train/loss': 0.27809098788670134, 'validation/ssim': 0.7228128050040448, 'validation/loss': 0.28994282135885624, 'validation/num_examples': 3554, 'test/ssim': 0.7397060740496719, 'test/loss': 0.2915075877897235, 'test/num_examples': 3581}
I0302 01:54:48.901048 139591092774656 logging_writer.py:48] [4110] global_step=4110, preemption_count=0, score=1078.546887, test/loss=0.291508, test/num_examples=3581, test/ssim=0.739706, total_duration=1362.277855, train/loss=0.278091, train/ssim=0.741353, validation/loss=0.289943, validation/num_examples=3554, validation/ssim=0.722813
I0302 01:54:48.927785 139915712112448 checkpoints.py:356] Saving checkpoint at step: 4110
I0302 01:54:49.070807 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_4110
I0302 01:54:49.071213 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_4110.
I0302 01:55:09.039965 139591000520448 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.20340366661548615, loss=0.28424352407455444
I0302 01:55:32.905605 139590992127744 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.39560040831565857, loss=0.3216075897216797
I0302 01:55:56.942454 139591000520448 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.36129117012023926, loss=0.2821531891822815
I0302 01:56:09.326809 139915712112448 spec.py:298] Evaluating on the training split.
I0302 01:56:10.738546 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 01:56:12.088427 139915712112448 spec.py:326] Evaluating on the test split.
I0302 01:56:13.441288 139915712112448 submission_runner.py:359] Time since start: 1446.84s, 	Step: 4453, 	{'train/ssim': 0.7343431200299945, 'train/loss': 0.2878243923187256, 'validation/ssim': 0.7203180917408202, 'validation/loss': 0.29026946420406585, 'validation/num_examples': 3554, 'test/ssim': 0.7375517597214465, 'test/loss': 0.29177470394966487, 'test/num_examples': 3581}
I0302 01:56:13.449209 139590992127744 logging_writer.py:48] [4453] global_step=4453, preemption_count=0, score=1158.477039, test/loss=0.291775, test/num_examples=3581, test/ssim=0.737552, total_duration=1446.835505, train/loss=0.287824, train/ssim=0.734343, validation/loss=0.290269, validation/num_examples=3554, validation/ssim=0.720318
I0302 01:56:13.476348 139915712112448 checkpoints.py:356] Saving checkpoint at step: 4453
I0302 01:56:13.617990 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_4453
I0302 01:56:13.618390 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_4453.
I0302 01:56:22.680522 139591000520448 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.32325348258018494, loss=0.3677142262458801
I0302 01:56:46.486393 139590983735040 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.36803168058395386, loss=0.3075658082962036
I0302 01:57:10.283456 139591000520448 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.5550346374511719, loss=0.26278355717658997
I0302 01:57:33.675341 139915712112448 spec.py:298] Evaluating on the training split.
I0302 01:57:35.087906 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 01:57:36.445996 139915712112448 spec.py:326] Evaluating on the test split.
I0302 01:57:37.808346 139915712112448 submission_runner.py:359] Time since start: 1531.18s, 	Step: 4799, 	{'train/ssim': 0.7320254870823452, 'train/loss': 0.2829779386520386, 'validation/ssim': 0.7135823109744303, 'validation/loss': 0.29312901451269696, 'validation/num_examples': 3554, 'test/ssim': 0.7308024747582729, 'test/loss': 0.29439694879441847, 'test/num_examples': 3581}
I0302 01:57:37.816220 139590983735040 logging_writer.py:48] [4799] global_step=4799, preemption_count=0, score=1238.205311, test/loss=0.294397, test/num_examples=3581, test/ssim=0.730802, total_duration=1531.184083, train/loss=0.282978, train/ssim=0.732025, validation/loss=0.293129, validation/num_examples=3554, validation/ssim=0.713582
I0302 01:57:37.844082 139915712112448 checkpoints.py:356] Saving checkpoint at step: 4799
I0302 01:57:37.983860 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_4799
I0302 01:57:37.984251 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_4799.
I0302 01:57:38.139069 139591000520448 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.5634397268295288, loss=0.23521775007247925
I0302 01:58:00.139092 139590975342336 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.17580652236938477, loss=0.2665526866912842
I0302 01:58:23.713772 139591000520448 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.2580590546131134, loss=0.3262448310852051
I0302 01:58:47.587335 139590975342336 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.2222900092601776, loss=0.2780954837799072
I0302 01:58:58.141865 139915712112448 spec.py:298] Evaluating on the training split.
I0302 01:58:59.554867 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 01:59:00.913204 139915712112448 spec.py:326] Evaluating on the test split.
I0302 01:59:02.270382 139915712112448 submission_runner.py:359] Time since start: 1615.65s, 	Step: 5146, 	{'train/ssim': 0.7356536047799247, 'train/loss': 0.2693652936390468, 'validation/ssim': 0.7205893667346651, 'validation/loss': 0.2893341184668683, 'validation/num_examples': 3554, 'test/ssim': 0.7378603272916084, 'test/loss': 0.29079292593505657, 'test/num_examples': 3581}
I0302 01:59:02.278428 139591000520448 logging_writer.py:48] [5146] global_step=5146, preemption_count=0, score=1318.029844, test/loss=0.290793, test/num_examples=3581, test/ssim=0.737860, total_duration=1615.650607, train/loss=0.269365, train/ssim=0.735654, validation/loss=0.289334, validation/num_examples=3554, validation/ssim=0.720589
I0302 01:59:02.305153 139915712112448 checkpoints.py:356] Saving checkpoint at step: 5146
I0302 01:59:02.446023 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_5146
I0302 01:59:02.446437 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_5146.
I0302 01:59:13.181296 139590975342336 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.16449642181396484, loss=0.241897314786911
I0302 01:59:37.571201 139590966949632 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.6476762890815735, loss=0.2578348219394684
I0302 02:00:01.423139 139590975342336 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.49121567606925964, loss=0.2830863296985626
I0302 02:00:22.462883 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:00:23.878354 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:00:25.240436 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:00:26.605811 139915712112448 submission_runner.py:359] Time since start: 1699.97s, 	Step: 5489, 	{'train/ssim': 0.7465353693280902, 'train/loss': 0.26449292046683176, 'validation/ssim': 0.7221417961056205, 'validation/loss': 0.29033747186268993, 'validation/num_examples': 3554, 'test/ssim': 0.7390551232852206, 'test/loss': 0.2918963992905264, 'test/num_examples': 3581}
I0302 02:00:26.619409 139590966949632 logging_writer.py:48] [5489] global_step=5489, preemption_count=0, score=1397.721910, test/loss=0.291896, test/num_examples=3581, test/ssim=0.739055, total_duration=1699.971626, train/loss=0.264493, train/ssim=0.746535, validation/loss=0.290337, validation/num_examples=3554, validation/ssim=0.722142
I0302 02:00:26.647468 139915712112448 checkpoints.py:356] Saving checkpoint at step: 5489
I0302 02:00:26.793169 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_5489
I0302 02:00:26.793577 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_5489.
I0302 02:00:27.670815 139590975342336 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.5459809899330139, loss=0.2367086559534073
I0302 02:00:51.045657 139590958556928 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.2041839361190796, loss=0.2207004427909851
I0302 02:01:14.616144 139590975342336 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.2597733438014984, loss=0.2685948312282562
I0302 02:01:38.579492 139590958556928 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.3972972631454468, loss=0.3924156427383423
I0302 02:01:46.920369 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:01:48.331064 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:01:49.690996 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:01:51.050471 139915712112448 submission_runner.py:359] Time since start: 1784.43s, 	Step: 5836, 	{'train/ssim': 0.7426540510995048, 'train/loss': 0.277286171913147, 'validation/ssim': 0.7203687883590673, 'validation/loss': 0.28958935327052265, 'validation/num_examples': 3554, 'test/ssim': 0.7375546231412315, 'test/loss': 0.2911408996155927, 'test/num_examples': 3581}
I0302 02:01:51.059022 139590975342336 logging_writer.py:48] [5836] global_step=5836, preemption_count=0, score=1477.524584, test/loss=0.291141, test/num_examples=3581, test/ssim=0.737555, total_duration=1784.429078, train/loss=0.277286, train/ssim=0.742654, validation/loss=0.289589, validation/num_examples=3554, validation/ssim=0.720369
I0302 02:01:51.085679 139915712112448 checkpoints.py:356] Saving checkpoint at step: 5836
I0302 02:01:51.232434 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_5836
I0302 02:01:51.232915 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_5836.
I0302 02:02:04.369140 139590958556928 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.1337648630142212, loss=0.23720350861549377
I0302 02:02:28.448935 139590950164224 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.5553335547447205, loss=0.2026686668395996
I0302 02:02:52.286641 139590958556928 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.3817090094089508, loss=0.2786844074726105
I0302 02:03:11.327723 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:03:12.742156 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:03:14.097569 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:03:15.457028 139915712112448 submission_runner.py:359] Time since start: 1868.84s, 	Step: 6181, 	{'train/ssim': 0.7307814870561872, 'train/loss': 0.26315663542066303, 'validation/ssim': 0.7216040547402575, 'validation/loss': 0.2896250057703468, 'validation/num_examples': 3554, 'test/ssim': 0.7389070435763404, 'test/loss': 0.2910990732337336, 'test/num_examples': 3581}
I0302 02:03:15.465253 139590950164224 logging_writer.py:48] [6181] global_step=6181, preemption_count=0, score=1557.285712, test/loss=0.291099, test/num_examples=3581, test/ssim=0.738907, total_duration=1868.836441, train/loss=0.263157, train/ssim=0.730781, validation/loss=0.289625, validation/num_examples=3554, validation/ssim=0.721604
I0302 02:03:15.492049 139915712112448 checkpoints.py:356] Saving checkpoint at step: 6181
I0302 02:03:15.639453 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_6181
I0302 02:03:15.639912 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_6181.
I0302 02:03:18.071337 139590958556928 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.24775762856006622, loss=0.2242877036333084
I0302 02:03:42.353002 139590866302720 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.5868246555328369, loss=0.23757246136665344
I0302 02:04:06.773856 139590958556928 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.5996333956718445, loss=0.2874597907066345
I0302 02:04:30.710739 139590866302720 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.4385313093662262, loss=0.3978807032108307
I0302 02:04:35.780558 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:04:37.197389 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:04:38.554692 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:04:39.917852 139915712112448 submission_runner.py:359] Time since start: 1953.29s, 	Step: 6523, 	{'train/ssim': 0.7344935962132045, 'train/loss': 0.2830423968178885, 'validation/ssim': 0.7190740324502322, 'validation/loss': 0.29117489344092923, 'validation/num_examples': 3554, 'test/ssim': 0.7362060887758308, 'test/loss': 0.2926381272798276, 'test/num_examples': 3581}
I0302 02:04:39.925749 139590958556928 logging_writer.py:48] [6523] global_step=6523, preemption_count=0, score=1637.100861, test/loss=0.292638, test/num_examples=3581, test/ssim=0.736206, total_duration=1953.289291, train/loss=0.283042, train/ssim=0.734494, validation/loss=0.291175, validation/num_examples=3554, validation/ssim=0.719074
I0302 02:04:39.952533 139915712112448 checkpoints.py:356] Saving checkpoint at step: 6523
I0302 02:04:40.097430 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_6523
I0302 02:04:40.097921 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_6523.
I0302 02:04:56.301883 139590866302720 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.41873595118522644, loss=0.22461053729057312
I0302 02:05:20.221322 139590857910016 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.3951692283153534, loss=0.19673378765583038
I0302 02:05:44.006477 139590866302720 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.1987667977809906, loss=0.2672906219959259
I0302 02:06:00.269456 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:06:01.680140 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:06:03.034996 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:06:04.391365 139915712112448 submission_runner.py:359] Time since start: 2037.78s, 	Step: 6869, 	{'train/ssim': 0.7282147407531738, 'train/loss': 0.2853403772626604, 'validation/ssim': 0.72100359520083, 'validation/loss': 0.28985159492385343, 'validation/num_examples': 3554, 'test/ssim': 0.7380816287349903, 'test/loss': 0.2914263552974902, 'test/num_examples': 3581}
I0302 02:06:04.399801 139590857910016 logging_writer.py:48] [6869] global_step=6869, preemption_count=0, score=1716.951137, test/loss=0.291426, test/num_examples=3581, test/ssim=0.738082, total_duration=2037.778188, train/loss=0.285340, train/ssim=0.728215, validation/loss=0.289852, validation/num_examples=3554, validation/ssim=0.721004
I0302 02:06:04.426530 139915712112448 checkpoints.py:356] Saving checkpoint at step: 6869
I0302 02:06:04.572087 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_6869
I0302 02:06:04.572517 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_6869.
I0302 02:06:09.984387 139590866302720 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.2786024212837219, loss=0.33631032705307007
I0302 02:06:33.477299 139590849517312 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.36551329493522644, loss=0.20171986520290375
I0302 02:06:57.485571 139590866302720 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.5670369863510132, loss=0.2757417857646942
I0302 02:07:21.229368 139590849517312 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.31045252084732056, loss=0.29636627435684204
I0302 02:07:24.754195 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:07:26.165935 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:07:27.518671 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:07:28.871286 139915712112448 submission_runner.py:359] Time since start: 2122.26s, 	Step: 7216, 	{'train/ssim': 0.7226830891200474, 'train/loss': 0.29210332461765837, 'validation/ssim': 0.7157615099184018, 'validation/loss': 0.29178682497933667, 'validation/num_examples': 3554, 'test/ssim': 0.7330833249703295, 'test/loss': 0.29313479425919786, 'test/num_examples': 3581}
I0302 02:07:28.879792 139590866302720 logging_writer.py:48] [7216] global_step=7216, preemption_count=0, score=1796.804602, test/loss=0.293135, test/num_examples=3581, test/ssim=0.733083, total_duration=2122.262931, train/loss=0.292103, train/ssim=0.722683, validation/loss=0.291787, validation/num_examples=3554, validation/ssim=0.715762
I0302 02:07:28.906459 139915712112448 checkpoints.py:356] Saving checkpoint at step: 7216
I0302 02:07:29.051929 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_7216
I0302 02:07:29.052341 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_7216.
I0302 02:07:46.709398 139590849517312 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.2060251384973526, loss=0.23957908153533936
I0302 02:08:10.814285 139590841124608 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.33169806003570557, loss=0.21272169053554535
I0302 02:08:35.148961 139590849517312 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.24270528554916382, loss=0.2189500778913498
I0302 02:08:49.085735 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:08:50.499017 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:08:51.855413 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:08:53.210222 139915712112448 submission_runner.py:359] Time since start: 2206.59s, 	Step: 7560, 	{'train/ssim': 0.7384037290300641, 'train/loss': 0.27625836644853863, 'validation/ssim': 0.7206056473559721, 'validation/loss': 0.2884274183798185, 'validation/num_examples': 3554, 'test/ssim': 0.737837215403344, 'test/loss': 0.2899240825603009, 'test/num_examples': 3581}
I0302 02:08:53.218492 139590841124608 logging_writer.py:48] [7560] global_step=7560, preemption_count=0, score=1876.515980, test/loss=0.289924, test/num_examples=3581, test/ssim=0.737837, total_duration=2206.594470, train/loss=0.276258, train/ssim=0.738404, validation/loss=0.288427, validation/num_examples=3554, validation/ssim=0.720606
I0302 02:08:53.244681 139915712112448 checkpoints.py:356] Saving checkpoint at step: 7560
I0302 02:08:53.388752 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_7560
I0302 02:08:53.389178 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_7560.
I0302 02:09:01.056303 139590849517312 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.39299312233924866, loss=0.2994236350059509
I0302 02:09:24.726921 139590832731904 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.3831915259361267, loss=0.21297450363636017
I0302 02:09:48.307161 139590849517312 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.1358724683523178, loss=0.27336543798446655
I0302 02:10:12.020749 139590832731904 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.33287331461906433, loss=0.23008427023887634
I0302 02:10:13.484352 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:10:14.895591 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:10:16.253420 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:10:17.608110 139915712112448 submission_runner.py:359] Time since start: 2290.99s, 	Step: 7907, 	{'train/ssim': 0.7362739018031529, 'train/loss': 0.28678481919424875, 'validation/ssim': 0.7226230018113393, 'validation/loss': 0.28954133574185775, 'validation/num_examples': 3554, 'test/ssim': 0.7395748339761938, 'test/loss': 0.29100471673415246, 'test/num_examples': 3581}
I0302 02:10:17.616648 139590849517312 logging_writer.py:48] [7907] global_step=7907, preemption_count=0, score=1956.284961, test/loss=0.291005, test/num_examples=3581, test/ssim=0.739575, total_duration=2290.993094, train/loss=0.286785, train/ssim=0.736274, validation/loss=0.289541, validation/num_examples=3554, validation/ssim=0.722623
I0302 02:10:17.643236 139915712112448 checkpoints.py:356] Saving checkpoint at step: 7907
I0302 02:10:17.786157 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_7907
I0302 02:10:17.786562 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_7907.
I0302 02:10:37.872937 139590832731904 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.7973429560661316, loss=0.3020220994949341
I0302 02:11:01.692331 139590824339200 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.4923035502433777, loss=0.21974575519561768
I0302 02:11:25.533157 139590832731904 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.14747311174869537, loss=0.3045786917209625
I0302 02:11:37.806303 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:11:39.213338 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:11:40.569536 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:11:41.926935 139915712112448 submission_runner.py:359] Time since start: 2375.32s, 	Step: 8253, 	{'train/ssim': 0.74249267578125, 'train/loss': 0.2762948104313442, 'validation/ssim': 0.724341466041784, 'validation/loss': 0.28792258173009283, 'validation/num_examples': 3554, 'test/ssim': 0.7415389354187029, 'test/loss': 0.289338547302604, 'test/num_examples': 3581}
I0302 02:11:41.935249 139590824339200 logging_writer.py:48] [8253] global_step=8253, preemption_count=0, score=2035.981540, test/loss=0.289339, test/num_examples=3581, test/ssim=0.741539, total_duration=2375.315050, train/loss=0.276295, train/ssim=0.742493, validation/loss=0.287923, validation/num_examples=3554, validation/ssim=0.724341
I0302 02:11:41.962007 139915712112448 checkpoints.py:356] Saving checkpoint at step: 8253
I0302 02:11:42.107622 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_8253
I0302 02:11:42.108061 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_8253.
I0302 02:11:51.337758 139590832731904 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.4045499265193939, loss=0.21836669743061066
I0302 02:12:15.125921 139590815946496 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.32261890172958374, loss=0.24459311366081238
I0302 02:12:39.207286 139590832731904 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.1956126093864441, loss=0.3188740015029907
I0302 02:13:02.266489 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:13:03.677122 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:13:05.035085 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:13:06.392763 139915712112448 submission_runner.py:359] Time since start: 2459.78s, 	Step: 8597, 	{'train/ssim': 0.7405343736921038, 'train/loss': 0.26618312086377827, 'validation/ssim': 0.7215460077993107, 'validation/loss': 0.28914562047165165, 'validation/num_examples': 3554, 'test/ssim': 0.7386440180160919, 'test/loss': 0.2905587731909732, 'test/num_examples': 3581}
I0302 02:13:06.401319 139590815946496 logging_writer.py:48] [8597] global_step=8597, preemption_count=0, score=2115.819061, test/loss=0.290559, test/num_examples=3581, test/ssim=0.738644, total_duration=2459.775220, train/loss=0.266183, train/ssim=0.740534, validation/loss=0.289146, validation/num_examples=3554, validation/ssim=0.721546
I0302 02:13:06.429088 139915712112448 checkpoints.py:356] Saving checkpoint at step: 8597
I0302 02:13:06.575528 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_8597
I0302 02:13:06.575962 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_8597.
I0302 02:13:06.874760 139590832731904 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.5891355872154236, loss=0.19102708995342255
I0302 02:13:29.175056 139590664976128 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.794365644454956, loss=0.2394924759864807
I0302 02:13:52.999007 139590832731904 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.17474359273910522, loss=0.28517791628837585
I0302 02:14:16.612828 139590664976128 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.2574020326137543, loss=0.30140408873558044
I0302 02:14:26.579211 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:14:27.991318 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:14:29.351871 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:14:30.711076 139915712112448 submission_runner.py:359] Time since start: 2544.09s, 	Step: 8943, 	{'train/ssim': 0.7475596155439105, 'train/loss': 0.2644381693431309, 'validation/ssim': 0.7222872225837085, 'validation/loss': 0.28810053510349254, 'validation/num_examples': 3554, 'test/ssim': 0.7394394351263613, 'test/loss': 0.28954791783021505, 'test/num_examples': 3581}
I0302 02:14:30.721051 139590832731904 logging_writer.py:48] [8943] global_step=8943, preemption_count=0, score=2195.500982, test/loss=0.289548, test/num_examples=3581, test/ssim=0.739439, total_duration=2544.087947, train/loss=0.264438, train/ssim=0.747560, validation/loss=0.288101, validation/num_examples=3554, validation/ssim=0.722287
I0302 02:14:30.742046 139915712112448 checkpoints.py:356] Saving checkpoint at step: 8943
I0302 02:14:30.924617 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_8943
I0302 02:14:30.925159 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_8943.
I0302 02:14:42.467468 139590664976128 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.980627715587616, loss=0.3331230878829956
I0302 02:15:06.337932 139590656583424 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.7350994944572449, loss=0.2724902331829071
I0302 02:15:30.062030 139590664976128 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.3294151723384857, loss=0.181038498878479
I0302 02:15:51.098064 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:15:52.511610 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:15:53.870526 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:15:55.233264 139915712112448 submission_runner.py:359] Time since start: 2628.61s, 	Step: 9290, 	{'train/ssim': 0.7446566309247699, 'train/loss': 0.2740920100893293, 'validation/ssim': 0.7217589610737901, 'validation/loss': 0.28772879425031656, 'validation/num_examples': 3554, 'test/ssim': 0.7391177094605208, 'test/loss': 0.28912890406834685, 'test/num_examples': 3581}
I0302 02:15:55.241729 139590656583424 logging_writer.py:48] [9290] global_step=9290, preemption_count=0, score=2275.344107, test/loss=0.289129, test/num_examples=3581, test/ssim=0.739118, total_duration=2628.606782, train/loss=0.274092, train/ssim=0.744657, validation/loss=0.287729, validation/num_examples=3554, validation/ssim=0.721759
I0302 02:15:55.268498 139915712112448 checkpoints.py:356] Saving checkpoint at step: 9290
I0302 02:15:55.414050 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_9290
I0302 02:15:55.414458 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_9290.
I0302 02:15:56.222826 139590664976128 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.1505061388015747, loss=0.3781604766845703
I0302 02:16:19.475774 139590648190720 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.2716549038887024, loss=0.2177312672138214
I0302 02:16:43.175381 139590664976128 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.12046100944280624, loss=0.25849154591560364
I0302 02:17:06.884789 139590648190720 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.20007328689098358, loss=0.2342492789030075
I0302 02:17:15.623734 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:17:17.032750 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:17:18.386682 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:17:19.742082 139915712112448 submission_runner.py:359] Time since start: 2713.13s, 	Step: 9637, 	{'train/ssim': 0.7278357233319964, 'train/loss': 0.26279328550611225, 'validation/ssim': 0.7217888432268219, 'validation/loss': 0.28763202072598654, 'validation/num_examples': 3554, 'test/ssim': 0.7391528886178791, 'test/loss': 0.2890142650119555, 'test/num_examples': 3581}
I0302 02:17:19.750616 139590664976128 logging_writer.py:48] [9637] global_step=9637, preemption_count=0, score=2355.232203, test/loss=0.289014, test/num_examples=3581, test/ssim=0.739153, total_duration=2713.132478, train/loss=0.262793, train/ssim=0.727836, validation/loss=0.287632, validation/num_examples=3554, validation/ssim=0.721789
I0302 02:17:19.777799 139915712112448 checkpoints.py:356] Saving checkpoint at step: 9637
I0302 02:17:19.924157 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_9637
I0302 02:17:19.924573 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_9637.
I0302 02:17:32.913450 139590648190720 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.15566277503967285, loss=0.37565916776657104
I0302 02:17:56.724575 139590639798016 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.27680036425590515, loss=0.22463583946228027
I0302 02:18:20.110746 139590648190720 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.1747506707906723, loss=0.2456274926662445
I0302 02:18:40.062985 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:18:41.477858 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:18:42.836488 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:18:44.193769 139915712112448 submission_runner.py:359] Time since start: 2797.57s, 	Step: 9986, 	{'train/ssim': 0.7371879305158343, 'train/loss': 0.2821736676352365, 'validation/ssim': 0.7230290556195484, 'validation/loss': 0.2874431449104442, 'validation/num_examples': 3554, 'test/ssim': 0.7403438667184445, 'test/loss': 0.28887869572046915, 'test/num_examples': 3581}
I0302 02:18:44.202455 139590639798016 logging_writer.py:48] [9986] global_step=9986, preemption_count=0, score=2435.047010, test/loss=0.288879, test/num_examples=3581, test/ssim=0.740344, total_duration=2797.571704, train/loss=0.282174, train/ssim=0.737188, validation/loss=0.287443, validation/num_examples=3554, validation/ssim=0.723029
I0302 02:18:44.229030 139915712112448 checkpoints.py:356] Saving checkpoint at step: 9986
I0302 02:18:44.372174 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_9986
I0302 02:18:44.372571 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_9986.
I0302 02:18:45.708145 139590648190720 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.14688076078891754, loss=0.27516084909439087
I0302 02:19:09.119616 139590631405312 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.20340026915073395, loss=0.30435964465141296
I0302 02:19:32.597015 139590648190720 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.5585697889328003, loss=0.3136896789073944
I0302 02:19:56.093557 139590631405312 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.2511920630931854, loss=0.22994285821914673
I0302 02:20:04.522273 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:20:05.936035 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:20:07.296641 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:20:08.654050 139915712112448 submission_runner.py:359] Time since start: 2882.03s, 	Step: 10337, 	{'train/ssim': 0.7273233277457101, 'train/loss': 0.28542470932006836, 'validation/ssim': 0.7217946822682189, 'validation/loss': 0.28742212436141495, 'validation/num_examples': 3554, 'test/ssim': 0.7391716371998045, 'test/loss': 0.28880891690737576, 'test/num_examples': 3581}
I0302 02:20:08.664080 139590648190720 logging_writer.py:48] [10337] global_step=10337, preemption_count=0, score=2514.864759, test/loss=0.288809, test/num_examples=3581, test/ssim=0.739172, total_duration=2882.030989, train/loss=0.285425, train/ssim=0.727323, validation/loss=0.287422, validation/num_examples=3554, validation/ssim=0.721795
I0302 02:20:08.684743 139915712112448 checkpoints.py:356] Saving checkpoint at step: 10337
I0302 02:20:08.868143 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_10337
I0302 02:20:08.868754 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_10337.
I0302 02:20:21.768851 139590631405312 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.20111162960529327, loss=0.25396355986595154
I0302 02:20:45.327547 139590623012608 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.23330163955688477, loss=0.3538336157798767
I0302 02:21:08.922982 139590631405312 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.23017112910747528, loss=0.23873689770698547
I0302 02:21:28.872250 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:21:30.285202 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:21:31.639482 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:21:33.001557 139915712112448 submission_runner.py:359] Time since start: 2966.38s, 	Step: 10684, 	{'train/ssim': 0.7325865200587681, 'train/loss': 0.2801370450428554, 'validation/ssim': 0.7190905878499578, 'validation/loss': 0.2880573948917593, 'validation/num_examples': 3554, 'test/ssim': 0.7366486916625943, 'test/loss': 0.2893611478659069, 'test/num_examples': 3581}
I0302 02:21:33.010379 139590623012608 logging_writer.py:48] [10684] global_step=10684, preemption_count=0, score=2594.538832, test/loss=0.289361, test/num_examples=3581, test/ssim=0.736649, total_duration=2966.380987, train/loss=0.280137, train/ssim=0.732587, validation/loss=0.288057, validation/num_examples=3554, validation/ssim=0.719091
I0302 02:21:33.038104 139915712112448 checkpoints.py:356] Saving checkpoint at step: 10684
I0302 02:21:33.187468 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_10684
I0302 02:21:33.187904 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_10684.
I0302 02:21:34.940045 139590631405312 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.2582177519798279, loss=0.20964863896369934
I0302 02:21:59.022555 139590614619904 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.1591184288263321, loss=0.3016290068626404
I0302 02:22:22.906261 139590631405312 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.3544938862323761, loss=0.24134741723537445
I0302 02:22:46.539498 139590614619904 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.22429487109184265, loss=0.301431804895401
I0302 02:22:53.385854 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:22:54.799854 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:22:56.158237 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:22:57.517196 139915712112448 submission_runner.py:359] Time since start: 3050.89s, 	Step: 11031, 	{'train/ssim': 0.7395448684692383, 'train/loss': 0.28031485421316965, 'validation/ssim': 0.7244779622212648, 'validation/loss': 0.2883040772171321, 'validation/num_examples': 3554, 'test/ssim': 0.7415795005323234, 'test/loss': 0.2897497889250559, 'test/num_examples': 3581}
I0302 02:22:57.525617 139590631405312 logging_writer.py:48] [11031] global_step=11031, preemption_count=0, score=2674.409859, test/loss=0.289750, test/num_examples=3581, test/ssim=0.741580, total_duration=3050.894589, train/loss=0.280315, train/ssim=0.739545, validation/loss=0.288304, validation/num_examples=3554, validation/ssim=0.724478
I0302 02:22:57.552765 139915712112448 checkpoints.py:356] Saving checkpoint at step: 11031
I0302 02:22:57.701733 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_11031
I0302 02:22:57.702148 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_11031.
I0302 02:23:12.046537 139590614619904 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.23577193915843964, loss=0.281461626291275
I0302 02:23:35.682885 139590530758400 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.3411555588245392, loss=0.2606053054332733
I0302 02:23:59.467758 139590614619904 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.28955700993537903, loss=0.3541676104068756
I0302 02:24:17.949975 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:24:19.366366 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:24:20.724398 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:24:22.079460 139915712112448 submission_runner.py:359] Time since start: 3135.46s, 	Step: 11379, 	{'train/ssim': 0.7356535366603306, 'train/loss': 0.283963714327131, 'validation/ssim': 0.7209256268245287, 'validation/loss': 0.28815741423616, 'validation/num_examples': 3554, 'test/ssim': 0.7376685463426766, 'test/loss': 0.2896824303834474, 'test/num_examples': 3581}
I0302 02:24:22.088004 139590530758400 logging_writer.py:48] [11379] global_step=11379, preemption_count=0, score=2754.332240, test/loss=0.289682, test/num_examples=3581, test/ssim=0.737669, total_duration=3135.458713, train/loss=0.283964, train/ssim=0.735654, validation/loss=0.288157, validation/num_examples=3554, validation/ssim=0.720926
I0302 02:24:22.114405 139915712112448 checkpoints.py:356] Saving checkpoint at step: 11379
I0302 02:24:22.259470 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_11379
I0302 02:24:22.259918 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_11379.
I0302 02:24:25.225929 139590614619904 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.2930304706096649, loss=0.2904447615146637
I0302 02:24:48.927204 139590522365696 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.19610777497291565, loss=0.252983957529068
I0302 02:25:12.745335 139590614619904 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.725955069065094, loss=0.20015692710876465
I0302 02:25:36.226386 139590522365696 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.20993655920028687, loss=0.32080376148223877
I0302 02:25:42.386086 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:25:43.795622 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:25:45.159551 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:25:46.516998 139915712112448 submission_runner.py:359] Time since start: 3219.89s, 	Step: 11727, 	{'train/ssim': 0.7408665929521833, 'train/loss': 0.27324650968824116, 'validation/ssim': 0.7241101713078574, 'validation/loss': 0.2871414897276836, 'validation/num_examples': 3554, 'test/ssim': 0.741227504428756, 'test/loss': 0.28856269689419856, 'test/num_examples': 3581}
I0302 02:25:46.526304 139590614619904 logging_writer.py:48] [11727] global_step=11727, preemption_count=0, score=2834.130538, test/loss=0.288563, test/num_examples=3581, test/ssim=0.741228, total_duration=3219.894807, train/loss=0.273247, train/ssim=0.740867, validation/loss=0.287141, validation/num_examples=3554, validation/ssim=0.724110
I0302 02:25:46.552954 139915712112448 checkpoints.py:356] Saving checkpoint at step: 11727
I0302 02:25:46.699478 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_11727
I0302 02:25:46.699923 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_11727.
I0302 02:26:02.440571 139590522365696 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.22724896669387817, loss=0.1790437251329422
I0302 02:26:25.952454 139590513972992 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.30404242873191833, loss=0.34253644943237305
I0302 02:26:49.811171 139590522365696 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.2554085850715637, loss=0.27680352330207825
I0302 02:27:06.765836 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:27:08.186364 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:27:09.546425 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:27:10.909002 139915712112448 submission_runner.py:359] Time since start: 3304.27s, 	Step: 12073, 	{'train/ssim': 0.7443915775844029, 'train/loss': 0.26108511856624056, 'validation/ssim': 0.7234937746201463, 'validation/loss': 0.28742585104371837, 'validation/num_examples': 3554, 'test/ssim': 0.7406917722223192, 'test/loss': 0.288840789496649, 'test/num_examples': 3581}
I0302 02:27:10.918009 139590513972992 logging_writer.py:48] [12073] global_step=12073, preemption_count=0, score=2913.869099, test/loss=0.288841, test/num_examples=3581, test/ssim=0.740692, total_duration=3304.274581, train/loss=0.261085, train/ssim=0.744392, validation/loss=0.287426, validation/num_examples=3554, validation/ssim=0.723494
I0302 02:27:10.944165 139915712112448 checkpoints.py:356] Saving checkpoint at step: 12073
I0302 02:27:11.090427 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_12073
I0302 02:27:11.090854 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_12073.
I0302 02:27:15.334829 139590522365696 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.20457600057125092, loss=0.27214673161506653
I0302 02:27:38.708310 139590505580288 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.215572327375412, loss=0.26586949825286865
I0302 02:28:02.259520 139590522365696 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.23111701011657715, loss=0.29641515016555786
I0302 02:28:25.828700 139590505580288 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.2475859820842743, loss=0.2574304938316345
I0302 02:28:31.227265 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:28:32.636816 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:28:33.995696 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:28:35.348173 139915712112448 submission_runner.py:359] Time since start: 3388.74s, 	Step: 12424, 	{'train/ssim': 0.7494527271815709, 'train/loss': 0.26867951665605816, 'validation/ssim': 0.7240120067177828, 'validation/loss': 0.2870363869825373, 'validation/num_examples': 3554, 'test/ssim': 0.7412882498341944, 'test/loss': 0.28847089701942547, 'test/num_examples': 3581}
I0302 02:28:35.356997 139590522365696 logging_writer.py:48] [12424] global_step=12424, preemption_count=0, score=2993.679573, test/loss=0.288471, test/num_examples=3581, test/ssim=0.741288, total_duration=3388.735998, train/loss=0.268680, train/ssim=0.749453, validation/loss=0.287036, validation/num_examples=3554, validation/ssim=0.724012
I0302 02:28:35.384728 139915712112448 checkpoints.py:356] Saving checkpoint at step: 12424
I0302 02:28:35.532574 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_12424
I0302 02:28:35.533015 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_12424.
I0302 02:28:51.437175 139590505580288 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.4015275239944458, loss=0.3249589800834656
I0302 02:29:14.857498 139590497187584 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.3144035041332245, loss=0.320597767829895
I0302 02:29:38.440529 139590505580288 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.18165400624275208, loss=0.3381783366203308
I0302 02:29:55.644652 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:29:57.062001 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:29:58.420782 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:29:59.775139 139915712112448 submission_runner.py:359] Time since start: 3473.15s, 	Step: 12775, 	{'train/ssim': 0.7270932878766742, 'train/loss': 0.2677886996950422, 'validation/ssim': 0.7205795434061972, 'validation/loss': 0.28736478154016604, 'validation/num_examples': 3554, 'test/ssim': 0.7380961503638998, 'test/loss': 0.2887373655010821, 'test/num_examples': 3581}
I0302 02:29:59.785617 139590497187584 logging_writer.py:48] [12775] global_step=12775, preemption_count=0, score=3073.462013, test/loss=0.288737, test/num_examples=3581, test/ssim=0.738096, total_duration=3473.153382, train/loss=0.267789, train/ssim=0.727093, validation/loss=0.287365, validation/num_examples=3554, validation/ssim=0.720580
I0302 02:29:59.813509 139915712112448 checkpoints.py:356] Saving checkpoint at step: 12775
I0302 02:29:59.961831 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_12775
I0302 02:29:59.962276 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_12775.
I0302 02:30:03.875034 139590505580288 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.17059709131717682, loss=0.21368297934532166
I0302 02:30:28.185563 139590488794880 logging_writer.py:48] [12900] global_step=12900, grad_norm=1.287939429283142, loss=0.2680475115776062
I0302 02:30:51.987501 139590505580288 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.29319798946380615, loss=0.35292676091194153
I0302 02:31:15.810253 139590488794880 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.22721828520298004, loss=0.30559399724006653
I0302 02:31:19.993338 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:31:21.402613 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:31:22.763432 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:31:24.123751 139915712112448 submission_runner.py:359] Time since start: 3557.50s, 	Step: 13119, 	{'train/ssim': 0.7386341776166644, 'train/loss': 0.27210647719247, 'validation/ssim': 0.7176662052221089, 'validation/loss': 0.291753679832583, 'validation/num_examples': 3554, 'test/ssim': 0.7347565165980173, 'test/loss': 0.29338585481534485, 'test/num_examples': 3581}
I0302 02:31:24.134023 139590505580288 logging_writer.py:48] [13119] global_step=13119, preemption_count=0, score=3153.176270, test/loss=0.293386, test/num_examples=3581, test/ssim=0.734757, total_duration=3557.502077, train/loss=0.272106, train/ssim=0.738634, validation/loss=0.291754, validation/num_examples=3554, validation/ssim=0.717666
I0302 02:31:24.155326 139915712112448 checkpoints.py:356] Saving checkpoint at step: 13119
I0302 02:31:24.346859 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_13119
I0302 02:31:24.347407 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_13119.
I0302 02:31:41.518845 139590488794880 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.23037825524806976, loss=0.256718248128891
I0302 02:32:05.278589 139590480402176 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.16043418645858765, loss=0.43616271018981934
I0302 02:32:28.981975 139590488794880 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.1348535120487213, loss=0.30990931391716003
I0302 02:32:44.508779 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:32:45.922811 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:32:47.278191 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:32:48.634396 139915712112448 submission_runner.py:359] Time since start: 3642.02s, 	Step: 13468, 	{'train/ssim': 0.7326493263244629, 'train/loss': 0.28339806624821257, 'validation/ssim': 0.7210196010437183, 'validation/loss': 0.2889764256603475, 'validation/num_examples': 3554, 'test/ssim': 0.738158122949246, 'test/loss': 0.29048943752617984, 'test/num_examples': 3581}
I0302 02:32:48.645443 139590480402176 logging_writer.py:48] [13468] global_step=13468, preemption_count=0, score=3233.011066, test/loss=0.290489, test/num_examples=3581, test/ssim=0.738158, total_duration=3642.017526, train/loss=0.283398, train/ssim=0.732649, validation/loss=0.288976, validation/num_examples=3554, validation/ssim=0.721020
I0302 02:32:48.668519 139915712112448 checkpoints.py:356] Saving checkpoint at step: 13468
I0302 02:32:48.853822 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_13468
I0302 02:32:48.854324 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_13468.
I0302 02:32:54.325172 139590488794880 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.1645783632993698, loss=0.24106153845787048
I0302 02:33:17.985236 139590329431808 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.25196778774261475, loss=0.2879127860069275
I0302 02:33:41.309209 139590488794880 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.19792713224887848, loss=0.27718687057495117
I0302 02:34:05.222571 139590329431808 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.1643778532743454, loss=0.2833600342273712
I0302 02:34:08.884477 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:34:10.295607 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:34:11.650295 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:34:13.008223 139915712112448 submission_runner.py:359] Time since start: 3726.39s, 	Step: 13817, 	{'train/ssim': 0.7236015456063407, 'train/loss': 0.2901172297341483, 'validation/ssim': 0.7200778667082864, 'validation/loss': 0.2891386479692776, 'validation/num_examples': 3554, 'test/ssim': 0.7370891128961882, 'test/loss': 0.29067924135192685, 'test/num_examples': 3581}
I0302 02:34:13.017986 139590488794880 logging_writer.py:48] [13817] global_step=13817, preemption_count=0, score=3312.717055, test/loss=0.290679, test/num_examples=3581, test/ssim=0.737089, total_duration=3726.393211, train/loss=0.290117, train/ssim=0.723602, validation/loss=0.289139, validation/num_examples=3554, validation/ssim=0.720078
I0302 02:34:13.044663 139915712112448 checkpoints.py:356] Saving checkpoint at step: 13817
I0302 02:34:13.192152 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_13817
I0302 02:34:13.192572 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_13817.
I0302 02:34:30.739206 139590329431808 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.2556881606578827, loss=0.22751542925834656
I0302 02:34:55.081983 139590321039104 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.37361857295036316, loss=0.2631071209907532
I0302 02:35:18.933858 139590329431808 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.2376948744058609, loss=0.31179124116897583
I0302 02:35:33.217248 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:35:34.633271 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:35:35.989936 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:35:37.351032 139915712112448 submission_runner.py:359] Time since start: 3810.73s, 	Step: 14162, 	{'train/ssim': 0.7370419502258301, 'train/loss': 0.2792008774621146, 'validation/ssim': 0.7218947016126196, 'validation/loss': 0.2880085873751407, 'validation/num_examples': 3554, 'test/ssim': 0.7391405486421391, 'test/loss': 0.2894437438913711, 'test/num_examples': 3581}
I0302 02:35:37.361957 139590321039104 logging_writer.py:48] [14162] global_step=14162, preemption_count=0, score=3392.422317, test/loss=0.289444, test/num_examples=3581, test/ssim=0.739141, total_duration=3810.725993, train/loss=0.279201, train/ssim=0.737042, validation/loss=0.288009, validation/num_examples=3554, validation/ssim=0.721895
I0302 02:35:37.382397 139915712112448 checkpoints.py:356] Saving checkpoint at step: 14162
I0302 02:35:37.568403 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_14162
I0302 02:35:37.569018 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_14162.
I0302 02:35:44.666480 139590329431808 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.29433414340019226, loss=0.21709199249744415
I0302 02:36:08.260953 139590312646400 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.16251873970031738, loss=0.23479947447776794
I0302 02:36:31.673120 139590329431808 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.2794720232486725, loss=0.3075563311576843
I0302 02:36:55.492839 139590312646400 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.21866880357265472, loss=0.2855049669742584
I0302 02:36:57.826130 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:36:59.233313 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:37:00.590793 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:37:01.949047 139915712112448 submission_runner.py:359] Time since start: 3895.33s, 	Step: 14511, 	{'train/ssim': 0.7362714494977679, 'train/loss': 0.2807021311351231, 'validation/ssim': 0.721497303324599, 'validation/loss': 0.28790461809097145, 'validation/num_examples': 3554, 'test/ssim': 0.7388224363393605, 'test/loss': 0.28933530891118053, 'test/num_examples': 3581}
I0302 02:37:01.959279 139590329431808 logging_writer.py:48] [14511] global_step=14511, preemption_count=0, score=3472.348451, test/loss=0.289335, test/num_examples=3581, test/ssim=0.738822, total_duration=3895.334852, train/loss=0.280702, train/ssim=0.736271, validation/loss=0.287905, validation/num_examples=3554, validation/ssim=0.721497
I0302 02:37:01.985967 139915712112448 checkpoints.py:356] Saving checkpoint at step: 14511
I0302 02:37:02.137165 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_14511
I0302 02:37:02.137614 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_14511.
I0302 02:37:21.116334 139590312646400 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.2069789618253708, loss=0.2551317512989044
I0302 02:37:44.804025 139590170035968 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.3351718485355377, loss=0.2960234582424164
I0302 02:38:08.177698 139590312646400 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.2865760326385498, loss=0.31424596905708313
I0302 02:38:22.283978 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:38:23.692070 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:38:25.047014 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:38:26.404960 139915712112448 submission_runner.py:359] Time since start: 3979.79s, 	Step: 14861, 	{'train/ssim': 0.7366507393973214, 'train/loss': 0.2830709218978882, 'validation/ssim': 0.7186876939935636, 'validation/loss': 0.28924048772070204, 'validation/num_examples': 3554, 'test/ssim': 0.7359393816758587, 'test/loss': 0.29062616582091244, 'test/num_examples': 3581}
I0302 02:38:26.413928 139590170035968 logging_writer.py:48] [14861] global_step=14861, preemption_count=0, score=3552.172005, test/loss=0.290626, test/num_examples=3581, test/ssim=0.735939, total_duration=3979.792713, train/loss=0.283071, train/ssim=0.736651, validation/loss=0.289240, validation/num_examples=3554, validation/ssim=0.718688
I0302 02:38:26.441381 139915712112448 checkpoints.py:356] Saving checkpoint at step: 14861
I0302 02:38:26.597635 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_14861
I0302 02:38:26.598146 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_14861.
I0302 02:38:33.853033 139590312646400 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.2846781313419342, loss=0.22579115629196167
I0302 02:38:57.587424 139590329431808 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.22665394842624664, loss=0.32890328764915466
I0302 02:39:21.757845 139590312646400 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.3222033381462097, loss=0.21031038463115692
I0302 02:39:45.614814 139590329431808 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.21634308993816376, loss=0.2143423855304718
I0302 02:39:46.686874 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:39:48.094551 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:39:49.441897 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:39:50.791530 139915712112448 submission_runner.py:359] Time since start: 4064.20s, 	Step: 15206, 	{'train/ssim': 0.7365939957754952, 'train/loss': 0.27231015477861675, 'validation/ssim': 0.7206913782226013, 'validation/loss': 0.2894989511707759, 'validation/num_examples': 3554, 'test/ssim': 0.7377725157515359, 'test/loss': 0.2908930774508692, 'test/num_examples': 3581}
I0302 02:39:50.801554 139590312646400 logging_writer.py:48] [15206] global_step=15206, preemption_count=0, score=3631.943328, test/loss=0.290893, test/num_examples=3581, test/ssim=0.737773, total_duration=4064.195611, train/loss=0.272310, train/ssim=0.736594, validation/loss=0.289499, validation/num_examples=3554, validation/ssim=0.720691
I0302 02:39:50.828095 139915712112448 checkpoints.py:356] Saving checkpoint at step: 15206
I0302 02:39:50.976064 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_15206
I0302 02:39:50.976474 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_15206.
I0302 02:40:11.157013 139590329431808 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.5529147386550903, loss=0.22408652305603027
I0302 02:40:34.790480 139590287468288 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.4525100290775299, loss=0.32012611627578735
I0302 02:40:58.379675 139590329431808 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.3986136317253113, loss=0.22016356885433197
I0302 02:41:11.095200 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:41:12.504183 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:41:13.858821 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:41:15.215828 139915712112448 submission_runner.py:359] Time since start: 4148.60s, 	Step: 15555, 	{'train/ssim': 0.7357465199061802, 'train/loss': 0.26746983187539236, 'validation/ssim': 0.7136501125492403, 'validation/loss': 0.29249843238912143, 'validation/num_examples': 3554, 'test/ssim': 0.7302127466358909, 'test/loss': 0.2942535391868542, 'test/num_examples': 3581}
I0302 02:41:15.226760 139590287468288 logging_writer.py:48] [15555] global_step=15555, preemption_count=0, score=3711.740069, test/loss=0.294254, test/num_examples=3581, test/ssim=0.730213, total_duration=4148.603936, train/loss=0.267470, train/ssim=0.735747, validation/loss=0.292498, validation/num_examples=3554, validation/ssim=0.713650
I0302 02:41:15.247379 139915712112448 checkpoints.py:356] Saving checkpoint at step: 15555
I0302 02:41:15.429328 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_15555
I0302 02:41:15.429847 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_15555.
I0302 02:41:23.927148 139590329431808 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.42070272564888, loss=0.31727343797683716
I0302 02:41:47.367581 139590279075584 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.44594916701316833, loss=0.22676202654838562
I0302 02:42:11.311065 139590329431808 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.2071487009525299, loss=0.33264073729515076
I0302 02:42:34.855562 139590279075584 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.6620041728019714, loss=0.2539450526237488
I0302 02:42:35.535162 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:42:36.946194 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:42:38.303502 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:42:39.654798 139915712112448 submission_runner.py:359] Time since start: 4233.04s, 	Step: 15904, 	{'train/ssim': 0.7369802338736398, 'train/loss': 0.2794285672051566, 'validation/ssim': 0.713772869807787, 'validation/loss': 0.2942804047815841, 'validation/num_examples': 3554, 'test/ssim': 0.7305249275691148, 'test/loss': 0.29580871701340405, 'test/num_examples': 3581}
I0302 02:42:39.664013 139590329431808 logging_writer.py:48] [15904] global_step=15904, preemption_count=0, score=3791.519129, test/loss=0.295809, test/num_examples=3581, test/ssim=0.730525, total_duration=4233.043887, train/loss=0.279429, train/ssim=0.736980, validation/loss=0.294280, validation/num_examples=3554, validation/ssim=0.713773
I0302 02:42:39.690881 139915712112448 checkpoints.py:356] Saving checkpoint at step: 15904
I0302 02:42:39.838421 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_15904
I0302 02:42:39.838821 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_15904.
I0302 02:43:00.520253 139590279075584 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.22189860045909882, loss=0.25807395577430725
I0302 02:43:24.563273 139590195214080 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.2750401496887207, loss=0.2598949074745178
I0302 02:43:48.728785 139590279075584 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.24278265237808228, loss=0.28036069869995117
I0302 02:44:00.056988 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:44:01.463337 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:44:02.820809 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:44:04.180107 139915712112448 submission_runner.py:359] Time since start: 4317.57s, 	Step: 16249, 	{'train/ssim': 0.7322956493922642, 'train/loss': 0.26223894527980257, 'validation/ssim': 0.7246778635208568, 'validation/loss': 0.2872241121634514, 'validation/num_examples': 3554, 'test/ssim': 0.7416867424209369, 'test/loss': 0.2887783055863411, 'test/num_examples': 3581}
I0302 02:44:04.189586 139590195214080 logging_writer.py:48] [16249] global_step=16249, preemption_count=0, score=3871.410145, test/loss=0.288778, test/num_examples=3581, test/ssim=0.741687, total_duration=4317.565728, train/loss=0.262239, train/ssim=0.732296, validation/loss=0.287224, validation/num_examples=3554, validation/ssim=0.724678
I0302 02:44:04.216147 139915712112448 checkpoints.py:356] Saving checkpoint at step: 16249
I0302 02:44:04.363811 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_16249
I0302 02:44:04.364232 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_16249.
I0302 02:44:14.545325 139590279075584 logging_writer.py:48] [16300] global_step=16300, grad_norm=1.013394832611084, loss=0.2361724078655243
I0302 02:44:38.266149 139590186821376 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.4967290163040161, loss=0.2570856213569641
I0302 02:45:02.044358 139590279075584 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.23119506239891052, loss=0.2743194103240967
I0302 02:45:24.437125 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:45:25.849029 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:45:27.206631 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:45:28.567124 139915712112448 submission_runner.py:359] Time since start: 4401.95s, 	Step: 16596, 	{'train/ssim': 0.7400255884443011, 'train/loss': 0.27337050437927246, 'validation/ssim': 0.7214063516680149, 'validation/loss': 0.2873047081083814, 'validation/num_examples': 3554, 'test/ssim': 0.7388218227494066, 'test/loss': 0.2885886381139172, 'test/num_examples': 3581}
I0302 02:45:28.576330 139590186821376 logging_writer.py:48] [16596] global_step=16596, preemption_count=0, score=3951.157141, test/loss=0.288589, test/num_examples=3581, test/ssim=0.738822, total_duration=4401.945869, train/loss=0.273371, train/ssim=0.740026, validation/loss=0.287305, validation/num_examples=3554, validation/ssim=0.721406
I0302 02:45:28.603707 139915712112448 checkpoints.py:356] Saving checkpoint at step: 16596
I0302 02:45:28.751089 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_16596
I0302 02:45:28.751481 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_16596.
I0302 02:45:29.122512 139590279075584 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.6843065619468689, loss=0.2443625032901764
I0302 02:45:51.241448 139590178428672 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.27413424849510193, loss=0.2932484447956085
I0302 02:46:15.063631 139590279075584 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.26364684104919434, loss=0.2004540115594864
I0302 02:46:38.788691 139590178428672 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.18431280553340912, loss=0.3301294445991516
I0302 02:46:48.754232 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:46:50.165646 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:46:51.516736 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:46:52.879269 139915712112448 submission_runner.py:359] Time since start: 4486.26s, 	Step: 16943, 	{'train/ssim': 0.7309530803135463, 'train/loss': 0.283855744770595, 'validation/ssim': 0.7230032264481921, 'validation/loss': 0.2867632572343662, 'validation/num_examples': 3554, 'test/ssim': 0.740266281677604, 'test/loss': 0.2881603523260786, 'test/num_examples': 3581}
I0302 02:46:52.888315 139590279075584 logging_writer.py:48] [16943] global_step=16943, preemption_count=0, score=4030.839056, test/loss=0.288160, test/num_examples=3581, test/ssim=0.740266, total_duration=4486.262968, train/loss=0.283856, train/ssim=0.730953, validation/loss=0.286763, validation/num_examples=3554, validation/ssim=0.723003
I0302 02:46:52.914694 139915712112448 checkpoints.py:356] Saving checkpoint at step: 16943
I0302 02:46:53.063545 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_16943
I0302 02:46:53.063953 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_16943.
I0302 02:47:04.608735 139590178428672 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.26085248589515686, loss=0.2812085747718811
I0302 02:47:28.176018 139590170035968 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.19176135957241058, loss=0.31796708703041077
I0302 02:47:52.205127 139590178428672 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.2033410668373108, loss=0.30127304792404175
I0302 02:48:13.097122 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:48:14.509721 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:48:15.860539 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:48:17.221363 139915712112448 submission_runner.py:359] Time since start: 4570.61s, 	Step: 17288, 	{'train/ssim': 0.7281818389892578, 'train/loss': 0.2864894185747419, 'validation/ssim': 0.7230350320501547, 'validation/loss': 0.28675705754629466, 'validation/num_examples': 3554, 'test/ssim': 0.7403873634285116, 'test/loss': 0.28804441791311786, 'test/num_examples': 3581}
I0302 02:48:17.230854 139590170035968 logging_writer.py:48] [17288] global_step=17288, preemption_count=0, score=4110.554134, test/loss=0.288044, test/num_examples=3581, test/ssim=0.740387, total_duration=4570.605865, train/loss=0.286489, train/ssim=0.728182, validation/loss=0.286757, validation/num_examples=3554, validation/ssim=0.723035
I0302 02:48:17.257776 139915712112448 checkpoints.py:356] Saving checkpoint at step: 17288
I0302 02:48:17.405609 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_17288
I0302 02:48:17.406011 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_17288.
I0302 02:48:18.354549 139590178428672 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.22039079666137695, loss=0.27336177229881287
I0302 02:48:41.723907 139590161643264 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.5373728275299072, loss=0.27376875281333923
I0302 02:49:05.393309 139590178428672 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.2951855957508087, loss=0.2225983887910843
I0302 02:49:28.964624 139590161643264 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.2561694085597992, loss=0.33215323090553284
I0302 02:49:37.632498 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:49:39.044943 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:49:40.401590 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:49:41.758924 139915712112448 submission_runner.py:359] Time since start: 4655.14s, 	Step: 17638, 	{'train/ssim': 0.7427566392081124, 'train/loss': 0.27351622922079905, 'validation/ssim': 0.7237881996957654, 'validation/loss': 0.28649074573763716, 'validation/num_examples': 3554, 'test/ssim': 0.741075606826829, 'test/loss': 0.28782410503132855, 'test/num_examples': 3581}
I0302 02:49:41.767990 139590178428672 logging_writer.py:48] [17638] global_step=17638, preemption_count=0, score=4190.447368, test/loss=0.287824, test/num_examples=3581, test/ssim=0.741076, total_duration=4655.141243, train/loss=0.273516, train/ssim=0.742757, validation/loss=0.286491, validation/num_examples=3554, validation/ssim=0.723788
I0302 02:49:41.794975 139915712112448 checkpoints.py:356] Saving checkpoint at step: 17638
I0302 02:49:41.942313 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_17638
I0302 02:49:41.942717 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_17638.
I0302 02:49:54.587330 139590161643264 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.3380402624607086, loss=0.2659815847873688
I0302 02:50:18.060930 139590153250560 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.4704272449016571, loss=0.25713080167770386
I0302 02:50:41.529725 139590161643264 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.16592812538146973, loss=0.2905411422252655
I0302 02:51:02.029423 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:51:03.437775 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:51:04.795754 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:51:06.150620 139915712112448 submission_runner.py:359] Time since start: 4739.54s, 	Step: 17987, 	{'train/ssim': 0.7360964502607074, 'train/loss': 0.2857444626944406, 'validation/ssim': 0.7229855032401871, 'validation/loss': 0.28671245757421215, 'validation/num_examples': 3554, 'test/ssim': 0.7402163763613516, 'test/loss': 0.2881528869816392, 'test/num_examples': 3581}
I0302 02:51:06.161167 139590153250560 logging_writer.py:48] [17987] global_step=17987, preemption_count=0, score=4270.205456, test/loss=0.288153, test/num_examples=3581, test/ssim=0.740216, total_duration=4739.538158, train/loss=0.285744, train/ssim=0.736096, validation/loss=0.286712, validation/num_examples=3554, validation/ssim=0.722986
I0302 02:51:06.188781 139915712112448 checkpoints.py:356] Saving checkpoint at step: 17987
I0302 02:51:06.340078 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_17987
I0302 02:51:06.340495 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_17987.
I0302 02:51:07.441001 139590161643264 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.22370697557926178, loss=0.25384408235549927
I0302 02:51:30.831546 139590144857856 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.31141209602355957, loss=0.19310705363750458
I0302 02:51:54.376512 139590161643264 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.2850947082042694, loss=0.2970469892024994
I0302 02:52:18.247342 139590144857856 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.38530752062797546, loss=0.24602285027503967
I0302 02:52:26.523639 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:52:27.936800 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:52:29.292100 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:52:30.649755 139915712112448 submission_runner.py:359] Time since start: 4824.03s, 	Step: 18335, 	{'train/ssim': 0.7430698531014579, 'train/loss': 0.27559798104422434, 'validation/ssim': 0.7234673271973481, 'validation/loss': 0.2869436149189294, 'validation/num_examples': 3554, 'test/ssim': 0.7407904920282393, 'test/loss': 0.28825310667411336, 'test/num_examples': 3581}
I0302 02:52:30.661904 139590161643264 logging_writer.py:48] [18335] global_step=18335, preemption_count=0, score=4350.063153, test/loss=0.288253, test/num_examples=3581, test/ssim=0.740790, total_duration=4824.032369, train/loss=0.275598, train/ssim=0.743070, validation/loss=0.286944, validation/num_examples=3554, validation/ssim=0.723467
I0302 02:52:30.683625 139915712112448 checkpoints.py:356] Saving checkpoint at step: 18335
I0302 02:52:30.882727 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_18335
I0302 02:52:30.883267 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_18335.
I0302 02:52:44.260866 139590144857856 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.3673532009124756, loss=0.3247230350971222
I0302 02:53:08.081439 139590060996352 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.2732554078102112, loss=0.29275086522102356
I0302 02:53:31.400784 139590144857856 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.2356194257736206, loss=0.3007431626319885
I0302 02:53:51.151424 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:53:52.559726 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:53:53.915403 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:53:55.267346 139915712112448 submission_runner.py:359] Time since start: 4908.66s, 	Step: 18686, 	{'train/ssim': 0.7405351911272321, 'train/loss': 0.2641417809895107, 'validation/ssim': 0.7244073441676632, 'validation/loss': 0.2865372519849993, 'validation/num_examples': 3554, 'test/ssim': 0.7416597444629642, 'test/loss': 0.28796393536416154, 'test/num_examples': 3581}
I0302 02:53:55.276552 139590060996352 logging_writer.py:48] [18686] global_step=18686, preemption_count=0, score=4430.007924, test/loss=0.287964, test/num_examples=3581, test/ssim=0.741660, total_duration=4908.660131, train/loss=0.264142, train/ssim=0.740535, validation/loss=0.286537, validation/num_examples=3554, validation/ssim=0.724407
I0302 02:53:55.303213 139915712112448 checkpoints.py:356] Saving checkpoint at step: 18686
I0302 02:53:55.454180 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_18686
I0302 02:53:55.454578 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_18686.
I0302 02:53:56.699971 139590144857856 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.1920412927865982, loss=0.2809722125530243
I0302 02:54:20.280328 139590052603648 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.28563961386680603, loss=0.34210890531539917
I0302 02:54:43.936099 139590144857856 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.20542097091674805, loss=0.249940425157547
I0302 02:55:07.609663 139590052603648 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.28173092007637024, loss=0.2658909559249878
I0302 02:55:15.667851 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:55:17.080406 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:55:18.439737 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:55:19.798007 139915712112448 submission_runner.py:359] Time since start: 4993.18s, 	Step: 19035, 	{'train/ssim': 0.7496295656476702, 'train/loss': 0.2624638421194894, 'validation/ssim': 0.724393399162915, 'validation/loss': 0.28633987521212895, 'validation/num_examples': 3554, 'test/ssim': 0.7416380642845923, 'test/loss': 0.2876839679035186, 'test/num_examples': 3581}
I0302 02:55:19.809139 139590144857856 logging_writer.py:48] [19035] global_step=19035, preemption_count=0, score=4509.893764, test/loss=0.287684, test/num_examples=3581, test/ssim=0.741638, total_duration=4993.176601, train/loss=0.262464, train/ssim=0.749630, validation/loss=0.286340, validation/num_examples=3554, validation/ssim=0.724393
I0302 02:55:19.829387 139915712112448 checkpoints.py:356] Saving checkpoint at step: 19035
I0302 02:55:20.021342 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_19035
I0302 02:55:20.021913 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_19035.
I0302 02:55:33.341179 139590052603648 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.1806735247373581, loss=0.27793973684310913
I0302 02:55:56.878163 139590044210944 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.7324997186660767, loss=0.20500557124614716
I0302 02:56:20.315249 139590052603648 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.21774549782276154, loss=0.24321097135543823
I0302 02:56:40.163918 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:56:41.571118 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:56:42.929917 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:56:44.286668 139915712112448 submission_runner.py:359] Time since start: 5077.67s, 	Step: 19384, 	{'train/ssim': 0.746638298034668, 'train/loss': 0.27263310977390837, 'validation/ssim': 0.7238344311647088, 'validation/loss': 0.2861723118976857, 'validation/num_examples': 3554, 'test/ssim': 0.7410997413650168, 'test/loss': 0.28751441254625104, 'test/num_examples': 3581}
I0302 02:56:44.296304 139590044210944 logging_writer.py:48] [19384] global_step=19384, preemption_count=0, score=4589.705970, test/loss=0.287514, test/num_examples=3581, test/ssim=0.741100, total_duration=5077.672664, train/loss=0.272633, train/ssim=0.746638, validation/loss=0.286172, validation/num_examples=3554, validation/ssim=0.723834
I0302 02:56:44.322890 139915712112448 checkpoints.py:356] Saving checkpoint at step: 19384
I0302 02:56:44.473961 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_19384
I0302 02:56:44.474377 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_19384.
I0302 02:56:46.240044 139590052603648 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.3756488859653473, loss=0.212603360414505
I0302 02:57:09.824563 139590035818240 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.28392493724823, loss=0.33590105175971985
I0302 02:57:33.409238 139590052603648 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.34316587448120117, loss=0.2961224913597107
I0302 02:57:57.008611 139590035818240 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.28078868985176086, loss=0.29665863513946533
I0302 02:58:04.501129 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:58:05.922079 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:58:07.282197 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:58:08.636395 139915712112448 submission_runner.py:359] Time since start: 5162.01s, 	Step: 19733, 	{'train/ssim': 0.7340303148542132, 'train/loss': 0.2587484461920602, 'validation/ssim': 0.7249358117613957, 'validation/loss': 0.2862537150042206, 'validation/num_examples': 3554, 'test/ssim': 0.7420623276493996, 'test/loss': 0.2876268699494729, 'test/num_examples': 3581}
I0302 02:58:08.647354 139590052603648 logging_writer.py:48] [19733] global_step=19733, preemption_count=0, score=4669.404869, test/loss=0.287627, test/num_examples=3581, test/ssim=0.742062, total_duration=5162.009876, train/loss=0.258748, train/ssim=0.734030, validation/loss=0.286254, validation/num_examples=3554, validation/ssim=0.724936
I0302 02:58:08.669064 139915712112448 checkpoints.py:356] Saving checkpoint at step: 19733
I0302 02:58:08.859303 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_19733
I0302 02:58:08.859861 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_19733.
I0302 02:58:22.650520 139590035818240 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.22762851417064667, loss=0.2514171898365021
I0302 02:58:46.211799 139590027425536 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.2732848823070526, loss=0.361118882894516
I0302 02:59:09.993352 139590035818240 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.25310754776000977, loss=0.2595602869987488
I0302 02:59:29.063825 139915712112448 spec.py:298] Evaluating on the training split.
I0302 02:59:30.474083 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 02:59:31.828706 139915712112448 spec.py:326] Evaluating on the test split.
I0302 02:59:33.189425 139915712112448 submission_runner.py:359] Time since start: 5246.57s, 	Step: 20082, 	{'train/ssim': 0.7385052272251674, 'train/loss': 0.28101861476898193, 'validation/ssim': 0.7245590218547763, 'validation/loss': 0.286016684270804, 'validation/num_examples': 3554, 'test/ssim': 0.7418799550797612, 'test/loss': 0.28735085673519967, 'test/num_examples': 3581}
I0302 02:59:33.198835 139590027425536 logging_writer.py:48] [20082] global_step=20082, preemption_count=0, score=4749.285076, test/loss=0.287351, test/num_examples=3581, test/ssim=0.741880, total_duration=5246.572540, train/loss=0.281019, train/ssim=0.738505, validation/loss=0.286017, validation/num_examples=3554, validation/ssim=0.724559
I0302 02:59:33.225640 139915712112448 checkpoints.py:356] Saving checkpoint at step: 20082
I0302 02:59:33.376772 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_20082
I0302 02:59:33.377174 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_20082.
I0302 02:59:35.591058 139590035818240 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.17561905086040497, loss=0.2510708272457123
I0302 02:59:59.312770 139590019032832 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.2892281711101532, loss=0.29762759804725647
I0302 03:00:23.125932 139590035818240 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.34164682030677795, loss=0.19513258337974548
I0302 03:00:47.057600 139590019032832 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.3310368061065674, loss=0.2187224179506302
I0302 03:00:53.505282 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:00:54.912067 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:00:56.268818 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:00:57.623281 139915712112448 submission_runner.py:359] Time since start: 5331.01s, 	Step: 20428, 	{'train/ssim': 0.7306624821254185, 'train/loss': 0.28198327336992535, 'validation/ssim': 0.7237579053751055, 'validation/loss': 0.28606823957160943, 'validation/num_examples': 3554, 'test/ssim': 0.7409222093383482, 'test/loss': 0.28745373531747415, 'test/num_examples': 3581}
I0302 03:00:57.634390 139590035818240 logging_writer.py:48] [20428] global_step=20428, preemption_count=0, score=4829.093563, test/loss=0.287454, test/num_examples=3581, test/ssim=0.740922, total_duration=5331.014028, train/loss=0.281983, train/ssim=0.730662, validation/loss=0.286068, validation/num_examples=3554, validation/ssim=0.723758
I0302 03:00:57.661525 139915712112448 checkpoints.py:356] Saving checkpoint at step: 20428
I0302 03:00:57.810542 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_20428
I0302 03:00:57.810949 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_20428.
I0302 03:01:13.321233 139590019032832 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.2761998176574707, loss=0.19719457626342773
I0302 03:01:36.858248 139590027425536 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.5072110295295715, loss=0.38317057490348816
I0302 03:02:00.544273 139590019032832 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.26977866888046265, loss=0.23042410612106323
I0302 03:02:17.980760 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:02:19.393946 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:02:20.742854 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:02:22.099285 139915712112448 submission_runner.py:359] Time since start: 5415.49s, 	Step: 20775, 	{'train/ssim': 0.7339572906494141, 'train/loss': 0.28309484890529085, 'validation/ssim': 0.7245834771340391, 'validation/loss': 0.28604617142985894, 'validation/num_examples': 3554, 'test/ssim': 0.7418563659548659, 'test/loss': 0.28740359138290633, 'test/num_examples': 3581}
I0302 03:02:22.109206 139590027425536 logging_writer.py:48] [20775] global_step=20775, preemption_count=0, score=4908.940237, test/loss=0.287404, test/num_examples=3581, test/ssim=0.741856, total_duration=5415.489462, train/loss=0.283095, train/ssim=0.733957, validation/loss=0.286046, validation/num_examples=3554, validation/ssim=0.724583
I0302 03:02:22.136065 139915712112448 checkpoints.py:356] Saving checkpoint at step: 20775
I0302 03:02:22.288782 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_20775
I0302 03:02:22.289199 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_20775.
I0302 03:02:26.172190 139590019032832 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.20222140848636627, loss=0.2512624263763428
I0302 03:02:49.704191 139590035818240 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.2594071924686432, loss=0.2898920774459839
I0302 03:03:13.399361 139590019032832 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.4941379427909851, loss=0.3325652480125427
I0302 03:03:37.248150 139590035818240 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.21575486660003662, loss=0.2739141583442688
I0302 03:03:42.414474 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:03:43.825272 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:03:45.180866 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:03:46.542459 139915712112448 submission_runner.py:359] Time since start: 5499.92s, 	Step: 21123, 	{'train/ssim': 0.7421747616359166, 'train/loss': 0.27381997449057444, 'validation/ssim': 0.7251903252717009, 'validation/loss': 0.2861104352325285, 'validation/num_examples': 3554, 'test/ssim': 0.7424083923834125, 'test/loss': 0.28748966441810947, 'test/num_examples': 3581}
I0302 03:03:46.552205 139590019032832 logging_writer.py:48] [21123] global_step=21123, preemption_count=0, score=4988.741964, test/loss=0.287490, test/num_examples=3581, test/ssim=0.742408, total_duration=5499.923208, train/loss=0.273820, train/ssim=0.742175, validation/loss=0.286110, validation/num_examples=3554, validation/ssim=0.725190
I0302 03:03:46.578714 139915712112448 checkpoints.py:356] Saving checkpoint at step: 21123
I0302 03:03:46.730229 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_21123
I0302 03:03:46.730638 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_21123.
I0302 03:04:02.822297 139590035818240 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.2841627597808838, loss=0.17243963479995728
I0302 03:04:26.527567 139590027425536 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.2404373437166214, loss=0.247613787651062
I0302 03:04:50.185365 139590035818240 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.23963265120983124, loss=0.25305718183517456
I0302 03:05:06.891942 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:05:08.304299 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:05:09.658576 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:05:11.009989 139915712112448 submission_runner.py:359] Time since start: 5584.40s, 	Step: 21471, 	{'train/ssim': 0.7384370395115444, 'train/loss': 0.2828362498964582, 'validation/ssim': 0.7244731535989378, 'validation/loss': 0.28579431983548464, 'validation/num_examples': 3554, 'test/ssim': 0.7417686907681165, 'test/loss': 0.2871083523500768, 'test/num_examples': 3581}
I0302 03:05:11.020025 139590027425536 logging_writer.py:48] [21471] global_step=21471, preemption_count=0, score=5068.577327, test/loss=0.287108, test/num_examples=3581, test/ssim=0.741769, total_duration=5584.400688, train/loss=0.282836, train/ssim=0.738437, validation/loss=0.285794, validation/num_examples=3554, validation/ssim=0.724473
I0302 03:05:11.046105 139915712112448 checkpoints.py:356] Saving checkpoint at step: 21471
I0302 03:05:11.197675 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_21471
I0302 03:05:11.198085 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_21471.
I0302 03:05:15.992427 139590035818240 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.28675219416618347, loss=0.19638296961784363
I0302 03:05:40.015442 139590019032832 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.25154197216033936, loss=0.279867947101593
I0302 03:06:03.726330 139590035818240 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.22487376630306244, loss=0.30442267656326294
I0302 03:06:27.440786 139590019032832 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.4745481610298157, loss=0.1929248869419098
I0302 03:06:31.234096 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:06:32.646931 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:06:34.001191 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:06:35.356408 139915712112448 submission_runner.py:359] Time since start: 5668.74s, 	Step: 21817, 	{'train/ssim': 0.7434684889657157, 'train/loss': 0.2739727326801845, 'validation/ssim': 0.7247087760929586, 'validation/loss': 0.28626455157810743, 'validation/num_examples': 3554, 'test/ssim': 0.7419014307281485, 'test/loss': 0.2876473570362678, 'test/num_examples': 3581}
I0302 03:06:35.367885 139590035818240 logging_writer.py:48] [21817] global_step=21817, preemption_count=0, score=5148.291775, test/loss=0.287647, test/num_examples=3581, test/ssim=0.741901, total_duration=5668.742829, train/loss=0.273973, train/ssim=0.743468, validation/loss=0.286265, validation/num_examples=3554, validation/ssim=0.724709
I0302 03:06:35.388151 139915712112448 checkpoints.py:356] Saving checkpoint at step: 21817
I0302 03:06:35.573861 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_21817
I0302 03:06:35.574430 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_21817.
I0302 03:06:53.266531 139590019032832 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.40120911598205566, loss=0.2047387957572937
I0302 03:07:17.053559 139590027425536 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.37631773948669434, loss=0.27252012491226196
I0302 03:07:40.959194 139590019032832 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.22619086503982544, loss=0.3262808918952942
I0302 03:07:55.652019 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:07:57.061048 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:07:58.421883 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:07:59.780415 139915712112448 submission_runner.py:359] Time since start: 5753.16s, 	Step: 22164, 	{'train/ssim': 0.7443317004612514, 'train/loss': 0.26108368805476595, 'validation/ssim': 0.7251654578248101, 'validation/loss': 0.28572212180597567, 'validation/num_examples': 3554, 'test/ssim': 0.7424100967999512, 'test/loss': 0.2870805362721656, 'test/num_examples': 3581}
I0302 03:07:59.789865 139590027425536 logging_writer.py:48] [22164] global_step=22164, preemption_count=0, score=5228.042233, test/loss=0.287081, test/num_examples=3581, test/ssim=0.742410, total_duration=5753.160734, train/loss=0.261084, train/ssim=0.744332, validation/loss=0.285722, validation/num_examples=3554, validation/ssim=0.725165
I0302 03:07:59.816105 139915712112448 checkpoints.py:356] Saving checkpoint at step: 22164
I0302 03:07:59.968852 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_22164
I0302 03:07:59.969408 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_22164.
I0302 03:08:06.407967 139590019032832 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.24321722984313965, loss=0.30469727516174316
I0302 03:08:30.453494 139590035818240 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.3645208477973938, loss=0.26998117566108704
I0302 03:08:54.512198 139590019032832 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.28826281428337097, loss=0.32122802734375
I0302 03:09:18.989996 139590035818240 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.3384859561920166, loss=0.23773498833179474
I0302 03:09:20.047272 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:09:21.454153 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:09:22.810609 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:09:24.168782 139915712112448 submission_runner.py:359] Time since start: 5837.56s, 	Step: 22506, 	{'train/ssim': 0.7528704915727887, 'train/loss': 0.2639666795730591, 'validation/ssim': 0.7257712755434018, 'validation/loss': 0.2856162462465268, 'validation/num_examples': 3554, 'test/ssim': 0.7429919164295937, 'test/loss': 0.2869437738891022, 'test/num_examples': 3581}
I0302 03:09:24.178925 139590019032832 logging_writer.py:48] [22506] global_step=22506, preemption_count=0, score=5307.797541, test/loss=0.286944, test/num_examples=3581, test/ssim=0.742992, total_duration=5837.556020, train/loss=0.263967, train/ssim=0.752870, validation/loss=0.285616, validation/num_examples=3554, validation/ssim=0.725771
I0302 03:09:24.205519 139915712112448 checkpoints.py:356] Saving checkpoint at step: 22506
I0302 03:09:24.357243 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_22506
I0302 03:09:24.357755 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_22506.
I0302 03:09:44.850854 139590035818240 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.26623743772506714, loss=0.27552399039268494
I0302 03:10:09.111323 139590027425536 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.3181014060974121, loss=0.2227625846862793
I0302 03:10:33.111170 139590035818240 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.3037698268890381, loss=0.23775425553321838
I0302 03:10:44.400460 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:10:45.811253 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:10:47.165414 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:10:48.527446 139915712112448 submission_runner.py:359] Time since start: 5921.91s, 	Step: 22848, 	{'train/ssim': 0.7306479045322963, 'train/loss': 0.26438052313668386, 'validation/ssim': 0.7243115838887522, 'validation/loss': 0.28581260977397827, 'validation/num_examples': 3554, 'test/ssim': 0.7416356099247766, 'test/loss': 0.2871911869938565, 'test/num_examples': 3581}
I0302 03:10:48.537424 139590027425536 logging_writer.py:48] [22848] global_step=22848, preemption_count=0, score=5387.517241, test/loss=0.287191, test/num_examples=3581, test/ssim=0.741636, total_duration=5921.909206, train/loss=0.264381, train/ssim=0.730648, validation/loss=0.285813, validation/num_examples=3554, validation/ssim=0.724312
I0302 03:10:48.564500 139915712112448 checkpoints.py:356] Saving checkpoint at step: 22848
I0302 03:10:48.715533 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_22848
I0302 03:10:48.715956 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_22848.
I0302 03:10:59.237556 139590035818240 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.44374874234199524, loss=0.23082765936851501
I0302 03:11:23.249503 139590019032832 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.24259938299655914, loss=0.346851110458374
I0302 03:11:47.084612 139590035818240 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.2959200143814087, loss=0.22738075256347656
I0302 03:12:08.794656 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:12:10.203343 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:12:11.558473 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:12:12.916998 139915712112448 submission_runner.py:359] Time since start: 6006.30s, 	Step: 23192, 	{'train/ssim': 0.7457763808114188, 'train/loss': 0.26810583046504427, 'validation/ssim': 0.7238475518342009, 'validation/loss': 0.2860625207457706, 'validation/num_examples': 3554, 'test/ssim': 0.7412209594692474, 'test/loss': 0.2874011711114214, 'test/num_examples': 3581}
I0302 03:12:12.929271 139590019032832 logging_writer.py:48] [23192] global_step=23192, preemption_count=0, score=5467.271271, test/loss=0.287401, test/num_examples=3581, test/ssim=0.741221, total_duration=6006.303374, train/loss=0.268106, train/ssim=0.745776, validation/loss=0.286063, validation/num_examples=3554, validation/ssim=0.723848
I0302 03:12:12.949965 139915712112448 checkpoints.py:356] Saving checkpoint at step: 23192
I0302 03:12:13.145324 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_23192
I0302 03:12:13.145886 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_23192.
I0302 03:12:13.807977 139590035818240 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.278459757566452, loss=0.2505614161491394
I0302 03:12:36.940837 139590027425536 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.3064100444316864, loss=0.2739414572715759
I0302 03:13:01.024252 139590035818240 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.27858108282089233, loss=0.2655859887599945
I0302 03:13:25.418568 139590027425536 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.29904308915138245, loss=0.2614353597164154
I0302 03:13:33.390784 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:13:34.806182 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:13:36.168368 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:13:37.524909 139915712112448 submission_runner.py:359] Time since start: 6090.90s, 	Step: 23534, 	{'train/ssim': 0.7396838324410575, 'train/loss': 0.2783816541944231, 'validation/ssim': 0.7261285561822945, 'validation/loss': 0.28548017940832515, 'validation/num_examples': 3554, 'test/ssim': 0.7433863184166434, 'test/loss': 0.2867323921499756, 'test/num_examples': 3581}
I0302 03:13:37.534855 139590035818240 logging_writer.py:48] [23534] global_step=23534, preemption_count=0, score=5547.198360, test/loss=0.286732, test/num_examples=3581, test/ssim=0.743386, total_duration=6090.899531, train/loss=0.278382, train/ssim=0.739684, validation/loss=0.285480, validation/num_examples=3554, validation/ssim=0.726129
I0302 03:13:37.561183 139915712112448 checkpoints.py:356] Saving checkpoint at step: 23534
I0302 03:13:37.716881 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_23534
I0302 03:13:37.717326 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_23534.
I0302 03:13:51.212767 139590027425536 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.26632553339004517, loss=0.28522440791130066
I0302 03:14:15.522884 139590019032832 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.22067385911941528, loss=0.33289554715156555
I0302 03:14:40.030033 139590027425536 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.25508010387420654, loss=0.25955626368522644
I0302 03:14:57.966923 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:14:59.380747 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:15:00.737710 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:15:02.100080 139915712112448 submission_runner.py:359] Time since start: 6175.48s, 	Step: 23874, 	{'train/ssim': 0.7295436177934919, 'train/loss': 0.28571336609976633, 'validation/ssim': 0.7248272055914111, 'validation/loss': 0.2855212759555694, 'validation/num_examples': 3554, 'test/ssim': 0.7421349357939472, 'test/loss': 0.28684317922498953, 'test/num_examples': 3581}
I0302 03:15:02.110393 139590019032832 logging_writer.py:48] [23874] global_step=23874, preemption_count=0, score=5627.127336, test/loss=0.286843, test/num_examples=3581, test/ssim=0.742135, total_duration=6175.475660, train/loss=0.285713, train/ssim=0.729544, validation/loss=0.285521, validation/num_examples=3554, validation/ssim=0.724827
I0302 03:15:02.137011 139915712112448 checkpoints.py:356] Saving checkpoint at step: 23874
I0302 03:15:02.289376 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_23874
I0302 03:15:02.289798 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_23874.
I0302 03:15:06.378405 139590027425536 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.3276062607765198, loss=0.22944408655166626
I0302 03:15:30.113631 139590035818240 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.5818490982055664, loss=0.24601945281028748
I0302 03:15:53.925022 139590027425536 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.2381506711244583, loss=0.2789730727672577
I0302 03:16:17.571250 139590035818240 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.39066192507743835, loss=0.2135823369026184
I0302 03:16:22.450981 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:16:23.861383 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:16:25.215378 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:16:26.572300 139915712112448 submission_runner.py:359] Time since start: 6259.96s, 	Step: 24222, 	{'train/ssim': 0.7397308349609375, 'train/loss': 0.27566334179469515, 'validation/ssim': 0.7255228071583075, 'validation/loss': 0.2853322284035154, 'validation/num_examples': 3554, 'test/ssim': 0.7427121875872661, 'test/loss': 0.2866842935152541, 'test/num_examples': 3581}
I0302 03:16:26.582483 139590027425536 logging_writer.py:48] [24222] global_step=24222, preemption_count=0, score=5706.964847, test/loss=0.286684, test/num_examples=3581, test/ssim=0.742712, total_duration=6259.959719, train/loss=0.275663, train/ssim=0.739731, validation/loss=0.285332, validation/num_examples=3554, validation/ssim=0.725523
I0302 03:16:26.608610 139915712112448 checkpoints.py:356] Saving checkpoint at step: 24222
I0302 03:16:26.763197 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_24222
I0302 03:16:26.763670 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_24222.
I0302 03:16:43.423059 139590035818240 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.2793908715248108, loss=0.2907162308692932
I0302 03:17:07.266324 139590019032832 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.3255870044231415, loss=0.24761085212230682
I0302 03:17:31.125679 139590035818240 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.25962260365486145, loss=0.3023000657558441
I0302 03:17:46.814031 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:17:48.227941 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:17:49.581196 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:17:50.934530 139915712112448 submission_runner.py:359] Time since start: 6344.32s, 	Step: 24567, 	{'train/ssim': 0.742084094456264, 'train/loss': 0.2773745741162981, 'validation/ssim': 0.7257603531012592, 'validation/loss': 0.28516275881379255, 'validation/num_examples': 3554, 'test/ssim': 0.7430516391851089, 'test/loss': 0.2864481977363167, 'test/num_examples': 3581}
I0302 03:17:50.944983 139590019032832 logging_writer.py:48] [24567] global_step=24567, preemption_count=0, score=5786.689669, test/loss=0.286448, test/num_examples=3581, test/ssim=0.743052, total_duration=6344.322777, train/loss=0.277375, train/ssim=0.742084, validation/loss=0.285163, validation/num_examples=3554, validation/ssim=0.725760
I0302 03:17:50.971228 139915712112448 checkpoints.py:356] Saving checkpoint at step: 24567
I0302 03:17:51.122663 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_24567
I0302 03:17:51.123068 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_24567.
I0302 03:17:56.938333 139590035818240 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.282652348279953, loss=0.2809693515300751
I0302 03:18:20.616075 139590027425536 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.29215946793556213, loss=0.3345544934272766
I0302 03:18:44.922241 139590035818240 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.30891022086143494, loss=0.22996030747890472
I0302 03:19:09.073718 139590027425536 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.2542271912097931, loss=0.2932479679584503
I0302 03:19:11.151308 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:19:12.561963 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:19:13.915028 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:19:15.268789 139915712112448 submission_runner.py:359] Time since start: 6428.66s, 	Step: 24910, 	{'train/ssim': 0.7430941036769322, 'train/loss': 0.27792354992457796, 'validation/ssim': 0.7255961043014912, 'validation/loss': 0.284950818784732, 'validation/num_examples': 3554, 'test/ssim': 0.7428653805457623, 'test/loss': 0.2862345320790282, 'test/num_examples': 3581}
I0302 03:19:15.279481 139590035818240 logging_writer.py:48] [24910] global_step=24910, preemption_count=0, score=5866.398561, test/loss=0.286235, test/num_examples=3581, test/ssim=0.742865, total_duration=6428.660042, train/loss=0.277924, train/ssim=0.743094, validation/loss=0.284951, validation/num_examples=3554, validation/ssim=0.725596
I0302 03:19:15.306678 139915712112448 checkpoints.py:356] Saving checkpoint at step: 24910
I0302 03:19:15.459481 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_24910
I0302 03:19:15.459922 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_24910.
I0302 03:19:34.869472 139590027425536 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.24260313808918, loss=0.27058476209640503
I0302 03:19:58.613845 139590019032832 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.30491870641708374, loss=0.3130936324596405
I0302 03:20:22.164724 139590027425536 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.23233412206172943, loss=0.3366101086139679
I0302 03:20:35.604243 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:20:37.015594 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:20:38.369450 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:20:39.729588 139915712112448 submission_runner.py:359] Time since start: 6513.11s, 	Step: 25258, 	{'train/ssim': 0.7437185559953962, 'train/loss': 0.2664283173424857, 'validation/ssim': 0.7264150813783765, 'validation/loss': 0.28494690319226573, 'validation/num_examples': 3554, 'test/ssim': 0.7436237777288118, 'test/loss': 0.2862851532502269, 'test/num_examples': 3581}
I0302 03:20:39.740403 139590019032832 logging_writer.py:48] [25258] global_step=25258, preemption_count=0, score=5946.222469, test/loss=0.286285, test/num_examples=3581, test/ssim=0.743624, total_duration=6513.112962, train/loss=0.266428, train/ssim=0.743719, validation/loss=0.284947, validation/num_examples=3554, validation/ssim=0.726415
I0302 03:20:39.766669 139915712112448 checkpoints.py:356] Saving checkpoint at step: 25258
I0302 03:20:39.919297 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_25258
I0302 03:20:39.919721 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_25258.
I0302 03:20:47.834070 139590027425536 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.25876298546791077, loss=0.21966859698295593
I0302 03:21:11.866230 139590035818240 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.24623142182826996, loss=0.29500654339790344
I0302 03:21:35.785559 139590027425536 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.24798144400119781, loss=0.272619366645813
I0302 03:21:59.531625 139590035818240 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.22564764320850372, loss=0.2806839048862457
I0302 03:21:59.940694 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:22:01.357181 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:22:02.713102 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:22:04.074074 139915712112448 submission_runner.py:359] Time since start: 6597.45s, 	Step: 25603, 	{'train/ssim': 0.7491168294634137, 'train/loss': 0.2603654180254255, 'validation/ssim': 0.7261901065480796, 'validation/loss': 0.28491980317072313, 'validation/num_examples': 3554, 'test/ssim': 0.7434139299645699, 'test/loss': 0.2862444517832833, 'test/num_examples': 3581}
I0302 03:22:04.084183 139590027425536 logging_writer.py:48] [25603] global_step=25603, preemption_count=0, score=6025.926921, test/loss=0.286244, test/num_examples=3581, test/ssim=0.743414, total_duration=6597.449430, train/loss=0.260365, train/ssim=0.749117, validation/loss=0.284920, validation/num_examples=3554, validation/ssim=0.726190
I0302 03:22:04.110457 139915712112448 checkpoints.py:356] Saving checkpoint at step: 25603
I0302 03:22:04.261235 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_25603
I0302 03:22:04.261677 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_25603.
I0302 03:22:25.241858 139590035818240 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.2796953618526459, loss=0.25023967027664185
I0302 03:22:48.826781 139590019032832 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.3328306972980499, loss=0.31491851806640625
I0302 03:23:12.789313 139590035818240 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.2836064398288727, loss=0.2727264165878296
I0302 03:23:24.337795 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:23:25.748335 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:23:27.104053 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:23:28.463586 139915712112448 submission_runner.py:359] Time since start: 6681.85s, 	Step: 25948, 	{'train/ssim': 0.7520076887948173, 'train/loss': 0.26495511191231863, 'validation/ssim': 0.726618623492016, 'validation/loss': 0.2847220314038759, 'validation/num_examples': 3554, 'test/ssim': 0.74388414439926, 'test/loss': 0.2859982658584369, 'test/num_examples': 3581}
I0302 03:23:28.473632 139590019032832 logging_writer.py:48] [25948] global_step=25948, preemption_count=0, score=6105.679899, test/loss=0.285998, test/num_examples=3581, test/ssim=0.743884, total_duration=6681.846530, train/loss=0.264955, train/ssim=0.752008, validation/loss=0.284722, validation/num_examples=3554, validation/ssim=0.726619
I0302 03:23:28.500342 139915712112448 checkpoints.py:356] Saving checkpoint at step: 25948
I0302 03:23:28.653095 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_25948
I0302 03:23:28.653498 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_25948.
I0302 03:23:39.074726 139590035818240 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.35368093848228455, loss=0.23783859610557556
I0302 03:24:03.001020 139590027425536 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.23474162817001343, loss=0.2700634300708771
I0302 03:24:26.766749 139590035818240 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.2803909182548523, loss=0.332932710647583
I0302 03:24:48.811576 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:24:50.225731 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:24:51.588278 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:24:52.946778 139915712112448 submission_runner.py:359] Time since start: 6766.32s, 	Step: 26293, 	{'train/ssim': 0.7336794989449638, 'train/loss': 0.2651408740452358, 'validation/ssim': 0.7266215773600169, 'validation/loss': 0.28467655557558386, 'validation/num_examples': 3554, 'test/ssim': 0.7438034914086498, 'test/loss': 0.2860378424104649, 'test/num_examples': 3581}
I0302 03:24:52.958148 139590027425536 logging_writer.py:48] [26293] global_step=26293, preemption_count=0, score=6185.522095, test/loss=0.286038, test/num_examples=3581, test/ssim=0.743803, total_duration=6766.320322, train/loss=0.265141, train/ssim=0.733679, validation/loss=0.284677, validation/num_examples=3554, validation/ssim=0.726622
I0302 03:24:52.986674 139915712112448 checkpoints.py:356] Saving checkpoint at step: 26293
I0302 03:24:53.145653 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_26293
I0302 03:24:53.146095 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_26293.
I0302 03:24:53.734123 139590035818240 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.2446308732032776, loss=0.299105167388916
I0302 03:25:16.628068 139590019032832 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.2911442518234253, loss=0.2747412919998169
I0302 03:25:40.318904 139590035818240 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.2561882734298706, loss=0.23798364400863647
I0302 03:26:04.061347 139590019032832 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.249870166182518, loss=0.2732962369918823
I0302 03:26:13.225971 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:26:14.640893 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:26:15.994863 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:26:17.346296 139915712112448 submission_runner.py:359] Time since start: 6850.73s, 	Step: 26640, 	{'train/ssim': 0.7490513665335519, 'train/loss': 0.26346707344055176, 'validation/ssim': 0.7263763376213421, 'validation/loss': 0.2845012297708128, 'validation/num_examples': 3554, 'test/ssim': 0.7436519346900308, 'test/loss': 0.28579238938473017, 'test/num_examples': 3581}
I0302 03:26:17.356652 139590035818240 logging_writer.py:48] [26640] global_step=26640, preemption_count=0, score=6265.280235, test/loss=0.285792, test/num_examples=3581, test/ssim=0.743652, total_duration=6850.734718, train/loss=0.263467, train/ssim=0.749051, validation/loss=0.284501, validation/num_examples=3554, validation/ssim=0.726376
I0302 03:26:17.383941 139915712112448 checkpoints.py:356] Saving checkpoint at step: 26640
I0302 03:26:17.537603 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_26640
I0302 03:26:17.538043 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_26640.
I0302 03:26:29.695599 139590019032832 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.2821909785270691, loss=0.22680111229419708
I0302 03:26:53.736522 139590027425536 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.26404428482055664, loss=0.22807127237319946
I0302 03:27:17.768790 139590019032832 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.3010978102684021, loss=0.32149937748908997
I0302 03:27:37.630363 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:27:39.046122 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:27:40.405600 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:27:41.764018 139915712112448 submission_runner.py:359] Time since start: 6935.14s, 	Step: 26983, 	{'train/ssim': 0.7362876619611468, 'train/loss': 0.2790779897144863, 'validation/ssim': 0.7266112731693163, 'validation/loss': 0.28442733154983824, 'validation/num_examples': 3554, 'test/ssim': 0.7438127634346202, 'test/loss': 0.28571814500030546, 'test/num_examples': 3581}
I0302 03:27:41.776070 139590027425536 logging_writer.py:48] [26983] global_step=26983, preemption_count=0, score=6345.050931, test/loss=0.285718, test/num_examples=3581, test/ssim=0.743813, total_duration=6935.139114, train/loss=0.279078, train/ssim=0.736288, validation/loss=0.284427, validation/num_examples=3554, validation/ssim=0.726611
I0302 03:27:41.796294 139915712112448 checkpoints.py:356] Saving checkpoint at step: 26983
I0302 03:27:41.985642 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_26983
I0302 03:27:41.986190 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_26983.
I0302 03:27:44.026018 139590019032832 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.23409819602966309, loss=0.21978531777858734
I0302 03:28:07.816891 139590035818240 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.3547188341617584, loss=0.3588218688964844
I0302 03:28:31.854257 139590019032832 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.2633799612522125, loss=0.2698381543159485
I0302 03:28:55.931436 139590035818240 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.2753799855709076, loss=0.3006828725337982
I0302 03:29:02.062353 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:29:03.476929 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:29:04.833923 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:29:06.192185 139915712112448 submission_runner.py:359] Time since start: 7019.57s, 	Step: 27327, 	{'train/ssim': 0.7293259075709752, 'train/loss': 0.2874189444950649, 'validation/ssim': 0.7269812623100732, 'validation/loss': 0.28445752282859105, 'validation/num_examples': 3554, 'test/ssim': 0.7441627824150028, 'test/loss': 0.28576730037328085, 'test/num_examples': 3581}
I0302 03:29:06.202837 139590019032832 logging_writer.py:48] [27327] global_step=27327, preemption_count=0, score=6424.803192, test/loss=0.285767, test/num_examples=3581, test/ssim=0.744163, total_duration=7019.571090, train/loss=0.287419, train/ssim=0.729326, validation/loss=0.284458, validation/num_examples=3554, validation/ssim=0.726981
I0302 03:29:06.229354 139915712112448 checkpoints.py:356] Saving checkpoint at step: 27327
I0302 03:29:06.381359 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_27327
I0302 03:29:06.381779 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_27327.
I0302 03:29:21.951555 139590035818240 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.2247830182313919, loss=0.30996501445770264
I0302 03:29:46.137120 139590027425536 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.261558473110199, loss=0.2694624066352844
I0302 03:30:10.233420 139590035818240 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.2545336186885834, loss=0.24860109388828278
I0302 03:30:26.589985 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:30:28.005901 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:30:29.362861 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:30:30.716209 139915712112448 submission_runner.py:359] Time since start: 7104.10s, 	Step: 27669, 	{'train/ssim': 0.7469111851283482, 'train/loss': 0.2712784835270473, 'validation/ssim': 0.727038690999578, 'validation/loss': 0.28440912747960045, 'validation/num_examples': 3554, 'test/ssim': 0.7442169828609327, 'test/loss': 0.2857197471518518, 'test/num_examples': 3581}
I0302 03:30:30.727751 139590027425536 logging_writer.py:48] [27669] global_step=27669, preemption_count=0, score=6504.698726, test/loss=0.285720, test/num_examples=3581, test/ssim=0.744217, total_duration=7104.098731, train/loss=0.271278, train/ssim=0.746911, validation/loss=0.284409, validation/num_examples=3554, validation/ssim=0.727039
I0302 03:30:30.754203 139915712112448 checkpoints.py:356] Saving checkpoint at step: 27669
I0302 03:30:30.907408 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_27669
I0302 03:30:30.907821 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_27669.
I0302 03:30:36.284755 139590035818240 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.2555628716945648, loss=0.28202590346336365
I0302 03:31:00.117180 139590019032832 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.261848509311676, loss=0.2768528461456299
I0302 03:31:24.532923 139590035818240 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.23190060257911682, loss=0.32154595851898193
I0302 03:31:48.464351 139590019032832 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.25880739092826843, loss=0.28828319907188416
I0302 03:31:51.132201 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:31:52.544578 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:31:53.900412 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:31:55.262520 139915712112448 submission_runner.py:359] Time since start: 7188.64s, 	Step: 28012, 	{'train/ssim': 0.7419052805219378, 'train/loss': 0.28069818019866943, 'validation/ssim': 0.7270608793568866, 'validation/loss': 0.28440407842615717, 'validation/num_examples': 3554, 'test/ssim': 0.7442178009808713, 'test/loss': 0.28570652087951165, 'test/num_examples': 3581}
I0302 03:31:55.272907 139590035818240 logging_writer.py:48] [28012] global_step=28012, preemption_count=0, score=6584.606689, test/loss=0.285707, test/num_examples=3581, test/ssim=0.744218, total_duration=7188.640939, train/loss=0.280698, train/ssim=0.741905, validation/loss=0.284404, validation/num_examples=3554, validation/ssim=0.727061
I0302 03:31:55.300126 139915712112448 checkpoints.py:356] Saving checkpoint at step: 28012
I0302 03:31:55.455492 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_28012
I0302 03:31:55.455913 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_28012.
I0302 03:32:14.901745 139590019032832 logging_writer.py:48] [28100] global_step=28100, grad_norm=0.24556294083595276, loss=0.1761912703514099
I0302 03:32:38.700757 139590027425536 logging_writer.py:48] [28200] global_step=28200, grad_norm=0.2576165795326233, loss=0.3124735951423645
I0302 03:33:02.688179 139590019032832 logging_writer.py:48] [28300] global_step=28300, grad_norm=0.2620360255241394, loss=0.35465988516807556
I0302 03:33:15.675758 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:33:17.083085 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:33:18.438395 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:33:19.794173 139915712112448 submission_runner.py:359] Time since start: 7273.18s, 	Step: 28355, 	{'train/ssim': 0.7477944237845284, 'train/loss': 0.272686243057251, 'validation/ssim': 0.7270521551420934, 'validation/loss': 0.2844690635221757, 'validation/num_examples': 3554, 'test/ssim': 0.7441861670099135, 'test/loss': 0.28580103077658126, 'test/num_examples': 3581}
I0302 03:33:19.805234 139590027425536 logging_writer.py:48] [28355] global_step=28355, preemption_count=0, score=6664.507387, test/loss=0.285801, test/num_examples=3581, test/ssim=0.744186, total_duration=7273.184459, train/loss=0.272686, train/ssim=0.747794, validation/loss=0.284469, validation/num_examples=3554, validation/ssim=0.727052
I0302 03:33:19.832051 139915712112448 checkpoints.py:356] Saving checkpoint at step: 28355
I0302 03:33:19.985890 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_28355
I0302 03:33:19.986320 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_28355.
I0302 03:33:28.658129 139590019032832 logging_writer.py:48] [28400] global_step=28400, grad_norm=0.2303033322095871, loss=0.2451678216457367
I0302 03:33:52.514247 139590035818240 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.3001830577850342, loss=0.26052430272102356
I0302 03:34:16.409378 139590019032832 logging_writer.py:48] [28600] global_step=28600, grad_norm=0.3129040002822876, loss=0.29366588592529297
I0302 03:34:40.254897 139590035818240 logging_writer.py:48] [28700] global_step=28700, grad_norm=0.25032639503479004, loss=0.3128105700016022
I0302 03:34:40.258823 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:34:41.611306 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:34:42.965729 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:34:44.324147 139915712112448 submission_runner.py:359] Time since start: 7357.77s, 	Step: 28701, 	{'train/ssim': 0.7423764637538365, 'train/loss': 0.26366070338657926, 'validation/ssim': 0.726705659556134, 'validation/loss': 0.2844607686486617, 'validation/num_examples': 3554, 'test/ssim': 0.743913051303756, 'test/loss': 0.28579792873848087, 'test/num_examples': 3581}
I0302 03:34:44.335505 139590019032832 logging_writer.py:48] [28701] global_step=28701, preemption_count=0, score=6744.458938, test/loss=0.285798, test/num_examples=3581, test/ssim=0.743913, total_duration=7357.767594, train/loss=0.263661, train/ssim=0.742376, validation/loss=0.284461, validation/num_examples=3554, validation/ssim=0.726706
I0302 03:34:44.363543 139915712112448 checkpoints.py:356] Saving checkpoint at step: 28701
I0302 03:34:44.524498 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_28701
I0302 03:34:44.524972 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_28701.
I0302 03:35:06.426628 139590035818240 logging_writer.py:48] [28800] global_step=28800, grad_norm=0.3610185384750366, loss=0.2343551367521286
I0302 03:35:30.349563 139590027425536 logging_writer.py:48] [28900] global_step=28900, grad_norm=0.2919034957885742, loss=0.2915687561035156
I0302 03:35:54.388494 139590035818240 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.3011893033981323, loss=0.23122385144233704
I0302 03:36:04.730561 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:36:06.139763 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:36:07.497589 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:36:08.863924 139915712112448 submission_runner.py:359] Time since start: 7442.24s, 	Step: 29044, 	{'train/ssim': 0.7525337764195034, 'train/loss': 0.25751045772007536, 'validation/ssim': 0.7266383388435566, 'validation/loss': 0.2844665733427564, 'validation/num_examples': 3554, 'test/ssim': 0.7438510105417481, 'test/loss': 0.28575712500654493, 'test/num_examples': 3581}
I0302 03:36:08.874754 139590027425536 logging_writer.py:48] [29044] global_step=29044, preemption_count=0, score=6824.338840, test/loss=0.285757, test/num_examples=3581, test/ssim=0.743851, total_duration=7442.239293, train/loss=0.257510, train/ssim=0.752534, validation/loss=0.284467, validation/num_examples=3554, validation/ssim=0.726638
I0302 03:36:08.902387 139915712112448 checkpoints.py:356] Saving checkpoint at step: 29044
I0302 03:36:09.055561 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_29044
I0302 03:36:09.056009 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_29044.
I0302 03:36:20.409426 139590035818240 logging_writer.py:48] [29100] global_step=29100, grad_norm=0.3991084098815918, loss=0.26294681429862976
I0302 03:36:44.823318 139590019032832 logging_writer.py:48] [29200] global_step=29200, grad_norm=0.249113529920578, loss=0.26439541578292847
I0302 03:37:09.147925 139590035818240 logging_writer.py:48] [29300] global_step=29300, grad_norm=0.31442102789878845, loss=0.3153475522994995
I0302 03:37:29.161833 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:37:30.574708 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:37:31.934078 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:37:33.292140 139915712112448 submission_runner.py:359] Time since start: 7526.67s, 	Step: 29385, 	{'train/ssim': 0.7504747935703823, 'train/loss': 0.27070348603384836, 'validation/ssim': 0.7269673859999296, 'validation/loss': 0.2845018823695572, 'validation/num_examples': 3554, 'test/ssim': 0.7441354435737224, 'test/loss': 0.2858167625412332, 'test/num_examples': 3581}
I0302 03:37:33.302947 139590019032832 logging_writer.py:48] [29385] global_step=29385, preemption_count=0, score=6904.124021, test/loss=0.285817, test/num_examples=3581, test/ssim=0.744135, total_duration=7526.670565, train/loss=0.270703, train/ssim=0.750475, validation/loss=0.284502, validation/num_examples=3554, validation/ssim=0.726967
I0302 03:37:33.330083 139915712112448 checkpoints.py:356] Saving checkpoint at step: 29385
I0302 03:37:33.483526 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_29385
I0302 03:37:33.483936 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_29385.
I0302 03:37:34.927753 139590035818240 logging_writer.py:48] [29400] global_step=29400, grad_norm=0.2602022588253021, loss=0.3047400414943695
I0302 03:37:58.794251 139590027425536 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.29060080647468567, loss=0.21456344425678253
I0302 03:38:22.615249 139590035818240 logging_writer.py:48] [29600] global_step=29600, grad_norm=0.28843608498573303, loss=0.27893391251564026
I0302 03:38:46.547265 139590027425536 logging_writer.py:48] [29700] global_step=29700, grad_norm=0.3505290150642395, loss=0.3855753540992737
I0302 03:38:53.594120 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:38:55.006458 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:38:56.365483 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:38:57.720305 139915712112448 submission_runner.py:359] Time since start: 7611.10s, 	Step: 29731, 	{'train/ssim': 0.7370663370404925, 'train/loss': 0.2566635438374111, 'validation/ssim': 0.7267545701146595, 'validation/loss': 0.2844736317133863, 'validation/num_examples': 3554, 'test/ssim': 0.7439520483541608, 'test/loss': 0.2857998206408388, 'test/num_examples': 3581}
I0302 03:38:57.730852 139590035818240 logging_writer.py:48] [29731] global_step=29731, preemption_count=0, score=6983.911327, test/loss=0.285800, test/num_examples=3581, test/ssim=0.743952, total_duration=7611.102858, train/loss=0.256664, train/ssim=0.737066, validation/loss=0.284474, validation/num_examples=3554, validation/ssim=0.726755
I0302 03:38:57.760527 139915712112448 checkpoints.py:356] Saving checkpoint at step: 29731
I0302 03:38:57.919442 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_29731
I0302 03:38:57.919857 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_29731.
I0302 03:39:12.366152 139590027425536 logging_writer.py:48] [29800] global_step=29800, grad_norm=0.32932448387145996, loss=0.290178120136261
I0302 03:39:36.144307 139590019032832 logging_writer.py:48] [29900] global_step=29900, grad_norm=0.22285467386245728, loss=0.2989475131034851
I0302 03:39:59.943609 139590027425536 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.23425699770450592, loss=0.2755964398384094
I0302 03:40:18.006300 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:40:19.419250 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:40:20.775260 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:40:22.137385 139915712112448 submission_runner.py:359] Time since start: 7695.52s, 	Step: 30077, 	{'train/ssim': 0.7431699889046806, 'train/loss': 0.27530431747436523, 'validation/ssim': 0.726706689975204, 'validation/loss': 0.2844639114268254, 'validation/num_examples': 3554, 'test/ssim': 0.7439390266118053, 'test/loss': 0.28576021000047996, 'test/num_examples': 3581}
I0302 03:40:22.147977 139590019032832 logging_writer.py:48] [30077] global_step=30077, preemption_count=0, score=7063.669901, test/loss=0.285760, test/num_examples=3581, test/ssim=0.743939, total_duration=7695.515041, train/loss=0.275304, train/ssim=0.743170, validation/loss=0.284464, validation/num_examples=3554, validation/ssim=0.726707
I0302 03:40:22.175117 139915712112448 checkpoints.py:356] Saving checkpoint at step: 30077
I0302 03:40:22.329457 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_30077
I0302 03:40:22.329886 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_30077.
I0302 03:40:25.753137 139590027425536 logging_writer.py:48] [30100] global_step=30100, grad_norm=0.2944529056549072, loss=0.23934587836265564
I0302 03:40:49.673047 139590035818240 logging_writer.py:48] [30200] global_step=30200, grad_norm=0.34888893365859985, loss=0.19515758752822876
I0302 03:41:13.803144 139590027425536 logging_writer.py:48] [30300] global_step=30300, grad_norm=0.29403895139694214, loss=0.24724315106868744
I0302 03:41:37.802359 139590035818240 logging_writer.py:48] [30400] global_step=30400, grad_norm=0.311215877532959, loss=0.20378808677196503
I0302 03:41:42.489593 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:41:43.902968 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:41:45.264180 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:41:46.621906 139915712112448 submission_runner.py:359] Time since start: 7780.00s, 	Step: 30421, 	{'train/ssim': 0.7346618516104562, 'train/loss': 0.2791956492832729, 'validation/ssim': 0.726741312055958, 'validation/loss': 0.2845689798246694, 'validation/num_examples': 3554, 'test/ssim': 0.7439440716847598, 'test/loss': 0.28587196859292097, 'test/num_examples': 3581}
I0302 03:41:46.634149 139590027425536 logging_writer.py:48] [30421] global_step=30421, preemption_count=0, score=7143.505771, test/loss=0.285872, test/num_examples=3581, test/ssim=0.743944, total_duration=7779.998342, train/loss=0.279196, train/ssim=0.734662, validation/loss=0.284569, validation/num_examples=3554, validation/ssim=0.726741
I0302 03:41:46.654833 139915712112448 checkpoints.py:356] Saving checkpoint at step: 30421
I0302 03:41:46.849787 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_30421
I0302 03:41:46.850340 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_30421.
I0302 03:42:03.635455 139590035818240 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.27305328845977783, loss=0.2208167314529419
I0302 03:42:27.469162 139590019032832 logging_writer.py:48] [30600] global_step=30600, grad_norm=0.2885054349899292, loss=0.3637883961200714
I0302 03:42:51.401706 139590035818240 logging_writer.py:48] [30700] global_step=30700, grad_norm=0.30900219082832336, loss=0.23407748341560364
I0302 03:43:06.916626 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:43:08.327573 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:43:09.685760 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:43:11.040998 139915712112448 submission_runner.py:359] Time since start: 7864.43s, 	Step: 30766, 	{'train/ssim': 0.7350190026419503, 'train/loss': 0.2832580123628889, 'validation/ssim': 0.7267911156443444, 'validation/loss': 0.284531764522589, 'validation/num_examples': 3554, 'test/ssim': 0.7439836141484572, 'test/loss': 0.28587776360915246, 'test/num_examples': 3581}
I0302 03:43:11.052059 139590019032832 logging_writer.py:48] [30766] global_step=30766, preemption_count=0, score=7223.251319, test/loss=0.285878, test/num_examples=3581, test/ssim=0.743984, total_duration=7864.425346, train/loss=0.283258, train/ssim=0.735019, validation/loss=0.284532, validation/num_examples=3554, validation/ssim=0.726791
I0302 03:43:11.078380 139915712112448 checkpoints.py:356] Saving checkpoint at step: 30766
I0302 03:43:11.230894 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_30766
I0302 03:43:11.231304 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_30766.
I0302 03:43:17.257075 139590035818240 logging_writer.py:48] [30800] global_step=30800, grad_norm=0.3022122383117676, loss=0.3238323926925659
I0302 03:43:41.322902 139590027425536 logging_writer.py:48] [30900] global_step=30900, grad_norm=0.2747401297092438, loss=0.2091892957687378
I0302 03:44:05.270023 139590035818240 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.2702932059764862, loss=0.3099740743637085
I0302 03:44:29.043189 139590027425536 logging_writer.py:48] [31100] global_step=31100, grad_norm=0.2815912663936615, loss=0.1865004152059555
I0302 03:44:31.346501 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:44:32.760849 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:44:34.111903 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:44:35.467617 139915712112448 submission_runner.py:359] Time since start: 7948.86s, 	Step: 31111, 	{'train/ssim': 0.7455925941467285, 'train/loss': 0.27105060645512175, 'validation/ssim': 0.7269190249982415, 'validation/loss': 0.2844824589700865, 'validation/num_examples': 3554, 'test/ssim': 0.7440869017907009, 'test/loss': 0.2857846342894792, 'test/num_examples': 3581}
I0302 03:44:35.479022 139590035818240 logging_writer.py:48] [31111] global_step=31111, preemption_count=0, score=7303.040741, test/loss=0.285785, test/num_examples=3581, test/ssim=0.744087, total_duration=7948.855228, train/loss=0.271051, train/ssim=0.745593, validation/loss=0.284482, validation/num_examples=3554, validation/ssim=0.726919
I0302 03:44:35.506441 139915712112448 checkpoints.py:356] Saving checkpoint at step: 31111
I0302 03:44:35.659940 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_31111
I0302 03:44:35.660405 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_31111.
I0302 03:44:54.851655 139590027425536 logging_writer.py:48] [31200] global_step=31200, grad_norm=0.2652817964553833, loss=0.2844293415546417
I0302 03:45:19.370611 139590019032832 logging_writer.py:48] [31300] global_step=31300, grad_norm=0.31650054454803467, loss=0.35335904359817505
I0302 03:45:43.867522 139590027425536 logging_writer.py:48] [31400] global_step=31400, grad_norm=0.26149982213974, loss=0.20218995213508606
I0302 03:45:55.844807 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:45:57.252678 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:45:58.606662 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:45:59.964734 139915712112448 submission_runner.py:359] Time since start: 8033.35s, 	Step: 31451, 	{'train/ssim': 0.7409185682024274, 'train/loss': 0.28087001187460764, 'validation/ssim': 0.7265022548317037, 'validation/loss': 0.28456295187310954, 'validation/num_examples': 3554, 'test/ssim': 0.7437259063678092, 'test/loss': 0.28589259203303896, 'test/num_examples': 3581}
I0302 03:45:59.976600 139590019032832 logging_writer.py:48] [31451] global_step=31451, preemption_count=0, score=7382.900626, test/loss=0.285893, test/num_examples=3581, test/ssim=0.743726, total_duration=8033.353553, train/loss=0.280870, train/ssim=0.740919, validation/loss=0.284563, validation/num_examples=3554, validation/ssim=0.726502
I0302 03:46:00.003223 139915712112448 checkpoints.py:356] Saving checkpoint at step: 31451
I0302 03:46:00.155525 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_31451
I0302 03:46:00.155936 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_31451.
I0302 03:46:10.234418 139590027425536 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.31664901971817017, loss=0.23154278099536896
I0302 03:46:34.173730 139590035818240 logging_writer.py:48] [31600] global_step=31600, grad_norm=0.3160231113433838, loss=0.2238311469554901
I0302 03:46:58.219867 139590027425536 logging_writer.py:48] [31700] global_step=31700, grad_norm=0.2987075746059418, loss=0.3278156518936157
I0302 03:47:20.352107 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:47:21.761155 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:47:23.115728 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:47:24.471669 139915712112448 submission_runner.py:359] Time since start: 8117.86s, 	Step: 31792, 	{'train/ssim': 0.7459501538957868, 'train/loss': 0.27182929856436594, 'validation/ssim': 0.7268374158078925, 'validation/loss': 0.28453279494165906, 'validation/num_examples': 3554, 'test/ssim': 0.7440335194647095, 'test/loss': 0.2858595945288502, 'test/num_examples': 3581}
I0302 03:47:24.483101 139590035818240 logging_writer.py:48] [31792] global_step=31792, preemption_count=0, score=7462.779617, test/loss=0.285860, test/num_examples=3581, test/ssim=0.744034, total_duration=8117.860857, train/loss=0.271829, train/ssim=0.745950, validation/loss=0.284533, validation/num_examples=3554, validation/ssim=0.726837
I0302 03:47:24.509561 139915712112448 checkpoints.py:356] Saving checkpoint at step: 31792
I0302 03:47:24.662650 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_31792
I0302 03:47:24.663065 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_31792.
I0302 03:47:25.320476 139590027425536 logging_writer.py:48] [31800] global_step=31800, grad_norm=0.3677663803100586, loss=0.19893276691436768
I0302 03:47:48.432432 139590019032832 logging_writer.py:48] [31900] global_step=31900, grad_norm=0.31782224774360657, loss=0.27740585803985596
I0302 03:48:12.124503 139590027425536 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.2802424430847168, loss=0.24826088547706604
I0302 03:48:36.086001 139590019032832 logging_writer.py:48] [32100] global_step=32100, grad_norm=0.29503360390663147, loss=0.2865646481513977
I0302 03:48:44.715859 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:48:46.123745 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:48:47.478264 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:48:48.837903 139915712112448 submission_runner.py:359] Time since start: 8202.22s, 	Step: 32137, 	{'train/ssim': 0.7466423852103097, 'train/loss': 0.2605804715837751, 'validation/ssim': 0.72703930925102, 'validation/loss': 0.28451769930228266, 'validation/num_examples': 3554, 'test/ssim': 0.744217528274225, 'test/loss': 0.2858317443626082, 'test/num_examples': 3581}
I0302 03:48:48.848650 139590027425536 logging_writer.py:48] [32137] global_step=32137, preemption_count=0, score=7542.509768, test/loss=0.285832, test/num_examples=3581, test/ssim=0.744218, total_duration=8202.224610, train/loss=0.260580, train/ssim=0.746642, validation/loss=0.284518, validation/num_examples=3554, validation/ssim=0.727039
I0302 03:48:48.875679 139915712112448 checkpoints.py:356] Saving checkpoint at step: 32137
I0302 03:48:49.032746 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_32137
I0302 03:48:49.033199 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_32137.
I0302 03:49:01.995078 139590019032832 logging_writer.py:48] [32200] global_step=32200, grad_norm=0.29605698585510254, loss=0.3097316026687622
I0302 03:49:25.878097 139590035818240 logging_writer.py:48] [32300] global_step=32300, grad_norm=0.355117529630661, loss=0.25863900780677795
I0302 03:49:50.167719 139590019032832 logging_writer.py:48] [32400] global_step=32400, grad_norm=0.3110004663467407, loss=0.22612111270427704
I0302 03:50:09.092341 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:50:10.500091 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:50:11.855894 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:50:13.214252 139915712112448 submission_runner.py:359] Time since start: 8286.60s, 	Step: 32479, 	{'train/ssim': 0.7531042098999023, 'train/loss': 0.2595487322126116, 'validation/ssim': 0.7266214399708075, 'validation/loss': 0.2845176134340268, 'validation/num_examples': 3554, 'test/ssim': 0.7438471244720399, 'test/loss': 0.2858061440261973, 'test/num_examples': 3581}
I0302 03:50:13.225098 139590035818240 logging_writer.py:48] [32479] global_step=32479, preemption_count=0, score=7622.250522, test/loss=0.285806, test/num_examples=3581, test/ssim=0.743847, total_duration=8286.601069, train/loss=0.259549, train/ssim=0.753104, validation/loss=0.284518, validation/num_examples=3554, validation/ssim=0.726621
I0302 03:50:13.251303 139915712112448 checkpoints.py:356] Saving checkpoint at step: 32479
I0302 03:50:13.406750 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_32479
I0302 03:50:13.407154 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_32479.
I0302 03:50:16.296796 139590019032832 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.30414846539497375, loss=0.2760665714740753
I0302 03:50:40.346459 139590027425536 logging_writer.py:48] [32600] global_step=32600, grad_norm=0.2890274226665497, loss=0.2823602259159088
I0302 03:51:04.499105 139590019032832 logging_writer.py:48] [32700] global_step=32700, grad_norm=0.3468984365463257, loss=0.26441389322280884
I0302 03:51:28.255957 139590027425536 logging_writer.py:48] [32800] global_step=32800, grad_norm=0.285163938999176, loss=0.26774144172668457
I0302 03:51:33.656128 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:51:35.067758 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:51:36.422158 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:51:37.778565 139915712112448 submission_runner.py:359] Time since start: 8371.16s, 	Step: 32824, 	{'train/ssim': 0.750568185533796, 'train/loss': 0.26950892380305697, 'validation/ssim': 0.7267238636263716, 'validation/loss': 0.28455304267638576, 'validation/num_examples': 3554, 'test/ssim': 0.7438981887915387, 'test/loss': 0.28589262612136973, 'test/num_examples': 3581}
I0302 03:51:37.791245 139590019032832 logging_writer.py:48] [32824] global_step=32824, preemption_count=0, score=7702.177709, test/loss=0.285893, test/num_examples=3581, test/ssim=0.743898, total_duration=8371.164874, train/loss=0.269509, train/ssim=0.750568, validation/loss=0.284553, validation/num_examples=3554, validation/ssim=0.726724
I0302 03:51:37.812470 139915712112448 checkpoints.py:356] Saving checkpoint at step: 32824
I0302 03:51:38.000279 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_32824
I0302 03:51:38.000838 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_32824.
I0302 03:51:54.390150 139590027425536 logging_writer.py:48] [32900] global_step=32900, grad_norm=0.34441596269607544, loss=0.22587436437606812
I0302 03:52:18.335283 139590035818240 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.3252822458744049, loss=0.27241528034210205
I0302 03:52:42.631221 139590027425536 logging_writer.py:48] [33100] global_step=33100, grad_norm=0.35938042402267456, loss=0.31365594267845154
I0302 03:52:58.210909 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:52:59.620194 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:53:00.978541 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:53:02.337522 139915712112448 submission_runner.py:359] Time since start: 8455.72s, 	Step: 33166, 	{'train/ssim': 0.7340775217328753, 'train/loss': 0.2582530805042812, 'validation/ssim': 0.7266601150332372, 'validation/loss': 0.2845718649980656, 'validation/num_examples': 3554, 'test/ssim': 0.7438710544802429, 'test/loss': 0.28588272346128, 'test/num_examples': 3581}
I0302 03:53:02.348369 139590035818240 logging_writer.py:48] [33166] global_step=33166, preemption_count=0, score=7782.067092, test/loss=0.285883, test/num_examples=3581, test/ssim=0.743871, total_duration=8455.719643, train/loss=0.258253, train/ssim=0.734078, validation/loss=0.284572, validation/num_examples=3554, validation/ssim=0.726660
I0302 03:53:02.375948 139915712112448 checkpoints.py:356] Saving checkpoint at step: 33166
I0302 03:53:02.532628 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_33166
I0302 03:53:02.533087 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_33166.
I0302 03:53:08.405269 139590027425536 logging_writer.py:48] [33200] global_step=33200, grad_norm=0.3352970778942108, loss=0.25588366389274597
I0302 03:53:32.124123 139590019032832 logging_writer.py:48] [33300] global_step=33300, grad_norm=0.34873896837234497, loss=0.2622145712375641
I0302 03:53:56.094914 139590027425536 logging_writer.py:48] [33400] global_step=33400, grad_norm=0.34849876165390015, loss=0.27064254879951477
I0302 03:54:20.216769 139590019032832 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.2778400480747223, loss=0.24875634908676147
I0302 03:54:22.580792 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:54:23.996455 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:54:25.352569 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:54:26.711733 139915712112448 submission_runner.py:359] Time since start: 8540.09s, 	Step: 33510, 	{'train/ssim': 0.7421445165361676, 'train/loss': 0.2783117634909494, 'validation/ssim': 0.7272397601074494, 'validation/loss': 0.2845718993453679, 'validation/num_examples': 3554, 'test/ssim': 0.7443729028858909, 'test/loss': 0.28589320562299286, 'test/num_examples': 3581}
I0302 03:54:26.722814 139590027425536 logging_writer.py:48] [33510] global_step=33510, preemption_count=0, score=7861.790159, test/loss=0.285893, test/num_examples=3581, test/ssim=0.744373, total_duration=8540.089530, train/loss=0.278312, train/ssim=0.742145, validation/loss=0.284572, validation/num_examples=3554, validation/ssim=0.727240
I0302 03:54:26.750605 139915712112448 checkpoints.py:356] Saving checkpoint at step: 33510
I0302 03:54:26.904438 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_33510
I0302 03:54:26.904860 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_33510.
I0302 03:54:46.522307 139590019032832 logging_writer.py:48] [33600] global_step=33600, grad_norm=0.3334099352359772, loss=0.39537712931632996
I0302 03:55:10.890828 139590035818240 logging_writer.py:48] [33700] global_step=33700, grad_norm=0.35056522488594055, loss=0.2864459156990051
I0302 03:55:34.668271 139590019032832 logging_writer.py:48] [33800] global_step=33800, grad_norm=0.3851659893989563, loss=0.34689316153526306
I0302 03:55:46.975757 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:55:48.392222 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:55:49.748087 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:55:51.106604 139915712112448 submission_runner.py:359] Time since start: 8624.48s, 	Step: 33853, 	{'train/ssim': 0.7332722118922642, 'train/loss': 0.281471848487854, 'validation/ssim': 0.7268323324071468, 'validation/loss': 0.2845601525679692, 'validation/num_examples': 3554, 'test/ssim': 0.7439896136946733, 'test/loss': 0.28591388019560704, 'test/num_examples': 3581}
I0302 03:55:51.119455 139590035818240 logging_writer.py:48] [33853] global_step=33853, preemption_count=0, score=7941.540546, test/loss=0.285914, test/num_examples=3581, test/ssim=0.743990, total_duration=8624.484503, train/loss=0.281472, train/ssim=0.733272, validation/loss=0.284560, validation/num_examples=3554, validation/ssim=0.726832
I0302 03:55:51.140027 139915712112448 checkpoints.py:356] Saving checkpoint at step: 33853
I0302 03:55:51.331549 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_33853
I0302 03:55:51.332126 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_33853.
I0302 03:56:00.496822 139590019032832 logging_writer.py:48] [33900] global_step=33900, grad_norm=0.2883930504322052, loss=0.24026131629943848
I0302 03:56:24.502479 139590027425536 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.3280087113380432, loss=0.28974857926368713
I0302 03:56:48.228071 139590019032832 logging_writer.py:48] [34100] global_step=34100, grad_norm=0.35599610209465027, loss=0.2770974636077881
I0302 03:57:11.452346 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:57:12.864618 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:57:14.220157 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:57:15.574559 139915712112448 submission_runner.py:359] Time since start: 8708.96s, 	Step: 34199, 	{'train/ssim': 0.7411680902753558, 'train/loss': 0.2750984600612095, 'validation/ssim': 0.7264695561998804, 'validation/loss': 0.2845659916093662, 'validation/num_examples': 3554, 'test/ssim': 0.7437061351359606, 'test/loss': 0.2858594581755271, 'test/num_examples': 3581}
I0302 03:57:15.586251 139590027425536 logging_writer.py:48] [34199] global_step=34199, preemption_count=0, score=8021.334625, test/loss=0.285859, test/num_examples=3581, test/ssim=0.743706, total_duration=8708.961094, train/loss=0.275098, train/ssim=0.741168, validation/loss=0.284566, validation/num_examples=3554, validation/ssim=0.726470
I0302 03:57:15.613633 139915712112448 checkpoints.py:356] Saving checkpoint at step: 34199
I0302 03:57:15.767979 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_34199
I0302 03:57:15.768398 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_34199.
I0302 03:57:15.926077 139590019032832 logging_writer.py:48] [34200] global_step=34200, grad_norm=0.32520031929016113, loss=0.25982338190078735
I0302 03:57:37.909050 139590035818240 logging_writer.py:48] [34300] global_step=34300, grad_norm=0.38337600231170654, loss=0.2831208407878876
I0302 03:58:01.668272 139590019032832 logging_writer.py:48] [34400] global_step=34400, grad_norm=0.31731346249580383, loss=0.26148268580436707
I0302 03:58:25.179066 139590035818240 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.35747748613357544, loss=0.300947368144989
I0302 03:58:35.874928 139915712112448 spec.py:298] Evaluating on the training split.
I0302 03:58:37.285704 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 03:58:38.643544 139915712112448 spec.py:326] Evaluating on the test split.
I0302 03:58:40.001004 139915712112448 submission_runner.py:359] Time since start: 8793.38s, 	Step: 34546, 	{'train/ssim': 0.7426195825849261, 'train/loss': 0.275631274495806, 'validation/ssim': 0.7266281720420653, 'validation/loss': 0.28461830255082304, 'validation/num_examples': 3554, 'test/ssim': 0.7437914923162176, 'test/loss': 0.2859204421992809, 'test/num_examples': 3581}
I0302 03:58:40.012718 139590019032832 logging_writer.py:48] [34546] global_step=34546, preemption_count=0, score=8101.111959, test/loss=0.285920, test/num_examples=3581, test/ssim=0.743791, total_duration=8793.383621, train/loss=0.275631, train/ssim=0.742620, validation/loss=0.284618, validation/num_examples=3554, validation/ssim=0.726628
I0302 03:58:40.040690 139915712112448 checkpoints.py:356] Saving checkpoint at step: 34546
I0302 03:58:40.196060 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_34546
I0302 03:58:40.196485 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_34546.
I0302 03:58:51.550731 139590035818240 logging_writer.py:48] [34600] global_step=34600, grad_norm=0.3537510931491852, loss=0.2163313776254654
I0302 03:59:15.491377 139590027425536 logging_writer.py:48] [34700] global_step=34700, grad_norm=0.9007351398468018, loss=0.43768569827079773
I0302 03:59:39.517932 139590035818240 logging_writer.py:48] [34800] global_step=34800, grad_norm=0.3427989184856415, loss=0.2963075041770935
I0302 04:00:00.334871 139915712112448 spec.py:298] Evaluating on the training split.
I0302 04:00:01.750051 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 04:00:03.107984 139915712112448 spec.py:326] Evaluating on the test split.
I0302 04:00:04.465587 139915712112448 submission_runner.py:359] Time since start: 8877.84s, 	Step: 34889, 	{'train/ssim': 0.7431909016200474, 'train/loss': 0.27897143363952637, 'validation/ssim': 0.7265249927458497, 'validation/loss': 0.28467227933644307, 'validation/num_examples': 3554, 'test/ssim': 0.743702180889591, 'test/loss': 0.28598906200912805, 'test/num_examples': 3581}
I0302 04:00:04.478786 139590027425536 logging_writer.py:48] [34889] global_step=34889, preemption_count=0, score=8180.931327, test/loss=0.285989, test/num_examples=3581, test/ssim=0.743702, total_duration=8877.843622, train/loss=0.278971, train/ssim=0.743191, validation/loss=0.284672, validation/num_examples=3554, validation/ssim=0.726525
I0302 04:00:04.499368 139915712112448 checkpoints.py:356] Saving checkpoint at step: 34889
I0302 04:00:04.694847 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_34889
I0302 04:00:04.695419 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_34889.
I0302 04:00:05.574139 139590035818240 logging_writer.py:48] [34900] global_step=34900, grad_norm=0.36940163373947144, loss=0.3535005450248718
I0302 04:00:29.197300 139590019032832 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.41797107458114624, loss=0.25043362379074097
I0302 04:00:52.774856 139590035818240 logging_writer.py:48] [35100] global_step=35100, grad_norm=0.4152856767177582, loss=0.248771533370018
I0302 04:01:16.462721 139590019032832 logging_writer.py:48] [35200] global_step=35200, grad_norm=0.3354796767234802, loss=0.23445583879947662
I0302 04:01:24.752075 139915712112448 spec.py:298] Evaluating on the training split.
I0302 04:01:26.159945 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 04:01:27.515132 139915712112448 spec.py:326] Evaluating on the test split.
I0302 04:01:28.871558 139915712112448 submission_runner.py:359] Time since start: 8962.26s, 	Step: 35236, 	{'train/ssim': 0.744368416922433, 'train/loss': 0.2698590244565691, 'validation/ssim': 0.7268087701577448, 'validation/loss': 0.2845668846392269, 'validation/num_examples': 3554, 'test/ssim': 0.7439990902506283, 'test/loss': 0.28588974565741937, 'test/num_examples': 3581}
I0302 04:01:28.882890 139590035818240 logging_writer.py:48] [35236] global_step=35236, preemption_count=0, score=8260.666568, test/loss=0.285890, test/num_examples=3581, test/ssim=0.743999, total_duration=8962.260824, train/loss=0.269859, train/ssim=0.744368, validation/loss=0.284567, validation/num_examples=3554, validation/ssim=0.726809
I0302 04:01:28.909150 139915712112448 checkpoints.py:356] Saving checkpoint at step: 35236
I0302 04:01:29.064828 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_35236
I0302 04:01:29.065223 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_35236.
I0302 04:01:42.250750 139590019032832 logging_writer.py:48] [35300] global_step=35300, grad_norm=0.3329314589500427, loss=0.2943642735481262
I0302 04:02:06.289535 139590027425536 logging_writer.py:48] [35400] global_step=35400, grad_norm=0.29955679178237915, loss=0.2697279155254364
I0302 04:02:30.076711 139590019032832 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.29710420966148376, loss=0.3024279773235321
I0302 04:02:49.298361 139915712112448 spec.py:298] Evaluating on the training split.
I0302 04:02:50.708911 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 04:02:52.061707 139915712112448 spec.py:326] Evaluating on the test split.
I0302 04:02:53.413645 139915712112448 submission_runner.py:359] Time since start: 9046.81s, 	Step: 35582, 	{'train/ssim': 0.7490621294294085, 'train/loss': 0.2568952866962978, 'validation/ssim': 0.7266555811893289, 'validation/loss': 0.28462833196310494, 'validation/num_examples': 3554, 'test/ssim': 0.7438124907279741, 'test/loss': 0.28593714548135996, 'test/num_examples': 3581}
I0302 04:02:53.426296 139590027425536 logging_writer.py:48] [35582] global_step=35582, preemption_count=0, score=8340.574032, test/loss=0.285937, test/num_examples=3581, test/ssim=0.743812, total_duration=9046.807101, train/loss=0.256895, train/ssim=0.749062, validation/loss=0.284628, validation/num_examples=3554, validation/ssim=0.726656
I0302 04:02:53.453431 139915712112448 checkpoints.py:356] Saving checkpoint at step: 35582
I0302 04:02:53.609289 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_35582
I0302 04:02:53.609742 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_35582.
I0302 04:02:55.803100 139590019032832 logging_writer.py:48] [35600] global_step=35600, grad_norm=0.3726412355899811, loss=0.2311776578426361
I0302 04:03:20.346204 139590035818240 logging_writer.py:48] [35700] global_step=35700, grad_norm=0.3783859312534332, loss=0.20354823768138885
I0302 04:03:44.218822 139590019032832 logging_writer.py:48] [35800] global_step=35800, grad_norm=0.6249403953552246, loss=0.38582244515419006
I0302 04:04:08.245278 139590035818240 logging_writer.py:48] [35900] global_step=35900, grad_norm=0.28101152181625366, loss=0.22423386573791504
I0302 04:04:13.725614 139915712112448 spec.py:298] Evaluating on the training split.
I0302 04:04:15.140688 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 04:04:16.497527 139915712112448 spec.py:326] Evaluating on the test split.
I0302 04:04:17.856352 139915712112448 submission_runner.py:359] Time since start: 9131.23s, 	Step: 35924, 	{'train/ssim': 0.7537999153137207, 'train/loss': 0.26463004520961214, 'validation/ssim': 0.7267942069015546, 'validation/loss': 0.28470707315370886, 'validation/num_examples': 3554, 'test/ssim': 0.743905074634355, 'test/loss': 0.2860466371998045, 'test/num_examples': 3581}
I0302 04:04:17.867599 139590019032832 logging_writer.py:48] [35924] global_step=35924, preemption_count=0, score=8420.371723, test/loss=0.286047, test/num_examples=3581, test/ssim=0.743905, total_duration=9131.234361, train/loss=0.264630, train/ssim=0.753800, validation/loss=0.284707, validation/num_examples=3554, validation/ssim=0.726794
I0302 04:04:17.893799 139915712112448 checkpoints.py:356] Saving checkpoint at step: 35924
I0302 04:04:18.049332 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_35924
I0302 04:04:18.049776 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_35924.
I0302 04:04:34.337975 139590035818240 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.36371085047721863, loss=0.2304445058107376
I0302 04:04:58.432025 139590027425536 logging_writer.py:48] [36100] global_step=36100, grad_norm=0.3527926802635193, loss=0.2505263686180115
I0302 04:05:19.274615 139915712112448 spec.py:298] Evaluating on the training split.
I0302 04:05:20.682598 139915712112448 spec.py:310] Evaluating on the validation split.
I0302 04:05:22.036998 139915712112448 spec.py:326] Evaluating on the test split.
I0302 04:05:23.401703 139915712112448 submission_runner.py:359] Time since start: 9196.78s, 	Step: 36189, 	{'train/ssim': 0.7339744567871094, 'train/loss': 0.26372272627694265, 'validation/ssim': 0.7268813803548818, 'validation/loss': 0.2846497131588087, 'validation/num_examples': 3554, 'test/ssim': 0.7440500182168039, 'test/loss': 0.2860044358463069, 'test/num_examples': 3581}
I0302 04:05:23.413305 139590035818240 logging_writer.py:48] [36189] global_step=36189, preemption_count=0, score=8481.344740, test/loss=0.286004, test/num_examples=3581, test/ssim=0.744050, total_duration=9196.783359, train/loss=0.263723, train/ssim=0.733974, validation/loss=0.284650, validation/num_examples=3554, validation/ssim=0.726881
I0302 04:05:23.440977 139915712112448 checkpoints.py:356] Saving checkpoint at step: 36189
I0302 04:05:23.601105 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_36189
I0302 04:05:23.601526 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_36189.
I0302 04:05:23.611395 139590027425536 logging_writer.py:48] [36189] global_step=36189, preemption_count=0, score=8481.344740
I0302 04:05:23.634884 139915712112448 checkpoints.py:356] Saving checkpoint at step: 36189
I0302 04:05:23.869830 139915712112448 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_36189
I0302 04:05:23.870271 139915712112448 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing/fastmri_jax/trial_1/checkpoint_36189.
I0302 04:05:24.230199 139915712112448 submission_runner.py:520] Tuning trial 1/1
I0302 04:05:24.230406 139915712112448 submission_runner.py:521] Hyperparameters: Hyperparameters(learning_rate=0.028609, beta1=0.981543, warmup_steps=1357, decay_steps_factor=0.984398, end_factor=0.01, weight_decay=0.000576)
I0302 04:05:24.257447 139915712112448 submission_runner.py:522] Metrics: {'eval_results': [(1, {'train/ssim': 0.18789427621023996, 'train/loss': 1.0984931673322404, 'validation/ssim': 0.1809655631199001, 'validation/loss': 1.1008112558033203, 'validation/num_examples': 3554, 'test/ssim': 0.20369739420618369, 'test/loss': 1.0969732562046217, 'test/num_examples': 3581, 'score': 41.398505210876465, 'total_duration': 41.5205500125885, 'global_step': 1, 'preemption_count': 0}), (344, {'train/ssim': 0.6813851084027972, 'train/loss': 0.333465508052281, 'validation/ssim': 0.6676634024822383, 'validation/loss': 0.34051345370093555, 'validation/num_examples': 3554, 'test/ssim': 0.6866580864065555, 'test/loss': 0.3416468181679349, 'test/num_examples': 3581, 'score': 121.07085180282593, 'total_duration': 291.24738788604736, 'global_step': 344, 'preemption_count': 0}), (652, {'train/ssim': 0.6940059661865234, 'train/loss': 0.318281888961792, 'validation/ssim': 0.6903933480541291, 'validation/loss': 0.3168203067296532, 'validation/num_examples': 3554, 'test/ssim': 0.7082901320554663, 'test/loss': 0.31852964621221375, 'test/num_examples': 3581, 'score': 200.65218377113342, 'total_duration': 384.24955010414124, 'global_step': 652, 'preemption_count': 0}), (846, {'train/ssim': 0.7104338918413434, 'train/loss': 0.30027481487819124, 'validation/ssim': 0.6968724170828644, 'validation/loss': 0.30940688803548816, 'validation/num_examples': 3554, 'test/ssim': 0.7146659452666853, 'test/loss': 0.3110776984868054, 'test/num_examples': 3581, 'score': 280.51303267478943, 'total_duration': 476.4844226837158, 'global_step': 846, 'preemption_count': 0}), (1084, {'train/ssim': 0.7154936790466309, 'train/loss': 0.2975177764892578, 'validation/ssim': 0.7006745947567882, 'validation/loss': 0.30375400901712857, 'validation/num_examples': 3554, 'test/ssim': 0.7179700589919017, 'test/loss': 0.30548782582990086, 'test/num_examples': 3581, 'score': 360.3765687942505, 'total_duration': 568.8982229232788, 'global_step': 1084, 'preemption_count': 0}), (1408, {'train/ssim': 0.7248620305742536, 'train/loss': 0.29473400115966797, 'validation/ssim': 0.7081991269740081, 'validation/loss': 0.30017725268843204, 'validation/num_examples': 3554, 'test/ssim': 0.7252759382199455, 'test/loss': 0.30199162436077565, 'test/num_examples': 3581, 'score': 440.1560471057892, 'total_duration': 661.0642216205597, 'global_step': 1408, 'preemption_count': 0}), (1732, {'train/ssim': 0.7268259865897042, 'train/loss': 0.27910947799682617, 'validation/ssim': 0.7102113293340251, 'validation/loss': 0.29668100643640966, 'validation/num_examples': 3554, 'test/ssim': 0.7273779610487643, 'test/loss': 0.2983653759097494, 'test/num_examples': 3581, 'score': 519.9329378604889, 'total_duration': 753.8603932857513, 'global_step': 1732, 'preemption_count': 0}), (2050, {'train/ssim': 0.7077398300170898, 'train/loss': 0.2864923817770822, 'validation/ssim': 0.6934004543735931, 'validation/loss': 0.30792775580771664, 'validation/num_examples': 3554, 'test/ssim': 0.7095427418580704, 'test/loss': 0.3093622373289584, 'test/num_examples': 3581, 'score': 599.7182402610779, 'total_duration': 846.3330774307251, 'global_step': 2050, 'preemption_count': 0}), (2380, {'train/ssim': 0.73947845186506, 'train/loss': 0.2753781591142927, 'validation/ssim': 0.7155793318268149, 'validation/loss': 0.29323116338984245, 'validation/num_examples': 3554, 'test/ssim': 0.7324267837196314, 'test/loss': 0.29507735187665807, 'test/num_examples': 3581, 'score': 679.4975454807281, 'total_duration': 939.0015451908112, 'global_step': 2380, 'preemption_count': 0}), (2726, {'train/ssim': 0.722844123840332, 'train/loss': 0.2736499309539795, 'validation/ssim': 0.7170002110298256, 'validation/loss': 0.29189144686225027, 'validation/num_examples': 3554, 'test/ssim': 0.7340125046905543, 'test/loss': 0.29353669567901775, 'test/num_examples': 3581, 'score': 759.3026208877563, 'total_duration': 1024.04714179039, 'global_step': 2726, 'preemption_count': 0}), (3072, {'train/ssim': 0.7383990968976702, 'train/loss': 0.27230184418814524, 'validation/ssim': 0.7176478637626618, 'validation/loss': 0.2917685522144942, 'validation/num_examples': 3554, 'test/ssim': 0.7349857947108001, 'test/loss': 0.29323317318181025, 'test/num_examples': 3581, 'score': 839.0994930267334, 'total_duration': 1108.5385220050812, 'global_step': 3072, 'preemption_count': 0}), (3415, {'train/ssim': 0.7267757143293109, 'train/loss': 0.28714026723589214, 'validation/ssim': 0.7185622576454347, 'validation/loss': 0.29108802911332304, 'validation/num_examples': 3554, 'test/ssim': 0.7357952562133482, 'test/loss': 0.29249246784243227, 'test/num_examples': 3581, 'score': 918.7927746772766, 'total_duration': 1192.8722233772278, 'global_step': 3415, 'preemption_count': 0}), (3764, {'train/ssim': 0.7187568119594029, 'train/loss': 0.2959432601928711, 'validation/ssim': 0.7168086217773987, 'validation/loss': 0.2923096252681837, 'validation/num_examples': 3554, 'test/ssim': 0.733796998263404, 'test/loss': 0.2939709128364109, 'test/num_examples': 3581, 'score': 998.6424341201782, 'total_duration': 1277.3656656742096, 'global_step': 3764, 'preemption_count': 0}), (4110, {'train/ssim': 0.7413531712123326, 'train/loss': 0.27809098788670134, 'validation/ssim': 0.7228128050040448, 'validation/loss': 0.28994282135885624, 'validation/num_examples': 3554, 'test/ssim': 0.7397060740496719, 'test/loss': 0.2915075877897235, 'test/num_examples': 3581, 'score': 1078.546887397766, 'total_duration': 1362.2778553962708, 'global_step': 4110, 'preemption_count': 0}), (4453, {'train/ssim': 0.7343431200299945, 'train/loss': 0.2878243923187256, 'validation/ssim': 0.7203180917408202, 'validation/loss': 0.29026946420406585, 'validation/num_examples': 3554, 'test/ssim': 0.7375517597214465, 'test/loss': 0.29177470394966487, 'test/num_examples': 3581, 'score': 1158.4770390987396, 'total_duration': 1446.8355045318604, 'global_step': 4453, 'preemption_count': 0}), (4799, {'train/ssim': 0.7320254870823452, 'train/loss': 0.2829779386520386, 'validation/ssim': 0.7135823109744303, 'validation/loss': 0.29312901451269696, 'validation/num_examples': 3554, 'test/ssim': 0.7308024747582729, 'test/loss': 0.29439694879441847, 'test/num_examples': 3581, 'score': 1238.2053110599518, 'total_duration': 1531.1840834617615, 'global_step': 4799, 'preemption_count': 0}), (5146, {'train/ssim': 0.7356536047799247, 'train/loss': 0.2693652936390468, 'validation/ssim': 0.7205893667346651, 'validation/loss': 0.2893341184668683, 'validation/num_examples': 3554, 'test/ssim': 0.7378603272916084, 'test/loss': 0.29079292593505657, 'test/num_examples': 3581, 'score': 1318.029844045639, 'total_duration': 1615.6506071090698, 'global_step': 5146, 'preemption_count': 0}), (5489, {'train/ssim': 0.7465353693280902, 'train/loss': 0.26449292046683176, 'validation/ssim': 0.7221417961056205, 'validation/loss': 0.29033747186268993, 'validation/num_examples': 3554, 'test/ssim': 0.7390551232852206, 'test/loss': 0.2918963992905264, 'test/num_examples': 3581, 'score': 1397.721910238266, 'total_duration': 1699.9716258049011, 'global_step': 5489, 'preemption_count': 0}), (5836, {'train/ssim': 0.7426540510995048, 'train/loss': 0.277286171913147, 'validation/ssim': 0.7203687883590673, 'validation/loss': 0.28958935327052265, 'validation/num_examples': 3554, 'test/ssim': 0.7375546231412315, 'test/loss': 0.2911408996155927, 'test/num_examples': 3581, 'score': 1477.524584054947, 'total_duration': 1784.4290778636932, 'global_step': 5836, 'preemption_count': 0}), (6181, {'train/ssim': 0.7307814870561872, 'train/loss': 0.26315663542066303, 'validation/ssim': 0.7216040547402575, 'validation/loss': 0.2896250057703468, 'validation/num_examples': 3554, 'test/ssim': 0.7389070435763404, 'test/loss': 0.2910990732337336, 'test/num_examples': 3581, 'score': 1557.285712480545, 'total_duration': 1868.836440563202, 'global_step': 6181, 'preemption_count': 0}), (6523, {'train/ssim': 0.7344935962132045, 'train/loss': 0.2830423968178885, 'validation/ssim': 0.7190740324502322, 'validation/loss': 0.29117489344092923, 'validation/num_examples': 3554, 'test/ssim': 0.7362060887758308, 'test/loss': 0.2926381272798276, 'test/num_examples': 3581, 'score': 1637.1008613109589, 'total_duration': 1953.289291381836, 'global_step': 6523, 'preemption_count': 0}), (6869, {'train/ssim': 0.7282147407531738, 'train/loss': 0.2853403772626604, 'validation/ssim': 0.72100359520083, 'validation/loss': 0.28985159492385343, 'validation/num_examples': 3554, 'test/ssim': 0.7380816287349903, 'test/loss': 0.2914263552974902, 'test/num_examples': 3581, 'score': 1716.9511365890503, 'total_duration': 2037.7781884670258, 'global_step': 6869, 'preemption_count': 0}), (7216, {'train/ssim': 0.7226830891200474, 'train/loss': 0.29210332461765837, 'validation/ssim': 0.7157615099184018, 'validation/loss': 0.29178682497933667, 'validation/num_examples': 3554, 'test/ssim': 0.7330833249703295, 'test/loss': 0.29313479425919786, 'test/num_examples': 3581, 'score': 1796.8046023845673, 'total_duration': 2122.2629313468933, 'global_step': 7216, 'preemption_count': 0}), (7560, {'train/ssim': 0.7384037290300641, 'train/loss': 0.27625836644853863, 'validation/ssim': 0.7206056473559721, 'validation/loss': 0.2884274183798185, 'validation/num_examples': 3554, 'test/ssim': 0.737837215403344, 'test/loss': 0.2899240825603009, 'test/num_examples': 3581, 'score': 1876.5159795284271, 'total_duration': 2206.5944702625275, 'global_step': 7560, 'preemption_count': 0}), (7907, {'train/ssim': 0.7362739018031529, 'train/loss': 0.28678481919424875, 'validation/ssim': 0.7226230018113393, 'validation/loss': 0.28954133574185775, 'validation/num_examples': 3554, 'test/ssim': 0.7395748339761938, 'test/loss': 0.29100471673415246, 'test/num_examples': 3581, 'score': 1956.2849614620209, 'total_duration': 2290.9930939674377, 'global_step': 7907, 'preemption_count': 0}), (8253, {'train/ssim': 0.74249267578125, 'train/loss': 0.2762948104313442, 'validation/ssim': 0.724341466041784, 'validation/loss': 0.28792258173009283, 'validation/num_examples': 3554, 'test/ssim': 0.7415389354187029, 'test/loss': 0.289338547302604, 'test/num_examples': 3581, 'score': 2035.981540441513, 'total_duration': 2375.3150498867035, 'global_step': 8253, 'preemption_count': 0}), (8597, {'train/ssim': 0.7405343736921038, 'train/loss': 0.26618312086377827, 'validation/ssim': 0.7215460077993107, 'validation/loss': 0.28914562047165165, 'validation/num_examples': 3554, 'test/ssim': 0.7386440180160919, 'test/loss': 0.2905587731909732, 'test/num_examples': 3581, 'score': 2115.819060564041, 'total_duration': 2459.775220155716, 'global_step': 8597, 'preemption_count': 0}), (8943, {'train/ssim': 0.7475596155439105, 'train/loss': 0.2644381693431309, 'validation/ssim': 0.7222872225837085, 'validation/loss': 0.28810053510349254, 'validation/num_examples': 3554, 'test/ssim': 0.7394394351263613, 'test/loss': 0.28954791783021505, 'test/num_examples': 3581, 'score': 2195.50098156929, 'total_duration': 2544.087946653366, 'global_step': 8943, 'preemption_count': 0}), (9290, {'train/ssim': 0.7446566309247699, 'train/loss': 0.2740920100893293, 'validation/ssim': 0.7217589610737901, 'validation/loss': 0.28772879425031656, 'validation/num_examples': 3554, 'test/ssim': 0.7391177094605208, 'test/loss': 0.28912890406834685, 'test/num_examples': 3581, 'score': 2275.3441066741943, 'total_duration': 2628.6067821979523, 'global_step': 9290, 'preemption_count': 0}), (9637, {'train/ssim': 0.7278357233319964, 'train/loss': 0.26279328550611225, 'validation/ssim': 0.7217888432268219, 'validation/loss': 0.28763202072598654, 'validation/num_examples': 3554, 'test/ssim': 0.7391528886178791, 'test/loss': 0.2890142650119555, 'test/num_examples': 3581, 'score': 2355.2322034835815, 'total_duration': 2713.1324775218964, 'global_step': 9637, 'preemption_count': 0}), (9986, {'train/ssim': 0.7371879305158343, 'train/loss': 0.2821736676352365, 'validation/ssim': 0.7230290556195484, 'validation/loss': 0.2874431449104442, 'validation/num_examples': 3554, 'test/ssim': 0.7403438667184445, 'test/loss': 0.28887869572046915, 'test/num_examples': 3581, 'score': 2435.0470101833344, 'total_duration': 2797.571704149246, 'global_step': 9986, 'preemption_count': 0}), (10337, {'train/ssim': 0.7273233277457101, 'train/loss': 0.28542470932006836, 'validation/ssim': 0.7217946822682189, 'validation/loss': 0.28742212436141495, 'validation/num_examples': 3554, 'test/ssim': 0.7391716371998045, 'test/loss': 0.28880891690737576, 'test/num_examples': 3581, 'score': 2514.864759206772, 'total_duration': 2882.030988931656, 'global_step': 10337, 'preemption_count': 0}), (10684, {'train/ssim': 0.7325865200587681, 'train/loss': 0.2801370450428554, 'validation/ssim': 0.7190905878499578, 'validation/loss': 0.2880573948917593, 'validation/num_examples': 3554, 'test/ssim': 0.7366486916625943, 'test/loss': 0.2893611478659069, 'test/num_examples': 3581, 'score': 2594.538832426071, 'total_duration': 2966.38098692894, 'global_step': 10684, 'preemption_count': 0}), (11031, {'train/ssim': 0.7395448684692383, 'train/loss': 0.28031485421316965, 'validation/ssim': 0.7244779622212648, 'validation/loss': 0.2883040772171321, 'validation/num_examples': 3554, 'test/ssim': 0.7415795005323234, 'test/loss': 0.2897497889250559, 'test/num_examples': 3581, 'score': 2674.409858942032, 'total_duration': 3050.8945891857147, 'global_step': 11031, 'preemption_count': 0}), (11379, {'train/ssim': 0.7356535366603306, 'train/loss': 0.283963714327131, 'validation/ssim': 0.7209256268245287, 'validation/loss': 0.28815741423616, 'validation/num_examples': 3554, 'test/ssim': 0.7376685463426766, 'test/loss': 0.2896824303834474, 'test/num_examples': 3581, 'score': 2754.332240343094, 'total_duration': 3135.458713054657, 'global_step': 11379, 'preemption_count': 0}), (11727, {'train/ssim': 0.7408665929521833, 'train/loss': 0.27324650968824116, 'validation/ssim': 0.7241101713078574, 'validation/loss': 0.2871414897276836, 'validation/num_examples': 3554, 'test/ssim': 0.741227504428756, 'test/loss': 0.28856269689419856, 'test/num_examples': 3581, 'score': 2834.1305384635925, 'total_duration': 3219.894807100296, 'global_step': 11727, 'preemption_count': 0}), (12073, {'train/ssim': 0.7443915775844029, 'train/loss': 0.26108511856624056, 'validation/ssim': 0.7234937746201463, 'validation/loss': 0.28742585104371837, 'validation/num_examples': 3554, 'test/ssim': 0.7406917722223192, 'test/loss': 0.288840789496649, 'test/num_examples': 3581, 'score': 2913.8690991401672, 'total_duration': 3304.2745814323425, 'global_step': 12073, 'preemption_count': 0}), (12424, {'train/ssim': 0.7494527271815709, 'train/loss': 0.26867951665605816, 'validation/ssim': 0.7240120067177828, 'validation/loss': 0.2870363869825373, 'validation/num_examples': 3554, 'test/ssim': 0.7412882498341944, 'test/loss': 0.28847089701942547, 'test/num_examples': 3581, 'score': 2993.679572582245, 'total_duration': 3388.735997915268, 'global_step': 12424, 'preemption_count': 0}), (12775, {'train/ssim': 0.7270932878766742, 'train/loss': 0.2677886996950422, 'validation/ssim': 0.7205795434061972, 'validation/loss': 0.28736478154016604, 'validation/num_examples': 3554, 'test/ssim': 0.7380961503638998, 'test/loss': 0.2887373655010821, 'test/num_examples': 3581, 'score': 3073.462012529373, 'total_duration': 3473.1533818244934, 'global_step': 12775, 'preemption_count': 0}), (13119, {'train/ssim': 0.7386341776166644, 'train/loss': 0.27210647719247, 'validation/ssim': 0.7176662052221089, 'validation/loss': 0.291753679832583, 'validation/num_examples': 3554, 'test/ssim': 0.7347565165980173, 'test/loss': 0.29338585481534485, 'test/num_examples': 3581, 'score': 3153.1762697696686, 'total_duration': 3557.502077102661, 'global_step': 13119, 'preemption_count': 0}), (13468, {'train/ssim': 0.7326493263244629, 'train/loss': 0.28339806624821257, 'validation/ssim': 0.7210196010437183, 'validation/loss': 0.2889764256603475, 'validation/num_examples': 3554, 'test/ssim': 0.738158122949246, 'test/loss': 0.29048943752617984, 'test/num_examples': 3581, 'score': 3233.011066198349, 'total_duration': 3642.0175261497498, 'global_step': 13468, 'preemption_count': 0}), (13817, {'train/ssim': 0.7236015456063407, 'train/loss': 0.2901172297341483, 'validation/ssim': 0.7200778667082864, 'validation/loss': 0.2891386479692776, 'validation/num_examples': 3554, 'test/ssim': 0.7370891128961882, 'test/loss': 0.29067924135192685, 'test/num_examples': 3581, 'score': 3312.717055082321, 'total_duration': 3726.393211364746, 'global_step': 13817, 'preemption_count': 0}), (14162, {'train/ssim': 0.7370419502258301, 'train/loss': 0.2792008774621146, 'validation/ssim': 0.7218947016126196, 'validation/loss': 0.2880085873751407, 'validation/num_examples': 3554, 'test/ssim': 0.7391405486421391, 'test/loss': 0.2894437438913711, 'test/num_examples': 3581, 'score': 3392.4223165512085, 'total_duration': 3810.7259933948517, 'global_step': 14162, 'preemption_count': 0}), (14511, {'train/ssim': 0.7362714494977679, 'train/loss': 0.2807021311351231, 'validation/ssim': 0.721497303324599, 'validation/loss': 0.28790461809097145, 'validation/num_examples': 3554, 'test/ssim': 0.7388224363393605, 'test/loss': 0.28933530891118053, 'test/num_examples': 3581, 'score': 3472.3484513759613, 'total_duration': 3895.334852218628, 'global_step': 14511, 'preemption_count': 0}), (14861, {'train/ssim': 0.7366507393973214, 'train/loss': 0.2830709218978882, 'validation/ssim': 0.7186876939935636, 'validation/loss': 0.28924048772070204, 'validation/num_examples': 3554, 'test/ssim': 0.7359393816758587, 'test/loss': 0.29062616582091244, 'test/num_examples': 3581, 'score': 3552.172005176544, 'total_duration': 3979.792712688446, 'global_step': 14861, 'preemption_count': 0}), (15206, {'train/ssim': 0.7365939957754952, 'train/loss': 0.27231015477861675, 'validation/ssim': 0.7206913782226013, 'validation/loss': 0.2894989511707759, 'validation/num_examples': 3554, 'test/ssim': 0.7377725157515359, 'test/loss': 0.2908930774508692, 'test/num_examples': 3581, 'score': 3631.9433279037476, 'total_duration': 4064.195611000061, 'global_step': 15206, 'preemption_count': 0}), (15555, {'train/ssim': 0.7357465199061802, 'train/loss': 0.26746983187539236, 'validation/ssim': 0.7136501125492403, 'validation/loss': 0.29249843238912143, 'validation/num_examples': 3554, 'test/ssim': 0.7302127466358909, 'test/loss': 0.2942535391868542, 'test/num_examples': 3581, 'score': 3711.7400686740875, 'total_duration': 4148.603936433792, 'global_step': 15555, 'preemption_count': 0}), (15904, {'train/ssim': 0.7369802338736398, 'train/loss': 0.2794285672051566, 'validation/ssim': 0.713772869807787, 'validation/loss': 0.2942804047815841, 'validation/num_examples': 3554, 'test/ssim': 0.7305249275691148, 'test/loss': 0.29580871701340405, 'test/num_examples': 3581, 'score': 3791.5191292762756, 'total_duration': 4233.043887376785, 'global_step': 15904, 'preemption_count': 0}), (16249, {'train/ssim': 0.7322956493922642, 'train/loss': 0.26223894527980257, 'validation/ssim': 0.7246778635208568, 'validation/loss': 0.2872241121634514, 'validation/num_examples': 3554, 'test/ssim': 0.7416867424209369, 'test/loss': 0.2887783055863411, 'test/num_examples': 3581, 'score': 3871.410144805908, 'total_duration': 4317.565727710724, 'global_step': 16249, 'preemption_count': 0}), (16596, {'train/ssim': 0.7400255884443011, 'train/loss': 0.27337050437927246, 'validation/ssim': 0.7214063516680149, 'validation/loss': 0.2873047081083814, 'validation/num_examples': 3554, 'test/ssim': 0.7388218227494066, 'test/loss': 0.2885886381139172, 'test/num_examples': 3581, 'score': 3951.1571414470673, 'total_duration': 4401.945869207382, 'global_step': 16596, 'preemption_count': 0}), (16943, {'train/ssim': 0.7309530803135463, 'train/loss': 0.283855744770595, 'validation/ssim': 0.7230032264481921, 'validation/loss': 0.2867632572343662, 'validation/num_examples': 3554, 'test/ssim': 0.740266281677604, 'test/loss': 0.2881603523260786, 'test/num_examples': 3581, 'score': 4030.8390560150146, 'total_duration': 4486.262967824936, 'global_step': 16943, 'preemption_count': 0}), (17288, {'train/ssim': 0.7281818389892578, 'train/loss': 0.2864894185747419, 'validation/ssim': 0.7230350320501547, 'validation/loss': 0.28675705754629466, 'validation/num_examples': 3554, 'test/ssim': 0.7403873634285116, 'test/loss': 0.28804441791311786, 'test/num_examples': 3581, 'score': 4110.554134130478, 'total_duration': 4570.605864524841, 'global_step': 17288, 'preemption_count': 0}), (17638, {'train/ssim': 0.7427566392081124, 'train/loss': 0.27351622922079905, 'validation/ssim': 0.7237881996957654, 'validation/loss': 0.28649074573763716, 'validation/num_examples': 3554, 'test/ssim': 0.741075606826829, 'test/loss': 0.28782410503132855, 'test/num_examples': 3581, 'score': 4190.447368383408, 'total_duration': 4655.141242980957, 'global_step': 17638, 'preemption_count': 0}), (17987, {'train/ssim': 0.7360964502607074, 'train/loss': 0.2857444626944406, 'validation/ssim': 0.7229855032401871, 'validation/loss': 0.28671245757421215, 'validation/num_examples': 3554, 'test/ssim': 0.7402163763613516, 'test/loss': 0.2881528869816392, 'test/num_examples': 3581, 'score': 4270.205455541611, 'total_duration': 4739.538157939911, 'global_step': 17987, 'preemption_count': 0}), (18335, {'train/ssim': 0.7430698531014579, 'train/loss': 0.27559798104422434, 'validation/ssim': 0.7234673271973481, 'validation/loss': 0.2869436149189294, 'validation/num_examples': 3554, 'test/ssim': 0.7407904920282393, 'test/loss': 0.28825310667411336, 'test/num_examples': 3581, 'score': 4350.063152551651, 'total_duration': 4824.032368659973, 'global_step': 18335, 'preemption_count': 0}), (18686, {'train/ssim': 0.7405351911272321, 'train/loss': 0.2641417809895107, 'validation/ssim': 0.7244073441676632, 'validation/loss': 0.2865372519849993, 'validation/num_examples': 3554, 'test/ssim': 0.7416597444629642, 'test/loss': 0.28796393536416154, 'test/num_examples': 3581, 'score': 4430.007924318314, 'total_duration': 4908.6601305007935, 'global_step': 18686, 'preemption_count': 0}), (19035, {'train/ssim': 0.7496295656476702, 'train/loss': 0.2624638421194894, 'validation/ssim': 0.724393399162915, 'validation/loss': 0.28633987521212895, 'validation/num_examples': 3554, 'test/ssim': 0.7416380642845923, 'test/loss': 0.2876839679035186, 'test/num_examples': 3581, 'score': 4509.893764019012, 'total_duration': 4993.176600933075, 'global_step': 19035, 'preemption_count': 0}), (19384, {'train/ssim': 0.746638298034668, 'train/loss': 0.27263310977390837, 'validation/ssim': 0.7238344311647088, 'validation/loss': 0.2861723118976857, 'validation/num_examples': 3554, 'test/ssim': 0.7410997413650168, 'test/loss': 0.28751441254625104, 'test/num_examples': 3581, 'score': 4589.705970048904, 'total_duration': 5077.67266368866, 'global_step': 19384, 'preemption_count': 0}), (19733, {'train/ssim': 0.7340303148542132, 'train/loss': 0.2587484461920602, 'validation/ssim': 0.7249358117613957, 'validation/loss': 0.2862537150042206, 'validation/num_examples': 3554, 'test/ssim': 0.7420623276493996, 'test/loss': 0.2876268699494729, 'test/num_examples': 3581, 'score': 4669.40486907959, 'total_duration': 5162.009875535965, 'global_step': 19733, 'preemption_count': 0}), (20082, {'train/ssim': 0.7385052272251674, 'train/loss': 0.28101861476898193, 'validation/ssim': 0.7245590218547763, 'validation/loss': 0.286016684270804, 'validation/num_examples': 3554, 'test/ssim': 0.7418799550797612, 'test/loss': 0.28735085673519967, 'test/num_examples': 3581, 'score': 4749.285075902939, 'total_duration': 5246.572539806366, 'global_step': 20082, 'preemption_count': 0}), (20428, {'train/ssim': 0.7306624821254185, 'train/loss': 0.28198327336992535, 'validation/ssim': 0.7237579053751055, 'validation/loss': 0.28606823957160943, 'validation/num_examples': 3554, 'test/ssim': 0.7409222093383482, 'test/loss': 0.28745373531747415, 'test/num_examples': 3581, 'score': 4829.093562841415, 'total_duration': 5331.014027833939, 'global_step': 20428, 'preemption_count': 0}), (20775, {'train/ssim': 0.7339572906494141, 'train/loss': 0.28309484890529085, 'validation/ssim': 0.7245834771340391, 'validation/loss': 0.28604617142985894, 'validation/num_examples': 3554, 'test/ssim': 0.7418563659548659, 'test/loss': 0.28740359138290633, 'test/num_examples': 3581, 'score': 4908.940237045288, 'total_duration': 5415.489462137222, 'global_step': 20775, 'preemption_count': 0}), (21123, {'train/ssim': 0.7421747616359166, 'train/loss': 0.27381997449057444, 'validation/ssim': 0.7251903252717009, 'validation/loss': 0.2861104352325285, 'validation/num_examples': 3554, 'test/ssim': 0.7424083923834125, 'test/loss': 0.28748966441810947, 'test/num_examples': 3581, 'score': 4988.741963863373, 'total_duration': 5499.923207521439, 'global_step': 21123, 'preemption_count': 0}), (21471, {'train/ssim': 0.7384370395115444, 'train/loss': 0.2828362498964582, 'validation/ssim': 0.7244731535989378, 'validation/loss': 0.28579431983548464, 'validation/num_examples': 3554, 'test/ssim': 0.7417686907681165, 'test/loss': 0.2871083523500768, 'test/num_examples': 3581, 'score': 5068.577326774597, 'total_duration': 5584.400688409805, 'global_step': 21471, 'preemption_count': 0}), (21817, {'train/ssim': 0.7434684889657157, 'train/loss': 0.2739727326801845, 'validation/ssim': 0.7247087760929586, 'validation/loss': 0.28626455157810743, 'validation/num_examples': 3554, 'test/ssim': 0.7419014307281485, 'test/loss': 0.2876473570362678, 'test/num_examples': 3581, 'score': 5148.291775465012, 'total_duration': 5668.742828607559, 'global_step': 21817, 'preemption_count': 0}), (22164, {'train/ssim': 0.7443317004612514, 'train/loss': 0.26108368805476595, 'validation/ssim': 0.7251654578248101, 'validation/loss': 0.28572212180597567, 'validation/num_examples': 3554, 'test/ssim': 0.7424100967999512, 'test/loss': 0.2870805362721656, 'test/num_examples': 3581, 'score': 5228.042232513428, 'total_duration': 5753.160733938217, 'global_step': 22164, 'preemption_count': 0}), (22506, {'train/ssim': 0.7528704915727887, 'train/loss': 0.2639666795730591, 'validation/ssim': 0.7257712755434018, 'validation/loss': 0.2856162462465268, 'validation/num_examples': 3554, 'test/ssim': 0.7429919164295937, 'test/loss': 0.2869437738891022, 'test/num_examples': 3581, 'score': 5307.797540664673, 'total_duration': 5837.556019544601, 'global_step': 22506, 'preemption_count': 0}), (22848, {'train/ssim': 0.7306479045322963, 'train/loss': 0.26438052313668386, 'validation/ssim': 0.7243115838887522, 'validation/loss': 0.28581260977397827, 'validation/num_examples': 3554, 'test/ssim': 0.7416356099247766, 'test/loss': 0.2871911869938565, 'test/num_examples': 3581, 'score': 5387.517241239548, 'total_duration': 5921.909205913544, 'global_step': 22848, 'preemption_count': 0}), (23192, {'train/ssim': 0.7457763808114188, 'train/loss': 0.26810583046504427, 'validation/ssim': 0.7238475518342009, 'validation/loss': 0.2860625207457706, 'validation/num_examples': 3554, 'test/ssim': 0.7412209594692474, 'test/loss': 0.2874011711114214, 'test/num_examples': 3581, 'score': 5467.271270513535, 'total_duration': 6006.303373813629, 'global_step': 23192, 'preemption_count': 0}), (23534, {'train/ssim': 0.7396838324410575, 'train/loss': 0.2783816541944231, 'validation/ssim': 0.7261285561822945, 'validation/loss': 0.28548017940832515, 'validation/num_examples': 3554, 'test/ssim': 0.7433863184166434, 'test/loss': 0.2867323921499756, 'test/num_examples': 3581, 'score': 5547.198359966278, 'total_duration': 6090.899531126022, 'global_step': 23534, 'preemption_count': 0}), (23874, {'train/ssim': 0.7295436177934919, 'train/loss': 0.28571336609976633, 'validation/ssim': 0.7248272055914111, 'validation/loss': 0.2855212759555694, 'validation/num_examples': 3554, 'test/ssim': 0.7421349357939472, 'test/loss': 0.28684317922498953, 'test/num_examples': 3581, 'score': 5627.127336025238, 'total_duration': 6175.475660085678, 'global_step': 23874, 'preemption_count': 0}), (24222, {'train/ssim': 0.7397308349609375, 'train/loss': 0.27566334179469515, 'validation/ssim': 0.7255228071583075, 'validation/loss': 0.2853322284035154, 'validation/num_examples': 3554, 'test/ssim': 0.7427121875872661, 'test/loss': 0.2866842935152541, 'test/num_examples': 3581, 'score': 5706.964846611023, 'total_duration': 6259.959718704224, 'global_step': 24222, 'preemption_count': 0}), (24567, {'train/ssim': 0.742084094456264, 'train/loss': 0.2773745741162981, 'validation/ssim': 0.7257603531012592, 'validation/loss': 0.28516275881379255, 'validation/num_examples': 3554, 'test/ssim': 0.7430516391851089, 'test/loss': 0.2864481977363167, 'test/num_examples': 3581, 'score': 5786.689669370651, 'total_duration': 6344.322776794434, 'global_step': 24567, 'preemption_count': 0}), (24910, {'train/ssim': 0.7430941036769322, 'train/loss': 0.27792354992457796, 'validation/ssim': 0.7255961043014912, 'validation/loss': 0.284950818784732, 'validation/num_examples': 3554, 'test/ssim': 0.7428653805457623, 'test/loss': 0.2862345320790282, 'test/num_examples': 3581, 'score': 5866.398560523987, 'total_duration': 6428.660042285919, 'global_step': 24910, 'preemption_count': 0}), (25258, {'train/ssim': 0.7437185559953962, 'train/loss': 0.2664283173424857, 'validation/ssim': 0.7264150813783765, 'validation/loss': 0.28494690319226573, 'validation/num_examples': 3554, 'test/ssim': 0.7436237777288118, 'test/loss': 0.2862851532502269, 'test/num_examples': 3581, 'score': 5946.222469329834, 'total_duration': 6513.112962007523, 'global_step': 25258, 'preemption_count': 0}), (25603, {'train/ssim': 0.7491168294634137, 'train/loss': 0.2603654180254255, 'validation/ssim': 0.7261901065480796, 'validation/loss': 0.28491980317072313, 'validation/num_examples': 3554, 'test/ssim': 0.7434139299645699, 'test/loss': 0.2862444517832833, 'test/num_examples': 3581, 'score': 6025.926921129227, 'total_duration': 6597.44943022728, 'global_step': 25603, 'preemption_count': 0}), (25948, {'train/ssim': 0.7520076887948173, 'train/loss': 0.26495511191231863, 'validation/ssim': 0.726618623492016, 'validation/loss': 0.2847220314038759, 'validation/num_examples': 3554, 'test/ssim': 0.74388414439926, 'test/loss': 0.2859982658584369, 'test/num_examples': 3581, 'score': 6105.679899215698, 'total_duration': 6681.8465304374695, 'global_step': 25948, 'preemption_count': 0}), (26293, {'train/ssim': 0.7336794989449638, 'train/loss': 0.2651408740452358, 'validation/ssim': 0.7266215773600169, 'validation/loss': 0.28467655557558386, 'validation/num_examples': 3554, 'test/ssim': 0.7438034914086498, 'test/loss': 0.2860378424104649, 'test/num_examples': 3581, 'score': 6185.5220947265625, 'total_duration': 6766.320321559906, 'global_step': 26293, 'preemption_count': 0}), (26640, {'train/ssim': 0.7490513665335519, 'train/loss': 0.26346707344055176, 'validation/ssim': 0.7263763376213421, 'validation/loss': 0.2845012297708128, 'validation/num_examples': 3554, 'test/ssim': 0.7436519346900308, 'test/loss': 0.28579238938473017, 'test/num_examples': 3581, 'score': 6265.280235052109, 'total_duration': 6850.734718322754, 'global_step': 26640, 'preemption_count': 0}), (26983, {'train/ssim': 0.7362876619611468, 'train/loss': 0.2790779897144863, 'validation/ssim': 0.7266112731693163, 'validation/loss': 0.28442733154983824, 'validation/num_examples': 3554, 'test/ssim': 0.7438127634346202, 'test/loss': 0.28571814500030546, 'test/num_examples': 3581, 'score': 6345.050931453705, 'total_duration': 6935.139113664627, 'global_step': 26983, 'preemption_count': 0}), (27327, {'train/ssim': 0.7293259075709752, 'train/loss': 0.2874189444950649, 'validation/ssim': 0.7269812623100732, 'validation/loss': 0.28445752282859105, 'validation/num_examples': 3554, 'test/ssim': 0.7441627824150028, 'test/loss': 0.28576730037328085, 'test/num_examples': 3581, 'score': 6424.80319237709, 'total_duration': 7019.571089744568, 'global_step': 27327, 'preemption_count': 0}), (27669, {'train/ssim': 0.7469111851283482, 'train/loss': 0.2712784835270473, 'validation/ssim': 0.727038690999578, 'validation/loss': 0.28440912747960045, 'validation/num_examples': 3554, 'test/ssim': 0.7442169828609327, 'test/loss': 0.2857197471518518, 'test/num_examples': 3581, 'score': 6504.698725938797, 'total_duration': 7104.098731279373, 'global_step': 27669, 'preemption_count': 0}), (28012, {'train/ssim': 0.7419052805219378, 'train/loss': 0.28069818019866943, 'validation/ssim': 0.7270608793568866, 'validation/loss': 0.28440407842615717, 'validation/num_examples': 3554, 'test/ssim': 0.7442178009808713, 'test/loss': 0.28570652087951165, 'test/num_examples': 3581, 'score': 6584.606688976288, 'total_duration': 7188.64093875885, 'global_step': 28012, 'preemption_count': 0}), (28355, {'train/ssim': 0.7477944237845284, 'train/loss': 0.272686243057251, 'validation/ssim': 0.7270521551420934, 'validation/loss': 0.2844690635221757, 'validation/num_examples': 3554, 'test/ssim': 0.7441861670099135, 'test/loss': 0.28580103077658126, 'test/num_examples': 3581, 'score': 6664.5073873996735, 'total_duration': 7273.184458732605, 'global_step': 28355, 'preemption_count': 0}), (28701, {'train/ssim': 0.7423764637538365, 'train/loss': 0.26366070338657926, 'validation/ssim': 0.726705659556134, 'validation/loss': 0.2844607686486617, 'validation/num_examples': 3554, 'test/ssim': 0.743913051303756, 'test/loss': 0.28579792873848087, 'test/num_examples': 3581, 'score': 6744.458938121796, 'total_duration': 7357.767594099045, 'global_step': 28701, 'preemption_count': 0}), (29044, {'train/ssim': 0.7525337764195034, 'train/loss': 0.25751045772007536, 'validation/ssim': 0.7266383388435566, 'validation/loss': 0.2844665733427564, 'validation/num_examples': 3554, 'test/ssim': 0.7438510105417481, 'test/loss': 0.28575712500654493, 'test/num_examples': 3581, 'score': 6824.338840246201, 'total_duration': 7442.239293336868, 'global_step': 29044, 'preemption_count': 0}), (29385, {'train/ssim': 0.7504747935703823, 'train/loss': 0.27070348603384836, 'validation/ssim': 0.7269673859999296, 'validation/loss': 0.2845018823695572, 'validation/num_examples': 3554, 'test/ssim': 0.7441354435737224, 'test/loss': 0.2858167625412332, 'test/num_examples': 3581, 'score': 6904.124021053314, 'total_duration': 7526.670565128326, 'global_step': 29385, 'preemption_count': 0}), (29731, {'train/ssim': 0.7370663370404925, 'train/loss': 0.2566635438374111, 'validation/ssim': 0.7267545701146595, 'validation/loss': 0.2844736317133863, 'validation/num_examples': 3554, 'test/ssim': 0.7439520483541608, 'test/loss': 0.2857998206408388, 'test/num_examples': 3581, 'score': 6983.911327123642, 'total_duration': 7611.102858304977, 'global_step': 29731, 'preemption_count': 0}), (30077, {'train/ssim': 0.7431699889046806, 'train/loss': 0.27530431747436523, 'validation/ssim': 0.726706689975204, 'validation/loss': 0.2844639114268254, 'validation/num_examples': 3554, 'test/ssim': 0.7439390266118053, 'test/loss': 0.28576021000047996, 'test/num_examples': 3581, 'score': 7063.669901132584, 'total_duration': 7695.515040636063, 'global_step': 30077, 'preemption_count': 0}), (30421, {'train/ssim': 0.7346618516104562, 'train/loss': 0.2791956492832729, 'validation/ssim': 0.726741312055958, 'validation/loss': 0.2845689798246694, 'validation/num_examples': 3554, 'test/ssim': 0.7439440716847598, 'test/loss': 0.28587196859292097, 'test/num_examples': 3581, 'score': 7143.505771160126, 'total_duration': 7779.998341560364, 'global_step': 30421, 'preemption_count': 0}), (30766, {'train/ssim': 0.7350190026419503, 'train/loss': 0.2832580123628889, 'validation/ssim': 0.7267911156443444, 'validation/loss': 0.284531764522589, 'validation/num_examples': 3554, 'test/ssim': 0.7439836141484572, 'test/loss': 0.28587776360915246, 'test/num_examples': 3581, 'score': 7223.251319169998, 'total_duration': 7864.425345659256, 'global_step': 30766, 'preemption_count': 0}), (31111, {'train/ssim': 0.7455925941467285, 'train/loss': 0.27105060645512175, 'validation/ssim': 0.7269190249982415, 'validation/loss': 0.2844824589700865, 'validation/num_examples': 3554, 'test/ssim': 0.7440869017907009, 'test/loss': 0.2857846342894792, 'test/num_examples': 3581, 'score': 7303.040740728378, 'total_duration': 7948.8552277088165, 'global_step': 31111, 'preemption_count': 0}), (31451, {'train/ssim': 0.7409185682024274, 'train/loss': 0.28087001187460764, 'validation/ssim': 0.7265022548317037, 'validation/loss': 0.28456295187310954, 'validation/num_examples': 3554, 'test/ssim': 0.7437259063678092, 'test/loss': 0.28589259203303896, 'test/num_examples': 3581, 'score': 7382.900626420975, 'total_duration': 8033.353553056717, 'global_step': 31451, 'preemption_count': 0}), (31792, {'train/ssim': 0.7459501538957868, 'train/loss': 0.27182929856436594, 'validation/ssim': 0.7268374158078925, 'validation/loss': 0.28453279494165906, 'validation/num_examples': 3554, 'test/ssim': 0.7440335194647095, 'test/loss': 0.2858595945288502, 'test/num_examples': 3581, 'score': 7462.779616594315, 'total_duration': 8117.8608565330505, 'global_step': 31792, 'preemption_count': 0}), (32137, {'train/ssim': 0.7466423852103097, 'train/loss': 0.2605804715837751, 'validation/ssim': 0.72703930925102, 'validation/loss': 0.28451769930228266, 'validation/num_examples': 3554, 'test/ssim': 0.744217528274225, 'test/loss': 0.2858317443626082, 'test/num_examples': 3581, 'score': 7542.509768009186, 'total_duration': 8202.224610328674, 'global_step': 32137, 'preemption_count': 0}), (32479, {'train/ssim': 0.7531042098999023, 'train/loss': 0.2595487322126116, 'validation/ssim': 0.7266214399708075, 'validation/loss': 0.2845176134340268, 'validation/num_examples': 3554, 'test/ssim': 0.7438471244720399, 'test/loss': 0.2858061440261973, 'test/num_examples': 3581, 'score': 7622.250522375107, 'total_duration': 8286.601069450378, 'global_step': 32479, 'preemption_count': 0}), (32824, {'train/ssim': 0.750568185533796, 'train/loss': 0.26950892380305697, 'validation/ssim': 0.7267238636263716, 'validation/loss': 0.28455304267638576, 'validation/num_examples': 3554, 'test/ssim': 0.7438981887915387, 'test/loss': 0.28589262612136973, 'test/num_examples': 3581, 'score': 7702.1777086257935, 'total_duration': 8371.164874315262, 'global_step': 32824, 'preemption_count': 0}), (33166, {'train/ssim': 0.7340775217328753, 'train/loss': 0.2582530805042812, 'validation/ssim': 0.7266601150332372, 'validation/loss': 0.2845718649980656, 'validation/num_examples': 3554, 'test/ssim': 0.7438710544802429, 'test/loss': 0.28588272346128, 'test/num_examples': 3581, 'score': 7782.067091703415, 'total_duration': 8455.719642877579, 'global_step': 33166, 'preemption_count': 0}), (33510, {'train/ssim': 0.7421445165361676, 'train/loss': 0.2783117634909494, 'validation/ssim': 0.7272397601074494, 'validation/loss': 0.2845718993453679, 'validation/num_examples': 3554, 'test/ssim': 0.7443729028858909, 'test/loss': 0.28589320562299286, 'test/num_examples': 3581, 'score': 7861.790158748627, 'total_duration': 8540.089529752731, 'global_step': 33510, 'preemption_count': 0}), (33853, {'train/ssim': 0.7332722118922642, 'train/loss': 0.281471848487854, 'validation/ssim': 0.7268323324071468, 'validation/loss': 0.2845601525679692, 'validation/num_examples': 3554, 'test/ssim': 0.7439896136946733, 'test/loss': 0.28591388019560704, 'test/num_examples': 3581, 'score': 7941.540546178818, 'total_duration': 8624.484502792358, 'global_step': 33853, 'preemption_count': 0}), (34199, {'train/ssim': 0.7411680902753558, 'train/loss': 0.2750984600612095, 'validation/ssim': 0.7264695561998804, 'validation/loss': 0.2845659916093662, 'validation/num_examples': 3554, 'test/ssim': 0.7437061351359606, 'test/loss': 0.2858594581755271, 'test/num_examples': 3581, 'score': 8021.334625482559, 'total_duration': 8708.961094379425, 'global_step': 34199, 'preemption_count': 0}), (34546, {'train/ssim': 0.7426195825849261, 'train/loss': 0.275631274495806, 'validation/ssim': 0.7266281720420653, 'validation/loss': 0.28461830255082304, 'validation/num_examples': 3554, 'test/ssim': 0.7437914923162176, 'test/loss': 0.2859204421992809, 'test/num_examples': 3581, 'score': 8101.1119594573975, 'total_duration': 8793.383621454239, 'global_step': 34546, 'preemption_count': 0}), (34889, {'train/ssim': 0.7431909016200474, 'train/loss': 0.27897143363952637, 'validation/ssim': 0.7265249927458497, 'validation/loss': 0.28467227933644307, 'validation/num_examples': 3554, 'test/ssim': 0.743702180889591, 'test/loss': 0.28598906200912805, 'test/num_examples': 3581, 'score': 8180.9313271045685, 'total_duration': 8877.843621969223, 'global_step': 34889, 'preemption_count': 0}), (35236, {'train/ssim': 0.744368416922433, 'train/loss': 0.2698590244565691, 'validation/ssim': 0.7268087701577448, 'validation/loss': 0.2845668846392269, 'validation/num_examples': 3554, 'test/ssim': 0.7439990902506283, 'test/loss': 0.28588974565741937, 'test/num_examples': 3581, 'score': 8260.66656756401, 'total_duration': 8962.26082444191, 'global_step': 35236, 'preemption_count': 0}), (35582, {'train/ssim': 0.7490621294294085, 'train/loss': 0.2568952866962978, 'validation/ssim': 0.7266555811893289, 'validation/loss': 0.28462833196310494, 'validation/num_examples': 3554, 'test/ssim': 0.7438124907279741, 'test/loss': 0.28593714548135996, 'test/num_examples': 3581, 'score': 8340.574032068253, 'total_duration': 9046.807101011276, 'global_step': 35582, 'preemption_count': 0}), (35924, {'train/ssim': 0.7537999153137207, 'train/loss': 0.26463004520961214, 'validation/ssim': 0.7267942069015546, 'validation/loss': 0.28470707315370886, 'validation/num_examples': 3554, 'test/ssim': 0.743905074634355, 'test/loss': 0.2860466371998045, 'test/num_examples': 3581, 'score': 8420.371722698212, 'total_duration': 9131.234360694885, 'global_step': 35924, 'preemption_count': 0}), (36189, {'train/ssim': 0.7339744567871094, 'train/loss': 0.26372272627694265, 'validation/ssim': 0.7268813803548818, 'validation/loss': 0.2846497131588087, 'validation/num_examples': 3554, 'test/ssim': 0.7440500182168039, 'test/loss': 0.2860044358463069, 'test/num_examples': 3581, 'score': 8481.344739675522, 'total_duration': 9196.78335905075, 'global_step': 36189, 'preemption_count': 0})], 'global_step': 36189}
I0302 04:05:24.257623 139915712112448 submission_runner.py:523] Timing: 8481.344739675522
I0302 04:05:24.257667 139915712112448 submission_runner.py:524] ====================
I0302 04:05:24.257876 139915712112448 submission_runner.py:583] Final fastmri score: 8481.344739675522
