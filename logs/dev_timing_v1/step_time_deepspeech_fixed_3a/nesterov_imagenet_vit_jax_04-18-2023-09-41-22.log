I0418 09:41:45.647290 139725965485888 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax.
I0418 09:41:45.715780 139725965485888 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0418 09:41:46.603611 139725965485888 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Host Interpreter
I0418 09:41:46.604260 139725965485888 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0418 09:41:46.608571 139725965485888 submission_runner.py:528] Using RNG seed 855926677
I0418 09:41:49.242370 139725965485888 submission_runner.py:537] --- Tuning run 1/1 ---
I0418 09:41:49.242554 139725965485888 submission_runner.py:542] Creating tuning directory at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1.
I0418 09:41:49.242717 139725965485888 logger_utils.py:83] Saving hparams to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/hparams.json.
I0418 09:41:49.363797 139725965485888 submission_runner.py:232] Initializing dataset.
I0418 09:41:49.375702 139725965485888 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0418 09:41:49.383350 139725965485888 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0418 09:41:49.383460 139725965485888 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0418 09:41:49.641176 139725965485888 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0418 09:41:56.242228 139725965485888 submission_runner.py:239] Initializing model.
I0418 09:42:07.020078 139725965485888 submission_runner.py:249] Initializing optimizer.
I0418 09:42:07.498071 139725965485888 submission_runner.py:256] Initializing metrics bundle.
I0418 09:42:07.498252 139725965485888 submission_runner.py:273] Initializing checkpoint and logger.
I0418 09:42:07.499115 139725965485888 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1 with prefix checkpoint_
I0418 09:42:08.197172 139725965485888 submission_runner.py:294] Saving meta data to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/meta_data_0.json.
I0418 09:42:08.198151 139725965485888 submission_runner.py:297] Saving flags to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/flags_0.json.
I0418 09:42:08.202926 139725965485888 submission_runner.py:309] Starting training loop.
I0418 09:42:55.541533 139548336051968 logging_writer.py:48] [0] global_step=0, grad_norm=0.2905541956424713, loss=6.9077534675598145
I0418 09:42:55.558205 139725965485888 spec.py:298] Evaluating on the training split.
I0418 09:42:55.564454 139725965485888 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0418 09:42:55.570714 139725965485888 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0418 09:42:55.570827 139725965485888 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0418 09:42:55.634307 139725965485888 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0418 09:43:15.157807 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 09:43:15.167022 139725965485888 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0418 09:43:15.179376 139725965485888 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0418 09:43:15.179585 139725965485888 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0418 09:43:15.229377 139725965485888 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0418 09:43:33.660635 139725965485888 spec.py:326] Evaluating on the test split.
I0418 09:43:33.667759 139725965485888 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0418 09:43:33.673101 139725965485888 dataset_builder.py:510] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0418 09:43:33.706453 139725965485888 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0418 09:43:44.640405 139725965485888 submission_runner.py:406] Time since start: 96.44s, 	Step: 1, 	{'train/accuracy': 0.0008984374580904841, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 47.355101346969604, 'total_duration': 96.43742775917053, 'accumulated_submission_time': 47.355101346969604, 'accumulated_eval_time': 49.082154750823975, 'accumulated_logging_time': 0}
I0418 09:43:44.656955 139489053763328 logging_writer.py:48] [1] accumulated_eval_time=49.082155, accumulated_logging_time=0, accumulated_submission_time=47.355101, global_step=1, preemption_count=0, score=47.355101, test/accuracy=0.001000, test/loss=6.907757, test/num_examples=10000, total_duration=96.437428, train/accuracy=0.000898, train/loss=6.907756, validation/accuracy=0.001000, validation/loss=6.907756, validation/num_examples=50000
I0418 09:43:44.766979 139725965485888 checkpoints.py:356] Saving checkpoint at step: 1
I0418 09:43:45.303119 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_1
I0418 09:43:45.303912 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_1.
I0418 09:44:39.988273 139543458039552 logging_writer.py:48] [100] global_step=100, grad_norm=0.29294124245643616, loss=6.9055376052856445
I0418 09:45:21.503478 139543466432256 logging_writer.py:48] [200] global_step=200, grad_norm=0.29434776306152344, loss=6.895899295806885
I0418 09:46:03.114411 139543458039552 logging_writer.py:48] [300] global_step=300, grad_norm=0.31306466460227966, loss=6.88141393661499
I0418 09:46:44.675446 139543466432256 logging_writer.py:48] [400] global_step=400, grad_norm=0.49992212653160095, loss=6.819204330444336
I0418 09:47:26.271698 139543458039552 logging_writer.py:48] [500] global_step=500, grad_norm=0.8988189101219177, loss=6.741367816925049
I0418 09:48:07.868290 139543466432256 logging_writer.py:48] [600] global_step=600, grad_norm=0.9453520178794861, loss=6.669085502624512
I0418 09:48:49.358060 139543458039552 logging_writer.py:48] [700] global_step=700, grad_norm=0.8823655247688293, loss=6.808304309844971
I0418 09:49:31.143359 139543466432256 logging_writer.py:48] [800] global_step=800, grad_norm=0.9450005888938904, loss=6.558021068572998
I0418 09:50:12.777583 139543458039552 logging_writer.py:48] [900] global_step=900, grad_norm=1.0262298583984375, loss=6.513345718383789
I0418 09:50:45.493311 139725965485888 spec.py:298] Evaluating on the training split.
I0418 09:50:56.225646 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 09:51:02.689801 139725965485888 spec.py:326] Evaluating on the test split.
I0418 09:51:04.729294 139725965485888 submission_runner.py:406] Time since start: 536.53s, 	Step: 980, 	{'train/accuracy': 0.0380859375, 'train/loss': 6.04341459274292, 'validation/accuracy': 0.0364999994635582, 'validation/loss': 6.067896842956543, 'validation/num_examples': 50000, 'test/accuracy': 0.027700001373887062, 'test/loss': 6.168490886688232, 'test/num_examples': 10000, 'score': 467.5246934890747, 'total_duration': 536.5262660980225, 'accumulated_submission_time': 467.5246934890747, 'accumulated_eval_time': 68.3180878162384, 'accumulated_logging_time': 0.6644711494445801}
I0418 09:51:04.763326 139489431238400 logging_writer.py:48] [980] accumulated_eval_time=68.318088, accumulated_logging_time=0.664471, accumulated_submission_time=467.524693, global_step=980, preemption_count=0, score=467.524693, test/accuracy=0.027700, test/loss=6.168491, test/num_examples=10000, total_duration=536.526266, train/accuracy=0.038086, train/loss=6.043415, validation/accuracy=0.036500, validation/loss=6.067897, validation/num_examples=50000
I0418 09:51:05.357791 139725965485888 checkpoints.py:356] Saving checkpoint at step: 980
I0418 09:51:06.725586 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_980
I0418 09:51:06.727385 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_980.
I0418 09:51:15.468907 139489439631104 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.0256677865982056, loss=6.545823574066162
I0418 09:51:57.064766 139548319266560 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.8415993452072144, loss=6.4292497634887695
I0418 09:52:38.783185 139489439631104 logging_writer.py:48] [1200] global_step=1200, grad_norm=1.1231695413589478, loss=6.493365287780762
I0418 09:53:22.478775 139548319266560 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.9925358295440674, loss=6.587536334991455
I0418 09:54:04.124890 139489439631104 logging_writer.py:48] [1400] global_step=1400, grad_norm=1.2183773517608643, loss=6.431924343109131
I0418 09:54:45.747935 139548319266560 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.9124815464019775, loss=6.532612323760986
I0418 09:55:27.122666 139489439631104 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.9883570671081543, loss=6.263039588928223
I0418 09:56:08.917793 139548319266560 logging_writer.py:48] [1700] global_step=1700, grad_norm=1.1089885234832764, loss=6.305683612823486
I0418 09:56:50.662804 139489439631104 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.9153351187705994, loss=6.250332832336426
I0418 09:57:32.400786 139548319266560 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.9184197187423706, loss=6.689722061157227
I0418 09:58:07.118705 139725965485888 spec.py:298] Evaluating on the training split.
I0418 09:58:17.586919 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 09:58:24.171292 139725965485888 spec.py:326] Evaluating on the test split.
I0418 09:58:25.898613 139725965485888 submission_runner.py:406] Time since start: 977.70s, 	Step: 1984, 	{'train/accuracy': 0.06900390237569809, 'train/loss': 5.5743231773376465, 'validation/accuracy': 0.06521999835968018, 'validation/loss': 5.6049981117248535, 'validation/num_examples': 50000, 'test/accuracy': 0.05010000243782997, 'test/loss': 5.770705699920654, 'test/num_examples': 10000, 'score': 887.8947412967682, 'total_duration': 977.6956031322479, 'accumulated_submission_time': 887.8947412967682, 'accumulated_eval_time': 87.09795045852661, 'accumulated_logging_time': 2.6638894081115723}
I0418 09:58:25.912022 139489439631104 logging_writer.py:48] [1984] accumulated_eval_time=87.097950, accumulated_logging_time=2.663889, accumulated_submission_time=887.894741, global_step=1984, preemption_count=0, score=887.894741, test/accuracy=0.050100, test/loss=5.770706, test/num_examples=10000, total_duration=977.695603, train/accuracy=0.069004, train/loss=5.574323, validation/accuracy=0.065220, validation/loss=5.604998, validation/num_examples=50000
I0418 09:58:26.275625 139725965485888 checkpoints.py:356] Saving checkpoint at step: 1984
I0418 09:58:28.091303 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_1984
I0418 09:58:28.096191 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_1984.
I0418 09:58:35.131847 139548319266560 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.7923005223274231, loss=6.471858978271484
I0418 09:59:16.504977 139548436698880 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.9667310118675232, loss=6.242883205413818
I0418 09:59:58.180744 139548319266560 logging_writer.py:48] [2200] global_step=2200, grad_norm=1.0364493131637573, loss=6.19736385345459
I0418 10:00:39.608455 139548436698880 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.7021260261535645, loss=6.354440689086914
I0418 10:01:21.187208 139548319266560 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.8223069906234741, loss=6.179327964782715
I0418 10:02:02.712360 139548436698880 logging_writer.py:48] [2500] global_step=2500, grad_norm=1.2499794960021973, loss=6.740154266357422
I0418 10:02:44.192703 139548319266560 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.7014897465705872, loss=6.5833282470703125
I0418 10:03:25.867171 139548436698880 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.7453967928886414, loss=6.1706132888793945
I0418 10:04:07.698994 139548319266560 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.8751651048660278, loss=6.084410190582275
I0418 10:04:49.291206 139548436698880 logging_writer.py:48] [2900] global_step=2900, grad_norm=1.0728338956832886, loss=6.338953971862793
I0418 10:05:28.213072 139725965485888 spec.py:298] Evaluating on the training split.
I0418 10:05:38.996850 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 10:05:45.519068 139725965485888 spec.py:326] Evaluating on the test split.
I0418 10:05:47.252584 139725965485888 submission_runner.py:406] Time since start: 1419.05s, 	Step: 2995, 	{'train/accuracy': 0.1005273386836052, 'train/loss': 5.207403659820557, 'validation/accuracy': 0.09352000057697296, 'validation/loss': 5.251680374145508, 'validation/num_examples': 50000, 'test/accuracy': 0.06890000402927399, 'test/loss': 5.488145351409912, 'test/num_examples': 10000, 'score': 1307.9904942512512, 'total_duration': 1419.049589395523, 'accumulated_submission_time': 1307.9904942512512, 'accumulated_eval_time': 106.13783574104309, 'accumulated_logging_time': 4.862898588180542}
I0418 10:05:47.266354 139548319266560 logging_writer.py:48] [2995] accumulated_eval_time=106.137836, accumulated_logging_time=4.862899, accumulated_submission_time=1307.990494, global_step=2995, preemption_count=0, score=1307.990494, test/accuracy=0.068900, test/loss=5.488145, test/num_examples=10000, total_duration=1419.049589, train/accuracy=0.100527, train/loss=5.207404, validation/accuracy=0.093520, validation/loss=5.251680, validation/num_examples=50000
I0418 10:05:47.380213 139725965485888 checkpoints.py:356] Saving checkpoint at step: 2995
I0418 10:05:49.907401 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_2995
I0418 10:05:49.910202 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_2995.
I0418 10:05:52.432469 139548436698880 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.7492761611938477, loss=6.011436939239502
I0418 10:06:34.092122 139548411520768 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.8287074565887451, loss=6.074492454528809
I0418 10:07:15.694587 139548436698880 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.7418487668037415, loss=6.2825517654418945
I0418 10:07:57.266858 139548411520768 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.9019405841827393, loss=6.216460704803467
I0418 10:08:38.858410 139548436698880 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.7323495149612427, loss=6.01993989944458
I0418 10:09:20.537449 139548411520768 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.7664223909378052, loss=6.052947521209717
I0418 10:10:02.093374 139548436698880 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.8080491423606873, loss=5.989432334899902
I0418 10:10:43.849037 139548411520768 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.6375601887702942, loss=6.259312152862549
I0418 10:11:25.538416 139548436698880 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.7466307282447815, loss=5.912234306335449
I0418 10:12:07.038226 139548411520768 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.7171560525894165, loss=6.1646728515625
I0418 10:12:48.728627 139548436698880 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.6742187142372131, loss=6.14238977432251
I0418 10:12:50.102861 139725965485888 spec.py:298] Evaluating on the training split.
I0418 10:13:00.903879 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 10:13:07.524687 139725965485888 spec.py:326] Evaluating on the test split.
I0418 10:13:09.243496 139725965485888 submission_runner.py:406] Time since start: 1861.04s, 	Step: 4005, 	{'train/accuracy': 0.1371484398841858, 'train/loss': 4.827167987823486, 'validation/accuracy': 0.11653999984264374, 'validation/loss': 4.96237325668335, 'validation/num_examples': 50000, 'test/accuracy': 0.08800000697374344, 'test/loss': 5.238028526306152, 'test/num_examples': 10000, 'score': 1728.1618773937225, 'total_duration': 1861.0405068397522, 'accumulated_submission_time': 1728.1618773937225, 'accumulated_eval_time': 125.27846503257751, 'accumulated_logging_time': 7.522132158279419}
I0418 10:13:09.256914 139548411520768 logging_writer.py:48] [4005] accumulated_eval_time=125.278465, accumulated_logging_time=7.522132, accumulated_submission_time=1728.161877, global_step=4005, preemption_count=0, score=1728.161877, test/accuracy=0.088000, test/loss=5.238029, test/num_examples=10000, total_duration=1861.040507, train/accuracy=0.137148, train/loss=4.827168, validation/accuracy=0.116540, validation/loss=4.962373, validation/num_examples=50000
I0418 10:13:09.370672 139725965485888 checkpoints.py:356] Saving checkpoint at step: 4005
I0418 10:13:11.616428 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_4005
I0418 10:13:11.628669 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_4005.
I0418 10:13:51.460326 139548436698880 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.7559635043144226, loss=5.914913177490234
I0418 10:14:33.131146 139548327659264 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.7495443224906921, loss=5.862797737121582
I0418 10:15:14.834692 139548436698880 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.6990653872489929, loss=6.036336898803711
I0418 10:15:56.505641 139548327659264 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.7426028847694397, loss=5.908291339874268
I0418 10:16:38.329718 139548436698880 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.8068084120750427, loss=6.701547145843506
I0418 10:17:20.035800 139548327659264 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.6546546816825867, loss=5.889839172363281
I0418 10:18:01.688552 139548436698880 logging_writer.py:48] [4700] global_step=4700, grad_norm=1.4693036079406738, loss=5.927087783813477
I0418 10:18:43.660823 139548327659264 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.6369960904121399, loss=5.8803253173828125
I0418 10:19:25.369967 139548436698880 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.5394343137741089, loss=6.5670061111450195
I0418 10:20:07.382615 139548327659264 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.8391129374504089, loss=5.7934370040893555
I0418 10:20:11.758683 139725965485888 spec.py:298] Evaluating on the training split.
I0418 10:20:22.703815 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 10:20:29.581846 139725965485888 spec.py:326] Evaluating on the test split.
I0418 10:20:31.306155 139725965485888 submission_runner.py:406] Time since start: 2303.10s, 	Step: 5012, 	{'train/accuracy': 0.1635156273841858, 'train/loss': 4.583794116973877, 'validation/accuracy': 0.15067999064922333, 'validation/loss': 4.659067153930664, 'validation/num_examples': 50000, 'test/accuracy': 0.11360000818967819, 'test/loss': 4.985012054443359, 'test/num_examples': 10000, 'score': 2148.271285533905, 'total_duration': 2303.1031243801117, 'accumulated_submission_time': 2148.271285533905, 'accumulated_eval_time': 144.82586526870728, 'accumulated_logging_time': 9.908594131469727}
I0418 10:20:31.319272 139548436698880 logging_writer.py:48] [5012] accumulated_eval_time=144.825865, accumulated_logging_time=9.908594, accumulated_submission_time=2148.271286, global_step=5012, preemption_count=0, score=2148.271286, test/accuracy=0.113600, test/loss=4.985012, test/num_examples=10000, total_duration=2303.103124, train/accuracy=0.163516, train/loss=4.583794, validation/accuracy=0.150680, validation/loss=4.659067, validation/num_examples=50000
I0418 10:20:31.434213 139725965485888 checkpoints.py:356] Saving checkpoint at step: 5012
I0418 10:20:33.009615 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_5012
I0418 10:20:33.012423 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_5012.
I0418 10:21:09.817739 139548327659264 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.7770310640335083, loss=5.784089088439941
I0418 10:21:51.333320 139548319266560 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.5142847299575806, loss=6.499905109405518
I0418 10:22:33.078001 139548327659264 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.595853328704834, loss=6.302968978881836
I0418 10:23:14.751688 139548319266560 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.5428503155708313, loss=6.55435848236084
I0418 10:23:56.477939 139548327659264 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.6909493803977966, loss=5.881046295166016
I0418 10:24:38.262947 139548319266560 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.8000583052635193, loss=5.6983561515808105
I0418 10:25:20.221816 139548327659264 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.7123011350631714, loss=5.639396667480469
I0418 10:26:01.974226 139548319266560 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.7229005098342896, loss=5.872182369232178
I0418 10:26:43.861823 139548327659264 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.8711791038513184, loss=5.731208801269531
I0418 10:27:25.813009 139548319266560 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.6994120478630066, loss=5.8337721824646
I0418 10:27:33.114324 139725965485888 spec.py:298] Evaluating on the training split.
I0418 10:27:43.893081 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 10:27:50.551154 139725965485888 spec.py:326] Evaluating on the test split.
I0418 10:27:52.276823 139725965485888 submission_runner.py:406] Time since start: 2744.07s, 	Step: 6019, 	{'train/accuracy': 0.18886718153953552, 'train/loss': 4.421493053436279, 'validation/accuracy': 0.17295999825000763, 'validation/loss': 4.508814811706543, 'validation/num_examples': 50000, 'test/accuracy': 0.13260000944137573, 'test/loss': 4.830865859985352, 'test/num_examples': 10000, 'score': 2568.3523111343384, 'total_duration': 2744.073734521866, 'accumulated_submission_time': 2568.3523111343384, 'accumulated_eval_time': 163.9882435798645, 'accumulated_logging_time': 11.616264343261719}
I0418 10:27:52.288580 139548327659264 logging_writer.py:48] [6019] accumulated_eval_time=163.988244, accumulated_logging_time=11.616264, accumulated_submission_time=2568.352311, global_step=6019, preemption_count=0, score=2568.352311, test/accuracy=0.132600, test/loss=4.830866, test/num_examples=10000, total_duration=2744.073735, train/accuracy=0.188867, train/loss=4.421493, validation/accuracy=0.172960, validation/loss=4.508815, validation/num_examples=50000
I0418 10:27:52.386979 139725965485888 checkpoints.py:356] Saving checkpoint at step: 6019
I0418 10:27:54.605017 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_6019
I0418 10:27:54.619754 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_6019.
I0418 10:28:28.669486 139548319266560 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.6825799345970154, loss=5.780890941619873
I0418 10:29:10.052486 139548310873856 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.5640481114387512, loss=6.314740180969238
I0418 10:29:51.723661 139548319266560 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.9544968605041504, loss=5.569889068603516
I0418 10:30:33.271914 139548310873856 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.5965830087661743, loss=5.550205230712891
I0418 10:31:14.890627 139548319266560 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.46994930505752563, loss=6.531034469604492
I0418 10:31:56.637332 139548310873856 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.7066866159439087, loss=5.544845104217529
I0418 10:32:38.693533 139548319266560 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.6564438939094543, loss=5.584458351135254
I0418 10:33:20.686114 139548310873856 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.7178549766540527, loss=5.4208598136901855
I0418 10:34:02.705194 139548319266560 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.8332870006561279, loss=6.044713020324707
I0418 10:34:44.488276 139548310873856 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.6392014622688293, loss=5.438266754150391
I0418 10:34:54.718698 139725965485888 spec.py:298] Evaluating on the training split.
I0418 10:35:05.831669 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 10:35:13.830590 139725965485888 spec.py:326] Evaluating on the test split.
I0418 10:35:15.527757 139725965485888 submission_runner.py:406] Time since start: 3187.32s, 	Step: 7026, 	{'train/accuracy': 0.2374609261751175, 'train/loss': 4.050613880157471, 'validation/accuracy': 0.21639999747276306, 'validation/loss': 4.165241241455078, 'validation/num_examples': 50000, 'test/accuracy': 0.16170001029968262, 'test/loss': 4.558784008026123, 'test/num_examples': 10000, 'score': 2988.4303283691406, 'total_duration': 3187.324772119522, 'accumulated_submission_time': 2988.4303283691406, 'accumulated_eval_time': 184.79728412628174, 'accumulated_logging_time': 13.96054220199585}
I0418 10:35:15.539965 139548319266560 logging_writer.py:48] [7026] accumulated_eval_time=184.797284, accumulated_logging_time=13.960542, accumulated_submission_time=2988.430328, global_step=7026, preemption_count=0, score=2988.430328, test/accuracy=0.161700, test/loss=4.558784, test/num_examples=10000, total_duration=3187.324772, train/accuracy=0.237461, train/loss=4.050614, validation/accuracy=0.216400, validation/loss=4.165241, validation/num_examples=50000
I0418 10:35:15.646074 139725965485888 checkpoints.py:356] Saving checkpoint at step: 7026
I0418 10:35:16.940275 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_7026
I0418 10:35:16.953103 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_7026.
I0418 10:35:48.209464 139548310873856 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.7220574021339417, loss=5.409390449523926
I0418 10:36:29.549351 139548302481152 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.6556109189987183, loss=5.459853649139404
I0418 10:37:11.202419 139548310873856 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.5924914479255676, loss=5.75871467590332
I0418 10:37:52.891029 139548302481152 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.632594108581543, loss=5.337169647216797
I0418 10:38:34.770879 139548310873856 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.5045010447502136, loss=6.158109664916992
I0418 10:39:16.635454 139548302481152 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.4423750042915344, loss=6.414125442504883
I0418 10:39:59.313067 139548310873856 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.7675862908363342, loss=5.474267482757568
I0418 10:40:41.435845 139548302481152 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.6702612042427063, loss=5.394220352172852
I0418 10:41:23.457837 139548310873856 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.6012189984321594, loss=5.739323139190674
I0418 10:42:05.438827 139548302481152 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.4570530652999878, loss=6.327517509460449
I0418 10:42:16.966555 139725965485888 spec.py:298] Evaluating on the training split.
I0418 10:42:28.938179 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 10:42:37.384343 139725965485888 spec.py:326] Evaluating on the test split.
I0418 10:42:39.081990 139725965485888 submission_runner.py:406] Time since start: 3630.88s, 	Step: 8029, 	{'train/accuracy': 0.2777343690395355, 'train/loss': 3.7647171020507812, 'validation/accuracy': 0.24393999576568604, 'validation/loss': 3.9391419887542725, 'validation/num_examples': 50000, 'test/accuracy': 0.18090000748634338, 'test/loss': 4.377520561218262, 'test/num_examples': 10000, 'score': 3408.422794342041, 'total_duration': 3630.878957271576, 'accumulated_submission_time': 3408.422794342041, 'accumulated_eval_time': 206.91264510154724, 'accumulated_logging_time': 15.387310266494751}
I0418 10:42:39.096003 139548310873856 logging_writer.py:48] [8029] accumulated_eval_time=206.912645, accumulated_logging_time=15.387310, accumulated_submission_time=3408.422794, global_step=8029, preemption_count=0, score=3408.422794, test/accuracy=0.180900, test/loss=4.377521, test/num_examples=10000, total_duration=3630.878957, train/accuracy=0.277734, train/loss=3.764717, validation/accuracy=0.243940, validation/loss=3.939142, validation/num_examples=50000
I0418 10:42:39.203522 139725965485888 checkpoints.py:356] Saving checkpoint at step: 8029
I0418 10:42:40.154629 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_8029
I0418 10:42:40.165349 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_8029.
I0418 10:43:10.210309 139548302481152 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.6105413436889648, loss=5.1875786781311035
I0418 10:43:51.874815 139548294088448 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.4524984061717987, loss=6.248138427734375
I0418 10:44:33.805203 139548302481152 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.6551390290260315, loss=5.2691779136657715
I0418 10:45:15.634050 139548294088448 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.41013506054878235, loss=6.412737846374512
I0418 10:45:57.480463 139548302481152 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.4370373785495758, loss=6.412775039672852
I0418 10:46:39.278877 139548294088448 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.6695935130119324, loss=5.2321038246154785
I0418 10:47:21.244294 139548302481152 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.5089414119720459, loss=6.4562578201293945
I0418 10:48:03.562065 139548294088448 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.5459302067756653, loss=6.006649971008301
I0418 10:48:46.377764 139548302481152 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.5668678879737854, loss=5.92351770401001
I0418 10:49:29.276445 139548294088448 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.766960859298706, loss=5.306175231933594
I0418 10:49:40.299675 139725965485888 spec.py:298] Evaluating on the training split.
I0418 10:49:53.494761 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 10:50:02.710556 139725965485888 spec.py:326] Evaluating on the test split.
I0418 10:50:04.375237 139725965485888 submission_runner.py:406] Time since start: 4076.17s, 	Step: 9028, 	{'train/accuracy': 0.29966795444488525, 'train/loss': 3.5713510513305664, 'validation/accuracy': 0.2738199830055237, 'validation/loss': 3.6930508613586426, 'validation/num_examples': 50000, 'test/accuracy': 0.20980000495910645, 'test/loss': 4.16384744644165, 'test/num_examples': 10000, 'score': 3828.536628007889, 'total_duration': 4076.172243833542, 'accumulated_submission_time': 3828.536628007889, 'accumulated_eval_time': 230.98818492889404, 'accumulated_logging_time': 16.472405195236206}
I0418 10:50:04.386779 139548302481152 logging_writer.py:48] [9028] accumulated_eval_time=230.988185, accumulated_logging_time=16.472405, accumulated_submission_time=3828.536628, global_step=9028, preemption_count=0, score=3828.536628, test/accuracy=0.209800, test/loss=4.163847, test/num_examples=10000, total_duration=4076.172244, train/accuracy=0.299668, train/loss=3.571351, validation/accuracy=0.273820, validation/loss=3.693051, validation/num_examples=50000
I0418 10:50:04.513696 139725965485888 checkpoints.py:356] Saving checkpoint at step: 9028
I0418 10:50:05.383348 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_9028
I0418 10:50:05.394141 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_9028.
I0418 10:50:35.856484 139548294088448 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.6862896680831909, loss=5.165626049041748
I0418 10:51:17.772327 139548285695744 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.6664158701896667, loss=5.145010948181152
I0418 10:51:59.391007 139548294088448 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.6779641509056091, loss=5.232287406921387
I0418 10:52:41.127998 139548285695744 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.6656209826469421, loss=5.418266296386719
I0418 10:53:22.983568 139548294088448 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.636658251285553, loss=5.6363067626953125
I0418 10:54:05.230735 139548285695744 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.5658316612243652, loss=6.399508953094482
I0418 10:54:47.121779 139548294088448 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.6385406255722046, loss=5.838424205780029
I0418 10:55:29.262597 139548285695744 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.614145040512085, loss=5.30272912979126
I0418 10:56:11.525845 139548294088448 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.6912693977355957, loss=5.113536357879639
I0418 10:56:54.025592 139548285695744 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.7314532399177551, loss=5.084043502807617
I0418 10:57:05.693490 139725965485888 spec.py:298] Evaluating on the training split.
I0418 10:57:18.984825 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 10:57:29.096972 139725965485888 spec.py:326] Evaluating on the test split.
I0418 10:57:30.769353 139725965485888 submission_runner.py:406] Time since start: 4522.57s, 	Step: 10029, 	{'train/accuracy': 0.33134764432907104, 'train/loss': 3.4058403968811035, 'validation/accuracy': 0.3026999831199646, 'validation/loss': 3.5449271202087402, 'validation/num_examples': 50000, 'test/accuracy': 0.22910000383853912, 'test/loss': 4.047345161437988, 'test/num_examples': 10000, 'score': 4248.8159263134, 'total_duration': 4522.56636095047, 'accumulated_submission_time': 4248.8159263134, 'accumulated_eval_time': 256.0640115737915, 'accumulated_logging_time': 17.49241876602173}
I0418 10:57:30.781371 139548294088448 logging_writer.py:48] [10029] accumulated_eval_time=256.064012, accumulated_logging_time=17.492419, accumulated_submission_time=4248.815926, global_step=10029, preemption_count=0, score=4248.815926, test/accuracy=0.229100, test/loss=4.047345, test/num_examples=10000, total_duration=4522.566361, train/accuracy=0.331348, train/loss=3.405840, validation/accuracy=0.302700, validation/loss=3.544927, validation/num_examples=50000
I0418 10:57:30.878174 139725965485888 checkpoints.py:356] Saving checkpoint at step: 10029
I0418 10:57:31.693591 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_10029
I0418 10:57:31.704622 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_10029.
I0418 10:58:01.732556 139548285695744 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.6156448125839233, loss=5.043854713439941
I0418 10:58:43.353962 139548277303040 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.3877663314342499, loss=6.2706475257873535
I0418 10:59:25.142930 139548285695744 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.7345551252365112, loss=5.014934539794922
I0418 11:00:06.899559 139548277303040 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.43038123846054077, loss=6.1914286613464355
I0418 11:00:48.808179 139548285695744 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.7152831554412842, loss=5.011262893676758
I0418 11:01:30.587795 139548277303040 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.5798528790473938, loss=4.978208541870117
I0418 11:02:12.468244 139548285695744 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.5987895727157593, loss=4.930745601654053
I0418 11:02:54.307462 139548277303040 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.5754554271697998, loss=5.19474983215332
I0418 11:03:36.982022 139548285695744 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.45977306365966797, loss=5.6551337242126465
I0418 11:04:19.795224 139548277303040 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.6475256085395813, loss=4.949639320373535
I0418 11:04:31.872783 139725965485888 spec.py:298] Evaluating on the training split.
I0418 11:04:46.050812 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 11:04:56.330166 139725965485888 spec.py:326] Evaluating on the test split.
I0418 11:04:57.992811 139725965485888 submission_runner.py:406] Time since start: 4969.79s, 	Step: 11030, 	{'train/accuracy': 0.3590429723262787, 'train/loss': 3.217349052429199, 'validation/accuracy': 0.32646000385284424, 'validation/loss': 3.3776917457580566, 'validation/num_examples': 50000, 'test/accuracy': 0.25050002336502075, 'test/loss': 3.8918797969818115, 'test/num_examples': 10000, 'score': 4668.96368265152, 'total_duration': 4969.789789199829, 'accumulated_submission_time': 4668.96368265152, 'accumulated_eval_time': 282.18397092819214, 'accumulated_logging_time': 18.429189205169678}
I0418 11:04:58.008023 139548285695744 logging_writer.py:48] [11030] accumulated_eval_time=282.183971, accumulated_logging_time=18.429189, accumulated_submission_time=4668.963683, global_step=11030, preemption_count=0, score=4668.963683, test/accuracy=0.250500, test/loss=3.891880, test/num_examples=10000, total_duration=4969.789789, train/accuracy=0.359043, train/loss=3.217349, validation/accuracy=0.326460, validation/loss=3.377692, validation/num_examples=50000
I0418 11:04:58.125574 139725965485888 checkpoints.py:356] Saving checkpoint at step: 11030
I0418 11:04:58.975842 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_11030
I0418 11:04:58.988590 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_11030.
I0418 11:05:28.556524 139548277303040 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.6195610761642456, loss=5.057868957519531
I0418 11:06:10.575793 139548268910336 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.5774967670440674, loss=5.285789489746094
I0418 11:06:52.387434 139548277303040 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.6446650624275208, loss=4.8589887619018555
I0418 11:07:34.395678 139548268910336 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.7999012470245361, loss=4.973128795623779
I0418 11:08:16.510427 139548277303040 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.47279423475265503, loss=6.318503379821777
I0418 11:08:58.451201 139548268910336 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.6515275835990906, loss=4.874167442321777
I0418 11:09:40.310172 139548277303040 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.6357152462005615, loss=5.010655403137207
I0418 11:10:22.659109 139548268910336 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.6557978391647339, loss=4.813739776611328
I0418 11:11:04.797980 139548277303040 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.5836144685745239, loss=4.790822982788086
I0418 11:11:47.579960 139548268910336 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.632137656211853, loss=4.81353759765625
I0418 11:11:59.342001 139725965485888 spec.py:298] Evaluating on the training split.
I0418 11:12:13.984271 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 11:12:24.523703 139725965485888 spec.py:326] Evaluating on the test split.
I0418 11:12:26.196303 139725965485888 submission_runner.py:406] Time since start: 5417.99s, 	Step: 12029, 	{'train/accuracy': 0.39720702171325684, 'train/loss': 3.0174014568328857, 'validation/accuracy': 0.3565399944782257, 'validation/loss': 3.2220492362976074, 'validation/num_examples': 50000, 'test/accuracy': 0.27000001072883606, 'test/loss': 3.755986213684082, 'test/num_examples': 10000, 'score': 5089.289659976959, 'total_duration': 5417.99328327179, 'accumulated_submission_time': 5089.289659976959, 'accumulated_eval_time': 309.0382170677185, 'accumulated_logging_time': 19.43401336669922}
I0418 11:12:26.211169 139548277303040 logging_writer.py:48] [12029] accumulated_eval_time=309.038217, accumulated_logging_time=19.434013, accumulated_submission_time=5089.289660, global_step=12029, preemption_count=0, score=5089.289660, test/accuracy=0.270000, test/loss=3.755986, test/num_examples=10000, total_duration=5417.993283, train/accuracy=0.397207, train/loss=3.017401, validation/accuracy=0.356540, validation/loss=3.222049, validation/num_examples=50000
I0418 11:12:26.389473 139725965485888 checkpoints.py:356] Saving checkpoint at step: 12029
I0418 11:12:27.406718 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_12029
I0418 11:12:27.419353 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_12029.
I0418 11:12:57.271582 139548268910336 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.6437678933143616, loss=4.907963275909424
I0418 11:13:39.239069 139548193441536 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.6504791378974915, loss=4.842004776000977
I0418 11:14:21.436984 139548268910336 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.6867741346359253, loss=5.016268730163574
I0418 11:15:03.400448 139548193441536 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.5666234493255615, loss=5.0615386962890625
I0418 11:15:45.623059 139548268910336 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.6502217054367065, loss=4.757663726806641
I0418 11:16:27.618360 139548193441536 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.6555809378623962, loss=4.8696112632751465
I0418 11:17:09.835478 139548268910336 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.6016902327537537, loss=4.80610466003418
I0418 11:17:52.438349 139548193441536 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.5993404984474182, loss=5.014917373657227
I0418 11:18:34.953374 139548268910336 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.4908457398414612, loss=6.320976734161377
I0418 11:19:17.502784 139548193441536 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.6290112137794495, loss=4.73984956741333
I0418 11:19:27.422184 139725965485888 spec.py:298] Evaluating on the training split.
I0418 11:19:42.462344 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 11:19:53.034602 139725965485888 spec.py:326] Evaluating on the test split.
I0418 11:19:54.721118 139725965485888 submission_runner.py:406] Time since start: 5866.52s, 	Step: 13025, 	{'train/accuracy': 0.40562498569488525, 'train/loss': 2.927992582321167, 'validation/accuracy': 0.3734000027179718, 'validation/loss': 3.0815927982330322, 'validation/num_examples': 50000, 'test/accuracy': 0.2898000180721283, 'test/loss': 3.6270172595977783, 'test/num_examples': 10000, 'score': 5509.27228140831, 'total_duration': 5866.518084049225, 'accumulated_submission_time': 5509.27228140831, 'accumulated_eval_time': 336.33707785606384, 'accumulated_logging_time': 20.658891916275024}
I0418 11:19:54.735038 139548268910336 logging_writer.py:48] [13025] accumulated_eval_time=336.337078, accumulated_logging_time=20.658892, accumulated_submission_time=5509.272281, global_step=13025, preemption_count=0, score=5509.272281, test/accuracy=0.289800, test/loss=3.627017, test/num_examples=10000, total_duration=5866.518084, train/accuracy=0.405625, train/loss=2.927993, validation/accuracy=0.373400, validation/loss=3.081593, validation/num_examples=50000
I0418 11:19:54.980277 139725965485888 checkpoints.py:356] Saving checkpoint at step: 13025
I0418 11:19:55.987528 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_13025
I0418 11:19:55.997475 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_13025.
I0418 11:20:27.622880 139548193441536 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.5976076126098633, loss=4.8058695793151855
I0418 11:21:09.866790 139548185048832 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.585080087184906, loss=4.901398181915283
I0418 11:21:52.523468 139548193441536 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.6672104597091675, loss=4.786974906921387
I0418 11:22:34.849813 139548185048832 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.5585498213768005, loss=5.052650451660156
I0418 11:23:16.999637 139548193441536 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.6785882711410522, loss=4.7134199142456055
I0418 11:23:59.026222 139548185048832 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.6221555471420288, loss=4.902154445648193
I0418 11:24:41.384336 139548193441536 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.6451619267463684, loss=4.62556791305542
I0418 11:25:24.240488 139548185048832 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.5781040787696838, loss=5.204721927642822
I0418 11:26:07.146121 139548193441536 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.6227630972862244, loss=4.736016750335693
I0418 11:26:49.958585 139548185048832 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.6958916783332825, loss=4.767245292663574
I0418 11:26:56.394298 139725965485888 spec.py:298] Evaluating on the training split.
I0418 11:27:11.100373 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 11:27:21.633769 139725965485888 spec.py:326] Evaluating on the test split.
I0418 11:27:23.308545 139725965485888 submission_runner.py:406] Time since start: 6315.11s, 	Step: 14017, 	{'train/accuracy': 0.4374414086341858, 'train/loss': 2.783097267150879, 'validation/accuracy': 0.3989599943161011, 'validation/loss': 2.954355239868164, 'validation/num_examples': 50000, 'test/accuracy': 0.30790001153945923, 'test/loss': 3.510413408279419, 'test/num_examples': 10000, 'score': 5929.647999048233, 'total_duration': 6315.105541944504, 'accumulated_submission_time': 5929.647999048233, 'accumulated_eval_time': 363.25127124786377, 'accumulated_logging_time': 21.93695878982544}
I0418 11:27:23.324318 139548193441536 logging_writer.py:48] [14017] accumulated_eval_time=363.251271, accumulated_logging_time=21.936959, accumulated_submission_time=5929.647999, global_step=14017, preemption_count=0, score=5929.647999, test/accuracy=0.307900, test/loss=3.510413, test/num_examples=10000, total_duration=6315.105542, train/accuracy=0.437441, train/loss=2.783097, validation/accuracy=0.398960, validation/loss=2.954355, validation/num_examples=50000
I0418 11:27:23.430619 139725965485888 checkpoints.py:356] Saving checkpoint at step: 14017
I0418 11:27:24.325088 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_14017
I0418 11:27:24.337954 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_14017.
I0418 11:27:59.322568 139548185048832 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.7082236409187317, loss=4.649164199829102
I0418 11:28:41.989879 139548176656128 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.7005462050437927, loss=4.590644359588623
I0418 11:29:24.515135 139548185048832 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.7163261771202087, loss=4.65485143661499
I0418 11:30:07.153373 139548176656128 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.5327187180519104, loss=5.1691389083862305
I0418 11:30:49.671325 139548185048832 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.6994683742523193, loss=4.712561130523682
I0418 11:31:32.038086 139548176656128 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.6429799795150757, loss=4.612094879150391
I0418 11:32:14.524008 139548185048832 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.5316591262817383, loss=6.006678104400635
I0418 11:32:57.115490 139548176656128 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.5413262844085693, loss=5.256927013397217
I0418 11:33:40.025012 139548185048832 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.6242892146110535, loss=4.801701068878174
I0418 11:34:22.537521 139548176656128 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.5731245279312134, loss=4.668413162231445
I0418 11:34:24.357857 139725965485888 spec.py:298] Evaluating on the training split.
I0418 11:34:39.108493 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 11:34:49.668732 139725965485888 spec.py:326] Evaluating on the test split.
I0418 11:34:51.343045 139725965485888 submission_runner.py:406] Time since start: 6763.14s, 	Step: 15006, 	{'train/accuracy': 0.4559374749660492, 'train/loss': 2.634718656539917, 'validation/accuracy': 0.41915997862815857, 'validation/loss': 2.817216396331787, 'validation/num_examples': 50000, 'test/accuracy': 0.32200002670288086, 'test/loss': 3.4150826930999756, 'test/num_examples': 10000, 'score': 6349.643064260483, 'total_duration': 6763.140064001083, 'accumulated_submission_time': 6349.643064260483, 'accumulated_eval_time': 390.23643732070923, 'accumulated_logging_time': 22.973034858703613}
I0418 11:34:51.355035 139548185048832 logging_writer.py:48] [15006] accumulated_eval_time=390.236437, accumulated_logging_time=22.973035, accumulated_submission_time=6349.643064, global_step=15006, preemption_count=0, score=6349.643064, test/accuracy=0.322000, test/loss=3.415083, test/num_examples=10000, total_duration=6763.140064, train/accuracy=0.455937, train/loss=2.634719, validation/accuracy=0.419160, validation/loss=2.817216, validation/num_examples=50000
I0418 11:34:51.533314 139725965485888 checkpoints.py:356] Saving checkpoint at step: 15006
I0418 11:34:52.418649 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_15006
I0418 11:34:52.432734 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_15006.
I0418 11:35:32.091529 139548176656128 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.5036916732788086, loss=5.532167911529541
I0418 11:36:14.490175 139548168263424 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.6158818602561951, loss=4.524868965148926
I0418 11:36:57.698690 139548176656128 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.6345089673995972, loss=4.70721960067749
I0418 11:37:40.092969 139548168263424 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.5904471278190613, loss=4.866157531738281
I0418 11:38:22.891403 139548176656128 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.607505738735199, loss=4.657814979553223
I0418 11:39:05.714216 139548168263424 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.770495593547821, loss=4.43581485748291
I0418 11:39:48.217332 139548176656128 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.656181812286377, loss=4.676455497741699
I0418 11:40:31.135911 139548168263424 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.6323404908180237, loss=4.61970853805542
I0418 11:41:13.745513 139548176656128 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.48804226517677307, loss=6.097487926483154
I0418 11:41:52.733396 139725965485888 spec.py:298] Evaluating on the training split.
I0418 11:42:07.446607 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 11:42:18.185726 139725965485888 spec.py:326] Evaluating on the test split.
I0418 11:42:19.837926 139725965485888 submission_runner.py:406] Time since start: 7211.63s, 	Step: 15993, 	{'train/accuracy': 0.46921873092651367, 'train/loss': 2.622598171234131, 'validation/accuracy': 0.41933998465538025, 'validation/loss': 2.8649752140045166, 'validation/num_examples': 50000, 'test/accuracy': 0.3232000172138214, 'test/loss': 3.4455127716064453, 'test/num_examples': 10000, 'score': 6769.924319028854, 'total_duration': 7211.634873390198, 'accumulated_submission_time': 6769.924319028854, 'accumulated_eval_time': 417.34088373184204, 'accumulated_logging_time': 24.06400465965271}
I0418 11:42:19.853524 139548168263424 logging_writer.py:48] [15993] accumulated_eval_time=417.340884, accumulated_logging_time=24.064005, accumulated_submission_time=6769.924319, global_step=15993, preemption_count=0, score=6769.924319, test/accuracy=0.323200, test/loss=3.445513, test/num_examples=10000, total_duration=7211.634873, train/accuracy=0.469219, train/loss=2.622598, validation/accuracy=0.419340, validation/loss=2.864975, validation/num_examples=50000
I0418 11:42:20.055851 139725965485888 checkpoints.py:356] Saving checkpoint at step: 15993
I0418 11:42:20.955359 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_15993
I0418 11:42:20.969661 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_15993.
I0418 11:42:24.275757 139548176656128 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.7094436287879944, loss=4.489357948303223
I0418 11:43:06.266134 139548159870720 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.6844913959503174, loss=4.597621917724609
I0418 11:43:48.364917 139548176656128 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.6373579502105713, loss=4.514137268066406
I0418 11:44:31.524941 139548159870720 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.5361455082893372, loss=5.319511413574219
I0418 11:45:14.653701 139548176656128 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.46154266595840454, loss=5.797433853149414
I0418 11:45:57.424417 139548159870720 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.5762616395950317, loss=4.815615653991699
I0418 11:46:41.094049 139548176656128 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.5930973887443542, loss=5.279300689697266
I0418 11:47:23.549947 139548159870720 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.49546757340431213, loss=6.069107532501221
I0418 11:48:06.950056 139548176656128 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.5771011710166931, loss=4.669074058532715
I0418 11:48:49.655018 139548159870720 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.6324107050895691, loss=4.459010124206543
I0418 11:49:21.190992 139725965485888 spec.py:298] Evaluating on the training split.
I0418 11:49:36.328211 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 11:49:47.155679 139725965485888 spec.py:326] Evaluating on the test split.
I0418 11:49:48.815994 139725965485888 submission_runner.py:406] Time since start: 7660.61s, 	Step: 16976, 	{'train/accuracy': 0.4714648425579071, 'train/loss': 2.6139378547668457, 'validation/accuracy': 0.4397199749946594, 'validation/loss': 2.7801358699798584, 'validation/num_examples': 50000, 'test/accuracy': 0.34450000524520874, 'test/loss': 3.357974052429199, 'test/num_examples': 10000, 'score': 7190.114460468292, 'total_duration': 7660.612909793854, 'accumulated_submission_time': 7190.114460468292, 'accumulated_eval_time': 444.9658489227295, 'accumulated_logging_time': 25.20846390724182}
I0418 11:49:48.827539 139548176656128 logging_writer.py:48] [16976] accumulated_eval_time=444.965849, accumulated_logging_time=25.208464, accumulated_submission_time=7190.114460, global_step=16976, preemption_count=0, score=7190.114460, test/accuracy=0.344500, test/loss=3.357974, test/num_examples=10000, total_duration=7660.612910, train/accuracy=0.471465, train/loss=2.613938, validation/accuracy=0.439720, validation/loss=2.780136, validation/num_examples=50000
I0418 11:49:48.972016 139725965485888 checkpoints.py:356] Saving checkpoint at step: 16976
I0418 11:49:49.861080 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_16976
I0418 11:49:49.877669 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_16976.
I0418 11:50:00.322462 139548159870720 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.6836857199668884, loss=4.43949031829834
I0418 11:50:42.203703 139548151478016 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.650188684463501, loss=4.445849895477295
I0418 11:51:24.723010 139548159870720 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.4691961705684662, loss=6.132739543914795
I0418 11:52:07.631288 139548151478016 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.5509651303291321, loss=5.595520973205566
I0418 11:52:50.389839 139548159870720 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.5744061470031738, loss=5.814293384552002
I0418 11:53:33.348192 139548151478016 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.5276995301246643, loss=5.276743412017822
I0418 11:54:16.490246 139548159870720 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.5556628108024597, loss=5.4407453536987305
I0418 11:54:59.352035 139548151478016 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.7385973930358887, loss=4.514013290405273
I0418 11:55:42.000889 139548159870720 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.6428303718566895, loss=4.6446614265441895
I0418 11:56:24.386536 139548151478016 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.6410902738571167, loss=4.537725448608398
I0418 11:56:49.948440 139725965485888 spec.py:298] Evaluating on the training split.
I0418 11:57:05.172315 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 11:57:16.108483 139725965485888 spec.py:326] Evaluating on the test split.
I0418 11:57:17.770814 139725965485888 submission_runner.py:406] Time since start: 8109.57s, 	Step: 17961, 	{'train/accuracy': 0.49839842319488525, 'train/loss': 2.4446253776550293, 'validation/accuracy': 0.4579799771308899, 'validation/loss': 2.6331374645233154, 'validation/num_examples': 50000, 'test/accuracy': 0.3499000072479248, 'test/loss': 3.238227605819702, 'test/num_examples': 10000, 'score': 7610.157889842987, 'total_duration': 8109.567834615707, 'accumulated_submission_time': 7610.157889842987, 'accumulated_eval_time': 472.788204908371, 'accumulated_logging_time': 26.27936840057373}
I0418 11:57:17.784735 139548159870720 logging_writer.py:48] [17961] accumulated_eval_time=472.788205, accumulated_logging_time=26.279368, accumulated_submission_time=7610.157890, global_step=17961, preemption_count=0, score=7610.157890, test/accuracy=0.349900, test/loss=3.238228, test/num_examples=10000, total_duration=8109.567835, train/accuracy=0.498398, train/loss=2.444625, validation/accuracy=0.457980, validation/loss=2.633137, validation/num_examples=50000
I0418 11:57:17.973647 139725965485888 checkpoints.py:356] Saving checkpoint at step: 17961
I0418 11:57:18.886723 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_17961
I0418 11:57:18.905826 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_17961.
I0418 11:57:35.567587 139548151478016 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.6524642109870911, loss=4.367119789123535
I0418 11:58:17.581420 139548143085312 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.5092886090278625, loss=5.409847259521484
I0418 11:59:00.163145 139548151478016 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.5469135046005249, loss=5.047787666320801
I0418 11:59:42.303585 139548143085312 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.5854929685592651, loss=4.808292865753174
I0418 12:00:24.913942 139548151478016 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.6199825406074524, loss=4.431422710418701
I0418 12:01:07.642980 139548143085312 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.7241345047950745, loss=4.45958948135376
I0418 12:01:50.664157 139548151478016 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.5935439467430115, loss=5.288974285125732
I0418 12:02:32.858572 139548143085312 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.650230348110199, loss=4.462310791015625
I0418 12:03:16.186787 139548151478016 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.5081084966659546, loss=5.9955735206604
I0418 12:03:58.856182 139548143085312 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.6448197960853577, loss=4.3689374923706055
I0418 12:04:19.162459 139725965485888 spec.py:298] Evaluating on the training split.
I0418 12:04:34.089569 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 12:04:45.446956 139725965485888 spec.py:326] Evaluating on the test split.
I0418 12:04:47.115012 139725965485888 submission_runner.py:406] Time since start: 8558.91s, 	Step: 18949, 	{'train/accuracy': 0.5101757645606995, 'train/loss': 2.383735179901123, 'validation/accuracy': 0.46469998359680176, 'validation/loss': 2.5818302631378174, 'validation/num_examples': 50000, 'test/accuracy': 0.3588000237941742, 'test/loss': 3.2062575817108154, 'test/num_examples': 10000, 'score': 8030.394687175751, 'total_duration': 8558.910800218582, 'accumulated_submission_time': 8030.394687175751, 'accumulated_eval_time': 500.7395296096802, 'accumulated_logging_time': 27.41585421562195}
I0418 12:04:47.126507 139548151478016 logging_writer.py:48] [18949] accumulated_eval_time=500.739530, accumulated_logging_time=27.415854, accumulated_submission_time=8030.394687, global_step=18949, preemption_count=0, score=8030.394687, test/accuracy=0.358800, test/loss=3.206258, test/num_examples=10000, total_duration=8558.910800, train/accuracy=0.510176, train/loss=2.383735, validation/accuracy=0.464700, validation/loss=2.581830, validation/num_examples=50000
I0418 12:04:47.314542 139725965485888 checkpoints.py:356] Saving checkpoint at step: 18949
I0418 12:04:48.213222 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_18949
I0418 12:04:48.227141 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_18949.
I0418 12:05:09.952780 139548143085312 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.5247625708580017, loss=5.151802062988281
I0418 12:05:52.449763 139548017260288 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.6727153062820435, loss=4.304723739624023
I0418 12:06:36.214145 139548143085312 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.6426611542701721, loss=4.464623928070068
I0418 12:07:19.537473 139548017260288 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.6487318873405457, loss=4.575718879699707
I0418 12:08:03.467361 139548143085312 logging_writer.py:48] [19400] global_step=19400, grad_norm=2.324915647506714, loss=5.101870536804199
I0418 12:08:46.526045 139548017260288 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.4451279938220978, loss=6.001387596130371
I0418 12:09:29.950694 139548143085312 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.6688891649246216, loss=4.395887851715088
I0418 12:10:13.389569 139548017260288 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.6907433867454529, loss=4.330049991607666
I0418 12:10:56.932832 139548143085312 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.655731201171875, loss=4.22022819519043
I0418 12:11:40.512556 139548017260288 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.6540568470954895, loss=4.3894805908203125
I0418 12:11:48.679906 139725965485888 spec.py:298] Evaluating on the training split.
I0418 12:12:02.698674 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 12:12:14.529390 139725965485888 spec.py:326] Evaluating on the test split.
I0418 12:12:16.205497 139725965485888 submission_runner.py:406] Time since start: 9008.00s, 	Step: 19920, 	{'train/accuracy': 0.5308789014816284, 'train/loss': 2.2876999378204346, 'validation/accuracy': 0.4732799828052521, 'validation/loss': 2.5403599739074707, 'validation/num_examples': 50000, 'test/accuracy': 0.3645000159740448, 'test/loss': 3.1625895500183105, 'test/num_examples': 10000, 'score': 8450.828124046326, 'total_duration': 9008.00137090683, 'accumulated_submission_time': 8450.828124046326, 'accumulated_eval_time': 528.2639634609222, 'accumulated_logging_time': 28.529584169387817}
I0418 12:12:16.216741 139548143085312 logging_writer.py:48] [19920] accumulated_eval_time=528.263963, accumulated_logging_time=28.529584, accumulated_submission_time=8450.828124, global_step=19920, preemption_count=0, score=8450.828124, test/accuracy=0.364500, test/loss=3.162590, test/num_examples=10000, total_duration=9008.001371, train/accuracy=0.530879, train/loss=2.287700, validation/accuracy=0.473280, validation/loss=2.540360, validation/num_examples=50000
I0418 12:12:16.428587 139725965485888 checkpoints.py:356] Saving checkpoint at step: 19920
I0418 12:12:17.396218 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_19920
I0418 12:12:17.414091 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_19920.
I0418 12:12:51.123812 139548017260288 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.6624516844749451, loss=4.284051895141602
I0418 12:13:34.654294 139548008867584 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.6370114088058472, loss=4.2149882316589355
I0418 12:14:17.632767 139548017260288 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.6525247097015381, loss=4.395626544952393
I0418 12:15:00.533271 139548008867584 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.5401037335395813, loss=4.872552871704102
I0418 12:15:43.555967 139548017260288 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.5199777483940125, loss=5.335636138916016
I0418 12:16:26.690474 139548008867584 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.6745104193687439, loss=4.344681739807129
I0418 12:17:09.785314 139548017260288 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.7318651080131531, loss=4.385931015014648
I0418 12:17:52.853047 139548008867584 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.5265596508979797, loss=5.304263591766357
I0418 12:18:36.035853 139548017260288 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.5485541820526123, loss=5.977280139923096
I0418 12:19:17.465218 139725965485888 spec.py:298] Evaluating on the training split.
I0418 12:19:31.909883 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 12:19:44.122030 139725965485888 spec.py:326] Evaluating on the test split.
I0418 12:19:45.795081 139725965485888 submission_runner.py:406] Time since start: 9457.59s, 	Step: 20898, 	{'train/accuracy': 0.5333398580551147, 'train/loss': 2.248889923095703, 'validation/accuracy': 0.49235999584198, 'validation/loss': 2.4485726356506348, 'validation/num_examples': 50000, 'test/accuracy': 0.37620002031326294, 'test/loss': 3.077709913253784, 'test/num_examples': 10000, 'score': 8870.860184907913, 'total_duration': 9457.591031551361, 'accumulated_submission_time': 8870.860184907913, 'accumulated_eval_time': 556.5927631855011, 'accumulated_logging_time': 29.73952841758728}
I0418 12:19:45.806155 139548008867584 logging_writer.py:48] [20898] accumulated_eval_time=556.592763, accumulated_logging_time=29.739528, accumulated_submission_time=8870.860185, global_step=20898, preemption_count=0, score=8870.860185, test/accuracy=0.376200, test/loss=3.077710, test/num_examples=10000, total_duration=9457.591032, train/accuracy=0.533340, train/loss=2.248890, validation/accuracy=0.492360, validation/loss=2.448573, validation/num_examples=50000
I0418 12:19:46.026883 139725965485888 checkpoints.py:356] Saving checkpoint at step: 20898
I0418 12:19:46.842354 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_20898
I0418 12:19:46.857881 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_20898.
I0418 12:19:48.152123 139548017260288 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.5299842357635498, loss=4.781133651733398
I0418 12:20:30.110219 139548017260288 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.6502171754837036, loss=4.575748443603516
I0418 12:21:12.877769 139548000474880 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.5678430795669556, loss=5.403201103210449
I0418 12:21:55.686068 139548017260288 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.6426827907562256, loss=4.268437385559082
I0418 12:22:38.777873 139548000474880 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.5363272428512573, loss=5.270138740539551
I0418 12:23:21.421241 139548017260288 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.6836481690406799, loss=4.230433940887451
I0418 12:24:04.816411 139548000474880 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.5909123420715332, loss=4.4322190284729
I0418 12:24:47.769868 139548017260288 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.6269490122795105, loss=4.377790451049805
I0418 12:25:30.352371 139548000474880 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.6654884219169617, loss=4.257620334625244
I0418 12:26:12.875993 139548017260288 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.5731367468833923, loss=4.807162284851074
I0418 12:26:46.956478 139725965485888 spec.py:298] Evaluating on the training split.
I0418 12:27:01.101684 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 12:27:13.261138 139725965485888 spec.py:326] Evaluating on the test split.
I0418 12:27:14.959839 139725965485888 submission_runner.py:406] Time since start: 9906.76s, 	Step: 21881, 	{'train/accuracy': 0.5456445217132568, 'train/loss': 2.1703507900238037, 'validation/accuracy': 0.5004000067710876, 'validation/loss': 2.381711959838867, 'validation/num_examples': 50000, 'test/accuracy': 0.38350000977516174, 'test/loss': 3.021646738052368, 'test/num_examples': 10000, 'score': 9290.939864397049, 'total_duration': 9906.755863666534, 'accumulated_submission_time': 9290.939864397049, 'accumulated_eval_time': 584.5951685905457, 'accumulated_logging_time': 30.803417205810547}
I0418 12:27:14.976724 139548000474880 logging_writer.py:48] [21881] accumulated_eval_time=584.595169, accumulated_logging_time=30.803417, accumulated_submission_time=9290.939864, global_step=21881, preemption_count=0, score=9290.939864, test/accuracy=0.383500, test/loss=3.021647, test/num_examples=10000, total_duration=9906.755864, train/accuracy=0.545645, train/loss=2.170351, validation/accuracy=0.500400, validation/loss=2.381712, validation/num_examples=50000
I0418 12:27:15.208038 139725965485888 checkpoints.py:356] Saving checkpoint at step: 21881
I0418 12:27:15.993189 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_21881
I0418 12:27:16.008103 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_21881.
I0418 12:27:24.350345 139548017260288 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.6679071187973022, loss=4.471770286560059
I0418 12:28:06.623227 139547346204416 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.5714719891548157, loss=5.078884124755859
I0418 12:28:49.986099 139548017260288 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.5832103490829468, loss=4.9121599197387695
I0418 12:29:33.495863 139547346204416 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.6491398811340332, loss=4.1746296882629395
I0418 12:30:17.268961 139548017260288 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.6572751402854919, loss=4.273378372192383
I0418 12:31:00.749183 139547346204416 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.6531440019607544, loss=4.244411945343018
I0418 12:31:44.526357 139548017260288 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.6170167922973633, loss=4.267020225524902
I0418 12:32:28.385177 139547346204416 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.5931006669998169, loss=5.546638488769531
I0418 12:33:12.195857 139548017260288 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.627627968788147, loss=4.286792755126953
I0418 12:33:55.873185 139547346204416 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.6717949509620667, loss=4.228167533874512
I0418 12:34:16.358835 139725965485888 spec.py:298] Evaluating on the training split.
I0418 12:34:31.289796 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 12:34:42.534675 139725965485888 spec.py:326] Evaluating on the test split.
I0418 12:34:44.239739 139725965485888 submission_runner.py:406] Time since start: 10356.03s, 	Step: 22848, 	{'train/accuracy': 0.5533984303474426, 'train/loss': 2.165682554244995, 'validation/accuracy': 0.5064200162887573, 'validation/loss': 2.3866326808929443, 'validation/num_examples': 50000, 'test/accuracy': 0.39180001616477966, 'test/loss': 3.0143938064575195, 'test/num_examples': 10000, 'score': 9711.272295475006, 'total_duration': 10356.031516075134, 'accumulated_submission_time': 9711.272295475006, 'accumulated_eval_time': 612.4708178043365, 'accumulated_logging_time': 31.852665424346924}
I0418 12:34:44.256016 139548017260288 logging_writer.py:48] [22848] accumulated_eval_time=612.470818, accumulated_logging_time=31.852665, accumulated_submission_time=9711.272295, global_step=22848, preemption_count=0, score=9711.272295, test/accuracy=0.391800, test/loss=3.014394, test/num_examples=10000, total_duration=10356.031516, train/accuracy=0.553398, train/loss=2.165683, validation/accuracy=0.506420, validation/loss=2.386633, validation/num_examples=50000
I0418 12:34:45.097162 139725965485888 checkpoints.py:356] Saving checkpoint at step: 22848
I0418 12:34:46.087888 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_22848
I0418 12:34:46.107381 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_22848.
I0418 12:35:08.139116 139547346204416 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.6277793049812317, loss=4.389987468719482
I0418 12:35:52.879820 139547337811712 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.4891659915447235, loss=6.047384262084961
I0418 12:36:38.043414 139547346204416 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.5720773339271545, loss=6.051290035247803
I0418 12:37:22.588145 139547337811712 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.6051052808761597, loss=4.430087089538574
I0418 12:38:07.682475 139547346204416 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.6636145114898682, loss=4.509529113769531
I0418 12:38:53.252908 139547337811712 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.6271386742591858, loss=4.217267990112305
I0418 12:39:38.697869 139547346204416 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.6166779398918152, loss=4.585638523101807
I0418 12:40:23.724968 139547337811712 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.5399975180625916, loss=5.144759178161621
I0418 12:41:08.983015 139547346204416 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.5211192965507507, loss=5.734233856201172
I0418 12:41:46.310705 139725965485888 spec.py:298] Evaluating on the training split.
I0418 12:41:57.770686 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 12:42:10.097234 139725965485888 spec.py:326] Evaluating on the test split.
I0418 12:42:11.769893 139725965485888 submission_runner.py:406] Time since start: 10803.57s, 	Step: 23784, 	{'train/accuracy': 0.5850585699081421, 'train/loss': 2.0339505672454834, 'validation/accuracy': 0.5124399662017822, 'validation/loss': 2.362550973892212, 'validation/num_examples': 50000, 'test/accuracy': 0.39570000767707825, 'test/loss': 2.9936623573303223, 'test/num_examples': 10000, 'score': 10131.457832574844, 'total_duration': 10803.565744161606, 'accumulated_submission_time': 10131.457832574844, 'accumulated_eval_time': 637.9288079738617, 'accumulated_logging_time': 33.72146987915039}
I0418 12:42:11.786707 139547337811712 logging_writer.py:48] [23784] accumulated_eval_time=637.928808, accumulated_logging_time=33.721470, accumulated_submission_time=10131.457833, global_step=23784, preemption_count=0, score=10131.457833, test/accuracy=0.395700, test/loss=2.993662, test/num_examples=10000, total_duration=10803.565744, train/accuracy=0.585059, train/loss=2.033951, validation/accuracy=0.512440, validation/loss=2.362551, validation/num_examples=50000
I0418 12:42:11.954146 139725965485888 checkpoints.py:356] Saving checkpoint at step: 23784
I0418 12:42:12.883557 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_23784
I0418 12:42:12.900046 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_23784.
I0418 12:42:20.042435 139547346204416 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.6850308775901794, loss=4.135862827301025
I0418 12:43:01.984887 139547329419008 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.6844109892845154, loss=4.203898906707764
I0418 12:43:45.154593 139547346204416 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.6784822940826416, loss=4.245735168457031
I0418 12:44:28.194504 139547329419008 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.6293556094169617, loss=4.18611478805542
I0418 12:45:11.285703 139547346204416 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.6345674395561218, loss=4.173238754272461
I0418 12:45:53.971800 139547329419008 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.5819453001022339, loss=5.500975131988525
I0418 12:46:36.914965 139547346204416 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.6185106039047241, loss=4.00691032409668
I0418 12:47:19.722565 139547329419008 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.5819239020347595, loss=4.92543888092041
I0418 12:48:02.695160 139547346204416 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.6572444438934326, loss=4.175513744354248
I0418 12:48:46.028923 139547329419008 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.623432457447052, loss=4.997365474700928
I0418 12:49:13.241443 139725965485888 spec.py:298] Evaluating on the training split.
I0418 12:49:24.174939 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 12:49:36.526796 139725965485888 spec.py:326] Evaluating on the test split.
I0418 12:49:38.190669 139725965485888 submission_runner.py:406] Time since start: 11249.99s, 	Step: 24765, 	{'train/accuracy': 0.563769519329071, 'train/loss': 2.06766939163208, 'validation/accuracy': 0.5243200063705444, 'validation/loss': 2.280478000640869, 'validation/num_examples': 50000, 'test/accuracy': 0.40540000796318054, 'test/loss': 2.9250264167785645, 'test/num_examples': 10000, 'score': 10551.780296564102, 'total_duration': 11249.986682415009, 'accumulated_submission_time': 10551.780296564102, 'accumulated_eval_time': 662.8770232200623, 'accumulated_logging_time': 34.8529634475708}
I0418 12:49:38.209506 139547346204416 logging_writer.py:48] [24765] accumulated_eval_time=662.877023, accumulated_logging_time=34.852963, accumulated_submission_time=10551.780297, global_step=24765, preemption_count=0, score=10551.780297, test/accuracy=0.405400, test/loss=2.925026, test/num_examples=10000, total_duration=11249.986682, train/accuracy=0.563770, train/loss=2.067669, validation/accuracy=0.524320, validation/loss=2.280478, validation/num_examples=50000
I0418 12:49:38.461768 139725965485888 checkpoints.py:356] Saving checkpoint at step: 24765
I0418 12:49:39.356494 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_24765
I0418 12:49:39.371858 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_24765.
I0418 12:49:54.399455 139547329419008 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.6878404021263123, loss=4.170598030090332
I0418 12:50:36.167803 139547245541120 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.5623124837875366, loss=5.061217308044434
I0418 12:51:18.668190 139547329419008 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.7629011869430542, loss=4.092816352844238
I0418 12:52:01.518149 139547245541120 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.6365677714347839, loss=4.213333606719971
I0418 12:52:44.748991 139547329419008 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.5934837460517883, loss=4.490800380706787
I0418 12:53:27.160154 139547245541120 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.6340153813362122, loss=4.375057220458984
I0418 12:54:10.142059 139547329419008 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.5608208775520325, loss=4.7856645584106445
I0418 12:54:53.129769 139547245541120 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.5938172936439514, loss=5.745448589324951
I0418 12:55:35.496826 139547329419008 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.5787953734397888, loss=4.855666637420654
I0418 12:56:18.529633 139547245541120 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.5957040786743164, loss=4.797164440155029
I0418 12:56:39.561877 139725965485888 spec.py:298] Evaluating on the training split.
I0418 12:56:50.351244 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 12:57:02.934006 139725965485888 spec.py:326] Evaluating on the test split.
I0418 12:57:04.627385 139725965485888 submission_runner.py:406] Time since start: 11696.42s, 	Step: 25750, 	{'train/accuracy': 0.5771093368530273, 'train/loss': 2.069854736328125, 'validation/accuracy': 0.531059980392456, 'validation/loss': 2.285112142562866, 'validation/num_examples': 50000, 'test/accuracy': 0.41120001673698425, 'test/loss': 2.9230196475982666, 'test/num_examples': 10000, 'score': 10971.936915636063, 'total_duration': 11696.423310041428, 'accumulated_submission_time': 10971.936915636063, 'accumulated_eval_time': 687.9413969516754, 'accumulated_logging_time': 36.04941987991333}
I0418 12:57:04.639151 139547329419008 logging_writer.py:48] [25750] accumulated_eval_time=687.941397, accumulated_logging_time=36.049420, accumulated_submission_time=10971.936916, global_step=25750, preemption_count=0, score=10971.936916, test/accuracy=0.411200, test/loss=2.923020, test/num_examples=10000, total_duration=11696.423310, train/accuracy=0.577109, train/loss=2.069855, validation/accuracy=0.531060, validation/loss=2.285112, validation/num_examples=50000
I0418 12:57:04.814673 139725965485888 checkpoints.py:356] Saving checkpoint at step: 25750
I0418 12:57:05.730257 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_25750
I0418 12:57:05.746283 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_25750.
I0418 12:57:27.004009 139547245541120 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.7338745594024658, loss=4.136197566986084
I0418 12:58:08.941104 139547237148416 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.5587644577026367, loss=5.8133158683776855
I0418 12:58:51.934322 139547245541120 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.5696004033088684, loss=4.947634220123291
I0418 12:59:34.697550 139547237148416 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.7264871001243591, loss=4.051975727081299
I0418 13:00:18.074952 139547245541120 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.5718011856079102, loss=5.250203609466553
I0418 13:01:01.977528 139547237148416 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.5751037001609802, loss=5.285872459411621
I0418 13:01:44.777829 139547245541120 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.6261485815048218, loss=4.5311665534973145
I0418 13:02:27.525071 139547237148416 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.6144585013389587, loss=5.049993991851807
I0418 13:03:10.809412 139547245541120 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.6742122769355774, loss=4.064760208129883
I0418 13:03:53.351786 139547237148416 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.6760735511779785, loss=4.229523181915283
I0418 13:04:05.866170 139725965485888 spec.py:298] Evaluating on the training split.
I0418 13:04:16.875180 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 13:04:29.340168 139725965485888 spec.py:326] Evaluating on the test split.
I0418 13:04:31.011021 139725965485888 submission_runner.py:406] Time since start: 12142.81s, 	Step: 26731, 	{'train/accuracy': 0.5933398008346558, 'train/loss': 1.9381568431854248, 'validation/accuracy': 0.5432199835777283, 'validation/loss': 2.1782312393188477, 'validation/num_examples': 50000, 'test/accuracy': 0.4269000291824341, 'test/loss': 2.8167614936828613, 'test/num_examples': 10000, 'score': 11392.037526845932, 'total_duration': 12142.806905269623, 'accumulated_submission_time': 11392.037526845932, 'accumulated_eval_time': 713.0851266384125, 'accumulated_logging_time': 37.16981363296509}
I0418 13:04:31.023206 139547245541120 logging_writer.py:48] [26731] accumulated_eval_time=713.085127, accumulated_logging_time=37.169814, accumulated_submission_time=11392.037527, global_step=26731, preemption_count=0, score=11392.037527, test/accuracy=0.426900, test/loss=2.816761, test/num_examples=10000, total_duration=12142.806905, train/accuracy=0.593340, train/loss=1.938157, validation/accuracy=0.543220, validation/loss=2.178231, validation/num_examples=50000
I0418 13:04:31.224257 139725965485888 checkpoints.py:356] Saving checkpoint at step: 26731
I0418 13:04:32.182800 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_26731
I0418 13:04:32.197591 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_26731.
I0418 13:05:01.264715 139547237148416 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.7242662310600281, loss=4.087283134460449
I0418 13:05:43.686506 139547228755712 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.59629225730896, loss=5.584733486175537
I0418 13:06:26.771275 139547237148416 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.5591930150985718, loss=4.667028903961182
I0418 13:07:09.690196 139547228755712 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.548331081867218, loss=5.845993518829346
I0418 13:07:52.796374 139547237148416 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.617514967918396, loss=4.349619388580322
I0418 13:08:36.337758 139547228755712 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.6658315062522888, loss=4.078400135040283
I0418 13:09:19.776144 139547237148416 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.6108222007751465, loss=4.092087745666504
I0418 13:10:02.370866 139547228755712 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.6709254384040833, loss=4.107229709625244
I0418 13:10:45.770316 139547237148416 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.6865994930267334, loss=4.0841803550720215
I0418 13:11:28.830493 139547228755712 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.6412876844406128, loss=4.142021179199219
I0418 13:11:32.289003 139725965485888 spec.py:298] Evaluating on the training split.
I0418 13:11:43.263667 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 13:11:56.032383 139725965485888 spec.py:326] Evaluating on the test split.
I0418 13:11:57.722554 139725965485888 submission_runner.py:406] Time since start: 12589.52s, 	Step: 27710, 	{'train/accuracy': 0.613476574420929, 'train/loss': 1.867006540298462, 'validation/accuracy': 0.5487200021743774, 'validation/loss': 2.1564571857452393, 'validation/num_examples': 50000, 'test/accuracy': 0.4336000084877014, 'test/loss': 2.800959587097168, 'test/num_examples': 10000, 'score': 11812.109931468964, 'total_duration': 12589.518400669098, 'accumulated_submission_time': 11812.109931468964, 'accumulated_eval_time': 738.517516374588, 'accumulated_logging_time': 38.357693672180176}
I0418 13:11:57.741328 139547237148416 logging_writer.py:48] [27710] accumulated_eval_time=738.517516, accumulated_logging_time=38.357694, accumulated_submission_time=11812.109931, global_step=27710, preemption_count=0, score=11812.109931, test/accuracy=0.433600, test/loss=2.800960, test/num_examples=10000, total_duration=12589.518401, train/accuracy=0.613477, train/loss=1.867007, validation/accuracy=0.548720, validation/loss=2.156457, validation/num_examples=50000
I0418 13:11:57.964574 139725965485888 checkpoints.py:356] Saving checkpoint at step: 27710
I0418 13:11:58.758105 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_27710
I0418 13:11:58.773293 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_27710.
I0418 13:12:36.750139 139547228755712 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.5438448786735535, loss=4.928844451904297
I0418 13:13:19.419540 139547220363008 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.5254542827606201, loss=5.428641319274902
I0418 13:14:01.658322 139725965485888 spec.py:298] Evaluating on the training split.
I0418 13:14:12.888822 139725965485888 spec.py:310] Evaluating on the validation split.
I0418 13:14:25.391027 139725965485888 spec.py:326] Evaluating on the test split.
I0418 13:14:27.046642 139725965485888 submission_runner.py:406] Time since start: 12738.84s, 	Step: 28000, 	{'train/accuracy': 0.6099023222923279, 'train/loss': 1.8996089696884155, 'validation/accuracy': 0.5519199967384338, 'validation/loss': 2.1612887382507324, 'validation/num_examples': 50000, 'test/accuracy': 0.4301000237464905, 'test/loss': 2.798818826675415, 'test/num_examples': 10000, 'score': 11934.98826432228, 'total_duration': 12738.843650341034, 'accumulated_submission_time': 11934.98826432228, 'accumulated_eval_time': 763.905818939209, 'accumulated_logging_time': 39.409586668014526}
I0418 13:14:27.059709 139547228755712 logging_writer.py:48] [28000] accumulated_eval_time=763.905819, accumulated_logging_time=39.409587, accumulated_submission_time=11934.988264, global_step=28000, preemption_count=0, score=11934.988264, test/accuracy=0.430100, test/loss=2.798819, test/num_examples=10000, total_duration=12738.843650, train/accuracy=0.609902, train/loss=1.899609, validation/accuracy=0.551920, validation/loss=2.161289, validation/num_examples=50000
I0418 13:14:27.239900 139725965485888 checkpoints.py:356] Saving checkpoint at step: 28000
I0418 13:14:28.142601 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_28000
I0418 13:14:28.156574 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_28000.
I0418 13:14:28.184496 139547220363008 logging_writer.py:48] [28000] global_step=28000, preemption_count=0, score=11934.988264
I0418 13:14:28.400254 139725965485888 checkpoints.py:356] Saving checkpoint at step: 28000
I0418 13:14:29.475506 139725965485888 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_28000
I0418 13:14:29.487762 139725965485888 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_28000.
I0418 13:14:30.366144 139725965485888 submission_runner.py:567] Tuning trial 1/1
I0418 13:14:30.367219 139725965485888 submission_runner.py:568] Hyperparameters: Hyperparameters(learning_rate=0.4394877561366806, one_minus_beta1=0.07113602458522507, warmup_factor=0.05, weight_decay=9.611851572925426e-07, label_smoothing=0.2, dropout_rate=0.0, decay_steps_factor=0.9, end_factor=0.001)
I0418 13:14:30.376129 139725965485888 submission_runner.py:569] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0008984374580904841, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 47.355101346969604, 'total_duration': 96.43742775917053, 'accumulated_submission_time': 47.355101346969604, 'accumulated_eval_time': 49.082154750823975, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (980, {'train/accuracy': 0.0380859375, 'train/loss': 6.04341459274292, 'validation/accuracy': 0.0364999994635582, 'validation/loss': 6.067896842956543, 'validation/num_examples': 50000, 'test/accuracy': 0.027700001373887062, 'test/loss': 6.168490886688232, 'test/num_examples': 10000, 'score': 467.5246934890747, 'total_duration': 536.5262660980225, 'accumulated_submission_time': 467.5246934890747, 'accumulated_eval_time': 68.3180878162384, 'accumulated_logging_time': 0.6644711494445801, 'global_step': 980, 'preemption_count': 0}), (1984, {'train/accuracy': 0.06900390237569809, 'train/loss': 5.5743231773376465, 'validation/accuracy': 0.06521999835968018, 'validation/loss': 5.6049981117248535, 'validation/num_examples': 50000, 'test/accuracy': 0.05010000243782997, 'test/loss': 5.770705699920654, 'test/num_examples': 10000, 'score': 887.8947412967682, 'total_duration': 977.6956031322479, 'accumulated_submission_time': 887.8947412967682, 'accumulated_eval_time': 87.09795045852661, 'accumulated_logging_time': 2.6638894081115723, 'global_step': 1984, 'preemption_count': 0}), (2995, {'train/accuracy': 0.1005273386836052, 'train/loss': 5.207403659820557, 'validation/accuracy': 0.09352000057697296, 'validation/loss': 5.251680374145508, 'validation/num_examples': 50000, 'test/accuracy': 0.06890000402927399, 'test/loss': 5.488145351409912, 'test/num_examples': 10000, 'score': 1307.9904942512512, 'total_duration': 1419.049589395523, 'accumulated_submission_time': 1307.9904942512512, 'accumulated_eval_time': 106.13783574104309, 'accumulated_logging_time': 4.862898588180542, 'global_step': 2995, 'preemption_count': 0}), (4005, {'train/accuracy': 0.1371484398841858, 'train/loss': 4.827167987823486, 'validation/accuracy': 0.11653999984264374, 'validation/loss': 4.96237325668335, 'validation/num_examples': 50000, 'test/accuracy': 0.08800000697374344, 'test/loss': 5.238028526306152, 'test/num_examples': 10000, 'score': 1728.1618773937225, 'total_duration': 1861.0405068397522, 'accumulated_submission_time': 1728.1618773937225, 'accumulated_eval_time': 125.27846503257751, 'accumulated_logging_time': 7.522132158279419, 'global_step': 4005, 'preemption_count': 0}), (5012, {'train/accuracy': 0.1635156273841858, 'train/loss': 4.583794116973877, 'validation/accuracy': 0.15067999064922333, 'validation/loss': 4.659067153930664, 'validation/num_examples': 50000, 'test/accuracy': 0.11360000818967819, 'test/loss': 4.985012054443359, 'test/num_examples': 10000, 'score': 2148.271285533905, 'total_duration': 2303.1031243801117, 'accumulated_submission_time': 2148.271285533905, 'accumulated_eval_time': 144.82586526870728, 'accumulated_logging_time': 9.908594131469727, 'global_step': 5012, 'preemption_count': 0}), (6019, {'train/accuracy': 0.18886718153953552, 'train/loss': 4.421493053436279, 'validation/accuracy': 0.17295999825000763, 'validation/loss': 4.508814811706543, 'validation/num_examples': 50000, 'test/accuracy': 0.13260000944137573, 'test/loss': 4.830865859985352, 'test/num_examples': 10000, 'score': 2568.3523111343384, 'total_duration': 2744.073734521866, 'accumulated_submission_time': 2568.3523111343384, 'accumulated_eval_time': 163.9882435798645, 'accumulated_logging_time': 11.616264343261719, 'global_step': 6019, 'preemption_count': 0}), (7026, {'train/accuracy': 0.2374609261751175, 'train/loss': 4.050613880157471, 'validation/accuracy': 0.21639999747276306, 'validation/loss': 4.165241241455078, 'validation/num_examples': 50000, 'test/accuracy': 0.16170001029968262, 'test/loss': 4.558784008026123, 'test/num_examples': 10000, 'score': 2988.4303283691406, 'total_duration': 3187.324772119522, 'accumulated_submission_time': 2988.4303283691406, 'accumulated_eval_time': 184.79728412628174, 'accumulated_logging_time': 13.96054220199585, 'global_step': 7026, 'preemption_count': 0}), (8029, {'train/accuracy': 0.2777343690395355, 'train/loss': 3.7647171020507812, 'validation/accuracy': 0.24393999576568604, 'validation/loss': 3.9391419887542725, 'validation/num_examples': 50000, 'test/accuracy': 0.18090000748634338, 'test/loss': 4.377520561218262, 'test/num_examples': 10000, 'score': 3408.422794342041, 'total_duration': 3630.878957271576, 'accumulated_submission_time': 3408.422794342041, 'accumulated_eval_time': 206.91264510154724, 'accumulated_logging_time': 15.387310266494751, 'global_step': 8029, 'preemption_count': 0}), (9028, {'train/accuracy': 0.29966795444488525, 'train/loss': 3.5713510513305664, 'validation/accuracy': 0.2738199830055237, 'validation/loss': 3.6930508613586426, 'validation/num_examples': 50000, 'test/accuracy': 0.20980000495910645, 'test/loss': 4.16384744644165, 'test/num_examples': 10000, 'score': 3828.536628007889, 'total_duration': 4076.172243833542, 'accumulated_submission_time': 3828.536628007889, 'accumulated_eval_time': 230.98818492889404, 'accumulated_logging_time': 16.472405195236206, 'global_step': 9028, 'preemption_count': 0}), (10029, {'train/accuracy': 0.33134764432907104, 'train/loss': 3.4058403968811035, 'validation/accuracy': 0.3026999831199646, 'validation/loss': 3.5449271202087402, 'validation/num_examples': 50000, 'test/accuracy': 0.22910000383853912, 'test/loss': 4.047345161437988, 'test/num_examples': 10000, 'score': 4248.8159263134, 'total_duration': 4522.56636095047, 'accumulated_submission_time': 4248.8159263134, 'accumulated_eval_time': 256.0640115737915, 'accumulated_logging_time': 17.49241876602173, 'global_step': 10029, 'preemption_count': 0}), (11030, {'train/accuracy': 0.3590429723262787, 'train/loss': 3.217349052429199, 'validation/accuracy': 0.32646000385284424, 'validation/loss': 3.3776917457580566, 'validation/num_examples': 50000, 'test/accuracy': 0.25050002336502075, 'test/loss': 3.8918797969818115, 'test/num_examples': 10000, 'score': 4668.96368265152, 'total_duration': 4969.789789199829, 'accumulated_submission_time': 4668.96368265152, 'accumulated_eval_time': 282.18397092819214, 'accumulated_logging_time': 18.429189205169678, 'global_step': 11030, 'preemption_count': 0}), (12029, {'train/accuracy': 0.39720702171325684, 'train/loss': 3.0174014568328857, 'validation/accuracy': 0.3565399944782257, 'validation/loss': 3.2220492362976074, 'validation/num_examples': 50000, 'test/accuracy': 0.27000001072883606, 'test/loss': 3.755986213684082, 'test/num_examples': 10000, 'score': 5089.289659976959, 'total_duration': 5417.99328327179, 'accumulated_submission_time': 5089.289659976959, 'accumulated_eval_time': 309.0382170677185, 'accumulated_logging_time': 19.43401336669922, 'global_step': 12029, 'preemption_count': 0}), (13025, {'train/accuracy': 0.40562498569488525, 'train/loss': 2.927992582321167, 'validation/accuracy': 0.3734000027179718, 'validation/loss': 3.0815927982330322, 'validation/num_examples': 50000, 'test/accuracy': 0.2898000180721283, 'test/loss': 3.6270172595977783, 'test/num_examples': 10000, 'score': 5509.27228140831, 'total_duration': 5866.518084049225, 'accumulated_submission_time': 5509.27228140831, 'accumulated_eval_time': 336.33707785606384, 'accumulated_logging_time': 20.658891916275024, 'global_step': 13025, 'preemption_count': 0}), (14017, {'train/accuracy': 0.4374414086341858, 'train/loss': 2.783097267150879, 'validation/accuracy': 0.3989599943161011, 'validation/loss': 2.954355239868164, 'validation/num_examples': 50000, 'test/accuracy': 0.30790001153945923, 'test/loss': 3.510413408279419, 'test/num_examples': 10000, 'score': 5929.647999048233, 'total_duration': 6315.105541944504, 'accumulated_submission_time': 5929.647999048233, 'accumulated_eval_time': 363.25127124786377, 'accumulated_logging_time': 21.93695878982544, 'global_step': 14017, 'preemption_count': 0}), (15006, {'train/accuracy': 0.4559374749660492, 'train/loss': 2.634718656539917, 'validation/accuracy': 0.41915997862815857, 'validation/loss': 2.817216396331787, 'validation/num_examples': 50000, 'test/accuracy': 0.32200002670288086, 'test/loss': 3.4150826930999756, 'test/num_examples': 10000, 'score': 6349.643064260483, 'total_duration': 6763.140064001083, 'accumulated_submission_time': 6349.643064260483, 'accumulated_eval_time': 390.23643732070923, 'accumulated_logging_time': 22.973034858703613, 'global_step': 15006, 'preemption_count': 0}), (15993, {'train/accuracy': 0.46921873092651367, 'train/loss': 2.622598171234131, 'validation/accuracy': 0.41933998465538025, 'validation/loss': 2.8649752140045166, 'validation/num_examples': 50000, 'test/accuracy': 0.3232000172138214, 'test/loss': 3.4455127716064453, 'test/num_examples': 10000, 'score': 6769.924319028854, 'total_duration': 7211.634873390198, 'accumulated_submission_time': 6769.924319028854, 'accumulated_eval_time': 417.34088373184204, 'accumulated_logging_time': 24.06400465965271, 'global_step': 15993, 'preemption_count': 0}), (16976, {'train/accuracy': 0.4714648425579071, 'train/loss': 2.6139378547668457, 'validation/accuracy': 0.4397199749946594, 'validation/loss': 2.7801358699798584, 'validation/num_examples': 50000, 'test/accuracy': 0.34450000524520874, 'test/loss': 3.357974052429199, 'test/num_examples': 10000, 'score': 7190.114460468292, 'total_duration': 7660.612909793854, 'accumulated_submission_time': 7190.114460468292, 'accumulated_eval_time': 444.9658489227295, 'accumulated_logging_time': 25.20846390724182, 'global_step': 16976, 'preemption_count': 0}), (17961, {'train/accuracy': 0.49839842319488525, 'train/loss': 2.4446253776550293, 'validation/accuracy': 0.4579799771308899, 'validation/loss': 2.6331374645233154, 'validation/num_examples': 50000, 'test/accuracy': 0.3499000072479248, 'test/loss': 3.238227605819702, 'test/num_examples': 10000, 'score': 7610.157889842987, 'total_duration': 8109.567834615707, 'accumulated_submission_time': 7610.157889842987, 'accumulated_eval_time': 472.788204908371, 'accumulated_logging_time': 26.27936840057373, 'global_step': 17961, 'preemption_count': 0}), (18949, {'train/accuracy': 0.5101757645606995, 'train/loss': 2.383735179901123, 'validation/accuracy': 0.46469998359680176, 'validation/loss': 2.5818302631378174, 'validation/num_examples': 50000, 'test/accuracy': 0.3588000237941742, 'test/loss': 3.2062575817108154, 'test/num_examples': 10000, 'score': 8030.394687175751, 'total_duration': 8558.910800218582, 'accumulated_submission_time': 8030.394687175751, 'accumulated_eval_time': 500.7395296096802, 'accumulated_logging_time': 27.41585421562195, 'global_step': 18949, 'preemption_count': 0}), (19920, {'train/accuracy': 0.5308789014816284, 'train/loss': 2.2876999378204346, 'validation/accuracy': 0.4732799828052521, 'validation/loss': 2.5403599739074707, 'validation/num_examples': 50000, 'test/accuracy': 0.3645000159740448, 'test/loss': 3.1625895500183105, 'test/num_examples': 10000, 'score': 8450.828124046326, 'total_duration': 9008.00137090683, 'accumulated_submission_time': 8450.828124046326, 'accumulated_eval_time': 528.2639634609222, 'accumulated_logging_time': 28.529584169387817, 'global_step': 19920, 'preemption_count': 0}), (20898, {'train/accuracy': 0.5333398580551147, 'train/loss': 2.248889923095703, 'validation/accuracy': 0.49235999584198, 'validation/loss': 2.4485726356506348, 'validation/num_examples': 50000, 'test/accuracy': 0.37620002031326294, 'test/loss': 3.077709913253784, 'test/num_examples': 10000, 'score': 8870.860184907913, 'total_duration': 9457.591031551361, 'accumulated_submission_time': 8870.860184907913, 'accumulated_eval_time': 556.5927631855011, 'accumulated_logging_time': 29.73952841758728, 'global_step': 20898, 'preemption_count': 0}), (21881, {'train/accuracy': 0.5456445217132568, 'train/loss': 2.1703507900238037, 'validation/accuracy': 0.5004000067710876, 'validation/loss': 2.381711959838867, 'validation/num_examples': 50000, 'test/accuracy': 0.38350000977516174, 'test/loss': 3.021646738052368, 'test/num_examples': 10000, 'score': 9290.939864397049, 'total_duration': 9906.755863666534, 'accumulated_submission_time': 9290.939864397049, 'accumulated_eval_time': 584.5951685905457, 'accumulated_logging_time': 30.803417205810547, 'global_step': 21881, 'preemption_count': 0}), (22848, {'train/accuracy': 0.5533984303474426, 'train/loss': 2.165682554244995, 'validation/accuracy': 0.5064200162887573, 'validation/loss': 2.3866326808929443, 'validation/num_examples': 50000, 'test/accuracy': 0.39180001616477966, 'test/loss': 3.0143938064575195, 'test/num_examples': 10000, 'score': 9711.272295475006, 'total_duration': 10356.031516075134, 'accumulated_submission_time': 9711.272295475006, 'accumulated_eval_time': 612.4708178043365, 'accumulated_logging_time': 31.852665424346924, 'global_step': 22848, 'preemption_count': 0}), (23784, {'train/accuracy': 0.5850585699081421, 'train/loss': 2.0339505672454834, 'validation/accuracy': 0.5124399662017822, 'validation/loss': 2.362550973892212, 'validation/num_examples': 50000, 'test/accuracy': 0.39570000767707825, 'test/loss': 2.9936623573303223, 'test/num_examples': 10000, 'score': 10131.457832574844, 'total_duration': 10803.565744161606, 'accumulated_submission_time': 10131.457832574844, 'accumulated_eval_time': 637.9288079738617, 'accumulated_logging_time': 33.72146987915039, 'global_step': 23784, 'preemption_count': 0}), (24765, {'train/accuracy': 0.563769519329071, 'train/loss': 2.06766939163208, 'validation/accuracy': 0.5243200063705444, 'validation/loss': 2.280478000640869, 'validation/num_examples': 50000, 'test/accuracy': 0.40540000796318054, 'test/loss': 2.9250264167785645, 'test/num_examples': 10000, 'score': 10551.780296564102, 'total_duration': 11249.986682415009, 'accumulated_submission_time': 10551.780296564102, 'accumulated_eval_time': 662.8770232200623, 'accumulated_logging_time': 34.8529634475708, 'global_step': 24765, 'preemption_count': 0}), (25750, {'train/accuracy': 0.5771093368530273, 'train/loss': 2.069854736328125, 'validation/accuracy': 0.531059980392456, 'validation/loss': 2.285112142562866, 'validation/num_examples': 50000, 'test/accuracy': 0.41120001673698425, 'test/loss': 2.9230196475982666, 'test/num_examples': 10000, 'score': 10971.936915636063, 'total_duration': 11696.423310041428, 'accumulated_submission_time': 10971.936915636063, 'accumulated_eval_time': 687.9413969516754, 'accumulated_logging_time': 36.04941987991333, 'global_step': 25750, 'preemption_count': 0}), (26731, {'train/accuracy': 0.5933398008346558, 'train/loss': 1.9381568431854248, 'validation/accuracy': 0.5432199835777283, 'validation/loss': 2.1782312393188477, 'validation/num_examples': 50000, 'test/accuracy': 0.4269000291824341, 'test/loss': 2.8167614936828613, 'test/num_examples': 10000, 'score': 11392.037526845932, 'total_duration': 12142.806905269623, 'accumulated_submission_time': 11392.037526845932, 'accumulated_eval_time': 713.0851266384125, 'accumulated_logging_time': 37.16981363296509, 'global_step': 26731, 'preemption_count': 0}), (27710, {'train/accuracy': 0.613476574420929, 'train/loss': 1.867006540298462, 'validation/accuracy': 0.5487200021743774, 'validation/loss': 2.1564571857452393, 'validation/num_examples': 50000, 'test/accuracy': 0.4336000084877014, 'test/loss': 2.800959587097168, 'test/num_examples': 10000, 'score': 11812.109931468964, 'total_duration': 12589.518400669098, 'accumulated_submission_time': 11812.109931468964, 'accumulated_eval_time': 738.517516374588, 'accumulated_logging_time': 38.357693672180176, 'global_step': 27710, 'preemption_count': 0}), (28000, {'train/accuracy': 0.6099023222923279, 'train/loss': 1.8996089696884155, 'validation/accuracy': 0.5519199967384338, 'validation/loss': 2.1612887382507324, 'validation/num_examples': 50000, 'test/accuracy': 0.4301000237464905, 'test/loss': 2.798818826675415, 'test/num_examples': 10000, 'score': 11934.98826432228, 'total_duration': 12738.843650341034, 'accumulated_submission_time': 11934.98826432228, 'accumulated_eval_time': 763.905818939209, 'accumulated_logging_time': 39.409586668014526, 'global_step': 28000, 'preemption_count': 0})], 'global_step': 28000}
I0418 13:14:30.376286 139725965485888 submission_runner.py:570] Timing: 11934.98826432228
I0418 13:14:30.376332 139725965485888 submission_runner.py:571] ====================
I0418 13:14:30.376499 139725965485888 submission_runner.py:631] Final imagenet_vit score: 11934.98826432228
