python3 submission_runner.py --framework=jax --workload=fastmri --submission_path=baselines/sam/jax/submission.py --tuning_search_space=baselines/sam/tuning_search_space.json --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_fancy_2/timing_sam --overwrite=True --save_checkpoints=False --max_global_steps=5428 2>&1 | tee -a /logs/fastmri_jax_05-02-2023-06-36-57.log
I0502 06:37:16.594378 139631035082560 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_fancy_2/timing_sam/fastmri_jax.
I0502 06:37:16.754015 139631035082560 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0502 06:37:17.627516 139631035082560 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0502 06:37:17.628469 139631035082560 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0502 06:37:17.632812 139631035082560 submission_runner.py:538] Using RNG seed 1721055577
I0502 06:37:20.479819 139631035082560 submission_runner.py:547] --- Tuning run 1/1 ---
I0502 06:37:20.480069 139631035082560 submission_runner.py:552] Creating tuning directory at /experiment_runs/timing_fancy_2/timing_sam/fastmri_jax/trial_1.
I0502 06:37:20.480308 139631035082560 logger_utils.py:92] Saving hparams to /experiment_runs/timing_fancy_2/timing_sam/fastmri_jax/trial_1/hparams.json.
I0502 06:37:20.605052 139631035082560 submission_runner.py:241] Initializing dataset.
I0502 06:37:24.668416 139631035082560 submission_runner.py:248] Initializing model.
I0502 06:37:31.958115 139631035082560 submission_runner.py:258] Initializing optimizer.
I0502 06:37:32.420765 139631035082560 submission_runner.py:265] Initializing metrics bundle.
I0502 06:37:32.421128 139631035082560 submission_runner.py:282] Initializing checkpoint and logger.
I0502 06:37:32.423827 139631035082560 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_fancy_2/timing_sam/fastmri_jax/trial_1 with prefix checkpoint_
I0502 06:37:32.424052 139631035082560 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0502 06:37:32.424113 139631035082560 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0502 06:37:33.382002 139631035082560 submission_runner.py:303] Saving meta data to /experiment_runs/timing_fancy_2/timing_sam/fastmri_jax/trial_1/meta_data_0.json.
I0502 06:37:33.382986 139631035082560 submission_runner.py:306] Saving flags to /experiment_runs/timing_fancy_2/timing_sam/fastmri_jax/trial_1/flags_0.json.
I0502 06:37:33.388434 139631035082560 submission_runner.py:318] Starting training loop.
I0502 06:38:44.015805 139454853404416 logging_writer.py:48] [0] global_step=0, grad_norm=7.111948013305664, loss=1.0595213174819946
I0502 06:38:44.025918 139631035082560 spec.py:298] Evaluating on the training split.
I0502 06:40:13.827818 139631035082560 spec.py:310] Evaluating on the validation split.
I0502 06:41:18.019741 139631035082560 spec.py:326] Evaluating on the test split.
I0502 06:42:19.491567 139631035082560 submission_runner.py:415] Time since start: 286.10s, 	Step: 1, 	{'train/ssim': 0.19806415694100515, 'train/loss': 1.0715648106166296, 'validation/ssim': 0.19566289400477455, 'validation/loss': 1.071294489373769, 'validation/num_examples': 3554, 'test/ssim': 0.21896218281489982, 'test/loss': 1.0674319678729753, 'test/num_examples': 3581, 'score': 70.63732814788818, 'total_duration': 286.103018283844, 'accumulated_submission_time': 70.63732814788818, 'accumulated_eval_time': 215.4655499458313, 'accumulated_logging_time': 0}
I0502 06:42:19.511560 139424977368832 logging_writer.py:48] [1] accumulated_eval_time=215.465550, accumulated_logging_time=0, accumulated_submission_time=70.637328, global_step=1, preemption_count=0, score=70.637328, test/loss=1.067432, test/num_examples=3581, test/ssim=0.218962, total_duration=286.103018, train/loss=1.071565, train/ssim=0.198064, validation/loss=1.071294, validation/num_examples=3554, validation/ssim=0.195663
I0502 06:42:41.765361 139424968976128 logging_writer.py:48] [100] global_step=100, grad_norm=0.40803372859954834, loss=0.32025936245918274
I0502 06:43:05.965599 139424977368832 logging_writer.py:48] [200] global_step=200, grad_norm=0.28515058755874634, loss=0.3529987037181854
I0502 06:43:30.202337 139424968976128 logging_writer.py:48] [300] global_step=300, grad_norm=0.3390209972858429, loss=0.22869594395160675
I0502 06:43:39.575459 139631035082560 spec.py:298] Evaluating on the training split.
I0502 06:43:41.428739 139631035082560 spec.py:310] Evaluating on the validation split.
I0502 06:43:42.782126 139631035082560 spec.py:326] Evaluating on the test split.
I0502 06:43:44.134415 139631035082560 submission_runner.py:415] Time since start: 370.75s, 	Step: 328, 	{'train/ssim': 0.6978415761675153, 'train/loss': 0.3031109401157924, 'validation/ssim': 0.674048703375598, 'validation/loss': 0.3279291516820836, 'validation/num_examples': 3554, 'test/ssim': 0.6927200142680118, 'test/loss': 0.32953707501396257, 'test/num_examples': 3581, 'score': 150.6885232925415, 'total_duration': 370.7459144592285, 'accumulated_submission_time': 150.6885232925415, 'accumulated_eval_time': 220.02448654174805, 'accumulated_logging_time': 0.028630495071411133}
I0502 06:43:44.143675 139424977368832 logging_writer.py:48] [328] accumulated_eval_time=220.024487, accumulated_logging_time=0.028630, accumulated_submission_time=150.688523, global_step=328, preemption_count=0, score=150.688523, test/loss=0.329537, test/num_examples=3581, test/ssim=0.692720, total_duration=370.745914, train/loss=0.303111, train/ssim=0.697842, validation/loss=0.327929, validation/num_examples=3554, validation/ssim=0.674049
I0502 06:44:06.549676 139424968976128 logging_writer.py:48] [400] global_step=400, grad_norm=0.2996830344200134, loss=0.27263566851615906
I0502 06:44:43.318879 139424977368832 logging_writer.py:48] [500] global_step=500, grad_norm=0.17379622161388397, loss=0.32232192158699036
I0502 06:45:04.479910 139631035082560 spec.py:298] Evaluating on the training split.
I0502 06:45:05.953693 139631035082560 spec.py:310] Evaluating on the validation split.
I0502 06:45:07.301880 139631035082560 spec.py:326] Evaluating on the test split.
I0502 06:45:08.653781 139631035082560 submission_runner.py:415] Time since start: 455.27s, 	Step: 561, 	{'train/ssim': 0.715043272290911, 'train/loss': 0.28882016454424175, 'validation/ssim': 0.6921770034644062, 'validation/loss': 0.3125341412185214, 'validation/num_examples': 3554, 'test/ssim': 0.710016774185807, 'test/loss': 0.31422756251527156, 'test/num_examples': 3581, 'score': 231.0089099407196, 'total_duration': 455.26527881622314, 'accumulated_submission_time': 231.0089099407196, 'accumulated_eval_time': 224.19832396507263, 'accumulated_logging_time': 0.0510561466217041}
I0502 06:45:08.664345 139424968976128 logging_writer.py:48] [561] accumulated_eval_time=224.198324, accumulated_logging_time=0.051056, accumulated_submission_time=231.008910, global_step=561, preemption_count=0, score=231.008910, test/loss=0.314228, test/num_examples=3581, test/ssim=0.710017, total_duration=455.265279, train/loss=0.288820, train/ssim=0.715043, validation/loss=0.312534, validation/num_examples=3554, validation/ssim=0.692177
I0502 06:45:19.534007 139424977368832 logging_writer.py:48] [600] global_step=600, grad_norm=0.2154979407787323, loss=0.3546055555343628
I0502 06:45:55.548216 139424968976128 logging_writer.py:48] [700] global_step=700, grad_norm=0.21437795460224152, loss=0.3071996867656708
I0502 06:46:28.884768 139631035082560 spec.py:298] Evaluating on the training split.
I0502 06:46:30.353999 139631035082560 spec.py:310] Evaluating on the validation split.
I0502 06:46:31.703047 139631035082560 spec.py:326] Evaluating on the test split.
I0502 06:46:33.056493 139631035082560 submission_runner.py:415] Time since start: 539.67s, 	Step: 794, 	{'train/ssim': 0.7194465909685407, 'train/loss': 0.2880207470485142, 'validation/ssim': 0.696329111454523, 'validation/loss': 0.3121126998188661, 'validation/num_examples': 3554, 'test/ssim': 0.7137521052953085, 'test/loss': 0.31411377566714954, 'test/num_examples': 3581, 'score': 311.21634435653687, 'total_duration': 539.667973279953, 'accumulated_submission_time': 311.21634435653687, 'accumulated_eval_time': 228.37002444267273, 'accumulated_logging_time': 0.07191681861877441}
I0502 06:46:33.068979 139424977368832 logging_writer.py:48] [794] accumulated_eval_time=228.370024, accumulated_logging_time=0.071917, accumulated_submission_time=311.216344, global_step=794, preemption_count=0, score=311.216344, test/loss=0.314114, test/num_examples=3581, test/ssim=0.713752, total_duration=539.667973, train/loss=0.288021, train/ssim=0.719447, validation/loss=0.312113, validation/num_examples=3554, validation/ssim=0.696329
I0502 06:46:34.084750 139424968976128 logging_writer.py:48] [800] global_step=800, grad_norm=0.1763698011636734, loss=0.20762908458709717
I0502 06:47:10.745543 139424977368832 logging_writer.py:48] [900] global_step=900, grad_norm=0.18878313899040222, loss=0.3684086203575134
I0502 06:47:42.993146 139424968976128 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.1893046349287033, loss=0.32920652627944946
I0502 06:47:53.081931 139631035082560 spec.py:298] Evaluating on the training split.
I0502 06:47:54.552121 139631035082560 spec.py:310] Evaluating on the validation split.
I0502 06:47:55.906104 139631035082560 spec.py:326] Evaluating on the test split.
I0502 06:47:57.255729 139631035082560 submission_runner.py:415] Time since start: 623.87s, 	Step: 1043, 	{'train/ssim': 0.726442813873291, 'train/loss': 0.2818132979529245, 'validation/ssim': 0.7037976575689364, 'validation/loss': 0.3052636416493739, 'validation/num_examples': 3554, 'test/ssim': 0.7209581738908475, 'test/loss': 0.3074215545696907, 'test/num_examples': 3581, 'score': 391.2160847187042, 'total_duration': 623.8672182559967, 'accumulated_submission_time': 391.2160847187042, 'accumulated_eval_time': 232.543781042099, 'accumulated_logging_time': 0.09460091590881348}
I0502 06:47:57.264250 139424977368832 logging_writer.py:48] [1043] accumulated_eval_time=232.543781, accumulated_logging_time=0.094601, accumulated_submission_time=391.216085, global_step=1043, preemption_count=0, score=391.216085, test/loss=0.307422, test/num_examples=3581, test/ssim=0.720958, total_duration=623.867218, train/loss=0.281813, train/ssim=0.726443, validation/loss=0.305264, validation/num_examples=3554, validation/ssim=0.703798
I0502 06:48:09.225902 139424968976128 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.13493242859840393, loss=0.3048786222934723
I0502 06:48:33.302071 139424977368832 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.12856584787368774, loss=0.2896950840950012
I0502 06:48:57.410380 139424968976128 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.23738957941532135, loss=0.32294949889183044
I0502 06:49:17.488397 139631035082560 spec.py:298] Evaluating on the training split.
I0502 06:49:18.961780 139631035082560 spec.py:310] Evaluating on the validation split.
I0502 06:49:20.312746 139631035082560 spec.py:326] Evaluating on the test split.
I0502 06:49:21.664686 139631035082560 submission_runner.py:415] Time since start: 708.28s, 	Step: 1385, 	{'train/ssim': 0.7258015360151019, 'train/loss': 0.2815223591668265, 'validation/ssim': 0.703241643438731, 'validation/loss': 0.3044945368554797, 'validation/num_examples': 3554, 'test/ssim': 0.7203445157602625, 'test/loss': 0.30647117190772477, 'test/num_examples': 3581, 'score': 471.4273316860199, 'total_duration': 708.2761731147766, 'accumulated_submission_time': 471.4273316860199, 'accumulated_eval_time': 236.72002696990967, 'accumulated_logging_time': 0.11157894134521484}
I0502 06:49:21.673272 139424977368832 logging_writer.py:48] [1385] accumulated_eval_time=236.720027, accumulated_logging_time=0.111579, accumulated_submission_time=471.427332, global_step=1385, preemption_count=0, score=471.427332, test/loss=0.306471, test/num_examples=3581, test/ssim=0.720345, total_duration=708.276173, train/loss=0.281522, train/ssim=0.725802, validation/loss=0.304495, validation/num_examples=3554, validation/ssim=0.703242
I0502 06:49:23.970266 139424968976128 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.28665000200271606, loss=0.22351256012916565
I0502 06:49:47.403117 139424977368832 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.1327650398015976, loss=0.2730107605457306
I0502 06:50:11.356233 139424968976128 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.15659673511981964, loss=0.32351046800613403
I0502 06:50:35.235903 139424977368832 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.14635702967643738, loss=0.36065351963043213
I0502 06:50:41.797762 139631035082560 spec.py:298] Evaluating on the training split.
I0502 06:50:43.267874 139631035082560 spec.py:310] Evaluating on the validation split.
I0502 06:50:44.619308 139631035082560 spec.py:326] Evaluating on the test split.
I0502 06:50:45.973316 139631035082560 submission_runner.py:415] Time since start: 792.58s, 	Step: 1729, 	{'train/ssim': 0.7336995942252023, 'train/loss': 0.27444236619131906, 'validation/ssim': 0.7104050481191967, 'validation/loss': 0.29792712656513787, 'validation/num_examples': 3554, 'test/ssim': 0.7274980201497486, 'test/loss': 0.2996973774347249, 'test/num_examples': 3581, 'score': 551.5395247936249, 'total_duration': 792.5847816467285, 'accumulated_submission_time': 551.5395247936249, 'accumulated_eval_time': 240.89553046226501, 'accumulated_logging_time': 0.12791681289672852}
I0502 06:50:45.986660 139424968976128 logging_writer.py:48] [1729] accumulated_eval_time=240.895530, accumulated_logging_time=0.127917, accumulated_submission_time=551.539525, global_step=1729, preemption_count=0, score=551.539525, test/loss=0.299697, test/num_examples=3581, test/ssim=0.727498, total_duration=792.584782, train/loss=0.274442, train/ssim=0.733700, validation/loss=0.297927, validation/num_examples=3554, validation/ssim=0.710405
I0502 06:51:01.224336 139424977368832 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.05479339882731438, loss=0.2645013928413391
I0502 06:51:25.035463 139424968976128 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.07301095873117447, loss=0.34732162952423096
I0502 06:51:48.982000 139424977368832 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.10035856813192368, loss=0.2911689877510071
I0502 06:52:06.230751 139631035082560 spec.py:298] Evaluating on the training split.
I0502 06:52:07.704471 139631035082560 spec.py:310] Evaluating on the validation split.
I0502 06:52:09.058326 139631035082560 spec.py:326] Evaluating on the test split.
I0502 06:52:10.415219 139631035082560 submission_runner.py:415] Time since start: 877.03s, 	Step: 2072, 	{'train/ssim': 0.7138056755065918, 'train/loss': 0.2924119404384068, 'validation/ssim': 0.6941132295916573, 'validation/loss': 0.3162494202175366, 'validation/num_examples': 3554, 'test/ssim': 0.7102620056373918, 'test/loss': 0.3186227414435563, 'test/num_examples': 3581, 'score': 631.7711107730865, 'total_duration': 877.0267090797424, 'accumulated_submission_time': 631.7711107730865, 'accumulated_eval_time': 245.0799732208252, 'accumulated_logging_time': 0.14934754371643066}
I0502 06:52:10.423423 139424968976128 logging_writer.py:48] [2072] accumulated_eval_time=245.079973, accumulated_logging_time=0.149348, accumulated_submission_time=631.771111, global_step=2072, preemption_count=0, score=631.771111, test/loss=0.318623, test/num_examples=3581, test/ssim=0.710262, total_duration=877.026709, train/loss=0.292412, train/ssim=0.713806, validation/loss=0.316249, validation/num_examples=3554, validation/ssim=0.694113
I0502 06:52:15.361608 139424977368832 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.15488064289093018, loss=0.4358319640159607
I0502 06:52:39.286253 139424968976128 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.2583003044128418, loss=0.2601381540298462
I0502 06:53:03.163169 139424977368832 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.13963505625724792, loss=0.24789990484714508
I0502 06:53:27.084681 139424968976128 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.12312285602092743, loss=0.2565748393535614
I0502 06:53:30.581027 139631035082560 spec.py:298] Evaluating on the training split.
I0502 06:53:32.055493 139631035082560 spec.py:310] Evaluating on the validation split.
I0502 06:53:33.408887 139631035082560 spec.py:326] Evaluating on the test split.
I0502 06:53:34.761561 139631035082560 submission_runner.py:415] Time since start: 961.37s, 	Step: 2416, 	{'train/ssim': 0.7355931145804269, 'train/loss': 0.27176828043801443, 'validation/ssim': 0.7117846418648002, 'validation/loss': 0.29551426292337857, 'validation/num_examples': 3554, 'test/ssim': 0.729096762863027, 'test/loss': 0.2971669665530753, 'test/num_examples': 3581, 'score': 711.9153237342834, 'total_duration': 961.3730535507202, 'accumulated_submission_time': 711.9153237342834, 'accumulated_eval_time': 249.2604615688324, 'accumulated_logging_time': 0.1665024757385254}
I0502 06:53:34.770024 139424977368832 logging_writer.py:48] [2416] accumulated_eval_time=249.260462, accumulated_logging_time=0.166502, accumulated_submission_time=711.915324, global_step=2416, preemption_count=0, score=711.915324, test/loss=0.297167, test/num_examples=3581, test/ssim=0.729097, total_duration=961.373054, train/loss=0.271768, train/ssim=0.735593, validation/loss=0.295514, validation/num_examples=3554, validation/ssim=0.711785
I0502 06:53:53.326941 139424968976128 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.07593054324388504, loss=0.26397255063056946
I0502 06:54:17.189109 139424977368832 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.07583100348711014, loss=0.2402210235595703
I0502 06:54:41.103890 139424968976128 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.10334512591362, loss=0.25430548191070557
I0502 06:54:54.904610 139631035082560 spec.py:298] Evaluating on the training split.
I0502 06:54:56.377590 139631035082560 spec.py:310] Evaluating on the validation split.
I0502 06:54:57.731356 139631035082560 spec.py:326] Evaluating on the test split.
I0502 06:54:59.084243 139631035082560 submission_runner.py:415] Time since start: 1045.70s, 	Step: 2759, 	{'train/ssim': 0.7361875942775181, 'train/loss': 0.27084042344774517, 'validation/ssim': 0.713146649791608, 'validation/loss': 0.2942074854587261, 'validation/num_examples': 3554, 'test/ssim': 0.7304864077553407, 'test/loss': 0.29579364997120217, 'test/num_examples': 3581, 'score': 792.0375425815582, 'total_duration': 1045.6957318782806, 'accumulated_submission_time': 792.0375425815582, 'accumulated_eval_time': 253.4400496482849, 'accumulated_logging_time': 0.1828901767730713}
I0502 06:54:59.093893 139424977368832 logging_writer.py:48] [2759] accumulated_eval_time=253.440050, accumulated_logging_time=0.182890, accumulated_submission_time=792.037543, global_step=2759, preemption_count=0, score=792.037543, test/loss=0.295794, test/num_examples=3581, test/ssim=0.730486, total_duration=1045.695732, train/loss=0.270840, train/ssim=0.736188, validation/loss=0.294207, validation/num_examples=3554, validation/ssim=0.713147
I0502 06:55:07.150490 139424968976128 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.0862651988863945, loss=0.27016937732696533
I0502 06:55:31.278770 139424977368832 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.1555892378091812, loss=0.2925131618976593
I0502 06:55:55.192351 139424968976128 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.11388207972049713, loss=0.2793651521205902
I0502 06:56:19.126459 139424977368832 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.2089945673942566, loss=0.2305384874343872
I0502 06:56:19.131384 139631035082560 spec.py:298] Evaluating on the training split.
I0502 06:56:20.477630 139631035082560 spec.py:310] Evaluating on the validation split.
I0502 06:56:21.831504 139631035082560 spec.py:326] Evaluating on the test split.
I0502 06:56:23.182520 139631035082560 submission_runner.py:415] Time since start: 1129.79s, 	Step: 3101, 	{'train/ssim': 0.7385143552507673, 'train/loss': 0.26950653961726595, 'validation/ssim': 0.7153779879405248, 'validation/loss': 0.29315178677414533, 'validation/num_examples': 3554, 'test/ssim': 0.7325688638822955, 'test/loss': 0.29474543379991625, 'test/num_examples': 3581, 'score': 872.062747001648, 'total_duration': 1129.7940118312836, 'accumulated_submission_time': 872.062747001648, 'accumulated_eval_time': 257.49113154411316, 'accumulated_logging_time': 0.20040082931518555}
I0502 06:56:23.191267 139424968976128 logging_writer.py:48] [3101] accumulated_eval_time=257.491132, accumulated_logging_time=0.200401, accumulated_submission_time=872.062747, global_step=3101, preemption_count=0, score=872.062747, test/loss=0.294745, test/num_examples=3581, test/ssim=0.732569, total_duration=1129.794012, train/loss=0.269507, train/ssim=0.738514, validation/loss=0.293152, validation/num_examples=3554, validation/ssim=0.715378
I0502 06:56:45.125495 139424977368832 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.15962542593479156, loss=0.22670701146125793
I0502 06:57:08.948596 139424968976128 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.1492428481578827, loss=0.25502240657806396
I0502 06:57:32.597397 139424977368832 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.09288201481103897, loss=0.27391836047172546
I0502 06:57:43.285617 139631035082560 spec.py:298] Evaluating on the training split.
I0502 06:57:44.759368 139631035082560 spec.py:310] Evaluating on the validation split.
I0502 06:57:46.112839 139631035082560 spec.py:326] Evaluating on the test split.
I0502 06:57:47.464257 139631035082560 submission_runner.py:415] Time since start: 1214.08s, 	Step: 3446, 	{'train/ssim': 0.740776675088065, 'train/loss': 0.26943717684064594, 'validation/ssim': 0.7169721836311199, 'validation/loss': 0.29378058283799946, 'validation/num_examples': 3554, 'test/ssim': 0.734095339334334, 'test/loss': 0.29543521117311855, 'test/num_examples': 3581, 'score': 952.1442821025848, 'total_duration': 1214.0757360458374, 'accumulated_submission_time': 952.1442821025848, 'accumulated_eval_time': 261.66973543167114, 'accumulated_logging_time': 0.21737337112426758}
I0502 06:57:47.474082 139424968976128 logging_writer.py:48] [3446] accumulated_eval_time=261.669735, accumulated_logging_time=0.217373, accumulated_submission_time=952.144282, global_step=3446, preemption_count=0, score=952.144282, test/loss=0.295435, test/num_examples=3581, test/ssim=0.734095, total_duration=1214.075736, train/loss=0.269437, train/ssim=0.740777, validation/loss=0.293781, validation/num_examples=3554, validation/ssim=0.716972
I0502 06:57:58.790750 139424977368832 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.1816854476928711, loss=0.3791068196296692
I0502 06:58:22.465579 139424968976128 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.0983780100941658, loss=0.3190774917602539
I0502 06:58:46.556389 139424977368832 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.13669197261333466, loss=0.33780431747436523
I0502 06:59:07.526138 139631035082560 spec.py:298] Evaluating on the training split.
I0502 06:59:08.999026 139631035082560 spec.py:310] Evaluating on the validation split.
I0502 06:59:10.351717 139631035082560 spec.py:326] Evaluating on the test split.
I0502 06:59:11.705026 139631035082560 submission_runner.py:415] Time since start: 1298.32s, 	Step: 3790, 	{'train/ssim': 0.7392283167157855, 'train/loss': 0.2687582118170602, 'validation/ssim': 0.7161014795169176, 'validation/loss': 0.2922332712150921, 'validation/num_examples': 3554, 'test/ssim': 0.7333726667219352, 'test/loss': 0.2937981190877199, 'test/num_examples': 3581, 'score': 1032.1843082904816, 'total_duration': 1298.3165152072906, 'accumulated_submission_time': 1032.1843082904816, 'accumulated_eval_time': 265.848580121994, 'accumulated_logging_time': 0.23486614227294922}
I0502 06:59:11.713606 139424968976128 logging_writer.py:48] [3790] accumulated_eval_time=265.848580, accumulated_logging_time=0.234866, accumulated_submission_time=1032.184308, global_step=3790, preemption_count=0, score=1032.184308, test/loss=0.293798, test/num_examples=3581, test/ssim=0.733373, total_duration=1298.316515, train/loss=0.268758, train/ssim=0.739228, validation/loss=0.292233, validation/num_examples=3554, validation/ssim=0.716101
I0502 06:59:13.295446 139424977368832 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.053126946091651917, loss=0.38166379928588867
I0502 06:59:36.247559 139424968976128 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.13055124878883362, loss=0.25963735580444336
I0502 07:00:00.185701 139424977368832 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.0767095759510994, loss=0.2142639458179474
I0502 07:00:23.833800 139424968976128 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.07245257496833801, loss=0.25224554538726807
I0502 07:00:31.765929 139631035082560 spec.py:298] Evaluating on the training split.
I0502 07:00:33.236761 139631035082560 spec.py:310] Evaluating on the validation split.
I0502 07:00:34.588396 139631035082560 spec.py:326] Evaluating on the test split.
I0502 07:00:35.941241 139631035082560 submission_runner.py:415] Time since start: 1382.55s, 	Step: 4134, 	{'train/ssim': 0.7376311847141811, 'train/loss': 0.26939025947025846, 'validation/ssim': 0.714538883344471, 'validation/loss': 0.2928323225151238, 'validation/num_examples': 3554, 'test/ssim': 0.7318714848113307, 'test/loss': 0.2943093076959997, 'test/num_examples': 3581, 'score': 1112.2244012355804, 'total_duration': 1382.5527226924896, 'accumulated_submission_time': 1112.2244012355804, 'accumulated_eval_time': 270.0238399505615, 'accumulated_logging_time': 0.2511942386627197}
I0502 07:00:35.950330 139424977368832 logging_writer.py:48] [4134] accumulated_eval_time=270.023840, accumulated_logging_time=0.251194, accumulated_submission_time=1112.224401, global_step=4134, preemption_count=0, score=1112.224401, test/loss=0.294309, test/num_examples=3581, test/ssim=0.731871, total_duration=1382.552723, train/loss=0.269390, train/ssim=0.737631, validation/loss=0.292832, validation/num_examples=3554, validation/ssim=0.714539
I0502 07:00:50.544455 139424968976128 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.07066171616315842, loss=0.2444978952407837
I0502 07:01:14.722704 139424977368832 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.16046245396137238, loss=0.26652732491493225
I0502 07:01:38.585188 139424968976128 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.08239033818244934, loss=0.28220802545547485
I0502 07:01:56.062789 139631035082560 spec.py:298] Evaluating on the training split.
I0502 07:01:57.538266 139631035082560 spec.py:310] Evaluating on the validation split.
I0502 07:01:58.891792 139631035082560 spec.py:326] Evaluating on the test split.
I0502 07:02:00.242170 139631035082560 submission_runner.py:415] Time since start: 1466.85s, 	Step: 4475, 	{'train/ssim': 0.736961841583252, 'train/loss': 0.27037899834769114, 'validation/ssim': 0.7139212501538759, 'validation/loss': 0.2938374276233645, 'validation/num_examples': 3554, 'test/ssim': 0.7311897863725216, 'test/loss': 0.29541220154984643, 'test/num_examples': 3581, 'score': 1192.324464082718, 'total_duration': 1466.85364818573, 'accumulated_submission_time': 1192.324464082718, 'accumulated_eval_time': 274.203164100647, 'accumulated_logging_time': 0.268216609954834}
I0502 07:02:00.251308 139424977368832 logging_writer.py:48] [4475] accumulated_eval_time=274.203164, accumulated_logging_time=0.268217, accumulated_submission_time=1192.324464, global_step=4475, preemption_count=0, score=1192.324464, test/loss=0.295412, test/num_examples=3581, test/ssim=0.731190, total_duration=1466.853648, train/loss=0.270379, train/ssim=0.736962, validation/loss=0.293837, validation/num_examples=3554, validation/ssim=0.713921
I0502 07:02:04.511755 139424968976128 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.21676340699195862, loss=0.22225923836231232
I0502 07:02:28.534886 139424977368832 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.0884043350815773, loss=0.21075724065303802
I0502 07:02:52.463822 139424968976128 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.1076570451259613, loss=0.2278800755739212
I0502 07:03:16.328238 139424977368832 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.03926720842719078, loss=0.23202137649059296
I0502 07:03:20.381640 139631035082560 spec.py:298] Evaluating on the training split.
I0502 07:03:21.857716 139631035082560 spec.py:310] Evaluating on the validation split.
I0502 07:03:23.210014 139631035082560 spec.py:326] Evaluating on the test split.
I0502 07:03:24.560315 139631035082560 submission_runner.py:415] Time since start: 1551.17s, 	Step: 4819, 	{'train/ssim': 0.7421336855207171, 'train/loss': 0.2669982739857265, 'validation/ssim': 0.71858410252972, 'validation/loss': 0.29066985070738954, 'validation/num_examples': 3554, 'test/ssim': 0.7358322761405682, 'test/loss': 0.292258758246649, 'test/num_examples': 3581, 'score': 1272.4417164325714, 'total_duration': 1551.1717925071716, 'accumulated_submission_time': 1272.4417164325714, 'accumulated_eval_time': 278.3818061351776, 'accumulated_logging_time': 0.28598594665527344}
I0502 07:03:24.569131 139424968976128 logging_writer.py:48] [4819] accumulated_eval_time=278.381806, accumulated_logging_time=0.285986, accumulated_submission_time=1272.441716, global_step=4819, preemption_count=0, score=1272.441716, test/loss=0.292259, test/num_examples=3581, test/ssim=0.735832, total_duration=1551.171793, train/loss=0.266998, train/ssim=0.742134, validation/loss=0.290670, validation/num_examples=3554, validation/ssim=0.718584
I0502 07:03:42.293992 139424977368832 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.13800956308841705, loss=0.31382325291633606
I0502 07:04:06.186330 139424968976128 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.07004106044769287, loss=0.247841477394104
I0502 07:04:29.963928 139424977368832 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.08086983859539032, loss=0.23660679161548615
I0502 07:04:44.723417 139631035082560 spec.py:298] Evaluating on the training split.
I0502 07:04:46.195218 139631035082560 spec.py:310] Evaluating on the validation split.
I0502 07:04:47.547589 139631035082560 spec.py:326] Evaluating on the test split.
I0502 07:04:48.899023 139631035082560 submission_runner.py:415] Time since start: 1635.51s, 	Step: 5163, 	{'train/ssim': 0.7406464985438755, 'train/loss': 0.2675704615456717, 'validation/ssim': 0.7172062261492332, 'validation/loss': 0.29107556104257526, 'validation/num_examples': 3554, 'test/ssim': 0.7344748106325049, 'test/loss': 0.2926450131226438, 'test/num_examples': 3581, 'score': 1352.5829083919525, 'total_duration': 1635.5104660987854, 'accumulated_submission_time': 1352.5829083919525, 'accumulated_eval_time': 282.5573239326477, 'accumulated_logging_time': 0.30336999893188477}
I0502 07:04:48.908136 139424968976128 logging_writer.py:48] [5163] accumulated_eval_time=282.557324, accumulated_logging_time=0.303370, accumulated_submission_time=1352.582908, global_step=5163, preemption_count=0, score=1352.582908, test/loss=0.292645, test/num_examples=3581, test/ssim=0.734475, total_duration=1635.510466, train/loss=0.267570, train/ssim=0.740646, validation/loss=0.291076, validation/num_examples=3554, validation/ssim=0.717206
I0502 07:04:56.098658 139424977368832 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.06017399951815605, loss=0.2400454431772232
I0502 07:05:20.976988 139424968976128 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.10861587524414062, loss=0.21124723553657532
I0502 07:05:44.751549 139424977368832 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.10611963272094727, loss=0.2406330406665802
I0502 07:05:51.119791 139631035082560 spec.py:298] Evaluating on the training split.
I0502 07:05:52.594981 139631035082560 spec.py:310] Evaluating on the validation split.
I0502 07:05:53.949773 139631035082560 spec.py:326] Evaluating on the test split.
I0502 07:05:55.298956 139631035082560 submission_runner.py:415] Time since start: 1701.91s, 	Step: 5428, 	{'train/ssim': 0.7331299100603376, 'train/loss': 0.27473468439919607, 'validation/ssim': 0.7104453718521384, 'validation/loss': 0.298001797600415, 'validation/num_examples': 3554, 'test/ssim': 0.7276830516091873, 'test/loss': 0.29973020449725984, 'test/num_examples': 3581, 'score': 1414.782300710678, 'total_duration': 1701.9104497432709, 'accumulated_submission_time': 1414.782300710678, 'accumulated_eval_time': 286.7364454269409, 'accumulated_logging_time': 0.3211367130279541}
I0502 07:05:55.307785 139424968976128 logging_writer.py:48] [5428] accumulated_eval_time=286.736445, accumulated_logging_time=0.321137, accumulated_submission_time=1414.782301, global_step=5428, preemption_count=0, score=1414.782301, test/loss=0.299730, test/num_examples=3581, test/ssim=0.727683, total_duration=1701.910450, train/loss=0.274735, train/ssim=0.733130, validation/loss=0.298002, validation/num_examples=3554, validation/ssim=0.710445
I0502 07:05:55.322744 139424977368832 logging_writer.py:48] [5428] global_step=5428, preemption_count=0, score=1414.782301
I0502 07:05:55.357073 139631035082560 checkpoints.py:356] Saving checkpoint at step: 5428
I0502 07:05:55.605310 139631035082560 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_fancy_2/timing_sam/fastmri_jax/trial_1/checkpoint_5428
I0502 07:05:55.605989 139631035082560 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_fancy_2/timing_sam/fastmri_jax/trial_1/checkpoint_5428.
I0502 07:05:56.462276 139631035082560 submission_runner.py:578] Tuning trial 1/1
I0502 07:05:56.462530 139631035082560 submission_runner.py:579] Hyperparameters: Hyperparameters(learning_rate=0.0013159053452895648, one_minus_beta1=0.2018302260773442, beta2=0.999, warmup_factor=0.05, weight_decay=0.07935861128365443, label_smoothing=0.1, dropout_rate=0.0, rho=0.01)
I0502 07:05:56.465538 139631035082560 submission_runner.py:580] Metrics: {'eval_results': [(1, {'train/ssim': 0.19806415694100515, 'train/loss': 1.0715648106166296, 'validation/ssim': 0.19566289400477455, 'validation/loss': 1.071294489373769, 'validation/num_examples': 3554, 'test/ssim': 0.21896218281489982, 'test/loss': 1.0674319678729753, 'test/num_examples': 3581, 'score': 70.63732814788818, 'total_duration': 286.103018283844, 'accumulated_submission_time': 70.63732814788818, 'accumulated_eval_time': 215.4655499458313, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (328, {'train/ssim': 0.6978415761675153, 'train/loss': 0.3031109401157924, 'validation/ssim': 0.674048703375598, 'validation/loss': 0.3279291516820836, 'validation/num_examples': 3554, 'test/ssim': 0.6927200142680118, 'test/loss': 0.32953707501396257, 'test/num_examples': 3581, 'score': 150.6885232925415, 'total_duration': 370.7459144592285, 'accumulated_submission_time': 150.6885232925415, 'accumulated_eval_time': 220.02448654174805, 'accumulated_logging_time': 0.028630495071411133, 'global_step': 328, 'preemption_count': 0}), (561, {'train/ssim': 0.715043272290911, 'train/loss': 0.28882016454424175, 'validation/ssim': 0.6921770034644062, 'validation/loss': 0.3125341412185214, 'validation/num_examples': 3554, 'test/ssim': 0.710016774185807, 'test/loss': 0.31422756251527156, 'test/num_examples': 3581, 'score': 231.0089099407196, 'total_duration': 455.26527881622314, 'accumulated_submission_time': 231.0089099407196, 'accumulated_eval_time': 224.19832396507263, 'accumulated_logging_time': 0.0510561466217041, 'global_step': 561, 'preemption_count': 0}), (794, {'train/ssim': 0.7194465909685407, 'train/loss': 0.2880207470485142, 'validation/ssim': 0.696329111454523, 'validation/loss': 0.3121126998188661, 'validation/num_examples': 3554, 'test/ssim': 0.7137521052953085, 'test/loss': 0.31411377566714954, 'test/num_examples': 3581, 'score': 311.21634435653687, 'total_duration': 539.667973279953, 'accumulated_submission_time': 311.21634435653687, 'accumulated_eval_time': 228.37002444267273, 'accumulated_logging_time': 0.07191681861877441, 'global_step': 794, 'preemption_count': 0}), (1043, {'train/ssim': 0.726442813873291, 'train/loss': 0.2818132979529245, 'validation/ssim': 0.7037976575689364, 'validation/loss': 0.3052636416493739, 'validation/num_examples': 3554, 'test/ssim': 0.7209581738908475, 'test/loss': 0.3074215545696907, 'test/num_examples': 3581, 'score': 391.2160847187042, 'total_duration': 623.8672182559967, 'accumulated_submission_time': 391.2160847187042, 'accumulated_eval_time': 232.543781042099, 'accumulated_logging_time': 0.09460091590881348, 'global_step': 1043, 'preemption_count': 0}), (1385, {'train/ssim': 0.7258015360151019, 'train/loss': 0.2815223591668265, 'validation/ssim': 0.703241643438731, 'validation/loss': 0.3044945368554797, 'validation/num_examples': 3554, 'test/ssim': 0.7203445157602625, 'test/loss': 0.30647117190772477, 'test/num_examples': 3581, 'score': 471.4273316860199, 'total_duration': 708.2761731147766, 'accumulated_submission_time': 471.4273316860199, 'accumulated_eval_time': 236.72002696990967, 'accumulated_logging_time': 0.11157894134521484, 'global_step': 1385, 'preemption_count': 0}), (1729, {'train/ssim': 0.7336995942252023, 'train/loss': 0.27444236619131906, 'validation/ssim': 0.7104050481191967, 'validation/loss': 0.29792712656513787, 'validation/num_examples': 3554, 'test/ssim': 0.7274980201497486, 'test/loss': 0.2996973774347249, 'test/num_examples': 3581, 'score': 551.5395247936249, 'total_duration': 792.5847816467285, 'accumulated_submission_time': 551.5395247936249, 'accumulated_eval_time': 240.89553046226501, 'accumulated_logging_time': 0.12791681289672852, 'global_step': 1729, 'preemption_count': 0}), (2072, {'train/ssim': 0.7138056755065918, 'train/loss': 0.2924119404384068, 'validation/ssim': 0.6941132295916573, 'validation/loss': 0.3162494202175366, 'validation/num_examples': 3554, 'test/ssim': 0.7102620056373918, 'test/loss': 0.3186227414435563, 'test/num_examples': 3581, 'score': 631.7711107730865, 'total_duration': 877.0267090797424, 'accumulated_submission_time': 631.7711107730865, 'accumulated_eval_time': 245.0799732208252, 'accumulated_logging_time': 0.14934754371643066, 'global_step': 2072, 'preemption_count': 0}), (2416, {'train/ssim': 0.7355931145804269, 'train/loss': 0.27176828043801443, 'validation/ssim': 0.7117846418648002, 'validation/loss': 0.29551426292337857, 'validation/num_examples': 3554, 'test/ssim': 0.729096762863027, 'test/loss': 0.2971669665530753, 'test/num_examples': 3581, 'score': 711.9153237342834, 'total_duration': 961.3730535507202, 'accumulated_submission_time': 711.9153237342834, 'accumulated_eval_time': 249.2604615688324, 'accumulated_logging_time': 0.1665024757385254, 'global_step': 2416, 'preemption_count': 0}), (2759, {'train/ssim': 0.7361875942775181, 'train/loss': 0.27084042344774517, 'validation/ssim': 0.713146649791608, 'validation/loss': 0.2942074854587261, 'validation/num_examples': 3554, 'test/ssim': 0.7304864077553407, 'test/loss': 0.29579364997120217, 'test/num_examples': 3581, 'score': 792.0375425815582, 'total_duration': 1045.6957318782806, 'accumulated_submission_time': 792.0375425815582, 'accumulated_eval_time': 253.4400496482849, 'accumulated_logging_time': 0.1828901767730713, 'global_step': 2759, 'preemption_count': 0}), (3101, {'train/ssim': 0.7385143552507673, 'train/loss': 0.26950653961726595, 'validation/ssim': 0.7153779879405248, 'validation/loss': 0.29315178677414533, 'validation/num_examples': 3554, 'test/ssim': 0.7325688638822955, 'test/loss': 0.29474543379991625, 'test/num_examples': 3581, 'score': 872.062747001648, 'total_duration': 1129.7940118312836, 'accumulated_submission_time': 872.062747001648, 'accumulated_eval_time': 257.49113154411316, 'accumulated_logging_time': 0.20040082931518555, 'global_step': 3101, 'preemption_count': 0}), (3446, {'train/ssim': 0.740776675088065, 'train/loss': 0.26943717684064594, 'validation/ssim': 0.7169721836311199, 'validation/loss': 0.29378058283799946, 'validation/num_examples': 3554, 'test/ssim': 0.734095339334334, 'test/loss': 0.29543521117311855, 'test/num_examples': 3581, 'score': 952.1442821025848, 'total_duration': 1214.0757360458374, 'accumulated_submission_time': 952.1442821025848, 'accumulated_eval_time': 261.66973543167114, 'accumulated_logging_time': 0.21737337112426758, 'global_step': 3446, 'preemption_count': 0}), (3790, {'train/ssim': 0.7392283167157855, 'train/loss': 0.2687582118170602, 'validation/ssim': 0.7161014795169176, 'validation/loss': 0.2922332712150921, 'validation/num_examples': 3554, 'test/ssim': 0.7333726667219352, 'test/loss': 0.2937981190877199, 'test/num_examples': 3581, 'score': 1032.1843082904816, 'total_duration': 1298.3165152072906, 'accumulated_submission_time': 1032.1843082904816, 'accumulated_eval_time': 265.848580121994, 'accumulated_logging_time': 0.23486614227294922, 'global_step': 3790, 'preemption_count': 0}), (4134, {'train/ssim': 0.7376311847141811, 'train/loss': 0.26939025947025846, 'validation/ssim': 0.714538883344471, 'validation/loss': 0.2928323225151238, 'validation/num_examples': 3554, 'test/ssim': 0.7318714848113307, 'test/loss': 0.2943093076959997, 'test/num_examples': 3581, 'score': 1112.2244012355804, 'total_duration': 1382.5527226924896, 'accumulated_submission_time': 1112.2244012355804, 'accumulated_eval_time': 270.0238399505615, 'accumulated_logging_time': 0.2511942386627197, 'global_step': 4134, 'preemption_count': 0}), (4475, {'train/ssim': 0.736961841583252, 'train/loss': 0.27037899834769114, 'validation/ssim': 0.7139212501538759, 'validation/loss': 0.2938374276233645, 'validation/num_examples': 3554, 'test/ssim': 0.7311897863725216, 'test/loss': 0.29541220154984643, 'test/num_examples': 3581, 'score': 1192.324464082718, 'total_duration': 1466.85364818573, 'accumulated_submission_time': 1192.324464082718, 'accumulated_eval_time': 274.203164100647, 'accumulated_logging_time': 0.268216609954834, 'global_step': 4475, 'preemption_count': 0}), (4819, {'train/ssim': 0.7421336855207171, 'train/loss': 0.2669982739857265, 'validation/ssim': 0.71858410252972, 'validation/loss': 0.29066985070738954, 'validation/num_examples': 3554, 'test/ssim': 0.7358322761405682, 'test/loss': 0.292258758246649, 'test/num_examples': 3581, 'score': 1272.4417164325714, 'total_duration': 1551.1717925071716, 'accumulated_submission_time': 1272.4417164325714, 'accumulated_eval_time': 278.3818061351776, 'accumulated_logging_time': 0.28598594665527344, 'global_step': 4819, 'preemption_count': 0}), (5163, {'train/ssim': 0.7406464985438755, 'train/loss': 0.2675704615456717, 'validation/ssim': 0.7172062261492332, 'validation/loss': 0.29107556104257526, 'validation/num_examples': 3554, 'test/ssim': 0.7344748106325049, 'test/loss': 0.2926450131226438, 'test/num_examples': 3581, 'score': 1352.5829083919525, 'total_duration': 1635.5104660987854, 'accumulated_submission_time': 1352.5829083919525, 'accumulated_eval_time': 282.5573239326477, 'accumulated_logging_time': 0.30336999893188477, 'global_step': 5163, 'preemption_count': 0}), (5428, {'train/ssim': 0.7331299100603376, 'train/loss': 0.27473468439919607, 'validation/ssim': 0.7104453718521384, 'validation/loss': 0.298001797600415, 'validation/num_examples': 3554, 'test/ssim': 0.7276830516091873, 'test/loss': 0.29973020449725984, 'test/num_examples': 3581, 'score': 1414.782300710678, 'total_duration': 1701.9104497432709, 'accumulated_submission_time': 1414.782300710678, 'accumulated_eval_time': 286.7364454269409, 'accumulated_logging_time': 0.3211367130279541, 'global_step': 5428, 'preemption_count': 0})], 'global_step': 5428}
I0502 07:05:56.465675 139631035082560 submission_runner.py:581] Timing: 1414.782300710678
I0502 07:05:56.465719 139631035082560 submission_runner.py:582] ====================
I0502 07:05:56.465826 139631035082560 submission_runner.py:645] Final fastmri score: 1414.782300710678
