python3 submission_runner.py --framework=jax --workload=fastmri --submission_path=baselines/adafactor/jax/submission.py --tuning_search_space=baselines/adafactor/tuning_search_space.json --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_fancy_adafactor/timing_adafactor --overwrite=True --save_checkpoints=False --max_global_steps=5428 2>&1 | tee -a /logs/fastmri_jax_05-10-2023-08-06-32.log
I0510 08:06:52.730752 140344290568000 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_fancy_adafactor/timing_adafactor/fastmri_jax.
I0510 08:06:52.890311 140344290568000 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0510 08:06:53.776805 140344290568000 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter Host
I0510 08:06:53.778052 140344290568000 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0510 08:06:53.783785 140344290568000 submission_runner.py:544] Using RNG seed 2903937023
I0510 08:06:56.572965 140344290568000 submission_runner.py:553] --- Tuning run 1/1 ---
I0510 08:06:56.573171 140344290568000 submission_runner.py:558] Creating tuning directory at /experiment_runs/timing_fancy_adafactor/timing_adafactor/fastmri_jax/trial_1.
I0510 08:06:56.573347 140344290568000 logger_utils.py:92] Saving hparams to /experiment_runs/timing_fancy_adafactor/timing_adafactor/fastmri_jax/trial_1/hparams.json.
I0510 08:06:56.708028 140344290568000 submission_runner.py:241] Initializing dataset.
I0510 08:07:01.926981 140344290568000 submission_runner.py:248] Initializing model.
I0510 08:07:09.178349 140344290568000 submission_runner.py:258] Initializing optimizer.
I0510 08:07:11.067983 140344290568000 submission_runner.py:265] Initializing metrics bundle.
I0510 08:07:11.068180 140344290568000 submission_runner.py:283] Initializing checkpoint and logger.
I0510 08:07:11.070148 140344290568000 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_fancy_adafactor/timing_adafactor/fastmri_jax/trial_1 with prefix checkpoint_
I0510 08:07:11.070429 140344290568000 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0510 08:07:11.070500 140344290568000 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0510 08:07:11.840017 140344290568000 submission_runner.py:304] Saving meta data to /experiment_runs/timing_fancy_adafactor/timing_adafactor/fastmri_jax/trial_1/meta_data_0.json.
I0510 08:07:11.841105 140344290568000 submission_runner.py:307] Saving flags to /experiment_runs/timing_fancy_adafactor/timing_adafactor/fastmri_jax/trial_1/flags_0.json.
I0510 08:07:11.847618 140344290568000 submission_runner.py:319] Starting training loop.
I0510 08:08:07.264736 140167826368256 logging_writer.py:48] [0] global_step=0, grad_norm=5.035466194152832, loss=0.9240580201148987
I0510 08:08:07.278513 140344290568000 spec.py:298] Evaluating on the training split.
I0510 08:09:22.990661 140344290568000 spec.py:310] Evaluating on the validation split.
I0510 08:10:07.942088 140344290568000 spec.py:326] Evaluating on the test split.
I0510 08:10:48.681030 140344290568000 submission_runner.py:421] Time since start: 216.83s, 	Step: 1, 	{'train/ssim': 0.18846821784973145, 'train/loss': 0.9440065792628697, 'validation/ssim': 0.18410002923642374, 'validation/loss': 0.9490453648178109, 'validation/num_examples': 3554, 'test/ssim': 0.20769997782894967, 'test/loss': 0.9445568298834125, 'test/num_examples': 3581, 'score': 55.43068838119507, 'total_duration': 216.8333191871643, 'accumulated_submission_time': 55.43068838119507, 'accumulated_eval_time': 161.4024715423584, 'accumulated_logging_time': 0}
I0510 08:10:48.697870 140139640628992 logging_writer.py:48] [1] accumulated_eval_time=161.402472, accumulated_logging_time=0, accumulated_submission_time=55.430688, global_step=1, preemption_count=0, score=55.430688, test/loss=0.944557, test/num_examples=3581, test/ssim=0.207700, total_duration=216.833319, train/loss=0.944007, train/ssim=0.188468, validation/loss=0.949045, validation/num_examples=3554, validation/ssim=0.184100
I0510 08:11:10.996480 140139632236288 logging_writer.py:48] [100] global_step=100, grad_norm=0.4037410616874695, loss=0.28162047266960144
I0510 08:11:35.523702 140139640628992 logging_writer.py:48] [200] global_step=200, grad_norm=0.13195674121379852, loss=0.38086363673210144
I0510 08:11:59.973157 140139632236288 logging_writer.py:48] [300] global_step=300, grad_norm=0.3730638027191162, loss=0.34878379106521606
I0510 08:12:08.770764 140344290568000 spec.py:298] Evaluating on the training split.
I0510 08:12:10.483768 140344290568000 spec.py:310] Evaluating on the validation split.
I0510 08:12:11.836515 140344290568000 spec.py:326] Evaluating on the test split.
I0510 08:12:13.183866 140344290568000 submission_runner.py:421] Time since start: 301.34s, 	Step: 337, 	{'train/ssim': 0.7135613305228097, 'train/loss': 0.29684948921203613, 'validation/ssim': 0.6913500578133793, 'validation/loss': 0.3167252333967888, 'validation/num_examples': 3554, 'test/ssim': 0.7089708760210137, 'test/loss': 0.31888430120558153, 'test/num_examples': 3581, 'score': 135.4901602268219, 'total_duration': 301.33613657951355, 'accumulated_submission_time': 135.4901602268219, 'accumulated_eval_time': 165.81550550460815, 'accumulated_logging_time': 0.025691747665405273}
I0510 08:12:13.194098 140139640628992 logging_writer.py:48] [337] accumulated_eval_time=165.815506, accumulated_logging_time=0.025692, accumulated_submission_time=135.490160, global_step=337, preemption_count=0, score=135.490160, test/loss=0.318884, test/num_examples=3581, test/ssim=0.708971, total_duration=301.336137, train/loss=0.296849, train/ssim=0.713561, validation/loss=0.316725, validation/num_examples=3554, validation/ssim=0.691350
I0510 08:12:26.777792 140139632236288 logging_writer.py:48] [400] global_step=400, grad_norm=0.19252483546733856, loss=0.27803364396095276
I0510 08:12:51.581433 140139640628992 logging_writer.py:48] [500] global_step=500, grad_norm=0.18874265253543854, loss=0.1995203197002411
I0510 08:13:16.098462 140139632236288 logging_writer.py:48] [600] global_step=600, grad_norm=0.09856436401605606, loss=0.3346725106239319
I0510 08:13:33.266240 140344290568000 spec.py:298] Evaluating on the training split.
I0510 08:13:34.671596 140344290568000 spec.py:310] Evaluating on the validation split.
I0510 08:13:36.024217 140344290568000 spec.py:326] Evaluating on the test split.
I0510 08:13:37.376449 140344290568000 submission_runner.py:421] Time since start: 385.53s, 	Step: 671, 	{'train/ssim': 0.7274330002920968, 'train/loss': 0.282851048878261, 'validation/ssim': 0.7055020394054234, 'validation/loss': 0.3024638556468064, 'validation/num_examples': 3554, 'test/ssim': 0.7225696656398353, 'test/loss': 0.30436260411939753, 'test/num_examples': 3581, 'score': 215.5485134124756, 'total_duration': 385.5287482738495, 'accumulated_submission_time': 215.5485134124756, 'accumulated_eval_time': 169.9256715774536, 'accumulated_logging_time': 0.04537248611450195}
I0510 08:13:37.385203 140139640628992 logging_writer.py:48] [671] accumulated_eval_time=169.925672, accumulated_logging_time=0.045372, accumulated_submission_time=215.548513, global_step=671, preemption_count=0, score=215.548513, test/loss=0.304363, test/num_examples=3581, test/ssim=0.722570, total_duration=385.528748, train/loss=0.282851, train/ssim=0.727433, validation/loss=0.302464, validation/num_examples=3554, validation/ssim=0.705502
I0510 08:13:42.498769 140139632236288 logging_writer.py:48] [700] global_step=700, grad_norm=0.19830523431301117, loss=0.3022284209728241
I0510 08:14:07.412074 140139640628992 logging_writer.py:48] [800] global_step=800, grad_norm=0.24879607558250427, loss=0.24588452279567719
I0510 08:14:32.656039 140139632236288 logging_writer.py:48] [900] global_step=900, grad_norm=0.6094372868537903, loss=0.2805967926979065
I0510 08:14:57.422695 140139640628992 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.09805840998888016, loss=0.2166873812675476
I0510 08:14:57.429092 140344290568000 spec.py:298] Evaluating on the training split.
I0510 08:14:58.779742 140344290568000 spec.py:310] Evaluating on the validation split.
I0510 08:15:05.018586 140344290568000 spec.py:326] Evaluating on the test split.
I0510 08:15:06.374189 140344290568000 submission_runner.py:421] Time since start: 474.53s, 	Step: 1001, 	{'train/ssim': 0.7319323675973075, 'train/loss': 0.27857249123709543, 'validation/ssim': 0.7097594562245005, 'validation/loss': 0.2981810905186058, 'validation/num_examples': 3554, 'test/ssim': 0.7266676284121055, 'test/loss': 0.3000763374079342, 'test/num_examples': 3581, 'score': 295.57986545562744, 'total_duration': 474.5264890193939, 'accumulated_submission_time': 295.57986545562744, 'accumulated_eval_time': 178.87070274353027, 'accumulated_logging_time': 0.06247138977050781}
I0510 08:15:06.383081 140139632236288 logging_writer.py:48] [1001] accumulated_eval_time=178.870703, accumulated_logging_time=0.062471, accumulated_submission_time=295.579865, global_step=1001, preemption_count=0, score=295.579865, test/loss=0.300076, test/num_examples=3581, test/ssim=0.726668, total_duration=474.526489, train/loss=0.278572, train/ssim=0.731932, validation/loss=0.298181, validation/num_examples=3554, validation/ssim=0.709759
I0510 08:15:28.496273 140139640628992 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.28737595677375793, loss=0.300161749124527
I0510 08:15:52.946489 140139632236288 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.12131376564502716, loss=0.22976773977279663
I0510 08:16:17.454813 140139640628992 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.16390696167945862, loss=0.3680471181869507
I0510 08:16:26.413134 140344290568000 spec.py:298] Evaluating on the training split.
I0510 08:16:27.822727 140344290568000 spec.py:310] Evaluating on the validation split.
I0510 08:16:29.177010 140344290568000 spec.py:326] Evaluating on the test split.
I0510 08:16:30.533246 140344290568000 submission_runner.py:421] Time since start: 558.69s, 	Step: 1338, 	{'train/ssim': 0.7289798600333077, 'train/loss': 0.27987188952309744, 'validation/ssim': 0.7077793342448649, 'validation/loss': 0.29949016925251476, 'validation/num_examples': 3554, 'test/ssim': 0.7244033451288048, 'test/loss': 0.3014644824136938, 'test/num_examples': 3581, 'score': 375.5970199108124, 'total_duration': 558.6855351924896, 'accumulated_submission_time': 375.5970199108124, 'accumulated_eval_time': 182.9907603263855, 'accumulated_logging_time': 0.07972908020019531}
I0510 08:16:30.542576 140139632236288 logging_writer.py:48] [1338] accumulated_eval_time=182.990760, accumulated_logging_time=0.079729, accumulated_submission_time=375.597020, global_step=1338, preemption_count=0, score=375.597020, test/loss=0.301464, test/num_examples=3581, test/ssim=0.724403, total_duration=558.685535, train/loss=0.279872, train/ssim=0.728980, validation/loss=0.299490, validation/num_examples=3554, validation/ssim=0.707779
I0510 08:16:43.468173 140139640628992 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.262626588344574, loss=0.28426581621170044
I0510 08:17:08.087371 140139632236288 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.16030116379261017, loss=0.25297093391418457
I0510 08:17:32.531597 140139640628992 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.22567987442016602, loss=0.24284662306308746
I0510 08:17:50.688989 140344290568000 spec.py:298] Evaluating on the training split.
I0510 08:17:52.095983 140344290568000 spec.py:310] Evaluating on the validation split.
I0510 08:17:53.446898 140344290568000 spec.py:326] Evaluating on the test split.
I0510 08:17:54.803721 140344290568000 submission_runner.py:421] Time since start: 642.96s, 	Step: 1676, 	{'train/ssim': 0.7347164835248675, 'train/loss': 0.2745510850633894, 'validation/ssim': 0.7122093806054798, 'validation/loss': 0.2942154196855656, 'validation/num_examples': 3554, 'test/ssim': 0.7294075802630201, 'test/loss': 0.2958835068111212, 'test/num_examples': 3581, 'score': 455.72976088523865, 'total_duration': 642.9560129642487, 'accumulated_submission_time': 455.72976088523865, 'accumulated_eval_time': 187.10544419288635, 'accumulated_logging_time': 0.09813451766967773}
I0510 08:17:54.817219 140139632236288 logging_writer.py:48] [1676] accumulated_eval_time=187.105444, accumulated_logging_time=0.098135, accumulated_submission_time=455.729761, global_step=1676, preemption_count=0, score=455.729761, test/loss=0.295884, test/num_examples=3581, test/ssim=0.729408, total_duration=642.956013, train/loss=0.274551, train/ssim=0.734716, validation/loss=0.294215, validation/num_examples=3554, validation/ssim=0.712209
I0510 08:17:58.668973 140139640628992 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.11053407192230225, loss=0.34520554542541504
I0510 08:18:23.170434 140139632236288 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.19534894824028015, loss=0.2636849284172058
I0510 08:18:47.473597 140139640628992 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.07485722005367279, loss=0.29447492957115173
I0510 08:19:12.185821 140139632236288 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.12679584324359894, loss=0.30626755952835083
I0510 08:19:15.037642 140344290568000 spec.py:298] Evaluating on the training split.
I0510 08:19:16.441699 140344290568000 spec.py:310] Evaluating on the validation split.
I0510 08:19:17.797573 140344290568000 spec.py:326] Evaluating on the test split.
I0510 08:19:19.153203 140344290568000 submission_runner.py:421] Time since start: 727.31s, 	Step: 2013, 	{'train/ssim': 0.7374000549316406, 'train/loss': 0.2736536094120571, 'validation/ssim': 0.7152411482880205, 'validation/loss': 0.2933357165781514, 'validation/num_examples': 3554, 'test/ssim': 0.7324845975286233, 'test/loss': 0.29491642086707626, 'test/num_examples': 3581, 'score': 535.9370617866516, 'total_duration': 727.3054983615875, 'accumulated_submission_time': 535.9370617866516, 'accumulated_eval_time': 191.2209677696228, 'accumulated_logging_time': 0.12015986442565918}
I0510 08:19:19.162536 140139640628992 logging_writer.py:48] [2013] accumulated_eval_time=191.220968, accumulated_logging_time=0.120160, accumulated_submission_time=535.937062, global_step=2013, preemption_count=0, score=535.937062, test/loss=0.294916, test/num_examples=3581, test/ssim=0.732485, total_duration=727.305498, train/loss=0.273654, train/ssim=0.737400, validation/loss=0.293336, validation/num_examples=3554, validation/ssim=0.715241
I0510 08:19:38.323015 140139632236288 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.17254666984081268, loss=0.27005332708358765
I0510 08:20:02.677655 140139640628992 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.07345474511384964, loss=0.24800899624824524
I0510 08:20:26.813173 140139632236288 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.15728305280208588, loss=0.2603592872619629
I0510 08:20:39.320627 140344290568000 spec.py:298] Evaluating on the training split.
I0510 08:20:40.727824 140344290568000 spec.py:310] Evaluating on the validation split.
I0510 08:20:42.081710 140344290568000 spec.py:326] Evaluating on the test split.
I0510 08:20:43.437464 140344290568000 submission_runner.py:421] Time since start: 811.59s, 	Step: 2352, 	{'train/ssim': 0.7387945992606026, 'train/loss': 0.27111893040793283, 'validation/ssim': 0.7165666106851435, 'validation/loss': 0.2911949522654931, 'validation/num_examples': 3554, 'test/ssim': 0.7338742424209369, 'test/loss': 0.2927177235321837, 'test/num_examples': 3581, 'score': 616.0827157497406, 'total_duration': 811.5897462368011, 'accumulated_submission_time': 616.0827157497406, 'accumulated_eval_time': 195.33774590492249, 'accumulated_logging_time': 0.13742280006408691}
I0510 08:20:43.446843 140139640628992 logging_writer.py:48] [2352] accumulated_eval_time=195.337746, accumulated_logging_time=0.137423, accumulated_submission_time=616.082716, global_step=2352, preemption_count=0, score=616.082716, test/loss=0.292718, test/num_examples=3581, test/ssim=0.733874, total_duration=811.589746, train/loss=0.271119, train/ssim=0.738795, validation/loss=0.291195, validation/num_examples=3554, validation/ssim=0.716567
I0510 08:20:53.208089 140139632236288 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.07701901346445084, loss=0.2956544756889343
I0510 08:21:17.528347 140139640628992 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.1268487274646759, loss=0.2365032434463501
I0510 08:21:41.767954 140139632236288 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.09165339916944504, loss=0.29169195890426636
I0510 08:22:03.482562 140344290568000 spec.py:298] Evaluating on the training split.
I0510 08:22:04.891306 140344290568000 spec.py:310] Evaluating on the validation split.
I0510 08:22:06.246553 140344290568000 spec.py:326] Evaluating on the test split.
I0510 08:22:07.599251 140344290568000 submission_runner.py:421] Time since start: 895.75s, 	Step: 2691, 	{'train/ssim': 0.7428957394191197, 'train/loss': 0.2703591414860317, 'validation/ssim': 0.7205604463060987, 'validation/loss': 0.2903789977512134, 'validation/num_examples': 3554, 'test/ssim': 0.7376489796408127, 'test/loss': 0.2918989900036652, 'test/num_examples': 3581, 'score': 696.1043603420258, 'total_duration': 895.7515385150909, 'accumulated_submission_time': 696.1043603420258, 'accumulated_eval_time': 199.4543845653534, 'accumulated_logging_time': 0.15631341934204102}
I0510 08:22:07.608601 140139640628992 logging_writer.py:48] [2691] accumulated_eval_time=199.454385, accumulated_logging_time=0.156313, accumulated_submission_time=696.104360, global_step=2691, preemption_count=0, score=696.104360, test/loss=0.291899, test/num_examples=3581, test/ssim=0.737649, total_duration=895.751539, train/loss=0.270359, train/ssim=0.742896, validation/loss=0.290379, validation/num_examples=3554, validation/ssim=0.720560
I0510 08:22:08.372680 140139632236288 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.05468045920133591, loss=0.3295871615409851
I0510 08:22:31.871104 140139640628992 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.06324762105941772, loss=0.2901383340358734
I0510 08:22:55.798239 140139632236288 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.1308189034461975, loss=0.25076931715011597
I0510 08:23:20.132819 140139640628992 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.09321507066488266, loss=0.3079046308994293
I0510 08:23:27.678622 140344290568000 spec.py:298] Evaluating on the training split.
I0510 08:23:29.086127 140344290568000 spec.py:310] Evaluating on the validation split.
I0510 08:23:30.438844 140344290568000 spec.py:326] Evaluating on the test split.
I0510 08:23:31.793305 140344290568000 submission_runner.py:421] Time since start: 979.95s, 	Step: 3033, 	{'train/ssim': 0.7404073306492397, 'train/loss': 0.270068747656686, 'validation/ssim': 0.7175667354345456, 'validation/loss': 0.2901580415552898, 'validation/num_examples': 3554, 'test/ssim': 0.7350267007077282, 'test/loss': 0.2916850516397305, 'test/num_examples': 3581, 'score': 776.1616406440735, 'total_duration': 979.9455945491791, 'accumulated_submission_time': 776.1616406440735, 'accumulated_eval_time': 203.5690245628357, 'accumulated_logging_time': 0.1737990379333496}
I0510 08:23:31.802956 140139632236288 logging_writer.py:48] [3033] accumulated_eval_time=203.569025, accumulated_logging_time=0.173799, accumulated_submission_time=776.161641, global_step=3033, preemption_count=0, score=776.161641, test/loss=0.291685, test/num_examples=3581, test/ssim=0.735027, total_duration=979.945595, train/loss=0.270069, train/ssim=0.740407, validation/loss=0.290158, validation/num_examples=3554, validation/ssim=0.717567
I0510 08:23:45.926137 140139640628992 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.15481634438037872, loss=0.260384202003479
I0510 08:24:10.216041 140139632236288 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.09460777044296265, loss=0.330414354801178
I0510 08:24:34.827372 140139640628992 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.10226669907569885, loss=0.22060132026672363
I0510 08:24:51.984839 140344290568000 spec.py:298] Evaluating on the training split.
I0510 08:24:53.394507 140344290568000 spec.py:310] Evaluating on the validation split.
I0510 08:24:54.751415 140344290568000 spec.py:326] Evaluating on the test split.
I0510 08:24:56.109663 140344290568000 submission_runner.py:421] Time since start: 1064.26s, 	Step: 3372, 	{'train/ssim': 0.7434169905526298, 'train/loss': 0.26891376291002544, 'validation/ssim': 0.7200901630425225, 'validation/loss': 0.2896968259795301, 'validation/num_examples': 3554, 'test/ssim': 0.7374588349317579, 'test/loss': 0.29110517504494204, 'test/num_examples': 3581, 'score': 856.3303730487823, 'total_duration': 1064.261960029602, 'accumulated_submission_time': 856.3303730487823, 'accumulated_eval_time': 207.69381093978882, 'accumulated_logging_time': 0.19204211235046387}
I0510 08:24:56.119687 140139632236288 logging_writer.py:48] [3372] accumulated_eval_time=207.693811, accumulated_logging_time=0.192042, accumulated_submission_time=856.330373, global_step=3372, preemption_count=0, score=856.330373, test/loss=0.291105, test/num_examples=3581, test/ssim=0.737459, total_duration=1064.261960, train/loss=0.268914, train/ssim=0.743417, validation/loss=0.289697, validation/num_examples=3554, validation/ssim=0.720090
I0510 08:25:00.939737 140139640628992 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.09734384715557098, loss=0.30588963627815247
I0510 08:25:25.072560 140139632236288 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.11951163411140442, loss=0.24805596470832825
I0510 08:25:49.466065 140139640628992 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.034394972026348114, loss=0.33039507269859314
I0510 08:26:13.950725 140139632236288 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.10220173001289368, loss=0.31766363978385925
I0510 08:26:16.259361 140344290568000 spec.py:298] Evaluating on the training split.
I0510 08:26:17.665221 140344290568000 spec.py:310] Evaluating on the validation split.
I0510 08:26:19.018278 140344290568000 spec.py:326] Evaluating on the test split.
I0510 08:26:20.371904 140344290568000 submission_runner.py:421] Time since start: 1148.52s, 	Step: 3711, 	{'train/ssim': 0.7443983895438058, 'train/loss': 0.26862951687404085, 'validation/ssim': 0.7216906099421426, 'validation/loss': 0.2891156696240152, 'validation/num_examples': 3554, 'test/ssim': 0.7388884995243996, 'test/loss': 0.29055928451593477, 'test/num_examples': 3581, 'score': 936.4570770263672, 'total_duration': 1148.524199962616, 'accumulated_submission_time': 936.4570770263672, 'accumulated_eval_time': 211.8063097000122, 'accumulated_logging_time': 0.21039628982543945}
I0510 08:26:20.381235 140139640628992 logging_writer.py:48] [3711] accumulated_eval_time=211.806310, accumulated_logging_time=0.210396, accumulated_submission_time=936.457077, global_step=3711, preemption_count=0, score=936.457077, test/loss=0.290559, test/num_examples=3581, test/ssim=0.738888, total_duration=1148.524200, train/loss=0.268630, train/ssim=0.744398, validation/loss=0.289116, validation/num_examples=3554, validation/ssim=0.721691
I0510 08:26:39.982061 140139632236288 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.08807240426540375, loss=0.2850974202156067
I0510 08:27:04.336722 140139640628992 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.14855031669139862, loss=0.32030656933784485
I0510 08:27:28.872331 140139632236288 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.06265617161989212, loss=0.2662024199962616
I0510 08:27:40.669066 140344290568000 spec.py:298] Evaluating on the training split.
I0510 08:27:42.076372 140344290568000 spec.py:310] Evaluating on the validation split.
I0510 08:27:43.430888 140344290568000 spec.py:326] Evaluating on the test split.
I0510 08:27:44.791043 140344290568000 submission_runner.py:421] Time since start: 1232.94s, 	Step: 4050, 	{'train/ssim': 0.7438938277108329, 'train/loss': 0.2688070024762835, 'validation/ssim': 0.7210495518913548, 'validation/loss': 0.2891796929955684, 'validation/num_examples': 3554, 'test/ssim': 0.7382453208993647, 'test/loss': 0.2905891458936924, 'test/num_examples': 3581, 'score': 1016.7323260307312, 'total_duration': 1232.943341255188, 'accumulated_submission_time': 1016.7323260307312, 'accumulated_eval_time': 215.92824363708496, 'accumulated_logging_time': 0.22772741317749023}
I0510 08:27:44.801056 140139640628992 logging_writer.py:48] [4050] accumulated_eval_time=215.928244, accumulated_logging_time=0.227727, accumulated_submission_time=1016.732326, global_step=4050, preemption_count=0, score=1016.732326, test/loss=0.290589, test/num_examples=3581, test/ssim=0.738245, total_duration=1232.943341, train/loss=0.268807, train/ssim=0.743894, validation/loss=0.289180, validation/num_examples=3554, validation/ssim=0.721050
I0510 08:27:54.823628 140139632236288 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.07122418284416199, loss=0.2221812605857849
I0510 08:28:19.658919 140139640628992 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.062416307628154755, loss=0.21116143465042114
I0510 08:28:44.009050 140139632236288 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.1304565668106079, loss=0.32352909445762634
I0510 08:29:04.875476 140344290568000 spec.py:298] Evaluating on the training split.
I0510 08:29:06.280763 140344290568000 spec.py:310] Evaluating on the validation split.
I0510 08:29:07.634316 140344290568000 spec.py:326] Evaluating on the test split.
I0510 08:29:08.990063 140344290568000 submission_runner.py:421] Time since start: 1317.14s, 	Step: 4386, 	{'train/ssim': 0.741934095110212, 'train/loss': 0.26860225200653076, 'validation/ssim': 0.7186933269511466, 'validation/loss': 0.2891097618880135, 'validation/num_examples': 3554, 'test/ssim': 0.7361447979571, 'test/loss': 0.2905195034339221, 'test/num_examples': 3581, 'score': 1096.7941064834595, 'total_duration': 1317.1423361301422, 'accumulated_submission_time': 1096.7941064834595, 'accumulated_eval_time': 220.0427634716034, 'accumulated_logging_time': 0.245849609375}
I0510 08:29:08.999779 140139640628992 logging_writer.py:48] [4386] accumulated_eval_time=220.042763, accumulated_logging_time=0.245850, accumulated_submission_time=1096.794106, global_step=4386, preemption_count=0, score=1096.794106, test/loss=0.290520, test/num_examples=3581, test/ssim=0.736145, total_duration=1317.142336, train/loss=0.268602, train/ssim=0.741934, validation/loss=0.289110, validation/num_examples=3554, validation/ssim=0.718693
I0510 08:29:10.369853 140139632236288 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.06477140635251999, loss=0.26469287276268005
I0510 08:29:34.613109 140139640628992 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.062797412276268, loss=0.24779903888702393
I0510 08:29:58.473278 140139632236288 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.07880415767431259, loss=0.3294338583946228
I0510 08:30:22.833856 140139640628992 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.1050400510430336, loss=0.21028269827365875
I0510 08:30:29.268541 140344290568000 spec.py:298] Evaluating on the training split.
I0510 08:30:30.679561 140344290568000 spec.py:310] Evaluating on the validation split.
I0510 08:30:32.034361 140344290568000 spec.py:326] Evaluating on the test split.
I0510 08:30:33.385676 140344290568000 submission_runner.py:421] Time since start: 1401.54s, 	Step: 4728, 	{'train/ssim': 0.743628706250872, 'train/loss': 0.2696126529148647, 'validation/ssim': 0.7207703770179728, 'validation/loss': 0.29006386125228617, 'validation/num_examples': 3554, 'test/ssim': 0.7379478661250349, 'test/loss': 0.29143058225050616, 'test/num_examples': 3581, 'score': 1177.0500705242157, 'total_duration': 1401.5379729270935, 'accumulated_submission_time': 1177.0500705242157, 'accumulated_eval_time': 224.15986013412476, 'accumulated_logging_time': 0.26378870010375977}
I0510 08:30:33.395199 140139632236288 logging_writer.py:48] [4728] accumulated_eval_time=224.159860, accumulated_logging_time=0.263789, accumulated_submission_time=1177.050071, global_step=4728, preemption_count=0, score=1177.050071, test/loss=0.291431, test/num_examples=3581, test/ssim=0.737948, total_duration=1401.537973, train/loss=0.269613, train/ssim=0.743629, validation/loss=0.290064, validation/num_examples=3554, validation/ssim=0.720770
I0510 08:30:48.766948 140139640628992 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.07871703803539276, loss=0.2741810083389282
I0510 08:31:12.881191 140139632236288 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.040269773453474045, loss=0.2886139750480652
I0510 08:31:37.412425 140139640628992 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.11808311194181442, loss=0.2686643898487091
I0510 08:31:53.521849 140344290568000 spec.py:298] Evaluating on the training split.
I0510 08:31:54.929809 140344290568000 spec.py:310] Evaluating on the validation split.
I0510 08:31:56.284928 140344290568000 spec.py:326] Evaluating on the test split.
I0510 08:31:57.643238 140344290568000 submission_runner.py:421] Time since start: 1485.80s, 	Step: 5067, 	{'train/ssim': 0.7443624905177525, 'train/loss': 0.26743355819157194, 'validation/ssim': 0.7212513766398776, 'validation/loss': 0.28803661477384634, 'validation/num_examples': 3554, 'test/ssim': 0.7386798789400656, 'test/loss': 0.2894362103702702, 'test/num_examples': 3581, 'score': 1257.1631999015808, 'total_duration': 1485.7955224514008, 'accumulated_submission_time': 1257.1631999015808, 'accumulated_eval_time': 228.28120160102844, 'accumulated_logging_time': 0.28227663040161133}
I0510 08:31:57.654154 140139632236288 logging_writer.py:48] [5067] accumulated_eval_time=228.281202, accumulated_logging_time=0.282277, accumulated_submission_time=1257.163200, global_step=5067, preemption_count=0, score=1257.163200, test/loss=0.289436, test/num_examples=3581, test/ssim=0.738680, total_duration=1485.795522, train/loss=0.267434, train/ssim=0.744362, validation/loss=0.288037, validation/num_examples=3554, validation/ssim=0.721251
I0510 08:32:03.710899 140139640628992 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.13522771000862122, loss=0.27810660004615784
I0510 08:32:28.298260 140139632236288 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.10454113036394119, loss=0.2422352135181427
I0510 08:32:53.869710 140139640628992 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.04160011559724808, loss=0.22779971361160278
I0510 08:33:17.926527 140139632236288 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.17144790291786194, loss=0.3104953169822693
I0510 08:33:17.932801 140344290568000 spec.py:298] Evaluating on the training split.
I0510 08:33:19.282275 140344290568000 spec.py:310] Evaluating on the validation split.
I0510 08:33:20.636321 140344290568000 spec.py:326] Evaluating on the test split.
I0510 08:33:21.992234 140344290568000 submission_runner.py:421] Time since start: 1570.14s, 	Step: 5401, 	{'train/ssim': 0.7415917941502163, 'train/loss': 0.26866800444466726, 'validation/ssim': 0.7185035237584412, 'validation/loss': 0.2890594430900921, 'validation/num_examples': 3554, 'test/ssim': 0.7359988317247277, 'test/loss': 0.29046390536643046, 'test/num_examples': 3581, 'score': 1337.4286479949951, 'total_duration': 1570.14453125, 'accumulated_submission_time': 1337.4286479949951, 'accumulated_eval_time': 232.3405945301056, 'accumulated_logging_time': 0.3017590045928955}
I0510 08:33:22.002785 140139640628992 logging_writer.py:48] [5401] accumulated_eval_time=232.340595, accumulated_logging_time=0.301759, accumulated_submission_time=1337.428648, global_step=5401, preemption_count=0, score=1337.428648, test/loss=0.290464, test/num_examples=3581, test/ssim=0.735999, total_duration=1570.144531, train/loss=0.268668, train/ssim=0.741592, validation/loss=0.289059, validation/num_examples=3554, validation/ssim=0.718504
I0510 08:33:26.277386 140344290568000 spec.py:298] Evaluating on the training split.
I0510 08:33:27.685365 140344290568000 spec.py:310] Evaluating on the validation split.
I0510 08:33:29.042037 140344290568000 spec.py:326] Evaluating on the test split.
I0510 08:33:30.399236 140344290568000 submission_runner.py:421] Time since start: 1578.55s, 	Step: 5428, 	{'train/ssim': 0.7455861909048898, 'train/loss': 0.2676119974681309, 'validation/ssim': 0.7225745034204417, 'validation/loss': 0.28833165810090744, 'validation/num_examples': 3554, 'test/ssim': 0.7398754248769548, 'test/loss': 0.28968116911520875, 'test/num_examples': 3581, 'score': 1341.6939396858215, 'total_duration': 1578.5515389442444, 'accumulated_submission_time': 1341.6939396858215, 'accumulated_eval_time': 236.4624195098877, 'accumulated_logging_time': 0.3209645748138428}
I0510 08:33:30.408802 140139632236288 logging_writer.py:48] [5428] accumulated_eval_time=236.462420, accumulated_logging_time=0.320965, accumulated_submission_time=1341.693940, global_step=5428, preemption_count=0, score=1341.693940, test/loss=0.289681, test/num_examples=3581, test/ssim=0.739875, total_duration=1578.551539, train/loss=0.267612, train/ssim=0.745586, validation/loss=0.288332, validation/num_examples=3554, validation/ssim=0.722575
I0510 08:33:30.424814 140139640628992 logging_writer.py:48] [5428] global_step=5428, preemption_count=0, score=1341.693940
I0510 08:33:30.454773 140344290568000 checkpoints.py:356] Saving checkpoint at step: 5428
I0510 08:33:30.599663 140344290568000 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_fancy_adafactor/timing_adafactor/fastmri_jax/trial_1/checkpoint_5428
I0510 08:33:30.600163 140344290568000 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_fancy_adafactor/timing_adafactor/fastmri_jax/trial_1/checkpoint_5428.
I0510 08:33:31.430831 140344290568000 submission_runner.py:584] Tuning trial 1/1
I0510 08:33:31.431088 140344290568000 submission_runner.py:585] Hyperparameters: Hyperparameters(learning_rate=0.0032594519610942875, one_minus_beta1=0.03999478140191344, warmup_factor=0.05, weight_decay=0.002578922011395245, label_smoothing=0.1, dropout_rate=0.0)
I0510 08:33:31.434348 140344290568000 submission_runner.py:586] Metrics: {'eval_results': [(1, {'train/ssim': 0.18846821784973145, 'train/loss': 0.9440065792628697, 'validation/ssim': 0.18410002923642374, 'validation/loss': 0.9490453648178109, 'validation/num_examples': 3554, 'test/ssim': 0.20769997782894967, 'test/loss': 0.9445568298834125, 'test/num_examples': 3581, 'score': 55.43068838119507, 'total_duration': 216.8333191871643, 'accumulated_submission_time': 55.43068838119507, 'accumulated_eval_time': 161.4024715423584, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (337, {'train/ssim': 0.7135613305228097, 'train/loss': 0.29684948921203613, 'validation/ssim': 0.6913500578133793, 'validation/loss': 0.3167252333967888, 'validation/num_examples': 3554, 'test/ssim': 0.7089708760210137, 'test/loss': 0.31888430120558153, 'test/num_examples': 3581, 'score': 135.4901602268219, 'total_duration': 301.33613657951355, 'accumulated_submission_time': 135.4901602268219, 'accumulated_eval_time': 165.81550550460815, 'accumulated_logging_time': 0.025691747665405273, 'global_step': 337, 'preemption_count': 0}), (671, {'train/ssim': 0.7274330002920968, 'train/loss': 0.282851048878261, 'validation/ssim': 0.7055020394054234, 'validation/loss': 0.3024638556468064, 'validation/num_examples': 3554, 'test/ssim': 0.7225696656398353, 'test/loss': 0.30436260411939753, 'test/num_examples': 3581, 'score': 215.5485134124756, 'total_duration': 385.5287482738495, 'accumulated_submission_time': 215.5485134124756, 'accumulated_eval_time': 169.9256715774536, 'accumulated_logging_time': 0.04537248611450195, 'global_step': 671, 'preemption_count': 0}), (1001, {'train/ssim': 0.7319323675973075, 'train/loss': 0.27857249123709543, 'validation/ssim': 0.7097594562245005, 'validation/loss': 0.2981810905186058, 'validation/num_examples': 3554, 'test/ssim': 0.7266676284121055, 'test/loss': 0.3000763374079342, 'test/num_examples': 3581, 'score': 295.57986545562744, 'total_duration': 474.5264890193939, 'accumulated_submission_time': 295.57986545562744, 'accumulated_eval_time': 178.87070274353027, 'accumulated_logging_time': 0.06247138977050781, 'global_step': 1001, 'preemption_count': 0}), (1338, {'train/ssim': 0.7289798600333077, 'train/loss': 0.27987188952309744, 'validation/ssim': 0.7077793342448649, 'validation/loss': 0.29949016925251476, 'validation/num_examples': 3554, 'test/ssim': 0.7244033451288048, 'test/loss': 0.3014644824136938, 'test/num_examples': 3581, 'score': 375.5970199108124, 'total_duration': 558.6855351924896, 'accumulated_submission_time': 375.5970199108124, 'accumulated_eval_time': 182.9907603263855, 'accumulated_logging_time': 0.07972908020019531, 'global_step': 1338, 'preemption_count': 0}), (1676, {'train/ssim': 0.7347164835248675, 'train/loss': 0.2745510850633894, 'validation/ssim': 0.7122093806054798, 'validation/loss': 0.2942154196855656, 'validation/num_examples': 3554, 'test/ssim': 0.7294075802630201, 'test/loss': 0.2958835068111212, 'test/num_examples': 3581, 'score': 455.72976088523865, 'total_duration': 642.9560129642487, 'accumulated_submission_time': 455.72976088523865, 'accumulated_eval_time': 187.10544419288635, 'accumulated_logging_time': 0.09813451766967773, 'global_step': 1676, 'preemption_count': 0}), (2013, {'train/ssim': 0.7374000549316406, 'train/loss': 0.2736536094120571, 'validation/ssim': 0.7152411482880205, 'validation/loss': 0.2933357165781514, 'validation/num_examples': 3554, 'test/ssim': 0.7324845975286233, 'test/loss': 0.29491642086707626, 'test/num_examples': 3581, 'score': 535.9370617866516, 'total_duration': 727.3054983615875, 'accumulated_submission_time': 535.9370617866516, 'accumulated_eval_time': 191.2209677696228, 'accumulated_logging_time': 0.12015986442565918, 'global_step': 2013, 'preemption_count': 0}), (2352, {'train/ssim': 0.7387945992606026, 'train/loss': 0.27111893040793283, 'validation/ssim': 0.7165666106851435, 'validation/loss': 0.2911949522654931, 'validation/num_examples': 3554, 'test/ssim': 0.7338742424209369, 'test/loss': 0.2927177235321837, 'test/num_examples': 3581, 'score': 616.0827157497406, 'total_duration': 811.5897462368011, 'accumulated_submission_time': 616.0827157497406, 'accumulated_eval_time': 195.33774590492249, 'accumulated_logging_time': 0.13742280006408691, 'global_step': 2352, 'preemption_count': 0}), (2691, {'train/ssim': 0.7428957394191197, 'train/loss': 0.2703591414860317, 'validation/ssim': 0.7205604463060987, 'validation/loss': 0.2903789977512134, 'validation/num_examples': 3554, 'test/ssim': 0.7376489796408127, 'test/loss': 0.2918989900036652, 'test/num_examples': 3581, 'score': 696.1043603420258, 'total_duration': 895.7515385150909, 'accumulated_submission_time': 696.1043603420258, 'accumulated_eval_time': 199.4543845653534, 'accumulated_logging_time': 0.15631341934204102, 'global_step': 2691, 'preemption_count': 0}), (3033, {'train/ssim': 0.7404073306492397, 'train/loss': 0.270068747656686, 'validation/ssim': 0.7175667354345456, 'validation/loss': 0.2901580415552898, 'validation/num_examples': 3554, 'test/ssim': 0.7350267007077282, 'test/loss': 0.2916850516397305, 'test/num_examples': 3581, 'score': 776.1616406440735, 'total_duration': 979.9455945491791, 'accumulated_submission_time': 776.1616406440735, 'accumulated_eval_time': 203.5690245628357, 'accumulated_logging_time': 0.1737990379333496, 'global_step': 3033, 'preemption_count': 0}), (3372, {'train/ssim': 0.7434169905526298, 'train/loss': 0.26891376291002544, 'validation/ssim': 0.7200901630425225, 'validation/loss': 0.2896968259795301, 'validation/num_examples': 3554, 'test/ssim': 0.7374588349317579, 'test/loss': 0.29110517504494204, 'test/num_examples': 3581, 'score': 856.3303730487823, 'total_duration': 1064.261960029602, 'accumulated_submission_time': 856.3303730487823, 'accumulated_eval_time': 207.69381093978882, 'accumulated_logging_time': 0.19204211235046387, 'global_step': 3372, 'preemption_count': 0}), (3711, {'train/ssim': 0.7443983895438058, 'train/loss': 0.26862951687404085, 'validation/ssim': 0.7216906099421426, 'validation/loss': 0.2891156696240152, 'validation/num_examples': 3554, 'test/ssim': 0.7388884995243996, 'test/loss': 0.29055928451593477, 'test/num_examples': 3581, 'score': 936.4570770263672, 'total_duration': 1148.524199962616, 'accumulated_submission_time': 936.4570770263672, 'accumulated_eval_time': 211.8063097000122, 'accumulated_logging_time': 0.21039628982543945, 'global_step': 3711, 'preemption_count': 0}), (4050, {'train/ssim': 0.7438938277108329, 'train/loss': 0.2688070024762835, 'validation/ssim': 0.7210495518913548, 'validation/loss': 0.2891796929955684, 'validation/num_examples': 3554, 'test/ssim': 0.7382453208993647, 'test/loss': 0.2905891458936924, 'test/num_examples': 3581, 'score': 1016.7323260307312, 'total_duration': 1232.943341255188, 'accumulated_submission_time': 1016.7323260307312, 'accumulated_eval_time': 215.92824363708496, 'accumulated_logging_time': 0.22772741317749023, 'global_step': 4050, 'preemption_count': 0}), (4386, {'train/ssim': 0.741934095110212, 'train/loss': 0.26860225200653076, 'validation/ssim': 0.7186933269511466, 'validation/loss': 0.2891097618880135, 'validation/num_examples': 3554, 'test/ssim': 0.7361447979571, 'test/loss': 0.2905195034339221, 'test/num_examples': 3581, 'score': 1096.7941064834595, 'total_duration': 1317.1423361301422, 'accumulated_submission_time': 1096.7941064834595, 'accumulated_eval_time': 220.0427634716034, 'accumulated_logging_time': 0.245849609375, 'global_step': 4386, 'preemption_count': 0}), (4728, {'train/ssim': 0.743628706250872, 'train/loss': 0.2696126529148647, 'validation/ssim': 0.7207703770179728, 'validation/loss': 0.29006386125228617, 'validation/num_examples': 3554, 'test/ssim': 0.7379478661250349, 'test/loss': 0.29143058225050616, 'test/num_examples': 3581, 'score': 1177.0500705242157, 'total_duration': 1401.5379729270935, 'accumulated_submission_time': 1177.0500705242157, 'accumulated_eval_time': 224.15986013412476, 'accumulated_logging_time': 0.26378870010375977, 'global_step': 4728, 'preemption_count': 0}), (5067, {'train/ssim': 0.7443624905177525, 'train/loss': 0.26743355819157194, 'validation/ssim': 0.7212513766398776, 'validation/loss': 0.28803661477384634, 'validation/num_examples': 3554, 'test/ssim': 0.7386798789400656, 'test/loss': 0.2894362103702702, 'test/num_examples': 3581, 'score': 1257.1631999015808, 'total_duration': 1485.7955224514008, 'accumulated_submission_time': 1257.1631999015808, 'accumulated_eval_time': 228.28120160102844, 'accumulated_logging_time': 0.28227663040161133, 'global_step': 5067, 'preemption_count': 0}), (5401, {'train/ssim': 0.7415917941502163, 'train/loss': 0.26866800444466726, 'validation/ssim': 0.7185035237584412, 'validation/loss': 0.2890594430900921, 'validation/num_examples': 3554, 'test/ssim': 0.7359988317247277, 'test/loss': 0.29046390536643046, 'test/num_examples': 3581, 'score': 1337.4286479949951, 'total_duration': 1570.14453125, 'accumulated_submission_time': 1337.4286479949951, 'accumulated_eval_time': 232.3405945301056, 'accumulated_logging_time': 0.3017590045928955, 'global_step': 5401, 'preemption_count': 0}), (5428, {'train/ssim': 0.7455861909048898, 'train/loss': 0.2676119974681309, 'validation/ssim': 0.7225745034204417, 'validation/loss': 0.28833165810090744, 'validation/num_examples': 3554, 'test/ssim': 0.7398754248769548, 'test/loss': 0.28968116911520875, 'test/num_examples': 3581, 'score': 1341.6939396858215, 'total_duration': 1578.5515389442444, 'accumulated_submission_time': 1341.6939396858215, 'accumulated_eval_time': 236.4624195098877, 'accumulated_logging_time': 0.3209645748138428, 'global_step': 5428, 'preemption_count': 0})], 'global_step': 5428}
I0510 08:33:31.434481 140344290568000 submission_runner.py:587] Timing: 1341.6939396858215
I0510 08:33:31.434530 140344290568000 submission_runner.py:588] ====================
I0510 08:33:31.434643 140344290568000 submission_runner.py:651] Final fastmri score: 1341.6939396858215
