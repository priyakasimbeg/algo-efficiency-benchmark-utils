python3 submission_runner.py --framework=jax --workload=fastmri --submission_path=baselines/sam/jax/submission.py --tuning_search_space=baselines/sam/tuning_search_space.json --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_fancy/timing_sam --overwrite=True --save_checkpoints=False --max_global_steps=5428 2>&1 | tee -a /logs/fastmri_jax_04-28-2023-17-15-33.log
I0428 17:15:53.935100 140079318550336 logger_utils.py:61] Removing existing experiment directory /experiment_runs/timing_fancy/timing_sam/fastmri_jax because --overwrite was set.
I0428 17:15:53.936574 140079318550336 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_fancy/timing_sam/fastmri_jax.
I0428 17:15:54.084056 140079318550336 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0428 17:15:54.957427 140079318550336 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0428 17:15:54.958117 140079318550336 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0428 17:15:54.964037 140079318550336 submission_runner.py:538] Using RNG seed 3384034685
I0428 17:15:57.625705 140079318550336 submission_runner.py:547] --- Tuning run 1/1 ---
I0428 17:15:57.625934 140079318550336 submission_runner.py:552] Creating tuning directory at /experiment_runs/timing_fancy/timing_sam/fastmri_jax/trial_1.
I0428 17:15:57.626097 140079318550336 logger_utils.py:92] Saving hparams to /experiment_runs/timing_fancy/timing_sam/fastmri_jax/trial_1/hparams.json.
I0428 17:15:57.758086 140079318550336 submission_runner.py:241] Initializing dataset.
I0428 17:16:02.726108 140079318550336 submission_runner.py:248] Initializing model.
I0428 17:16:10.014776 140079318550336 submission_runner.py:258] Initializing optimizer.
I0428 17:16:10.488701 140079318550336 submission_runner.py:265] Initializing metrics bundle.
I0428 17:16:10.488901 140079318550336 submission_runner.py:282] Initializing checkpoint and logger.
I0428 17:16:10.491039 140079318550336 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_fancy/timing_sam/fastmri_jax/trial_1 with prefix checkpoint_
I0428 17:16:10.491327 140079318550336 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0428 17:16:10.491394 140079318550336 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0428 17:16:11.482711 140079318550336 submission_runner.py:303] Saving meta data to /experiment_runs/timing_fancy/timing_sam/fastmri_jax/trial_1/meta_data_0.json.
I0428 17:16:11.483651 140079318550336 submission_runner.py:306] Saving flags to /experiment_runs/timing_fancy/timing_sam/fastmri_jax/trial_1/flags_0.json.
I0428 17:16:11.488799 140079318550336 submission_runner.py:318] Starting training loop.
I0428 17:17:19.529402 139903006398208 logging_writer.py:48] [0] global_step=0, grad_norm=4.343635559082031, loss=0.7868982553482056
I0428 17:17:19.538564 140079318550336 spec.py:298] Evaluating on the training split.
I0428 17:18:47.523172 140079318550336 spec.py:310] Evaluating on the validation split.
I0428 17:19:51.507214 140079318550336 spec.py:326] Evaluating on the test split.
I0428 17:20:50.985615 140079318550336 submission_runner.py:415] Time since start: 279.50s, 	Step: 1, 	{'train/ssim': 0.2377901758466448, 'train/loss': 0.7721883228846959, 'validation/ssim': 0.23108511234040868, 'validation/loss': 0.7795606622819359, 'validation/num_examples': 3554, 'test/ssim': 0.2562092576270595, 'test/loss': 0.7780728993952457, 'test/num_examples': 3581, 'score': 68.04961562156677, 'total_duration': 279.4966995716095, 'accumulated_submission_time': 68.04961562156677, 'accumulated_eval_time': 211.44695162773132, 'accumulated_logging_time': 0}
I0428 17:20:51.003456 139873612699392 logging_writer.py:48] [1] accumulated_eval_time=211.446952, accumulated_logging_time=0, accumulated_submission_time=68.049616, global_step=1, preemption_count=0, score=68.049616, test/loss=0.778073, test/num_examples=3581, test/ssim=0.256209, total_duration=279.496700, train/loss=0.772188, train/ssim=0.237790, validation/loss=0.779561, validation/num_examples=3554, validation/ssim=0.231085
I0428 17:21:13.373074 139873528837888 logging_writer.py:48] [100] global_step=100, grad_norm=0.2367054969072342, loss=0.44281309843063354
I0428 17:21:37.724854 139873612699392 logging_writer.py:48] [200] global_step=200, grad_norm=0.14670728147029877, loss=0.34807538986206055
I0428 17:22:02.155750 139873528837888 logging_writer.py:48] [300] global_step=300, grad_norm=0.26125216484069824, loss=0.39660385251045227
I0428 17:22:11.204693 140079318550336 spec.py:298] Evaluating on the training split.
I0428 17:22:13.019363 140079318550336 spec.py:310] Evaluating on the validation split.
I0428 17:22:14.372303 140079318550336 spec.py:326] Evaluating on the test split.
I0428 17:22:15.723942 140079318550336 submission_runner.py:415] Time since start: 364.24s, 	Step: 333, 	{'train/ssim': 0.7024924414498466, 'train/loss': 0.30259946414402555, 'validation/ssim': 0.6807848963096159, 'validation/loss': 0.32462470076630207, 'validation/num_examples': 3554, 'test/ssim': 0.6989765183215233, 'test/loss': 0.32636536036547054, 'test/num_examples': 3581, 'score': 148.23660111427307, 'total_duration': 364.2350523471832, 'accumulated_submission_time': 148.23660111427307, 'accumulated_eval_time': 215.9661476612091, 'accumulated_logging_time': 0.02747058868408203}
I0428 17:22:15.738207 139873612699392 logging_writer.py:48] [333] accumulated_eval_time=215.966148, accumulated_logging_time=0.027471, accumulated_submission_time=148.236601, global_step=333, preemption_count=0, score=148.236601, test/loss=0.326365, test/num_examples=3581, test/ssim=0.698977, total_duration=364.235052, train/loss=0.302599, train/ssim=0.702492, validation/loss=0.324625, validation/num_examples=3554, validation/ssim=0.680785
I0428 17:22:36.377635 139873528837888 logging_writer.py:48] [400] global_step=400, grad_norm=0.27467602491378784, loss=0.38560640811920166
I0428 17:23:12.143983 139873612699392 logging_writer.py:48] [500] global_step=500, grad_norm=0.2416735142469406, loss=0.2585258185863495
I0428 17:23:36.069291 140079318550336 spec.py:298] Evaluating on the training split.
I0428 17:23:37.541908 140079318550336 spec.py:310] Evaluating on the validation split.
I0428 17:23:38.895400 140079318550336 spec.py:326] Evaluating on the test split.
I0428 17:23:40.251237 140079318550336 submission_runner.py:415] Time since start: 448.76s, 	Step: 569, 	{'train/ssim': 0.7163990565708706, 'train/loss': 0.2916197436196463, 'validation/ssim': 0.6956474548923748, 'validation/loss': 0.3131784966103334, 'validation/num_examples': 3554, 'test/ssim': 0.7133056163388369, 'test/loss': 0.3152419630624302, 'test/num_examples': 3581, 'score': 228.54848504066467, 'total_duration': 448.7623598575592, 'accumulated_submission_time': 228.54848504066467, 'accumulated_eval_time': 220.1480541229248, 'accumulated_logging_time': 0.05762028694152832}
I0428 17:23:40.263078 139873528837888 logging_writer.py:48] [569] accumulated_eval_time=220.148054, accumulated_logging_time=0.057620, accumulated_submission_time=228.548485, global_step=569, preemption_count=0, score=228.548485, test/loss=0.315242, test/num_examples=3581, test/ssim=0.713306, total_duration=448.762360, train/loss=0.291620, train/ssim=0.716399, validation/loss=0.313178, validation/num_examples=3554, validation/ssim=0.695647
I0428 17:23:47.702480 139873612699392 logging_writer.py:48] [600] global_step=600, grad_norm=0.16530729830265045, loss=0.2790735363960266
I0428 17:24:22.979212 139873528837888 logging_writer.py:48] [700] global_step=700, grad_norm=0.08787484467029572, loss=0.2958400249481201
I0428 17:24:58.165704 139873612699392 logging_writer.py:48] [800] global_step=800, grad_norm=0.38966867327690125, loss=0.2688892185688019
I0428 17:25:00.318848 140079318550336 spec.py:298] Evaluating on the training split.
I0428 17:25:01.793302 140079318550336 spec.py:310] Evaluating on the validation split.
I0428 17:25:03.150394 140079318550336 spec.py:326] Evaluating on the test split.
I0428 17:25:04.503215 140079318550336 submission_runner.py:415] Time since start: 533.01s, 	Step: 808, 	{'train/ssim': 0.7220664024353027, 'train/loss': 0.2863627161298479, 'validation/ssim': 0.700489325407991, 'validation/loss': 0.3080063767827624, 'validation/num_examples': 3554, 'test/ssim': 0.71779811745148, 'test/loss': 0.3102339782118298, 'test/num_examples': 3581, 'score': 308.5878036022186, 'total_duration': 533.0143365859985, 'accumulated_submission_time': 308.5878036022186, 'accumulated_eval_time': 224.33238911628723, 'accumulated_logging_time': 0.08208155632019043}
I0428 17:25:04.515358 139873528837888 logging_writer.py:48] [808] accumulated_eval_time=224.332389, accumulated_logging_time=0.082082, accumulated_submission_time=308.587804, global_step=808, preemption_count=0, score=308.587804, test/loss=0.310234, test/num_examples=3581, test/ssim=0.717798, total_duration=533.014337, train/loss=0.286363, train/ssim=0.722066, validation/loss=0.308006, validation/num_examples=3554, validation/ssim=0.700489
I0428 17:25:34.678261 139873612699392 logging_writer.py:48] [900] global_step=900, grad_norm=0.16390159726142883, loss=0.26496604084968567
I0428 17:26:06.146922 139873528837888 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.2210610955953598, loss=0.23304717242717743
I0428 17:26:24.621201 140079318550336 spec.py:298] Evaluating on the training split.
I0428 17:26:26.093202 140079318550336 spec.py:310] Evaluating on the validation split.
I0428 17:26:27.449891 140079318550336 spec.py:326] Evaluating on the test split.
I0428 17:26:28.805633 140079318550336 submission_runner.py:415] Time since start: 617.32s, 	Step: 1077, 	{'train/ssim': 0.7180415562220982, 'train/loss': 0.2908926010131836, 'validation/ssim': 0.697782483205543, 'validation/loss': 0.312111257232168, 'validation/num_examples': 3554, 'test/ssim': 0.7148898374232058, 'test/loss': 0.3144041741570092, 'test/num_examples': 3581, 'score': 388.67969846725464, 'total_duration': 617.3167171478271, 'accumulated_submission_time': 388.67969846725464, 'accumulated_eval_time': 228.5167589187622, 'accumulated_logging_time': 0.10426878929138184}
I0428 17:26:28.816428 139873612699392 logging_writer.py:48] [1077] accumulated_eval_time=228.516759, accumulated_logging_time=0.104269, accumulated_submission_time=388.679698, global_step=1077, preemption_count=0, score=388.679698, test/loss=0.314404, test/num_examples=3581, test/ssim=0.714890, total_duration=617.316717, train/loss=0.290893, train/ssim=0.718042, validation/loss=0.312111, validation/num_examples=3554, validation/ssim=0.697782
I0428 17:26:32.528603 139873528837888 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.25796541571617126, loss=0.21787162125110626
I0428 17:26:56.549751 139873612699392 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.13966460525989532, loss=0.23199200630187988
I0428 17:27:20.342621 139873528837888 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.22169385850429535, loss=0.24176964163780212
I0428 17:27:44.405066 139873612699392 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.11038471013307571, loss=0.25584256649017334
I0428 17:27:48.904152 140079318550336 spec.py:298] Evaluating on the training split.
I0428 17:27:50.379335 140079318550336 spec.py:310] Evaluating on the validation split.
I0428 17:27:51.736987 140079318550336 spec.py:326] Evaluating on the test split.
I0428 17:27:53.089706 140079318550336 submission_runner.py:415] Time since start: 701.60s, 	Step: 1420, 	{'train/ssim': 0.7289153507777623, 'train/loss': 0.2779803786958967, 'validation/ssim': 0.7080968407076533, 'validation/loss': 0.29877739403445064, 'validation/num_examples': 3554, 'test/ssim': 0.7253872707082519, 'test/loss': 0.300572186267366, 'test/num_examples': 3581, 'score': 468.75325870513916, 'total_duration': 701.6008129119873, 'accumulated_submission_time': 468.75325870513916, 'accumulated_eval_time': 232.70226740837097, 'accumulated_logging_time': 0.12393617630004883}
I0428 17:27:53.098936 139873528837888 logging_writer.py:48] [1420] accumulated_eval_time=232.702267, accumulated_logging_time=0.123936, accumulated_submission_time=468.753259, global_step=1420, preemption_count=0, score=468.753259, test/loss=0.300572, test/num_examples=3581, test/ssim=0.725387, total_duration=701.600813, train/loss=0.277980, train/ssim=0.728915, validation/loss=0.298777, validation/num_examples=3554, validation/ssim=0.708097
I0428 17:28:10.611863 139873612699392 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.2348463237285614, loss=0.2922349274158478
I0428 17:28:34.989158 139873528837888 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.215397447347641, loss=0.2716861963272095
I0428 17:28:59.278602 139873612699392 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.07609120011329651, loss=0.38107728958129883
I0428 17:29:13.164543 140079318550336 spec.py:298] Evaluating on the training split.
I0428 17:29:14.638463 140079318550336 spec.py:310] Evaluating on the validation split.
I0428 17:29:15.990994 140079318550336 spec.py:326] Evaluating on the test split.
I0428 17:29:17.344510 140079318550336 submission_runner.py:415] Time since start: 785.86s, 	Step: 1759, 	{'train/ssim': 0.7326836585998535, 'train/loss': 0.2754877976008824, 'validation/ssim': 0.7114327880996765, 'validation/loss': 0.2965795101580086, 'validation/num_examples': 3554, 'test/ssim': 0.7287506981290143, 'test/loss': 0.29808172690938284, 'test/num_examples': 3581, 'score': 548.8057496547699, 'total_duration': 785.8556315898895, 'accumulated_submission_time': 548.8057496547699, 'accumulated_eval_time': 236.88219285011292, 'accumulated_logging_time': 0.14136338233947754}
I0428 17:29:17.353894 139873528837888 logging_writer.py:48] [1759] accumulated_eval_time=236.882193, accumulated_logging_time=0.141363, accumulated_submission_time=548.805750, global_step=1759, preemption_count=0, score=548.805750, test/loss=0.298082, test/num_examples=3581, test/ssim=0.728751, total_duration=785.855632, train/loss=0.275488, train/ssim=0.732684, validation/loss=0.296580, validation/num_examples=3554, validation/ssim=0.711433
I0428 17:29:25.540344 139873612699392 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.06902424246072769, loss=0.23098181188106537
I0428 17:29:49.722020 139873528837888 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.14833717048168182, loss=0.3282738924026489
I0428 17:30:14.101788 139873612699392 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.09570444375276566, loss=0.34479063749313354
I0428 17:30:37.499364 140079318550336 spec.py:298] Evaluating on the training split.
I0428 17:30:38.971416 140079318550336 spec.py:310] Evaluating on the validation split.
I0428 17:30:40.326327 140079318550336 spec.py:326] Evaluating on the test split.
I0428 17:30:41.678769 140079318550336 submission_runner.py:415] Time since start: 870.19s, 	Step: 2096, 	{'train/ssim': 0.7357713154384068, 'train/loss': 0.27512785366603304, 'validation/ssim': 0.7141565291748734, 'validation/loss': 0.29670230176385765, 'validation/num_examples': 3554, 'test/ssim': 0.731293892134704, 'test/loss': 0.29834437749799286, 'test/num_examples': 3581, 'score': 628.9366776943207, 'total_duration': 870.1898782253265, 'accumulated_submission_time': 628.9366776943207, 'accumulated_eval_time': 241.06154918670654, 'accumulated_logging_time': 0.1599569320678711}
I0428 17:30:41.688304 139873528837888 logging_writer.py:48] [2096] accumulated_eval_time=241.061549, accumulated_logging_time=0.159957, accumulated_submission_time=628.936678, global_step=2096, preemption_count=0, score=628.936678, test/loss=0.298344, test/num_examples=3581, test/ssim=0.731294, total_duration=870.189878, train/loss=0.275128, train/ssim=0.735771, validation/loss=0.296702, validation/num_examples=3554, validation/ssim=0.714157
I0428 17:30:42.419366 139873612699392 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.198673814535141, loss=0.2853388488292694
I0428 17:31:05.048282 139873528837888 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.13088896870613098, loss=0.22142747044563293
I0428 17:31:29.442043 139873612699392 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.10376466065645218, loss=0.31015342473983765
I0428 17:31:53.454248 139873528837888 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.04758886992931366, loss=0.39889582991600037
I0428 17:32:01.748662 140079318550336 spec.py:298] Evaluating on the training split.
I0428 17:32:03.222252 140079318550336 spec.py:310] Evaluating on the validation split.
I0428 17:32:04.574008 140079318550336 spec.py:326] Evaluating on the test split.
I0428 17:32:05.927616 140079318550336 submission_runner.py:415] Time since start: 954.44s, 	Step: 2436, 	{'train/ssim': 0.7375599997384208, 'train/loss': 0.2719287702015468, 'validation/ssim': 0.7154338366541221, 'validation/loss': 0.29360311032683245, 'validation/num_examples': 3554, 'test/ssim': 0.7326635612651843, 'test/loss': 0.2952378738262706, 'test/num_examples': 3581, 'score': 708.9823253154755, 'total_duration': 954.4386851787567, 'accumulated_submission_time': 708.9823253154755, 'accumulated_eval_time': 245.24040818214417, 'accumulated_logging_time': 0.1789548397064209}
I0428 17:32:05.938906 139873612699392 logging_writer.py:48] [2436] accumulated_eval_time=245.240408, accumulated_logging_time=0.178955, accumulated_submission_time=708.982325, global_step=2436, preemption_count=0, score=708.982325, test/loss=0.295238, test/num_examples=3581, test/ssim=0.732664, total_duration=954.438685, train/loss=0.271929, train/ssim=0.737560, validation/loss=0.293603, validation/num_examples=3554, validation/ssim=0.715434
I0428 17:32:19.813780 139873528837888 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.051429182291030884, loss=0.2581537365913391
I0428 17:32:44.007885 139873612699392 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.1633055955171585, loss=0.25828108191490173
I0428 17:33:07.904671 139873528837888 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.1331195831298828, loss=0.254418283700943
I0428 17:33:25.999243 140079318550336 spec.py:298] Evaluating on the training split.
I0428 17:33:27.473132 140079318550336 spec.py:310] Evaluating on the validation split.
I0428 17:33:28.824341 140079318550336 spec.py:326] Evaluating on the test split.
I0428 17:33:30.177981 140079318550336 submission_runner.py:415] Time since start: 1038.69s, 	Step: 2776, 	{'train/ssim': 0.7369886125837054, 'train/loss': 0.27174573285239084, 'validation/ssim': 0.7157661124569148, 'validation/loss': 0.2928762870621131, 'validation/num_examples': 3554, 'test/ssim': 0.7330249657480452, 'test/loss': 0.2944525468619101, 'test/num_examples': 3581, 'score': 789.0276658535004, 'total_duration': 1038.6890728473663, 'accumulated_submission_time': 789.0276658535004, 'accumulated_eval_time': 249.4190731048584, 'accumulated_logging_time': 0.20000267028808594}
I0428 17:33:30.188490 139873612699392 logging_writer.py:48] [2776] accumulated_eval_time=249.419073, accumulated_logging_time=0.200003, accumulated_submission_time=789.027666, global_step=2776, preemption_count=0, score=789.027666, test/loss=0.294453, test/num_examples=3581, test/ssim=0.733025, total_duration=1038.689073, train/loss=0.271746, train/ssim=0.736989, validation/loss=0.292876, validation/num_examples=3554, validation/ssim=0.715766
I0428 17:33:34.197283 139873528837888 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.08546976745128632, loss=0.28747546672821045
I0428 17:33:58.407285 139873612699392 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.17573650181293488, loss=0.2522019147872925
I0428 17:34:22.548880 139873528837888 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.0963110700249672, loss=0.34853804111480713
I0428 17:34:47.262053 139873612699392 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.10983462631702423, loss=0.23346619307994843
I0428 17:34:50.318449 140079318550336 spec.py:298] Evaluating on the training split.
I0428 17:34:51.792509 140079318550336 spec.py:310] Evaluating on the validation split.
I0428 17:34:53.146771 140079318550336 spec.py:326] Evaluating on the test split.
I0428 17:34:54.501151 140079318550336 submission_runner.py:415] Time since start: 1123.01s, 	Step: 3113, 	{'train/ssim': 0.7383807046072823, 'train/loss': 0.2708390099661691, 'validation/ssim': 0.7166471207618177, 'validation/loss': 0.29192043598542133, 'validation/num_examples': 3554, 'test/ssim': 0.7340085504441846, 'test/loss': 0.2934589401965233, 'test/num_examples': 3581, 'score': 869.1440601348877, 'total_duration': 1123.012272119522, 'accumulated_submission_time': 869.1440601348877, 'accumulated_eval_time': 253.60174679756165, 'accumulated_logging_time': 0.21895623207092285}
I0428 17:34:54.510603 139873528837888 logging_writer.py:48] [3113] accumulated_eval_time=253.601747, accumulated_logging_time=0.218956, accumulated_submission_time=869.144060, global_step=3113, preemption_count=0, score=869.144060, test/loss=0.293459, test/num_examples=3581, test/ssim=0.734009, total_duration=1123.012272, train/loss=0.270839, train/ssim=0.738381, validation/loss=0.291920, validation/num_examples=3554, validation/ssim=0.716647
I0428 17:35:13.756736 139873612699392 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.08477777242660522, loss=0.24738812446594238
I0428 17:35:38.281373 139873528837888 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.08031857758760452, loss=0.2581039369106293
I0428 17:36:02.432480 139873612699392 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.07371366024017334, loss=0.32670819759368896
I0428 17:36:14.547664 140079318550336 spec.py:298] Evaluating on the training split.
I0428 17:36:16.020960 140079318550336 spec.py:310] Evaluating on the validation split.
I0428 17:36:17.373741 140079318550336 spec.py:326] Evaluating on the test split.
I0428 17:36:18.730747 140079318550336 submission_runner.py:415] Time since start: 1207.24s, 	Step: 3452, 	{'train/ssim': 0.740962096623012, 'train/loss': 0.2706309046064104, 'validation/ssim': 0.7189376736599606, 'validation/loss': 0.2923204790157217, 'validation/num_examples': 3554, 'test/ssim': 0.7360718489292446, 'test/loss': 0.2939969563211219, 'test/num_examples': 3581, 'score': 949.1675138473511, 'total_duration': 1207.241866827011, 'accumulated_submission_time': 949.1675138473511, 'accumulated_eval_time': 257.78479647636414, 'accumulated_logging_time': 0.23683810234069824}
I0428 17:36:18.740586 139873528837888 logging_writer.py:48] [3452] accumulated_eval_time=257.784796, accumulated_logging_time=0.236838, accumulated_submission_time=949.167514, global_step=3452, preemption_count=0, score=949.167514, test/loss=0.293997, test/num_examples=3581, test/ssim=0.736072, total_duration=1207.241867, train/loss=0.270631, train/ssim=0.740962, validation/loss=0.292320, validation/num_examples=3554, validation/ssim=0.718938
I0428 17:36:28.388604 139873612699392 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.09996803849935532, loss=0.24661868810653687
I0428 17:36:52.378161 139873528837888 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.07678084075450897, loss=0.2494416981935501
I0428 17:37:16.598374 139873612699392 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.09649460017681122, loss=0.22530610859394073
I0428 17:37:38.886852 140079318550336 spec.py:298] Evaluating on the training split.
I0428 17:37:40.363349 140079318550336 spec.py:310] Evaluating on the validation split.
I0428 17:37:41.718270 140079318550336 spec.py:326] Evaluating on the test split.
I0428 17:37:43.075795 140079318550336 submission_runner.py:415] Time since start: 1291.59s, 	Step: 3794, 	{'train/ssim': 0.7407369613647461, 'train/loss': 0.2699665682656424, 'validation/ssim': 0.7186091760604248, 'validation/loss': 0.29167959270144556, 'validation/num_examples': 3554, 'test/ssim': 0.7357661447788676, 'test/loss': 0.29328188540648564, 'test/num_examples': 3581, 'score': 1029.2982468605042, 'total_duration': 1291.5869150161743, 'accumulated_submission_time': 1029.2982468605042, 'accumulated_eval_time': 261.9736964702606, 'accumulated_logging_time': 0.2571237087249756}
I0428 17:37:43.086187 139873528837888 logging_writer.py:48] [3794] accumulated_eval_time=261.973696, accumulated_logging_time=0.257124, accumulated_submission_time=1029.298247, global_step=3794, preemption_count=0, score=1029.298247, test/loss=0.293282, test/num_examples=3581, test/ssim=0.735766, total_duration=1291.586915, train/loss=0.269967, train/ssim=0.740737, validation/loss=0.291680, validation/num_examples=3554, validation/ssim=0.718609
I0428 17:37:44.102490 139873612699392 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.08024629950523376, loss=0.31872299313545227
I0428 17:38:06.932716 139873528837888 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.13171960413455963, loss=0.3225930333137512
I0428 17:38:31.094401 139873612699392 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.2809154987335205, loss=0.2921740412712097
I0428 17:38:55.056732 139873528837888 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.056986454874277115, loss=0.36373844742774963
I0428 17:39:03.293420 140079318550336 spec.py:298] Evaluating on the training split.
I0428 17:39:04.766258 140079318550336 spec.py:310] Evaluating on the validation split.
I0428 17:39:06.120071 140079318550336 spec.py:326] Evaluating on the test split.
I0428 17:39:07.474967 140079318550336 submission_runner.py:415] Time since start: 1375.99s, 	Step: 4136, 	{'train/ssim': 0.7371579578944615, 'train/loss': 0.2719958509717669, 'validation/ssim': 0.715853079826428, 'validation/loss': 0.2931714677783835, 'validation/num_examples': 3554, 'test/ssim': 0.7331472746788606, 'test/loss': 0.2947376275721691, 'test/num_examples': 3581, 'score': 1109.4911046028137, 'total_duration': 1375.9860303401947, 'accumulated_submission_time': 1109.4911046028137, 'accumulated_eval_time': 266.15515518188477, 'accumulated_logging_time': 0.27674293518066406}
I0428 17:39:07.486543 139873612699392 logging_writer.py:48] [4136] accumulated_eval_time=266.155155, accumulated_logging_time=0.276743, accumulated_submission_time=1109.491105, global_step=4136, preemption_count=0, score=1109.491105, test/loss=0.294738, test/num_examples=3581, test/ssim=0.733147, total_duration=1375.986030, train/loss=0.271996, train/ssim=0.737158, validation/loss=0.293171, validation/num_examples=3554, validation/ssim=0.715853
I0428 17:39:21.760792 139873528837888 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.12820875644683838, loss=0.26881808042526245
I0428 17:39:45.968794 139873612699392 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.05891555920243263, loss=0.41220784187316895
I0428 17:40:10.302604 139873528837888 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.07751196622848511, loss=0.31594812870025635
I0428 17:40:27.614000 140079318550336 spec.py:298] Evaluating on the training split.
I0428 17:40:29.088889 140079318550336 spec.py:310] Evaluating on the validation split.
I0428 17:40:30.444212 140079318550336 spec.py:326] Evaluating on the test split.
I0428 17:40:31.801503 140079318550336 submission_runner.py:415] Time since start: 1460.31s, 	Step: 4473, 	{'train/ssim': 0.7364418847220284, 'train/loss': 0.2708725758961269, 'validation/ssim': 0.7158201751107907, 'validation/loss': 0.29213222145162143, 'validation/num_examples': 3554, 'test/ssim': 0.7328282079028204, 'test/loss': 0.2937293629245497, 'test/num_examples': 3581, 'score': 1189.6044523715973, 'total_duration': 1460.3126232624054, 'accumulated_submission_time': 1189.6044523715973, 'accumulated_eval_time': 270.3426218032837, 'accumulated_logging_time': 0.2972581386566162}
I0428 17:40:31.811667 139873612699392 logging_writer.py:48] [4473] accumulated_eval_time=270.342622, accumulated_logging_time=0.297258, accumulated_submission_time=1189.604452, global_step=4473, preemption_count=0, score=1189.604452, test/loss=0.293729, test/num_examples=3581, test/ssim=0.732828, total_duration=1460.312623, train/loss=0.270873, train/ssim=0.736442, validation/loss=0.292132, validation/num_examples=3554, validation/ssim=0.715820
I0428 17:40:36.480748 139873528837888 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.1530383676290512, loss=0.23203253746032715
I0428 17:41:00.573370 139873612699392 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.09085744619369507, loss=0.29447752237319946
I0428 17:41:24.675321 139873528837888 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.04942416399717331, loss=0.3352806270122528
I0428 17:41:48.780434 139873612699392 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.09323935210704803, loss=0.22933991253376007
I0428 17:41:51.942316 140079318550336 spec.py:298] Evaluating on the training split.
I0428 17:41:53.417529 140079318550336 spec.py:310] Evaluating on the validation split.
I0428 17:41:54.773598 140079318550336 spec.py:326] Evaluating on the test split.
I0428 17:41:56.130274 140079318550336 submission_runner.py:415] Time since start: 1544.64s, 	Step: 4815, 	{'train/ssim': 0.7397608075823102, 'train/loss': 0.26959378378731863, 'validation/ssim': 0.7183396871263014, 'validation/loss': 0.29095445245454066, 'validation/num_examples': 3554, 'test/ssim': 0.7355247993969911, 'test/loss': 0.2926071409871544, 'test/num_examples': 3581, 'score': 1269.7215580940247, 'total_duration': 1544.6413946151733, 'accumulated_submission_time': 1269.7215580940247, 'accumulated_eval_time': 274.5305564403534, 'accumulated_logging_time': 0.31571507453918457}
I0428 17:41:56.140099 139873528837888 logging_writer.py:48] [4815] accumulated_eval_time=274.530556, accumulated_logging_time=0.315715, accumulated_submission_time=1269.721558, global_step=4815, preemption_count=0, score=1269.721558, test/loss=0.292607, test/num_examples=3581, test/ssim=0.735525, total_duration=1544.641395, train/loss=0.269594, train/ssim=0.739761, validation/loss=0.290954, validation/num_examples=3554, validation/ssim=0.718340
I0428 17:42:14.999662 139873612699392 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.13921774923801422, loss=0.29242193698883057
I0428 17:42:39.270971 139873528837888 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.1198350265622139, loss=0.2979258596897125
I0428 17:43:03.234375 139873612699392 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.16170601546764374, loss=0.2864531874656677
I0428 17:43:16.187208 140079318550336 spec.py:298] Evaluating on the training split.
I0428 17:43:17.662425 140079318550336 spec.py:310] Evaluating on the validation split.
I0428 17:43:19.017706 140079318550336 spec.py:326] Evaluating on the test split.
I0428 17:43:20.373751 140079318550336 submission_runner.py:415] Time since start: 1628.88s, 	Step: 5155, 	{'train/ssim': 0.7412094388689313, 'train/loss': 0.26883266653333393, 'validation/ssim': 0.7197248451348832, 'validation/loss': 0.29023511690173043, 'validation/num_examples': 3554, 'test/ssim': 0.7368772880087615, 'test/loss': 0.2918522208138439, 'test/num_examples': 3581, 'score': 1349.7553243637085, 'total_duration': 1628.8848705291748, 'accumulated_submission_time': 1349.7553243637085, 'accumulated_eval_time': 278.7170557975769, 'accumulated_logging_time': 0.33372974395751953}
I0428 17:43:20.383622 139873528837888 logging_writer.py:48] [5155] accumulated_eval_time=278.717056, accumulated_logging_time=0.333730, accumulated_submission_time=1349.755324, global_step=5155, preemption_count=0, score=1349.755324, test/loss=0.291852, test/num_examples=3581, test/ssim=0.736877, total_duration=1628.884871, train/loss=0.268833, train/ssim=0.741209, validation/loss=0.290235, validation/num_examples=3554, validation/ssim=0.719725
I0428 17:43:29.370882 139873612699392 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.08359038084745407, loss=0.2720610797405243
I0428 17:43:54.080815 139873528837888 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.2741640508174896, loss=0.18970869481563568
I0428 17:44:18.184343 139873612699392 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.18217046558856964, loss=0.34733879566192627
I0428 17:44:24.802781 140079318550336 spec.py:298] Evaluating on the training split.
I0428 17:44:26.273168 140079318550336 spec.py:310] Evaluating on the validation split.
I0428 17:44:27.626260 140079318550336 spec.py:326] Evaluating on the test split.
I0428 17:44:28.981437 140079318550336 submission_runner.py:415] Time since start: 1697.49s, 	Step: 5428, 	{'train/ssim': 0.7357198851449149, 'train/loss': 0.27096785817827496, 'validation/ssim': 0.7151247109331036, 'validation/loss': 0.29191521519546637, 'validation/num_examples': 3554, 'test/ssim': 0.732113171076515, 'test/loss': 0.2936628906795413, 'test/num_examples': 3581, 'score': 1414.1618666648865, 'total_duration': 1697.4925284385681, 'accumulated_submission_time': 1414.1618666648865, 'accumulated_eval_time': 282.8956518173218, 'accumulated_logging_time': 0.35193634033203125}
I0428 17:44:28.993700 139873528837888 logging_writer.py:48] [5428] accumulated_eval_time=282.895652, accumulated_logging_time=0.351936, accumulated_submission_time=1414.161867, global_step=5428, preemption_count=0, score=1414.161867, test/loss=0.293663, test/num_examples=3581, test/ssim=0.732113, total_duration=1697.492528, train/loss=0.270968, train/ssim=0.735720, validation/loss=0.291915, validation/num_examples=3554, validation/ssim=0.715125
I0428 17:44:29.010141 139873612699392 logging_writer.py:48] [5428] global_step=5428, preemption_count=0, score=1414.161867
I0428 17:44:29.040226 140079318550336 checkpoints.py:356] Saving checkpoint at step: 5428
I0428 17:44:29.297719 140079318550336 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_fancy/timing_sam/fastmri_jax/trial_1/checkpoint_5428
I0428 17:44:29.298273 140079318550336 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_fancy/timing_sam/fastmri_jax/trial_1/checkpoint_5428.
I0428 17:44:30.110842 140079318550336 submission_runner.py:578] Tuning trial 1/1
I0428 17:44:30.111165 140079318550336 submission_runner.py:579] Hyperparameters: Hyperparameters(learning_rate=0.0013159053452895648, one_minus_beta1=0.2018302260773442, beta2=0.999, warmup_factor=0.05, weight_decay=0.07935861128365443, label_smoothing=0.1, dropout_rate=0.0, rho=0.01)
I0428 17:44:30.118024 140079318550336 submission_runner.py:580] Metrics: {'eval_results': [(1, {'train/ssim': 0.2377901758466448, 'train/loss': 0.7721883228846959, 'validation/ssim': 0.23108511234040868, 'validation/loss': 0.7795606622819359, 'validation/num_examples': 3554, 'test/ssim': 0.2562092576270595, 'test/loss': 0.7780728993952457, 'test/num_examples': 3581, 'score': 68.04961562156677, 'total_duration': 279.4966995716095, 'accumulated_submission_time': 68.04961562156677, 'accumulated_eval_time': 211.44695162773132, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (333, {'train/ssim': 0.7024924414498466, 'train/loss': 0.30259946414402555, 'validation/ssim': 0.6807848963096159, 'validation/loss': 0.32462470076630207, 'validation/num_examples': 3554, 'test/ssim': 0.6989765183215233, 'test/loss': 0.32636536036547054, 'test/num_examples': 3581, 'score': 148.23660111427307, 'total_duration': 364.2350523471832, 'accumulated_submission_time': 148.23660111427307, 'accumulated_eval_time': 215.9661476612091, 'accumulated_logging_time': 0.02747058868408203, 'global_step': 333, 'preemption_count': 0}), (569, {'train/ssim': 0.7163990565708706, 'train/loss': 0.2916197436196463, 'validation/ssim': 0.6956474548923748, 'validation/loss': 0.3131784966103334, 'validation/num_examples': 3554, 'test/ssim': 0.7133056163388369, 'test/loss': 0.3152419630624302, 'test/num_examples': 3581, 'score': 228.54848504066467, 'total_duration': 448.7623598575592, 'accumulated_submission_time': 228.54848504066467, 'accumulated_eval_time': 220.1480541229248, 'accumulated_logging_time': 0.05762028694152832, 'global_step': 569, 'preemption_count': 0}), (808, {'train/ssim': 0.7220664024353027, 'train/loss': 0.2863627161298479, 'validation/ssim': 0.700489325407991, 'validation/loss': 0.3080063767827624, 'validation/num_examples': 3554, 'test/ssim': 0.71779811745148, 'test/loss': 0.3102339782118298, 'test/num_examples': 3581, 'score': 308.5878036022186, 'total_duration': 533.0143365859985, 'accumulated_submission_time': 308.5878036022186, 'accumulated_eval_time': 224.33238911628723, 'accumulated_logging_time': 0.08208155632019043, 'global_step': 808, 'preemption_count': 0}), (1077, {'train/ssim': 0.7180415562220982, 'train/loss': 0.2908926010131836, 'validation/ssim': 0.697782483205543, 'validation/loss': 0.312111257232168, 'validation/num_examples': 3554, 'test/ssim': 0.7148898374232058, 'test/loss': 0.3144041741570092, 'test/num_examples': 3581, 'score': 388.67969846725464, 'total_duration': 617.3167171478271, 'accumulated_submission_time': 388.67969846725464, 'accumulated_eval_time': 228.5167589187622, 'accumulated_logging_time': 0.10426878929138184, 'global_step': 1077, 'preemption_count': 0}), (1420, {'train/ssim': 0.7289153507777623, 'train/loss': 0.2779803786958967, 'validation/ssim': 0.7080968407076533, 'validation/loss': 0.29877739403445064, 'validation/num_examples': 3554, 'test/ssim': 0.7253872707082519, 'test/loss': 0.300572186267366, 'test/num_examples': 3581, 'score': 468.75325870513916, 'total_duration': 701.6008129119873, 'accumulated_submission_time': 468.75325870513916, 'accumulated_eval_time': 232.70226740837097, 'accumulated_logging_time': 0.12393617630004883, 'global_step': 1420, 'preemption_count': 0}), (1759, {'train/ssim': 0.7326836585998535, 'train/loss': 0.2754877976008824, 'validation/ssim': 0.7114327880996765, 'validation/loss': 0.2965795101580086, 'validation/num_examples': 3554, 'test/ssim': 0.7287506981290143, 'test/loss': 0.29808172690938284, 'test/num_examples': 3581, 'score': 548.8057496547699, 'total_duration': 785.8556315898895, 'accumulated_submission_time': 548.8057496547699, 'accumulated_eval_time': 236.88219285011292, 'accumulated_logging_time': 0.14136338233947754, 'global_step': 1759, 'preemption_count': 0}), (2096, {'train/ssim': 0.7357713154384068, 'train/loss': 0.27512785366603304, 'validation/ssim': 0.7141565291748734, 'validation/loss': 0.29670230176385765, 'validation/num_examples': 3554, 'test/ssim': 0.731293892134704, 'test/loss': 0.29834437749799286, 'test/num_examples': 3581, 'score': 628.9366776943207, 'total_duration': 870.1898782253265, 'accumulated_submission_time': 628.9366776943207, 'accumulated_eval_time': 241.06154918670654, 'accumulated_logging_time': 0.1599569320678711, 'global_step': 2096, 'preemption_count': 0}), (2436, {'train/ssim': 0.7375599997384208, 'train/loss': 0.2719287702015468, 'validation/ssim': 0.7154338366541221, 'validation/loss': 0.29360311032683245, 'validation/num_examples': 3554, 'test/ssim': 0.7326635612651843, 'test/loss': 0.2952378738262706, 'test/num_examples': 3581, 'score': 708.9823253154755, 'total_duration': 954.4386851787567, 'accumulated_submission_time': 708.9823253154755, 'accumulated_eval_time': 245.24040818214417, 'accumulated_logging_time': 0.1789548397064209, 'global_step': 2436, 'preemption_count': 0}), (2776, {'train/ssim': 0.7369886125837054, 'train/loss': 0.27174573285239084, 'validation/ssim': 0.7157661124569148, 'validation/loss': 0.2928762870621131, 'validation/num_examples': 3554, 'test/ssim': 0.7330249657480452, 'test/loss': 0.2944525468619101, 'test/num_examples': 3581, 'score': 789.0276658535004, 'total_duration': 1038.6890728473663, 'accumulated_submission_time': 789.0276658535004, 'accumulated_eval_time': 249.4190731048584, 'accumulated_logging_time': 0.20000267028808594, 'global_step': 2776, 'preemption_count': 0}), (3113, {'train/ssim': 0.7383807046072823, 'train/loss': 0.2708390099661691, 'validation/ssim': 0.7166471207618177, 'validation/loss': 0.29192043598542133, 'validation/num_examples': 3554, 'test/ssim': 0.7340085504441846, 'test/loss': 0.2934589401965233, 'test/num_examples': 3581, 'score': 869.1440601348877, 'total_duration': 1123.012272119522, 'accumulated_submission_time': 869.1440601348877, 'accumulated_eval_time': 253.60174679756165, 'accumulated_logging_time': 0.21895623207092285, 'global_step': 3113, 'preemption_count': 0}), (3452, {'train/ssim': 0.740962096623012, 'train/loss': 0.2706309046064104, 'validation/ssim': 0.7189376736599606, 'validation/loss': 0.2923204790157217, 'validation/num_examples': 3554, 'test/ssim': 0.7360718489292446, 'test/loss': 0.2939969563211219, 'test/num_examples': 3581, 'score': 949.1675138473511, 'total_duration': 1207.241866827011, 'accumulated_submission_time': 949.1675138473511, 'accumulated_eval_time': 257.78479647636414, 'accumulated_logging_time': 0.23683810234069824, 'global_step': 3452, 'preemption_count': 0}), (3794, {'train/ssim': 0.7407369613647461, 'train/loss': 0.2699665682656424, 'validation/ssim': 0.7186091760604248, 'validation/loss': 0.29167959270144556, 'validation/num_examples': 3554, 'test/ssim': 0.7357661447788676, 'test/loss': 0.29328188540648564, 'test/num_examples': 3581, 'score': 1029.2982468605042, 'total_duration': 1291.5869150161743, 'accumulated_submission_time': 1029.2982468605042, 'accumulated_eval_time': 261.9736964702606, 'accumulated_logging_time': 0.2571237087249756, 'global_step': 3794, 'preemption_count': 0}), (4136, {'train/ssim': 0.7371579578944615, 'train/loss': 0.2719958509717669, 'validation/ssim': 0.715853079826428, 'validation/loss': 0.2931714677783835, 'validation/num_examples': 3554, 'test/ssim': 0.7331472746788606, 'test/loss': 0.2947376275721691, 'test/num_examples': 3581, 'score': 1109.4911046028137, 'total_duration': 1375.9860303401947, 'accumulated_submission_time': 1109.4911046028137, 'accumulated_eval_time': 266.15515518188477, 'accumulated_logging_time': 0.27674293518066406, 'global_step': 4136, 'preemption_count': 0}), (4473, {'train/ssim': 0.7364418847220284, 'train/loss': 0.2708725758961269, 'validation/ssim': 0.7158201751107907, 'validation/loss': 0.29213222145162143, 'validation/num_examples': 3554, 'test/ssim': 0.7328282079028204, 'test/loss': 0.2937293629245497, 'test/num_examples': 3581, 'score': 1189.6044523715973, 'total_duration': 1460.3126232624054, 'accumulated_submission_time': 1189.6044523715973, 'accumulated_eval_time': 270.3426218032837, 'accumulated_logging_time': 0.2972581386566162, 'global_step': 4473, 'preemption_count': 0}), (4815, {'train/ssim': 0.7397608075823102, 'train/loss': 0.26959378378731863, 'validation/ssim': 0.7183396871263014, 'validation/loss': 0.29095445245454066, 'validation/num_examples': 3554, 'test/ssim': 0.7355247993969911, 'test/loss': 0.2926071409871544, 'test/num_examples': 3581, 'score': 1269.7215580940247, 'total_duration': 1544.6413946151733, 'accumulated_submission_time': 1269.7215580940247, 'accumulated_eval_time': 274.5305564403534, 'accumulated_logging_time': 0.31571507453918457, 'global_step': 4815, 'preemption_count': 0}), (5155, {'train/ssim': 0.7412094388689313, 'train/loss': 0.26883266653333393, 'validation/ssim': 0.7197248451348832, 'validation/loss': 0.29023511690173043, 'validation/num_examples': 3554, 'test/ssim': 0.7368772880087615, 'test/loss': 0.2918522208138439, 'test/num_examples': 3581, 'score': 1349.7553243637085, 'total_duration': 1628.8848705291748, 'accumulated_submission_time': 1349.7553243637085, 'accumulated_eval_time': 278.7170557975769, 'accumulated_logging_time': 0.33372974395751953, 'global_step': 5155, 'preemption_count': 0}), (5428, {'train/ssim': 0.7357198851449149, 'train/loss': 0.27096785817827496, 'validation/ssim': 0.7151247109331036, 'validation/loss': 0.29191521519546637, 'validation/num_examples': 3554, 'test/ssim': 0.732113171076515, 'test/loss': 0.2936628906795413, 'test/num_examples': 3581, 'score': 1414.1618666648865, 'total_duration': 1697.4925284385681, 'accumulated_submission_time': 1414.1618666648865, 'accumulated_eval_time': 282.8956518173218, 'accumulated_logging_time': 0.35193634033203125, 'global_step': 5428, 'preemption_count': 0})], 'global_step': 5428}
I0428 17:44:30.118178 140079318550336 submission_runner.py:581] Timing: 1414.1618666648865
I0428 17:44:30.118233 140079318550336 submission_runner.py:582] ====================
I0428 17:44:30.118380 140079318550336 submission_runner.py:645] Final fastmri score: 1414.1618666648865
