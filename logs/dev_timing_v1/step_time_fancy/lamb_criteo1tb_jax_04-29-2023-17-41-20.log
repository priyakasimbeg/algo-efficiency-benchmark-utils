python3 submission_runner.py --framework=jax --workload=criteo1tb --submission_path=baselines/lamb/jax/submission.py --tuning_search_space=baselines/lamb/tuning_search_space.json --data_dir=/data/criteo1tb --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_fancy/timing_lamb --overwrite=True --save_checkpoints=False --max_global_steps=1600 2>&1 | tee -a /logs/criteo1tb_jax_04-29-2023-17-41-20.log
I0429 17:41:39.799893 140452435760960 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_fancy/timing_lamb/criteo1tb_jax.
I0429 17:41:39.948937 140452435760960 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0429 17:41:40.794322 140452435760960 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Host Interpreter
I0429 17:41:40.795517 140452435760960 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0429 17:41:40.799522 140452435760960 submission_runner.py:538] Using RNG seed 1970464740
I0429 17:41:43.391149 140452435760960 submission_runner.py:547] --- Tuning run 1/1 ---
I0429 17:41:43.391355 140452435760960 submission_runner.py:552] Creating tuning directory at /experiment_runs/timing_fancy/timing_lamb/criteo1tb_jax/trial_1.
I0429 17:41:43.391544 140452435760960 logger_utils.py:92] Saving hparams to /experiment_runs/timing_fancy/timing_lamb/criteo1tb_jax/trial_1/hparams.json.
I0429 17:41:43.516420 140452435760960 submission_runner.py:241] Initializing dataset.
I0429 17:41:43.516635 140452435760960 submission_runner.py:248] Initializing model.
I0429 17:41:49.728881 140452435760960 submission_runner.py:258] Initializing optimizer.
I0429 17:41:52.550822 140452435760960 submission_runner.py:265] Initializing metrics bundle.
I0429 17:41:52.551069 140452435760960 submission_runner.py:282] Initializing checkpoint and logger.
I0429 17:41:52.555277 140452435760960 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_fancy/timing_lamb/criteo1tb_jax/trial_1 with prefix checkpoint_
I0429 17:41:52.555587 140452435760960 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0429 17:41:52.555663 140452435760960 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0429 17:41:53.305454 140452435760960 submission_runner.py:303] Saving meta data to /experiment_runs/timing_fancy/timing_lamb/criteo1tb_jax/trial_1/meta_data_0.json.
I0429 17:41:53.306493 140452435760960 submission_runner.py:306] Saving flags to /experiment_runs/timing_fancy/timing_lamb/criteo1tb_jax/trial_1/flags_0.json.
I0429 17:41:53.357682 140452435760960 submission_runner.py:318] Starting training loop.
I0429 17:42:18.851780 140276132730624 logging_writer.py:48] [0] global_step=0, grad_norm=5.793594837188721, loss=0.6184495687484741
I0429 17:42:18.859591 140452435760960 spec.py:298] Evaluating on the training split.
I0429 17:46:37.254907 140452435760960 spec.py:310] Evaluating on the validation split.
I0429 17:50:54.745510 140452435760960 spec.py:326] Evaluating on the test split.
I0429 17:55:12.406142 140452435760960 submission_runner.py:415] Time since start: 799.05s, 	Step: 1, 	{'train/loss': 0.618982670147512, 'validation/loss': 0.6222923595505618, 'validation/num_examples': 89000000, 'test/loss': 0.6206704374502245, 'test/num_examples': 89274637, 'score': 25.501710176467896, 'total_duration': 799.0483276844025, 'accumulated_submission_time': 25.501710176467896, 'accumulated_eval_time': 773.5464246273041, 'accumulated_logging_time': 0}
I0429 17:55:12.423528 140263045338880 logging_writer.py:48] [1] accumulated_eval_time=773.546425, accumulated_logging_time=0, accumulated_submission_time=25.501710, global_step=1, preemption_count=0, score=25.501710, test/loss=0.620670, test/num_examples=89274637, total_duration=799.048328, train/loss=0.618983, validation/loss=0.622292, validation/num_examples=89000000
I0429 17:56:09.907183 140262894466816 logging_writer.py:48] [100] global_step=100, grad_norm=0.10024461895227432, loss=0.15316356718540192
I0429 17:57:12.645075 140452435760960 spec.py:298] Evaluating on the training split.
I0429 18:01:26.314007 140452435760960 spec.py:310] Evaluating on the validation split.
I0429 18:05:28.234637 140452435760960 spec.py:326] Evaluating on the test split.
I0429 18:09:19.002333 140452435760960 submission_runner.py:415] Time since start: 1645.64s, 	Step: 183, 	{'train/loss': 0.138787567834805, 'validation/loss': 0.13832731460674158, 'validation/num_examples': 89000000, 'test/loss': 0.14201381742946767, 'test/num_examples': 89274637, 'score': 145.71231698989868, 'total_duration': 1645.6445519924164, 'accumulated_submission_time': 145.71231698989868, 'accumulated_eval_time': 1499.9036178588867, 'accumulated_logging_time': 0.025792598724365234}
I0429 18:09:19.010670 140263045338880 logging_writer.py:48] [183] accumulated_eval_time=1499.903618, accumulated_logging_time=0.025793, accumulated_submission_time=145.712317, global_step=183, preemption_count=0, score=145.712317, test/loss=0.142014, test/num_examples=89274637, total_duration=1645.644552, train/loss=0.138788, validation/loss=0.138327, validation/num_examples=89000000
I0429 18:09:21.419886 140262894466816 logging_writer.py:48] [200] global_step=200, grad_norm=0.16105790436267853, loss=0.14460358023643494
I0429 18:10:30.679823 140263045338880 logging_writer.py:48] [300] global_step=300, grad_norm=0.06336864084005356, loss=0.13159489631652832
I0429 18:11:19.370446 140452435760960 spec.py:298] Evaluating on the training split.
I0429 18:15:38.075925 140452435760960 spec.py:310] Evaluating on the validation split.
I0429 18:19:39.521277 140452435760960 spec.py:326] Evaluating on the test split.
I0429 18:23:32.131307 140452435760960 submission_runner.py:415] Time since start: 2498.77s, 	Step: 365, 	{'train/loss': 0.13677069051376242, 'validation/loss': 0.1355906629213483, 'validation/num_examples': 89000000, 'test/loss': 0.1394350446924808, 'test/num_examples': 89274637, 'score': 266.0628125667572, 'total_duration': 2498.773511171341, 'accumulated_submission_time': 266.0628125667572, 'accumulated_eval_time': 2232.6644039154053, 'accumulated_logging_time': 0.04093003273010254}
I0429 18:23:32.140684 140262894466816 logging_writer.py:48] [365] accumulated_eval_time=2232.664404, accumulated_logging_time=0.040930, accumulated_submission_time=266.062813, global_step=365, preemption_count=0, score=266.062813, test/loss=0.139435, test/num_examples=89274637, total_duration=2498.773511, train/loss=0.136771, validation/loss=0.135591, validation/num_examples=89000000
I0429 18:23:41.297092 140263045338880 logging_writer.py:48] [400] global_step=400, grad_norm=0.095659039914608, loss=0.14006373286247253
I0429 18:24:57.925531 140262894466816 logging_writer.py:48] [500] global_step=500, grad_norm=0.2898954749107361, loss=0.1261092573404312
I0429 18:25:32.589101 140452435760960 spec.py:298] Evaluating on the training split.
I0429 18:29:40.124747 140452435760960 spec.py:310] Evaluating on the validation split.
I0429 18:33:46.308221 140452435760960 spec.py:326] Evaluating on the test split.
I0429 18:37:54.281664 140452435760960 submission_runner.py:415] Time since start: 3360.92s, 	Step: 547, 	{'train/loss': 0.13501916342223716, 'validation/loss': 0.13397761797752808, 'validation/num_examples': 89000000, 'test/loss': 0.13741255537112965, 'test/num_examples': 89274637, 'score': 386.50207710266113, 'total_duration': 3360.9238879680634, 'accumulated_submission_time': 386.50207710266113, 'accumulated_eval_time': 2974.3569066524506, 'accumulated_logging_time': 0.05705428123474121}
I0429 18:37:54.290806 140263045338880 logging_writer.py:48] [547] accumulated_eval_time=2974.356907, accumulated_logging_time=0.057054, accumulated_submission_time=386.502077, global_step=547, preemption_count=0, score=386.502077, test/loss=0.137413, test/num_examples=89274637, total_duration=3360.923888, train/loss=0.135019, validation/loss=0.133978, validation/num_examples=89000000
I0429 18:38:17.380548 140262894466816 logging_writer.py:48] [600] global_step=600, grad_norm=0.7619435787200928, loss=0.13622228801250458
I0429 18:39:33.896280 140263045338880 logging_writer.py:48] [700] global_step=700, grad_norm=0.5326743125915527, loss=0.13345998525619507
I0429 18:39:54.874690 140452435760960 spec.py:298] Evaluating on the training split.
I0429 18:44:01.324549 140452435760960 spec.py:310] Evaluating on the validation split.
I0429 18:48:08.460837 140452435760960 spec.py:326] Evaluating on the test split.
I0429 18:52:03.290901 140452435760960 submission_runner.py:415] Time since start: 4209.93s, 	Step: 729, 	{'train/loss': 0.130375742122827, 'validation/loss': 0.13028560674157302, 'validation/num_examples': 89000000, 'test/loss': 0.1333466077268956, 'test/num_examples': 89274637, 'score': 507.0767831802368, 'total_duration': 4209.933111190796, 'accumulated_submission_time': 507.0767831802368, 'accumulated_eval_time': 3702.7730491161346, 'accumulated_logging_time': 0.07293939590454102}
I0429 18:52:03.298943 140262894466816 logging_writer.py:48] [729] accumulated_eval_time=3702.773049, accumulated_logging_time=0.072939, accumulated_submission_time=507.076783, global_step=729, preemption_count=0, score=507.076783, test/loss=0.133347, test/num_examples=89274637, total_duration=4209.933111, train/loss=0.130376, validation/loss=0.130286, validation/num_examples=89000000
I0429 18:52:40.175222 140263045338880 logging_writer.py:48] [800] global_step=800, grad_norm=0.8163466453552246, loss=0.13234391808509827
I0429 18:53:56.126897 140262894466816 logging_writer.py:48] [900] global_step=900, grad_norm=0.8497092127799988, loss=0.13047020137310028
I0429 18:54:03.588863 140452435760960 spec.py:298] Evaluating on the training split.
I0429 18:58:10.691121 140452435760960 spec.py:310] Evaluating on the validation split.
I0429 19:02:19.486406 140452435760960 spec.py:326] Evaluating on the test split.
I0429 19:06:27.599175 140452435760960 submission_runner.py:415] Time since start: 5074.24s, 	Step: 911, 	{'train/loss': 0.12946189897213023, 'validation/loss': 0.1287422584269663, 'validation/num_examples': 89000000, 'test/loss': 0.13166354291645005, 'test/num_examples': 89274637, 'score': 627.3577110767365, 'total_duration': 5074.241379022598, 'accumulated_submission_time': 627.3577110767365, 'accumulated_eval_time': 4446.783273458481, 'accumulated_logging_time': 0.08737587928771973}
I0429 19:06:27.607275 140263045338880 logging_writer.py:48] [911] accumulated_eval_time=4446.783273, accumulated_logging_time=0.087376, accumulated_submission_time=627.357711, global_step=911, preemption_count=0, score=627.357711, test/loss=0.131664, test/num_examples=89274637, total_duration=5074.241379, train/loss=0.129462, validation/loss=0.128742, validation/num_examples=89000000
I0429 19:07:18.508458 140262894466816 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.40042316913604736, loss=0.13470084965229034
I0429 19:08:28.164335 140452435760960 spec.py:298] Evaluating on the training split.
I0429 19:12:42.015576 140452435760960 spec.py:310] Evaluating on the validation split.
I0429 19:16:52.314869 140452435760960 spec.py:326] Evaluating on the test split.
I0429 19:20:47.123683 140452435760960 submission_runner.py:415] Time since start: 5933.77s, 	Step: 1092, 	{'train/loss': 0.12779697308740343, 'validation/loss': 0.12909450561797753, 'validation/num_examples': 89000000, 'test/loss': 0.13159994142569295, 'test/num_examples': 89274637, 'score': 747.9056451320648, 'total_duration': 5933.765902042389, 'accumulated_submission_time': 747.9056451320648, 'accumulated_eval_time': 5185.742575407028, 'accumulated_logging_time': 0.10222458839416504}
I0429 19:20:47.132997 140263045338880 logging_writer.py:48] [1092] accumulated_eval_time=5185.742575, accumulated_logging_time=0.102225, accumulated_submission_time=747.905645, global_step=1092, preemption_count=0, score=747.905645, test/loss=0.131600, test/num_examples=89274637, total_duration=5933.765902, train/loss=0.127797, validation/loss=0.129095, validation/num_examples=89000000
I0429 19:20:48.351203 140262894466816 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.2457195371389389, loss=0.12060478329658508
I0429 19:21:52.765540 140263045338880 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.08480832725763321, loss=0.12754343450069427
I0429 19:22:47.973086 140452435760960 spec.py:298] Evaluating on the training split.
I0429 19:27:03.642175 140452435760960 spec.py:310] Evaluating on the validation split.
I0429 19:31:12.723840 140452435760960 spec.py:326] Evaluating on the test split.
I0429 19:35:24.136524 140452435760960 submission_runner.py:415] Time since start: 6810.78s, 	Step: 1273, 	{'train/loss': 0.12589531702711093, 'validation/loss': 0.12762351685393258, 'validation/num_examples': 89000000, 'test/loss': 0.13029625648323834, 'test/num_examples': 89274637, 'score': 868.7368564605713, 'total_duration': 6810.778725862503, 'accumulated_submission_time': 868.7368564605713, 'accumulated_eval_time': 5941.9059290885925, 'accumulated_logging_time': 0.11808085441589355}
I0429 19:35:24.147624 140262894466816 logging_writer.py:48] [1273] accumulated_eval_time=5941.905929, accumulated_logging_time=0.118081, accumulated_submission_time=868.736856, global_step=1273, preemption_count=0, score=868.736856, test/loss=0.130296, test/num_examples=89274637, total_duration=6810.778726, train/loss=0.125895, validation/loss=0.127624, validation/num_examples=89000000
I0429 19:35:27.876093 140263045338880 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.12039053440093994, loss=0.12648946046829224
I0429 19:36:43.773142 140262894466816 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.27325770258903503, loss=0.1347217857837677
I0429 19:37:24.937466 140452435760960 spec.py:298] Evaluating on the training split.
I0429 19:41:35.478824 140452435760960 spec.py:310] Evaluating on the validation split.
I0429 19:45:46.066674 140452435760960 spec.py:326] Evaluating on the test split.
I0429 19:49:58.078505 140452435760960 submission_runner.py:415] Time since start: 7684.72s, 	Step: 1455, 	{'train/loss': 0.1269639262914482, 'validation/loss': 0.12732985393258428, 'validation/num_examples': 89000000, 'test/loss': 0.12992373186574815, 'test/num_examples': 89274637, 'score': 989.5173292160034, 'total_duration': 7684.720726490021, 'accumulated_submission_time': 989.5173292160034, 'accumulated_eval_time': 6695.046911001205, 'accumulated_logging_time': 0.1361098289489746}
I0429 19:49:58.087704 140263045338880 logging_writer.py:48] [1455] accumulated_eval_time=6695.046911, accumulated_logging_time=0.136110, accumulated_submission_time=989.517329, global_step=1455, preemption_count=0, score=989.517329, test/loss=0.129924, test/num_examples=89274637, total_duration=7684.720726, train/loss=0.126964, validation/loss=0.127330, validation/num_examples=89000000
I0429 19:50:14.977003 140262894466816 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.38066941499710083, loss=0.12368986010551453
I0429 19:51:29.962898 140452435760960 spec.py:298] Evaluating on the training split.
I0429 19:55:45.246677 140452435760960 spec.py:310] Evaluating on the validation split.
I0429 19:59:54.126202 140452435760960 spec.py:326] Evaluating on the test split.
I0429 20:04:05.312151 140452435760960 submission_runner.py:415] Time since start: 8531.95s, 	Step: 1600, 	{'train/loss': 0.12610232680926348, 'validation/loss': 0.12725093258426967, 'validation/num_examples': 89000000, 'test/loss': 0.12980985853798543, 'test/num_examples': 89274637, 'score': 1081.3836839199066, 'total_duration': 8531.954353094101, 'accumulated_submission_time': 1081.3836839199066, 'accumulated_eval_time': 7450.3960881233215, 'accumulated_logging_time': 0.1522371768951416}
I0429 20:04:05.320251 140263045338880 logging_writer.py:48] [1600] accumulated_eval_time=7450.396088, accumulated_logging_time=0.152237, accumulated_submission_time=1081.383684, global_step=1600, preemption_count=0, score=1081.383684, test/loss=0.129810, test/num_examples=89274637, total_duration=8531.954353, train/loss=0.126102, validation/loss=0.127251, validation/num_examples=89000000
I0429 20:04:05.332344 140262894466816 logging_writer.py:48] [1600] global_step=1600, preemption_count=0, score=1081.383684
I0429 20:04:08.709505 140452435760960 checkpoints.py:356] Saving checkpoint at step: 1600
I0429 20:04:28.934059 140452435760960 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_fancy/timing_lamb/criteo1tb_jax/trial_1/checkpoint_1600
I0429 20:04:28.949009 140452435760960 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_fancy/timing_lamb/criteo1tb_jax/trial_1/checkpoint_1600.
I0429 20:04:29.018694 140452435760960 submission_runner.py:578] Tuning trial 1/1
I0429 20:04:29.018951 140452435760960 submission_runner.py:579] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.19395352613343847, beta2=0.999, warmup_factor=0.05, weight_decay=0.002578922011395245, label_smoothing=0.1, dropout_rate=0.0)
I0429 20:04:29.020474 140452435760960 submission_runner.py:580] Metrics: {'eval_results': [(1, {'train/loss': 0.618982670147512, 'validation/loss': 0.6222923595505618, 'validation/num_examples': 89000000, 'test/loss': 0.6206704374502245, 'test/num_examples': 89274637, 'score': 25.501710176467896, 'total_duration': 799.0483276844025, 'accumulated_submission_time': 25.501710176467896, 'accumulated_eval_time': 773.5464246273041, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (183, {'train/loss': 0.138787567834805, 'validation/loss': 0.13832731460674158, 'validation/num_examples': 89000000, 'test/loss': 0.14201381742946767, 'test/num_examples': 89274637, 'score': 145.71231698989868, 'total_duration': 1645.6445519924164, 'accumulated_submission_time': 145.71231698989868, 'accumulated_eval_time': 1499.9036178588867, 'accumulated_logging_time': 0.025792598724365234, 'global_step': 183, 'preemption_count': 0}), (365, {'train/loss': 0.13677069051376242, 'validation/loss': 0.1355906629213483, 'validation/num_examples': 89000000, 'test/loss': 0.1394350446924808, 'test/num_examples': 89274637, 'score': 266.0628125667572, 'total_duration': 2498.773511171341, 'accumulated_submission_time': 266.0628125667572, 'accumulated_eval_time': 2232.6644039154053, 'accumulated_logging_time': 0.04093003273010254, 'global_step': 365, 'preemption_count': 0}), (547, {'train/loss': 0.13501916342223716, 'validation/loss': 0.13397761797752808, 'validation/num_examples': 89000000, 'test/loss': 0.13741255537112965, 'test/num_examples': 89274637, 'score': 386.50207710266113, 'total_duration': 3360.9238879680634, 'accumulated_submission_time': 386.50207710266113, 'accumulated_eval_time': 2974.3569066524506, 'accumulated_logging_time': 0.05705428123474121, 'global_step': 547, 'preemption_count': 0}), (729, {'train/loss': 0.130375742122827, 'validation/loss': 0.13028560674157302, 'validation/num_examples': 89000000, 'test/loss': 0.1333466077268956, 'test/num_examples': 89274637, 'score': 507.0767831802368, 'total_duration': 4209.933111190796, 'accumulated_submission_time': 507.0767831802368, 'accumulated_eval_time': 3702.7730491161346, 'accumulated_logging_time': 0.07293939590454102, 'global_step': 729, 'preemption_count': 0}), (911, {'train/loss': 0.12946189897213023, 'validation/loss': 0.1287422584269663, 'validation/num_examples': 89000000, 'test/loss': 0.13166354291645005, 'test/num_examples': 89274637, 'score': 627.3577110767365, 'total_duration': 5074.241379022598, 'accumulated_submission_time': 627.3577110767365, 'accumulated_eval_time': 4446.783273458481, 'accumulated_logging_time': 0.08737587928771973, 'global_step': 911, 'preemption_count': 0}), (1092, {'train/loss': 0.12779697308740343, 'validation/loss': 0.12909450561797753, 'validation/num_examples': 89000000, 'test/loss': 0.13159994142569295, 'test/num_examples': 89274637, 'score': 747.9056451320648, 'total_duration': 5933.765902042389, 'accumulated_submission_time': 747.9056451320648, 'accumulated_eval_time': 5185.742575407028, 'accumulated_logging_time': 0.10222458839416504, 'global_step': 1092, 'preemption_count': 0}), (1273, {'train/loss': 0.12589531702711093, 'validation/loss': 0.12762351685393258, 'validation/num_examples': 89000000, 'test/loss': 0.13029625648323834, 'test/num_examples': 89274637, 'score': 868.7368564605713, 'total_duration': 6810.778725862503, 'accumulated_submission_time': 868.7368564605713, 'accumulated_eval_time': 5941.9059290885925, 'accumulated_logging_time': 0.11808085441589355, 'global_step': 1273, 'preemption_count': 0}), (1455, {'train/loss': 0.1269639262914482, 'validation/loss': 0.12732985393258428, 'validation/num_examples': 89000000, 'test/loss': 0.12992373186574815, 'test/num_examples': 89274637, 'score': 989.5173292160034, 'total_duration': 7684.720726490021, 'accumulated_submission_time': 989.5173292160034, 'accumulated_eval_time': 6695.046911001205, 'accumulated_logging_time': 0.1361098289489746, 'global_step': 1455, 'preemption_count': 0}), (1600, {'train/loss': 0.12610232680926348, 'validation/loss': 0.12725093258426967, 'validation/num_examples': 89000000, 'test/loss': 0.12980985853798543, 'test/num_examples': 89274637, 'score': 1081.3836839199066, 'total_duration': 8531.954353094101, 'accumulated_submission_time': 1081.3836839199066, 'accumulated_eval_time': 7450.3960881233215, 'accumulated_logging_time': 0.1522371768951416, 'global_step': 1600, 'preemption_count': 0})], 'global_step': 1600}
I0429 20:04:29.020601 140452435760960 submission_runner.py:581] Timing: 1081.3836839199066
I0429 20:04:29.020649 140452435760960 submission_runner.py:582] ====================
I0429 20:04:29.020757 140452435760960 submission_runner.py:645] Final criteo1tb score: 1081.3836839199066
