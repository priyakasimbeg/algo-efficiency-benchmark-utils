python3 submission_runner.py --framework=jax --workload=fastmri --submission_path=baselines/adafactor/jax/submission.py --tuning_search_space=baselines/adafactor/tuning_search_space.json --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_fancy/timing_adafactor --overwrite=True --save_checkpoints=False --max_global_steps=5428 2>&1 | tee -a /logs/fastmri_jax_04-28-2023-12-46-33.log
I0428 12:46:53.567357 140582376589120 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_fancy/timing_adafactor/fastmri_jax.
I0428 12:46:53.718576 140582376589120 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0428 12:46:54.616510 140582376589120 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0428 12:46:54.617274 140582376589120 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0428 12:46:54.620986 140582376589120 submission_runner.py:538] Using RNG seed 852335236
I0428 12:46:57.314210 140582376589120 submission_runner.py:547] --- Tuning run 1/1 ---
I0428 12:46:57.314433 140582376589120 submission_runner.py:552] Creating tuning directory at /experiment_runs/timing_fancy/timing_adafactor/fastmri_jax/trial_1.
I0428 12:46:57.314707 140582376589120 logger_utils.py:92] Saving hparams to /experiment_runs/timing_fancy/timing_adafactor/fastmri_jax/trial_1/hparams.json.
I0428 12:46:57.439455 140582376589120 submission_runner.py:241] Initializing dataset.
I0428 12:47:01.404966 140582376589120 submission_runner.py:248] Initializing model.
I0428 12:47:08.553239 140582376589120 submission_runner.py:258] Initializing optimizer.
I0428 12:47:10.206242 140582376589120 submission_runner.py:265] Initializing metrics bundle.
I0428 12:47:10.206422 140582376589120 submission_runner.py:282] Initializing checkpoint and logger.
I0428 12:47:10.208432 140582376589120 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_fancy/timing_adafactor/fastmri_jax/trial_1 with prefix checkpoint_
I0428 12:47:10.208672 140582376589120 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0428 12:47:10.208734 140582376589120 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0428 12:47:11.076804 140582376589120 submission_runner.py:303] Saving meta data to /experiment_runs/timing_fancy/timing_adafactor/fastmri_jax/trial_1/meta_data_0.json.
I0428 12:47:11.077684 140582376589120 submission_runner.py:306] Saving flags to /experiment_runs/timing_fancy/timing_adafactor/fastmri_jax/trial_1/flags_0.json.
I0428 12:47:11.083654 140582376589120 submission_runner.py:318] Starting training loop.
I0428 12:48:24.285761 140406155106048 logging_writer.py:48] [0] global_step=0, grad_norm=4.839449882507324, loss=0.8533709645271301
I0428 12:48:24.294548 140582376589120 spec.py:298] Evaluating on the training split.
I0428 12:49:54.328034 140582376589120 spec.py:310] Evaluating on the validation split.
I0428 12:50:58.966782 140582376589120 spec.py:326] Evaluating on the test split.
I0428 12:52:01.339184 140582376589120 submission_runner.py:415] Time since start: 290.26s, 	Step: 1, 	{'train/ssim': 0.23348496641431535, 'train/loss': 0.8525359971182687, 'validation/ssim': 0.2266468741481869, 'validation/loss': 0.8619860132289322, 'validation/num_examples': 3554, 'test/ssim': 0.25006480191680047, 'test/loss': 0.860315292516057, 'test/num_examples': 3581, 'score': 73.2107298374176, 'total_duration': 290.25539207458496, 'accumulated_submission_time': 73.2107298374176, 'accumulated_eval_time': 217.04450273513794, 'accumulated_logging_time': 0}
I0428 12:52:01.359349 140377684162304 logging_writer.py:48] [1] accumulated_eval_time=217.044503, accumulated_logging_time=0, accumulated_submission_time=73.210730, global_step=1, preemption_count=0, score=73.210730, test/loss=0.860315, test/num_examples=3581, test/ssim=0.250065, total_duration=290.255392, train/loss=0.852536, train/ssim=0.233485, validation/loss=0.861986, validation/num_examples=3554, validation/ssim=0.226647
I0428 12:52:22.981929 140377675769600 logging_writer.py:48] [100] global_step=100, grad_norm=0.2711370587348938, loss=0.2844006419181824
I0428 12:52:46.794541 140377684162304 logging_writer.py:48] [200] global_step=200, grad_norm=0.11569743603467941, loss=0.3012946844100952
I0428 12:53:10.906415 140377675769600 logging_writer.py:48] [300] global_step=300, grad_norm=0.18375332653522491, loss=0.41896820068359375
I0428 12:53:21.717897 140582376589120 spec.py:298] Evaluating on the training split.
I0428 12:53:23.531422 140582376589120 spec.py:310] Evaluating on the validation split.
I0428 12:53:24.878672 140582376589120 spec.py:326] Evaluating on the test split.
I0428 12:53:26.231026 140582376589120 submission_runner.py:415] Time since start: 375.15s, 	Step: 331, 	{'train/ssim': 0.7146010398864746, 'train/loss': 0.2931700774601528, 'validation/ssim': 0.6919301150552195, 'validation/loss': 0.31575361690832515, 'validation/num_examples': 3554, 'test/ssim': 0.7098517866648631, 'test/loss': 0.3178309376963488, 'test/num_examples': 3581, 'score': 153.55407667160034, 'total_duration': 375.1472964286804, 'accumulated_submission_time': 153.55407667160034, 'accumulated_eval_time': 221.55758476257324, 'accumulated_logging_time': 0.030902385711669922}
I0428 12:53:26.241440 140377684162304 logging_writer.py:48] [331] accumulated_eval_time=221.557585, accumulated_logging_time=0.030902, accumulated_submission_time=153.554077, global_step=331, preemption_count=0, score=153.554077, test/loss=0.317831, test/num_examples=3581, test/ssim=0.709852, total_duration=375.147296, train/loss=0.293170, train/ssim=0.714601, validation/loss=0.315754, validation/num_examples=3554, validation/ssim=0.691930
I0428 12:53:47.259433 140377675769600 logging_writer.py:48] [400] global_step=400, grad_norm=0.321654736995697, loss=0.3223729729652405
I0428 12:54:25.362730 140377684162304 logging_writer.py:48] [500] global_step=500, grad_norm=0.17755763232707977, loss=0.24564088881015778
I0428 12:54:46.262668 140582376589120 spec.py:298] Evaluating on the training split.
I0428 12:54:47.660508 140582376589120 spec.py:310] Evaluating on the validation split.
I0428 12:54:49.011514 140582376589120 spec.py:326] Evaluating on the test split.
I0428 12:54:50.364123 140582376589120 submission_runner.py:415] Time since start: 459.28s, 	Step: 561, 	{'train/ssim': 0.7252217701503209, 'train/loss': 0.2824568237577166, 'validation/ssim': 0.7028787985368599, 'validation/loss': 0.3045072797046462, 'validation/num_examples': 3554, 'test/ssim': 0.7203716500715582, 'test/loss': 0.30642978867416576, 'test/num_examples': 3581, 'score': 233.56388330459595, 'total_duration': 459.28040075302124, 'accumulated_submission_time': 233.56388330459595, 'accumulated_eval_time': 225.6590006351471, 'accumulated_logging_time': 0.04975438117980957}
I0428 12:54:50.377647 140377675769600 logging_writer.py:48] [561] accumulated_eval_time=225.659001, accumulated_logging_time=0.049754, accumulated_submission_time=233.563883, global_step=561, preemption_count=0, score=233.563883, test/loss=0.306430, test/num_examples=3581, test/ssim=0.720372, total_duration=459.280401, train/loss=0.282457, train/ssim=0.725222, validation/loss=0.304507, validation/num_examples=3554, validation/ssim=0.702879
I0428 12:55:01.691675 140377684162304 logging_writer.py:48] [600] global_step=600, grad_norm=0.1338609755039215, loss=0.3028310537338257
I0428 12:55:38.931493 140377675769600 logging_writer.py:48] [700] global_step=700, grad_norm=0.1626117080450058, loss=0.20877838134765625
I0428 12:56:10.718544 140582376589120 spec.py:298] Evaluating on the training split.
I0428 12:56:12.123319 140582376589120 spec.py:310] Evaluating on the validation split.
I0428 12:56:13.473718 140582376589120 spec.py:326] Evaluating on the test split.
I0428 12:56:14.820941 140582376589120 submission_runner.py:415] Time since start: 543.74s, 	Step: 789, 	{'train/ssim': 0.7322180611746651, 'train/loss': 0.2765345573425293, 'validation/ssim': 0.7093796437552757, 'validation/loss': 0.2985528313717818, 'validation/num_examples': 3554, 'test/ssim': 0.726647243590303, 'test/loss': 0.3004975328229719, 'test/num_examples': 3581, 'score': 313.88668966293335, 'total_duration': 543.737206697464, 'accumulated_submission_time': 313.88668966293335, 'accumulated_eval_time': 229.76134705543518, 'accumulated_logging_time': 0.07837176322937012}
I0428 12:56:14.832251 140377684162304 logging_writer.py:48] [789] accumulated_eval_time=229.761347, accumulated_logging_time=0.078372, accumulated_submission_time=313.886690, global_step=789, preemption_count=0, score=313.886690, test/loss=0.300498, test/num_examples=3581, test/ssim=0.726647, total_duration=543.737207, train/loss=0.276535, train/ssim=0.732218, validation/loss=0.298553, validation/num_examples=3554, validation/ssim=0.709380
I0428 12:56:15.748964 140377675769600 logging_writer.py:48] [800] global_step=800, grad_norm=0.2129768282175064, loss=0.26961085200309753
I0428 12:56:54.285876 140377684162304 logging_writer.py:48] [900] global_step=900, grad_norm=0.13164520263671875, loss=0.24978315830230713
I0428 12:57:26.710502 140377675769600 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.19165964424610138, loss=0.29902833700180054
I0428 12:57:35.038717 140582376589120 spec.py:298] Evaluating on the training split.
I0428 12:57:36.440836 140582376589120 spec.py:310] Evaluating on the validation split.
I0428 12:57:37.791531 140582376589120 spec.py:326] Evaluating on the test split.
I0428 12:57:39.143280 140582376589120 submission_runner.py:415] Time since start: 628.06s, 	Step: 1036, 	{'train/ssim': 0.7356125286647252, 'train/loss': 0.27614074093954905, 'validation/ssim': 0.7128959831791644, 'validation/loss': 0.29804620866233467, 'validation/num_examples': 3554, 'test/ssim': 0.7298196400054106, 'test/loss': 0.30005816832763194, 'test/num_examples': 3581, 'score': 394.07721757888794, 'total_duration': 628.059508562088, 'accumulated_submission_time': 394.07721757888794, 'accumulated_eval_time': 233.86582159996033, 'accumulated_logging_time': 0.10242724418640137}
I0428 12:57:39.153404 140377684162304 logging_writer.py:48] [1036] accumulated_eval_time=233.865822, accumulated_logging_time=0.102427, accumulated_submission_time=394.077218, global_step=1036, preemption_count=0, score=394.077218, test/loss=0.300058, test/num_examples=3581, test/ssim=0.729820, total_duration=628.059509, train/loss=0.276141, train/ssim=0.735613, validation/loss=0.298046, validation/num_examples=3554, validation/ssim=0.712896
I0428 12:57:52.354254 140377675769600 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.41317859292030334, loss=0.2966004014015198
I0428 12:58:16.194861 140377684162304 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.15444354712963104, loss=0.24208247661590576
I0428 12:58:39.859594 140377675769600 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.2448403537273407, loss=0.23149962723255157
I0428 12:58:59.349158 140582376589120 spec.py:298] Evaluating on the training split.
I0428 12:59:00.750306 140582376589120 spec.py:310] Evaluating on the validation split.
I0428 12:59:02.101645 140582376589120 spec.py:326] Evaluating on the test split.
I0428 12:59:03.453187 140582376589120 submission_runner.py:415] Time since start: 712.37s, 	Step: 1384, 	{'train/ssim': 0.7355663435799735, 'train/loss': 0.273026704788208, 'validation/ssim': 0.7124934327957935, 'validation/loss': 0.29523100072101854, 'validation/num_examples': 3554, 'test/ssim': 0.7295159129782184, 'test/loss': 0.29714300245654146, 'test/num_examples': 3581, 'score': 474.2598190307617, 'total_duration': 712.369460105896, 'accumulated_submission_time': 474.2598190307617, 'accumulated_eval_time': 237.96980786323547, 'accumulated_logging_time': 0.12094449996948242}
I0428 12:59:03.460922 140377684162304 logging_writer.py:48] [1384] accumulated_eval_time=237.969808, accumulated_logging_time=0.120944, accumulated_submission_time=474.259819, global_step=1384, preemption_count=0, score=474.259819, test/loss=0.297143, test/num_examples=3581, test/ssim=0.729516, total_duration=712.369460, train/loss=0.273027, train/ssim=0.735566, validation/loss=0.295231, validation/num_examples=3554, validation/ssim=0.712493
I0428 12:59:05.253021 140377675769600 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.2950834333896637, loss=0.26010051369667053
I0428 12:59:28.825272 140377684162304 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.10511886328458786, loss=0.2830749750137329
I0428 12:59:52.345260 140377675769600 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.12033527344465256, loss=0.20509831607341766
I0428 13:00:15.973700 140377684162304 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.1378665715456009, loss=0.3767283260822296
I0428 13:00:23.508660 140582376589120 spec.py:298] Evaluating on the training split.
I0428 13:00:24.912334 140582376589120 spec.py:310] Evaluating on the validation split.
I0428 13:00:26.265183 140582376589120 spec.py:326] Evaluating on the test split.
I0428 13:00:27.616400 140582376589120 submission_runner.py:415] Time since start: 796.53s, 	Step: 1733, 	{'train/ssim': 0.7377422196524483, 'train/loss': 0.2713466201509748, 'validation/ssim': 0.7144479316878869, 'validation/loss': 0.29378600971176844, 'validation/num_examples': 3554, 'test/ssim': 0.7316579555073652, 'test/loss': 0.29542812080031766, 'test/num_examples': 3581, 'score': 554.2953629493713, 'total_duration': 796.5326766967773, 'accumulated_submission_time': 554.2953629493713, 'accumulated_eval_time': 242.0775122642517, 'accumulated_logging_time': 0.13615632057189941}
I0428 13:00:27.624702 140377675769600 logging_writer.py:48] [1733] accumulated_eval_time=242.077512, accumulated_logging_time=0.136156, accumulated_submission_time=554.295363, global_step=1733, preemption_count=0, score=554.295363, test/loss=0.295428, test/num_examples=3581, test/ssim=0.731658, total_duration=796.532677, train/loss=0.271347, train/ssim=0.737742, validation/loss=0.293786, validation/num_examples=3554, validation/ssim=0.714448
I0428 13:00:41.405128 140377684162304 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.19003738462924957, loss=0.23146302998065948
I0428 13:01:05.290760 140377675769600 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.14472782611846924, loss=0.3566019833087921
I0428 13:01:29.373621 140377684162304 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.14980508387088776, loss=0.3030891418457031
I0428 13:01:47.836140 140582376589120 spec.py:298] Evaluating on the training split.
I0428 13:01:49.241783 140582376589120 spec.py:310] Evaluating on the validation split.
I0428 13:01:50.590971 140582376589120 spec.py:326] Evaluating on the test split.
I0428 13:01:51.941841 140582376589120 submission_runner.py:415] Time since start: 880.86s, 	Step: 2078, 	{'train/ssim': 0.7404657772609166, 'train/loss': 0.27080401352473665, 'validation/ssim': 0.7180699234137592, 'validation/loss': 0.2929245793691967, 'validation/num_examples': 3554, 'test/ssim': 0.7351833706759634, 'test/loss': 0.29448295365296007, 'test/num_examples': 3581, 'score': 634.4944434165955, 'total_duration': 880.8581011295319, 'accumulated_submission_time': 634.4944434165955, 'accumulated_eval_time': 246.18316054344177, 'accumulated_logging_time': 0.15212798118591309}
I0428 13:01:51.950102 140377675769600 logging_writer.py:48] [2078] accumulated_eval_time=246.183161, accumulated_logging_time=0.152128, accumulated_submission_time=634.494443, global_step=2078, preemption_count=0, score=634.494443, test/loss=0.294483, test/num_examples=3581, test/ssim=0.735183, total_duration=880.858101, train/loss=0.270804, train/ssim=0.740466, validation/loss=0.292925, validation/num_examples=3554, validation/ssim=0.718070
I0428 13:01:55.203705 140377684162304 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.18616384267807007, loss=0.2119211107492447
I0428 13:02:19.169554 140377675769600 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.10893584042787552, loss=0.2648496925830841
I0428 13:02:42.751342 140377684162304 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.06891918182373047, loss=0.2930998206138611
I0428 13:03:06.404738 140377675769600 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.1459653228521347, loss=0.2973257899284363
I0428 13:03:12.150834 140582376589120 spec.py:298] Evaluating on the training split.
I0428 13:03:13.558027 140582376589120 spec.py:310] Evaluating on the validation split.
I0428 13:03:14.908858 140582376589120 spec.py:326] Evaluating on the test split.
I0428 13:03:16.259827 140582376589120 submission_runner.py:415] Time since start: 965.18s, 	Step: 2426, 	{'train/ssim': 0.7410460880824498, 'train/loss': 0.26889794213431223, 'validation/ssim': 0.7175584233873804, 'validation/loss': 0.2915614723287141, 'validation/num_examples': 3554, 'test/ssim': 0.7348432373115051, 'test/loss': 0.2930732989104824, 'test/num_examples': 3581, 'score': 714.6824448108673, 'total_duration': 965.176105260849, 'accumulated_submission_time': 714.6824448108673, 'accumulated_eval_time': 250.29210996627808, 'accumulated_logging_time': 0.16844534873962402}
I0428 13:03:16.268137 140377684162304 logging_writer.py:48] [2426] accumulated_eval_time=250.292110, accumulated_logging_time=0.168445, accumulated_submission_time=714.682445, global_step=2426, preemption_count=0, score=714.682445, test/loss=0.293073, test/num_examples=3581, test/ssim=0.734843, total_duration=965.176105, train/loss=0.268898, train/ssim=0.741046, validation/loss=0.291561, validation/num_examples=3554, validation/ssim=0.717558
I0428 13:03:31.751767 140377675769600 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.1214633584022522, loss=0.2761780023574829
I0428 13:03:55.302437 140377684162304 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.15214082598686218, loss=0.2682511806488037
I0428 13:04:18.975181 140377675769600 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.16637520492076874, loss=0.3214651942253113
I0428 13:04:36.314145 140582376589120 spec.py:298] Evaluating on the training split.
I0428 13:04:37.720087 140582376589120 spec.py:310] Evaluating on the validation split.
I0428 13:04:39.072599 140582376589120 spec.py:326] Evaluating on the test split.
I0428 13:04:40.429571 140582376589120 submission_runner.py:415] Time since start: 1049.35s, 	Step: 2775, 	{'train/ssim': 0.744095870426723, 'train/loss': 0.26780918666294645, 'validation/ssim': 0.7210222801333005, 'validation/loss': 0.2902226488309827, 'validation/num_examples': 3554, 'test/ssim': 0.738053812657079, 'test/loss': 0.2917537396262392, 'test/num_examples': 3581, 'score': 794.7160558700562, 'total_duration': 1049.3458428382874, 'accumulated_submission_time': 794.7160558700562, 'accumulated_eval_time': 254.40748810768127, 'accumulated_logging_time': 0.1843864917755127}
I0428 13:04:40.437793 140377684162304 logging_writer.py:48] [2775] accumulated_eval_time=254.407488, accumulated_logging_time=0.184386, accumulated_submission_time=794.716056, global_step=2775, preemption_count=0, score=794.716056, test/loss=0.291754, test/num_examples=3581, test/ssim=0.738054, total_duration=1049.345843, train/loss=0.267809, train/ssim=0.744096, validation/loss=0.290223, validation/num_examples=3554, validation/ssim=0.721022
I0428 13:04:44.270668 140377675769600 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.15730886161327362, loss=0.30770042538642883
I0428 13:05:07.913174 140377684162304 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.1718236356973648, loss=0.25441616773605347
I0428 13:05:31.374407 140377675769600 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.0953984409570694, loss=0.316251665353775
I0428 13:05:55.164965 140377684162304 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.0962851420044899, loss=0.3151998519897461
I0428 13:06:00.615496 140582376589120 spec.py:298] Evaluating on the training split.
I0428 13:06:02.020104 140582376589120 spec.py:310] Evaluating on the validation split.
I0428 13:06:03.372170 140582376589120 spec.py:326] Evaluating on the test split.
I0428 13:06:04.725001 140582376589120 submission_runner.py:415] Time since start: 1133.64s, 	Step: 3123, 	{'train/ssim': 0.7437084061758858, 'train/loss': 0.2668420246669224, 'validation/ssim': 0.7196577992007246, 'validation/loss': 0.2896158350406232, 'validation/num_examples': 3554, 'test/ssim': 0.7368204968496929, 'test/loss': 0.2911421949721621, 'test/num_examples': 3581, 'score': 874.8812909126282, 'total_duration': 1133.641265630722, 'accumulated_submission_time': 874.8812909126282, 'accumulated_eval_time': 258.5169656276703, 'accumulated_logging_time': 0.20041990280151367}
I0428 13:06:04.734107 140377675769600 logging_writer.py:48] [3123] accumulated_eval_time=258.516966, accumulated_logging_time=0.200420, accumulated_submission_time=874.881291, global_step=3123, preemption_count=0, score=874.881291, test/loss=0.291142, test/num_examples=3581, test/ssim=0.736820, total_duration=1133.641266, train/loss=0.266842, train/ssim=0.743708, validation/loss=0.289616, validation/num_examples=3554, validation/ssim=0.719658
I0428 13:06:20.767366 140377684162304 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.07792490720748901, loss=0.2776830196380615
I0428 13:06:44.588082 140377675769600 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.26749494671821594, loss=0.31405001878738403
I0428 13:07:08.502553 140377684162304 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.04998015984892845, loss=0.32900792360305786
I0428 13:07:24.913042 140582376589120 spec.py:298] Evaluating on the training split.
I0428 13:07:26.318314 140582376589120 spec.py:310] Evaluating on the validation split.
I0428 13:07:27.670047 140582376589120 spec.py:326] Evaluating on the test split.
I0428 13:07:29.026803 140582376589120 submission_runner.py:415] Time since start: 1217.94s, 	Step: 3471, 	{'train/ssim': 0.7461060115269252, 'train/loss': 0.26580926350184847, 'validation/ssim': 0.7219130430720667, 'validation/loss': 0.28886170567054725, 'validation/num_examples': 3554, 'test/ssim': 0.739123095416783, 'test/loss': 0.290315109802604, 'test/num_examples': 3581, 'score': 955.04758477211, 'total_duration': 1217.9430775642395, 'accumulated_submission_time': 955.04758477211, 'accumulated_eval_time': 262.6306834220886, 'accumulated_logging_time': 0.2175002098083496}
I0428 13:07:29.036196 140377675769600 logging_writer.py:48] [3471] accumulated_eval_time=262.630683, accumulated_logging_time=0.217500, accumulated_submission_time=955.047585, global_step=3471, preemption_count=0, score=955.047585, test/loss=0.290315, test/num_examples=3581, test/ssim=0.739123, total_duration=1217.943078, train/loss=0.265809, train/ssim=0.746106, validation/loss=0.288862, validation/num_examples=3554, validation/ssim=0.721913
I0428 13:07:33.887420 140377684162304 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.12439681589603424, loss=0.35090333223342896
I0428 13:07:57.531146 140377675769600 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.08180724084377289, loss=0.25581666827201843
I0428 13:08:20.874636 140377684162304 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.08041267096996307, loss=0.27373433113098145
I0428 13:08:44.399501 140377675769600 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.13304893672466278, loss=0.27495718002319336
I0428 13:08:49.106912 140582376589120 spec.py:298] Evaluating on the training split.
I0428 13:08:50.507633 140582376589120 spec.py:310] Evaluating on the validation split.
I0428 13:08:51.860582 140582376589120 spec.py:326] Evaluating on the test split.
I0428 13:08:53.213421 140582376589120 submission_runner.py:415] Time since start: 1302.13s, 	Step: 3821, 	{'train/ssim': 0.7442838805062431, 'train/loss': 0.2664365768432617, 'validation/ssim': 0.7202111342413478, 'validation/loss': 0.28907088074176984, 'validation/num_examples': 3554, 'test/ssim': 0.7375685993568486, 'test/loss': 0.2905164013958217, 'test/num_examples': 3581, 'score': 1035.104543685913, 'total_duration': 1302.1297023296356, 'accumulated_submission_time': 1035.104543685913, 'accumulated_eval_time': 266.7371768951416, 'accumulated_logging_time': 0.23591852188110352}
I0428 13:08:53.221844 140377684162304 logging_writer.py:48] [3821] accumulated_eval_time=266.737177, accumulated_logging_time=0.235919, accumulated_submission_time=1035.104544, global_step=3821, preemption_count=0, score=1035.104544, test/loss=0.290516, test/num_examples=3581, test/ssim=0.737569, total_duration=1302.129702, train/loss=0.266437, train/ssim=0.744284, validation/loss=0.289071, validation/num_examples=3554, validation/ssim=0.720211
I0428 13:09:09.926042 140377675769600 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.07637085020542145, loss=0.27786242961883545
I0428 13:09:33.845251 140377684162304 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.04907219111919403, loss=0.21130594611167908
I0428 13:09:57.506649 140377675769600 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.1356756091117859, loss=0.26055800914764404
I0428 13:10:13.280604 140582376589120 spec.py:298] Evaluating on the training split.
I0428 13:10:14.683268 140582376589120 spec.py:310] Evaluating on the validation split.
I0428 13:10:16.034772 140582376589120 spec.py:326] Evaluating on the test split.
I0428 13:10:17.390634 140582376589120 submission_runner.py:415] Time since start: 1386.31s, 	Step: 4167, 	{'train/ssim': 0.7459643908909389, 'train/loss': 0.2654112236840384, 'validation/ssim': 0.721896281588527, 'validation/loss': 0.2881922767480304, 'validation/num_examples': 3554, 'test/ssim': 0.7392107706035326, 'test/loss': 0.28954825871352274, 'test/num_examples': 3581, 'score': 1115.1513714790344, 'total_duration': 1386.306897163391, 'accumulated_submission_time': 1115.1513714790344, 'accumulated_eval_time': 270.84715247154236, 'accumulated_logging_time': 0.25173401832580566}
I0428 13:10:17.399109 140377684162304 logging_writer.py:48] [4167] accumulated_eval_time=270.847152, accumulated_logging_time=0.251734, accumulated_submission_time=1115.151371, global_step=4167, preemption_count=0, score=1115.151371, test/loss=0.289548, test/num_examples=3581, test/ssim=0.739211, total_duration=1386.306897, train/loss=0.265411, train/ssim=0.745964, validation/loss=0.288192, validation/num_examples=3554, validation/ssim=0.721896
I0428 13:10:23.612997 140377675769600 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.06842944025993347, loss=0.29500916600227356
I0428 13:10:47.317723 140377684162304 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.19003906846046448, loss=0.2841896116733551
I0428 13:11:10.987489 140377675769600 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.06519249081611633, loss=0.2267657369375229
I0428 13:11:34.689140 140377684162304 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.11801515519618988, loss=0.24764443933963776
I0428 13:11:37.443129 140582376589120 spec.py:298] Evaluating on the training split.
I0428 13:11:38.849197 140582376589120 spec.py:310] Evaluating on the validation split.
I0428 13:11:40.199506 140582376589120 spec.py:326] Evaluating on the test split.
I0428 13:11:41.553287 140582376589120 submission_runner.py:415] Time since start: 1470.47s, 	Step: 4513, 	{'train/ssim': 0.7466088022504535, 'train/loss': 0.2649244580950056, 'validation/ssim': 0.7221253094004995, 'validation/loss': 0.28822387626617896, 'validation/num_examples': 3554, 'test/ssim': 0.7393449422734572, 'test/loss': 0.28973557409112327, 'test/num_examples': 3581, 'score': 1195.1829054355621, 'total_duration': 1470.4695632457733, 'accumulated_submission_time': 1195.1829054355621, 'accumulated_eval_time': 274.95726895332336, 'accumulated_logging_time': 0.2680971622467041}
I0428 13:11:41.562274 140377675769600 logging_writer.py:48] [4513] accumulated_eval_time=274.957269, accumulated_logging_time=0.268097, accumulated_submission_time=1195.182905, global_step=4513, preemption_count=0, score=1195.182905, test/loss=0.289736, test/num_examples=3581, test/ssim=0.739345, total_duration=1470.469563, train/loss=0.264924, train/ssim=0.746609, validation/loss=0.288224, validation/num_examples=3554, validation/ssim=0.722125
I0428 13:12:00.290797 140377684162304 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.049256790429353714, loss=0.30395346879959106
I0428 13:12:23.966206 140377675769600 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.1296740025281906, loss=0.23990175127983093
I0428 13:12:47.386584 140377684162304 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.05930937081575394, loss=0.2580840289592743
I0428 13:13:01.584710 140582376589120 spec.py:298] Evaluating on the training split.
I0428 13:13:02.991077 140582376589120 spec.py:310] Evaluating on the validation split.
I0428 13:13:04.343932 140582376589120 spec.py:326] Evaluating on the test split.
I0428 13:13:05.698160 140582376589120 submission_runner.py:415] Time since start: 1554.61s, 	Step: 4861, 	{'train/ssim': 0.7441663060869489, 'train/loss': 0.2653709990637643, 'validation/ssim': 0.7197796634294106, 'validation/loss': 0.2884745428786227, 'validation/num_examples': 3554, 'test/ssim': 0.7371930141283859, 'test/loss': 0.2898814380585032, 'test/num_examples': 3581, 'score': 1275.1918420791626, 'total_duration': 1554.6144366264343, 'accumulated_submission_time': 1275.1918420791626, 'accumulated_eval_time': 279.0706877708435, 'accumulated_logging_time': 0.2858762741088867}
I0428 13:13:05.706912 140377675769600 logging_writer.py:48] [4861] accumulated_eval_time=279.070688, accumulated_logging_time=0.285876, accumulated_submission_time=1275.191842, global_step=4861, preemption_count=0, score=1275.191842, test/loss=0.289881, test/num_examples=3581, test/ssim=0.737193, total_duration=1554.614437, train/loss=0.265371, train/ssim=0.744166, validation/loss=0.288475, validation/num_examples=3554, validation/ssim=0.719780
I0428 13:13:12.914687 140377684162304 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.1026420146226883, loss=0.31244122982025146
I0428 13:13:36.834363 140377675769600 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.05307261273264885, loss=0.2953997552394867
I0428 13:14:00.380024 140377684162304 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.2716974914073944, loss=0.21232716739177704
I0428 13:14:24.130482 140377675769600 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.06587964296340942, loss=0.2508944571018219
I0428 13:14:25.824331 140582376589120 spec.py:298] Evaluating on the training split.
I0428 13:14:27.227051 140582376589120 spec.py:310] Evaluating on the validation split.
I0428 13:14:28.581033 140582376589120 spec.py:326] Evaluating on the test split.
I0428 13:14:29.935071 140582376589120 submission_runner.py:415] Time since start: 1638.85s, 	Step: 5208, 	{'train/ssim': 0.7463622093200684, 'train/loss': 0.26492016656058176, 'validation/ssim': 0.7222004612980093, 'validation/loss': 0.2877903961370551, 'validation/num_examples': 3554, 'test/ssim': 0.7393746672978917, 'test/loss': 0.28929873213226054, 'test/num_examples': 3581, 'score': 1355.2958562374115, 'total_duration': 1638.8513369560242, 'accumulated_submission_time': 1355.2958562374115, 'accumulated_eval_time': 283.18139386177063, 'accumulated_logging_time': 0.30335521697998047}
I0428 13:14:29.944012 140377684162304 logging_writer.py:48] [5208] accumulated_eval_time=283.181394, accumulated_logging_time=0.303355, accumulated_submission_time=1355.295856, global_step=5208, preemption_count=0, score=1355.295856, test/loss=0.289299, test/num_examples=3581, test/ssim=0.739375, total_duration=1638.851337, train/loss=0.264920, train/ssim=0.746362, validation/loss=0.287790, validation/num_examples=3554, validation/ssim=0.722200
I0428 13:14:50.238343 140377675769600 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.0688830241560936, loss=0.204241544008255
I0428 13:15:13.688993 140377684162304 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.10694482177495956, loss=0.3045835793018341
I0428 13:15:20.159025 140582376589120 spec.py:298] Evaluating on the training split.
I0428 13:15:21.563293 140582376589120 spec.py:310] Evaluating on the validation split.
I0428 13:15:22.914344 140582376589120 spec.py:326] Evaluating on the test split.
I0428 13:15:24.272119 140582376589120 submission_runner.py:415] Time since start: 1693.19s, 	Step: 5428, 	{'train/ssim': 0.7456699098859515, 'train/loss': 0.2653438704354422, 'validation/ssim': 0.721009022074599, 'validation/loss': 0.28870944407929444, 'validation/num_examples': 3554, 'test/ssim': 0.7382841815964465, 'test/loss': 0.29016723462370847, 'test/num_examples': 3581, 'score': 1405.500220298767, 'total_duration': 1693.1883924007416, 'accumulated_submission_time': 1405.500220298767, 'accumulated_eval_time': 287.29445695877075, 'accumulated_logging_time': 0.3198816776275635}
I0428 13:15:24.280775 140377675769600 logging_writer.py:48] [5428] accumulated_eval_time=287.294457, accumulated_logging_time=0.319882, accumulated_submission_time=1405.500220, global_step=5428, preemption_count=0, score=1405.500220, test/loss=0.290167, test/num_examples=3581, test/ssim=0.738284, total_duration=1693.188392, train/loss=0.265344, train/ssim=0.745670, validation/loss=0.288709, validation/num_examples=3554, validation/ssim=0.721009
I0428 13:15:24.294186 140377684162304 logging_writer.py:48] [5428] global_step=5428, preemption_count=0, score=1405.500220
I0428 13:15:24.319376 140582376589120 checkpoints.py:356] Saving checkpoint at step: 5428
I0428 13:15:24.463504 140582376589120 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_fancy/timing_adafactor/fastmri_jax/trial_1/checkpoint_5428
I0428 13:15:24.464053 140582376589120 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_fancy/timing_adafactor/fastmri_jax/trial_1/checkpoint_5428.
I0428 13:15:25.039611 140582376589120 submission_runner.py:578] Tuning trial 1/1
I0428 13:15:25.039846 140582376589120 submission_runner.py:579] Hyperparameters: Hyperparameters(learning_rate=0.0032594519610942875, one_minus_beta1=0.03999478140191344, warmup_factor=0.05, weight_decay=0.002578922011395245, label_smoothing=0.1, dropout_rate=0.0)
I0428 13:15:25.045510 140582376589120 submission_runner.py:580] Metrics: {'eval_results': [(1, {'train/ssim': 0.23348496641431535, 'train/loss': 0.8525359971182687, 'validation/ssim': 0.2266468741481869, 'validation/loss': 0.8619860132289322, 'validation/num_examples': 3554, 'test/ssim': 0.25006480191680047, 'test/loss': 0.860315292516057, 'test/num_examples': 3581, 'score': 73.2107298374176, 'total_duration': 290.25539207458496, 'accumulated_submission_time': 73.2107298374176, 'accumulated_eval_time': 217.04450273513794, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (331, {'train/ssim': 0.7146010398864746, 'train/loss': 0.2931700774601528, 'validation/ssim': 0.6919301150552195, 'validation/loss': 0.31575361690832515, 'validation/num_examples': 3554, 'test/ssim': 0.7098517866648631, 'test/loss': 0.3178309376963488, 'test/num_examples': 3581, 'score': 153.55407667160034, 'total_duration': 375.1472964286804, 'accumulated_submission_time': 153.55407667160034, 'accumulated_eval_time': 221.55758476257324, 'accumulated_logging_time': 0.030902385711669922, 'global_step': 331, 'preemption_count': 0}), (561, {'train/ssim': 0.7252217701503209, 'train/loss': 0.2824568237577166, 'validation/ssim': 0.7028787985368599, 'validation/loss': 0.3045072797046462, 'validation/num_examples': 3554, 'test/ssim': 0.7203716500715582, 'test/loss': 0.30642978867416576, 'test/num_examples': 3581, 'score': 233.56388330459595, 'total_duration': 459.28040075302124, 'accumulated_submission_time': 233.56388330459595, 'accumulated_eval_time': 225.6590006351471, 'accumulated_logging_time': 0.04975438117980957, 'global_step': 561, 'preemption_count': 0}), (789, {'train/ssim': 0.7322180611746651, 'train/loss': 0.2765345573425293, 'validation/ssim': 0.7093796437552757, 'validation/loss': 0.2985528313717818, 'validation/num_examples': 3554, 'test/ssim': 0.726647243590303, 'test/loss': 0.3004975328229719, 'test/num_examples': 3581, 'score': 313.88668966293335, 'total_duration': 543.737206697464, 'accumulated_submission_time': 313.88668966293335, 'accumulated_eval_time': 229.76134705543518, 'accumulated_logging_time': 0.07837176322937012, 'global_step': 789, 'preemption_count': 0}), (1036, {'train/ssim': 0.7356125286647252, 'train/loss': 0.27614074093954905, 'validation/ssim': 0.7128959831791644, 'validation/loss': 0.29804620866233467, 'validation/num_examples': 3554, 'test/ssim': 0.7298196400054106, 'test/loss': 0.30005816832763194, 'test/num_examples': 3581, 'score': 394.07721757888794, 'total_duration': 628.059508562088, 'accumulated_submission_time': 394.07721757888794, 'accumulated_eval_time': 233.86582159996033, 'accumulated_logging_time': 0.10242724418640137, 'global_step': 1036, 'preemption_count': 0}), (1384, {'train/ssim': 0.7355663435799735, 'train/loss': 0.273026704788208, 'validation/ssim': 0.7124934327957935, 'validation/loss': 0.29523100072101854, 'validation/num_examples': 3554, 'test/ssim': 0.7295159129782184, 'test/loss': 0.29714300245654146, 'test/num_examples': 3581, 'score': 474.2598190307617, 'total_duration': 712.369460105896, 'accumulated_submission_time': 474.2598190307617, 'accumulated_eval_time': 237.96980786323547, 'accumulated_logging_time': 0.12094449996948242, 'global_step': 1384, 'preemption_count': 0}), (1733, {'train/ssim': 0.7377422196524483, 'train/loss': 0.2713466201509748, 'validation/ssim': 0.7144479316878869, 'validation/loss': 0.29378600971176844, 'validation/num_examples': 3554, 'test/ssim': 0.7316579555073652, 'test/loss': 0.29542812080031766, 'test/num_examples': 3581, 'score': 554.2953629493713, 'total_duration': 796.5326766967773, 'accumulated_submission_time': 554.2953629493713, 'accumulated_eval_time': 242.0775122642517, 'accumulated_logging_time': 0.13615632057189941, 'global_step': 1733, 'preemption_count': 0}), (2078, {'train/ssim': 0.7404657772609166, 'train/loss': 0.27080401352473665, 'validation/ssim': 0.7180699234137592, 'validation/loss': 0.2929245793691967, 'validation/num_examples': 3554, 'test/ssim': 0.7351833706759634, 'test/loss': 0.29448295365296007, 'test/num_examples': 3581, 'score': 634.4944434165955, 'total_duration': 880.8581011295319, 'accumulated_submission_time': 634.4944434165955, 'accumulated_eval_time': 246.18316054344177, 'accumulated_logging_time': 0.15212798118591309, 'global_step': 2078, 'preemption_count': 0}), (2426, {'train/ssim': 0.7410460880824498, 'train/loss': 0.26889794213431223, 'validation/ssim': 0.7175584233873804, 'validation/loss': 0.2915614723287141, 'validation/num_examples': 3554, 'test/ssim': 0.7348432373115051, 'test/loss': 0.2930732989104824, 'test/num_examples': 3581, 'score': 714.6824448108673, 'total_duration': 965.176105260849, 'accumulated_submission_time': 714.6824448108673, 'accumulated_eval_time': 250.29210996627808, 'accumulated_logging_time': 0.16844534873962402, 'global_step': 2426, 'preemption_count': 0}), (2775, {'train/ssim': 0.744095870426723, 'train/loss': 0.26780918666294645, 'validation/ssim': 0.7210222801333005, 'validation/loss': 0.2902226488309827, 'validation/num_examples': 3554, 'test/ssim': 0.738053812657079, 'test/loss': 0.2917537396262392, 'test/num_examples': 3581, 'score': 794.7160558700562, 'total_duration': 1049.3458428382874, 'accumulated_submission_time': 794.7160558700562, 'accumulated_eval_time': 254.40748810768127, 'accumulated_logging_time': 0.1843864917755127, 'global_step': 2775, 'preemption_count': 0}), (3123, {'train/ssim': 0.7437084061758858, 'train/loss': 0.2668420246669224, 'validation/ssim': 0.7196577992007246, 'validation/loss': 0.2896158350406232, 'validation/num_examples': 3554, 'test/ssim': 0.7368204968496929, 'test/loss': 0.2911421949721621, 'test/num_examples': 3581, 'score': 874.8812909126282, 'total_duration': 1133.641265630722, 'accumulated_submission_time': 874.8812909126282, 'accumulated_eval_time': 258.5169656276703, 'accumulated_logging_time': 0.20041990280151367, 'global_step': 3123, 'preemption_count': 0}), (3471, {'train/ssim': 0.7461060115269252, 'train/loss': 0.26580926350184847, 'validation/ssim': 0.7219130430720667, 'validation/loss': 0.28886170567054725, 'validation/num_examples': 3554, 'test/ssim': 0.739123095416783, 'test/loss': 0.290315109802604, 'test/num_examples': 3581, 'score': 955.04758477211, 'total_duration': 1217.9430775642395, 'accumulated_submission_time': 955.04758477211, 'accumulated_eval_time': 262.6306834220886, 'accumulated_logging_time': 0.2175002098083496, 'global_step': 3471, 'preemption_count': 0}), (3821, {'train/ssim': 0.7442838805062431, 'train/loss': 0.2664365768432617, 'validation/ssim': 0.7202111342413478, 'validation/loss': 0.28907088074176984, 'validation/num_examples': 3554, 'test/ssim': 0.7375685993568486, 'test/loss': 0.2905164013958217, 'test/num_examples': 3581, 'score': 1035.104543685913, 'total_duration': 1302.1297023296356, 'accumulated_submission_time': 1035.104543685913, 'accumulated_eval_time': 266.7371768951416, 'accumulated_logging_time': 0.23591852188110352, 'global_step': 3821, 'preemption_count': 0}), (4167, {'train/ssim': 0.7459643908909389, 'train/loss': 0.2654112236840384, 'validation/ssim': 0.721896281588527, 'validation/loss': 0.2881922767480304, 'validation/num_examples': 3554, 'test/ssim': 0.7392107706035326, 'test/loss': 0.28954825871352274, 'test/num_examples': 3581, 'score': 1115.1513714790344, 'total_duration': 1386.306897163391, 'accumulated_submission_time': 1115.1513714790344, 'accumulated_eval_time': 270.84715247154236, 'accumulated_logging_time': 0.25173401832580566, 'global_step': 4167, 'preemption_count': 0}), (4513, {'train/ssim': 0.7466088022504535, 'train/loss': 0.2649244580950056, 'validation/ssim': 0.7221253094004995, 'validation/loss': 0.28822387626617896, 'validation/num_examples': 3554, 'test/ssim': 0.7393449422734572, 'test/loss': 0.28973557409112327, 'test/num_examples': 3581, 'score': 1195.1829054355621, 'total_duration': 1470.4695632457733, 'accumulated_submission_time': 1195.1829054355621, 'accumulated_eval_time': 274.95726895332336, 'accumulated_logging_time': 0.2680971622467041, 'global_step': 4513, 'preemption_count': 0}), (4861, {'train/ssim': 0.7441663060869489, 'train/loss': 0.2653709990637643, 'validation/ssim': 0.7197796634294106, 'validation/loss': 0.2884745428786227, 'validation/num_examples': 3554, 'test/ssim': 0.7371930141283859, 'test/loss': 0.2898814380585032, 'test/num_examples': 3581, 'score': 1275.1918420791626, 'total_duration': 1554.6144366264343, 'accumulated_submission_time': 1275.1918420791626, 'accumulated_eval_time': 279.0706877708435, 'accumulated_logging_time': 0.2858762741088867, 'global_step': 4861, 'preemption_count': 0}), (5208, {'train/ssim': 0.7463622093200684, 'train/loss': 0.26492016656058176, 'validation/ssim': 0.7222004612980093, 'validation/loss': 0.2877903961370551, 'validation/num_examples': 3554, 'test/ssim': 0.7393746672978917, 'test/loss': 0.28929873213226054, 'test/num_examples': 3581, 'score': 1355.2958562374115, 'total_duration': 1638.8513369560242, 'accumulated_submission_time': 1355.2958562374115, 'accumulated_eval_time': 283.18139386177063, 'accumulated_logging_time': 0.30335521697998047, 'global_step': 5208, 'preemption_count': 0}), (5428, {'train/ssim': 0.7456699098859515, 'train/loss': 0.2653438704354422, 'validation/ssim': 0.721009022074599, 'validation/loss': 0.28870944407929444, 'validation/num_examples': 3554, 'test/ssim': 0.7382841815964465, 'test/loss': 0.29016723462370847, 'test/num_examples': 3581, 'score': 1405.500220298767, 'total_duration': 1693.1883924007416, 'accumulated_submission_time': 1405.500220298767, 'accumulated_eval_time': 287.29445695877075, 'accumulated_logging_time': 0.3198816776275635, 'global_step': 5428, 'preemption_count': 0})], 'global_step': 5428}
I0428 13:15:25.045640 140582376589120 submission_runner.py:581] Timing: 1405.500220298767
I0428 13:15:25.045688 140582376589120 submission_runner.py:582] ====================
I0428 13:15:25.045812 140582376589120 submission_runner.py:645] Final fastmri score: 1405.500220298767
