I0405 04:45:38.045680 140222196610880 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_nadamw_v2/criteo1tb_jax.
I0405 04:45:38.410399 140222196610880 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0405 04:45:39.314094 140222196610880 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0405 04:45:39.315157 140222196610880 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0405 04:45:39.320546 140222196610880 submission_runner.py:511] Using RNG seed 2268632662
I0405 04:45:41.666895 140222196610880 submission_runner.py:520] --- Tuning run 1/1 ---
I0405 04:45:41.667114 140222196610880 submission_runner.py:525] Creating tuning directory at /experiment_runs/timing_nadamw_v2/criteo1tb_jax/trial_1.
I0405 04:45:41.667302 140222196610880 logger_utils.py:84] Saving hparams to /experiment_runs/timing_nadamw_v2/criteo1tb_jax/trial_1/hparams.json.
I0405 04:45:41.794870 140222196610880 submission_runner.py:230] Starting train once: RAM USED (GB) 4.27382784
I0405 04:45:41.795037 140222196610880 submission_runner.py:231] Initializing dataset.
I0405 04:45:41.795197 140222196610880 submission_runner.py:239] After Initializing dataset: RAM USED (GB) 4.27382784
I0405 04:45:41.795256 140222196610880 submission_runner.py:240] Initializing model.
I0405 04:45:47.694843 140222196610880 submission_runner.py:251] After Initializing model: RAM USED (GB) 8.067145728
I0405 04:45:47.695061 140222196610880 submission_runner.py:252] Initializing optimizer.
I0405 04:45:50.927965 140222196610880 submission_runner.py:260] After Initializing metrics bundle: RAM USED (GB) 8.06766592
I0405 04:45:50.928155 140222196610880 submission_runner.py:261] Initializing metrics bundle.
I0405 04:45:50.928202 140222196610880 submission_runner.py:276] Initializing checkpoint and logger.
I0405 04:45:50.931313 140222196610880 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_nadamw_v2/criteo1tb_jax/trial_1 with prefix checkpoint_
I0405 04:45:50.931603 140222196610880 logger_utils.py:231] Unable to record workload.train_mean information. Continuing without it.
I0405 04:45:50.931675 140222196610880 logger_utils.py:231] Unable to record workload.train_stddev information. Continuing without it.
I0405 04:45:51.800479 140222196610880 submission_runner.py:297] Saving meta data to /experiment_runs/timing_nadamw_v2/criteo1tb_jax/trial_1/meta_data_0.json.
I0405 04:45:51.801440 140222196610880 submission_runner.py:300] Saving flags to /experiment_runs/timing_nadamw_v2/criteo1tb_jax/trial_1/flags_0.json.
I0405 04:45:51.848510 140222196610880 submission_runner.py:305] After checkpoint and logger metrics bundle: RAM USED (GB) 8.108417024
I0405 04:45:51.848757 140222196610880 submission_runner.py:312] Before starting training loop and logger metrics bundle: RAM USED (GB) 8.108417024
I0405 04:45:51.848821 140222196610880 submission_runner.py:313] Starting training loop.
I0405 04:48:14.125175 140222196610880 submission_runner.py:335] After dataselection batch at step 0: RAM USED (GB) 46.112161792
I0405 04:48:36.570457 140016495879936 logging_writer.py:48] [0] global_step=0, grad_norm=5.219003200531006, loss=0.6545301675796509
I0405 04:48:36.591288 140222196610880 submission_runner.py:352] After update parameters step 0: RAM USED (GB) 54.116999168
I0405 04:48:36.591564 140222196610880 submission_runner.py:373] Before eval at step 1: RAM USED (GB) 54.116999168
I0405 04:48:36.591652 140222196610880 spec.py:298] Evaluating on the training split.
I0405 04:58:15.026037 140222196610880 spec.py:310] Evaluating on the validation split.
I0405 05:02:38.875069 140222196610880 spec.py:326] Evaluating on the test split.
I0405 05:07:28.666453 140222196610880 submission_runner.py:382] Time since start: 164.74s, 	Step: 1, 	{'train/loss': 0.6544113103039919, 'validation/loss': 0.6567152359550562, 'validation/num_examples': 89000000, 'test/loss': 0.6554701084922921, 'test/num_examples': 89274637}
I0405 05:07:28.667926 140222196610880 submission_runner.py:396] After eval at step 1: RAM USED (GB) 95.847235584
I0405 05:07:28.677781 139963521824512 logging_writer.py:48] [1] global_step=1, preemption_count=0, score=164.548121, test/loss=0.655470, test/num_examples=89274637, total_duration=164.742799, train/loss=0.654411, validation/loss=0.656715, validation/num_examples=89000000
I0405 05:07:35.007478 140222196610880 checkpoints.py:356] Saving checkpoint at step: 1
I0405 05:08:11.376177 140222196610880 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nadamw_v2/criteo1tb_jax/trial_1/checkpoint_1
I0405 05:08:11.883398 140222196610880 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw_v2/criteo1tb_jax/trial_1/checkpoint_1.
I0405 05:08:12.414186 140222196610880 submission_runner.py:416] After logging and checkpointing eval at step 1: RAM USED (GB) 95.910006784
I0405 05:08:12.417257 140222196610880 submission_runner.py:335] After dataselection batch at step 1: RAM USED (GB) 95.869120512
I0405 05:08:12.461727 140222196610880 submission_runner.py:352] After update parameters step 1: RAM USED (GB) 95.86294784
I0405 05:09:34.547756 139963513431808 logging_writer.py:48] [100] global_step=100, grad_norm=0.032459985464811325, loss=0.13038446009159088
I0405 05:11:27.170078 139963479860992 logging_writer.py:48] [200] global_step=200, grad_norm=0.015967704355716705, loss=0.12792529165744781
I0405 05:13:23.874518 139963513431808 logging_writer.py:48] [300] global_step=300, grad_norm=0.021777454763650894, loss=0.1289055049419403
I0405 05:15:24.530938 139963479860992 logging_writer.py:48] [400] global_step=400, grad_norm=0.048552222549915314, loss=0.12787127494812012
I0405 05:17:13.234502 140222196610880 submission_runner.py:373] Before eval at step 493: RAM USED (GB) 103.258845184
I0405 05:17:13.234748 140222196610880 spec.py:298] Evaluating on the training split.
I0405 05:28:15.095850 140222196610880 spec.py:310] Evaluating on the validation split.
I0405 05:32:10.397311 140222196610880 spec.py:326] Evaluating on the test split.
I0405 05:36:56.229229 140222196610880 submission_runner.py:382] Time since start: 1881.39s, 	Step: 493, 	{'train/loss': 0.12520819994524351, 'validation/loss': 0.12671293258426966, 'validation/num_examples': 89000000, 'test/loss': 0.12917662157506168, 'test/num_examples': 89274637}
I0405 05:36:56.229705 140222196610880 submission_runner.py:396] After eval at step 493: RAM USED (GB) 108.373696512
I0405 05:36:56.236661 139959428183808 logging_writer.py:48] [493] global_step=493, preemption_count=0, score=703.248217, test/loss=0.129177, test/num_examples=89274637, total_duration=1881.385430, train/loss=0.125208, validation/loss=0.126713, validation/num_examples=89000000
I0405 05:37:02.460383 140222196610880 checkpoints.py:356] Saving checkpoint at step: 493
I0405 05:37:38.162008 140222196610880 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nadamw_v2/criteo1tb_jax/trial_1/checkpoint_493
I0405 05:37:38.647061 140222196610880 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw_v2/criteo1tb_jax/trial_1/checkpoint_493.
I0405 05:37:39.170404 140222196610880 submission_runner.py:416] After logging and checkpointing eval at step 493: RAM USED (GB) 108.466253824
I0405 05:37:40.071234 139959419791104 logging_writer.py:48] [500] global_step=500, grad_norm=0.014187098480761051, loss=0.12748835980892181
I0405 05:39:17.778887 139959377827584 logging_writer.py:48] [600] global_step=600, grad_norm=0.022852104157209396, loss=0.12484301626682281
I0405 05:41:32.989150 139959419791104 logging_writer.py:48] [700] global_step=700, grad_norm=0.015608465299010277, loss=0.12514860928058624
I0405 05:43:30.047335 140222196610880 submission_runner.py:373] Before eval at step 800: RAM USED (GB) 108.962373632
I0405 05:43:30.047529 140222196610880 spec.py:298] Evaluating on the training split.
I0405 05:54:25.892469 140222196610880 spec.py:310] Evaluating on the validation split.
I0405 05:58:17.202681 140222196610880 spec.py:326] Evaluating on the test split.
I0405 06:03:21.669475 140222196610880 submission_runner.py:382] Time since start: 3458.20s, 	Step: 800, 	{'train/loss': 0.1255875700444663, 'validation/loss': 0.12659748314606742, 'validation/num_examples': 89000000, 'test/loss': 0.12911004051464248, 'test/num_examples': 89274637}
I0405 06:03:21.670014 140222196610880 submission_runner.py:396] After eval at step 800: RAM USED (GB) 111.964250112
I0405 06:03:21.677869 139955871414016 logging_writer.py:48] [800] global_step=800, preemption_count=0, score=1052.462672, test/loss=0.129110, test/num_examples=89274637, total_duration=3458.198306, train/loss=0.125588, validation/loss=0.126597, validation/num_examples=89000000
I0405 06:03:27.990307 140222196610880 checkpoints.py:356] Saving checkpoint at step: 800
I0405 06:04:03.146673 140222196610880 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nadamw_v2/criteo1tb_jax/trial_1/checkpoint_800
I0405 06:04:03.631307 140222196610880 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw_v2/criteo1tb_jax/trial_1/checkpoint_800.
I0405 06:04:04.113013 140222196610880 submission_runner.py:416] After logging and checkpointing eval at step 800: RAM USED (GB) 111.968710656
I0405 06:04:04.118497 139955863021312 logging_writer.py:48] [800] global_step=800, preemption_count=0, score=1052.462672
I0405 06:04:09.979218 140222196610880 checkpoints.py:356] Saving checkpoint at step: 800
I0405 06:04:52.635766 140222196610880 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_nadamw_v2/criteo1tb_jax/trial_1/checkpoint_800
I0405 06:04:53.157354 140222196610880 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_nadamw_v2/criteo1tb_jax/trial_1/checkpoint_800.
I0405 06:06:45.642663 140222196610880 submission_runner.py:550] Tuning trial 1/1
I0405 06:06:45.642958 140222196610880 submission_runner.py:551] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.045677535963609565, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0405 06:06:45.644196 140222196610880 submission_runner.py:552] Metrics: {'eval_results': [(1, {'train/loss': 0.6544113103039919, 'validation/loss': 0.6567152359550562, 'validation/num_examples': 89000000, 'test/loss': 0.6554701084922921, 'test/num_examples': 89274637, 'score': 164.54812145233154, 'total_duration': 164.74279856681824, 'global_step': 1, 'preemption_count': 0}), (493, {'train/loss': 0.12520819994524351, 'validation/loss': 0.12671293258426966, 'validation/num_examples': 89000000, 'test/loss': 0.12917662157506168, 'test/num_examples': 89274637, 'score': 703.2482173442841, 'total_duration': 1881.38543009758, 'global_step': 493, 'preemption_count': 0}), (800, {'train/loss': 0.1255875700444663, 'validation/loss': 0.12659748314606742, 'validation/num_examples': 89000000, 'test/loss': 0.12911004051464248, 'test/num_examples': 89274637, 'score': 1052.4626715183258, 'total_duration': 3458.198306322098, 'global_step': 800, 'preemption_count': 0})], 'global_step': 800}
I0405 06:06:45.644404 140222196610880 submission_runner.py:553] Timing: 1052.4626715183258
I0405 06:06:45.644456 140222196610880 submission_runner.py:554] ====================
I0405 06:06:45.644564 140222196610880 submission_runner.py:613] Final criteo1tb score: 1052.4626715183258
