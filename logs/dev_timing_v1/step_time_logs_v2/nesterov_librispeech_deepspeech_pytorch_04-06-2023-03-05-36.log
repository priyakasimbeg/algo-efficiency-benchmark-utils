WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
I0406 03:05:52.307937 140563757188928 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 7
I0406 03:05:52.307965 140651988621120 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 4
I0406 03:05:52.308713 139752159610688 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 2
I0406 03:05:52.308755 139952926783296 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 5
I0406 03:05:52.308843 140556319041344 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 1
I0406 03:05:52.309121 140025738774336 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 6
I0406 03:05:52.309799 140664354391872 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 3
I0406 03:05:52.319235 140361875687232 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 0
I0406 03:05:52.319446 139952926783296 distributed_c10d.py:353] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 03:05:52.319480 140556319041344 distributed_c10d.py:353] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 03:05:52.319495 139752159610688 distributed_c10d.py:353] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 03:05:52.319613 140361875687232 distributed_c10d.py:353] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 03:05:52.319651 140025738774336 distributed_c10d.py:353] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 03:05:52.320368 140664354391872 distributed_c10d.py:353] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 03:05:52.328846 140651988621120 distributed_c10d.py:353] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 03:05:52.328875 140563757188928 distributed_c10d.py:353] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 03:05:52.727737 140361875687232 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_v2/timing_nesterov/librispeech_deepspeech_pytorch.
W0406 03:05:52.758499 139752159610688 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 03:05:52.758757 140563757188928 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 03:05:52.759096 140664354391872 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 03:05:52.759150 140556319041344 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 03:05:52.759998 140025738774336 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 03:05:52.760127 139952926783296 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 03:05:52.760386 140651988621120 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 03:05:52.804770 140361875687232 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0406 03:05:52.808421 140361875687232 submission_runner.py:511] Using RNG seed 3053311741
I0406 03:05:52.809495 140361875687232 submission_runner.py:520] --- Tuning run 1/1 ---
I0406 03:05:52.809596 140361875687232 submission_runner.py:525] Creating tuning directory at /experiment_runs/timing_v2/timing_nesterov/librispeech_deepspeech_pytorch/trial_1.
I0406 03:05:52.809788 140361875687232 logger_utils.py:84] Saving hparams to /experiment_runs/timing_v2/timing_nesterov/librispeech_deepspeech_pytorch/trial_1/hparams.json.
I0406 03:05:52.810674 140361875687232 submission_runner.py:230] Starting train once: RAM USED (GB) 5.750468608
I0406 03:05:52.810763 140361875687232 submission_runner.py:231] Initializing dataset.
I0406 03:05:52.810844 140361875687232 input_pipeline.py:20] Loading split = train-clean-100
I0406 03:05:52.838147 140361875687232 input_pipeline.py:20] Loading split = train-clean-360
I0406 03:05:53.171623 140361875687232 input_pipeline.py:20] Loading split = train-other-500
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
I0406 03:05:53.583847 140361875687232 submission_runner.py:239] After Initializing dataset: RAM USED (GB) 6.000582656
I0406 03:05:53.584001 140361875687232 submission_runner.py:240] Initializing model.
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
I0406 03:06:00.991735 140361875687232 submission_runner.py:251] After Initializing model: RAM USED (GB) 22.162788352
I0406 03:06:00.991936 140361875687232 submission_runner.py:252] Initializing optimizer.
I0406 03:06:01.184971 140361875687232 submission_runner.py:260] After Initializing metrics bundle: RAM USED (GB) 21.30245632
I0406 03:06:01.185154 140361875687232 submission_runner.py:261] Initializing metrics bundle.
I0406 03:06:01.185207 140361875687232 submission_runner.py:276] Initializing checkpoint and logger.
I0406 03:06:01.186367 140361875687232 logger_utils.py:231] Unable to record workload.train_mean information. Continuing without it.
I0406 03:06:01.186487 140361875687232 logger_utils.py:231] Unable to record workload.train_stddev information. Continuing without it.
I0406 03:06:02.042548 140361875687232 submission_runner.py:297] Saving meta data to /experiment_runs/timing_v2/timing_nesterov/librispeech_deepspeech_pytorch/trial_1/meta_data_0.json.
I0406 03:06:02.043495 140361875687232 submission_runner.py:300] Saving flags to /experiment_runs/timing_v2/timing_nesterov/librispeech_deepspeech_pytorch/trial_1/flags_0.json.
I0406 03:06:02.046678 140361875687232 submission_runner.py:305] After checkpoint and logger metrics bundle: RAM USED (GB) 21.295087616
I0406 03:06:02.047727 140361875687232 submission_runner.py:312] Before starting training loop and logger metrics bundle: RAM USED (GB) 21.295071232
I0406 03:06:02.047822 140361875687232 submission_runner.py:313] Starting training loop.
I0406 03:06:04.411794 140361875687232 submission_runner.py:335] After dataselection batch at step 0: RAM USED (GB) 25.706438656
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
I0406 03:06:10.957633 140335573366528 logging_writer.py:48] [0] global_step=0, grad_norm=25.134167, loss=33.548054
I0406 03:06:10.967458 140361875687232 submission.py:139] 0) loss = 33.548, grad_norm = 25.134
I0406 03:06:10.968180 140361875687232 submission_runner.py:352] After update parameters step 0: RAM USED (GB) 31.598145536
I0406 03:06:10.968764 140361875687232 submission_runner.py:373] Before eval at step 1: RAM USED (GB) 31.598145536
I0406 03:06:10.968879 140361875687232 spec.py:298] Evaluating on the training split.
I0406 03:06:10.969607 140361875687232 input_pipeline.py:20] Loading split = train-clean-100
I0406 03:06:10.998053 140361875687232 input_pipeline.py:20] Loading split = train-clean-360
I0406 03:06:11.404462 140361875687232 input_pipeline.py:20] Loading split = train-other-500
I0406 03:06:25.985974 140361875687232 spec.py:310] Evaluating on the validation split.
I0406 03:06:25.987148 140361875687232 input_pipeline.py:20] Loading split = dev-clean
I0406 03:06:25.991371 140361875687232 input_pipeline.py:20] Loading split = dev-other
I0406 03:06:36.970950 140361875687232 spec.py:326] Evaluating on the test split.
I0406 03:06:36.972421 140361875687232 input_pipeline.py:20] Loading split = test-clean
I0406 03:06:43.617661 140361875687232 submission_runner.py:382] Time since start: 8.92s, 	Step: 1, 	{'train/ctc_loss': 32.33188192332754, 'train/wer': 2.7004943927308567, 'validation/ctc_loss': 31.215858574442436, 'validation/wer': 2.4866122724858783, 'validation/num_examples': 5348, 'test/ctc_loss': 31.299477385637783, 'test/wer': 2.626530985314728, 'test/num_examples': 2472}
I0406 03:06:43.618560 140361875687232 submission_runner.py:396] After eval at step 1: RAM USED (GB) 45.288521728
I0406 03:06:43.631959 140332477966080 logging_writer.py:48] [1] global_step=1, preemption_count=0, score=8.919564, test/ctc_loss=31.299477, test/num_examples=2472, test/wer=2.626531, total_duration=8.921500, train/ctc_loss=32.331882, train/wer=2.700494, validation/ctc_loss=31.215859, validation/num_examples=5348, validation/wer=2.486612
I0406 03:06:43.839656 140361875687232 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v2/timing_nesterov/librispeech_deepspeech_pytorch/trial_1/checkpoint_1.
I0406 03:06:43.840194 140361875687232 submission_runner.py:416] After logging and checkpointing eval at step 1: RAM USED (GB) 45.315776512
I0406 03:06:43.842633 140361875687232 submission_runner.py:335] After dataselection batch at step 1: RAM USED (GB) 45.319380992
I0406 03:06:43.882007 140361875687232 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 03:06:43.883397 140563757188928 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 03:06:43.883459 140651988621120 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 03:06:43.883445 139752159610688 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 03:06:43.884302 140664354391872 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 03:06:43.884295 139952926783296 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 03:06:43.885154 140025738774336 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 03:06:43.885129 140556319041344 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 03:06:44.935830 140332469573376 logging_writer.py:48] [1] global_step=1, grad_norm=25.582705, loss=32.891884
I0406 03:06:44.939315 140361875687232 submission.py:139] 1) loss = 32.892, grad_norm = 25.583
I0406 03:06:44.940352 140361875687232 submission_runner.py:352] After update parameters step 1: RAM USED (GB) 45.47577856
I0406 03:06:45.900046 140332477966080 logging_writer.py:48] [2] global_step=2, grad_norm=33.455055, loss=33.368740
I0406 03:06:45.903422 140361875687232 submission.py:139] 2) loss = 33.369, grad_norm = 33.455
I0406 03:06:46.733839 140332469573376 logging_writer.py:48] [3] global_step=3, grad_norm=58.179790, loss=32.868210
I0406 03:06:46.737609 140361875687232 submission.py:139] 3) loss = 32.868, grad_norm = 58.180
I0406 03:06:47.577718 140332477966080 logging_writer.py:48] [4] global_step=4, grad_norm=68.417221, loss=30.519295
I0406 03:06:47.580686 140361875687232 submission.py:139] 4) loss = 30.519, grad_norm = 68.417
I0406 03:06:48.393714 140332469573376 logging_writer.py:48] [5] global_step=5, grad_norm=41.313179, loss=28.410137
I0406 03:06:48.396800 140361875687232 submission.py:139] 5) loss = 28.410, grad_norm = 41.313
I0406 03:06:49.206920 140332477966080 logging_writer.py:48] [6] global_step=6, grad_norm=30.093647, loss=27.148563
I0406 03:06:49.209853 140361875687232 submission.py:139] 6) loss = 27.149, grad_norm = 30.094
I0406 03:06:50.018932 140332469573376 logging_writer.py:48] [7] global_step=7, grad_norm=24.412758, loss=25.310574
I0406 03:06:50.022230 140361875687232 submission.py:139] 7) loss = 25.311, grad_norm = 24.413
I0406 03:06:50.831153 140332477966080 logging_writer.py:48] [8] global_step=8, grad_norm=24.140491, loss=24.472527
I0406 03:06:50.834318 140361875687232 submission.py:139] 8) loss = 24.473, grad_norm = 24.140
I0406 03:06:51.645141 140332469573376 logging_writer.py:48] [9] global_step=9, grad_norm=23.489521, loss=23.182037
I0406 03:06:51.648197 140361875687232 submission.py:139] 9) loss = 23.182, grad_norm = 23.490
I0406 03:06:52.449038 140332477966080 logging_writer.py:48] [10] global_step=10, grad_norm=24.248936, loss=21.802942
I0406 03:06:52.452134 140361875687232 submission.py:139] 10) loss = 21.803, grad_norm = 24.249
I0406 03:06:53.255796 140332469573376 logging_writer.py:48] [11] global_step=11, grad_norm=21.839754, loss=20.759544
I0406 03:06:53.258820 140361875687232 submission.py:139] 11) loss = 20.760, grad_norm = 21.840
I0406 03:06:54.080213 140332477966080 logging_writer.py:48] [12] global_step=12, grad_norm=20.160833, loss=19.239252
I0406 03:06:54.083284 140361875687232 submission.py:139] 12) loss = 19.239, grad_norm = 20.161
I0406 03:06:54.888027 140332469573376 logging_writer.py:48] [13] global_step=13, grad_norm=18.205641, loss=17.715233
I0406 03:06:54.891239 140361875687232 submission.py:139] 13) loss = 17.715, grad_norm = 18.206
I0406 03:06:55.694788 140332477966080 logging_writer.py:48] [14] global_step=14, grad_norm=16.214811, loss=16.585272
I0406 03:06:55.697816 140361875687232 submission.py:139] 14) loss = 16.585, grad_norm = 16.215
I0406 03:06:56.496759 140332469573376 logging_writer.py:48] [15] global_step=15, grad_norm=13.760155, loss=15.148315
I0406 03:06:56.500014 140361875687232 submission.py:139] 15) loss = 15.148, grad_norm = 13.760
I0406 03:06:57.309113 140332477966080 logging_writer.py:48] [16] global_step=16, grad_norm=12.964746, loss=14.469238
I0406 03:06:57.311955 140361875687232 submission.py:139] 16) loss = 14.469, grad_norm = 12.965
I0406 03:06:58.116062 140332469573376 logging_writer.py:48] [17] global_step=17, grad_norm=11.043379, loss=13.179450
I0406 03:06:58.119126 140361875687232 submission.py:139] 17) loss = 13.179, grad_norm = 11.043
I0406 03:06:58.921570 140332477966080 logging_writer.py:48] [18] global_step=18, grad_norm=10.300152, loss=12.465946
I0406 03:06:58.924423 140361875687232 submission.py:139] 18) loss = 12.466, grad_norm = 10.300
I0406 03:06:59.728484 140332469573376 logging_writer.py:48] [19] global_step=19, grad_norm=10.854466, loss=11.633185
I0406 03:06:59.731571 140361875687232 submission.py:139] 19) loss = 11.633, grad_norm = 10.854
I0406 03:07:00.534094 140332477966080 logging_writer.py:48] [20] global_step=20, grad_norm=9.532014, loss=10.867981
I0406 03:07:00.537234 140361875687232 submission.py:139] 20) loss = 10.868, grad_norm = 9.532
I0406 03:07:01.342684 140332469573376 logging_writer.py:48] [21] global_step=21, grad_norm=7.376887, loss=10.594631
I0406 03:07:01.346440 140361875687232 submission.py:139] 21) loss = 10.595, grad_norm = 7.377
I0406 03:07:02.149269 140332477966080 logging_writer.py:48] [22] global_step=22, grad_norm=7.885941, loss=10.448584
I0406 03:07:02.152336 140361875687232 submission.py:139] 22) loss = 10.449, grad_norm = 7.886
I0406 03:07:02.959360 140332469573376 logging_writer.py:48] [23] global_step=23, grad_norm=9.233633, loss=10.181518
I0406 03:07:02.962688 140361875687232 submission.py:139] 23) loss = 10.182, grad_norm = 9.234
I0406 03:07:03.782343 140332477966080 logging_writer.py:48] [24] global_step=24, grad_norm=9.291893, loss=9.952106
I0406 03:07:03.785365 140361875687232 submission.py:139] 24) loss = 9.952, grad_norm = 9.292
I0406 03:07:04.592550 140332469573376 logging_writer.py:48] [25] global_step=25, grad_norm=9.648528, loss=10.081126
I0406 03:07:04.595710 140361875687232 submission.py:139] 25) loss = 10.081, grad_norm = 9.649
I0406 03:07:05.401111 140332477966080 logging_writer.py:48] [26] global_step=26, grad_norm=4.907302, loss=9.305117
I0406 03:07:05.404037 140361875687232 submission.py:139] 26) loss = 9.305, grad_norm = 4.907
I0406 03:07:06.209990 140332469573376 logging_writer.py:48] [27] global_step=27, grad_norm=4.771773, loss=9.187788
I0406 03:07:06.213051 140361875687232 submission.py:139] 27) loss = 9.188, grad_norm = 4.772
I0406 03:07:07.018190 140332477966080 logging_writer.py:48] [28] global_step=28, grad_norm=5.206673, loss=9.242428
I0406 03:07:07.021309 140361875687232 submission.py:139] 28) loss = 9.242, grad_norm = 5.207
I0406 03:07:07.827729 140332469573376 logging_writer.py:48] [29] global_step=29, grad_norm=7.078321, loss=8.975315
I0406 03:07:07.830701 140361875687232 submission.py:139] 29) loss = 8.975, grad_norm = 7.078
I0406 03:07:08.631922 140332477966080 logging_writer.py:48] [30] global_step=30, grad_norm=13.354870, loss=8.983716
I0406 03:07:08.634931 140361875687232 submission.py:139] 30) loss = 8.984, grad_norm = 13.355
I0406 03:07:09.447658 140332469573376 logging_writer.py:48] [31] global_step=31, grad_norm=10.071889, loss=8.901332
I0406 03:07:09.450646 140361875687232 submission.py:139] 31) loss = 8.901, grad_norm = 10.072
I0406 03:07:10.251905 140332477966080 logging_writer.py:48] [32] global_step=32, grad_norm=8.613627, loss=8.663669
I0406 03:07:10.255307 140361875687232 submission.py:139] 32) loss = 8.664, grad_norm = 8.614
I0406 03:07:11.059604 140332469573376 logging_writer.py:48] [33] global_step=33, grad_norm=13.381246, loss=8.539041
I0406 03:07:11.062641 140361875687232 submission.py:139] 33) loss = 8.539, grad_norm = 13.381
I0406 03:07:11.865475 140332477966080 logging_writer.py:48] [34] global_step=34, grad_norm=10.221591, loss=8.338324
I0406 03:07:11.868535 140361875687232 submission.py:139] 34) loss = 8.338, grad_norm = 10.222
I0406 03:07:12.676379 140332469573376 logging_writer.py:48] [35] global_step=35, grad_norm=13.677674, loss=8.054264
I0406 03:07:12.679538 140361875687232 submission.py:139] 35) loss = 8.054, grad_norm = 13.678
I0406 03:07:13.478063 140332477966080 logging_writer.py:48] [36] global_step=36, grad_norm=13.632973, loss=8.410169
I0406 03:07:13.481003 140361875687232 submission.py:139] 36) loss = 8.410, grad_norm = 13.633
I0406 03:07:14.283120 140332469573376 logging_writer.py:48] [37] global_step=37, grad_norm=5.490434, loss=7.742381
I0406 03:07:14.286228 140361875687232 submission.py:139] 37) loss = 7.742, grad_norm = 5.490
I0406 03:07:15.093053 140332477966080 logging_writer.py:48] [38] global_step=38, grad_norm=3.318099, loss=7.604606
I0406 03:07:15.096152 140361875687232 submission.py:139] 38) loss = 7.605, grad_norm = 3.318
I0406 03:07:15.903928 140332469573376 logging_writer.py:48] [39] global_step=39, grad_norm=5.422840, loss=7.516831
I0406 03:07:15.907000 140361875687232 submission.py:139] 39) loss = 7.517, grad_norm = 5.423
I0406 03:07:16.712841 140332477966080 logging_writer.py:48] [40] global_step=40, grad_norm=12.098553, loss=7.591747
I0406 03:07:16.715920 140361875687232 submission.py:139] 40) loss = 7.592, grad_norm = 12.099
I0406 03:07:17.522396 140332469573376 logging_writer.py:48] [41] global_step=41, grad_norm=27.642538, loss=7.925507
I0406 03:07:17.525663 140361875687232 submission.py:139] 41) loss = 7.926, grad_norm = 27.643
I0406 03:07:18.330791 140332477966080 logging_writer.py:48] [42] global_step=42, grad_norm=15.975530, loss=8.190798
I0406 03:07:18.333749 140361875687232 submission.py:139] 42) loss = 8.191, grad_norm = 15.976
I0406 03:07:19.138592 140332469573376 logging_writer.py:48] [43] global_step=43, grad_norm=8.220658, loss=7.681870
I0406 03:07:19.141559 140361875687232 submission.py:139] 43) loss = 7.682, grad_norm = 8.221
I0406 03:07:19.951211 140332477966080 logging_writer.py:48] [44] global_step=44, grad_norm=9.452815, loss=7.629405
I0406 03:07:19.954139 140361875687232 submission.py:139] 44) loss = 7.629, grad_norm = 9.453
I0406 03:07:20.761019 140332469573376 logging_writer.py:48] [45] global_step=45, grad_norm=7.806608, loss=7.334276
I0406 03:07:20.763955 140361875687232 submission.py:139] 45) loss = 7.334, grad_norm = 7.807
I0406 03:07:21.576050 140332477966080 logging_writer.py:48] [46] global_step=46, grad_norm=15.724468, loss=7.309309
I0406 03:07:21.579092 140361875687232 submission.py:139] 46) loss = 7.309, grad_norm = 15.724
I0406 03:07:22.392690 140332469573376 logging_writer.py:48] [47] global_step=47, grad_norm=9.773824, loss=7.288947
I0406 03:07:22.395622 140361875687232 submission.py:139] 47) loss = 7.289, grad_norm = 9.774
I0406 03:07:23.201400 140332477966080 logging_writer.py:48] [48] global_step=48, grad_norm=5.134829, loss=6.995173
I0406 03:07:23.204342 140361875687232 submission.py:139] 48) loss = 6.995, grad_norm = 5.135
I0406 03:07:24.007208 140332469573376 logging_writer.py:48] [49] global_step=49, grad_norm=4.445643, loss=6.944561
I0406 03:07:24.010302 140361875687232 submission.py:139] 49) loss = 6.945, grad_norm = 4.446
I0406 03:07:24.825815 140332477966080 logging_writer.py:48] [50] global_step=50, grad_norm=6.752917, loss=6.968069
I0406 03:07:24.829026 140361875687232 submission.py:139] 50) loss = 6.968, grad_norm = 6.753
I0406 03:07:25.635748 140332469573376 logging_writer.py:48] [51] global_step=51, grad_norm=7.897501, loss=6.940065
I0406 03:07:25.638672 140361875687232 submission.py:139] 51) loss = 6.940, grad_norm = 7.898
I0406 03:07:26.441272 140332477966080 logging_writer.py:48] [52] global_step=52, grad_norm=9.621214, loss=6.934155
I0406 03:07:26.444149 140361875687232 submission.py:139] 52) loss = 6.934, grad_norm = 9.621
I0406 03:07:27.250916 140332469573376 logging_writer.py:48] [53] global_step=53, grad_norm=8.561513, loss=6.958976
I0406 03:07:27.253906 140361875687232 submission.py:139] 53) loss = 6.959, grad_norm = 8.562
I0406 03:07:28.056553 140332477966080 logging_writer.py:48] [54] global_step=54, grad_norm=6.051393, loss=6.852760
I0406 03:07:28.059596 140361875687232 submission.py:139] 54) loss = 6.853, grad_norm = 6.051
I0406 03:07:28.864783 140332469573376 logging_writer.py:48] [55] global_step=55, grad_norm=4.229286, loss=6.751659
I0406 03:07:28.867865 140361875687232 submission.py:139] 55) loss = 6.752, grad_norm = 4.229
I0406 03:07:29.673518 140332477966080 logging_writer.py:48] [56] global_step=56, grad_norm=6.355830, loss=6.682008
I0406 03:07:29.676627 140361875687232 submission.py:139] 56) loss = 6.682, grad_norm = 6.356
I0406 03:07:30.485665 140332469573376 logging_writer.py:48] [57] global_step=57, grad_norm=7.640220, loss=6.700017
I0406 03:07:30.488644 140361875687232 submission.py:139] 57) loss = 6.700, grad_norm = 7.640
I0406 03:07:31.291153 140332477966080 logging_writer.py:48] [58] global_step=58, grad_norm=9.943148, loss=6.721550
I0406 03:07:31.294126 140361875687232 submission.py:139] 58) loss = 6.722, grad_norm = 9.943
I0406 03:07:32.101206 140332469573376 logging_writer.py:48] [59] global_step=59, grad_norm=10.001635, loss=6.773966
I0406 03:07:32.104173 140361875687232 submission.py:139] 59) loss = 6.774, grad_norm = 10.002
I0406 03:07:32.903465 140332477966080 logging_writer.py:48] [60] global_step=60, grad_norm=7.283667, loss=6.585324
I0406 03:07:32.906687 140361875687232 submission.py:139] 60) loss = 6.585, grad_norm = 7.284
I0406 03:07:33.716805 140332469573376 logging_writer.py:48] [61] global_step=61, grad_norm=6.967655, loss=6.586633
I0406 03:07:33.720296 140361875687232 submission.py:139] 61) loss = 6.587, grad_norm = 6.968
I0406 03:07:34.527223 140332477966080 logging_writer.py:48] [62] global_step=62, grad_norm=8.357697, loss=6.550545
I0406 03:07:34.530415 140361875687232 submission.py:139] 62) loss = 6.551, grad_norm = 8.358
I0406 03:07:35.339152 140332469573376 logging_writer.py:48] [63] global_step=63, grad_norm=8.492640, loss=6.601395
I0406 03:07:35.342233 140361875687232 submission.py:139] 63) loss = 6.601, grad_norm = 8.493
I0406 03:07:36.147708 140332477966080 logging_writer.py:48] [64] global_step=64, grad_norm=9.467393, loss=6.502338
I0406 03:07:36.150826 140361875687232 submission.py:139] 64) loss = 6.502, grad_norm = 9.467
I0406 03:07:36.954993 140332469573376 logging_writer.py:48] [65] global_step=65, grad_norm=8.061207, loss=6.564651
I0406 03:07:36.958057 140361875687232 submission.py:139] 65) loss = 6.565, grad_norm = 8.061
I0406 03:07:37.760958 140332477966080 logging_writer.py:48] [66] global_step=66, grad_norm=3.836755, loss=6.409326
I0406 03:07:37.763898 140361875687232 submission.py:139] 66) loss = 6.409, grad_norm = 3.837
I0406 03:07:38.568927 140332469573376 logging_writer.py:48] [67] global_step=67, grad_norm=2.353821, loss=6.351218
I0406 03:07:38.572086 140361875687232 submission.py:139] 67) loss = 6.351, grad_norm = 2.354
I0406 03:07:39.378079 140332477966080 logging_writer.py:48] [68] global_step=68, grad_norm=4.328395, loss=6.357788
I0406 03:07:39.381219 140361875687232 submission.py:139] 68) loss = 6.358, grad_norm = 4.328
I0406 03:07:40.201992 140332469573376 logging_writer.py:48] [69] global_step=69, grad_norm=4.343725, loss=6.378069
I0406 03:07:40.205336 140361875687232 submission.py:139] 69) loss = 6.378, grad_norm = 4.344
I0406 03:07:41.011275 140332477966080 logging_writer.py:48] [70] global_step=70, grad_norm=4.917384, loss=6.315656
I0406 03:07:41.014247 140361875687232 submission.py:139] 70) loss = 6.316, grad_norm = 4.917
I0406 03:07:41.818961 140332469573376 logging_writer.py:48] [71] global_step=71, grad_norm=6.290967, loss=6.339153
I0406 03:07:41.822094 140361875687232 submission.py:139] 71) loss = 6.339, grad_norm = 6.291
I0406 03:07:42.622427 140332477966080 logging_writer.py:48] [72] global_step=72, grad_norm=8.712421, loss=6.330673
I0406 03:07:42.625561 140361875687232 submission.py:139] 72) loss = 6.331, grad_norm = 8.712
I0406 03:07:43.431510 140332469573376 logging_writer.py:48] [73] global_step=73, grad_norm=7.418590, loss=6.391203
I0406 03:07:43.434573 140361875687232 submission.py:139] 73) loss = 6.391, grad_norm = 7.419
I0406 03:07:44.239698 140332477966080 logging_writer.py:48] [74] global_step=74, grad_norm=2.740640, loss=6.267247
I0406 03:07:44.242867 140361875687232 submission.py:139] 74) loss = 6.267, grad_norm = 2.741
I0406 03:07:45.051734 140332469573376 logging_writer.py:48] [75] global_step=75, grad_norm=1.576920, loss=6.238060
I0406 03:07:45.054677 140361875687232 submission.py:139] 75) loss = 6.238, grad_norm = 1.577
I0406 03:07:45.861436 140332477966080 logging_writer.py:48] [76] global_step=76, grad_norm=0.761845, loss=6.179965
I0406 03:07:45.864446 140361875687232 submission.py:139] 76) loss = 6.180, grad_norm = 0.762
I0406 03:07:46.672885 140332469573376 logging_writer.py:48] [77] global_step=77, grad_norm=1.244038, loss=6.188366
I0406 03:07:46.676057 140361875687232 submission.py:139] 77) loss = 6.188, grad_norm = 1.244
I0406 03:07:47.479139 140332477966080 logging_writer.py:48] [78] global_step=78, grad_norm=1.668954, loss=6.211757
I0406 03:07:47.482361 140361875687232 submission.py:139] 78) loss = 6.212, grad_norm = 1.669
I0406 03:07:48.289684 140332469573376 logging_writer.py:48] [79] global_step=79, grad_norm=3.561140, loss=6.187891
I0406 03:07:48.292824 140361875687232 submission.py:139] 79) loss = 6.188, grad_norm = 3.561
I0406 03:07:49.098703 140332477966080 logging_writer.py:48] [80] global_step=80, grad_norm=5.768435, loss=6.214670
I0406 03:07:49.102124 140361875687232 submission.py:139] 80) loss = 6.215, grad_norm = 5.768
I0406 03:07:49.907528 140332469573376 logging_writer.py:48] [81] global_step=81, grad_norm=9.009051, loss=6.247042
I0406 03:07:49.910520 140361875687232 submission.py:139] 81) loss = 6.247, grad_norm = 9.009
I0406 03:07:50.725555 140332477966080 logging_writer.py:48] [82] global_step=82, grad_norm=9.499295, loss=6.401325
I0406 03:07:50.728737 140361875687232 submission.py:139] 82) loss = 6.401, grad_norm = 9.499
I0406 03:07:51.549673 140332469573376 logging_writer.py:48] [83] global_step=83, grad_norm=7.797809, loss=6.256538
I0406 03:07:51.552763 140361875687232 submission.py:139] 83) loss = 6.257, grad_norm = 7.798
I0406 03:07:52.355977 140332477966080 logging_writer.py:48] [84] global_step=84, grad_norm=6.167116, loss=6.256370
I0406 03:07:52.359033 140361875687232 submission.py:139] 84) loss = 6.256, grad_norm = 6.167
I0406 03:07:53.189643 140332469573376 logging_writer.py:48] [85] global_step=85, grad_norm=6.244019, loss=6.167735
I0406 03:07:53.192719 140361875687232 submission.py:139] 85) loss = 6.168, grad_norm = 6.244
I0406 03:07:54.002043 140332477966080 logging_writer.py:48] [86] global_step=86, grad_norm=6.531433, loss=6.186124
I0406 03:07:54.005078 140361875687232 submission.py:139] 86) loss = 6.186, grad_norm = 6.531
I0406 03:07:54.806355 140332469573376 logging_writer.py:48] [87] global_step=87, grad_norm=9.246523, loss=6.213278
I0406 03:07:54.809503 140361875687232 submission.py:139] 87) loss = 6.213, grad_norm = 9.247
I0406 03:07:55.638604 140332477966080 logging_writer.py:48] [88] global_step=88, grad_norm=10.018368, loss=6.383596
I0406 03:07:55.641752 140361875687232 submission.py:139] 88) loss = 6.384, grad_norm = 10.018
I0406 03:07:56.446023 140332469573376 logging_writer.py:48] [89] global_step=89, grad_norm=8.188990, loss=6.259825
I0406 03:07:56.448920 140361875687232 submission.py:139] 89) loss = 6.260, grad_norm = 8.189
I0406 03:07:57.255845 140332477966080 logging_writer.py:48] [90] global_step=90, grad_norm=6.957489, loss=6.205225
I0406 03:07:57.258780 140361875687232 submission.py:139] 90) loss = 6.205, grad_norm = 6.957
I0406 03:07:58.062895 140332469573376 logging_writer.py:48] [91] global_step=91, grad_norm=7.464986, loss=6.184907
I0406 03:07:58.066188 140361875687232 submission.py:139] 91) loss = 6.185, grad_norm = 7.465
I0406 03:07:58.874326 140332477966080 logging_writer.py:48] [92] global_step=92, grad_norm=8.154119, loss=6.236335
I0406 03:07:58.877305 140361875687232 submission.py:139] 92) loss = 6.236, grad_norm = 8.154
I0406 03:07:59.687991 140332469573376 logging_writer.py:48] [93] global_step=93, grad_norm=9.933445, loss=6.235147
I0406 03:07:59.691157 140361875687232 submission.py:139] 93) loss = 6.235, grad_norm = 9.933
I0406 03:08:00.493103 140332477966080 logging_writer.py:48] [94] global_step=94, grad_norm=11.099473, loss=6.443723
I0406 03:08:00.496073 140361875687232 submission.py:139] 94) loss = 6.444, grad_norm = 11.099
I0406 03:08:01.300829 140332469573376 logging_writer.py:48] [95] global_step=95, grad_norm=10.186804, loss=6.261320
I0406 03:08:01.303799 140361875687232 submission.py:139] 95) loss = 6.261, grad_norm = 10.187
I0406 03:08:02.109840 140332477966080 logging_writer.py:48] [96] global_step=96, grad_norm=8.364958, loss=6.275843
I0406 03:08:02.113088 140361875687232 submission.py:139] 96) loss = 6.276, grad_norm = 8.365
I0406 03:08:02.918049 140332469573376 logging_writer.py:48] [97] global_step=97, grad_norm=6.709261, loss=6.160451
I0406 03:08:02.921252 140361875687232 submission.py:139] 97) loss = 6.160, grad_norm = 6.709
I0406 03:08:03.734067 140332477966080 logging_writer.py:48] [98] global_step=98, grad_norm=5.380864, loss=6.132446
I0406 03:08:03.737332 140361875687232 submission.py:139] 98) loss = 6.132, grad_norm = 5.381
I0406 03:08:04.541810 140332469573376 logging_writer.py:48] [99] global_step=99, grad_norm=5.487043, loss=6.100801
I0406 03:08:04.544872 140361875687232 submission.py:139] 99) loss = 6.101, grad_norm = 5.487
I0406 03:08:05.345861 140332477966080 logging_writer.py:48] [100] global_step=100, grad_norm=5.462025, loss=6.115310
I0406 03:08:05.348865 140361875687232 submission.py:139] 100) loss = 6.115, grad_norm = 5.462
I0406 03:13:26.069479 140332469573376 logging_writer.py:48] [500] global_step=500, grad_norm=0.470062, loss=5.735039
I0406 03:13:26.074730 140361875687232 submission.py:139] 500) loss = 5.735, grad_norm = 0.470
I0406 03:20:00.832175 140332477966080 logging_writer.py:48] [1000] global_step=1000, grad_norm=nan, loss=nan
I0406 03:20:00.836282 140361875687232 submission.py:139] 1000) loss = nan, grad_norm = nan
I0406 03:26:30.615347 140332477966080 logging_writer.py:48] [1500] global_step=1500, grad_norm=nan, loss=nan
I0406 03:26:30.622107 140361875687232 submission.py:139] 1500) loss = nan, grad_norm = nan
I0406 03:32:58.751878 140332469573376 logging_writer.py:48] [2000] global_step=2000, grad_norm=nan, loss=nan
I0406 03:32:58.756695 140361875687232 submission.py:139] 2000) loss = nan, grad_norm = nan
I0406 03:39:30.193639 140332477966080 logging_writer.py:48] [2500] global_step=2500, grad_norm=nan, loss=nan
I0406 03:39:30.200626 140361875687232 submission.py:139] 2500) loss = nan, grad_norm = nan
I0406 03:45:57.863634 140332469573376 logging_writer.py:48] [3000] global_step=3000, grad_norm=nan, loss=nan
I0406 03:45:57.868353 140361875687232 submission.py:139] 3000) loss = nan, grad_norm = nan
I0406 03:46:44.283064 140361875687232 submission_runner.py:373] Before eval at step 3061: RAM USED (GB) 43.407560704
I0406 03:46:44.283281 140361875687232 spec.py:298] Evaluating on the training split.
I0406 03:46:53.855746 140361875687232 spec.py:310] Evaluating on the validation split.
I0406 03:47:02.687880 140361875687232 spec.py:326] Evaluating on the test split.
I0406 03:47:07.662347 140361875687232 submission_runner.py:382] Time since start: 2441.94s, 	Step: 3061, 	{'train/ctc_loss': nan, 'train/wer': 0.9417775395162208, 'validation/ctc_loss': nan, 'validation/wer': 0.8967218654950997, 'validation/num_examples': 5348, 'test/ctc_loss': nan, 'test/wer': 0.899579550301627, 'test/num_examples': 2472}
I0406 03:47:07.663213 140361875687232 submission_runner.py:396] After eval at step 3061: RAM USED (GB) 42.268819456
I0406 03:47:07.678144 140332477966080 logging_writer.py:48] [3061] global_step=3061, preemption_count=0, score=1494.726686, test/ctc_loss=nan, test/num_examples=2472, test/wer=0.899580, total_duration=2441.935520, train/ctc_loss=nan, train/wer=0.941778, validation/ctc_loss=nan, validation/num_examples=5348, validation/wer=0.896722
I0406 03:47:07.873507 140361875687232 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v2/timing_nesterov/librispeech_deepspeech_pytorch/trial_1/checkpoint_3061.
I0406 03:47:07.873978 140361875687232 submission_runner.py:416] After logging and checkpointing eval at step 3061: RAM USED (GB) 42.274009088
I0406 03:52:52.187575 140332477966080 logging_writer.py:48] [3500] global_step=3500, grad_norm=nan, loss=nan
I0406 03:52:52.200647 140361875687232 submission.py:139] 3500) loss = nan, grad_norm = nan
I0406 03:59:19.383279 140332469573376 logging_writer.py:48] [4000] global_step=4000, grad_norm=nan, loss=nan
I0406 03:59:19.390675 140361875687232 submission.py:139] 4000) loss = nan, grad_norm = nan
I0406 04:05:50.095153 140332477966080 logging_writer.py:48] [4500] global_step=4500, grad_norm=nan, loss=nan
I0406 04:05:50.102695 140361875687232 submission.py:139] 4500) loss = nan, grad_norm = nan
I0406 04:12:18.119842 140332469573376 logging_writer.py:48] [5000] global_step=5000, grad_norm=nan, loss=nan
I0406 04:12:18.126795 140361875687232 submission.py:139] 5000) loss = nan, grad_norm = nan
I0406 04:18:48.031291 140332477966080 logging_writer.py:48] [5500] global_step=5500, grad_norm=nan, loss=nan
I0406 04:18:48.037206 140361875687232 submission.py:139] 5500) loss = nan, grad_norm = nan
I0406 04:25:15.847776 140332469573376 logging_writer.py:48] [6000] global_step=6000, grad_norm=nan, loss=nan
I0406 04:25:15.855395 140361875687232 submission.py:139] 6000) loss = nan, grad_norm = nan
I0406 04:27:08.479751 140361875687232 submission_runner.py:373] Before eval at step 6146: RAM USED (GB) 42.307731456
I0406 04:27:08.479959 140361875687232 spec.py:298] Evaluating on the training split.
I0406 04:27:18.082377 140361875687232 spec.py:310] Evaluating on the validation split.
I0406 04:27:27.273849 140361875687232 spec.py:326] Evaluating on the test split.
I0406 04:27:32.601699 140361875687232 submission_runner.py:382] Time since start: 4866.12s, 	Step: 6146, 	{'train/ctc_loss': nan, 'train/wer': 0.9417775395162208, 'validation/ctc_loss': nan, 'validation/wer': 0.8967218654950997, 'validation/num_examples': 5348, 'test/ctc_loss': nan, 'test/wer': 0.899579550301627, 'test/num_examples': 2472}
I0406 04:27:32.602452 140361875687232 submission_runner.py:396] After eval at step 6146: RAM USED (GB) 42.091167744
I0406 04:27:32.619513 140332477966080 logging_writer.py:48] [6146] global_step=6146, preemption_count=0, score=2954.592504, test/ctc_loss=nan, test/num_examples=2472, test/wer=0.899580, total_duration=4866.121654, train/ctc_loss=nan, train/wer=0.941778, validation/ctc_loss=nan, validation/num_examples=5348, validation/wer=0.896722
I0406 04:27:32.818566 140361875687232 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v2/timing_nesterov/librispeech_deepspeech_pytorch/trial_1/checkpoint_6146.
I0406 04:27:32.819048 140361875687232 submission_runner.py:416] After logging and checkpointing eval at step 6146: RAM USED (GB) 42.096164864
I0406 04:32:11.266155 140332477966080 logging_writer.py:48] [6500] global_step=6500, grad_norm=nan, loss=nan
I0406 04:32:11.271959 140361875687232 submission.py:139] 6500) loss = nan, grad_norm = nan
I0406 04:38:39.039952 140332469573376 logging_writer.py:48] [7000] global_step=7000, grad_norm=nan, loss=nan
I0406 04:38:39.044690 140361875687232 submission.py:139] 7000) loss = nan, grad_norm = nan
I0406 04:45:08.812320 140332477966080 logging_writer.py:48] [7500] global_step=7500, grad_norm=nan, loss=nan
I0406 04:45:08.819074 140361875687232 submission.py:139] 7500) loss = nan, grad_norm = nan
I0406 04:51:35.189884 140361875687232 submission_runner.py:373] Before eval at step 8000: RAM USED (GB) 42.193199104
I0406 04:51:35.190135 140361875687232 spec.py:298] Evaluating on the training split.
I0406 04:51:44.856087 140361875687232 spec.py:310] Evaluating on the validation split.
I0406 04:51:53.527206 140361875687232 spec.py:326] Evaluating on the test split.
I0406 04:51:58.644584 140361875687232 submission_runner.py:382] Time since start: 6332.85s, 	Step: 8000, 	{'train/ctc_loss': nan, 'train/wer': 0.9417775395162208, 'validation/ctc_loss': nan, 'validation/wer': 0.8967218654950997, 'validation/num_examples': 5348, 'test/ctc_loss': nan, 'test/wer': 0.899579550301627, 'test/num_examples': 2472}
I0406 04:51:58.645364 140361875687232 submission_runner.py:396] After eval at step 8000: RAM USED (GB) 42.002468864
I0406 04:51:58.663370 140332477966080 logging_writer.py:48] [8000] global_step=8000, preemption_count=0, score=3830.559714, test/ctc_loss=nan, test/num_examples=2472, test/wer=0.899580, total_duration=6332.851665, train/ctc_loss=nan, train/wer=0.941778, validation/ctc_loss=nan, validation/num_examples=5348, validation/wer=0.896722
I0406 04:51:58.864231 140361875687232 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v2/timing_nesterov/librispeech_deepspeech_pytorch/trial_1/checkpoint_8000.
I0406 04:51:58.864721 140361875687232 submission_runner.py:416] After logging and checkpointing eval at step 8000: RAM USED (GB) 42.00753152
I0406 04:51:58.875896 140332469573376 logging_writer.py:48] [8000] global_step=8000, preemption_count=0, score=3830.559714
I0406 04:51:59.211103 140361875687232 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v2/timing_nesterov/librispeech_deepspeech_pytorch/trial_1/checkpoint_8000.
I0406 04:51:59.360958 140361875687232 submission_runner.py:550] Tuning trial 1/1
I0406 04:51:59.361212 140361875687232 submission_runner.py:551] Hyperparameters: Hyperparameters(learning_rate=0.4394877561366806, one_minus_beta1=0.07113602458522507, warmup_factor=0.05, weight_decay=9.611851572925426e-07, label_smoothing=0.2, dropout_rate=0.0, decay_steps_factor=0.9, end_factor=0.001)
I0406 04:51:59.361612 140361875687232 submission_runner.py:552] Metrics: {'eval_results': [(1, {'train/ctc_loss': 32.33188192332754, 'train/wer': 2.7004943927308567, 'validation/ctc_loss': 31.215858574442436, 'validation/wer': 2.4866122724858783, 'validation/num_examples': 5348, 'test/ctc_loss': 31.299477385637783, 'test/wer': 2.626530985314728, 'test/num_examples': 2472, 'score': 8.919564247131348, 'total_duration': 8.921500444412231, 'global_step': 1, 'preemption_count': 0}), (3061, {'train/ctc_loss': nan, 'train/wer': 0.9417775395162208, 'validation/ctc_loss': nan, 'validation/wer': 0.8967218654950997, 'validation/num_examples': 5348, 'test/ctc_loss': nan, 'test/wer': 0.899579550301627, 'test/num_examples': 2472, 'score': 1494.7266855239868, 'total_duration': 2441.935519695282, 'global_step': 3061, 'preemption_count': 0}), (6146, {'train/ctc_loss': nan, 'train/wer': 0.9417775395162208, 'validation/ctc_loss': nan, 'validation/wer': 0.8967218654950997, 'validation/num_examples': 5348, 'test/ctc_loss': nan, 'test/wer': 0.899579550301627, 'test/num_examples': 2472, 'score': 2954.592503786087, 'total_duration': 4866.121653556824, 'global_step': 6146, 'preemption_count': 0}), (8000, {'train/ctc_loss': nan, 'train/wer': 0.9417775395162208, 'validation/ctc_loss': nan, 'validation/wer': 0.8967218654950997, 'validation/num_examples': 5348, 'test/ctc_loss': nan, 'test/wer': 0.899579550301627, 'test/num_examples': 2472, 'score': 3830.559714317322, 'total_duration': 6332.851664543152, 'global_step': 8000, 'preemption_count': 0})], 'global_step': 8000}
I0406 04:51:59.361708 140361875687232 submission_runner.py:553] Timing: 3830.559714317322
I0406 04:51:59.361752 140361875687232 submission_runner.py:554] ====================
I0406 04:51:59.361941 140361875687232 submission_runner.py:613] Final librispeech_deepspeech score: 3830.559714317322
