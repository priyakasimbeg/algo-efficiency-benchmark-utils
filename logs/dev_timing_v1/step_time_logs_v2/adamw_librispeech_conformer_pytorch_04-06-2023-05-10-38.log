WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
I0406 05:11:00.728170 140394205820736 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 6
I0406 05:11:00.728147 139785043404608 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 1
I0406 05:11:00.728207 140481733093184 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 5
I0406 05:11:00.728239 139663252813632 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 7
I0406 05:11:00.728737 140074475947840 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 3
I0406 05:11:00.729552 140080998569792 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 2
I0406 05:11:01.711138 140159620630336 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 4
I0406 05:11:01.714848 140604226451264 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 0
I0406 05:11:01.715199 140604226451264 distributed_c10d.py:353] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 05:11:01.720354 140481733093184 distributed_c10d.py:353] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 05:11:01.720386 140074475947840 distributed_c10d.py:353] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 05:11:01.721987 140159620630336 distributed_c10d.py:353] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 05:11:01.723849 139785043404608 distributed_c10d.py:353] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 05:11:01.723874 140080998569792 distributed_c10d.py:353] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 05:11:01.723903 140394205820736 distributed_c10d.py:353] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 05:11:01.723947 139663252813632 distributed_c10d.py:353] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0406 05:11:02.255599 140604226451264 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_v2/timing_adamw/librispeech_conformer_pytorch.
W0406 05:11:02.264711 140080998569792 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 05:11:02.264821 139663252813632 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 05:11:02.265433 140159620630336 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 05:11:02.267064 140394205820736 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 05:11:02.267182 140481733093184 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 05:11:02.267342 140074475947840 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 05:11:02.267508 139785043404608 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0406 05:11:02.288197 140604226451264 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0406 05:11:02.291793 140604226451264 submission_runner.py:511] Using RNG seed 2695052222
I0406 05:11:02.292946 140604226451264 submission_runner.py:520] --- Tuning run 1/1 ---
I0406 05:11:02.293062 140604226451264 submission_runner.py:525] Creating tuning directory at /experiment_runs/timing_v2/timing_adamw/librispeech_conformer_pytorch/trial_1.
I0406 05:11:02.293296 140604226451264 logger_utils.py:84] Saving hparams to /experiment_runs/timing_v2/timing_adamw/librispeech_conformer_pytorch/trial_1/hparams.json.
I0406 05:11:02.294288 140604226451264 submission_runner.py:230] Starting train once: RAM USED (GB) 5.776502784
I0406 05:11:02.294394 140604226451264 submission_runner.py:231] Initializing dataset.
I0406 05:11:02.294484 140604226451264 input_pipeline.py:20] Loading split = train-clean-100
I0406 05:11:02.323654 140604226451264 input_pipeline.py:20] Loading split = train-clean-360
I0406 05:11:02.642624 140604226451264 input_pipeline.py:20] Loading split = train-other-500
I0406 05:11:03.057809 140604226451264 submission_runner.py:239] After Initializing dataset: RAM USED (GB) 5.994487808
I0406 05:11:03.058003 140604226451264 submission_runner.py:240] Initializing model.
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
I0406 05:11:10.002848 140604226451264 submission_runner.py:251] After Initializing model: RAM USED (GB) 19.186188288
I0406 05:11:10.003040 140604226451264 submission_runner.py:252] Initializing optimizer.
I0406 05:11:10.004130 140604226451264 submission_runner.py:260] After Initializing metrics bundle: RAM USED (GB) 19.186188288
I0406 05:11:10.004259 140604226451264 submission_runner.py:261] Initializing metrics bundle.
I0406 05:11:10.004315 140604226451264 submission_runner.py:276] Initializing checkpoint and logger.
I0406 05:11:10.005501 140604226451264 logger_utils.py:231] Unable to record workload.train_mean information. Continuing without it.
I0406 05:11:10.005623 140604226451264 logger_utils.py:231] Unable to record workload.train_stddev information. Continuing without it.
I0406 05:11:10.782020 140604226451264 submission_runner.py:297] Saving meta data to /experiment_runs/timing_v2/timing_adamw/librispeech_conformer_pytorch/trial_1/meta_data_0.json.
I0406 05:11:10.782813 140604226451264 submission_runner.py:300] Saving flags to /experiment_runs/timing_v2/timing_adamw/librispeech_conformer_pytorch/trial_1/flags_0.json.
I0406 05:11:10.787312 140604226451264 submission_runner.py:305] After checkpoint and logger metrics bundle: RAM USED (GB) 19.18947328
I0406 05:11:10.788279 140604226451264 submission_runner.py:312] Before starting training loop and logger metrics bundle: RAM USED (GB) 19.18947328
I0406 05:11:10.788379 140604226451264 submission_runner.py:313] Starting training loop.
I0406 05:11:12.521415 140604226451264 submission_runner.py:335] After dataselection batch at step 0: RAM USED (GB) 25.233047552
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
I0406 05:11:17.602212 140577735702272 logging_writer.py:48] [0] global_step=0, grad_norm=54.664207, loss=32.533176
I0406 05:11:17.615633 140604226451264 submission.py:119] 0) loss = 32.533, grad_norm = 54.664
I0406 05:11:17.616338 140604226451264 submission_runner.py:352] After update parameters step 0: RAM USED (GB) 33.189879808
I0406 05:11:17.616937 140604226451264 submission_runner.py:373] Before eval at step 1: RAM USED (GB) 33.189879808
I0406 05:11:17.617067 140604226451264 spec.py:298] Evaluating on the training split.
I0406 05:11:17.617798 140604226451264 input_pipeline.py:20] Loading split = train-clean-100
I0406 05:11:17.646056 140604226451264 input_pipeline.py:20] Loading split = train-clean-360
I0406 05:11:18.055779 140604226451264 input_pipeline.py:20] Loading split = train-other-500
I0406 05:11:31.034678 140604226451264 spec.py:310] Evaluating on the validation split.
I0406 05:11:31.035926 140604226451264 input_pipeline.py:20] Loading split = dev-clean
I0406 05:11:31.039647 140604226451264 input_pipeline.py:20] Loading split = dev-other
I0406 05:11:41.053288 140604226451264 spec.py:326] Evaluating on the test split.
I0406 05:11:41.062833 140604226451264 input_pipeline.py:20] Loading split = test-clean
I0406 05:11:46.328923 140604226451264 submission_runner.py:382] Time since start: 6.83s, 	Step: 1, 	{'train/ctc_loss': 32.01154687889434, 'train/wer': 1.73154741039348, 'validation/ctc_loss': 30.894153732167972, 'validation/wer': 1.592622990392507, 'validation/num_examples': 5348, 'test/ctc_loss': 30.947157881153622, 'test/wer': 1.6540125525562124, 'test/num_examples': 2472}
I0406 05:11:46.329713 140604226451264 submission_runner.py:396] After eval at step 1: RAM USED (GB) 45.771333632
I0406 05:11:46.343494 140569763133184 logging_writer.py:48] [1] global_step=1, preemption_count=0, score=6.827117, test/ctc_loss=30.947158, test/num_examples=2472, test/wer=1.654013, total_duration=6.829051, train/ctc_loss=32.011547, train/wer=1.731547, validation/ctc_loss=30.894154, validation/num_examples=5348, validation/wer=1.592623
I0406 05:11:46.933068 140604226451264 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v2/timing_adamw/librispeech_conformer_pytorch/trial_1/checkpoint_1.
I0406 05:11:46.933717 140604226451264 submission_runner.py:416] After logging and checkpointing eval at step 1: RAM USED (GB) 45.820710912
I0406 05:11:46.937855 140604226451264 submission_runner.py:335] After dataselection batch at step 1: RAM USED (GB) 45.823094784
I0406 05:11:46.980948 140604226451264 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 05:11:46.981029 139663252813632 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 05:11:46.981038 139785043404608 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 05:11:46.981059 140080998569792 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 05:11:46.981093 140394205820736 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 05:11:46.981072 140159620630336 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 05:11:46.981148 140481733093184 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 05:11:46.981230 140074475947840 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0406 05:11:48.069946 140563462592256 logging_writer.py:48] [1] global_step=1, grad_norm=55.727180, loss=32.011845
I0406 05:11:48.073274 140604226451264 submission.py:119] 1) loss = 32.012, grad_norm = 55.727
I0406 05:11:48.073959 140604226451264 submission_runner.py:352] After update parameters step 1: RAM USED (GB) 45.962653696
I0406 05:11:48.973953 140569763133184 logging_writer.py:48] [2] global_step=2, grad_norm=57.129448, loss=32.441761
I0406 05:11:48.977195 140604226451264 submission.py:119] 2) loss = 32.442, grad_norm = 57.129
I0406 05:11:49.990749 140563462592256 logging_writer.py:48] [3] global_step=3, grad_norm=60.441776, loss=32.400562
I0406 05:11:49.994012 140604226451264 submission.py:119] 3) loss = 32.401, grad_norm = 60.442
I0406 05:11:50.797401 140569763133184 logging_writer.py:48] [4] global_step=4, grad_norm=63.308414, loss=31.893261
I0406 05:11:50.800362 140604226451264 submission.py:119] 4) loss = 31.893, grad_norm = 63.308
I0406 05:11:51.605698 140563462592256 logging_writer.py:48] [5] global_step=5, grad_norm=71.234879, loss=31.963158
I0406 05:11:51.608683 140604226451264 submission.py:119] 5) loss = 31.963, grad_norm = 71.235
I0406 05:11:52.413350 140569763133184 logging_writer.py:48] [6] global_step=6, grad_norm=84.421654, loss=31.984495
I0406 05:11:52.416516 140604226451264 submission.py:119] 6) loss = 31.984, grad_norm = 84.422
I0406 05:11:53.219570 140563462592256 logging_writer.py:48] [7] global_step=7, grad_norm=91.942383, loss=30.652502
I0406 05:11:53.222739 140604226451264 submission.py:119] 7) loss = 30.653, grad_norm = 91.942
I0406 05:11:54.028734 140569763133184 logging_writer.py:48] [8] global_step=8, grad_norm=110.124321, loss=30.652285
I0406 05:11:54.031805 140604226451264 submission.py:119] 8) loss = 30.652, grad_norm = 110.124
I0406 05:11:54.832950 140563462592256 logging_writer.py:48] [9] global_step=9, grad_norm=124.928047, loss=29.830660
I0406 05:11:54.835947 140604226451264 submission.py:119] 9) loss = 29.831, grad_norm = 124.928
I0406 05:11:55.640061 140569763133184 logging_writer.py:48] [10] global_step=10, grad_norm=138.491165, loss=29.004364
I0406 05:11:55.643385 140604226451264 submission.py:119] 10) loss = 29.004, grad_norm = 138.491
I0406 05:11:56.449506 140563462592256 logging_writer.py:48] [11] global_step=11, grad_norm=154.043472, loss=28.222420
I0406 05:11:56.452760 140604226451264 submission.py:119] 11) loss = 28.222, grad_norm = 154.043
I0406 05:11:57.257275 140569763133184 logging_writer.py:48] [12] global_step=12, grad_norm=161.922836, loss=27.177954
I0406 05:11:57.260333 140604226451264 submission.py:119] 12) loss = 27.178, grad_norm = 161.923
I0406 05:11:58.066844 140563462592256 logging_writer.py:48] [13] global_step=13, grad_norm=163.875488, loss=25.451471
I0406 05:11:58.070432 140604226451264 submission.py:119] 13) loss = 25.451, grad_norm = 163.875
I0406 05:11:58.878408 140569763133184 logging_writer.py:48] [14] global_step=14, grad_norm=163.678345, loss=23.891386
I0406 05:11:58.881900 140604226451264 submission.py:119] 14) loss = 23.891, grad_norm = 163.678
I0406 05:11:59.682027 140563462592256 logging_writer.py:48] [15] global_step=15, grad_norm=157.680222, loss=21.708811
I0406 05:11:59.685124 140604226451264 submission.py:119] 15) loss = 21.709, grad_norm = 157.680
I0406 05:12:00.486572 140569763133184 logging_writer.py:48] [16] global_step=16, grad_norm=158.875381, loss=20.353903
I0406 05:12:00.489857 140604226451264 submission.py:119] 16) loss = 20.354, grad_norm = 158.875
I0406 05:12:01.291463 140563462592256 logging_writer.py:48] [17] global_step=17, grad_norm=153.474091, loss=18.444920
I0406 05:12:01.294466 140604226451264 submission.py:119] 17) loss = 18.445, grad_norm = 153.474
I0406 05:12:02.100427 140569763133184 logging_writer.py:48] [18] global_step=18, grad_norm=146.559799, loss=16.545324
I0406 05:12:02.103636 140604226451264 submission.py:119] 18) loss = 16.545, grad_norm = 146.560
I0406 05:12:02.909921 140563462592256 logging_writer.py:48] [19] global_step=19, grad_norm=135.266388, loss=14.622052
I0406 05:12:02.913096 140604226451264 submission.py:119] 19) loss = 14.622, grad_norm = 135.266
I0406 05:12:03.723315 140569763133184 logging_writer.py:48] [20] global_step=20, grad_norm=121.330353, loss=12.807617
I0406 05:12:03.726493 140604226451264 submission.py:119] 20) loss = 12.808, grad_norm = 121.330
I0406 05:12:04.536290 140563462592256 logging_writer.py:48] [21] global_step=21, grad_norm=107.341988, loss=11.389533
I0406 05:12:04.539394 140604226451264 submission.py:119] 21) loss = 11.390, grad_norm = 107.342
I0406 05:12:05.342723 140569763133184 logging_writer.py:48] [22] global_step=22, grad_norm=92.160126, loss=10.198603
I0406 05:12:05.345903 140604226451264 submission.py:119] 22) loss = 10.199, grad_norm = 92.160
I0406 05:12:06.147912 140563462592256 logging_writer.py:48] [23] global_step=23, grad_norm=70.355232, loss=9.052468
I0406 05:12:06.150966 140604226451264 submission.py:119] 23) loss = 9.052, grad_norm = 70.355
I0406 05:12:06.955640 140569763133184 logging_writer.py:48] [24] global_step=24, grad_norm=53.629189, loss=8.331828
I0406 05:12:06.958722 140604226451264 submission.py:119] 24) loss = 8.332, grad_norm = 53.629
I0406 05:12:07.762861 140563462592256 logging_writer.py:48] [25] global_step=25, grad_norm=37.846680, loss=7.835505
I0406 05:12:07.765897 140604226451264 submission.py:119] 25) loss = 7.836, grad_norm = 37.847
I0406 05:12:08.571395 140569763133184 logging_writer.py:48] [26] global_step=26, grad_norm=24.561737, loss=7.504689
I0406 05:12:08.574630 140604226451264 submission.py:119] 26) loss = 7.505, grad_norm = 24.562
I0406 05:12:09.381083 140563462592256 logging_writer.py:48] [27] global_step=27, grad_norm=14.231915, loss=7.313759
I0406 05:12:09.384456 140604226451264 submission.py:119] 27) loss = 7.314, grad_norm = 14.232
I0406 05:12:10.185823 140569763133184 logging_writer.py:48] [28] global_step=28, grad_norm=7.000028, loss=7.238944
I0406 05:12:10.189081 140604226451264 submission.py:119] 28) loss = 7.239, grad_norm = 7.000
I0406 05:12:10.991283 140563462592256 logging_writer.py:48] [29] global_step=29, grad_norm=3.453472, loss=7.216225
I0406 05:12:10.994983 140604226451264 submission.py:119] 29) loss = 7.216, grad_norm = 3.453
I0406 05:12:11.805243 140569763133184 logging_writer.py:48] [30] global_step=30, grad_norm=5.053975, loss=7.204071
I0406 05:12:11.808377 140604226451264 submission.py:119] 30) loss = 7.204, grad_norm = 5.054
I0406 05:12:12.616679 140563462592256 logging_writer.py:48] [31] global_step=31, grad_norm=7.190424, loss=7.206148
I0406 05:12:12.619916 140604226451264 submission.py:119] 31) loss = 7.206, grad_norm = 7.190
I0406 05:12:13.422080 140569763133184 logging_writer.py:48] [32] global_step=32, grad_norm=8.963518, loss=7.228773
I0406 05:12:13.425231 140604226451264 submission.py:119] 32) loss = 7.229, grad_norm = 8.964
I0406 05:12:14.226076 140563462592256 logging_writer.py:48] [33] global_step=33, grad_norm=9.718604, loss=7.225589
I0406 05:12:14.229097 140604226451264 submission.py:119] 33) loss = 7.226, grad_norm = 9.719
I0406 05:12:15.031455 140569763133184 logging_writer.py:48] [34] global_step=34, grad_norm=10.419257, loss=7.245109
I0406 05:12:15.034970 140604226451264 submission.py:119] 34) loss = 7.245, grad_norm = 10.419
I0406 05:12:15.842145 140563462592256 logging_writer.py:48] [35] global_step=35, grad_norm=10.537927, loss=7.232869
I0406 05:12:15.845366 140604226451264 submission.py:119] 35) loss = 7.233, grad_norm = 10.538
I0406 05:12:16.652665 140569763133184 logging_writer.py:48] [36] global_step=36, grad_norm=10.351242, loss=7.226192
I0406 05:12:16.656067 140604226451264 submission.py:119] 36) loss = 7.226, grad_norm = 10.351
I0406 05:12:17.460195 140563462592256 logging_writer.py:48] [37] global_step=37, grad_norm=10.088074, loss=7.203203
I0406 05:12:17.463089 140604226451264 submission.py:119] 37) loss = 7.203, grad_norm = 10.088
I0406 05:12:18.268442 140569763133184 logging_writer.py:48] [38] global_step=38, grad_norm=8.892576, loss=7.181333
I0406 05:12:18.271961 140604226451264 submission.py:119] 38) loss = 7.181, grad_norm = 8.893
I0406 05:12:19.083441 140563462592256 logging_writer.py:48] [39] global_step=39, grad_norm=8.547901, loss=7.146632
I0406 05:12:19.086880 140604226451264 submission.py:119] 39) loss = 7.147, grad_norm = 8.548
I0406 05:12:19.891660 140569763133184 logging_writer.py:48] [40] global_step=40, grad_norm=7.258733, loss=7.118886
I0406 05:12:19.894695 140604226451264 submission.py:119] 40) loss = 7.119, grad_norm = 7.259
I0406 05:12:20.698996 140563462592256 logging_writer.py:48] [41] global_step=41, grad_norm=6.619200, loss=7.098647
I0406 05:12:20.702108 140604226451264 submission.py:119] 41) loss = 7.099, grad_norm = 6.619
I0406 05:12:21.506196 140569763133184 logging_writer.py:48] [42] global_step=42, grad_norm=5.473541, loss=7.068118
I0406 05:12:21.509187 140604226451264 submission.py:119] 42) loss = 7.068, grad_norm = 5.474
I0406 05:12:22.308075 140563462592256 logging_writer.py:48] [43] global_step=43, grad_norm=4.466774, loss=7.053183
I0406 05:12:22.311137 140604226451264 submission.py:119] 43) loss = 7.053, grad_norm = 4.467
I0406 05:12:23.115799 140569763133184 logging_writer.py:48] [44] global_step=44, grad_norm=3.623914, loss=7.035020
I0406 05:12:23.118785 140604226451264 submission.py:119] 44) loss = 7.035, grad_norm = 3.624
I0406 05:12:23.921998 140563462592256 logging_writer.py:48] [45] global_step=45, grad_norm=3.195765, loss=7.007935
I0406 05:12:23.925204 140604226451264 submission.py:119] 45) loss = 7.008, grad_norm = 3.196
I0406 05:12:24.728000 140569763133184 logging_writer.py:48] [46] global_step=46, grad_norm=3.063783, loss=6.990283
I0406 05:12:24.731491 140604226451264 submission.py:119] 46) loss = 6.990, grad_norm = 3.064
I0406 05:12:25.539299 140563462592256 logging_writer.py:48] [47] global_step=47, grad_norm=3.368056, loss=6.984638
I0406 05:12:25.542627 140604226451264 submission.py:119] 47) loss = 6.985, grad_norm = 3.368
I0406 05:12:26.350703 140569763133184 logging_writer.py:48] [48] global_step=48, grad_norm=4.223682, loss=6.983802
I0406 05:12:26.354041 140604226451264 submission.py:119] 48) loss = 6.984, grad_norm = 4.224
I0406 05:12:27.159160 140563462592256 logging_writer.py:48] [49] global_step=49, grad_norm=4.678223, loss=6.972973
I0406 05:12:27.162494 140604226451264 submission.py:119] 49) loss = 6.973, grad_norm = 4.678
I0406 05:12:27.966769 140569763133184 logging_writer.py:48] [50] global_step=50, grad_norm=4.162090, loss=6.940634
I0406 05:12:27.970926 140604226451264 submission.py:119] 50) loss = 6.941, grad_norm = 4.162
I0406 05:12:28.775135 140563462592256 logging_writer.py:48] [51] global_step=51, grad_norm=4.082393, loss=6.926368
I0406 05:12:28.779062 140604226451264 submission.py:119] 51) loss = 6.926, grad_norm = 4.082
I0406 05:12:29.580466 140569763133184 logging_writer.py:48] [52] global_step=52, grad_norm=3.804569, loss=6.915338
I0406 05:12:29.584199 140604226451264 submission.py:119] 52) loss = 6.915, grad_norm = 3.805
I0406 05:12:30.388809 140563462592256 logging_writer.py:48] [53] global_step=53, grad_norm=3.782617, loss=6.906182
I0406 05:12:30.392049 140604226451264 submission.py:119] 53) loss = 6.906, grad_norm = 3.783
I0406 05:12:31.197059 140569763133184 logging_writer.py:48] [54] global_step=54, grad_norm=4.141767, loss=6.905021
I0406 05:12:31.200224 140604226451264 submission.py:119] 54) loss = 6.905, grad_norm = 4.142
I0406 05:12:32.005142 140563462592256 logging_writer.py:48] [55] global_step=55, grad_norm=4.105540, loss=6.873669
I0406 05:12:32.008127 140604226451264 submission.py:119] 55) loss = 6.874, grad_norm = 4.106
I0406 05:12:32.817229 140569763133184 logging_writer.py:48] [56] global_step=56, grad_norm=3.311756, loss=6.839909
I0406 05:12:32.820191 140604226451264 submission.py:119] 56) loss = 6.840, grad_norm = 3.312
I0406 05:12:33.631717 140563462592256 logging_writer.py:48] [57] global_step=57, grad_norm=3.383691, loss=6.841248
I0406 05:12:33.635029 140604226451264 submission.py:119] 57) loss = 6.841, grad_norm = 3.384
I0406 05:12:34.443425 140569763133184 logging_writer.py:48] [58] global_step=58, grad_norm=2.977920, loss=6.835134
I0406 05:12:34.446771 140604226451264 submission.py:119] 58) loss = 6.835, grad_norm = 2.978
I0406 05:12:35.252184 140563462592256 logging_writer.py:48] [59] global_step=59, grad_norm=2.888413, loss=6.821115
I0406 05:12:35.255675 140604226451264 submission.py:119] 59) loss = 6.821, grad_norm = 2.888
I0406 05:12:36.055510 140569763133184 logging_writer.py:48] [60] global_step=60, grad_norm=2.801342, loss=6.811554
I0406 05:12:36.058665 140604226451264 submission.py:119] 60) loss = 6.812, grad_norm = 2.801
I0406 05:12:36.861999 140563462592256 logging_writer.py:48] [61] global_step=61, grad_norm=2.716826, loss=6.782770
I0406 05:12:36.865204 140604226451264 submission.py:119] 61) loss = 6.783, grad_norm = 2.717
I0406 05:12:37.675888 140569763133184 logging_writer.py:48] [62] global_step=62, grad_norm=2.758615, loss=6.782318
I0406 05:12:37.678927 140604226451264 submission.py:119] 62) loss = 6.782, grad_norm = 2.759
I0406 05:12:38.486530 140563462592256 logging_writer.py:48] [63] global_step=63, grad_norm=3.024765, loss=6.744627
I0406 05:12:38.490476 140604226451264 submission.py:119] 63) loss = 6.745, grad_norm = 3.025
I0406 05:12:39.295404 140569763133184 logging_writer.py:48] [64] global_step=64, grad_norm=2.789851, loss=6.739102
I0406 05:12:39.299196 140604226451264 submission.py:119] 64) loss = 6.739, grad_norm = 2.790
I0406 05:12:40.104364 140563462592256 logging_writer.py:48] [65] global_step=65, grad_norm=2.715141, loss=6.731606
I0406 05:12:40.108278 140604226451264 submission.py:119] 65) loss = 6.732, grad_norm = 2.715
I0406 05:12:40.917004 140569763133184 logging_writer.py:48] [66] global_step=66, grad_norm=2.685340, loss=6.702658
I0406 05:12:40.920975 140604226451264 submission.py:119] 66) loss = 6.703, grad_norm = 2.685
I0406 05:12:41.730785 140563462592256 logging_writer.py:48] [67] global_step=67, grad_norm=2.643848, loss=6.685501
I0406 05:12:41.734600 140604226451264 submission.py:119] 67) loss = 6.686, grad_norm = 2.644
I0406 05:12:42.541973 140569763133184 logging_writer.py:48] [68] global_step=68, grad_norm=2.615205, loss=6.676293
I0406 05:12:42.545622 140604226451264 submission.py:119] 68) loss = 6.676, grad_norm = 2.615
I0406 05:12:43.349540 140563462592256 logging_writer.py:48] [69] global_step=69, grad_norm=3.386132, loss=6.679072
I0406 05:12:43.353392 140604226451264 submission.py:119] 69) loss = 6.679, grad_norm = 3.386
I0406 05:12:44.156344 140569763133184 logging_writer.py:48] [70] global_step=70, grad_norm=2.997168, loss=6.638807
I0406 05:12:44.160260 140604226451264 submission.py:119] 70) loss = 6.639, grad_norm = 2.997
I0406 05:12:44.962145 140563462592256 logging_writer.py:48] [71] global_step=71, grad_norm=3.183821, loss=6.639503
I0406 05:12:44.965814 140604226451264 submission.py:119] 71) loss = 6.640, grad_norm = 3.184
I0406 05:12:45.771456 140569763133184 logging_writer.py:48] [72] global_step=72, grad_norm=2.626457, loss=6.617744
I0406 05:12:45.775229 140604226451264 submission.py:119] 72) loss = 6.618, grad_norm = 2.626
I0406 05:12:46.581240 140563462592256 logging_writer.py:48] [73] global_step=73, grad_norm=2.679505, loss=6.603771
I0406 05:12:46.584948 140604226451264 submission.py:119] 73) loss = 6.604, grad_norm = 2.680
I0406 05:12:47.394770 140569763133184 logging_writer.py:48] [74] global_step=74, grad_norm=2.408584, loss=6.592255
I0406 05:12:47.398606 140604226451264 submission.py:119] 74) loss = 6.592, grad_norm = 2.409
I0406 05:12:48.207106 140563462592256 logging_writer.py:48] [75] global_step=75, grad_norm=2.606023, loss=6.580523
I0406 05:12:48.210913 140604226451264 submission.py:119] 75) loss = 6.581, grad_norm = 2.606
I0406 05:12:49.020480 140569763133184 logging_writer.py:48] [76] global_step=76, grad_norm=2.276523, loss=6.540823
I0406 05:12:49.024198 140604226451264 submission.py:119] 76) loss = 6.541, grad_norm = 2.277
I0406 05:12:49.827255 140563462592256 logging_writer.py:48] [77] global_step=77, grad_norm=2.222629, loss=6.548557
I0406 05:12:49.830990 140604226451264 submission.py:119] 77) loss = 6.549, grad_norm = 2.223
I0406 05:12:50.635941 140569763133184 logging_writer.py:48] [78] global_step=78, grad_norm=2.162986, loss=6.534519
I0406 05:12:50.639435 140604226451264 submission.py:119] 78) loss = 6.535, grad_norm = 2.163
I0406 05:12:51.447278 140563462592256 logging_writer.py:48] [79] global_step=79, grad_norm=2.247166, loss=6.527048
I0406 05:12:51.450690 140604226451264 submission.py:119] 79) loss = 6.527, grad_norm = 2.247
I0406 05:12:52.256131 140569763133184 logging_writer.py:48] [80] global_step=80, grad_norm=2.514698, loss=6.504285
I0406 05:12:52.259670 140604226451264 submission.py:119] 80) loss = 6.504, grad_norm = 2.515
I0406 05:12:53.065627 140563462592256 logging_writer.py:48] [81] global_step=81, grad_norm=2.368575, loss=6.482080
I0406 05:12:53.069033 140604226451264 submission.py:119] 81) loss = 6.482, grad_norm = 2.369
I0406 05:12:53.873708 140569763133184 logging_writer.py:48] [82] global_step=82, grad_norm=2.202164, loss=6.472412
I0406 05:12:53.876680 140604226451264 submission.py:119] 82) loss = 6.472, grad_norm = 2.202
I0406 05:12:54.684008 140563462592256 logging_writer.py:48] [83] global_step=83, grad_norm=2.318923, loss=6.467177
I0406 05:12:54.687182 140604226451264 submission.py:119] 83) loss = 6.467, grad_norm = 2.319
I0406 05:12:55.498660 140569763133184 logging_writer.py:48] [84] global_step=84, grad_norm=1.960451, loss=6.459111
I0406 05:12:55.501846 140604226451264 submission.py:119] 84) loss = 6.459, grad_norm = 1.960
I0406 05:12:56.311361 140563462592256 logging_writer.py:48] [85] global_step=85, grad_norm=2.132035, loss=6.433552
I0406 05:12:56.314487 140604226451264 submission.py:119] 85) loss = 6.434, grad_norm = 2.132
I0406 05:12:57.117474 140569763133184 logging_writer.py:48] [86] global_step=86, grad_norm=1.775947, loss=6.420261
I0406 05:12:57.120695 140604226451264 submission.py:119] 86) loss = 6.420, grad_norm = 1.776
I0406 05:12:57.921914 140563462592256 logging_writer.py:48] [87] global_step=87, grad_norm=1.735585, loss=6.406038
I0406 05:12:57.925003 140604226451264 submission.py:119] 87) loss = 6.406, grad_norm = 1.736
I0406 05:12:58.727291 140569763133184 logging_writer.py:48] [88] global_step=88, grad_norm=2.061511, loss=6.395469
I0406 05:12:58.730490 140604226451264 submission.py:119] 88) loss = 6.395, grad_norm = 2.062
I0406 05:12:59.537569 140563462592256 logging_writer.py:48] [89] global_step=89, grad_norm=2.208920, loss=6.402637
I0406 05:12:59.540607 140604226451264 submission.py:119] 89) loss = 6.403, grad_norm = 2.209
I0406 05:13:00.346555 140569763133184 logging_writer.py:48] [90] global_step=90, grad_norm=1.698485, loss=6.362479
I0406 05:13:00.349833 140604226451264 submission.py:119] 90) loss = 6.362, grad_norm = 1.698
I0406 05:13:01.155807 140563462592256 logging_writer.py:48] [91] global_step=91, grad_norm=1.972781, loss=6.361986
I0406 05:13:01.159064 140604226451264 submission.py:119] 91) loss = 6.362, grad_norm = 1.973
I0406 05:13:01.967191 140569763133184 logging_writer.py:48] [92] global_step=92, grad_norm=1.699463, loss=6.340010
I0406 05:13:01.970749 140604226451264 submission.py:119] 92) loss = 6.340, grad_norm = 1.699
I0406 05:13:02.779909 140563462592256 logging_writer.py:48] [93] global_step=93, grad_norm=1.628655, loss=6.330301
I0406 05:13:02.783153 140604226451264 submission.py:119] 93) loss = 6.330, grad_norm = 1.629
I0406 05:13:03.591172 140569763133184 logging_writer.py:48] [94] global_step=94, grad_norm=1.492025, loss=6.318491
I0406 05:13:03.594306 140604226451264 submission.py:119] 94) loss = 6.318, grad_norm = 1.492
I0406 05:13:04.401742 140563462592256 logging_writer.py:48] [95] global_step=95, grad_norm=1.510984, loss=6.316351
I0406 05:13:04.405049 140604226451264 submission.py:119] 95) loss = 6.316, grad_norm = 1.511
I0406 05:13:05.210005 140569763133184 logging_writer.py:48] [96] global_step=96, grad_norm=1.720963, loss=6.315832
I0406 05:13:05.213052 140604226451264 submission.py:119] 96) loss = 6.316, grad_norm = 1.721
I0406 05:13:06.017164 140563462592256 logging_writer.py:48] [97] global_step=97, grad_norm=1.523996, loss=6.282385
I0406 05:13:06.020169 140604226451264 submission.py:119] 97) loss = 6.282, grad_norm = 1.524
I0406 05:13:06.826051 140569763133184 logging_writer.py:48] [98] global_step=98, grad_norm=1.728504, loss=6.271897
I0406 05:13:06.829329 140604226451264 submission.py:119] 98) loss = 6.272, grad_norm = 1.729
I0406 05:13:07.633935 140563462592256 logging_writer.py:48] [99] global_step=99, grad_norm=1.766287, loss=6.277625
I0406 05:13:07.637171 140604226451264 submission.py:119] 99) loss = 6.278, grad_norm = 1.766
I0406 05:13:08.447285 140569763133184 logging_writer.py:48] [100] global_step=100, grad_norm=1.293903, loss=6.264268
I0406 05:13:08.450495 140604226451264 submission.py:119] 100) loss = 6.264, grad_norm = 1.294
I0406 05:18:28.325356 140563462592256 logging_writer.py:48] [500] global_step=500, grad_norm=0.772754, loss=5.791108
I0406 05:18:28.329808 140604226451264 submission.py:119] 500) loss = 5.791, grad_norm = 0.773
I0406 05:25:08.103880 140569763133184 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.247807, loss=5.420978
I0406 05:25:08.109314 140604226451264 submission.py:119] 1000) loss = 5.421, grad_norm = 1.248
I0406 05:31:49.249717 140569763133184 logging_writer.py:48] [1500] global_step=1500, grad_norm=1.324101, loss=3.547805
I0406 05:31:49.260458 140604226451264 submission.py:119] 1500) loss = 3.548, grad_norm = 1.324
I0406 05:38:28.287531 140569649084160 logging_writer.py:48] [2000] global_step=2000, grad_norm=1.268485, loss=2.963935
I0406 05:38:28.291278 140604226451264 submission.py:119] 2000) loss = 2.964, grad_norm = 1.268
I0406 05:45:08.407239 140569763133184 logging_writer.py:48] [2500] global_step=2500, grad_norm=1.352396, loss=2.663306
I0406 05:45:08.415112 140604226451264 submission.py:119] 2500) loss = 2.663, grad_norm = 1.352
I0406 05:51:46.733172 140569649084160 logging_writer.py:48] [3000] global_step=3000, grad_norm=1.101985, loss=2.508987
I0406 05:51:46.737652 140604226451264 submission.py:119] 3000) loss = 2.509, grad_norm = 1.102
I0406 05:51:47.536430 140604226451264 submission_runner.py:373] Before eval at step 3002: RAM USED (GB) 40.169340928
I0406 05:51:47.536628 140604226451264 spec.py:298] Evaluating on the training split.
I0406 05:51:58.360622 140604226451264 spec.py:310] Evaluating on the validation split.
I0406 05:52:08.085713 140604226451264 spec.py:326] Evaluating on the test split.
I0406 05:52:13.490781 140604226451264 submission_runner.py:382] Time since start: 2436.75s, 	Step: 3002, 	{'train/ctc_loss': 2.77864762046208, 'train/wer': 0.6185698010691438, 'validation/ctc_loss': 2.935271781444645, 'validation/wer': 0.6289962825278811, 'validation/num_examples': 5348, 'test/ctc_loss': 2.5865178801858186, 'test/wer': 0.5684195559888693, 'test/num_examples': 2472}
I0406 05:52:13.491573 140604226451264 submission_runner.py:396] After eval at step 3002: RAM USED (GB) 39.543353344
I0406 05:52:13.505767 140569763133184 logging_writer.py:48] [3002] global_step=3002, preemption_count=0, score=2398.663345, test/ctc_loss=2.586518, test/num_examples=2472, test/wer=0.568420, total_duration=2436.745299, train/ctc_loss=2.778648, train/wer=0.618570, validation/ctc_loss=2.935272, validation/num_examples=5348, validation/wer=0.628996
I0406 05:52:14.084193 140604226451264 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v2/timing_adamw/librispeech_conformer_pytorch/trial_1/checkpoint_3002.
I0406 05:52:14.084905 140604226451264 submission_runner.py:416] After logging and checkpointing eval at step 3002: RAM USED (GB) 39.548002304
I0406 05:58:53.079945 140569763133184 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.865259, loss=2.306532
I0406 05:58:53.086770 140604226451264 submission.py:119] 3500) loss = 2.307, grad_norm = 0.865
I0406 06:05:31.248281 140569649084160 logging_writer.py:48] [4000] global_step=4000, grad_norm=1.065493, loss=2.148192
I0406 06:05:31.253126 140604226451264 submission.py:119] 4000) loss = 2.148, grad_norm = 1.065
I0406 06:12:11.049162 140569763133184 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.773216, loss=2.018515
I0406 06:12:11.055641 140604226451264 submission.py:119] 4500) loss = 2.019, grad_norm = 0.773
I0406 06:18:48.990542 140569649084160 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.626984, loss=1.928013
I0406 06:18:49.000501 140604226451264 submission.py:119] 5000) loss = 1.928, grad_norm = 0.627
I0406 06:25:28.648057 140569763133184 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.628142, loss=1.855724
I0406 06:25:28.654199 140604226451264 submission.py:119] 5500) loss = 1.856, grad_norm = 0.628
I0406 06:32:05.896764 140569649084160 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.675535, loss=1.845212
I0406 06:32:05.901654 140604226451264 submission.py:119] 6000) loss = 1.845, grad_norm = 0.676
I0406 06:32:14.644639 140604226451264 submission_runner.py:373] Before eval at step 6012: RAM USED (GB) 39.637098496
I0406 06:32:14.644837 140604226451264 spec.py:298] Evaluating on the training split.
I0406 06:32:25.748204 140604226451264 spec.py:310] Evaluating on the validation split.
I0406 06:32:35.751671 140604226451264 spec.py:326] Evaluating on the test split.
I0406 06:32:41.347561 140604226451264 submission_runner.py:382] Time since start: 4863.85s, 	Step: 6012, 	{'train/ctc_loss': 0.6645985052561857, 'train/wer': 0.22441613355534135, 'validation/ctc_loss': 0.878245299471318, 'validation/wer': 0.26017476946844975, 'validation/num_examples': 5348, 'test/ctc_loss': 0.598237386282986, 'test/wer': 0.19941908882253773, 'test/num_examples': 2472}
I0406 06:32:41.348386 140604226451264 submission_runner.py:396] After eval at step 6012: RAM USED (GB) 39.442059264
I0406 06:32:41.365592 140569763133184 logging_writer.py:48] [6012] global_step=6012, preemption_count=0, score=4790.296340, test/ctc_loss=0.598237, test/num_examples=2472, test/wer=0.199419, total_duration=4863.853652, train/ctc_loss=0.664599, train/wer=0.224416, validation/ctc_loss=0.878245, validation/num_examples=5348, validation/wer=0.260175
I0406 06:32:41.955029 140604226451264 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v2/timing_adamw/librispeech_conformer_pytorch/trial_1/checkpoint_6012.
I0406 06:32:41.955643 140604226451264 submission_runner.py:416] After logging and checkpointing eval at step 6012: RAM USED (GB) 39.44824832
I0406 06:39:12.731565 140569763133184 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.495218, loss=1.757542
I0406 06:39:12.738279 140604226451264 submission.py:119] 6500) loss = 1.758, grad_norm = 0.495
I0406 06:45:49.803768 140569649084160 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.561563, loss=1.676579
I0406 06:45:49.808087 140604226451264 submission.py:119] 7000) loss = 1.677, grad_norm = 0.562
I0406 06:52:28.862172 140569763133184 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.487113, loss=1.669954
I0406 06:52:28.868908 140604226451264 submission.py:119] 7500) loss = 1.670, grad_norm = 0.487
I0406 06:59:06.473469 140569649084160 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.434478, loss=1.617483
I0406 06:59:06.477692 140604226451264 submission.py:119] 8000) loss = 1.617, grad_norm = 0.434
I0406 07:05:45.758566 140569763133184 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.530817, loss=1.584737
I0406 07:05:45.765599 140604226451264 submission.py:119] 8500) loss = 1.585, grad_norm = 0.531
I0406 07:12:23.143757 140569649084160 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.439516, loss=1.593730
I0406 07:12:23.148023 140604226451264 submission.py:119] 9000) loss = 1.594, grad_norm = 0.440
I0406 07:12:42.202418 140604226451264 submission_runner.py:373] Before eval at step 9025: RAM USED (GB) 39.577268224
I0406 07:12:42.202610 140604226451264 spec.py:298] Evaluating on the training split.
I0406 07:12:53.684413 140604226451264 spec.py:310] Evaluating on the validation split.
I0406 07:13:03.776855 140604226451264 spec.py:326] Evaluating on the test split.
I0406 07:13:09.246218 140604226451264 submission_runner.py:382] Time since start: 7291.41s, 	Step: 9025, 	{'train/ctc_loss': 0.48100180782743185, 'train/wer': 0.1681327228113224, 'validation/ctc_loss': 0.7076902874315601, 'validation/wer': 0.21284217641094966, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4467550325827473, 'test/wer': 0.15016350821603397, 'test/num_examples': 2472}
I0406 07:13:09.247052 140604226451264 submission_runner.py:396] After eval at step 9025: RAM USED (GB) 39.546478592
I0406 07:13:09.265375 140569763133184 logging_writer.py:48] [9025] global_step=9025, preemption_count=0, score=7181.740997, test/ctc_loss=0.446755, test/num_examples=2472, test/wer=0.150164, total_duration=7291.411244, train/ctc_loss=0.481002, train/wer=0.168133, validation/ctc_loss=0.707690, validation/num_examples=5348, validation/wer=0.212842
I0406 07:13:09.873142 140604226451264 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v2/timing_adamw/librispeech_conformer_pytorch/trial_1/checkpoint_9025.
I0406 07:13:09.873852 140604226451264 submission_runner.py:416] After logging and checkpointing eval at step 9025: RAM USED (GB) 39.552704512
I0406 07:19:30.111715 140569763133184 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.441002, loss=1.571212
I0406 07:19:30.119159 140604226451264 submission.py:119] 9500) loss = 1.571, grad_norm = 0.441
I0406 07:26:06.342380 140604226451264 submission_runner.py:373] Before eval at step 10000: RAM USED (GB) 39.67903744
I0406 07:26:06.342589 140604226451264 spec.py:298] Evaluating on the training split.
I0406 07:26:17.395323 140604226451264 spec.py:310] Evaluating on the validation split.
I0406 07:26:27.244495 140604226451264 spec.py:326] Evaluating on the test split.
I0406 07:26:32.733500 140604226451264 submission_runner.py:382] Time since start: 8095.55s, 	Step: 10000, 	{'train/ctc_loss': 0.4344197102269429, 'train/wer': 0.1535963105775129, 'validation/ctc_loss': 0.6652235046840466, 'validation/wer': 0.20025105006517646, 'validation/num_examples': 5348, 'test/ctc_loss': 0.42030377967933413, 'test/wer': 0.14264822375236122, 'test/num_examples': 2472}
I0406 07:26:32.734235 140604226451264 submission_runner.py:396] After eval at step 10000: RAM USED (GB) 39.516356608
I0406 07:26:32.750376 140569763133184 logging_writer.py:48] [10000] global_step=10000, preemption_count=0, score=7955.378039, test/ctc_loss=0.420304, test/num_examples=2472, test/wer=0.142648, total_duration=8095.552031, train/ctc_loss=0.434420, train/wer=0.153596, validation/ctc_loss=0.665224, validation/num_examples=5348, validation/wer=0.200251
I0406 07:26:33.327889 140604226451264 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v2/timing_adamw/librispeech_conformer_pytorch/trial_1/checkpoint_10000.
I0406 07:26:33.328522 140604226451264 submission_runner.py:416] After logging and checkpointing eval at step 10000: RAM USED (GB) 39.525249024
I0406 07:26:33.337474 140569649084160 logging_writer.py:48] [10000] global_step=10000, preemption_count=0, score=7955.378039
I0406 07:26:34.406475 140604226451264 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v2/timing_adamw/librispeech_conformer_pytorch/trial_1/checkpoint_10000.
I0406 07:26:34.550958 140604226451264 submission_runner.py:550] Tuning trial 1/1
I0406 07:26:34.551177 140604226451264 submission_runner.py:551] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0406 07:26:34.551609 140604226451264 submission_runner.py:552] Metrics: {'eval_results': [(1, {'train/ctc_loss': 32.01154687889434, 'train/wer': 1.73154741039348, 'validation/ctc_loss': 30.894153732167972, 'validation/wer': 1.592622990392507, 'validation/num_examples': 5348, 'test/ctc_loss': 30.947157881153622, 'test/wer': 1.6540125525562124, 'test/num_examples': 2472, 'score': 6.827117443084717, 'total_duration': 6.8290510177612305, 'global_step': 1, 'preemption_count': 0}), (3002, {'train/ctc_loss': 2.77864762046208, 'train/wer': 0.6185698010691438, 'validation/ctc_loss': 2.935271781444645, 'validation/wer': 0.6289962825278811, 'validation/num_examples': 5348, 'test/ctc_loss': 2.5865178801858186, 'test/wer': 0.5684195559888693, 'test/num_examples': 2472, 'score': 2398.663344860077, 'total_duration': 2436.7452993392944, 'global_step': 3002, 'preemption_count': 0}), (6012, {'train/ctc_loss': 0.6645985052561857, 'train/wer': 0.22441613355534135, 'validation/ctc_loss': 0.878245299471318, 'validation/wer': 0.26017476946844975, 'validation/num_examples': 5348, 'test/ctc_loss': 0.598237386282986, 'test/wer': 0.19941908882253773, 'test/num_examples': 2472, 'score': 4790.296339511871, 'total_duration': 4863.85365152359, 'global_step': 6012, 'preemption_count': 0}), (9025, {'train/ctc_loss': 0.48100180782743185, 'train/wer': 0.1681327228113224, 'validation/ctc_loss': 0.7076902874315601, 'validation/wer': 0.21284217641094966, 'validation/num_examples': 5348, 'test/ctc_loss': 0.4467550325827473, 'test/wer': 0.15016350821603397, 'test/num_examples': 2472, 'score': 7181.740996837616, 'total_duration': 7291.411243915558, 'global_step': 9025, 'preemption_count': 0}), (10000, {'train/ctc_loss': 0.4344197102269429, 'train/wer': 0.1535963105775129, 'validation/ctc_loss': 0.6652235046840466, 'validation/wer': 0.20025105006517646, 'validation/num_examples': 5348, 'test/ctc_loss': 0.42030377967933413, 'test/wer': 0.14264822375236122, 'test/num_examples': 2472, 'score': 7955.378038883209, 'total_duration': 8095.552030801773, 'global_step': 10000, 'preemption_count': 0})], 'global_step': 10000}
I0406 07:26:34.551687 140604226451264 submission_runner.py:553] Timing: 7955.378038883209
I0406 07:26:34.551732 140604226451264 submission_runner.py:554] ====================
I0406 07:26:34.551890 140604226451264 submission_runner.py:613] Final librispeech_conformer score: 7955.378038883209
