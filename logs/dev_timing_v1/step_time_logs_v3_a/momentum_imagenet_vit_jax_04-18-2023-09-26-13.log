I0418 09:26:35.339857 140588895340352 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax.
I0418 09:26:35.399816 140588895340352 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0418 09:26:36.355813 140588895340352 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0418 09:26:36.356806 140588895340352 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0418 09:26:36.361634 140588895340352 submission_runner.py:528] Using RNG seed 1503541158
I0418 09:26:38.977408 140588895340352 submission_runner.py:537] --- Tuning run 1/1 ---
I0418 09:26:38.977610 140588895340352 submission_runner.py:542] Creating tuning directory at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1.
I0418 09:26:38.977863 140588895340352 logger_utils.py:83] Saving hparams to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/hparams.json.
I0418 09:26:39.101214 140588895340352 submission_runner.py:232] Initializing dataset.
I0418 09:26:39.113804 140588895340352 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0418 09:26:39.121168 140588895340352 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0418 09:26:39.121282 140588895340352 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0418 09:26:39.379333 140588895340352 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0418 09:26:46.207183 140588895340352 submission_runner.py:239] Initializing model.
I0418 09:26:57.335242 140588895340352 submission_runner.py:249] Initializing optimizer.
I0418 09:26:57.828083 140588895340352 submission_runner.py:256] Initializing metrics bundle.
I0418 09:26:57.828271 140588895340352 submission_runner.py:273] Initializing checkpoint and logger.
I0418 09:26:57.829157 140588895340352 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1 with prefix checkpoint_
I0418 09:26:58.624044 140588895340352 submission_runner.py:294] Saving meta data to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/meta_data_0.json.
I0418 09:26:58.625148 140588895340352 submission_runner.py:297] Saving flags to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/flags_0.json.
I0418 09:26:58.630178 140588895340352 submission_runner.py:309] Starting training loop.
I0418 09:27:46.471787 140411825805056 logging_writer.py:48] [0] global_step=0, grad_norm=0.29705166816711426, loss=6.9077534675598145
I0418 09:27:46.486346 140588895340352 spec.py:298] Evaluating on the training split.
I0418 09:27:46.492624 140588895340352 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0418 09:27:46.499211 140588895340352 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0418 09:27:46.499324 140588895340352 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0418 09:27:46.560633 140588895340352 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0418 09:28:07.104337 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 09:28:07.112842 140588895340352 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0418 09:28:07.125399 140588895340352 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0418 09:28:07.125674 140588895340352 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0418 09:28:07.187505 140588895340352 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0418 09:28:26.638353 140588895340352 spec.py:326] Evaluating on the test split.
I0418 09:28:26.645668 140588895340352 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0418 09:28:26.650371 140588895340352 dataset_builder.py:510] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0418 09:28:26.682374 140588895340352 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0418 09:28:37.586088 140588895340352 submission_runner.py:406] Time since start: 98.96s, 	Step: 1, 	{'train/accuracy': 0.0009179687476716936, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 47.855984687805176, 'total_duration': 98.95584917068481, 'accumulated_submission_time': 47.855984687805176, 'accumulated_eval_time': 51.09971523284912, 'accumulated_logging_time': 0}
I0418 09:28:37.602278 140353038403328 logging_writer.py:48] [1] accumulated_eval_time=51.099715, accumulated_logging_time=0, accumulated_submission_time=47.855985, global_step=1, preemption_count=0, score=47.855985, test/accuracy=0.001000, test/loss=6.907757, test/num_examples=10000, total_duration=98.955849, train/accuracy=0.000918, train/loss=6.907756, validation/accuracy=0.001000, validation/loss=6.907756, validation/num_examples=50000
I0418 09:28:37.730928 140588895340352 checkpoints.py:356] Saving checkpoint at step: 1
I0418 09:28:38.105251 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_1
I0418 09:28:38.106146 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_1.
I0418 09:29:29.878124 140411238577920 logging_writer.py:48] [100] global_step=100, grad_norm=0.2938533425331116, loss=6.905445575714111
I0418 09:30:08.866558 140411246970624 logging_writer.py:48] [200] global_step=200, grad_norm=0.2821264863014221, loss=6.900937080383301
I0418 09:30:47.805344 140411238577920 logging_writer.py:48] [300] global_step=300, grad_norm=0.33178529143333435, loss=6.874541282653809
I0418 09:31:27.575274 140411246970624 logging_writer.py:48] [400] global_step=400, grad_norm=0.47062039375305176, loss=6.827422142028809
I0418 09:32:07.713455 140411238577920 logging_writer.py:48] [500] global_step=500, grad_norm=0.628470778465271, loss=6.7466607093811035
I0418 09:32:47.767723 140411246970624 logging_writer.py:48] [600] global_step=600, grad_norm=0.7789771556854248, loss=6.691800117492676
I0418 09:33:27.813039 140411238577920 logging_writer.py:48] [700] global_step=700, grad_norm=0.554655909538269, loss=6.700568199157715
I0418 09:34:07.956194 140411246970624 logging_writer.py:48] [800] global_step=800, grad_norm=0.8835901618003845, loss=6.606728553771973
I0418 09:34:48.062294 140411238577920 logging_writer.py:48] [900] global_step=900, grad_norm=0.8368864059448242, loss=6.760095596313477
I0418 09:35:28.275981 140411246970624 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.7573427557945251, loss=6.802082061767578
I0418 09:35:38.426779 140588895340352 spec.py:298] Evaluating on the training split.
I0418 09:35:49.552827 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 09:35:56.020882 140588895340352 spec.py:326] Evaluating on the test split.
I0418 09:35:58.042031 140588895340352 submission_runner.py:406] Time since start: 539.41s, 	Step: 1027, 	{'train/accuracy': 0.030449217185378075, 'train/loss': 6.134230613708496, 'validation/accuracy': 0.02985999919474125, 'validation/loss': 6.156836032867432, 'validation/num_examples': 50000, 'test/accuracy': 0.023400001227855682, 'test/loss': 6.247262477874756, 'test/num_examples': 10000, 'score': 468.1541361808777, 'total_duration': 539.4117102622986, 'accumulated_submission_time': 468.1541361808777, 'accumulated_eval_time': 70.71489262580872, 'accumulated_logging_time': 0.5210452079772949}
I0418 09:35:58.067709 140356905592576 logging_writer.py:48] [1027] accumulated_eval_time=70.714893, accumulated_logging_time=0.521045, accumulated_submission_time=468.154136, global_step=1027, preemption_count=0, score=468.154136, test/accuracy=0.023400, test/loss=6.247262, test/num_examples=10000, total_duration=539.411710, train/accuracy=0.030449, train/loss=6.134231, validation/accuracy=0.029860, validation/loss=6.156836, validation/num_examples=50000
I0418 09:35:58.805876 140588895340352 checkpoints.py:356] Saving checkpoint at step: 1027
I0418 09:35:59.794054 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_1027
I0418 09:35:59.796073 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_1027.
I0418 09:36:28.769120 140356913985280 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.6786651015281677, loss=6.509742736816406
I0418 09:37:07.874438 140413000210176 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.6941282153129578, loss=6.640756607055664
I0418 09:37:47.400981 140356913985280 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.8165687918663025, loss=6.56620979309082
I0418 09:38:27.404514 140413000210176 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.8162587285041809, loss=6.506293296813965
I0418 09:39:07.272718 140356913985280 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.9165065288543701, loss=6.4763689041137695
I0418 09:39:46.979137 140413000210176 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.9812795519828796, loss=6.457871913909912
I0418 09:40:26.979176 140356913985280 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.9599543809890747, loss=6.488824844360352
I0418 09:41:07.080789 140413000210176 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.979752242565155, loss=6.439479827880859
I0418 09:41:46.935817 140356913985280 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.7921111583709717, loss=6.376461505889893
I0418 09:42:26.938512 140413000210176 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.8245207667350769, loss=6.4683308601379395
I0418 09:42:59.865448 140588895340352 spec.py:298] Evaluating on the training split.
I0418 09:43:11.039033 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 09:43:17.567265 140588895340352 spec.py:326] Evaluating on the test split.
I0418 09:43:19.272517 140588895340352 submission_runner.py:406] Time since start: 980.64s, 	Step: 2084, 	{'train/accuracy': 0.05699218437075615, 'train/loss': 5.778841495513916, 'validation/accuracy': 0.055479999631643295, 'validation/loss': 5.813849925994873, 'validation/num_examples': 50000, 'test/accuracy': 0.03930000215768814, 'test/loss': 5.954679012298584, 'test/num_examples': 10000, 'score': 888.1965012550354, 'total_duration': 980.6421945095062, 'accumulated_submission_time': 888.1965012550354, 'accumulated_eval_time': 90.12190127372742, 'accumulated_logging_time': 2.2805063724517822}
I0418 09:43:19.286091 140356913985280 logging_writer.py:48] [2084] accumulated_eval_time=90.121901, accumulated_logging_time=2.280506, accumulated_submission_time=888.196501, global_step=2084, preemption_count=0, score=888.196501, test/accuracy=0.039300, test/loss=5.954679, test/num_examples=10000, total_duration=980.642195, train/accuracy=0.056992, train/loss=5.778841, validation/accuracy=0.055480, validation/loss=5.813850, validation/num_examples=50000
I0418 09:43:19.396440 140588895340352 checkpoints.py:356] Saving checkpoint at step: 2084
I0418 09:43:21.576187 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_2084
I0418 09:43:21.590524 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_2084.
I0418 09:43:28.286256 140413000210176 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.6989994645118713, loss=6.324041366577148
I0418 09:44:07.253120 140412966639360 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.70475172996521, loss=6.273305892944336
I0418 09:44:46.347883 140413000210176 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.7534022927284241, loss=6.4311418533325195
I0418 09:45:26.571740 140412966639360 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.6988856792449951, loss=6.3017377853393555
I0418 09:46:06.796164 140413000210176 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.5934375524520874, loss=6.757253170013428
I0418 09:46:46.654324 140412966639360 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.6194722652435303, loss=6.747265815734863
I0418 09:47:26.839660 140413000210176 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.5957214832305908, loss=6.270898342132568
I0418 09:48:06.963196 140412966639360 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.8101399540901184, loss=6.225863456726074
I0418 09:48:46.996262 140413000210176 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.6696707606315613, loss=6.187250137329102
I0418 09:49:26.979473 140412966639360 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.6850206255912781, loss=6.257225513458252
I0418 09:50:06.797212 140413000210176 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.8129103183746338, loss=6.287284851074219
I0418 09:50:21.819560 140588895340352 spec.py:298] Evaluating on the training split.
I0418 09:50:33.262316 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 09:50:40.060262 140588895340352 spec.py:326] Evaluating on the test split.
I0418 09:50:41.758613 140588895340352 submission_runner.py:406] Time since start: 1423.13s, 	Step: 3139, 	{'train/accuracy': 0.08167968690395355, 'train/loss': 5.3608903884887695, 'validation/accuracy': 0.07422000169754028, 'validation/loss': 5.420929431915283, 'validation/num_examples': 50000, 'test/accuracy': 0.057100001722574234, 'test/loss': 5.630521297454834, 'test/num_examples': 10000, 'score': 1308.4023022651672, 'total_duration': 1423.1283321380615, 'accumulated_submission_time': 1308.4023022651672, 'accumulated_eval_time': 110.06092143058777, 'accumulated_logging_time': 4.6000893115997314}
I0418 09:50:41.772663 140412966639360 logging_writer.py:48] [3139] accumulated_eval_time=110.060921, accumulated_logging_time=4.600089, accumulated_submission_time=1308.402302, global_step=3139, preemption_count=0, score=1308.402302, test/accuracy=0.057100, test/loss=5.630521, test/num_examples=10000, total_duration=1423.128332, train/accuracy=0.081680, train/loss=5.360890, validation/accuracy=0.074220, validation/loss=5.420929, validation/num_examples=50000
I0418 09:50:41.877270 140588895340352 checkpoints.py:356] Saving checkpoint at step: 3139
I0418 09:50:44.293866 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_3139
I0418 09:50:44.306179 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_3139.
I0418 09:51:08.538176 140413000210176 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.6845751404762268, loss=6.184213638305664
I0418 09:51:47.513084 140412949853952 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.717162549495697, loss=6.123111724853516
I0418 09:52:27.155663 140413000210176 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.7328394651412964, loss=6.223160266876221
I0418 09:53:07.141010 140412949853952 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.6665082573890686, loss=6.287242889404297
I0418 09:53:47.414708 140413000210176 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.6933339834213257, loss=6.742121696472168
I0418 09:54:27.722888 140412949853952 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.5805070400238037, loss=6.155357837677002
I0418 09:55:08.052693 140413000210176 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.5063402652740479, loss=6.3971052169799805
I0418 09:55:48.034184 140412949853952 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.6818828582763672, loss=6.056670188903809
I0418 09:56:28.265510 140413000210176 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.6299025416374207, loss=6.043981075286865
I0418 09:57:08.298029 140412949853952 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.6504232883453369, loss=6.017557144165039
I0418 09:57:44.439091 140588895340352 spec.py:298] Evaluating on the training split.
I0418 09:57:56.102541 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 09:58:03.107320 140588895340352 spec.py:326] Evaluating on the test split.
I0418 09:58:04.795031 140588895340352 submission_runner.py:406] Time since start: 1866.16s, 	Step: 4192, 	{'train/accuracy': 0.10152343660593033, 'train/loss': 5.119630336761475, 'validation/accuracy': 0.09111999720335007, 'validation/loss': 5.191515922546387, 'validation/num_examples': 50000, 'test/accuracy': 0.07380000501871109, 'test/loss': 5.432984828948975, 'test/num_examples': 10000, 'score': 1728.5121657848358, 'total_duration': 1866.1647453308105, 'accumulated_submission_time': 1728.5121657848358, 'accumulated_eval_time': 130.4168243408203, 'accumulated_logging_time': 7.149238109588623}
I0418 09:58:04.807845 140413000210176 logging_writer.py:48] [4192] accumulated_eval_time=130.416824, accumulated_logging_time=7.149238, accumulated_submission_time=1728.512166, global_step=4192, preemption_count=0, score=1728.512166, test/accuracy=0.073800, test/loss=5.432985, test/num_examples=10000, total_duration=1866.164745, train/accuracy=0.101523, train/loss=5.119630, validation/accuracy=0.091120, validation/loss=5.191516, validation/num_examples=50000
I0418 09:58:05.503435 140588895340352 checkpoints.py:356] Saving checkpoint at step: 4192
I0418 09:58:07.194644 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_4192
I0418 09:58:07.208703 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_4192.
I0418 09:58:10.730933 140412949853952 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.7060538530349731, loss=6.0575971603393555
I0418 09:58:49.719305 140412941461248 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.5878034234046936, loss=6.125354290008545
I0418 09:59:28.680953 140412949853952 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.608684241771698, loss=6.0199666023254395
I0418 10:00:08.926864 140412941461248 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.6083803176879883, loss=5.934784889221191
I0418 10:00:49.111234 140412949853952 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.632915735244751, loss=6.185263633728027
I0418 10:01:29.053717 140412941461248 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.6582489609718323, loss=6.015445709228516
I0418 10:02:09.225657 140412949853952 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.6938030123710632, loss=5.932900428771973
I0418 10:02:49.272647 140412941461248 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.4363069534301758, loss=6.583933353424072
I0418 10:03:29.750490 140412949853952 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.5121934413909912, loss=6.268723964691162
I0418 10:04:10.047647 140412941461248 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.54085773229599, loss=6.087152481079102
I0418 10:04:50.392683 140412949853952 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.8181016445159912, loss=5.941498756408691
I0418 10:05:07.441391 140588895340352 spec.py:298] Evaluating on the training split.
I0418 10:05:19.176956 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 10:05:26.891110 140588895340352 spec.py:326] Evaluating on the test split.
I0418 10:05:28.567387 140588895340352 submission_runner.py:406] Time since start: 2309.94s, 	Step: 5244, 	{'train/accuracy': 0.13718749582767487, 'train/loss': 4.81376314163208, 'validation/accuracy': 0.12637999653816223, 'validation/loss': 4.8988752365112305, 'validation/num_examples': 50000, 'test/accuracy': 0.09860000759363174, 'test/loss': 5.1829071044921875, 'test/num_examples': 10000, 'score': 2148.7142271995544, 'total_duration': 2309.937138557434, 'accumulated_submission_time': 2148.7142271995544, 'accumulated_eval_time': 151.54281091690063, 'accumulated_logging_time': 9.57218313217163}
I0418 10:05:28.580726 140412941461248 logging_writer.py:48] [5244] accumulated_eval_time=151.542811, accumulated_logging_time=9.572183, accumulated_submission_time=2148.714227, global_step=5244, preemption_count=0, score=2148.714227, test/accuracy=0.098600, test/loss=5.182907, test/num_examples=10000, total_duration=2309.937139, train/accuracy=0.137187, train/loss=4.813763, validation/accuracy=0.126380, validation/loss=4.898875, validation/num_examples=50000
I0418 10:05:28.665534 140588895340352 checkpoints.py:356] Saving checkpoint at step: 5244
I0418 10:05:30.288021 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_5244
I0418 10:05:30.302743 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_5244.
I0418 10:05:52.627470 140412949853952 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.5732113718986511, loss=5.8818159103393555
I0418 10:06:31.628230 140412933068544 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.42652902007102966, loss=6.602921962738037
I0418 10:07:11.662146 140412949853952 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.6597525477409363, loss=5.981068134307861
I0418 10:07:52.045821 140412933068544 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.6477047204971313, loss=5.856991767883301
I0418 10:08:32.294312 140412949853952 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.5448919534683228, loss=6.07449197769165
I0418 10:09:12.503326 140412933068544 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.5532228350639343, loss=5.971176624298096
I0418 10:09:52.735446 140412949853952 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.578129231929779, loss=5.778177261352539
I0418 10:10:33.010644 140412933068544 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.6715822815895081, loss=5.748367786407471
I0418 10:11:13.228717 140412949853952 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.5924732685089111, loss=5.814888954162598
I0418 10:11:53.444104 140412933068544 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.5934528112411499, loss=5.734403610229492
I0418 10:12:30.424331 140588895340352 spec.py:298] Evaluating on the training split.
I0418 10:12:42.698223 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 10:12:51.338061 140588895340352 spec.py:326] Evaluating on the test split.
I0418 10:12:52.992186 140588895340352 submission_runner.py:406] Time since start: 2754.36s, 	Step: 6293, 	{'train/accuracy': 0.15355467796325684, 'train/loss': 4.674384593963623, 'validation/accuracy': 0.14323998987674713, 'validation/loss': 4.755995273590088, 'validation/num_examples': 50000, 'test/accuracy': 0.10240000486373901, 'test/loss': 5.0877909660339355, 'test/num_examples': 10000, 'score': 2568.812723875046, 'total_duration': 2754.361873626709, 'accumulated_submission_time': 2568.812723875046, 'accumulated_eval_time': 174.1105923652649, 'accumulated_logging_time': 11.309327363967896}
I0418 10:12:53.003805 140412949853952 logging_writer.py:48] [6293] accumulated_eval_time=174.110592, accumulated_logging_time=11.309327, accumulated_submission_time=2568.812724, global_step=6293, preemption_count=0, score=2568.812724, test/accuracy=0.102400, test/loss=5.087791, test/num_examples=10000, total_duration=2754.361874, train/accuracy=0.153555, train/loss=4.674385, validation/accuracy=0.143240, validation/loss=4.755995, validation/num_examples=50000
I0418 10:12:53.085627 140588895340352 checkpoints.py:356] Saving checkpoint at step: 6293
I0418 10:12:54.041337 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_6293
I0418 10:12:54.052932 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_6293.
I0418 10:12:57.265860 140412933068544 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.6399210095405579, loss=5.907443523406982
I0418 10:13:36.307620 140412924675840 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.5530778765678406, loss=5.870497226715088
I0418 10:14:15.958011 140412933068544 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.5819050669670105, loss=5.765616416931152
I0418 10:14:56.113641 140412924675840 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.4230479896068573, loss=6.458189487457275
I0418 10:15:36.019023 140412933068544 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.45836183428764343, loss=6.124360084533691
I0418 10:16:16.489867 140412924675840 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.5875570178031921, loss=5.735897064208984
I0418 10:16:56.521575 140412933068544 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.5763074159622192, loss=5.727180004119873
I0418 10:17:36.670883 140412924675840 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.5399289131164551, loss=5.6012773513793945
I0418 10:18:17.021764 140412933068544 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.7057308554649353, loss=5.65186071395874
I0418 10:18:57.219438 140412924675840 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.47742873430252075, loss=6.227120399475098
I0418 10:19:37.788945 140412933068544 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.6664101481437683, loss=5.604767322540283
I0418 10:19:54.295252 140588895340352 spec.py:298] Evaluating on the training split.
I0418 10:20:08.364302 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 10:20:17.412961 140588895340352 spec.py:326] Evaluating on the test split.
I0418 10:20:19.057991 140588895340352 submission_runner.py:406] Time since start: 3200.43s, 	Step: 7342, 	{'train/accuracy': 0.1953710913658142, 'train/loss': 4.376893997192383, 'validation/accuracy': 0.1770399957895279, 'validation/loss': 4.468344688415527, 'validation/num_examples': 50000, 'test/accuracy': 0.13690000772476196, 'test/loss': 4.818387508392334, 'test/num_examples': 10000, 'score': 2989.0319254398346, 'total_duration': 3200.4276814460754, 'accumulated_submission_time': 2989.0319254398346, 'accumulated_eval_time': 198.8732554912567, 'accumulated_logging_time': 12.37194538116455}
I0418 10:20:19.072284 140412924675840 logging_writer.py:48] [7342] accumulated_eval_time=198.873255, accumulated_logging_time=12.371945, accumulated_submission_time=2989.031925, global_step=7342, preemption_count=0, score=2989.031925, test/accuracy=0.136900, test/loss=4.818388, test/num_examples=10000, total_duration=3200.427681, train/accuracy=0.195371, train/loss=4.376894, validation/accuracy=0.177040, validation/loss=4.468345, validation/num_examples=50000
I0418 10:20:19.177396 140588895340352 checkpoints.py:356] Saving checkpoint at step: 7342
I0418 10:20:19.903039 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_7342
I0418 10:20:19.917296 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_7342.
I0418 10:20:43.065681 140412933068544 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.5586035847663879, loss=5.64219331741333
I0418 10:21:22.981326 140412916283136 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.40102633833885193, loss=6.306458473205566
I0418 10:22:02.982048 140412933068544 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.5684536099433899, loss=5.595457077026367
I0418 10:22:43.182679 140412916283136 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.4386770725250244, loss=6.445683479309082
I0418 10:23:23.512345 140412933068544 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.49519506096839905, loss=6.4815778732299805
I0418 10:24:04.114926 140412916283136 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.567807137966156, loss=5.552986145019531
I0418 10:24:44.143612 140412933068544 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.5093052387237549, loss=5.874241828918457
I0418 10:25:24.460819 140412916283136 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.3919268548488617, loss=6.403936386108398
I0418 10:26:05.085975 140412933068544 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.5953968167304993, loss=5.458927154541016
I0418 10:26:45.097990 140412916283136 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.41207435727119446, loss=5.970131874084473
I0418 10:27:20.312360 140588895340352 spec.py:298] Evaluating on the training split.
I0418 10:27:34.857812 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 10:27:44.377810 140588895340352 spec.py:326] Evaluating on the test split.
I0418 10:27:46.031288 140588895340352 submission_runner.py:406] Time since start: 3647.40s, 	Step: 8388, 	{'train/accuracy': 0.22859375178813934, 'train/loss': 4.0883612632751465, 'validation/accuracy': 0.20867998898029327, 'validation/loss': 4.209028244018555, 'validation/num_examples': 50000, 'test/accuracy': 0.15820001065731049, 'test/loss': 4.608339309692383, 'test/num_examples': 10000, 'score': 3409.4042706489563, 'total_duration': 3647.401023864746, 'accumulated_submission_time': 3409.4042706489563, 'accumulated_eval_time': 224.592143535614, 'accumulated_logging_time': 13.232425928115845}
I0418 10:27:46.041130 140412933068544 logging_writer.py:48] [8388] accumulated_eval_time=224.592144, accumulated_logging_time=13.232426, accumulated_submission_time=3409.404271, global_step=8388, preemption_count=0, score=3409.404271, test/accuracy=0.158200, test/loss=4.608339, test/num_examples=10000, total_duration=3647.401024, train/accuracy=0.228594, train/loss=4.088361, validation/accuracy=0.208680, validation/loss=4.209028, validation/num_examples=50000
I0418 10:27:46.119485 140588895340352 checkpoints.py:356] Saving checkpoint at step: 8388
I0418 10:27:46.925603 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_8388
I0418 10:27:46.939845 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_8388.
I0418 10:27:52.074332 140412916283136 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.4908115565776825, loss=5.725866317749023
I0418 10:28:31.029214 140412907890432 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.4596717655658722, loss=6.527215003967285
I0418 10:29:11.307324 140412916283136 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.5352102518081665, loss=6.253074645996094
I0418 10:29:51.347041 140412907890432 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.5916755795478821, loss=5.472101211547852
I0418 10:30:31.891512 140412916283136 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.48431918025016785, loss=5.840213775634766
I0418 10:31:12.052088 140412907890432 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.5534405708312988, loss=5.441429138183594
I0418 10:31:52.059621 140412916283136 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.5554206371307373, loss=5.531006813049316
I0418 10:32:32.534579 140412907890432 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.6421769261360168, loss=5.4091362953186035
I0418 10:33:12.793209 140412916283136 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.4832852780818939, loss=6.3406782150268555
I0418 10:33:52.939851 140412907890432 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.5275617837905884, loss=5.470277309417725
I0418 10:34:33.200292 140412916283136 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.6075919270515442, loss=5.422741889953613
I0418 10:34:47.208700 140588895340352 spec.py:298] Evaluating on the training split.
I0418 10:35:01.704469 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 10:35:12.113188 140588895340352 spec.py:326] Evaluating on the test split.
I0418 10:35:13.761837 140588895340352 submission_runner.py:406] Time since start: 4095.13s, 	Step: 9436, 	{'train/accuracy': 0.26517578959465027, 'train/loss': 3.8037147521972656, 'validation/accuracy': 0.23827999830245972, 'validation/loss': 3.952683687210083, 'validation/num_examples': 50000, 'test/accuracy': 0.18320000171661377, 'test/loss': 4.390207290649414, 'test/num_examples': 10000, 'score': 3829.6493492126465, 'total_duration': 4095.13156414032, 'accumulated_submission_time': 3829.6493492126465, 'accumulated_eval_time': 251.1452395915985, 'accumulated_logging_time': 14.142561912536621}
I0418 10:35:13.776544 140412907890432 logging_writer.py:48] [9436] accumulated_eval_time=251.145240, accumulated_logging_time=14.142562, accumulated_submission_time=3829.649349, global_step=9436, preemption_count=0, score=3829.649349, test/accuracy=0.183200, test/loss=4.390207, test/num_examples=10000, total_duration=4095.131564, train/accuracy=0.265176, train/loss=3.803715, validation/accuracy=0.238280, validation/loss=3.952684, validation/num_examples=50000
I0418 10:35:13.935413 140588895340352 checkpoints.py:356] Saving checkpoint at step: 9436
I0418 10:35:14.838704 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_9436
I0418 10:35:14.852661 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_9436.
I0418 10:35:40.257348 140412916283136 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.4674391746520996, loss=5.776747703552246
I0418 10:36:20.415493 140411632838400 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.6112620830535889, loss=5.306388854980469
I0418 10:37:00.454615 140412916283136 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.45350706577301025, loss=6.32794713973999
I0418 10:37:40.584348 140411632838400 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.5338284373283386, loss=5.223538398742676
I0418 10:38:20.793231 140412916283136 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.7224494218826294, loss=5.291487693786621
I0418 10:39:01.451637 140411632838400 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.5487947463989258, loss=5.400689125061035
I0418 10:39:41.787786 140412916283136 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.5736668705940247, loss=5.184868335723877
I0418 10:40:21.987045 140411632838400 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.5767252445220947, loss=5.304427146911621
I0418 10:41:02.408201 140412916283136 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.5948722958564758, loss=5.365234375
I0418 10:41:43.108776 140411632838400 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.6092102527618408, loss=5.259421348571777
I0418 10:42:15.071044 140588895340352 spec.py:298] Evaluating on the training split.
I0418 10:42:29.138811 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 10:42:40.577846 140588895340352 spec.py:326] Evaluating on the test split.
I0418 10:42:42.238681 140588895340352 submission_runner.py:406] Time since start: 4543.61s, 	Step: 10480, 	{'train/accuracy': 0.29537108540534973, 'train/loss': 3.6718249320983887, 'validation/accuracy': 0.26736000180244446, 'validation/loss': 3.8045597076416016, 'validation/num_examples': 50000, 'test/accuracy': 0.20260000228881836, 'test/loss': 4.273815631866455, 'test/num_examples': 10000, 'score': 4249.838851451874, 'total_duration': 4543.608403682709, 'accumulated_submission_time': 4249.838851451874, 'accumulated_eval_time': 278.3128457069397, 'accumulated_logging_time': 15.241193532943726}
I0418 10:42:42.253998 140412916283136 logging_writer.py:48] [10480] accumulated_eval_time=278.312846, accumulated_logging_time=15.241194, accumulated_submission_time=4249.838851, global_step=10480, preemption_count=0, score=4249.838851, test/accuracy=0.202600, test/loss=4.273816, test/num_examples=10000, total_duration=4543.608404, train/accuracy=0.295371, train/loss=3.671825, validation/accuracy=0.267360, validation/loss=3.804560, validation/num_examples=50000
I0418 10:42:42.363036 140588895340352 checkpoints.py:356] Saving checkpoint at step: 10480
I0418 10:42:43.198401 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_10480
I0418 10:42:43.210495 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_10480.
I0418 10:42:51.490556 140411632838400 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.5444709658622742, loss=5.582953929901123
I0418 10:43:31.141550 140411624445696 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.5362359285354614, loss=5.655656814575195
I0418 10:44:11.447808 140411632838400 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.49601924419403076, loss=5.326369285583496
I0418 10:44:51.888428 140411624445696 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.5773169994354248, loss=5.118581771850586
I0418 10:45:31.972446 140411632838400 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.519967794418335, loss=5.6082258224487305
I0418 10:46:12.318692 140411624445696 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.45709577202796936, loss=6.191394805908203
I0418 10:46:52.562103 140411632838400 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.5268859267234802, loss=5.546292304992676
I0418 10:47:32.836877 140411624445696 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.45390868186950684, loss=6.283593654632568
I0418 10:48:13.287260 140411632838400 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.42987123131752014, loss=6.071481704711914
I0418 10:48:53.456642 140411624445696 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.61626136302948, loss=5.111051559448242
I0418 10:49:34.444478 140411632838400 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.5333534479141235, loss=5.589021682739258
I0418 10:49:43.410753 140588895340352 spec.py:298] Evaluating on the training split.
I0418 10:49:57.654251 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 10:50:08.486762 140588895340352 spec.py:326] Evaluating on the test split.
I0418 10:50:10.126251 140588895340352 submission_runner.py:406] Time since start: 4991.50s, 	Step: 11524, 	{'train/accuracy': 0.31947264075279236, 'train/loss': 3.527507781982422, 'validation/accuracy': 0.29462000727653503, 'validation/loss': 3.64550518989563, 'validation/num_examples': 50000, 'test/accuracy': 0.22440001368522644, 'test/loss': 4.127091407775879, 'test/num_examples': 10000, 'score': 4670.016874551773, 'total_duration': 4991.495959997177, 'accumulated_submission_time': 4670.016874551773, 'accumulated_eval_time': 305.02828788757324, 'accumulated_logging_time': 16.214516639709473}
I0418 10:50:10.140993 140411624445696 logging_writer.py:48] [11524] accumulated_eval_time=305.028288, accumulated_logging_time=16.214517, accumulated_submission_time=4670.016875, global_step=11524, preemption_count=0, score=4670.016875, test/accuracy=0.224400, test/loss=4.127091, test/num_examples=10000, total_duration=4991.495960, train/accuracy=0.319473, train/loss=3.527508, validation/accuracy=0.294620, validation/loss=3.645505, validation/num_examples=50000
I0418 10:50:10.270953 140588895340352 checkpoints.py:356] Saving checkpoint at step: 11524
I0418 10:50:11.099891 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_11524
I0418 10:50:11.114481 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_11524.
I0418 10:50:41.442074 140411632838400 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.6178256869316101, loss=5.026559829711914
I0418 10:51:22.183238 140411548976896 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.5274691581726074, loss=5.102936267852783
I0418 10:52:02.843269 140411632838400 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.5143359303474426, loss=5.990297794342041
I0418 10:52:43.181291 140411548976896 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.5928529500961304, loss=5.127744197845459
I0418 10:53:23.186316 140411632838400 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.5685888528823853, loss=5.285608291625977
I0418 10:54:03.692519 140411548976896 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.4848787486553192, loss=6.436287879943848
I0418 10:54:44.204836 140411632838400 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.5591387152671814, loss=5.072270393371582
I0418 10:55:24.409060 140411548976896 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.473901629447937, loss=6.389916896820068
I0418 10:56:04.782859 140411632838400 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.5344512462615967, loss=5.208576202392578
I0418 10:56:45.735293 140411548976896 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.5709477066993713, loss=5.03951358795166
I0418 10:57:11.225696 140588895340352 spec.py:298] Evaluating on the training split.
I0418 10:57:25.167079 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 10:57:36.723999 140588895340352 spec.py:326] Evaluating on the test split.
I0418 10:57:38.396655 140588895340352 submission_runner.py:406] Time since start: 5439.77s, 	Step: 12564, 	{'train/accuracy': 0.34187498688697815, 'train/loss': 3.344667673110962, 'validation/accuracy': 0.31379997730255127, 'validation/loss': 3.4939751625061035, 'validation/num_examples': 50000, 'test/accuracy': 0.2435000091791153, 'test/loss': 3.989381790161133, 'test/num_examples': 10000, 'score': 5090.100670814514, 'total_duration': 5439.766398668289, 'accumulated_submission_time': 5090.100670814514, 'accumulated_eval_time': 332.19921684265137, 'accumulated_logging_time': 17.20971393585205}
I0418 10:57:38.407563 140411632838400 logging_writer.py:48] [12564] accumulated_eval_time=332.199217, accumulated_logging_time=17.209714, accumulated_submission_time=5090.100671, global_step=12564, preemption_count=0, score=5090.100671, test/accuracy=0.243500, test/loss=3.989382, test/num_examples=10000, total_duration=5439.766399, train/accuracy=0.341875, train/loss=3.344668, validation/accuracy=0.313800, validation/loss=3.493975, validation/num_examples=50000
I0418 10:57:38.507139 140588895340352 checkpoints.py:356] Saving checkpoint at step: 12564
I0418 10:57:39.361943 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_12564
I0418 10:57:39.374151 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_12564.
I0418 10:57:53.898351 140411548976896 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.624625563621521, loss=4.979439735412598
I0418 10:58:33.942741 140411540584192 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.38929322361946106, loss=6.361940383911133
I0418 10:59:14.569773 140411548976896 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.48451000452041626, loss=6.2967305183410645
I0418 10:59:55.131307 140411540584192 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.6751042008399963, loss=5.115601062774658
I0418 11:00:35.550615 140411548976896 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.4260423183441162, loss=6.238674640655518
I0418 11:01:15.674090 140411540584192 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.5819490551948547, loss=5.005768775939941
I0418 11:01:56.167983 140411548976896 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.49103957414627075, loss=6.01430082321167
I0418 11:02:36.546066 140411540584192 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.5262167453765869, loss=5.064160346984863
I0418 11:03:16.980197 140411548976896 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.5432891845703125, loss=5.2952351570129395
I0418 11:03:57.723657 140411540584192 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.5884890556335449, loss=5.118163108825684
I0418 11:04:39.058618 140411548976896 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.6519898176193237, loss=4.905215263366699
I0418 11:04:39.728733 140588895340352 spec.py:298] Evaluating on the training split.
I0418 11:04:53.879498 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 11:05:05.149973 140588895340352 spec.py:326] Evaluating on the test split.
I0418 11:05:06.817364 140588895340352 submission_runner.py:406] Time since start: 5888.19s, 	Step: 13603, 	{'train/accuracy': 0.3636523485183716, 'train/loss': 3.2581868171691895, 'validation/accuracy': 0.33017998933792114, 'validation/loss': 3.4344542026519775, 'validation/num_examples': 50000, 'test/accuracy': 0.24880000948905945, 'test/loss': 3.962186574935913, 'test/num_examples': 10000, 'score': 5510.433007717133, 'total_duration': 5888.187043905258, 'accumulated_submission_time': 5510.433007717133, 'accumulated_eval_time': 359.2877712249756, 'accumulated_logging_time': 18.188780069351196}
I0418 11:05:06.833712 140411540584192 logging_writer.py:48] [13603] accumulated_eval_time=359.287771, accumulated_logging_time=18.188780, accumulated_submission_time=5510.433008, global_step=13603, preemption_count=0, score=5510.433008, test/accuracy=0.248800, test/loss=3.962187, test/num_examples=10000, total_duration=5888.187044, train/accuracy=0.363652, train/loss=3.258187, validation/accuracy=0.330180, validation/loss=3.434454, validation/num_examples=50000
I0418 11:05:06.936729 140588895340352 checkpoints.py:356] Saving checkpoint at step: 13603
I0418 11:05:07.685308 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_13603
I0418 11:05:07.703108 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_13603.
I0418 11:05:46.978505 140411548976896 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.5511687994003296, loss=5.140800952911377
I0418 11:06:28.312191 140411532191488 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.5288830995559692, loss=6.402007102966309
I0418 11:07:09.602340 140411548976896 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.6186611652374268, loss=4.904263496398926
I0418 11:07:49.906332 140411532191488 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.6112170815467834, loss=4.915028095245361
I0418 11:08:30.425364 140411548976896 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.47282564640045166, loss=5.961270332336426
I0418 11:09:10.851845 140411532191488 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.5568405985832214, loss=4.859982013702393
I0418 11:09:51.926745 140411548976896 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.5669035911560059, loss=5.0410614013671875
I0418 11:10:32.691070 140411532191488 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.6085352897644043, loss=4.879866600036621
I0418 11:11:13.384653 140411548976896 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.4106431007385254, loss=6.328342437744141
I0418 11:11:54.318835 140411532191488 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.6002817749977112, loss=4.783547401428223
I0418 11:12:08.079850 140588895340352 spec.py:298] Evaluating on the training split.
I0418 11:12:22.175074 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 11:12:34.112420 140588895340352 spec.py:326] Evaluating on the test split.
I0418 11:12:35.767048 140588895340352 submission_runner.py:406] Time since start: 6337.14s, 	Step: 14635, 	{'train/accuracy': 0.3933984339237213, 'train/loss': 3.045436382293701, 'validation/accuracy': 0.3510199785232544, 'validation/loss': 3.2551517486572266, 'validation/num_examples': 50000, 'test/accuracy': 0.26900002360343933, 'test/loss': 3.7806971073150635, 'test/num_examples': 10000, 'score': 5930.783458709717, 'total_duration': 6337.136749505997, 'accumulated_submission_time': 5930.783458709717, 'accumulated_eval_time': 386.9748980998993, 'accumulated_logging_time': 19.080673694610596}
I0418 11:12:35.782377 140411548976896 logging_writer.py:48] [14635] accumulated_eval_time=386.974898, accumulated_logging_time=19.080674, accumulated_submission_time=5930.783459, global_step=14635, preemption_count=0, score=5930.783459, test/accuracy=0.269000, test/loss=3.780697, test/num_examples=10000, total_duration=6337.136750, train/accuracy=0.393398, train/loss=3.045436, validation/accuracy=0.351020, validation/loss=3.255152, validation/num_examples=50000
I0418 11:12:35.888590 140588895340352 checkpoints.py:356] Saving checkpoint at step: 14635
I0418 11:12:36.764970 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_14635
I0418 11:12:36.780781 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_14635.
I0418 11:13:02.642778 140411532191488 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.6001888513565063, loss=4.921105861663818
I0418 11:13:43.542848 140411288934144 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.6782383322715759, loss=4.8277201652526855
I0418 11:14:24.579736 140411532191488 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.607077956199646, loss=4.907306671142578
I0418 11:15:05.658699 140411288934144 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.4151599109172821, loss=5.999856948852539
I0418 11:15:46.769407 140411532191488 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.4147197902202606, loss=6.309293270111084
I0418 11:16:27.798396 140411288934144 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.5637845396995544, loss=4.854453086853027
I0418 11:17:08.840091 140411532191488 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.4283839166164398, loss=6.238107681274414
I0418 11:17:49.878927 140411288934144 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.6383764147758484, loss=4.821887493133545
I0418 11:18:30.858355 140411532191488 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.45928239822387695, loss=6.294467449188232
I0418 11:19:11.672107 140411288934144 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.6509369015693665, loss=4.839158058166504
I0418 11:19:36.931326 140588895340352 spec.py:298] Evaluating on the training split.
I0418 11:19:51.887130 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 11:20:03.290966 140588895340352 spec.py:326] Evaluating on the test split.
I0418 11:20:04.935682 140588895340352 submission_runner.py:406] Time since start: 6786.31s, 	Step: 15663, 	{'train/accuracy': 0.40220701694488525, 'train/loss': 2.9306020736694336, 'validation/accuracy': 0.36941999197006226, 'validation/loss': 3.0936648845672607, 'validation/num_examples': 50000, 'test/accuracy': 0.28450000286102295, 'test/loss': 3.647273302078247, 'test/num_examples': 10000, 'score': 6350.912359714508, 'total_duration': 6786.3053476810455, 'accumulated_submission_time': 6350.912359714508, 'accumulated_eval_time': 414.9791507720947, 'accumulated_logging_time': 20.095966577529907}
I0418 11:20:04.951444 140411532191488 logging_writer.py:48] [15663] accumulated_eval_time=414.979151, accumulated_logging_time=20.095967, accumulated_submission_time=6350.912360, global_step=15663, preemption_count=0, score=6350.912360, test/accuracy=0.284500, test/loss=3.647273, test/num_examples=10000, total_duration=6786.305348, train/accuracy=0.402207, train/loss=2.930602, validation/accuracy=0.369420, validation/loss=3.093665, validation/num_examples=50000
I0418 11:20:05.056195 140588895340352 checkpoints.py:356] Saving checkpoint at step: 15663
I0418 11:20:05.838187 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_15663
I0418 11:20:05.853310 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_15663.
I0418 11:20:20.712882 140411288934144 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.592556893825531, loss=4.730894088745117
I0418 11:21:01.612936 140411205056256 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.46080124378204346, loss=6.228630065917969
I0418 11:21:43.341095 140411288934144 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.4629836678504944, loss=6.277238845825195
I0418 11:22:24.519776 140411205056256 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.5297839045524597, loss=5.2754058837890625
I0418 11:23:05.985097 140411288934144 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.6253982782363892, loss=4.7497148513793945
I0418 11:23:47.463609 140411205056256 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.467340350151062, loss=5.661158084869385
I0418 11:24:29.281713 140411288934144 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.4211233854293823, loss=6.312338829040527
I0418 11:25:10.956001 140411205056256 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.6189171075820923, loss=4.753296852111816
I0418 11:25:52.464246 140411288934144 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.5245100259780884, loss=4.952032566070557
I0418 11:26:33.270727 140411205056256 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.588983416557312, loss=4.6761088371276855
I0418 11:27:06.021374 140588895340352 spec.py:298] Evaluating on the training split.
I0418 11:27:20.666943 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 11:27:32.783543 140588895340352 spec.py:326] Evaluating on the test split.
I0418 11:27:34.436086 140588895340352 submission_runner.py:406] Time since start: 7235.81s, 	Step: 16682, 	{'train/accuracy': 0.4200976490974426, 'train/loss': 2.818995952606201, 'validation/accuracy': 0.3877599835395813, 'validation/loss': 2.994821548461914, 'validation/num_examples': 50000, 'test/accuracy': 0.2955000102519989, 'test/loss': 3.5650272369384766, 'test/num_examples': 10000, 'score': 6771.059458732605, 'total_duration': 7235.805813550949, 'accumulated_submission_time': 6771.059458732605, 'accumulated_eval_time': 443.3938202857971, 'accumulated_logging_time': 21.014688968658447}
I0418 11:27:34.452346 140411288934144 logging_writer.py:48] [16682] accumulated_eval_time=443.393820, accumulated_logging_time=21.014689, accumulated_submission_time=6771.059459, global_step=16682, preemption_count=0, score=6771.059459, test/accuracy=0.295500, test/loss=3.565027, test/num_examples=10000, total_duration=7235.805814, train/accuracy=0.420098, train/loss=2.818996, validation/accuracy=0.387760, validation/loss=2.994822, validation/num_examples=50000
I0418 11:27:34.549726 140588895340352 checkpoints.py:356] Saving checkpoint at step: 16682
I0418 11:27:35.343035 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_16682
I0418 11:27:35.359303 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_16682.
I0418 11:27:42.825145 140411205056256 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.5519089102745056, loss=4.877716064453125
I0418 11:28:22.592600 140411196663552 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.45429664850234985, loss=5.9040422439575195
I0418 11:29:03.201245 140411205056256 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.6166894435882568, loss=4.653007984161377
I0418 11:29:43.916290 140411196663552 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.6070073246955872, loss=4.822351932525635
I0418 11:30:24.608531 140411205056256 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.6284593343734741, loss=4.668369293212891
I0418 11:31:05.262117 140411196663552 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.539724588394165, loss=5.830132961273193
I0418 11:31:46.340427 140411205056256 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.6199954748153687, loss=4.815990447998047
I0418 11:32:27.561600 140411196663552 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.4945460259914398, loss=6.092306137084961
I0418 11:33:08.686033 140411205056256 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.6135872006416321, loss=5.117680072784424
I0418 11:33:49.858087 140411196663552 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.6011781692504883, loss=4.668023109436035
I0418 11:34:30.882455 140411205056256 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.5719603300094604, loss=4.6136980056762695
I0418 11:34:35.549978 140588895340352 spec.py:298] Evaluating on the training split.
I0418 11:34:49.953117 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 11:35:02.196695 140588895340352 spec.py:326] Evaluating on the test split.
I0418 11:35:03.862907 140588895340352 submission_runner.py:406] Time since start: 7685.23s, 	Step: 17713, 	{'train/accuracy': 0.43849608302116394, 'train/loss': 2.746001720428467, 'validation/accuracy': 0.39969998598098755, 'validation/loss': 2.9365105628967285, 'validation/num_examples': 50000, 'test/accuracy': 0.3091000020503998, 'test/loss': 3.525444269180298, 'test/num_examples': 10000, 'score': 7191.228957653046, 'total_duration': 7685.232613801956, 'accumulated_submission_time': 7191.228957653046, 'accumulated_eval_time': 471.70671367645264, 'accumulated_logging_time': 21.9390869140625}
I0418 11:35:03.876882 140411196663552 logging_writer.py:48] [17713] accumulated_eval_time=471.706714, accumulated_logging_time=21.939087, accumulated_submission_time=7191.228958, global_step=17713, preemption_count=0, score=7191.228958, test/accuracy=0.309100, test/loss=3.525444, test/num_examples=10000, total_duration=7685.232614, train/accuracy=0.438496, train/loss=2.746002, validation/accuracy=0.399700, validation/loss=2.936511, validation/num_examples=50000
I0418 11:35:04.044013 140588895340352 checkpoints.py:356] Saving checkpoint at step: 17713
I0418 11:35:04.914386 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_17713
I0418 11:35:04.930876 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_17713.
I0418 11:35:39.824002 140411205056256 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.5538374781608582, loss=4.818765163421631
I0418 11:36:20.837311 140411188270848 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.5460094809532166, loss=4.714298725128174
I0418 11:37:01.908195 140411205056256 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.5822531580924988, loss=4.685156345367432
I0418 11:37:42.706336 140411188270848 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.6335102319717407, loss=4.673921585083008
I0418 11:38:24.231010 140411205056256 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.6361549496650696, loss=4.633834362030029
I0418 11:39:05.334433 140411188270848 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.6323029398918152, loss=5.117773056030273
I0418 11:39:45.982306 140411205056256 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.6245399117469788, loss=4.545372009277344
I0418 11:40:26.907215 140411188270848 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.6059433817863464, loss=4.812134265899658
I0418 11:41:08.289098 140411205056256 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.5974886417388916, loss=4.605752944946289
I0418 11:41:49.449296 140411188270848 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.601346492767334, loss=4.628371238708496
I0418 11:42:05.027998 140588895340352 spec.py:298] Evaluating on the training split.
I0418 11:42:19.375182 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 11:42:32.079109 140588895340352 spec.py:326] Evaluating on the test split.
I0418 11:42:33.730917 140588895340352 submission_runner.py:406] Time since start: 8135.10s, 	Step: 18740, 	{'train/accuracy': 0.45384764671325684, 'train/loss': 2.6570589542388916, 'validation/accuracy': 0.4128599762916565, 'validation/loss': 2.876776695251465, 'validation/num_examples': 50000, 'test/accuracy': 0.3176000118255615, 'test/loss': 3.4601240158081055, 'test/num_examples': 10000, 'score': 7611.295107603073, 'total_duration': 8135.100620746613, 'accumulated_submission_time': 7611.295107603073, 'accumulated_eval_time': 500.4095685482025, 'accumulated_logging_time': 23.017999410629272}
I0418 11:42:33.748305 140411205056256 logging_writer.py:48] [18740] accumulated_eval_time=500.409569, accumulated_logging_time=23.017999, accumulated_submission_time=7611.295108, global_step=18740, preemption_count=0, score=7611.295108, test/accuracy=0.317600, test/loss=3.460124, test/num_examples=10000, total_duration=8135.100621, train/accuracy=0.453848, train/loss=2.657059, validation/accuracy=0.412860, validation/loss=2.876777, validation/num_examples=50000
I0418 11:42:33.896615 140588895340352 checkpoints.py:356] Saving checkpoint at step: 18740
I0418 11:42:34.700036 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_18740
I0418 11:42:34.715994 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_18740.
I0418 11:42:58.664115 140411188270848 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.5080638527870178, loss=4.954099178314209
I0418 11:43:39.969996 140411179878144 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.728727400302887, loss=4.681845188140869
I0418 11:44:21.225926 140411188270848 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.6163395643234253, loss=4.542540073394775
I0418 11:45:02.855829 140411179878144 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.46829789876937866, loss=6.165674209594727
I0418 11:45:44.330851 140411188270848 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.6539223194122314, loss=4.66041374206543
I0418 11:46:26.069445 140411179878144 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.5083310604095459, loss=5.585700035095215
I0418 11:47:07.737496 140411188270848 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.5860651731491089, loss=4.588923931121826
I0418 11:47:49.350887 140411179878144 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.5090961456298828, loss=5.365278720855713
I0418 11:48:30.866354 140411188270848 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.5314381122589111, loss=5.212510108947754
I0418 11:49:12.090386 140411179878144 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.6381273865699768, loss=4.609809875488281
I0418 11:49:34.898925 140588895340352 spec.py:298] Evaluating on the training split.
I0418 11:49:49.264790 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 11:50:01.326102 140588895340352 spec.py:326] Evaluating on the test split.
I0418 11:50:02.973268 140588895340352 submission_runner.py:406] Time since start: 8584.34s, 	Step: 19756, 	{'train/accuracy': 0.47935545444488525, 'train/loss': 2.5558032989501953, 'validation/accuracy': 0.4272199869155884, 'validation/loss': 2.80623459815979, 'validation/num_examples': 50000, 'test/accuracy': 0.32440000772476196, 'test/loss': 3.4039435386657715, 'test/num_examples': 10000, 'score': 8031.448212146759, 'total_duration': 8584.343006134033, 'accumulated_submission_time': 8031.448212146759, 'accumulated_eval_time': 528.4838931560516, 'accumulated_logging_time': 24.012748956680298}
I0418 11:50:02.988576 140411188270848 logging_writer.py:48] [19756] accumulated_eval_time=528.483893, accumulated_logging_time=24.012749, accumulated_submission_time=8031.448212, global_step=19756, preemption_count=0, score=8031.448212, test/accuracy=0.324400, test/loss=3.403944, test/num_examples=10000, total_duration=8584.343006, train/accuracy=0.479355, train/loss=2.555803, validation/accuracy=0.427220, validation/loss=2.806235, validation/num_examples=50000
I0418 11:50:03.123703 140588895340352 checkpoints.py:356] Saving checkpoint at step: 19756
I0418 11:50:04.009491 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_19756
I0418 11:50:04.025502 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_19756.
I0418 11:50:21.646057 140411179878144 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.6146873235702515, loss=4.517167091369629
I0418 11:51:02.605687 140410978551552 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.5687039494514465, loss=4.621089935302734
I0418 11:51:43.887891 140411179878144 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.552264928817749, loss=6.120098114013672
I0418 11:52:25.611724 140410978551552 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.6094071269035339, loss=4.556774616241455
I0418 11:53:07.069148 140411179878144 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.6317620873451233, loss=4.576335906982422
I0418 11:53:48.600397 140410978551552 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.5942933559417725, loss=4.503177165985107
I0418 11:54:29.945982 140411179878144 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.6445043087005615, loss=4.5631489753723145
I0418 11:55:11.108196 140410978551552 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.5918847918510437, loss=4.619837760925293
I0418 11:55:52.353264 140411179878144 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.6230975389480591, loss=4.526965141296387
I0418 11:56:33.244724 140410978551552 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.4698933959007263, loss=5.995748519897461
I0418 11:57:04.208256 140588895340352 spec.py:298] Evaluating on the training split.
I0418 11:57:18.990367 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 11:57:31.234652 140588895340352 spec.py:326] Evaluating on the test split.
I0418 11:57:32.895975 140588895340352 submission_runner.py:406] Time since start: 9034.27s, 	Step: 20777, 	{'train/accuracy': 0.4797070324420929, 'train/loss': 2.5169482231140137, 'validation/accuracy': 0.44165998697280884, 'validation/loss': 2.7020232677459717, 'validation/num_examples': 50000, 'test/accuracy': 0.3442000150680542, 'test/loss': 3.2963173389434814, 'test/num_examples': 10000, 'score': 8451.60296368599, 'total_duration': 9034.265623092651, 'accumulated_submission_time': 8451.60296368599, 'accumulated_eval_time': 557.1714894771576, 'accumulated_logging_time': 25.07313823699951}
I0418 11:57:32.911002 140411179878144 logging_writer.py:48] [20777] accumulated_eval_time=557.171489, accumulated_logging_time=25.073138, accumulated_submission_time=8451.602964, global_step=20777, preemption_count=0, score=8451.602964, test/accuracy=0.344200, test/loss=3.296317, test/num_examples=10000, total_duration=9034.265623, train/accuracy=0.479707, train/loss=2.516948, validation/accuracy=0.441660, validation/loss=2.702023, validation/num_examples=50000
I0418 11:57:33.081387 140588895340352 checkpoints.py:356] Saving checkpoint at step: 20777
I0418 11:57:33.979351 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_20777
I0418 11:57:33.996757 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_20777.
I0418 11:57:43.416942 140410978551552 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.5714988112449646, loss=4.9220757484436035
I0418 11:58:23.177772 140410970158848 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.44096362590789795, loss=6.037919998168945
I0418 11:59:03.919280 140410978551552 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.6044324636459351, loss=4.487793922424316
I0418 11:59:44.167080 140410970158848 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.5865424275398254, loss=4.491015911102295
I0418 12:00:24.767298 140410978551552 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.6297655701637268, loss=4.858201026916504
I0418 12:01:05.800382 140410970158848 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.5106054544448853, loss=5.304177284240723
I0418 12:01:46.775840 140410978551552 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.5921727418899536, loss=4.49044132232666
I0418 12:02:27.989936 140410970158848 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.49949246644973755, loss=6.214268684387207
I0418 12:03:08.897610 140410978551552 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.6119080781936646, loss=4.482974529266357
I0418 12:03:49.731379 140410970158848 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.5856704711914062, loss=4.7479777336120605
I0418 12:04:30.583146 140410978551552 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.6101237535476685, loss=4.504609107971191
I0418 12:04:34.306221 140588895340352 spec.py:298] Evaluating on the training split.
I0418 12:04:48.272930 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 12:05:01.554023 140588895340352 spec.py:326] Evaluating on the test split.
I0418 12:05:03.211465 140588895340352 submission_runner.py:406] Time since start: 9484.58s, 	Step: 21811, 	{'train/accuracy': 0.48027342557907104, 'train/loss': 2.5749154090881348, 'validation/accuracy': 0.4399999976158142, 'validation/loss': 2.768078565597534, 'validation/num_examples': 50000, 'test/accuracy': 0.3466000258922577, 'test/loss': 3.3403618335723877, 'test/num_examples': 10000, 'score': 8871.89065361023, 'total_duration': 9484.581191062927, 'accumulated_submission_time': 8871.89065361023, 'accumulated_eval_time': 586.076700925827, 'accumulated_logging_time': 26.175122022628784}
I0418 12:05:03.228395 140410970158848 logging_writer.py:48] [21811] accumulated_eval_time=586.076701, accumulated_logging_time=26.175122, accumulated_submission_time=8871.890654, global_step=21811, preemption_count=0, score=8871.890654, test/accuracy=0.346600, test/loss=3.340362, test/num_examples=10000, total_duration=9484.581191, train/accuracy=0.480273, train/loss=2.574915, validation/accuracy=0.440000, validation/loss=2.768079, validation/num_examples=50000
I0418 12:05:03.335110 140588895340352 checkpoints.py:356] Saving checkpoint at step: 21811
I0418 12:05:04.180619 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_21811
I0418 12:05:04.196594 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_21811.
I0418 12:05:39.668134 140410978551552 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.6463244557380676, loss=4.534947395324707
I0418 12:06:20.542854 140410961766144 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.599014163017273, loss=4.489292144775391
I0418 12:07:01.376910 140410978551552 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.6405751705169678, loss=4.438582897186279
I0418 12:07:43.147131 140410961766144 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.5250763893127441, loss=5.383825302124023
I0418 12:08:23.843358 140410978551552 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.6083610653877258, loss=4.497612476348877
I0418 12:09:04.745317 140410961766144 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.6027831435203552, loss=4.385837554931641
I0418 12:09:45.446847 140410978551552 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.660052478313446, loss=4.485065460205078
I0418 12:10:26.648304 140410961766144 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.5399430990219116, loss=5.464827060699463
I0418 12:11:07.765452 140410978551552 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.6274250745773315, loss=4.533116340637207
I0418 12:11:48.792365 140410961766144 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.6198111772537231, loss=4.38484001159668
I0418 12:12:04.473295 140588895340352 spec.py:298] Evaluating on the training split.
I0418 12:12:19.071809 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 12:12:31.871632 140588895340352 spec.py:326] Evaluating on the test split.
I0418 12:12:33.513262 140588895340352 submission_runner.py:406] Time since start: 9934.88s, 	Step: 22840, 	{'train/accuracy': 0.5030273199081421, 'train/loss': 2.392740488052368, 'validation/accuracy': 0.4592999815940857, 'validation/loss': 2.5979881286621094, 'validation/num_examples': 50000, 'test/accuracy': 0.35590001940727234, 'test/loss': 3.2174692153930664, 'test/num_examples': 10000, 'score': 9292.140046596527, 'total_duration': 9934.882987499237, 'accumulated_submission_time': 9292.140046596527, 'accumulated_eval_time': 615.1166138648987, 'accumulated_logging_time': 27.16744303703308}
I0418 12:12:33.531090 140410978551552 logging_writer.py:48] [22840] accumulated_eval_time=615.116614, accumulated_logging_time=27.167443, accumulated_submission_time=9292.140047, global_step=22840, preemption_count=0, score=9292.140047, test/accuracy=0.355900, test/loss=3.217469, test/num_examples=10000, total_duration=9934.882987, train/accuracy=0.503027, train/loss=2.392740, validation/accuracy=0.459300, validation/loss=2.597988, validation/num_examples=50000
I0418 12:12:33.697118 140588895340352 checkpoints.py:356] Saving checkpoint at step: 22840
I0418 12:12:34.668811 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_22840
I0418 12:12:34.683595 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_22840.
I0418 12:12:58.525232 140410961766144 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.6483145356178284, loss=4.404045104980469
I0418 12:13:39.010670 140410953373440 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.6955918669700623, loss=4.459644794464111
I0418 12:14:20.231756 140410961766144 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.5563071370124817, loss=5.370719909667969
I0418 12:15:02.127425 140410953373440 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.6170341372489929, loss=4.419228553771973
I0418 12:15:42.984794 140410961766144 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.6265169978141785, loss=4.623753547668457
I0418 12:16:23.602821 140410953373440 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.5587738752365112, loss=4.920407295227051
I0418 12:17:04.484145 140410961766144 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.4664088487625122, loss=5.468935966491699
I0418 12:17:45.785053 140410953373440 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.6255142092704773, loss=4.4018025398254395
I0418 12:18:26.316593 140410961766144 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.6395466923713684, loss=4.517100811004639
I0418 12:19:07.534496 140410953373440 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.6774841547012329, loss=4.4310455322265625
I0418 12:19:34.856555 140588895340352 spec.py:298] Evaluating on the training split.
I0418 12:19:49.623619 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 12:20:01.177458 140588895340352 spec.py:326] Evaluating on the test split.
I0418 12:20:02.850747 140588895340352 submission_runner.py:406] Time since start: 10384.22s, 	Step: 23868, 	{'train/accuracy': 0.5216601490974426, 'train/loss': 2.3356943130493164, 'validation/accuracy': 0.46719998121261597, 'validation/loss': 2.5898194313049316, 'validation/num_examples': 50000, 'test/accuracy': 0.3671000301837921, 'test/loss': 3.2059173583984375, 'test/num_examples': 10000, 'score': 9712.291100740433, 'total_duration': 10384.220490932465, 'accumulated_submission_time': 9712.291100740433, 'accumulated_eval_time': 643.1107819080353, 'accumulated_logging_time': 28.339356899261475}
I0418 12:20:02.866768 140410961766144 logging_writer.py:48] [23868] accumulated_eval_time=643.110782, accumulated_logging_time=28.339357, accumulated_submission_time=9712.291101, global_step=23868, preemption_count=0, score=9712.291101, test/accuracy=0.367100, test/loss=3.205917, test/num_examples=10000, total_duration=10384.220491, train/accuracy=0.521660, train/loss=2.335694, validation/accuracy=0.467200, validation/loss=2.589819, validation/num_examples=50000
I0418 12:20:03.351305 140588895340352 checkpoints.py:356] Saving checkpoint at step: 23868
I0418 12:20:04.799515 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_23868
I0418 12:20:04.817207 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_23868.
I0418 12:20:17.799706 140410953373440 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.6120878458023071, loss=4.5058512687683105
I0418 12:20:59.322890 140410735294208 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.6412833333015442, loss=4.623740196228027
I0418 12:21:42.044248 140410953373440 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.6391198039054871, loss=4.426329612731934
I0418 12:22:24.284735 140410735294208 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.5947607755661011, loss=4.918095588684082
I0418 12:23:06.774187 140410953373440 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.6984915137290955, loss=4.458639144897461
I0418 12:23:48.577359 140410735294208 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.6569898128509521, loss=4.400940895080566
I0418 12:24:31.157037 140410953373440 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.46073809266090393, loss=5.9783935546875
I0418 12:25:13.731658 140410735294208 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.4678269028663635, loss=5.949203968048096
I0418 12:25:56.770586 140410953373440 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.6788778901100159, loss=4.437707901000977
I0418 12:26:39.486687 140410735294208 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.6334571838378906, loss=4.263481140136719
I0418 12:27:04.834358 140588895340352 spec.py:298] Evaluating on the training split.
I0418 12:27:16.782593 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 12:27:29.928245 140588895340352 spec.py:326] Evaluating on the test split.
I0418 12:27:31.576214 140588895340352 submission_runner.py:406] Time since start: 10832.95s, 	Step: 24862, 	{'train/accuracy': 0.5180078148841858, 'train/loss': 2.328747272491455, 'validation/accuracy': 0.4762199819087982, 'validation/loss': 2.5247602462768555, 'validation/num_examples': 50000, 'test/accuracy': 0.37220001220703125, 'test/loss': 3.160764455795288, 'test/num_examples': 10000, 'score': 10132.28794670105, 'total_duration': 10832.945937395096, 'accumulated_submission_time': 10132.28794670105, 'accumulated_eval_time': 669.8525927066803, 'accumulated_logging_time': 30.307008266448975}
I0418 12:27:31.596376 140410953373440 logging_writer.py:48] [24862] accumulated_eval_time=669.852593, accumulated_logging_time=30.307008, accumulated_submission_time=10132.287947, global_step=24862, preemption_count=0, score=10132.287947, test/accuracy=0.372200, test/loss=3.160764, test/num_examples=10000, total_duration=10832.945937, train/accuracy=0.518008, train/loss=2.328747, validation/accuracy=0.476220, validation/loss=2.524760, validation/num_examples=50000
I0418 12:27:31.743752 140588895340352 checkpoints.py:356] Saving checkpoint at step: 24862
I0418 12:27:32.698731 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_24862
I0418 12:27:32.716877 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_24862.
I0418 12:27:48.026029 140410735294208 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.6434189081192017, loss=4.371212959289551
I0418 12:28:27.827782 140410726901504 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.638346254825592, loss=4.514310359954834
I0418 12:29:08.554102 140410735294208 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.5111663341522217, loss=5.300006866455078
I0418 12:29:49.627156 140410726901504 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.6150365471839905, loss=4.345717430114746
I0418 12:30:30.109317 140410735294208 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.611719012260437, loss=4.600378036499023
I0418 12:31:10.882287 140410726901504 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.46029362082481384, loss=5.814180850982666
I0418 12:31:51.684952 140410735294208 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.564868152141571, loss=4.749341011047363
I0418 12:32:32.255965 140410726901504 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.620011568069458, loss=4.157766819000244
I0418 12:33:12.743582 140410735294208 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.6925502419471741, loss=4.412477493286133
I0418 12:33:53.819324 140410726901504 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.5947572588920593, loss=4.417729377746582
I0418 12:34:32.954727 140588895340352 spec.py:298] Evaluating on the training split.
I0418 12:34:43.808147 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 12:34:56.827487 140588895340352 spec.py:326] Evaluating on the test split.
I0418 12:34:58.469417 140588895340352 submission_runner.py:406] Time since start: 11279.84s, 	Step: 25898, 	{'train/accuracy': 0.5267968773841858, 'train/loss': 2.2384138107299805, 'validation/accuracy': 0.4835599958896637, 'validation/loss': 2.445570707321167, 'validation/num_examples': 50000, 'test/accuracy': 0.37370002269744873, 'test/loss': 3.0754311084747314, 'test/num_examples': 10000, 'score': 10552.493962287903, 'total_duration': 11279.839145421982, 'accumulated_submission_time': 10552.493962287903, 'accumulated_eval_time': 695.3672559261322, 'accumulated_logging_time': 31.4588782787323}
I0418 12:34:58.487097 140410735294208 logging_writer.py:48] [25898] accumulated_eval_time=695.367256, accumulated_logging_time=31.458878, accumulated_submission_time=10552.493962, global_step=25898, preemption_count=0, score=10552.493962, test/accuracy=0.373700, test/loss=3.075431, test/num_examples=10000, total_duration=11279.839145, train/accuracy=0.526797, train/loss=2.238414, validation/accuracy=0.483560, validation/loss=2.445571, validation/num_examples=50000
I0418 12:34:58.618768 140588895340352 checkpoints.py:356] Saving checkpoint at step: 25898
I0418 12:34:59.615502 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_25898
I0418 12:34:59.633413 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_25898.
I0418 12:35:00.849113 140410726901504 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.5297311544418335, loss=5.339673042297363
I0418 12:35:40.125270 140410718508800 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.5371692180633545, loss=5.307954788208008
I0418 12:36:20.457465 140410726901504 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.5590881109237671, loss=4.515036582946777
I0418 12:37:01.072645 140410718508800 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.5948852300643921, loss=4.365658283233643
I0418 12:37:41.822703 140410726901504 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.7239448428153992, loss=4.333791732788086
I0418 12:38:22.806876 140410718508800 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.601342499256134, loss=4.219110012054443
I0418 12:39:03.291119 140410726901504 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.5935917496681213, loss=4.382558345794678
I0418 12:39:43.805947 140410718508800 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.6201117634773254, loss=4.275082111358643
I0418 12:40:24.583977 140410726901504 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.6352758407592773, loss=4.166137218475342
I0418 12:41:05.042679 140410718508800 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.652727484703064, loss=4.245129108428955
I0418 12:41:45.892300 140410726901504 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.5690423250198364, loss=4.544583320617676
I0418 12:41:59.871278 140588895340352 spec.py:298] Evaluating on the training split.
I0418 12:42:10.105357 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 12:42:23.416744 140588895340352 spec.py:326] Evaluating on the test split.
I0418 12:42:25.075063 140588895340352 submission_runner.py:406] Time since start: 11726.44s, 	Step: 26936, 	{'train/accuracy': 0.5380468368530273, 'train/loss': 2.2744386196136475, 'validation/accuracy': 0.49045997858047485, 'validation/loss': 2.493161201477051, 'validation/num_examples': 50000, 'test/accuracy': 0.3781000077724457, 'test/loss': 3.128312349319458, 'test/num_examples': 10000, 'score': 10972.700566291809, 'total_duration': 11726.44476056099, 'accumulated_submission_time': 10972.700566291809, 'accumulated_eval_time': 720.5709726810455, 'accumulated_logging_time': 32.63340759277344}
I0418 12:42:25.091587 140410718508800 logging_writer.py:48] [26936] accumulated_eval_time=720.570973, accumulated_logging_time=32.633408, accumulated_submission_time=10972.700566, global_step=26936, preemption_count=0, score=10972.700566, test/accuracy=0.378100, test/loss=3.128312, test/num_examples=10000, total_duration=11726.444761, train/accuracy=0.538047, train/loss=2.274439, validation/accuracy=0.490460, validation/loss=2.493161, validation/num_examples=50000
I0418 12:42:25.173711 140588895340352 checkpoints.py:356] Saving checkpoint at step: 26936
I0418 12:42:26.014187 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_26936
I0418 12:42:26.032346 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_26936.
I0418 12:42:51.481436 140410726901504 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.5246808528900146, loss=5.088563919067383
I0418 12:43:31.995393 140410710116096 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.5401682257652283, loss=4.794168472290039
I0418 12:44:13.323770 140410726901504 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.5870038866996765, loss=4.552328109741211
I0418 12:44:54.604106 140410710116096 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.6461255550384521, loss=4.378475666046143
I0418 12:45:35.318270 140410726901504 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.5903602838516235, loss=4.292810440063477
I0418 12:46:16.228528 140410710116096 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.6410323977470398, loss=4.246373653411865
I0418 12:46:57.202216 140410726901504 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.6063395142555237, loss=4.226169586181641
I0418 12:47:38.258459 140410710116096 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.5179681777954102, loss=6.016295433044434
I0418 12:48:19.433195 140410726901504 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.5840161442756653, loss=6.051407814025879
I0418 12:49:00.438390 140410710116096 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.5602173209190369, loss=4.548944473266602
I0418 12:49:26.206384 140588895340352 spec.py:298] Evaluating on the training split.
I0418 12:49:36.494399 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 12:49:49.716598 140588895340352 spec.py:326] Evaluating on the test split.
I0418 12:49:51.371062 140588895340352 submission_runner.py:406] Time since start: 12172.74s, 	Step: 27965, 	{'train/accuracy': 0.5544335842132568, 'train/loss': 2.109532117843628, 'validation/accuracy': 0.5051000118255615, 'validation/loss': 2.360149383544922, 'validation/num_examples': 50000, 'test/accuracy': 0.391400009393692, 'test/loss': 2.970461130142212, 'test/num_examples': 10000, 'score': 11392.852820634842, 'total_duration': 12172.740813732147, 'accumulated_submission_time': 11392.852820634842, 'accumulated_eval_time': 745.735659122467, 'accumulated_logging_time': 33.591902017593384}
I0418 12:49:51.383941 140410726901504 logging_writer.py:48] [27965] accumulated_eval_time=745.735659, accumulated_logging_time=33.591902, accumulated_submission_time=11392.852821, global_step=27965, preemption_count=0, score=11392.852821, test/accuracy=0.391400, test/loss=2.970461, test/num_examples=10000, total_duration=12172.740814, train/accuracy=0.554434, train/loss=2.109532, validation/accuracy=0.505100, validation/loss=2.360149, validation/num_examples=50000
I0418 12:49:51.474630 140588895340352 checkpoints.py:356] Saving checkpoint at step: 27965
I0418 12:49:52.256361 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_27965
I0418 12:49:52.273265 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_27965.
I0418 12:50:05.707329 140588895340352 spec.py:298] Evaluating on the training split.
I0418 12:50:16.273658 140588895340352 spec.py:310] Evaluating on the validation split.
I0418 12:50:26.553818 140588895340352 spec.py:326] Evaluating on the test split.
I0418 12:50:28.201735 140588895340352 submission_runner.py:406] Time since start: 12209.57s, 	Step: 28000, 	{'train/accuracy': 0.5536718368530273, 'train/loss': 2.228534460067749, 'validation/accuracy': 0.4994399845600128, 'validation/loss': 2.4828014373779297, 'validation/num_examples': 50000, 'test/accuracy': 0.38930001854896545, 'test/loss': 3.0895068645477295, 'test/num_examples': 10000, 'score': 11406.284784317017, 'total_duration': 12209.571457862854, 'accumulated_submission_time': 11406.284784317017, 'accumulated_eval_time': 768.2300038337708, 'accumulated_logging_time': 34.495277404785156}
I0418 12:50:28.220139 140410710116096 logging_writer.py:48] [28000] accumulated_eval_time=768.230004, accumulated_logging_time=34.495277, accumulated_submission_time=11406.284784, global_step=28000, preemption_count=0, score=11406.284784, test/accuracy=0.389300, test/loss=3.089507, test/num_examples=10000, total_duration=12209.571458, train/accuracy=0.553672, train/loss=2.228534, validation/accuracy=0.499440, validation/loss=2.482801, validation/num_examples=50000
I0418 12:50:28.328004 140588895340352 checkpoints.py:356] Saving checkpoint at step: 28000
I0418 12:50:29.202152 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_28000
I0418 12:50:29.216828 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_28000.
I0418 12:50:29.233913 140410701723392 logging_writer.py:48] [28000] global_step=28000, preemption_count=0, score=11406.284784
I0418 12:50:29.330031 140588895340352 checkpoints.py:356] Saving checkpoint at step: 28000
I0418 12:50:30.364291 140588895340352 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_28000
I0418 12:50:30.376735 140588895340352 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3/timing_momentum/imagenet_vit_jax/trial_1/checkpoint_28000.
I0418 12:50:31.394157 140588895340352 submission_runner.py:567] Tuning trial 1/1
I0418 12:50:31.397716 140588895340352 submission_runner.py:568] Hyperparameters: Hyperparameters(learning_rate=0.4394877561366806, one_minus_beta1=0.07113602458522507, warmup_factor=0.05, weight_decay=9.611851572925426e-07, label_smoothing=0.2, dropout_rate=0.0, decay_steps_factor=0.9, end_factor=0.001)
I0418 12:50:31.401813 140588895340352 submission_runner.py:569] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0009179687476716936, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 47.855984687805176, 'total_duration': 98.95584917068481, 'accumulated_submission_time': 47.855984687805176, 'accumulated_eval_time': 51.09971523284912, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (1027, {'train/accuracy': 0.030449217185378075, 'train/loss': 6.134230613708496, 'validation/accuracy': 0.02985999919474125, 'validation/loss': 6.156836032867432, 'validation/num_examples': 50000, 'test/accuracy': 0.023400001227855682, 'test/loss': 6.247262477874756, 'test/num_examples': 10000, 'score': 468.1541361808777, 'total_duration': 539.4117102622986, 'accumulated_submission_time': 468.1541361808777, 'accumulated_eval_time': 70.71489262580872, 'accumulated_logging_time': 0.5210452079772949, 'global_step': 1027, 'preemption_count': 0}), (2084, {'train/accuracy': 0.05699218437075615, 'train/loss': 5.778841495513916, 'validation/accuracy': 0.055479999631643295, 'validation/loss': 5.813849925994873, 'validation/num_examples': 50000, 'test/accuracy': 0.03930000215768814, 'test/loss': 5.954679012298584, 'test/num_examples': 10000, 'score': 888.1965012550354, 'total_duration': 980.6421945095062, 'accumulated_submission_time': 888.1965012550354, 'accumulated_eval_time': 90.12190127372742, 'accumulated_logging_time': 2.2805063724517822, 'global_step': 2084, 'preemption_count': 0}), (3139, {'train/accuracy': 0.08167968690395355, 'train/loss': 5.3608903884887695, 'validation/accuracy': 0.07422000169754028, 'validation/loss': 5.420929431915283, 'validation/num_examples': 50000, 'test/accuracy': 0.057100001722574234, 'test/loss': 5.630521297454834, 'test/num_examples': 10000, 'score': 1308.4023022651672, 'total_duration': 1423.1283321380615, 'accumulated_submission_time': 1308.4023022651672, 'accumulated_eval_time': 110.06092143058777, 'accumulated_logging_time': 4.6000893115997314, 'global_step': 3139, 'preemption_count': 0}), (4192, {'train/accuracy': 0.10152343660593033, 'train/loss': 5.119630336761475, 'validation/accuracy': 0.09111999720335007, 'validation/loss': 5.191515922546387, 'validation/num_examples': 50000, 'test/accuracy': 0.07380000501871109, 'test/loss': 5.432984828948975, 'test/num_examples': 10000, 'score': 1728.5121657848358, 'total_duration': 1866.1647453308105, 'accumulated_submission_time': 1728.5121657848358, 'accumulated_eval_time': 130.4168243408203, 'accumulated_logging_time': 7.149238109588623, 'global_step': 4192, 'preemption_count': 0}), (5244, {'train/accuracy': 0.13718749582767487, 'train/loss': 4.81376314163208, 'validation/accuracy': 0.12637999653816223, 'validation/loss': 4.8988752365112305, 'validation/num_examples': 50000, 'test/accuracy': 0.09860000759363174, 'test/loss': 5.1829071044921875, 'test/num_examples': 10000, 'score': 2148.7142271995544, 'total_duration': 2309.937138557434, 'accumulated_submission_time': 2148.7142271995544, 'accumulated_eval_time': 151.54281091690063, 'accumulated_logging_time': 9.57218313217163, 'global_step': 5244, 'preemption_count': 0}), (6293, {'train/accuracy': 0.15355467796325684, 'train/loss': 4.674384593963623, 'validation/accuracy': 0.14323998987674713, 'validation/loss': 4.755995273590088, 'validation/num_examples': 50000, 'test/accuracy': 0.10240000486373901, 'test/loss': 5.0877909660339355, 'test/num_examples': 10000, 'score': 2568.812723875046, 'total_duration': 2754.361873626709, 'accumulated_submission_time': 2568.812723875046, 'accumulated_eval_time': 174.1105923652649, 'accumulated_logging_time': 11.309327363967896, 'global_step': 6293, 'preemption_count': 0}), (7342, {'train/accuracy': 0.1953710913658142, 'train/loss': 4.376893997192383, 'validation/accuracy': 0.1770399957895279, 'validation/loss': 4.468344688415527, 'validation/num_examples': 50000, 'test/accuracy': 0.13690000772476196, 'test/loss': 4.818387508392334, 'test/num_examples': 10000, 'score': 2989.0319254398346, 'total_duration': 3200.4276814460754, 'accumulated_submission_time': 2989.0319254398346, 'accumulated_eval_time': 198.8732554912567, 'accumulated_logging_time': 12.37194538116455, 'global_step': 7342, 'preemption_count': 0}), (8388, {'train/accuracy': 0.22859375178813934, 'train/loss': 4.0883612632751465, 'validation/accuracy': 0.20867998898029327, 'validation/loss': 4.209028244018555, 'validation/num_examples': 50000, 'test/accuracy': 0.15820001065731049, 'test/loss': 4.608339309692383, 'test/num_examples': 10000, 'score': 3409.4042706489563, 'total_duration': 3647.401023864746, 'accumulated_submission_time': 3409.4042706489563, 'accumulated_eval_time': 224.592143535614, 'accumulated_logging_time': 13.232425928115845, 'global_step': 8388, 'preemption_count': 0}), (9436, {'train/accuracy': 0.26517578959465027, 'train/loss': 3.8037147521972656, 'validation/accuracy': 0.23827999830245972, 'validation/loss': 3.952683687210083, 'validation/num_examples': 50000, 'test/accuracy': 0.18320000171661377, 'test/loss': 4.390207290649414, 'test/num_examples': 10000, 'score': 3829.6493492126465, 'total_duration': 4095.13156414032, 'accumulated_submission_time': 3829.6493492126465, 'accumulated_eval_time': 251.1452395915985, 'accumulated_logging_time': 14.142561912536621, 'global_step': 9436, 'preemption_count': 0}), (10480, {'train/accuracy': 0.29537108540534973, 'train/loss': 3.6718249320983887, 'validation/accuracy': 0.26736000180244446, 'validation/loss': 3.8045597076416016, 'validation/num_examples': 50000, 'test/accuracy': 0.20260000228881836, 'test/loss': 4.273815631866455, 'test/num_examples': 10000, 'score': 4249.838851451874, 'total_duration': 4543.608403682709, 'accumulated_submission_time': 4249.838851451874, 'accumulated_eval_time': 278.3128457069397, 'accumulated_logging_time': 15.241193532943726, 'global_step': 10480, 'preemption_count': 0}), (11524, {'train/accuracy': 0.31947264075279236, 'train/loss': 3.527507781982422, 'validation/accuracy': 0.29462000727653503, 'validation/loss': 3.64550518989563, 'validation/num_examples': 50000, 'test/accuracy': 0.22440001368522644, 'test/loss': 4.127091407775879, 'test/num_examples': 10000, 'score': 4670.016874551773, 'total_duration': 4991.495959997177, 'accumulated_submission_time': 4670.016874551773, 'accumulated_eval_time': 305.02828788757324, 'accumulated_logging_time': 16.214516639709473, 'global_step': 11524, 'preemption_count': 0}), (12564, {'train/accuracy': 0.34187498688697815, 'train/loss': 3.344667673110962, 'validation/accuracy': 0.31379997730255127, 'validation/loss': 3.4939751625061035, 'validation/num_examples': 50000, 'test/accuracy': 0.2435000091791153, 'test/loss': 3.989381790161133, 'test/num_examples': 10000, 'score': 5090.100670814514, 'total_duration': 5439.766398668289, 'accumulated_submission_time': 5090.100670814514, 'accumulated_eval_time': 332.19921684265137, 'accumulated_logging_time': 17.20971393585205, 'global_step': 12564, 'preemption_count': 0}), (13603, {'train/accuracy': 0.3636523485183716, 'train/loss': 3.2581868171691895, 'validation/accuracy': 0.33017998933792114, 'validation/loss': 3.4344542026519775, 'validation/num_examples': 50000, 'test/accuracy': 0.24880000948905945, 'test/loss': 3.962186574935913, 'test/num_examples': 10000, 'score': 5510.433007717133, 'total_duration': 5888.187043905258, 'accumulated_submission_time': 5510.433007717133, 'accumulated_eval_time': 359.2877712249756, 'accumulated_logging_time': 18.188780069351196, 'global_step': 13603, 'preemption_count': 0}), (14635, {'train/accuracy': 0.3933984339237213, 'train/loss': 3.045436382293701, 'validation/accuracy': 0.3510199785232544, 'validation/loss': 3.2551517486572266, 'validation/num_examples': 50000, 'test/accuracy': 0.26900002360343933, 'test/loss': 3.7806971073150635, 'test/num_examples': 10000, 'score': 5930.783458709717, 'total_duration': 6337.136749505997, 'accumulated_submission_time': 5930.783458709717, 'accumulated_eval_time': 386.9748980998993, 'accumulated_logging_time': 19.080673694610596, 'global_step': 14635, 'preemption_count': 0}), (15663, {'train/accuracy': 0.40220701694488525, 'train/loss': 2.9306020736694336, 'validation/accuracy': 0.36941999197006226, 'validation/loss': 3.0936648845672607, 'validation/num_examples': 50000, 'test/accuracy': 0.28450000286102295, 'test/loss': 3.647273302078247, 'test/num_examples': 10000, 'score': 6350.912359714508, 'total_duration': 6786.3053476810455, 'accumulated_submission_time': 6350.912359714508, 'accumulated_eval_time': 414.9791507720947, 'accumulated_logging_time': 20.095966577529907, 'global_step': 15663, 'preemption_count': 0}), (16682, {'train/accuracy': 0.4200976490974426, 'train/loss': 2.818995952606201, 'validation/accuracy': 0.3877599835395813, 'validation/loss': 2.994821548461914, 'validation/num_examples': 50000, 'test/accuracy': 0.2955000102519989, 'test/loss': 3.5650272369384766, 'test/num_examples': 10000, 'score': 6771.059458732605, 'total_duration': 7235.805813550949, 'accumulated_submission_time': 6771.059458732605, 'accumulated_eval_time': 443.3938202857971, 'accumulated_logging_time': 21.014688968658447, 'global_step': 16682, 'preemption_count': 0}), (17713, {'train/accuracy': 0.43849608302116394, 'train/loss': 2.746001720428467, 'validation/accuracy': 0.39969998598098755, 'validation/loss': 2.9365105628967285, 'validation/num_examples': 50000, 'test/accuracy': 0.3091000020503998, 'test/loss': 3.525444269180298, 'test/num_examples': 10000, 'score': 7191.228957653046, 'total_duration': 7685.232613801956, 'accumulated_submission_time': 7191.228957653046, 'accumulated_eval_time': 471.70671367645264, 'accumulated_logging_time': 21.9390869140625, 'global_step': 17713, 'preemption_count': 0}), (18740, {'train/accuracy': 0.45384764671325684, 'train/loss': 2.6570589542388916, 'validation/accuracy': 0.4128599762916565, 'validation/loss': 2.876776695251465, 'validation/num_examples': 50000, 'test/accuracy': 0.3176000118255615, 'test/loss': 3.4601240158081055, 'test/num_examples': 10000, 'score': 7611.295107603073, 'total_duration': 8135.100620746613, 'accumulated_submission_time': 7611.295107603073, 'accumulated_eval_time': 500.4095685482025, 'accumulated_logging_time': 23.017999410629272, 'global_step': 18740, 'preemption_count': 0}), (19756, {'train/accuracy': 0.47935545444488525, 'train/loss': 2.5558032989501953, 'validation/accuracy': 0.4272199869155884, 'validation/loss': 2.80623459815979, 'validation/num_examples': 50000, 'test/accuracy': 0.32440000772476196, 'test/loss': 3.4039435386657715, 'test/num_examples': 10000, 'score': 8031.448212146759, 'total_duration': 8584.343006134033, 'accumulated_submission_time': 8031.448212146759, 'accumulated_eval_time': 528.4838931560516, 'accumulated_logging_time': 24.012748956680298, 'global_step': 19756, 'preemption_count': 0}), (20777, {'train/accuracy': 0.4797070324420929, 'train/loss': 2.5169482231140137, 'validation/accuracy': 0.44165998697280884, 'validation/loss': 2.7020232677459717, 'validation/num_examples': 50000, 'test/accuracy': 0.3442000150680542, 'test/loss': 3.2963173389434814, 'test/num_examples': 10000, 'score': 8451.60296368599, 'total_duration': 9034.265623092651, 'accumulated_submission_time': 8451.60296368599, 'accumulated_eval_time': 557.1714894771576, 'accumulated_logging_time': 25.07313823699951, 'global_step': 20777, 'preemption_count': 0}), (21811, {'train/accuracy': 0.48027342557907104, 'train/loss': 2.5749154090881348, 'validation/accuracy': 0.4399999976158142, 'validation/loss': 2.768078565597534, 'validation/num_examples': 50000, 'test/accuracy': 0.3466000258922577, 'test/loss': 3.3403618335723877, 'test/num_examples': 10000, 'score': 8871.89065361023, 'total_duration': 9484.581191062927, 'accumulated_submission_time': 8871.89065361023, 'accumulated_eval_time': 586.076700925827, 'accumulated_logging_time': 26.175122022628784, 'global_step': 21811, 'preemption_count': 0}), (22840, {'train/accuracy': 0.5030273199081421, 'train/loss': 2.392740488052368, 'validation/accuracy': 0.4592999815940857, 'validation/loss': 2.5979881286621094, 'validation/num_examples': 50000, 'test/accuracy': 0.35590001940727234, 'test/loss': 3.2174692153930664, 'test/num_examples': 10000, 'score': 9292.140046596527, 'total_duration': 9934.882987499237, 'accumulated_submission_time': 9292.140046596527, 'accumulated_eval_time': 615.1166138648987, 'accumulated_logging_time': 27.16744303703308, 'global_step': 22840, 'preemption_count': 0}), (23868, {'train/accuracy': 0.5216601490974426, 'train/loss': 2.3356943130493164, 'validation/accuracy': 0.46719998121261597, 'validation/loss': 2.5898194313049316, 'validation/num_examples': 50000, 'test/accuracy': 0.3671000301837921, 'test/loss': 3.2059173583984375, 'test/num_examples': 10000, 'score': 9712.291100740433, 'total_duration': 10384.220490932465, 'accumulated_submission_time': 9712.291100740433, 'accumulated_eval_time': 643.1107819080353, 'accumulated_logging_time': 28.339356899261475, 'global_step': 23868, 'preemption_count': 0}), (24862, {'train/accuracy': 0.5180078148841858, 'train/loss': 2.328747272491455, 'validation/accuracy': 0.4762199819087982, 'validation/loss': 2.5247602462768555, 'validation/num_examples': 50000, 'test/accuracy': 0.37220001220703125, 'test/loss': 3.160764455795288, 'test/num_examples': 10000, 'score': 10132.28794670105, 'total_duration': 10832.945937395096, 'accumulated_submission_time': 10132.28794670105, 'accumulated_eval_time': 669.8525927066803, 'accumulated_logging_time': 30.307008266448975, 'global_step': 24862, 'preemption_count': 0}), (25898, {'train/accuracy': 0.5267968773841858, 'train/loss': 2.2384138107299805, 'validation/accuracy': 0.4835599958896637, 'validation/loss': 2.445570707321167, 'validation/num_examples': 50000, 'test/accuracy': 0.37370002269744873, 'test/loss': 3.0754311084747314, 'test/num_examples': 10000, 'score': 10552.493962287903, 'total_duration': 11279.839145421982, 'accumulated_submission_time': 10552.493962287903, 'accumulated_eval_time': 695.3672559261322, 'accumulated_logging_time': 31.4588782787323, 'global_step': 25898, 'preemption_count': 0}), (26936, {'train/accuracy': 0.5380468368530273, 'train/loss': 2.2744386196136475, 'validation/accuracy': 0.49045997858047485, 'validation/loss': 2.493161201477051, 'validation/num_examples': 50000, 'test/accuracy': 0.3781000077724457, 'test/loss': 3.128312349319458, 'test/num_examples': 10000, 'score': 10972.700566291809, 'total_duration': 11726.44476056099, 'accumulated_submission_time': 10972.700566291809, 'accumulated_eval_time': 720.5709726810455, 'accumulated_logging_time': 32.63340759277344, 'global_step': 26936, 'preemption_count': 0}), (27965, {'train/accuracy': 0.5544335842132568, 'train/loss': 2.109532117843628, 'validation/accuracy': 0.5051000118255615, 'validation/loss': 2.360149383544922, 'validation/num_examples': 50000, 'test/accuracy': 0.391400009393692, 'test/loss': 2.970461130142212, 'test/num_examples': 10000, 'score': 11392.852820634842, 'total_duration': 12172.740813732147, 'accumulated_submission_time': 11392.852820634842, 'accumulated_eval_time': 745.735659122467, 'accumulated_logging_time': 33.591902017593384, 'global_step': 27965, 'preemption_count': 0}), (28000, {'train/accuracy': 0.5536718368530273, 'train/loss': 2.228534460067749, 'validation/accuracy': 0.4994399845600128, 'validation/loss': 2.4828014373779297, 'validation/num_examples': 50000, 'test/accuracy': 0.38930001854896545, 'test/loss': 3.0895068645477295, 'test/num_examples': 10000, 'score': 11406.284784317017, 'total_duration': 12209.571457862854, 'accumulated_submission_time': 11406.284784317017, 'accumulated_eval_time': 768.2300038337708, 'accumulated_logging_time': 34.495277404785156, 'global_step': 28000, 'preemption_count': 0})], 'global_step': 28000}
I0418 12:50:31.401977 140588895340352 submission_runner.py:570] Timing: 11406.284784317017
I0418 12:50:31.402039 140588895340352 submission_runner.py:571] ====================
I0418 12:50:31.402201 140588895340352 submission_runner.py:631] Final imagenet_vit score: 11406.284784317017
