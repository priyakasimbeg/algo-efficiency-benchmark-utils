I0425 00:57:51.825688 140188941555520 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax.
I0425 00:57:51.889847 140188941555520 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0425 00:57:52.713362 140188941555520 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter Host
I0425 00:57:52.713976 140188941555520 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0425 00:57:52.718294 140188941555520 submission_runner.py:528] Using RNG seed 2011787666
I0425 00:57:55.382271 140188941555520 submission_runner.py:537] --- Tuning run 1/1 ---
I0425 00:57:55.382524 140188941555520 submission_runner.py:542] Creating tuning directory at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1.
I0425 00:57:55.382834 140188941555520 logger_utils.py:83] Saving hparams to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/hparams.json.
I0425 00:57:55.502257 140188941555520 submission_runner.py:232] Initializing dataset.
I0425 00:57:55.514061 140188941555520 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0425 00:57:55.522718 140188941555520 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0425 00:57:55.522863 140188941555520 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0425 00:57:55.782496 140188941555520 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0425 00:58:02.624870 140188941555520 submission_runner.py:239] Initializing model.
I0425 00:58:14.352288 140188941555520 submission_runner.py:249] Initializing optimizer.
I0425 00:58:14.870254 140188941555520 submission_runner.py:256] Initializing metrics bundle.
I0425 00:58:14.870526 140188941555520 submission_runner.py:273] Initializing checkpoint and logger.
I0425 00:58:14.871518 140188941555520 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1 with prefix checkpoint_
I0425 00:58:15.735578 140188941555520 submission_runner.py:294] Saving meta data to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/meta_data_0.json.
I0425 00:58:15.736803 140188941555520 submission_runner.py:297] Saving flags to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/flags_0.json.
I0425 00:58:15.742045 140188941555520 submission_runner.py:309] Starting training loop.
I0425 00:59:02.267184 140012066694912 logging_writer.py:48] [0] global_step=0, grad_norm=0.2855411469936371, loss=6.9077534675598145
I0425 00:59:02.282410 140188941555520 spec.py:298] Evaluating on the training split.
I0425 00:59:02.288972 140188941555520 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0425 00:59:02.296045 140188941555520 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0425 00:59:02.296184 140188941555520 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0425 00:59:02.362932 140188941555520 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0425 00:59:22.328862 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 00:59:22.336267 140188941555520 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0425 00:59:22.347281 140188941555520 dataset_info.py:642] Field info.splits from disk and from code do not match. Keeping the one from code.
I0425 00:59:22.347570 140188941555520 dataset_info.py:642] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
I0425 00:59:22.406110 140188941555520 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0425 00:59:40.686206 140188941555520 spec.py:326] Evaluating on the test split.
I0425 00:59:40.693016 140188941555520 dataset_info.py:566] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0425 00:59:40.698381 140188941555520 dataset_builder.py:510] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0425 00:59:40.733190 140188941555520 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0425 00:59:51.758620 140188941555520 submission_runner.py:406] Time since start: 96.02s, 	Step: 1, 	{'train/accuracy': 0.0009960937313735485, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 46.54018259048462, 'total_duration': 96.01651453971863, 'accumulated_submission_time': 46.54018259048462, 'accumulated_eval_time': 49.47616744041443, 'accumulated_logging_time': 0}
I0425 00:59:51.775892 139951207307008 logging_writer.py:48] [1] accumulated_eval_time=49.476167, accumulated_logging_time=0, accumulated_submission_time=46.540183, global_step=1, preemption_count=0, score=46.540183, test/accuracy=0.001000, test/loss=6.907757, test/num_examples=10000, total_duration=96.016515, train/accuracy=0.000996, train/loss=6.907756, validation/accuracy=0.001000, validation/loss=6.907756, validation/num_examples=50000
I0425 00:59:51.905822 140188941555520 checkpoints.py:356] Saving checkpoint at step: 1
I0425 00:59:52.482202 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_1
I0425 00:59:52.483094 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_1.
I0425 01:00:46.704857 140006433715968 logging_writer.py:48] [100] global_step=100, grad_norm=0.30591362714767456, loss=6.906074047088623
I0425 01:01:27.873262 140006442108672 logging_writer.py:48] [200] global_step=200, grad_norm=0.2897642254829407, loss=6.895999908447266
I0425 01:02:09.260130 140006433715968 logging_writer.py:48] [300] global_step=300, grad_norm=0.3400610685348511, loss=6.8739728927612305
I0425 01:02:50.438156 140006442108672 logging_writer.py:48] [400] global_step=400, grad_norm=0.4990886151790619, loss=6.810425758361816
I0425 01:03:31.724747 140006433715968 logging_writer.py:48] [500] global_step=500, grad_norm=0.964358389377594, loss=6.719525337219238
I0425 01:04:12.950801 140006442108672 logging_writer.py:48] [600] global_step=600, grad_norm=0.8879167437553406, loss=6.751396656036377
I0425 01:04:54.280640 140006433715968 logging_writer.py:48] [700] global_step=700, grad_norm=0.7008388042449951, loss=6.742153644561768
I0425 01:05:35.992030 140006442108672 logging_writer.py:48] [800] global_step=800, grad_norm=0.8681550025939941, loss=6.604613304138184
I0425 01:06:17.446613 140006433715968 logging_writer.py:48] [900] global_step=900, grad_norm=1.1980676651000977, loss=6.534093856811523
I0425 01:06:52.769159 140188941555520 spec.py:298] Evaluating on the training split.
I0425 01:07:03.639742 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 01:07:10.151603 140188941555520 spec.py:326] Evaluating on the test split.
I0425 01:07:12.090179 140188941555520 submission_runner.py:406] Time since start: 536.35s, 	Step: 987, 	{'train/accuracy': 0.0322265625, 'train/loss': 6.083932876586914, 'validation/accuracy': 0.03150000050663948, 'validation/loss': 6.109715938568115, 'validation/num_examples': 50000, 'test/accuracy': 0.025200001895427704, 'test/loss': 6.197531700134277, 'test/num_examples': 10000, 'score': 466.8052730560303, 'total_duration': 536.3479995727539, 'accumulated_submission_time': 466.8052730560303, 'accumulated_eval_time': 68.79713177680969, 'accumulated_logging_time': 0.7254903316497803}
I0425 01:07:12.108791 139952700512000 logging_writer.py:48] [987] accumulated_eval_time=68.797132, accumulated_logging_time=0.725490, accumulated_submission_time=466.805273, global_step=987, preemption_count=0, score=466.805273, test/accuracy=0.025200, test/loss=6.197532, test/num_examples=10000, total_duration=536.348000, train/accuracy=0.032227, train/loss=6.083933, validation/accuracy=0.031500, validation/loss=6.109716, validation/num_examples=50000
I0425 01:07:12.703287 140188941555520 checkpoints.py:356] Saving checkpoint at step: 987
I0425 01:07:13.835818 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_987
I0425 01:07:13.837383 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_987.
I0425 01:07:19.670935 139952708904704 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.969269871711731, loss=6.485727787017822
I0425 01:08:00.929960 140011898906368 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.9131231307983398, loss=6.79495906829834
I0425 01:08:42.200098 139952708904704 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.9088826775550842, loss=6.38728141784668
I0425 01:09:23.395292 140011898906368 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.9989878535270691, loss=6.390102863311768
I0425 01:10:04.553728 139952708904704 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.7031446099281311, loss=6.651047706604004
I0425 01:10:46.085837 140011898906368 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.7702187895774841, loss=6.373003959655762
I0425 01:11:27.589354 139952708904704 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.9776661396026611, loss=6.328399658203125
I0425 01:12:08.871142 140011898906368 logging_writer.py:48] [1700] global_step=1700, grad_norm=1.1586872339248657, loss=6.3420820236206055
I0425 01:12:50.144981 139952708904704 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.9846692681312561, loss=6.314366340637207
I0425 01:13:31.494101 140011898906368 logging_writer.py:48] [1900] global_step=1900, grad_norm=1.080847144126892, loss=6.286093711853027
I0425 01:14:12.994983 139952708904704 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.8971974849700928, loss=6.2541680335998535
I0425 01:14:13.972591 140188941555520 spec.py:298] Evaluating on the training split.
I0425 01:14:25.412021 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 01:14:32.005839 140188941555520 spec.py:326] Evaluating on the test split.
I0425 01:14:33.696772 140188941555520 submission_runner.py:406] Time since start: 977.95s, 	Step: 2004, 	{'train/accuracy': 0.06744140386581421, 'train/loss': 5.538755416870117, 'validation/accuracy': 0.06449999660253525, 'validation/loss': 5.5709710121154785, 'validation/num_examples': 50000, 'test/accuracy': 0.048700001090765, 'test/loss': 5.755987167358398, 'test/num_examples': 10000, 'score': 886.9165542125702, 'total_duration': 977.954642534256, 'accumulated_submission_time': 886.9165542125702, 'accumulated_eval_time': 88.52128434181213, 'accumulated_logging_time': 2.4767982959747314}
I0425 01:14:33.711883 140011898906368 logging_writer.py:48] [2004] accumulated_eval_time=88.521284, accumulated_logging_time=2.476798, accumulated_submission_time=886.916554, global_step=2004, preemption_count=0, score=886.916554, test/accuracy=0.048700, test/loss=5.755987, test/num_examples=10000, total_duration=977.954643, train/accuracy=0.067441, train/loss=5.538755, validation/accuracy=0.064500, validation/loss=5.570971, validation/num_examples=50000
I0425 01:14:34.167409 140188941555520 checkpoints.py:356] Saving checkpoint at step: 2004
I0425 01:14:36.267972 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_2004
I0425 01:14:36.282046 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_2004.
I0425 01:15:16.259432 139952708904704 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.6783360838890076, loss=6.535245895385742
I0425 01:15:57.529658 140011865335552 logging_writer.py:48] [2200] global_step=2200, grad_norm=1.0284231901168823, loss=6.164289474487305
I0425 01:16:38.706921 139952708904704 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.8011072874069214, loss=6.192206859588623
I0425 01:17:19.833075 140011865335552 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.7816544771194458, loss=6.209940433502197
I0425 01:18:00.873794 139952708904704 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.8519322276115417, loss=6.154465675354004
I0425 01:18:42.140799 140011865335552 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.7570152878761292, loss=6.141379356384277
I0425 01:19:23.676142 139952708904704 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.9854118227958679, loss=6.237405776977539
I0425 01:20:04.954376 140011865335552 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.883312463760376, loss=6.072235107421875
I0425 01:20:46.525291 139952708904704 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.675835907459259, loss=6.622640609741211
I0425 01:21:27.868572 140011865335552 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.5831605792045593, loss=6.6488447189331055
I0425 01:21:36.652589 140188941555520 spec.py:298] Evaluating on the training split.
I0425 01:21:48.231093 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 01:21:55.028636 140188941555520 spec.py:326] Evaluating on the test split.
I0425 01:21:56.727005 140188941555520 submission_runner.py:406] Time since start: 1420.98s, 	Step: 3023, 	{'train/accuracy': 0.10279296338558197, 'train/loss': 5.1836419105529785, 'validation/accuracy': 0.09386000037193298, 'validation/loss': 5.238406181335449, 'validation/num_examples': 50000, 'test/accuracy': 0.07100000232458115, 'test/loss': 5.4594855308532715, 'test/num_examples': 10000, 'score': 1307.258901834488, 'total_duration': 1420.9848110675812, 'accumulated_submission_time': 1307.258901834488, 'accumulated_eval_time': 108.59562277793884, 'accumulated_logging_time': 5.070218086242676}
I0425 01:21:56.740187 139952708904704 logging_writer.py:48] [3023] accumulated_eval_time=108.595623, accumulated_logging_time=5.070218, accumulated_submission_time=1307.258902, global_step=3023, preemption_count=0, score=1307.258902, test/accuracy=0.071000, test/loss=5.459486, test/num_examples=10000, total_duration=1420.984811, train/accuracy=0.102793, train/loss=5.183642, validation/accuracy=0.093860, validation/loss=5.238406, validation/num_examples=50000
I0425 01:21:57.284053 140188941555520 checkpoints.py:356] Saving checkpoint at step: 3023
I0425 01:21:59.547148 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_3023
I0425 01:21:59.559203 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_3023.
I0425 01:22:31.476109 140011865335552 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.9268531203269958, loss=6.107650279998779
I0425 01:23:12.569690 140011856942848 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.834740400314331, loss=6.059262275695801
I0425 01:23:53.544787 140011865335552 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.9709720611572266, loss=6.02009391784668
I0425 01:24:34.700308 140011856942848 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.8186619281768799, loss=6.042226314544678
I0425 01:25:15.860354 140011865335552 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.640138566493988, loss=6.439948081970215
I0425 01:25:56.917676 140011856942848 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.7259127497673035, loss=6.654818534851074
I0425 01:26:38.076431 140011865335552 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.9938294887542725, loss=6.156200408935547
I0425 01:27:19.343966 140011856942848 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.6070049405097961, loss=6.338624000549316
I0425 01:28:00.464428 140011865335552 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.6977749466896057, loss=5.940561294555664
I0425 01:28:41.977844 140011856942848 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.8299170732498169, loss=5.878816604614258
I0425 01:28:59.889478 140188941555520 spec.py:298] Evaluating on the training split.
I0425 01:29:11.654767 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 01:29:19.509655 140188941555520 spec.py:326] Evaluating on the test split.
I0425 01:29:21.172464 140188941555520 submission_runner.py:406] Time since start: 1865.43s, 	Step: 4045, 	{'train/accuracy': 0.13740234076976776, 'train/loss': 4.837579727172852, 'validation/accuracy': 0.11614000052213669, 'validation/loss': 4.975306510925293, 'validation/num_examples': 50000, 'test/accuracy': 0.08830000460147858, 'test/loss': 5.251297950744629, 'test/num_examples': 10000, 'score': 1727.5673639774323, 'total_duration': 1865.4303455352783, 'accumulated_submission_time': 1727.5673639774323, 'accumulated_eval_time': 129.8786060810089, 'accumulated_logging_time': 7.904304504394531}
I0425 01:29:21.185740 140011865335552 logging_writer.py:48] [4045] accumulated_eval_time=129.878606, accumulated_logging_time=7.904305, accumulated_submission_time=1727.567364, global_step=4045, preemption_count=0, score=1727.567364, test/accuracy=0.088300, test/loss=5.251298, test/num_examples=10000, total_duration=1865.430346, train/accuracy=0.137402, train/loss=4.837580, validation/accuracy=0.116140, validation/loss=4.975307, validation/num_examples=50000
I0425 01:29:21.301685 140188941555520 checkpoints.py:356] Saving checkpoint at step: 4045
I0425 01:29:22.328397 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_4045
I0425 01:29:22.341971 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_4045.
I0425 01:29:45.491206 140011856942848 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.7862666249275208, loss=5.886666297912598
I0425 01:30:26.514657 140011034883840 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.8418609499931335, loss=5.881255149841309
I0425 01:31:07.669696 140011856942848 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.7560316324234009, loss=6.134696006774902
I0425 01:31:48.969716 140011034883840 logging_writer.py:48] [4400] global_step=4400, grad_norm=1.0667507648468018, loss=5.870701313018799
I0425 01:32:30.518308 140011856942848 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.6596813797950745, loss=6.622350692749023
I0425 01:33:11.924451 140011034883840 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.7547136545181274, loss=6.0351409912109375
I0425 01:33:53.231269 140011856942848 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.6604763865470886, loss=5.797506332397461
I0425 01:34:34.956810 140011034883840 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.668368399143219, loss=5.984839916229248
I0425 01:35:16.246286 140011856942848 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.5049969553947449, loss=6.567152500152588
I0425 01:35:57.684506 140011034883840 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.8152098655700684, loss=5.947230815887451
I0425 01:36:22.749971 140188941555520 spec.py:298] Evaluating on the training split.
I0425 01:36:34.631422 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 01:36:42.854717 140188941555520 spec.py:326] Evaluating on the test split.
I0425 01:36:44.499036 140188941555520 submission_runner.py:406] Time since start: 2308.76s, 	Step: 5062, 	{'train/accuracy': 0.15998046100139618, 'train/loss': 4.654322624206543, 'validation/accuracy': 0.14608000218868256, 'validation/loss': 4.726490020751953, 'validation/num_examples': 50000, 'test/accuracy': 0.11110000312328339, 'test/loss': 5.03836727142334, 'test/num_examples': 10000, 'score': 2147.9539024829865, 'total_duration': 2308.7568957805634, 'accumulated_submission_time': 2147.9539024829865, 'accumulated_eval_time': 151.62768054008484, 'accumulated_logging_time': 9.07567286491394}
I0425 01:36:44.510206 140011856942848 logging_writer.py:48] [5062] accumulated_eval_time=151.627681, accumulated_logging_time=9.075673, accumulated_submission_time=2147.953902, global_step=5062, preemption_count=0, score=2147.953902, test/accuracy=0.111100, test/loss=5.038367, test/num_examples=10000, total_duration=2308.756896, train/accuracy=0.159980, train/loss=4.654323, validation/accuracy=0.146080, validation/loss=4.726490, validation/num_examples=50000
I0425 01:36:44.620757 140188941555520 checkpoints.py:356] Saving checkpoint at step: 5062
I0425 01:36:45.466346 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_5062
I0425 01:36:45.476186 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_5062.
I0425 01:37:01.660917 140011034883840 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.7289395332336426, loss=5.719804763793945
I0425 01:37:43.086676 140011026491136 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.5668489336967468, loss=6.252028942108154
I0425 01:38:24.334846 140011034883840 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.7827209830284119, loss=5.714367866516113
I0425 01:39:05.629303 140011026491136 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.7009657025337219, loss=5.776047706604004
I0425 01:39:46.983630 140011034883840 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.9204539060592651, loss=5.681467533111572
I0425 01:40:28.477551 140011026491136 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.6211386322975159, loss=5.632850646972656
I0425 01:41:09.863523 140011034883840 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.658883810043335, loss=5.91140079498291
I0425 01:41:51.459321 140011026491136 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.686011791229248, loss=5.68580436706543
I0425 01:42:33.297384 140011034883840 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.7453721165657043, loss=5.615970611572266
I0425 01:43:14.860049 140011026491136 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.6514847278594971, loss=5.539102554321289
I0425 01:43:45.626276 140188941555520 spec.py:298] Evaluating on the training split.
I0425 01:43:58.385128 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 01:44:06.892998 140188941555520 spec.py:326] Evaluating on the test split.
I0425 01:44:08.543830 140188941555520 submission_runner.py:406] Time since start: 2752.80s, 	Step: 6076, 	{'train/accuracy': 0.1861913949251175, 'train/loss': 4.414586544036865, 'validation/accuracy': 0.1717199981212616, 'validation/loss': 4.497425079345703, 'validation/num_examples': 50000, 'test/accuracy': 0.12950000166893005, 'test/loss': 4.840025901794434, 'test/num_examples': 10000, 'score': 2568.082721710205, 'total_duration': 2752.801563978195, 'accumulated_submission_time': 2568.082721710205, 'accumulated_eval_time': 174.5450689792633, 'accumulated_logging_time': 10.053825855255127}
I0425 01:44:08.556794 140011034883840 logging_writer.py:48] [6076] accumulated_eval_time=174.545069, accumulated_logging_time=10.053826, accumulated_submission_time=2568.082722, global_step=6076, preemption_count=0, score=2568.082722, test/accuracy=0.129500, test/loss=4.840026, test/num_examples=10000, total_duration=2752.801564, train/accuracy=0.186191, train/loss=4.414587, validation/accuracy=0.171720, validation/loss=4.497425, validation/num_examples=50000
I0425 01:44:08.650602 140188941555520 checkpoints.py:356] Saving checkpoint at step: 6076
I0425 01:44:09.371254 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_6076
I0425 01:44:09.380778 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_6076.
I0425 01:44:19.721284 140011026491136 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.507892370223999, loss=6.548673629760742
I0425 01:45:01.034946 140011018098432 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.6601670980453491, loss=5.529879093170166
I0425 01:45:42.367014 140011026491136 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.5020340085029602, loss=6.426385402679443
I0425 01:46:23.835513 140011018098432 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.6775379180908203, loss=5.534080505371094
I0425 01:47:05.441671 140011026491136 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.8396356701850891, loss=5.55278205871582
I0425 01:47:47.185564 140011018098432 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.624248206615448, loss=6.1975908279418945
I0425 01:48:28.439811 140011026491136 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.8098151087760925, loss=5.502879619598389
I0425 01:49:09.878685 140011018098432 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.5546268820762634, loss=5.540972709655762
I0425 01:49:51.504102 140011026491136 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.7714046239852905, loss=5.438949108123779
I0425 01:50:32.932235 140011018098432 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.6815583109855652, loss=5.403496265411377
I0425 01:51:09.533252 140188941555520 spec.py:298] Evaluating on the training split.
I0425 01:51:23.125612 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 01:51:31.846383 140188941555520 spec.py:326] Evaluating on the test split.
I0425 01:51:33.503781 140188941555520 submission_runner.py:406] Time since start: 3197.76s, 	Step: 7090, 	{'train/accuracy': 0.23876953125, 'train/loss': 4.080831050872803, 'validation/accuracy': 0.21621999144554138, 'validation/loss': 4.197323799133301, 'validation/num_examples': 50000, 'test/accuracy': 0.16040000319480896, 'test/loss': 4.601830005645752, 'test/num_examples': 10000, 'score': 2988.2134969234467, 'total_duration': 3197.7616159915924, 'accumulated_submission_time': 2988.2134969234467, 'accumulated_eval_time': 198.51556015014648, 'accumulated_logging_time': 10.892399311065674}
I0425 01:51:33.513244 140011026491136 logging_writer.py:48] [7090] accumulated_eval_time=198.515560, accumulated_logging_time=10.892399, accumulated_submission_time=2988.213497, global_step=7090, preemption_count=0, score=2988.213497, test/accuracy=0.160400, test/loss=4.601830, test/num_examples=10000, total_duration=3197.761616, train/accuracy=0.238770, train/loss=4.080831, validation/accuracy=0.216220, validation/loss=4.197324, validation/num_examples=50000
I0425 01:51:33.588930 140188941555520 checkpoints.py:356] Saving checkpoint at step: 7090
I0425 01:51:34.314755 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_7090
I0425 01:51:34.324308 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_7090.
I0425 01:51:40.981746 140011018098432 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.6824700236320496, loss=5.46267557144165
I0425 01:52:22.163370 140011009705728 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.6760762929916382, loss=5.517698764801025
I0425 01:53:03.314548 140011018098432 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.6282240152359009, loss=5.572703838348389
I0425 01:53:44.746745 140011009705728 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.5319190621376038, loss=6.433292388916016
I0425 01:54:26.505798 140011018098432 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.7157918214797974, loss=5.378779411315918
I0425 01:55:07.822607 140011009705728 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.6895236372947693, loss=5.351109027862549
I0425 01:55:49.346615 140011018098432 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.44430357217788696, loss=6.156225681304932
I0425 01:56:30.743874 140011009705728 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.7696737051010132, loss=5.472591400146484
I0425 01:57:11.869522 140011018098432 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.4994053840637207, loss=6.102193832397461
I0425 01:57:53.226871 140011009705728 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.6630570292472839, loss=5.206770896911621
I0425 01:58:34.722667 140011018098432 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.6924498081207275, loss=5.316015243530273
I0425 01:58:34.731644 140188941555520 spec.py:298] Evaluating on the training split.
I0425 01:58:48.762675 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 01:58:57.930156 140188941555520 spec.py:326] Evaluating on the test split.
I0425 01:58:59.577941 140188941555520 submission_runner.py:406] Time since start: 3643.84s, 	Step: 8101, 	{'train/accuracy': 0.28369140625, 'train/loss': 3.6669929027557373, 'validation/accuracy': 0.2537800073623657, 'validation/loss': 3.818631887435913, 'validation/num_examples': 50000, 'test/accuracy': 0.1941000074148178, 'test/loss': 4.278420925140381, 'test/num_examples': 10000, 'score': 3408.5996429920197, 'total_duration': 3643.835775613785, 'accumulated_submission_time': 3408.5996429920197, 'accumulated_eval_time': 223.36178183555603, 'accumulated_logging_time': 11.714434623718262}
I0425 01:58:59.589907 140011009705728 logging_writer.py:48] [8101] accumulated_eval_time=223.361782, accumulated_logging_time=11.714435, accumulated_submission_time=3408.599643, global_step=8101, preemption_count=0, score=3408.599643, test/accuracy=0.194100, test/loss=4.278421, test/num_examples=10000, total_duration=3643.835776, train/accuracy=0.283691, train/loss=3.666993, validation/accuracy=0.253780, validation/loss=3.818632, validation/num_examples=50000
I0425 01:58:59.696416 140188941555520 checkpoints.py:356] Saving checkpoint at step: 8101
I0425 01:59:00.534453 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_8101
I0425 01:59:00.546554 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_8101.
I0425 01:59:41.937827 140011018098432 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.5749413967132568, loss=5.293322563171387
I0425 02:00:23.242530 140011001313024 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.5483108162879944, loss=5.688475131988525
I0425 02:01:04.765388 140011018098432 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.629763126373291, loss=5.258404731750488
I0425 02:01:46.301943 140011001313024 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.6329638957977295, loss=5.254212856292725
I0425 02:02:28.023666 140011018098432 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.5343987941741943, loss=5.428839206695557
I0425 02:03:09.904656 140011001313024 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.6413899660110474, loss=5.139282703399658
I0425 02:03:51.860822 140011018098432 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.6070432662963867, loss=5.453705787658691
I0425 02:04:33.680805 140011001313024 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.5835014581680298, loss=5.257472515106201
I0425 02:05:15.398762 140011018098432 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.44210660457611084, loss=5.993386268615723
I0425 02:05:57.190650 140011001313024 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.6023483872413635, loss=5.766173839569092
I0425 02:06:00.678181 140188941555520 spec.py:298] Evaluating on the training split.
I0425 02:06:14.994156 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 02:06:25.004802 140188941555520 spec.py:326] Evaluating on the test split.
I0425 02:06:26.651941 140188941555520 submission_runner.py:406] Time since start: 4090.91s, 	Step: 9110, 	{'train/accuracy': 0.3073437511920929, 'train/loss': 3.5522525310516357, 'validation/accuracy': 0.28147998452186584, 'validation/loss': 3.683795213699341, 'validation/num_examples': 50000, 'test/accuracy': 0.2127000093460083, 'test/loss': 4.144068241119385, 'test/num_examples': 10000, 'score': 3828.710543870926, 'total_duration': 4090.9098179340363, 'accumulated_submission_time': 3828.710543870926, 'accumulated_eval_time': 249.3355143070221, 'accumulated_logging_time': 12.684527397155762}
I0425 02:06:26.665148 140011018098432 logging_writer.py:48] [9110] accumulated_eval_time=249.335514, accumulated_logging_time=12.684527, accumulated_submission_time=3828.710544, global_step=9110, preemption_count=0, score=3828.710544, test/accuracy=0.212700, test/loss=4.144068, test/num_examples=10000, total_duration=4090.909818, train/accuracy=0.307344, train/loss=3.552253, validation/accuracy=0.281480, validation/loss=3.683795, validation/num_examples=50000
I0425 02:06:26.767831 140188941555520 checkpoints.py:356] Saving checkpoint at step: 9110
I0425 02:06:27.567821 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_9110
I0425 02:06:27.577826 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_9110.
I0425 02:07:05.058804 140011001313024 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.5559991598129272, loss=5.339151382446289
I0425 02:07:46.416546 140010992920320 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.4865160286426544, loss=5.732867240905762
I0425 02:08:27.929918 140011001313024 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.45952412486076355, loss=6.13114070892334
I0425 02:09:09.414700 140010992920320 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.5712134838104248, loss=5.694080352783203
I0425 02:09:51.071616 140011001313024 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.6352100372314453, loss=5.054729461669922
I0425 02:10:32.801921 140010992920320 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.6452270746231079, loss=5.167799472808838
I0425 02:11:14.743082 140011001313024 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.6240530014038086, loss=5.029946804046631
I0425 02:11:56.665784 140010992920320 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.6337571740150452, loss=5.247446060180664
I0425 02:12:38.729810 140011001313024 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.4997134804725647, loss=5.829038619995117
I0425 02:13:20.744246 140010992920320 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.6053372621536255, loss=5.243923664093018
I0425 02:13:27.995160 140188941555520 spec.py:298] Evaluating on the training split.
I0425 02:13:44.223897 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 02:13:54.444798 140188941555520 spec.py:326] Evaluating on the test split.
I0425 02:13:56.109242 140188941555520 submission_runner.py:406] Time since start: 4540.37s, 	Step: 10119, 	{'train/accuracy': 0.34486326575279236, 'train/loss': 3.2680375576019287, 'validation/accuracy': 0.3170599937438965, 'validation/loss': 3.4037563800811768, 'validation/num_examples': 50000, 'test/accuracy': 0.24610000848770142, 'test/loss': 3.933549404144287, 'test/num_examples': 10000, 'score': 4249.101299762726, 'total_duration': 4540.3670909404755, 'accumulated_submission_time': 4249.101299762726, 'accumulated_eval_time': 277.44955611228943, 'accumulated_logging_time': 13.617517948150635}
I0425 02:13:56.123026 140011001313024 logging_writer.py:48] [10119] accumulated_eval_time=277.449556, accumulated_logging_time=13.617518, accumulated_submission_time=4249.101300, global_step=10119, preemption_count=0, score=4249.101300, test/accuracy=0.246100, test/loss=3.933549, test/num_examples=10000, total_duration=4540.367091, train/accuracy=0.344863, train/loss=3.268038, validation/accuracy=0.317060, validation/loss=3.403756, validation/num_examples=50000
I0425 02:13:56.263485 140188941555520 checkpoints.py:356] Saving checkpoint at step: 10119
I0425 02:13:57.086259 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_10119
I0425 02:13:57.096768 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_10119.
I0425 02:14:30.876248 140010992920320 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.5724725723266602, loss=5.556972026824951
I0425 02:15:12.509979 140010984527616 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.4721906781196594, loss=6.0413665771484375
I0425 02:15:54.058399 140010992920320 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.6521735191345215, loss=4.882245063781738
I0425 02:16:35.699668 140010984527616 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.6088032722473145, loss=5.144298553466797
I0425 02:17:17.153975 140010992920320 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.6078687310218811, loss=5.004598140716553
I0425 02:17:59.174513 140010984527616 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.538444995880127, loss=6.341564178466797
I0425 02:18:41.250586 140010992920320 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.5319632291793823, loss=5.514962673187256
I0425 02:19:23.169142 140010984527616 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.6412574648857117, loss=4.860640525817871
I0425 02:20:04.728826 140010992920320 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.6091988682746887, loss=4.9257588386535645
I0425 02:20:46.294193 140010984527616 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.5567280650138855, loss=5.250525951385498
I0425 02:20:57.207564 140188941555520 spec.py:298] Evaluating on the training split.
I0425 02:21:11.626094 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 02:21:21.723533 140188941555520 spec.py:326] Evaluating on the test split.
I0425 02:21:23.373378 140188941555520 submission_runner.py:406] Time since start: 4987.63s, 	Step: 11128, 	{'train/accuracy': 0.3642578125, 'train/loss': 3.2387590408325195, 'validation/accuracy': 0.33489999175071716, 'validation/loss': 3.3810369968414307, 'validation/num_examples': 50000, 'test/accuracy': 0.25290000438690186, 'test/loss': 3.9036974906921387, 'test/num_examples': 10000, 'score': 4669.192192316055, 'total_duration': 4987.631262540817, 'accumulated_submission_time': 4669.192192316055, 'accumulated_eval_time': 303.61536407470703, 'accumulated_logging_time': 14.606244802474976}
I0425 02:21:23.384525 140010992920320 logging_writer.py:48] [11128] accumulated_eval_time=303.615364, accumulated_logging_time=14.606245, accumulated_submission_time=4669.192192, global_step=11128, preemption_count=0, score=4669.192192, test/accuracy=0.252900, test/loss=3.903697, test/num_examples=10000, total_duration=4987.631263, train/accuracy=0.364258, train/loss=3.238759, validation/accuracy=0.334900, validation/loss=3.381037, validation/num_examples=50000
I0425 02:21:23.482177 140188941555520 checkpoints.py:356] Saving checkpoint at step: 11128
I0425 02:21:24.345690 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_11128
I0425 02:21:24.356605 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_11128.
I0425 02:21:54.454160 140010984527616 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.6311594247817993, loss=4.896744728088379
I0425 02:22:36.232913 140010909058816 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.5604104399681091, loss=6.265377044677734
I0425 02:23:17.838253 140010984527616 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.4928271770477295, loss=5.936286926269531
I0425 02:23:59.672609 140010909058816 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.5972256064414978, loss=5.185116767883301
I0425 02:24:41.393319 140010984527616 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.6962867379188538, loss=4.88668966293335
I0425 02:25:23.138177 140010909058816 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.628931999206543, loss=4.811616897583008
I0425 02:26:04.666329 140010984527616 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.6093040704727173, loss=4.918209075927734
I0425 02:26:46.235969 140010909058816 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.7176182270050049, loss=4.845321178436279
I0425 02:27:27.830829 140010984527616 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.4859412610530853, loss=5.604130268096924
I0425 02:28:09.385902 140010909058816 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.6545189619064331, loss=4.952262878417969
I0425 02:28:24.774852 140188941555520 spec.py:298] Evaluating on the training split.
I0425 02:28:38.807731 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 02:28:49.090933 140188941555520 spec.py:326] Evaluating on the test split.
I0425 02:28:50.748292 140188941555520 submission_runner.py:406] Time since start: 5435.01s, 	Step: 12139, 	{'train/accuracy': 0.3927929699420929, 'train/loss': 3.077559471130371, 'validation/accuracy': 0.3542799949645996, 'validation/loss': 3.2594106197357178, 'validation/num_examples': 50000, 'test/accuracy': 0.27390000224113464, 'test/loss': 3.788681745529175, 'test/num_examples': 10000, 'score': 5089.585218429565, 'total_duration': 5435.006143808365, 'accumulated_submission_time': 5089.585218429565, 'accumulated_eval_time': 329.5887625217438, 'accumulated_logging_time': 15.595468044281006}
I0425 02:28:50.762922 140010984527616 logging_writer.py:48] [12139] accumulated_eval_time=329.588763, accumulated_logging_time=15.595468, accumulated_submission_time=5089.585218, global_step=12139, preemption_count=0, score=5089.585218, test/accuracy=0.273900, test/loss=3.788682, test/num_examples=10000, total_duration=5435.006144, train/accuracy=0.392793, train/loss=3.077559, validation/accuracy=0.354280, validation/loss=3.259411, validation/num_examples=50000
I0425 02:28:50.872530 140188941555520 checkpoints.py:356] Saving checkpoint at step: 12139
I0425 02:28:51.600865 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_12139
I0425 02:28:51.611390 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_12139.
I0425 02:29:17.312235 140010909058816 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.695563793182373, loss=4.866614818572998
I0425 02:29:58.846748 140010900666112 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.5917907953262329, loss=4.824646949768066
I0425 02:30:41.063106 140010909058816 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.6661958694458008, loss=4.848139762878418
I0425 02:31:23.404817 140010900666112 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.4568668603897095, loss=6.094749450683594
I0425 02:32:05.371791 140010909058816 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.5197135210037231, loss=6.02053165435791
I0425 02:32:47.725738 140010900666112 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.524858295917511, loss=6.299975395202637
I0425 02:33:29.706408 140010909058816 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.6380211114883423, loss=4.766448020935059
I0425 02:34:11.698020 140010900666112 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.5676296949386597, loss=4.9706878662109375
I0425 02:34:53.315504 140010909058816 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.46344584226608276, loss=6.261812210083008
I0425 02:35:34.915817 140010900666112 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.6238766312599182, loss=4.78229284286499
I0425 02:35:52.003461 140188941555520 spec.py:298] Evaluating on the training split.
I0425 02:36:06.118411 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 02:36:16.788670 140188941555520 spec.py:326] Evaluating on the test split.
I0425 02:36:18.442078 140188941555520 submission_runner.py:406] Time since start: 5882.70s, 	Step: 13143, 	{'train/accuracy': 0.4119921922683716, 'train/loss': 2.9095730781555176, 'validation/accuracy': 0.3752399981021881, 'validation/loss': 3.072901487350464, 'validation/num_examples': 50000, 'test/accuracy': 0.289000004529953, 'test/loss': 3.650526762008667, 'test/num_examples': 10000, 'score': 5509.953811168671, 'total_duration': 5882.69993853569, 'accumulated_submission_time': 5509.953811168671, 'accumulated_eval_time': 356.02735209465027, 'accumulated_logging_time': 16.463306427001953}
I0425 02:36:18.456663 140010909058816 logging_writer.py:48] [13143] accumulated_eval_time=356.027352, accumulated_logging_time=16.463306, accumulated_submission_time=5509.953811, global_step=13143, preemption_count=0, score=5509.953811, test/accuracy=0.289000, test/loss=3.650527, test/num_examples=10000, total_duration=5882.699939, train/accuracy=0.411992, train/loss=2.909573, validation/accuracy=0.375240, validation/loss=3.072901, validation/num_examples=50000
I0425 02:36:18.648926 140188941555520 checkpoints.py:356] Saving checkpoint at step: 13143
I0425 02:36:19.563004 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_13143
I0425 02:36:19.578755 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_13143.
I0425 02:36:43.709231 140010900666112 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.7335286736488342, loss=4.692771911621094
I0425 02:37:25.403686 140010892273408 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.41791677474975586, loss=6.181893348693848
I0425 02:38:06.991094 140010900666112 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.638702392578125, loss=5.060967445373535
I0425 02:38:49.156085 140010892273408 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.6901788115501404, loss=4.828619003295898
I0425 02:39:31.479953 140010900666112 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.8475066423416138, loss=4.79123592376709
I0425 02:40:13.449770 140010892273408 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.6031102538108826, loss=5.015864372253418
I0425 02:40:55.314576 140010900666112 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.6626499891281128, loss=4.710373401641846
I0425 02:41:37.559545 140010892273408 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.6524266004562378, loss=4.624645709991455
I0425 02:42:20.245479 140010900666112 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.6778830289840698, loss=4.610918998718262
I0425 02:43:02.642706 140010892273408 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.6995046138763428, loss=4.600868225097656
I0425 02:43:19.836327 140188941555520 spec.py:298] Evaluating on the training split.
I0425 02:43:34.215024 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 02:43:44.933380 140188941555520 spec.py:326] Evaluating on the test split.
I0425 02:43:46.583357 140188941555520 submission_runner.py:406] Time since start: 6330.84s, 	Step: 14142, 	{'train/accuracy': 0.4274023473262787, 'train/loss': 2.8841588497161865, 'validation/accuracy': 0.3940799832344055, 'validation/loss': 3.0327014923095703, 'validation/num_examples': 50000, 'test/accuracy': 0.30320000648498535, 'test/loss': 3.614177942276001, 'test/num_examples': 10000, 'score': 5930.191396951675, 'total_duration': 6330.841212511063, 'accumulated_submission_time': 5930.191396951675, 'accumulated_eval_time': 382.7743353843689, 'accumulated_logging_time': 17.601743936538696}
I0425 02:43:46.597502 140010900666112 logging_writer.py:48] [14142] accumulated_eval_time=382.774335, accumulated_logging_time=17.601744, accumulated_submission_time=5930.191397, global_step=14142, preemption_count=0, score=5930.191397, test/accuracy=0.303200, test/loss=3.614178, test/num_examples=10000, total_duration=6330.841213, train/accuracy=0.427402, train/loss=2.884159, validation/accuracy=0.394080, validation/loss=3.032701, validation/num_examples=50000
I0425 02:43:46.812421 140188941555520 checkpoints.py:356] Saving checkpoint at step: 14142
I0425 02:43:47.616192 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_14142
I0425 02:43:47.633426 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_14142.
I0425 02:44:11.931556 140010892273408 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.4860617220401764, loss=5.708710193634033
I0425 02:44:53.678788 140010883880704 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.628103494644165, loss=4.64609432220459
I0425 02:45:36.078342 140010892273408 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.4828280210494995, loss=6.004265785217285
I0425 02:46:17.879219 140010883880704 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.6433700323104858, loss=4.658389091491699
I0425 02:46:59.509094 140010892273408 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.6088019609451294, loss=4.722757816314697
I0425 02:47:41.388835 140010883880704 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.5515994429588318, loss=4.992999076843262
I0425 02:48:23.572454 140010892273408 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.6674161553382874, loss=4.664053916931152
I0425 02:49:05.746018 140010883880704 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.533868670463562, loss=5.685065746307373
I0425 02:49:47.961781 140010892273408 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.6788586974143982, loss=4.885821342468262
I0425 02:50:47.842714 140188941555520 spec.py:298] Evaluating on the training split.
I0425 02:51:02.154220 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 02:51:12.648372 140188941555520 spec.py:326] Evaluating on the test split.
I0425 02:51:14.287269 140188941555520 submission_runner.py:406] Time since start: 6778.55s, 	Step: 15093, 	{'train/accuracy': 0.4512890577316284, 'train/loss': 2.6843795776367188, 'validation/accuracy': 0.4163999855518341, 'validation/loss': 2.8727974891662598, 'validation/num_examples': 50000, 'test/accuracy': 0.31530001759529114, 'test/loss': 3.4674603939056396, 'test/num_examples': 10000, 'score': 6350.3741755485535, 'total_duration': 6778.5451102256775, 'accumulated_submission_time': 6350.3741755485535, 'accumulated_eval_time': 409.2188220024109, 'accumulated_logging_time': 18.661116123199463}
I0425 02:51:14.303549 140010883880704 logging_writer.py:48] [15093] accumulated_eval_time=409.218822, accumulated_logging_time=18.661116, accumulated_submission_time=6350.374176, global_step=15093, preemption_count=0, score=6350.374176, test/accuracy=0.315300, test/loss=3.467460, test/num_examples=10000, total_duration=6778.545110, train/accuracy=0.451289, train/loss=2.684380, validation/accuracy=0.416400, validation/loss=2.872797, validation/num_examples=50000
I0425 02:51:14.472036 140188941555520 checkpoints.py:356] Saving checkpoint at step: 15093
I0425 02:51:15.352745 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_15093
I0425 02:51:15.369088 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_15093.
I0425 02:51:18.702315 140010892273408 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.6684757471084595, loss=4.565156936645508
I0425 02:52:00.020653 140010875488000 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.5780842900276184, loss=5.128830432891846
I0425 02:52:42.240013 140010892273408 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.6386749148368835, loss=4.662891387939453
I0425 02:53:24.985508 140010875488000 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.48998579382896423, loss=5.498483657836914
I0425 02:54:07.090882 140010892273408 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.4869799017906189, loss=6.015825271606445
I0425 02:54:49.154365 140010875488000 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.6581957340240479, loss=4.513821125030518
I0425 02:55:31.624144 140010892273408 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.6726161241531372, loss=4.541077613830566
I0425 02:56:13.577822 140010875488000 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.7092736959457397, loss=4.577154159545898
I0425 02:56:55.597025 140010892273408 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.6683371067047119, loss=4.49095344543457
I0425 02:57:37.815789 140010875488000 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.624085545539856, loss=4.555881500244141
I0425 02:58:15.612537 140188941555520 spec.py:298] Evaluating on the training split.
I0425 02:58:30.713820 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 02:58:41.203523 140188941555520 spec.py:326] Evaluating on the test split.
I0425 02:58:42.858822 140188941555520 submission_runner.py:406] Time since start: 7227.12s, 	Step: 16091, 	{'train/accuracy': 0.47349607944488525, 'train/loss': 2.5890743732452393, 'validation/accuracy': 0.43143999576568604, 'validation/loss': 2.803948163986206, 'validation/num_examples': 50000, 'test/accuracy': 0.33650001883506775, 'test/loss': 3.391716480255127, 'test/num_examples': 10000, 'score': 6770.597817897797, 'total_duration': 7227.116655349731, 'accumulated_submission_time': 6770.597817897797, 'accumulated_eval_time': 436.4650490283966, 'accumulated_logging_time': 19.744170904159546}
I0425 02:58:42.874828 140010892273408 logging_writer.py:48] [16091] accumulated_eval_time=436.465049, accumulated_logging_time=19.744171, accumulated_submission_time=6770.597818, global_step=16091, preemption_count=0, score=6770.597818, test/accuracy=0.336500, test/loss=3.391716, test/num_examples=10000, total_duration=7227.116655, train/accuracy=0.473496, train/loss=2.589074, validation/accuracy=0.431440, validation/loss=2.803948, validation/num_examples=50000
I0425 02:58:43.073474 140188941555520 checkpoints.py:356] Saving checkpoint at step: 16091
I0425 02:58:43.868898 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_16091
I0425 02:58:43.884769 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_16091.
I0425 02:58:48.068973 140010875488000 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.5445170402526855, loss=4.980820655822754
I0425 02:59:29.325636 140010867095296 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.4969165623188019, loss=6.048393249511719
I0425 03:00:11.687009 140010875488000 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.6542811989784241, loss=4.620943069458008
I0425 03:00:53.779187 140010867095296 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.6330543160438538, loss=5.010514259338379
I0425 03:01:36.108189 140010875488000 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.6280093193054199, loss=4.556913375854492
I0425 03:02:18.299976 140010867095296 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.6486855149269104, loss=4.538775444030762
I0425 03:03:00.127477 140010875488000 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.6752820014953613, loss=4.4877729415893555
I0425 03:03:42.415400 140010867095296 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.5830916166305542, loss=4.3850998878479
I0425 03:04:24.599082 140010875488000 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.4302799105644226, loss=6.147964000701904
I0425 03:05:06.609418 140010867095296 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.5525044202804565, loss=5.01862907409668
I0425 03:05:44.117965 140188941555520 spec.py:298] Evaluating on the training split.
I0425 03:05:58.788900 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 03:06:09.852044 140188941555520 spec.py:326] Evaluating on the test split.
I0425 03:06:11.507182 140188941555520 submission_runner.py:406] Time since start: 7675.77s, 	Step: 17091, 	{'train/accuracy': 0.4855664074420929, 'train/loss': 2.469829797744751, 'validation/accuracy': 0.4524399936199188, 'validation/loss': 2.6456897258758545, 'validation/num_examples': 50000, 'test/accuracy': 0.34530001878738403, 'test/loss': 3.2488362789154053, 'test/num_examples': 10000, 'score': 7190.797775268555, 'total_duration': 7675.765034914017, 'accumulated_submission_time': 7190.797775268555, 'accumulated_eval_time': 463.8542513847351, 'accumulated_logging_time': 20.785062789916992}
I0425 03:06:11.527522 140010875488000 logging_writer.py:48] [17091] accumulated_eval_time=463.854251, accumulated_logging_time=20.785063, accumulated_submission_time=7190.797775, global_step=17091, preemption_count=0, score=7190.797775, test/accuracy=0.345300, test/loss=3.248836, test/num_examples=10000, total_duration=7675.765035, train/accuracy=0.485566, train/loss=2.469830, validation/accuracy=0.452440, validation/loss=2.645690, validation/num_examples=50000
I0425 03:06:11.699074 140188941555520 checkpoints.py:356] Saving checkpoint at step: 17091
I0425 03:06:12.527185 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_17091
I0425 03:06:12.543287 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_17091.
I0425 03:06:16.754709 140010867095296 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.48168736696243286, loss=6.147504806518555
I0425 03:06:58.171362 140010858702592 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.5516098141670227, loss=5.022427082061768
I0425 03:07:39.980838 140010867095296 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.6550881862640381, loss=4.533343315124512
I0425 03:08:22.018089 140010858702592 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.6173563599586487, loss=4.375617504119873
I0425 03:09:04.477433 140010867095296 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.5843451023101807, loss=4.82286262512207
I0425 03:09:46.320941 140010858702592 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.6894769668579102, loss=4.4776153564453125
I0425 03:10:28.313070 140010867095296 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.6702399849891663, loss=4.356563568115234
I0425 03:11:10.231367 140010858702592 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.6102015972137451, loss=5.079313278198242
I0425 03:11:52.080986 140010867095296 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.6370099782943726, loss=4.37054443359375
I0425 03:12:34.197308 140010858702592 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.6912952661514282, loss=4.310597896575928
I0425 03:13:12.686732 140188941555520 spec.py:298] Evaluating on the training split.
I0425 03:13:27.038454 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 03:13:38.414218 140188941555520 spec.py:326] Evaluating on the test split.
I0425 03:13:40.077518 140188941555520 submission_runner.py:406] Time since start: 8124.34s, 	Step: 18093, 	{'train/accuracy': 0.5006640553474426, 'train/loss': 2.404042959213257, 'validation/accuracy': 0.4616200029850006, 'validation/loss': 2.5777037143707275, 'validation/num_examples': 50000, 'test/accuracy': 0.3570000231266022, 'test/loss': 3.186311960220337, 'test/num_examples': 10000, 'score': 7610.9108102321625, 'total_duration': 8124.3353972435, 'accumulated_submission_time': 7610.9108102321625, 'accumulated_eval_time': 491.2451066970825, 'accumulated_logging_time': 21.83328652381897}
I0425 03:13:40.094997 140010867095296 logging_writer.py:48] [18093] accumulated_eval_time=491.245107, accumulated_logging_time=21.833287, accumulated_submission_time=7610.910810, global_step=18093, preemption_count=0, score=7610.910810, test/accuracy=0.357000, test/loss=3.186312, test/num_examples=10000, total_duration=8124.335397, train/accuracy=0.500664, train/loss=2.404043, validation/accuracy=0.461620, validation/loss=2.577704, validation/num_examples=50000
I0425 03:13:40.298172 140188941555520 checkpoints.py:356] Saving checkpoint at step: 18093
I0425 03:13:41.272188 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_18093
I0425 03:13:41.291450 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_18093.
I0425 03:13:44.616141 140010858702592 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.6644758582115173, loss=4.407482624053955
I0425 03:14:26.557728 140010858702592 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.7314189672470093, loss=4.380026340484619
I0425 03:15:08.801136 140010850309888 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.6276986598968506, loss=4.385587215423584
I0425 03:15:52.144135 140010858702592 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.5730920433998108, loss=5.119140625
I0425 03:16:34.748589 140010850309888 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.5447579026222229, loss=6.0543599128723145
I0425 03:17:17.037926 140010858702592 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.6139950752258301, loss=4.604339122772217
I0425 03:17:59.307760 140010850309888 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.5797558426856995, loss=4.7614827156066895
I0425 03:18:42.181372 140010858702592 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.6709303259849548, loss=4.460420608520508
I0425 03:19:25.083112 140010850309888 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.7044364809989929, loss=4.468451499938965
I0425 03:20:07.810418 140010858702592 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.5605313777923584, loss=5.5901923179626465
I0425 03:20:41.486412 140188941555520 spec.py:298] Evaluating on the training split.
I0425 03:20:56.224563 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 03:21:08.008374 140188941555520 spec.py:326] Evaluating on the test split.
I0425 03:21:09.659174 140188941555520 submission_runner.py:406] Time since start: 8573.92s, 	Step: 19081, 	{'train/accuracy': 0.5074999928474426, 'train/loss': 2.379533052444458, 'validation/accuracy': 0.4713999927043915, 'validation/loss': 2.5625834465026855, 'validation/num_examples': 50000, 'test/accuracy': 0.3621000051498413, 'test/loss': 3.1780245304107666, 'test/num_examples': 10000, 'score': 8031.074519395828, 'total_duration': 8573.917031764984, 'accumulated_submission_time': 8031.074519395828, 'accumulated_eval_time': 519.4178292751312, 'accumulated_logging_time': 23.060985565185547}
I0425 03:21:09.675157 140010850309888 logging_writer.py:48] [19081] accumulated_eval_time=519.417829, accumulated_logging_time=23.060986, accumulated_submission_time=8031.074519, global_step=19081, preemption_count=0, score=8031.074519, test/accuracy=0.362100, test/loss=3.178025, test/num_examples=10000, total_duration=8573.917032, train/accuracy=0.507500, train/loss=2.379533, validation/accuracy=0.471400, validation/loss=2.562583, validation/num_examples=50000
I0425 03:21:09.870912 140188941555520 checkpoints.py:356] Saving checkpoint at step: 19081
I0425 03:21:10.707687 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_19081
I0425 03:21:10.724916 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_19081.
I0425 03:21:18.962394 140010858702592 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.6038458943367004, loss=4.361665725708008
I0425 03:22:00.302350 140010145683200 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.5455618500709534, loss=5.240966320037842
I0425 03:22:42.544399 140010858702592 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.6818466186523438, loss=4.407389163970947
I0425 03:23:25.083394 140010145683200 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.6564260125160217, loss=4.273808479309082
I0425 03:24:07.823322 140010858702592 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.5545567274093628, loss=4.970524311065674
I0425 03:24:49.748571 140010145683200 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.6650742888450623, loss=4.279656410217285
I0425 03:25:31.506360 140010858702592 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.6204119324684143, loss=4.282957553863525
I0425 03:26:13.674839 140010145683200 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.7268643379211426, loss=4.372835159301758
I0425 03:26:55.939201 140010858702592 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.6880673766136169, loss=4.310486316680908
I0425 03:27:37.972847 140010145683200 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.6413829922676086, loss=4.316812038421631
I0425 03:28:11.064183 140188941555520 spec.py:298] Evaluating on the training split.
I0425 03:28:25.191814 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 03:28:35.836959 140188941555520 spec.py:326] Evaluating on the test split.
I0425 03:28:37.523699 140188941555520 submission_runner.py:406] Time since start: 9021.78s, 	Step: 20080, 	{'train/accuracy': 0.5354687571525574, 'train/loss': 2.2465405464172363, 'validation/accuracy': 0.48267999291419983, 'validation/loss': 2.491910457611084, 'validation/num_examples': 50000, 'test/accuracy': 0.3726000189781189, 'test/loss': 3.1086034774780273, 'test/num_examples': 10000, 'score': 8451.394375801086, 'total_duration': 9021.78155040741, 'accumulated_submission_time': 8451.394375801086, 'accumulated_eval_time': 545.8773019313812, 'accumulated_logging_time': 24.128031015396118}
I0425 03:28:37.538504 140010858702592 logging_writer.py:48] [20080] accumulated_eval_time=545.877302, accumulated_logging_time=24.128031, accumulated_submission_time=8451.394376, global_step=20080, preemption_count=0, score=8451.394376, test/accuracy=0.372600, test/loss=3.108603, test/num_examples=10000, total_duration=9021.781550, train/accuracy=0.535469, train/loss=2.246541, validation/accuracy=0.482680, validation/loss=2.491910, validation/num_examples=50000
I0425 03:28:38.035257 140188941555520 checkpoints.py:356] Saving checkpoint at step: 20080
I0425 03:28:40.456106 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_20080
I0425 03:28:40.472025 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_20080.
I0425 03:28:49.136835 140010145683200 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.5799266695976257, loss=4.690361976623535
I0425 03:29:30.363400 140010137290496 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.4696122705936432, loss=5.532411575317383
I0425 03:30:12.256765 140010145683200 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.6534999012947083, loss=4.421780109405518
I0425 03:30:53.922562 140010137290496 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.6521471738815308, loss=4.306868076324463
I0425 03:31:36.139146 140010145683200 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.686033308506012, loss=4.434038162231445
I0425 03:32:17.915566 140010137290496 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.7138281464576721, loss=4.334697723388672
I0425 03:32:59.571623 140010145683200 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.6818092465400696, loss=4.269418716430664
I0425 03:33:41.399985 140010137290496 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.6492756605148315, loss=4.1861252784729
I0425 03:34:23.491250 140010145683200 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.6410965323448181, loss=4.43576717376709
I0425 03:35:05.249046 140010137290496 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.6006444692611694, loss=4.476680755615234
I0425 03:35:40.555267 140188941555520 spec.py:298] Evaluating on the training split.
I0425 03:35:54.960312 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 03:36:07.289799 140188941555520 spec.py:326] Evaluating on the test split.
I0425 03:36:08.963702 140188941555520 submission_runner.py:406] Time since start: 9473.22s, 	Step: 21086, 	{'train/accuracy': 0.5404882431030273, 'train/loss': 2.2312099933624268, 'validation/accuracy': 0.4932999908924103, 'validation/loss': 2.4684717655181885, 'validation/num_examples': 50000, 'test/accuracy': 0.38050001859664917, 'test/loss': 3.086297035217285, 'test/num_examples': 10000, 'score': 8871.457185983658, 'total_duration': 9473.221551656723, 'accumulated_submission_time': 8871.457185983658, 'accumulated_eval_time': 574.2857191562653, 'accumulated_logging_time': 27.077858448028564}
I0425 03:36:08.981261 140010145683200 logging_writer.py:48] [21086] accumulated_eval_time=574.285719, accumulated_logging_time=27.077858, accumulated_submission_time=8871.457186, global_step=21086, preemption_count=0, score=8871.457186, test/accuracy=0.380500, test/loss=3.086297, test/num_examples=10000, total_duration=9473.221552, train/accuracy=0.540488, train/loss=2.231210, validation/accuracy=0.493300, validation/loss=2.468472, validation/num_examples=50000
I0425 03:36:09.094382 140188941555520 checkpoints.py:356] Saving checkpoint at step: 21086
I0425 03:36:09.964967 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_21086
I0425 03:36:09.981157 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_21086.
I0425 03:36:16.202666 140010137290496 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.6720985770225525, loss=4.239317893981934
I0425 03:36:57.640839 140010128897792 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.5888180136680603, loss=4.697536945343018
I0425 03:37:39.578184 140010137290496 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.7336584329605103, loss=4.287803649902344
I0425 03:38:21.476645 140010128897792 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.5498812198638916, loss=4.896392822265625
I0425 03:39:03.390850 140010137290496 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.5582998394966125, loss=4.832205772399902
I0425 03:39:45.423932 140010128897792 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.6920499205589294, loss=4.271945953369141
I0425 03:40:26.966040 140010137290496 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.6623438000679016, loss=4.2357096672058105
I0425 03:41:08.803694 140010128897792 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.6539843082427979, loss=4.398685932159424
I0425 03:41:50.528204 140010137290496 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.5244649648666382, loss=5.998045444488525
I0425 03:42:32.237048 140010128897792 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.646439790725708, loss=4.574303150177002
I0425 03:43:10.009636 140188941555520 spec.py:298] Evaluating on the training split.
I0425 03:43:24.060092 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 03:43:36.330298 140188941555520 spec.py:326] Evaluating on the test split.
I0425 03:43:37.985119 140188941555520 submission_runner.py:406] Time since start: 9922.24s, 	Step: 22092, 	{'train/accuracy': 0.5455468893051147, 'train/loss': 2.182596445083618, 'validation/accuracy': 0.5018599629402161, 'validation/loss': 2.373154401779175, 'validation/num_examples': 50000, 'test/accuracy': 0.3968000113964081, 'test/loss': 3.0087385177612305, 'test/num_examples': 10000, 'score': 9291.465188741684, 'total_duration': 9922.242956876755, 'accumulated_submission_time': 9291.465188741684, 'accumulated_eval_time': 602.261144399643, 'accumulated_logging_time': 28.096922874450684}
I0425 03:43:37.996579 140010137290496 logging_writer.py:48] [22092] accumulated_eval_time=602.261144, accumulated_logging_time=28.096923, accumulated_submission_time=9291.465189, global_step=22092, preemption_count=0, score=9291.465189, test/accuracy=0.396800, test/loss=3.008739, test/num_examples=10000, total_duration=9922.242957, train/accuracy=0.545547, train/loss=2.182596, validation/accuracy=0.501860, validation/loss=2.373154, validation/num_examples=50000
I0425 03:43:38.089254 140188941555520 checkpoints.py:356] Saving checkpoint at step: 22092
I0425 03:43:38.960384 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_22092
I0425 03:43:38.975663 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_22092.
I0425 03:43:42.734356 140010128897792 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.5977831482887268, loss=4.357983589172363
I0425 03:44:24.324341 140010120505088 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.6380700469017029, loss=4.419449329376221
I0425 03:45:07.100888 140010128897792 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.6492142081260681, loss=4.127499580383301
I0425 03:45:49.434580 140010120505088 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.6114991903305054, loss=4.274128437042236
I0425 03:46:31.943514 140010128897792 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.5171611905097961, loss=6.028024196624756
I0425 03:47:14.457976 140010120505088 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.6329795122146606, loss=4.232792377471924
I0425 03:47:56.958377 140010128897792 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.5821018218994141, loss=4.7439093589782715
I0425 03:48:39.310452 140010120505088 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.6274186372756958, loss=4.323630332946777
I0425 03:49:21.743715 140010128897792 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.6235447525978088, loss=4.61857271194458
I0425 03:50:04.191339 140010120505088 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.5496819615364075, loss=4.7993268966674805
I0425 03:50:39.312044 140188941555520 spec.py:298] Evaluating on the training split.
I0425 03:50:54.067157 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 03:51:05.176038 140188941555520 spec.py:326] Evaluating on the test split.
I0425 03:51:06.846837 140188941555520 submission_runner.py:406] Time since start: 10371.10s, 	Step: 23085, 	{'train/accuracy': 0.5616210699081421, 'train/loss': 2.150580644607544, 'validation/accuracy': 0.5141800045967102, 'validation/loss': 2.369142532348633, 'validation/num_examples': 50000, 'test/accuracy': 0.4004000127315521, 'test/loss': 2.9880428314208984, 'test/num_examples': 10000, 'score': 9711.782388687134, 'total_duration': 10371.101443767548, 'accumulated_submission_time': 9711.782388687134, 'accumulated_eval_time': 629.7926549911499, 'accumulated_logging_time': 29.088724374771118}
I0425 03:51:06.864212 140010128897792 logging_writer.py:48] [23085] accumulated_eval_time=629.792655, accumulated_logging_time=29.088724, accumulated_submission_time=9711.782389, global_step=23085, preemption_count=0, score=9711.782389, test/accuracy=0.400400, test/loss=2.988043, test/num_examples=10000, total_duration=10371.101444, train/accuracy=0.561621, train/loss=2.150581, validation/accuracy=0.514180, validation/loss=2.369143, validation/num_examples=50000
I0425 03:51:07.422458 140188941555520 checkpoints.py:356] Saving checkpoint at step: 23085
I0425 03:51:08.817281 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_23085
I0425 03:51:08.834059 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_23085.
I0425 03:51:15.405577 140010120505088 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.6583457589149475, loss=4.1850996017456055
I0425 03:51:58.086026 140010112112384 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.6470087766647339, loss=4.179477214813232
I0425 03:52:42.498060 140010120505088 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.4917106032371521, loss=5.646175384521484
I0425 03:53:26.779356 140010112112384 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.6696776151657104, loss=4.2094902992248535
I0425 03:54:11.206920 140010120505088 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.5363845229148865, loss=5.35565710067749
I0425 03:54:55.563606 140010112112384 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.5384995341300964, loss=4.876282215118408
I0425 03:55:39.987163 140010120505088 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.6567529439926147, loss=4.199099540710449
I0425 03:56:24.265789 140010112112384 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.6209236979484558, loss=4.277968406677246
I0425 03:57:08.624406 140010120505088 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.7364925742149353, loss=4.1171979904174805
I0425 03:57:52.660031 140010112112384 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.6879353523254395, loss=4.2850470542907715
I0425 03:58:09.138858 140188941555520 spec.py:298] Evaluating on the training split.
I0425 03:58:21.242528 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 03:58:34.330440 140188941555520 spec.py:326] Evaluating on the test split.
I0425 03:58:35.974568 140188941555520 submission_runner.py:406] Time since start: 10820.23s, 	Step: 24039, 	{'train/accuracy': 0.5726757645606995, 'train/loss': 2.1971826553344727, 'validation/accuracy': 0.5177599787712097, 'validation/loss': 2.4432191848754883, 'validation/num_examples': 50000, 'test/accuracy': 0.4003000259399414, 'test/loss': 3.0515408515930176, 'test/num_examples': 10000, 'score': 10132.069001674652, 'total_duration': 10820.231442689896, 'accumulated_submission_time': 10132.069001674652, 'accumulated_eval_time': 656.6273210048676, 'accumulated_logging_time': 31.077441215515137}
I0425 03:58:35.993590 140010112112384 logging_writer.py:48] [24039] accumulated_eval_time=656.627321, accumulated_logging_time=31.077441, accumulated_submission_time=10132.069002, global_step=24039, preemption_count=0, score=10132.069002, test/accuracy=0.400300, test/loss=3.051541, test/num_examples=10000, total_duration=10820.231443, train/accuracy=0.572676, train/loss=2.197183, validation/accuracy=0.517760, validation/loss=2.443219, validation/num_examples=50000
I0425 03:58:36.101939 140188941555520 checkpoints.py:356] Saving checkpoint at step: 24039
I0425 03:58:36.983094 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_24039
I0425 03:58:36.998923 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_24039.
I0425 03:59:02.533555 140010120505088 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.689129114151001, loss=4.13729190826416
I0425 03:59:44.035101 140010028267264 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.6527553200721741, loss=4.229583740234375
I0425 04:00:25.921993 140010120505088 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.619253933429718, loss=4.3662919998168945
I0425 04:01:07.866735 140010028267264 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.6788070201873779, loss=4.205375671386719
I0425 04:01:49.582280 140010120505088 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.587059497833252, loss=4.607144832611084
I0425 04:02:31.509265 140010028267264 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.5816659927368164, loss=4.992592811584473
I0425 04:03:13.271040 140010120505088 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.6368263363838196, loss=4.112966537475586
I0425 04:03:55.475123 140010028267264 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.650230348110199, loss=4.0536065101623535
I0425 04:04:37.577507 140010120505088 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.67804354429245, loss=4.151214122772217
I0425 04:05:19.431550 140010028267264 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.5639886856079102, loss=4.989799499511719
I0425 04:05:37.339467 140188941555520 spec.py:298] Evaluating on the training split.
I0425 04:05:49.060585 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 04:06:02.054496 140188941555520 spec.py:326] Evaluating on the test split.
I0425 04:06:03.707909 140188941555520 submission_runner.py:406] Time since start: 11267.96s, 	Step: 25044, 	{'train/accuracy': 0.5855273604393005, 'train/loss': 1.972352147102356, 'validation/accuracy': 0.536359965801239, 'validation/loss': 2.2183494567871094, 'validation/num_examples': 50000, 'test/accuracy': 0.4148000180721283, 'test/loss': 2.857422113418579, 'test/num_examples': 10000, 'score': 10552.389263391495, 'total_duration': 11267.964704036713, 'accumulated_submission_time': 10552.389263391495, 'accumulated_eval_time': 682.994678735733, 'accumulated_logging_time': 32.10330367088318}
I0425 04:06:03.719977 140010120505088 logging_writer.py:48] [25044] accumulated_eval_time=682.994679, accumulated_logging_time=32.103304, accumulated_submission_time=10552.389263, global_step=25044, preemption_count=0, score=10552.389263, test/accuracy=0.414800, test/loss=2.857422, test/num_examples=10000, total_duration=11267.964704, train/accuracy=0.585527, train/loss=1.972352, validation/accuracy=0.536360, validation/loss=2.218349, validation/num_examples=50000
I0425 04:06:03.889232 140188941555520 checkpoints.py:356] Saving checkpoint at step: 25044
I0425 04:06:04.840723 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_25044
I0425 04:06:04.862888 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_25044.
I0425 04:06:28.422317 140010028267264 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.653664231300354, loss=4.1137261390686035
I0425 04:07:10.194791 140010019874560 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.6876850128173828, loss=4.160025596618652
I0425 04:07:52.175584 140010028267264 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.5569579601287842, loss=4.839288711547852
I0425 04:08:33.948974 140010019874560 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.6187098026275635, loss=4.284119129180908
I0425 04:09:15.921697 140010028267264 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.6454013586044312, loss=4.0866923332214355
I0425 04:09:58.209538 140010019874560 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.6634442210197449, loss=4.21376371383667
I0425 04:10:40.368775 140010028267264 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.6685013771057129, loss=4.171518325805664
I0425 04:11:22.385865 140010019874560 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.6264464855194092, loss=4.0776238441467285
I0425 04:12:04.521780 140010028267264 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.6140263676643372, loss=4.0691351890563965
I0425 04:12:46.530176 140010019874560 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.493925005197525, loss=5.860836029052734
I0425 04:13:05.161387 140188941555520 spec.py:298] Evaluating on the training split.
I0425 04:13:16.569816 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 04:13:29.723059 140188941555520 spec.py:326] Evaluating on the test split.
I0425 04:13:31.361549 140188941555520 submission_runner.py:406] Time since start: 11715.62s, 	Step: 26046, 	{'train/accuracy': 0.5821484327316284, 'train/loss': 2.021918296813965, 'validation/accuracy': 0.5317800045013428, 'validation/loss': 2.24820613861084, 'validation/num_examples': 50000, 'test/accuracy': 0.4155000150203705, 'test/loss': 2.8895366191864014, 'test/num_examples': 10000, 'score': 10972.654935598373, 'total_duration': 11715.618239164352, 'accumulated_submission_time': 10972.654935598373, 'accumulated_eval_time': 709.1936414241791, 'accumulated_logging_time': 33.27214169502258}
I0425 04:13:31.373478 140010028267264 logging_writer.py:48] [26046] accumulated_eval_time=709.193641, accumulated_logging_time=33.272142, accumulated_submission_time=10972.654936, global_step=26046, preemption_count=0, score=10972.654936, test/accuracy=0.415500, test/loss=2.889537, test/num_examples=10000, total_duration=11715.618239, train/accuracy=0.582148, train/loss=2.021918, validation/accuracy=0.531780, validation/loss=2.248206, validation/num_examples=50000
I0425 04:13:31.474843 140188941555520 checkpoints.py:356] Saving checkpoint at step: 26046
I0425 04:13:32.406337 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_26046
I0425 04:13:32.422324 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_26046.
I0425 04:13:55.157778 140010019874560 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.6586739420890808, loss=4.097470760345459
I0425 04:14:36.765147 140010011481856 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.683650553226471, loss=4.078518390655518
I0425 04:15:18.818401 140010019874560 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.5799794793128967, loss=5.389790058135986
I0425 04:16:00.961892 140010011481856 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.5134871602058411, loss=4.9857048988342285
I0425 04:16:42.996232 140010019874560 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.6734415292739868, loss=4.043878555297852
I0425 04:17:24.835085 140010011481856 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.6379225254058838, loss=4.029900550842285
I0425 04:18:06.887307 140010019874560 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.6012876629829407, loss=4.641066074371338
I0425 04:18:48.573827 140010011481856 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.681532084941864, loss=4.08536434173584
I0425 04:19:30.739804 140010019874560 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.6501085758209229, loss=4.15413761138916
I0425 04:20:12.979566 140010011481856 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.5783522129058838, loss=4.491127967834473
I0425 04:20:32.588557 140188941555520 spec.py:298] Evaluating on the training split.
I0425 04:20:43.338041 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 04:20:55.772140 140188941555520 spec.py:326] Evaluating on the test split.
I0425 04:20:57.432027 140188941555520 submission_runner.py:406] Time since start: 12161.69s, 	Step: 27048, 	{'train/accuracy': 0.5941601395606995, 'train/loss': 1.9359617233276367, 'validation/accuracy': 0.5423399806022644, 'validation/loss': 2.166809558868408, 'validation/num_examples': 50000, 'test/accuracy': 0.42480000853538513, 'test/loss': 2.80875825881958, 'test/num_examples': 10000, 'score': 11392.794984817505, 'total_duration': 12161.688700675964, 'accumulated_submission_time': 11392.794984817505, 'accumulated_eval_time': 734.035947561264, 'accumulated_logging_time': 34.34053945541382}
I0425 04:20:57.450778 140010019874560 logging_writer.py:48] [27048] accumulated_eval_time=734.035948, accumulated_logging_time=34.340539, accumulated_submission_time=11392.794985, global_step=27048, preemption_count=0, score=11392.794985, test/accuracy=0.424800, test/loss=2.808758, test/num_examples=10000, total_duration=12161.688701, train/accuracy=0.594160, train/loss=1.935962, validation/accuracy=0.542340, validation/loss=2.166810, validation/num_examples=50000
I0425 04:20:57.560268 140188941555520 checkpoints.py:356] Saving checkpoint at step: 27048
I0425 04:20:58.414720 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_27048
I0425 04:20:58.432423 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_27048.
I0425 04:21:20.379732 140010011481856 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.5492056012153625, loss=4.969675064086914
I0425 04:22:01.749057 140010003089152 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.6559632420539856, loss=4.083344459533691
I0425 04:22:43.917733 140010011481856 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.4949561357498169, loss=5.869559288024902
I0425 04:23:26.013303 140010003089152 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.6902511119842529, loss=4.114100456237793
I0425 04:24:07.720041 140010011481856 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.6673587560653687, loss=4.034783840179443
I0425 04:24:50.118131 140010003089152 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.628995954990387, loss=4.124101638793945
I0425 04:25:31.992874 140010003089152 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.6810295581817627, loss=4.213212013244629
I0425 04:26:13.837512 140010011481856 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.5462667346000671, loss=5.81553840637207
I0425 04:26:55.689551 140010003089152 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.6203627586364746, loss=4.531912326812744
I0425 04:27:36.888540 140188941555520 spec.py:298] Evaluating on the training split.
I0425 04:27:47.657858 140188941555520 spec.py:310] Evaluating on the validation split.
I0425 04:28:00.109545 140188941555520 spec.py:326] Evaluating on the test split.
I0425 04:28:01.754906 140188941555520 submission_runner.py:406] Time since start: 12586.01s, 	Step: 28000, 	{'train/accuracy': 0.6087695360183716, 'train/loss': 1.874358057975769, 'validation/accuracy': 0.5547199845314026, 'validation/loss': 2.1405270099639893, 'validation/num_examples': 50000, 'test/accuracy': 0.4376000165939331, 'test/loss': 2.769239664077759, 'test/num_examples': 10000, 'score': 11791.227755069733, 'total_duration': 12586.011485099792, 'accumulated_submission_time': 11791.227755069733, 'accumulated_eval_time': 758.9010100364685, 'accumulated_logging_time': 35.34624743461609}
I0425 04:28:01.773039 140010011481856 logging_writer.py:48] [28000] accumulated_eval_time=758.901010, accumulated_logging_time=35.346247, accumulated_submission_time=11791.227755, global_step=28000, preemption_count=0, score=11791.227755, test/accuracy=0.437600, test/loss=2.769240, test/num_examples=10000, total_duration=12586.011485, train/accuracy=0.608770, train/loss=1.874358, validation/accuracy=0.554720, validation/loss=2.140527, validation/num_examples=50000
I0425 04:28:01.901500 140188941555520 checkpoints.py:356] Saving checkpoint at step: 28000
I0425 04:28:02.895317 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_28000
I0425 04:28:02.912710 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_28000.
I0425 04:28:02.938938 140010003089152 logging_writer.py:48] [28000] global_step=28000, preemption_count=0, score=11791.227755
I0425 04:28:03.134966 140188941555520 checkpoints.py:356] Saving checkpoint at step: 28000
I0425 04:28:04.117655 140188941555520 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_28000
I0425 04:28:04.131930 140188941555520 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_v3_b/timing_nesterov/imagenet_vit_jax/trial_1/checkpoint_28000.
I0425 04:28:05.062794 140188941555520 submission_runner.py:567] Tuning trial 1/1
I0425 04:28:05.063549 140188941555520 submission_runner.py:568] Hyperparameters: Hyperparameters(learning_rate=0.4394877561366806, one_minus_beta1=0.07113602458522507, warmup_factor=0.05, weight_decay=9.611851572925426e-07, label_smoothing=0.2, dropout_rate=0.0, decay_steps_factor=0.9, end_factor=0.001)
I0425 04:28:05.068541 140188941555520 submission_runner.py:569] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0009960937313735485, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 46.54018259048462, 'total_duration': 96.01651453971863, 'accumulated_submission_time': 46.54018259048462, 'accumulated_eval_time': 49.47616744041443, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (987, {'train/accuracy': 0.0322265625, 'train/loss': 6.083932876586914, 'validation/accuracy': 0.03150000050663948, 'validation/loss': 6.109715938568115, 'validation/num_examples': 50000, 'test/accuracy': 0.025200001895427704, 'test/loss': 6.197531700134277, 'test/num_examples': 10000, 'score': 466.8052730560303, 'total_duration': 536.3479995727539, 'accumulated_submission_time': 466.8052730560303, 'accumulated_eval_time': 68.79713177680969, 'accumulated_logging_time': 0.7254903316497803, 'global_step': 987, 'preemption_count': 0}), (2004, {'train/accuracy': 0.06744140386581421, 'train/loss': 5.538755416870117, 'validation/accuracy': 0.06449999660253525, 'validation/loss': 5.5709710121154785, 'validation/num_examples': 50000, 'test/accuracy': 0.048700001090765, 'test/loss': 5.755987167358398, 'test/num_examples': 10000, 'score': 886.9165542125702, 'total_duration': 977.954642534256, 'accumulated_submission_time': 886.9165542125702, 'accumulated_eval_time': 88.52128434181213, 'accumulated_logging_time': 2.4767982959747314, 'global_step': 2004, 'preemption_count': 0}), (3023, {'train/accuracy': 0.10279296338558197, 'train/loss': 5.1836419105529785, 'validation/accuracy': 0.09386000037193298, 'validation/loss': 5.238406181335449, 'validation/num_examples': 50000, 'test/accuracy': 0.07100000232458115, 'test/loss': 5.4594855308532715, 'test/num_examples': 10000, 'score': 1307.258901834488, 'total_duration': 1420.9848110675812, 'accumulated_submission_time': 1307.258901834488, 'accumulated_eval_time': 108.59562277793884, 'accumulated_logging_time': 5.070218086242676, 'global_step': 3023, 'preemption_count': 0}), (4045, {'train/accuracy': 0.13740234076976776, 'train/loss': 4.837579727172852, 'validation/accuracy': 0.11614000052213669, 'validation/loss': 4.975306510925293, 'validation/num_examples': 50000, 'test/accuracy': 0.08830000460147858, 'test/loss': 5.251297950744629, 'test/num_examples': 10000, 'score': 1727.5673639774323, 'total_duration': 1865.4303455352783, 'accumulated_submission_time': 1727.5673639774323, 'accumulated_eval_time': 129.8786060810089, 'accumulated_logging_time': 7.904304504394531, 'global_step': 4045, 'preemption_count': 0}), (5062, {'train/accuracy': 0.15998046100139618, 'train/loss': 4.654322624206543, 'validation/accuracy': 0.14608000218868256, 'validation/loss': 4.726490020751953, 'validation/num_examples': 50000, 'test/accuracy': 0.11110000312328339, 'test/loss': 5.03836727142334, 'test/num_examples': 10000, 'score': 2147.9539024829865, 'total_duration': 2308.7568957805634, 'accumulated_submission_time': 2147.9539024829865, 'accumulated_eval_time': 151.62768054008484, 'accumulated_logging_time': 9.07567286491394, 'global_step': 5062, 'preemption_count': 0}), (6076, {'train/accuracy': 0.1861913949251175, 'train/loss': 4.414586544036865, 'validation/accuracy': 0.1717199981212616, 'validation/loss': 4.497425079345703, 'validation/num_examples': 50000, 'test/accuracy': 0.12950000166893005, 'test/loss': 4.840025901794434, 'test/num_examples': 10000, 'score': 2568.082721710205, 'total_duration': 2752.801563978195, 'accumulated_submission_time': 2568.082721710205, 'accumulated_eval_time': 174.5450689792633, 'accumulated_logging_time': 10.053825855255127, 'global_step': 6076, 'preemption_count': 0}), (7090, {'train/accuracy': 0.23876953125, 'train/loss': 4.080831050872803, 'validation/accuracy': 0.21621999144554138, 'validation/loss': 4.197323799133301, 'validation/num_examples': 50000, 'test/accuracy': 0.16040000319480896, 'test/loss': 4.601830005645752, 'test/num_examples': 10000, 'score': 2988.2134969234467, 'total_duration': 3197.7616159915924, 'accumulated_submission_time': 2988.2134969234467, 'accumulated_eval_time': 198.51556015014648, 'accumulated_logging_time': 10.892399311065674, 'global_step': 7090, 'preemption_count': 0}), (8101, {'train/accuracy': 0.28369140625, 'train/loss': 3.6669929027557373, 'validation/accuracy': 0.2537800073623657, 'validation/loss': 3.818631887435913, 'validation/num_examples': 50000, 'test/accuracy': 0.1941000074148178, 'test/loss': 4.278420925140381, 'test/num_examples': 10000, 'score': 3408.5996429920197, 'total_duration': 3643.835775613785, 'accumulated_submission_time': 3408.5996429920197, 'accumulated_eval_time': 223.36178183555603, 'accumulated_logging_time': 11.714434623718262, 'global_step': 8101, 'preemption_count': 0}), (9110, {'train/accuracy': 0.3073437511920929, 'train/loss': 3.5522525310516357, 'validation/accuracy': 0.28147998452186584, 'validation/loss': 3.683795213699341, 'validation/num_examples': 50000, 'test/accuracy': 0.2127000093460083, 'test/loss': 4.144068241119385, 'test/num_examples': 10000, 'score': 3828.710543870926, 'total_duration': 4090.9098179340363, 'accumulated_submission_time': 3828.710543870926, 'accumulated_eval_time': 249.3355143070221, 'accumulated_logging_time': 12.684527397155762, 'global_step': 9110, 'preemption_count': 0}), (10119, {'train/accuracy': 0.34486326575279236, 'train/loss': 3.2680375576019287, 'validation/accuracy': 0.3170599937438965, 'validation/loss': 3.4037563800811768, 'validation/num_examples': 50000, 'test/accuracy': 0.24610000848770142, 'test/loss': 3.933549404144287, 'test/num_examples': 10000, 'score': 4249.101299762726, 'total_duration': 4540.3670909404755, 'accumulated_submission_time': 4249.101299762726, 'accumulated_eval_time': 277.44955611228943, 'accumulated_logging_time': 13.617517948150635, 'global_step': 10119, 'preemption_count': 0}), (11128, {'train/accuracy': 0.3642578125, 'train/loss': 3.2387590408325195, 'validation/accuracy': 0.33489999175071716, 'validation/loss': 3.3810369968414307, 'validation/num_examples': 50000, 'test/accuracy': 0.25290000438690186, 'test/loss': 3.9036974906921387, 'test/num_examples': 10000, 'score': 4669.192192316055, 'total_duration': 4987.631262540817, 'accumulated_submission_time': 4669.192192316055, 'accumulated_eval_time': 303.61536407470703, 'accumulated_logging_time': 14.606244802474976, 'global_step': 11128, 'preemption_count': 0}), (12139, {'train/accuracy': 0.3927929699420929, 'train/loss': 3.077559471130371, 'validation/accuracy': 0.3542799949645996, 'validation/loss': 3.2594106197357178, 'validation/num_examples': 50000, 'test/accuracy': 0.27390000224113464, 'test/loss': 3.788681745529175, 'test/num_examples': 10000, 'score': 5089.585218429565, 'total_duration': 5435.006143808365, 'accumulated_submission_time': 5089.585218429565, 'accumulated_eval_time': 329.5887625217438, 'accumulated_logging_time': 15.595468044281006, 'global_step': 12139, 'preemption_count': 0}), (13143, {'train/accuracy': 0.4119921922683716, 'train/loss': 2.9095730781555176, 'validation/accuracy': 0.3752399981021881, 'validation/loss': 3.072901487350464, 'validation/num_examples': 50000, 'test/accuracy': 0.289000004529953, 'test/loss': 3.650526762008667, 'test/num_examples': 10000, 'score': 5509.953811168671, 'total_duration': 5882.69993853569, 'accumulated_submission_time': 5509.953811168671, 'accumulated_eval_time': 356.02735209465027, 'accumulated_logging_time': 16.463306427001953, 'global_step': 13143, 'preemption_count': 0}), (14142, {'train/accuracy': 0.4274023473262787, 'train/loss': 2.8841588497161865, 'validation/accuracy': 0.3940799832344055, 'validation/loss': 3.0327014923095703, 'validation/num_examples': 50000, 'test/accuracy': 0.30320000648498535, 'test/loss': 3.614177942276001, 'test/num_examples': 10000, 'score': 5930.191396951675, 'total_duration': 6330.841212511063, 'accumulated_submission_time': 5930.191396951675, 'accumulated_eval_time': 382.7743353843689, 'accumulated_logging_time': 17.601743936538696, 'global_step': 14142, 'preemption_count': 0}), (15093, {'train/accuracy': 0.4512890577316284, 'train/loss': 2.6843795776367188, 'validation/accuracy': 0.4163999855518341, 'validation/loss': 2.8727974891662598, 'validation/num_examples': 50000, 'test/accuracy': 0.31530001759529114, 'test/loss': 3.4674603939056396, 'test/num_examples': 10000, 'score': 6350.3741755485535, 'total_duration': 6778.5451102256775, 'accumulated_submission_time': 6350.3741755485535, 'accumulated_eval_time': 409.2188220024109, 'accumulated_logging_time': 18.661116123199463, 'global_step': 15093, 'preemption_count': 0}), (16091, {'train/accuracy': 0.47349607944488525, 'train/loss': 2.5890743732452393, 'validation/accuracy': 0.43143999576568604, 'validation/loss': 2.803948163986206, 'validation/num_examples': 50000, 'test/accuracy': 0.33650001883506775, 'test/loss': 3.391716480255127, 'test/num_examples': 10000, 'score': 6770.597817897797, 'total_duration': 7227.116655349731, 'accumulated_submission_time': 6770.597817897797, 'accumulated_eval_time': 436.4650490283966, 'accumulated_logging_time': 19.744170904159546, 'global_step': 16091, 'preemption_count': 0}), (17091, {'train/accuracy': 0.4855664074420929, 'train/loss': 2.469829797744751, 'validation/accuracy': 0.4524399936199188, 'validation/loss': 2.6456897258758545, 'validation/num_examples': 50000, 'test/accuracy': 0.34530001878738403, 'test/loss': 3.2488362789154053, 'test/num_examples': 10000, 'score': 7190.797775268555, 'total_duration': 7675.765034914017, 'accumulated_submission_time': 7190.797775268555, 'accumulated_eval_time': 463.8542513847351, 'accumulated_logging_time': 20.785062789916992, 'global_step': 17091, 'preemption_count': 0}), (18093, {'train/accuracy': 0.5006640553474426, 'train/loss': 2.404042959213257, 'validation/accuracy': 0.4616200029850006, 'validation/loss': 2.5777037143707275, 'validation/num_examples': 50000, 'test/accuracy': 0.3570000231266022, 'test/loss': 3.186311960220337, 'test/num_examples': 10000, 'score': 7610.9108102321625, 'total_duration': 8124.3353972435, 'accumulated_submission_time': 7610.9108102321625, 'accumulated_eval_time': 491.2451066970825, 'accumulated_logging_time': 21.83328652381897, 'global_step': 18093, 'preemption_count': 0}), (19081, {'train/accuracy': 0.5074999928474426, 'train/loss': 2.379533052444458, 'validation/accuracy': 0.4713999927043915, 'validation/loss': 2.5625834465026855, 'validation/num_examples': 50000, 'test/accuracy': 0.3621000051498413, 'test/loss': 3.1780245304107666, 'test/num_examples': 10000, 'score': 8031.074519395828, 'total_duration': 8573.917031764984, 'accumulated_submission_time': 8031.074519395828, 'accumulated_eval_time': 519.4178292751312, 'accumulated_logging_time': 23.060985565185547, 'global_step': 19081, 'preemption_count': 0}), (20080, {'train/accuracy': 0.5354687571525574, 'train/loss': 2.2465405464172363, 'validation/accuracy': 0.48267999291419983, 'validation/loss': 2.491910457611084, 'validation/num_examples': 50000, 'test/accuracy': 0.3726000189781189, 'test/loss': 3.1086034774780273, 'test/num_examples': 10000, 'score': 8451.394375801086, 'total_duration': 9021.78155040741, 'accumulated_submission_time': 8451.394375801086, 'accumulated_eval_time': 545.8773019313812, 'accumulated_logging_time': 24.128031015396118, 'global_step': 20080, 'preemption_count': 0}), (21086, {'train/accuracy': 0.5404882431030273, 'train/loss': 2.2312099933624268, 'validation/accuracy': 0.4932999908924103, 'validation/loss': 2.4684717655181885, 'validation/num_examples': 50000, 'test/accuracy': 0.38050001859664917, 'test/loss': 3.086297035217285, 'test/num_examples': 10000, 'score': 8871.457185983658, 'total_duration': 9473.221551656723, 'accumulated_submission_time': 8871.457185983658, 'accumulated_eval_time': 574.2857191562653, 'accumulated_logging_time': 27.077858448028564, 'global_step': 21086, 'preemption_count': 0}), (22092, {'train/accuracy': 0.5455468893051147, 'train/loss': 2.182596445083618, 'validation/accuracy': 0.5018599629402161, 'validation/loss': 2.373154401779175, 'validation/num_examples': 50000, 'test/accuracy': 0.3968000113964081, 'test/loss': 3.0087385177612305, 'test/num_examples': 10000, 'score': 9291.465188741684, 'total_duration': 9922.242956876755, 'accumulated_submission_time': 9291.465188741684, 'accumulated_eval_time': 602.261144399643, 'accumulated_logging_time': 28.096922874450684, 'global_step': 22092, 'preemption_count': 0}), (23085, {'train/accuracy': 0.5616210699081421, 'train/loss': 2.150580644607544, 'validation/accuracy': 0.5141800045967102, 'validation/loss': 2.369142532348633, 'validation/num_examples': 50000, 'test/accuracy': 0.4004000127315521, 'test/loss': 2.9880428314208984, 'test/num_examples': 10000, 'score': 9711.782388687134, 'total_duration': 10371.101443767548, 'accumulated_submission_time': 9711.782388687134, 'accumulated_eval_time': 629.7926549911499, 'accumulated_logging_time': 29.088724374771118, 'global_step': 23085, 'preemption_count': 0}), (24039, {'train/accuracy': 0.5726757645606995, 'train/loss': 2.1971826553344727, 'validation/accuracy': 0.5177599787712097, 'validation/loss': 2.4432191848754883, 'validation/num_examples': 50000, 'test/accuracy': 0.4003000259399414, 'test/loss': 3.0515408515930176, 'test/num_examples': 10000, 'score': 10132.069001674652, 'total_duration': 10820.231442689896, 'accumulated_submission_time': 10132.069001674652, 'accumulated_eval_time': 656.6273210048676, 'accumulated_logging_time': 31.077441215515137, 'global_step': 24039, 'preemption_count': 0}), (25044, {'train/accuracy': 0.5855273604393005, 'train/loss': 1.972352147102356, 'validation/accuracy': 0.536359965801239, 'validation/loss': 2.2183494567871094, 'validation/num_examples': 50000, 'test/accuracy': 0.4148000180721283, 'test/loss': 2.857422113418579, 'test/num_examples': 10000, 'score': 10552.389263391495, 'total_duration': 11267.964704036713, 'accumulated_submission_time': 10552.389263391495, 'accumulated_eval_time': 682.994678735733, 'accumulated_logging_time': 32.10330367088318, 'global_step': 25044, 'preemption_count': 0}), (26046, {'train/accuracy': 0.5821484327316284, 'train/loss': 2.021918296813965, 'validation/accuracy': 0.5317800045013428, 'validation/loss': 2.24820613861084, 'validation/num_examples': 50000, 'test/accuracy': 0.4155000150203705, 'test/loss': 2.8895366191864014, 'test/num_examples': 10000, 'score': 10972.654935598373, 'total_duration': 11715.618239164352, 'accumulated_submission_time': 10972.654935598373, 'accumulated_eval_time': 709.1936414241791, 'accumulated_logging_time': 33.27214169502258, 'global_step': 26046, 'preemption_count': 0}), (27048, {'train/accuracy': 0.5941601395606995, 'train/loss': 1.9359617233276367, 'validation/accuracy': 0.5423399806022644, 'validation/loss': 2.166809558868408, 'validation/num_examples': 50000, 'test/accuracy': 0.42480000853538513, 'test/loss': 2.80875825881958, 'test/num_examples': 10000, 'score': 11392.794984817505, 'total_duration': 12161.688700675964, 'accumulated_submission_time': 11392.794984817505, 'accumulated_eval_time': 734.035947561264, 'accumulated_logging_time': 34.34053945541382, 'global_step': 27048, 'preemption_count': 0}), (28000, {'train/accuracy': 0.6087695360183716, 'train/loss': 1.874358057975769, 'validation/accuracy': 0.5547199845314026, 'validation/loss': 2.1405270099639893, 'validation/num_examples': 50000, 'test/accuracy': 0.4376000165939331, 'test/loss': 2.769239664077759, 'test/num_examples': 10000, 'score': 11791.227755069733, 'total_duration': 12586.011485099792, 'accumulated_submission_time': 11791.227755069733, 'accumulated_eval_time': 758.9010100364685, 'accumulated_logging_time': 35.34624743461609, 'global_step': 28000, 'preemption_count': 0})], 'global_step': 28000}
I0425 04:28:05.068672 140188941555520 submission_runner.py:570] Timing: 11791.227755069733
I0425 04:28:05.068717 140188941555520 submission_runner.py:571] ====================
I0425 04:28:05.068841 140188941555520 submission_runner.py:631] Final imagenet_vit score: 11791.227755069733
