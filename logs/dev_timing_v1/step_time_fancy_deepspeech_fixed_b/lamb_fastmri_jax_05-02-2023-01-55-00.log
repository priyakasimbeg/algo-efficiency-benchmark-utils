python3 submission_runner.py --framework=jax --workload=fastmri --submission_path=baselines/lamb/jax/submission.py --tuning_search_space=baselines/lamb/tuning_search_space.json --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=timing_fancy_2/timing_lamb --overwrite=True --save_checkpoints=False --max_global_steps=5428 2>&1 | tee -a /logs/fastmri_jax_05-02-2023-01-55-00.log
I0502 01:55:20.119596 140096480905024 logger_utils.py:76] Creating experiment directory at /experiment_runs/timing_fancy_2/timing_lamb/fastmri_jax.
I0502 01:55:20.276011 140096480905024 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0502 01:55:21.154407 140096480905024 xla_bridge.py:345] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0502 01:55:21.155101 140096480905024 xla_bridge.py:345] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0502 01:55:21.159043 140096480905024 submission_runner.py:538] Using RNG seed 4123999171
I0502 01:55:23.773253 140096480905024 submission_runner.py:547] --- Tuning run 1/1 ---
I0502 01:55:23.773443 140096480905024 submission_runner.py:552] Creating tuning directory at /experiment_runs/timing_fancy_2/timing_lamb/fastmri_jax/trial_1.
I0502 01:55:23.773720 140096480905024 logger_utils.py:92] Saving hparams to /experiment_runs/timing_fancy_2/timing_lamb/fastmri_jax/trial_1/hparams.json.
I0502 01:55:23.904482 140096480905024 submission_runner.py:241] Initializing dataset.
I0502 01:55:28.196654 140096480905024 submission_runner.py:248] Initializing model.
I0502 01:55:35.300116 140096480905024 submission_runner.py:258] Initializing optimizer.
I0502 01:55:35.735927 140096480905024 submission_runner.py:265] Initializing metrics bundle.
I0502 01:55:35.736121 140096480905024 submission_runner.py:282] Initializing checkpoint and logger.
I0502 01:55:35.738389 140096480905024 checkpoints.py:466] Found no checkpoint files in /experiment_runs/timing_fancy_2/timing_lamb/fastmri_jax/trial_1 with prefix checkpoint_
I0502 01:55:35.738628 140096480905024 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0502 01:55:35.738691 140096480905024 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0502 01:55:36.716034 140096480905024 submission_runner.py:303] Saving meta data to /experiment_runs/timing_fancy_2/timing_lamb/fastmri_jax/trial_1/meta_data_0.json.
I0502 01:55:36.716943 140096480905024 submission_runner.py:306] Saving flags to /experiment_runs/timing_fancy_2/timing_lamb/fastmri_jax/trial_1/flags_0.json.
I0502 01:55:36.723259 140096480905024 submission_runner.py:318] Starting training loop.
I0502 01:56:42.998024 139920119158528 logging_writer.py:48] [0] global_step=0, grad_norm=5.14007568359375, loss=0.8693246245384216
I0502 01:56:43.008846 140096480905024 spec.py:298] Evaluating on the training split.
I0502 01:58:12.452043 140096480905024 spec.py:310] Evaluating on the validation split.
I0502 01:59:15.751859 140096480905024 spec.py:326] Evaluating on the test split.
I0502 02:00:15.124227 140096480905024 submission_runner.py:415] Time since start: 278.40s, 	Step: 1, 	{'train/ssim': 0.24656886713845388, 'train/loss': 0.8762181827000209, 'validation/ssim': 0.2378361948299891, 'validation/loss': 0.8820438760683385, 'validation/num_examples': 3554, 'test/ssim': 0.26171764212924986, 'test/loss': 0.8802358312534907, 'test/num_examples': 3581, 'score': 66.28544306755066, 'total_duration': 278.40086913108826, 'accumulated_submission_time': 66.28544306755066, 'accumulated_eval_time': 212.1152982711792, 'accumulated_logging_time': 0}
I0502 02:00:15.141705 139891287508736 logging_writer.py:48] [1] accumulated_eval_time=212.115298, accumulated_logging_time=0, accumulated_submission_time=66.285443, global_step=1, preemption_count=0, score=66.285443, test/loss=0.880236, test/num_examples=3581, test/ssim=0.261718, total_duration=278.400869, train/loss=0.876218, train/ssim=0.246569, validation/loss=0.882044, validation/num_examples=3554, validation/ssim=0.237836
I0502 02:00:37.104240 139891279116032 logging_writer.py:48] [100] global_step=100, grad_norm=3.6286466121673584, loss=0.624083399772644
I0502 02:01:00.944260 139891287508736 logging_writer.py:48] [200] global_step=200, grad_norm=0.4584011733531952, loss=0.43101611733436584
I0502 02:01:25.471074 139891279116032 logging_writer.py:48] [300] global_step=300, grad_norm=0.21690836548805237, loss=0.3954409658908844
I0502 02:01:35.424340 140096480905024 spec.py:298] Evaluating on the training split.
I0502 02:01:37.295519 140096480905024 spec.py:310] Evaluating on the validation split.
I0502 02:01:38.645271 140096480905024 spec.py:326] Evaluating on the test split.
I0502 02:01:39.996155 140096480905024 submission_runner.py:415] Time since start: 363.27s, 	Step: 337, 	{'train/ssim': 0.6708760942731585, 'train/loss': 0.3284027576446533, 'validation/ssim': 0.6476729977446187, 'validation/loss': 0.3497098752066334, 'validation/num_examples': 3554, 'test/ssim': 0.6672310103453993, 'test/loss': 0.35090336803616307, 'test/num_examples': 3581, 'score': 146.55475902557373, 'total_duration': 363.2728054523468, 'accumulated_submission_time': 146.55475902557373, 'accumulated_eval_time': 216.6870789527893, 'accumulated_logging_time': 0.026622295379638672}
I0502 02:01:40.008134 139891287508736 logging_writer.py:48] [337] accumulated_eval_time=216.687079, accumulated_logging_time=0.026622, accumulated_submission_time=146.554759, global_step=337, preemption_count=0, score=146.554759, test/loss=0.350903, test/num_examples=3581, test/ssim=0.667231, total_duration=363.272805, train/loss=0.328403, train/ssim=0.670876, validation/loss=0.349710, validation/num_examples=3554, validation/ssim=0.647673
I0502 02:02:01.327444 139891279116032 logging_writer.py:48] [400] global_step=400, grad_norm=0.15003176033496857, loss=0.4026889204978943
I0502 02:02:37.617350 139891287508736 logging_writer.py:48] [500] global_step=500, grad_norm=0.16976496577262878, loss=0.22588303685188293
I0502 02:03:00.028025 140096480905024 spec.py:298] Evaluating on the training split.
I0502 02:03:01.428724 140096480905024 spec.py:310] Evaluating on the validation split.
I0502 02:03:02.780353 140096480905024 spec.py:326] Evaluating on the test split.
I0502 02:03:04.134271 140096480905024 submission_runner.py:415] Time since start: 447.41s, 	Step: 564, 	{'train/ssim': 0.7082386016845703, 'train/loss': 0.30050880568368094, 'validation/ssim': 0.6872200007913618, 'validation/loss': 0.3198664659318725, 'validation/num_examples': 3554, 'test/ssim': 0.7053637852118821, 'test/loss': 0.321866450646642, 'test/num_examples': 3581, 'score': 226.55850481987, 'total_duration': 447.4109306335449, 'accumulated_submission_time': 226.55850481987, 'accumulated_eval_time': 220.7932834625244, 'accumulated_logging_time': 0.05195021629333496}
I0502 02:03:04.145789 139891279116032 logging_writer.py:48] [564] accumulated_eval_time=220.793283, accumulated_logging_time=0.051950, accumulated_submission_time=226.558505, global_step=564, preemption_count=0, score=226.558505, test/loss=0.321866, test/num_examples=3581, test/ssim=0.705364, total_duration=447.410931, train/loss=0.300509, train/ssim=0.708239, validation/loss=0.319866, validation/num_examples=3554, validation/ssim=0.687220
I0502 02:03:14.028162 139891287508736 logging_writer.py:48] [600] global_step=600, grad_norm=0.2611426115036011, loss=0.3683449327945709
I0502 02:03:51.895120 139891279116032 logging_writer.py:48] [700] global_step=700, grad_norm=0.15128125250339508, loss=0.23244553804397583
I0502 02:04:24.264634 140096480905024 spec.py:298] Evaluating on the training split.
I0502 02:04:25.670960 140096480905024 spec.py:310] Evaluating on the validation split.
I0502 02:04:27.019041 140096480905024 spec.py:326] Evaluating on the test split.
I0502 02:04:28.372679 140096480905024 submission_runner.py:415] Time since start: 531.65s, 	Step: 790, 	{'train/ssim': 0.7127879687717983, 'train/loss': 0.29368373325892855, 'validation/ssim': 0.6934073925286649, 'validation/loss': 0.31209016798853406, 'validation/num_examples': 3554, 'test/ssim': 0.7112113656494345, 'test/loss': 0.3140870163274923, 'test/num_examples': 3581, 'score': 306.66207242012024, 'total_duration': 531.649331331253, 'accumulated_submission_time': 306.66207242012024, 'accumulated_eval_time': 224.90127849578857, 'accumulated_logging_time': 0.0760335922241211}
I0502 02:04:28.382687 139891287508736 logging_writer.py:48] [790] accumulated_eval_time=224.901278, accumulated_logging_time=0.076034, accumulated_submission_time=306.662072, global_step=790, preemption_count=0, score=306.662072, test/loss=0.314087, test/num_examples=3581, test/ssim=0.711211, total_duration=531.649331, train/loss=0.293684, train/ssim=0.712788, validation/loss=0.312090, validation/num_examples=3554, validation/ssim=0.693407
I0502 02:04:29.230212 139891279116032 logging_writer.py:48] [800] global_step=800, grad_norm=0.3567648231983185, loss=0.3870033025741577
I0502 02:05:06.929700 139891287508736 logging_writer.py:48] [900] global_step=900, grad_norm=0.1599012017250061, loss=0.364195853471756
I0502 02:05:39.861398 139891279116032 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.1822010725736618, loss=0.32348430156707764
I0502 02:05:48.575488 140096480905024 spec.py:298] Evaluating on the training split.
I0502 02:05:49.980886 140096480905024 spec.py:310] Evaluating on the validation split.
I0502 02:05:51.336398 140096480905024 spec.py:326] Evaluating on the test split.
I0502 02:05:52.690084 140096480905024 submission_runner.py:415] Time since start: 615.97s, 	Step: 1038, 	{'train/ssim': 0.7194576263427734, 'train/loss': 0.2898594651903425, 'validation/ssim': 0.6990968170767093, 'validation/loss': 0.30834033560336943, 'validation/num_examples': 3554, 'test/ssim': 0.7159353947046915, 'test/loss': 0.31104732578408617, 'test/num_examples': 3581, 'score': 386.8413841724396, 'total_duration': 615.9667382240295, 'accumulated_submission_time': 386.8413841724396, 'accumulated_eval_time': 229.01584362983704, 'accumulated_logging_time': 0.09658312797546387}
I0502 02:05:52.698442 139891287508736 logging_writer.py:48] [1038] accumulated_eval_time=229.015844, accumulated_logging_time=0.096583, accumulated_submission_time=386.841384, global_step=1038, preemption_count=0, score=386.841384, test/loss=0.311047, test/num_examples=3581, test/ssim=0.715935, total_duration=615.966738, train/loss=0.289859, train/ssim=0.719458, validation/loss=0.308340, validation/num_examples=3554, validation/ssim=0.699097
I0502 02:06:05.622454 139891279116032 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.16460177302360535, loss=0.2818557024002075
I0502 02:06:29.497234 139891287508736 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.3094511926174164, loss=0.23211947083473206
I0502 02:06:53.328447 139891279116032 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.3084438145160675, loss=0.3205295205116272
I0502 02:07:12.868649 140096480905024 spec.py:298] Evaluating on the training split.
I0502 02:07:14.275633 140096480905024 spec.py:310] Evaluating on the validation split.
I0502 02:07:15.627827 140096480905024 spec.py:326] Evaluating on the test split.
I0502 02:07:16.981511 140096480905024 submission_runner.py:415] Time since start: 700.26s, 	Step: 1382, 	{'train/ssim': 0.7254930223737445, 'train/loss': 0.28323047501700266, 'validation/ssim': 0.7051974475283131, 'validation/loss': 0.3015437601118458, 'validation/num_examples': 3554, 'test/ssim': 0.7226308882819045, 'test/loss': 0.3033638842043947, 'test/num_examples': 3581, 'score': 466.99929189682007, 'total_duration': 700.2581384181976, 'accumulated_submission_time': 466.99929189682007, 'accumulated_eval_time': 233.12864351272583, 'accumulated_logging_time': 0.11276078224182129}
I0502 02:07:16.992473 139891287508736 logging_writer.py:48] [1382] accumulated_eval_time=233.128644, accumulated_logging_time=0.112761, accumulated_submission_time=466.999292, global_step=1382, preemption_count=0, score=466.999292, test/loss=0.303364, test/num_examples=3581, test/ssim=0.722631, total_duration=700.258138, train/loss=0.283230, train/ssim=0.725493, validation/loss=0.301544, validation/num_examples=3554, validation/ssim=0.705197
I0502 02:07:19.324905 139891279116032 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.4585151970386505, loss=0.289733350276947
I0502 02:07:43.199234 139891287508736 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.31330469250679016, loss=0.29310619831085205
I0502 02:08:06.849016 139891279116032 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.2271815985441208, loss=0.24667738378047943
I0502 02:08:30.597561 139891287508736 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.1408694088459015, loss=0.4040002226829529
I0502 02:08:37.137763 140096480905024 spec.py:298] Evaluating on the training split.
I0502 02:08:38.544889 140096480905024 spec.py:310] Evaluating on the validation split.
I0502 02:08:39.896683 140096480905024 spec.py:326] Evaluating on the test split.
I0502 02:08:41.253572 140096480905024 submission_runner.py:415] Time since start: 784.53s, 	Step: 1729, 	{'train/ssim': 0.7280124255589077, 'train/loss': 0.2808577673775809, 'validation/ssim': 0.7072933886114238, 'validation/loss': 0.299122653117526, 'validation/num_examples': 3554, 'test/ssim': 0.7248389258194289, 'test/loss': 0.30076846687595993, 'test/num_examples': 3581, 'score': 547.1316814422607, 'total_duration': 784.5302348136902, 'accumulated_submission_time': 547.1316814422607, 'accumulated_eval_time': 237.24443364143372, 'accumulated_logging_time': 0.13222575187683105}
I0502 02:08:41.261961 139891279116032 logging_writer.py:48] [1729] accumulated_eval_time=237.244434, accumulated_logging_time=0.132226, accumulated_submission_time=547.131681, global_step=1729, preemption_count=0, score=547.131681, test/loss=0.300768, test/num_examples=3581, test/ssim=0.724839, total_duration=784.530235, train/loss=0.280858, train/ssim=0.728012, validation/loss=0.299123, validation/num_examples=3554, validation/ssim=0.707293
I0502 02:08:56.087871 139891287508736 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.09040302783250809, loss=0.2816694974899292
I0502 02:09:19.804909 139891279116032 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.16484075784683228, loss=0.2950260639190674
I0502 02:09:43.811291 139891287508736 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.15305832028388977, loss=0.2630787491798401
I0502 02:10:01.476751 140096480905024 spec.py:298] Evaluating on the training split.
I0502 02:10:02.879489 140096480905024 spec.py:310] Evaluating on the validation split.
I0502 02:10:04.231547 140096480905024 spec.py:326] Evaluating on the test split.
I0502 02:10:05.585461 140096480905024 submission_runner.py:415] Time since start: 868.86s, 	Step: 2075, 	{'train/ssim': 0.7327666282653809, 'train/loss': 0.27903381415775846, 'validation/ssim': 0.712363325214547, 'validation/loss': 0.2970117366105972, 'validation/num_examples': 3554, 'test/ssim': 0.7297127390001047, 'test/loss': 0.2986761933097424, 'test/num_examples': 3581, 'score': 627.3341128826141, 'total_duration': 868.8621211051941, 'accumulated_submission_time': 627.3341128826141, 'accumulated_eval_time': 241.3531153202057, 'accumulated_logging_time': 0.14854812622070312}
I0502 02:10:05.594668 139891279116032 logging_writer.py:48] [2075] accumulated_eval_time=241.353115, accumulated_logging_time=0.148548, accumulated_submission_time=627.334113, global_step=2075, preemption_count=0, score=627.334113, test/loss=0.298676, test/num_examples=3581, test/ssim=0.729713, total_duration=868.862121, train/loss=0.279034, train/ssim=0.732767, validation/loss=0.297012, validation/num_examples=3554, validation/ssim=0.712363
I0502 02:10:09.543360 139891287508736 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.185195654630661, loss=0.3036854863166809
I0502 02:10:33.548269 139891279116032 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.20460110902786255, loss=0.28273940086364746
I0502 02:10:57.282650 139891287508736 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.2622447609901428, loss=0.2683159112930298
I0502 02:11:20.970533 139891279116032 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.3853367567062378, loss=0.22397643327713013
I0502 02:11:25.795983 140096480905024 spec.py:298] Evaluating on the training split.
I0502 02:11:27.206057 140096480905024 spec.py:310] Evaluating on the validation split.
I0502 02:11:28.559097 140096480905024 spec.py:326] Evaluating on the test split.
I0502 02:11:29.913270 140096480905024 submission_runner.py:415] Time since start: 953.19s, 	Step: 2422, 	{'train/ssim': 0.7337854249136788, 'train/loss': 0.27746834073747906, 'validation/ssim': 0.7135217223331106, 'validation/loss': 0.2960021663530529, 'validation/num_examples': 3554, 'test/ssim': 0.7306603264189472, 'test/loss': 0.2976209549423171, 'test/num_examples': 3581, 'score': 707.5232479572296, 'total_duration': 953.1899363994598, 'accumulated_submission_time': 707.5232479572296, 'accumulated_eval_time': 245.47036266326904, 'accumulated_logging_time': 0.16553616523742676}
I0502 02:11:29.922377 139891287508736 logging_writer.py:48] [2422] accumulated_eval_time=245.470363, accumulated_logging_time=0.165536, accumulated_submission_time=707.523248, global_step=2422, preemption_count=0, score=707.523248, test/loss=0.297621, test/num_examples=3581, test/ssim=0.730660, total_duration=953.189936, train/loss=0.277468, train/ssim=0.733785, validation/loss=0.296002, validation/num_examples=3554, validation/ssim=0.713522
I0502 02:11:46.290877 139891279116032 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.11409704387187958, loss=0.28134605288505554
I0502 02:12:09.982351 139891287508736 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.283834844827652, loss=0.2380887269973755
I0502 02:12:33.426930 139891279116032 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.2713230848312378, loss=0.27647268772125244
I0502 02:12:49.969874 140096480905024 spec.py:298] Evaluating on the training split.
I0502 02:12:51.379758 140096480905024 spec.py:310] Evaluating on the validation split.
I0502 02:12:52.736314 140096480905024 spec.py:326] Evaluating on the test split.
I0502 02:12:54.090188 140096480905024 submission_runner.py:415] Time since start: 1037.37s, 	Step: 2771, 	{'train/ssim': 0.735692024230957, 'train/loss': 0.2747684717178345, 'validation/ssim': 0.7148846919843838, 'validation/loss': 0.29343669764701746, 'validation/num_examples': 3554, 'test/ssim': 0.7319949527453924, 'test/loss': 0.29509102129729825, 'test/num_examples': 3581, 'score': 787.5584256649017, 'total_duration': 1037.3668434619904, 'accumulated_submission_time': 787.5584256649017, 'accumulated_eval_time': 249.59062695503235, 'accumulated_logging_time': 0.18254852294921875}
I0502 02:12:54.098758 139891287508736 logging_writer.py:48] [2771] accumulated_eval_time=249.590627, accumulated_logging_time=0.182549, accumulated_submission_time=787.558426, global_step=2771, preemption_count=0, score=787.558426, test/loss=0.295091, test/num_examples=3581, test/ssim=0.731995, total_duration=1037.366843, train/loss=0.274768, train/ssim=0.735692, validation/loss=0.293437, validation/num_examples=3554, validation/ssim=0.714885
I0502 02:12:58.934228 139891279116032 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.19007642567157745, loss=0.23905864357948303
I0502 02:13:22.684950 139891287508736 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.2093057781457901, loss=0.29954826831817627
I0502 02:13:46.279079 139891279116032 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.08108697831630707, loss=0.26068899035453796
I0502 02:14:10.100593 139891287508736 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.1530977189540863, loss=0.2645665109157562
I0502 02:14:14.257451 140096480905024 spec.py:298] Evaluating on the training split.
I0502 02:14:15.667115 140096480905024 spec.py:310] Evaluating on the validation split.
I0502 02:14:17.020114 140096480905024 spec.py:326] Evaluating on the test split.
I0502 02:14:18.374216 140096480905024 submission_runner.py:415] Time since start: 1121.65s, 	Step: 3118, 	{'train/ssim': 0.7381557737077985, 'train/loss': 0.27350805486951557, 'validation/ssim': 0.717561858117614, 'validation/loss': 0.2919727469268782, 'validation/num_examples': 3554, 'test/ssim': 0.734773424410081, 'test/loss': 0.29350509579639067, 'test/num_examples': 3581, 'score': 867.7033286094666, 'total_duration': 1121.6508820056915, 'accumulated_submission_time': 867.7033286094666, 'accumulated_eval_time': 253.70736265182495, 'accumulated_logging_time': 0.20044374465942383}
I0502 02:14:18.382916 139891279116032 logging_writer.py:48] [3118] accumulated_eval_time=253.707363, accumulated_logging_time=0.200444, accumulated_submission_time=867.703329, global_step=3118, preemption_count=0, score=867.703329, test/loss=0.293505, test/num_examples=3581, test/ssim=0.734773, total_duration=1121.650882, train/loss=0.273508, train/ssim=0.738156, validation/loss=0.291973, validation/num_examples=3554, validation/ssim=0.717562
I0502 02:14:35.719866 139891287508736 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.08768274635076523, loss=0.2767329514026642
I0502 02:14:59.691154 139891279116032 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.14970198273658752, loss=0.3503258228302002
I0502 02:15:23.476106 139891287508736 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.16012653708457947, loss=0.27592718601226807
I0502 02:15:38.571774 140096480905024 spec.py:298] Evaluating on the training split.
I0502 02:15:39.978601 140096480905024 spec.py:310] Evaluating on the validation split.
I0502 02:15:41.329905 140096480905024 spec.py:326] Evaluating on the test split.
I0502 02:15:42.683931 140096480905024 submission_runner.py:415] Time since start: 1205.96s, 	Step: 3465, 	{'train/ssim': 0.7383127893720355, 'train/loss': 0.272965601512364, 'validation/ssim': 0.7170878653453855, 'validation/loss': 0.2921170399439892, 'validation/num_examples': 3554, 'test/ssim': 0.7341408813442474, 'test/loss': 0.2937979145577353, 'test/num_examples': 3581, 'score': 947.8799698352814, 'total_duration': 1205.9605913162231, 'accumulated_submission_time': 947.8799698352814, 'accumulated_eval_time': 257.8194839954376, 'accumulated_logging_time': 0.2169644832611084}
I0502 02:15:42.692660 139891279116032 logging_writer.py:48] [3465] accumulated_eval_time=257.819484, accumulated_logging_time=0.216964, accumulated_submission_time=947.879970, global_step=3465, preemption_count=0, score=947.879970, test/loss=0.293798, test/num_examples=3581, test/ssim=0.734141, total_duration=1205.960591, train/loss=0.272966, train/ssim=0.738313, validation/loss=0.292117, validation/num_examples=3554, validation/ssim=0.717088
I0502 02:15:48.939571 139891287508736 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.21323470771312714, loss=0.350600928068161
I0502 02:16:12.596263 139891279116032 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.11879824101924896, loss=0.2924323081970215
I0502 02:16:36.405251 139891287508736 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.15629982948303223, loss=0.22296816110610962
I0502 02:17:00.427182 139891279116032 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.12324375659227371, loss=0.2770693600177765
I0502 02:17:02.865936 140096480905024 spec.py:298] Evaluating on the training split.
I0502 02:17:04.271086 140096480905024 spec.py:310] Evaluating on the validation split.
I0502 02:17:05.627576 140096480905024 spec.py:326] Evaluating on the test split.
I0502 02:17:06.980487 140096480905024 submission_runner.py:415] Time since start: 1290.26s, 	Step: 3811, 	{'train/ssim': 0.7382136753627232, 'train/loss': 0.27263624327523367, 'validation/ssim': 0.7175094441342501, 'validation/loss': 0.2913319293072067, 'validation/num_examples': 3554, 'test/ssim': 0.7347461537454621, 'test/loss': 0.2928568380100705, 'test/num_examples': 3581, 'score': 1028.0407388210297, 'total_duration': 1290.2571499347687, 'accumulated_submission_time': 1028.0407388210297, 'accumulated_eval_time': 261.934002161026, 'accumulated_logging_time': 0.2337958812713623}
I0502 02:17:06.989120 139891287508736 logging_writer.py:48] [3811] accumulated_eval_time=261.934002, accumulated_logging_time=0.233796, accumulated_submission_time=1028.040739, global_step=3811, preemption_count=0, score=1028.040739, test/loss=0.292857, test/num_examples=3581, test/ssim=0.734746, total_duration=1290.257150, train/loss=0.272636, train/ssim=0.738214, validation/loss=0.291332, validation/num_examples=3554, validation/ssim=0.717509
I0502 02:17:25.939893 139891279116032 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.09980367124080658, loss=0.24832849204540253
I0502 02:17:49.800391 139891287508736 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.1668965369462967, loss=0.24999794363975525
I0502 02:18:13.456062 139891279116032 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.13220374286174774, loss=0.2851355969905853
I0502 02:18:27.101702 140096480905024 spec.py:298] Evaluating on the training split.
I0502 02:18:28.510750 140096480905024 spec.py:310] Evaluating on the validation split.
I0502 02:18:29.864449 140096480905024 spec.py:326] Evaluating on the test split.
I0502 02:18:31.216919 140096480905024 submission_runner.py:415] Time since start: 1374.49s, 	Step: 4158, 	{'train/ssim': 0.7386917386736188, 'train/loss': 0.2720444883619036, 'validation/ssim': 0.717972514464336, 'validation/loss': 0.2907838150565384, 'validation/num_examples': 3554, 'test/ssim': 0.7351556227747138, 'test/loss': 0.2922634965246265, 'test/num_examples': 3581, 'score': 1108.1409313678741, 'total_duration': 1374.4935836791992, 'accumulated_submission_time': 1108.1409313678741, 'accumulated_eval_time': 266.0491807460785, 'accumulated_logging_time': 0.2504701614379883}
I0502 02:18:31.225883 139891287508736 logging_writer.py:48] [4158] accumulated_eval_time=266.049181, accumulated_logging_time=0.250470, accumulated_submission_time=1108.140931, global_step=4158, preemption_count=0, score=1108.140931, test/loss=0.292263, test/num_examples=3581, test/ssim=0.735156, total_duration=1374.493584, train/loss=0.272044, train/ssim=0.738692, validation/loss=0.290784, validation/num_examples=3554, validation/ssim=0.717973
I0502 02:18:39.534383 139891279116032 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.21625399589538574, loss=0.2342381477355957
I0502 02:19:03.151537 139891287508736 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.12610489130020142, loss=0.2477709800004959
I0502 02:19:26.980050 139891279116032 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.14275877177715302, loss=0.3259755074977875
I0502 02:19:50.544037 139891287508736 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.1586887091398239, loss=0.25392621755599976
I0502 02:19:51.492791 140096480905024 spec.py:298] Evaluating on the training split.
I0502 02:19:52.901383 140096480905024 spec.py:310] Evaluating on the validation split.
I0502 02:19:54.256080 140096480905024 spec.py:326] Evaluating on the test split.
I0502 02:19:55.608070 140096480905024 submission_runner.py:415] Time since start: 1458.88s, 	Step: 4505, 	{'train/ssim': 0.7411651611328125, 'train/loss': 0.2717025450297764, 'validation/ssim': 0.7198084464687676, 'validation/loss': 0.2907734078239308, 'validation/num_examples': 3554, 'test/ssim': 0.7369439647837546, 'test/loss': 0.2922905285709299, 'test/num_examples': 3581, 'score': 1188.394892692566, 'total_duration': 1458.8847167491913, 'accumulated_submission_time': 1188.394892692566, 'accumulated_eval_time': 270.164404630661, 'accumulated_logging_time': 0.267988920211792}
I0502 02:19:55.617596 139891279116032 logging_writer.py:48] [4505] accumulated_eval_time=270.164405, accumulated_logging_time=0.267989, accumulated_submission_time=1188.394893, global_step=4505, preemption_count=0, score=1188.394893, test/loss=0.292291, test/num_examples=3581, test/ssim=0.736944, total_duration=1458.884717, train/loss=0.271703, train/ssim=0.741165, validation/loss=0.290773, validation/num_examples=3554, validation/ssim=0.719808
I0502 02:20:16.243943 139891287508736 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.09224262833595276, loss=0.2614121735095978
I0502 02:20:39.792363 139891279116032 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.09626248478889465, loss=0.2565150260925293
I0502 02:21:03.481667 139891287508736 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.06879179924726486, loss=0.23423893749713898
I0502 02:21:15.772026 140096480905024 spec.py:298] Evaluating on the training split.
I0502 02:21:17.182576 140096480905024 spec.py:310] Evaluating on the validation split.
I0502 02:21:18.538725 140096480905024 spec.py:326] Evaluating on the test split.
I0502 02:21:19.891884 140096480905024 submission_runner.py:415] Time since start: 1543.17s, 	Step: 4853, 	{'train/ssim': 0.7385628564017159, 'train/loss': 0.2712897743497576, 'validation/ssim': 0.7181334659230796, 'validation/loss': 0.28997167309281796, 'validation/num_examples': 3554, 'test/ssim': 0.7352340941121545, 'test/loss': 0.29152020047210975, 'test/num_examples': 3581, 'score': 1268.5371408462524, 'total_duration': 1543.1685481071472, 'accumulated_submission_time': 1268.5371408462524, 'accumulated_eval_time': 274.2842457294464, 'accumulated_logging_time': 0.28524303436279297}
I0502 02:21:19.900828 139891279116032 logging_writer.py:48] [4853] accumulated_eval_time=274.284246, accumulated_logging_time=0.285243, accumulated_submission_time=1268.537141, global_step=4853, preemption_count=0, score=1268.537141, test/loss=0.291520, test/num_examples=3581, test/ssim=0.735234, total_duration=1543.168548, train/loss=0.271290, train/ssim=0.738563, validation/loss=0.289972, validation/num_examples=3554, validation/ssim=0.718133
I0502 02:21:28.933907 139891287508736 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.09431291371583939, loss=0.3828989565372467
I0502 02:21:52.502720 139891279116032 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.114601269364357, loss=0.28982430696487427
I0502 02:22:16.214084 139891287508736 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.11460309475660324, loss=0.22715803980827332
I0502 02:22:39.740957 139891279116032 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.29649096727371216, loss=0.23337724804878235
I0502 02:22:39.948538 140096480905024 spec.py:298] Evaluating on the training split.
I0502 02:22:41.354743 140096480905024 spec.py:310] Evaluating on the validation split.
I0502 02:22:42.707060 140096480905024 spec.py:326] Evaluating on the test split.
I0502 02:22:44.061475 140096480905024 submission_runner.py:415] Time since start: 1627.34s, 	Step: 5202, 	{'train/ssim': 0.7359694072178432, 'train/loss': 0.2727207456316267, 'validation/ssim': 0.7162930000747397, 'validation/loss': 0.2909897271340391, 'validation/num_examples': 3554, 'test/ssim': 0.7335697654504677, 'test/loss': 0.2923361728458357, 'test/num_examples': 3581, 'score': 1348.571353673935, 'total_duration': 1627.3381361961365, 'accumulated_submission_time': 1348.571353673935, 'accumulated_eval_time': 278.3971393108368, 'accumulated_logging_time': 0.30319714546203613}
I0502 02:22:44.070233 139891287508736 logging_writer.py:48] [5202] accumulated_eval_time=278.397139, accumulated_logging_time=0.303197, accumulated_submission_time=1348.571354, global_step=5202, preemption_count=0, score=1348.571354, test/loss=0.292336, test/num_examples=3581, test/ssim=0.733570, total_duration=1627.338136, train/loss=0.272721, train/ssim=0.735969, validation/loss=0.290990, validation/num_examples=3554, validation/ssim=0.716293
I0502 02:23:05.838263 139891279116032 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.1395782232284546, loss=0.22576674818992615
I0502 02:23:29.380989 139891287508736 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.08534279465675354, loss=0.37326323986053467
I0502 02:23:35.895358 140096480905024 spec.py:298] Evaluating on the training split.
I0502 02:23:37.302958 140096480905024 spec.py:310] Evaluating on the validation split.
I0502 02:23:38.657200 140096480905024 spec.py:326] Evaluating on the test split.
I0502 02:23:40.011696 140096480905024 submission_runner.py:415] Time since start: 1683.29s, 	Step: 5428, 	{'train/ssim': 0.7419264657156808, 'train/loss': 0.2704759495598929, 'validation/ssim': 0.721031347821117, 'validation/loss': 0.2893194521687711, 'validation/num_examples': 3554, 'test/ssim': 0.7381033770900237, 'test/loss': 0.29087405616229756, 'test/num_examples': 3581, 'score': 1400.3847150802612, 'total_duration': 1683.2883462905884, 'accumulated_submission_time': 1400.3847150802612, 'accumulated_eval_time': 282.5134370326996, 'accumulated_logging_time': 0.3207216262817383}
I0502 02:23:40.020692 139891279116032 logging_writer.py:48] [5428] accumulated_eval_time=282.513437, accumulated_logging_time=0.320722, accumulated_submission_time=1400.384715, global_step=5428, preemption_count=0, score=1400.384715, test/loss=0.290874, test/num_examples=3581, test/ssim=0.738103, total_duration=1683.288346, train/loss=0.270476, train/ssim=0.741926, validation/loss=0.289319, validation/num_examples=3554, validation/ssim=0.721031
I0502 02:23:40.034499 139891287508736 logging_writer.py:48] [5428] global_step=5428, preemption_count=0, score=1400.384715
I0502 02:23:40.067134 140096480905024 checkpoints.py:356] Saving checkpoint at step: 5428
I0502 02:23:40.305727 140096480905024 checkpoints.py:317] Saved checkpoint at /experiment_runs/timing_fancy_2/timing_lamb/fastmri_jax/trial_1/checkpoint_5428
I0502 02:23:40.306303 140096480905024 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_fancy_2/timing_lamb/fastmri_jax/trial_1/checkpoint_5428.
I0502 02:23:41.117429 140096480905024 submission_runner.py:578] Tuning trial 1/1
I0502 02:23:41.117666 140096480905024 submission_runner.py:579] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.19395352613343847, beta2=0.999, warmup_factor=0.05, weight_decay=0.002578922011395245, label_smoothing=0.1, dropout_rate=0.0)
I0502 02:23:41.122971 140096480905024 submission_runner.py:580] Metrics: {'eval_results': [(1, {'train/ssim': 0.24656886713845388, 'train/loss': 0.8762181827000209, 'validation/ssim': 0.2378361948299891, 'validation/loss': 0.8820438760683385, 'validation/num_examples': 3554, 'test/ssim': 0.26171764212924986, 'test/loss': 0.8802358312534907, 'test/num_examples': 3581, 'score': 66.28544306755066, 'total_duration': 278.40086913108826, 'accumulated_submission_time': 66.28544306755066, 'accumulated_eval_time': 212.1152982711792, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (337, {'train/ssim': 0.6708760942731585, 'train/loss': 0.3284027576446533, 'validation/ssim': 0.6476729977446187, 'validation/loss': 0.3497098752066334, 'validation/num_examples': 3554, 'test/ssim': 0.6672310103453993, 'test/loss': 0.35090336803616307, 'test/num_examples': 3581, 'score': 146.55475902557373, 'total_duration': 363.2728054523468, 'accumulated_submission_time': 146.55475902557373, 'accumulated_eval_time': 216.6870789527893, 'accumulated_logging_time': 0.026622295379638672, 'global_step': 337, 'preemption_count': 0}), (564, {'train/ssim': 0.7082386016845703, 'train/loss': 0.30050880568368094, 'validation/ssim': 0.6872200007913618, 'validation/loss': 0.3198664659318725, 'validation/num_examples': 3554, 'test/ssim': 0.7053637852118821, 'test/loss': 0.321866450646642, 'test/num_examples': 3581, 'score': 226.55850481987, 'total_duration': 447.4109306335449, 'accumulated_submission_time': 226.55850481987, 'accumulated_eval_time': 220.7932834625244, 'accumulated_logging_time': 0.05195021629333496, 'global_step': 564, 'preemption_count': 0}), (790, {'train/ssim': 0.7127879687717983, 'train/loss': 0.29368373325892855, 'validation/ssim': 0.6934073925286649, 'validation/loss': 0.31209016798853406, 'validation/num_examples': 3554, 'test/ssim': 0.7112113656494345, 'test/loss': 0.3140870163274923, 'test/num_examples': 3581, 'score': 306.66207242012024, 'total_duration': 531.649331331253, 'accumulated_submission_time': 306.66207242012024, 'accumulated_eval_time': 224.90127849578857, 'accumulated_logging_time': 0.0760335922241211, 'global_step': 790, 'preemption_count': 0}), (1038, {'train/ssim': 0.7194576263427734, 'train/loss': 0.2898594651903425, 'validation/ssim': 0.6990968170767093, 'validation/loss': 0.30834033560336943, 'validation/num_examples': 3554, 'test/ssim': 0.7159353947046915, 'test/loss': 0.31104732578408617, 'test/num_examples': 3581, 'score': 386.8413841724396, 'total_duration': 615.9667382240295, 'accumulated_submission_time': 386.8413841724396, 'accumulated_eval_time': 229.01584362983704, 'accumulated_logging_time': 0.09658312797546387, 'global_step': 1038, 'preemption_count': 0}), (1382, {'train/ssim': 0.7254930223737445, 'train/loss': 0.28323047501700266, 'validation/ssim': 0.7051974475283131, 'validation/loss': 0.3015437601118458, 'validation/num_examples': 3554, 'test/ssim': 0.7226308882819045, 'test/loss': 0.3033638842043947, 'test/num_examples': 3581, 'score': 466.99929189682007, 'total_duration': 700.2581384181976, 'accumulated_submission_time': 466.99929189682007, 'accumulated_eval_time': 233.12864351272583, 'accumulated_logging_time': 0.11276078224182129, 'global_step': 1382, 'preemption_count': 0}), (1729, {'train/ssim': 0.7280124255589077, 'train/loss': 0.2808577673775809, 'validation/ssim': 0.7072933886114238, 'validation/loss': 0.299122653117526, 'validation/num_examples': 3554, 'test/ssim': 0.7248389258194289, 'test/loss': 0.30076846687595993, 'test/num_examples': 3581, 'score': 547.1316814422607, 'total_duration': 784.5302348136902, 'accumulated_submission_time': 547.1316814422607, 'accumulated_eval_time': 237.24443364143372, 'accumulated_logging_time': 0.13222575187683105, 'global_step': 1729, 'preemption_count': 0}), (2075, {'train/ssim': 0.7327666282653809, 'train/loss': 0.27903381415775846, 'validation/ssim': 0.712363325214547, 'validation/loss': 0.2970117366105972, 'validation/num_examples': 3554, 'test/ssim': 0.7297127390001047, 'test/loss': 0.2986761933097424, 'test/num_examples': 3581, 'score': 627.3341128826141, 'total_duration': 868.8621211051941, 'accumulated_submission_time': 627.3341128826141, 'accumulated_eval_time': 241.3531153202057, 'accumulated_logging_time': 0.14854812622070312, 'global_step': 2075, 'preemption_count': 0}), (2422, {'train/ssim': 0.7337854249136788, 'train/loss': 0.27746834073747906, 'validation/ssim': 0.7135217223331106, 'validation/loss': 0.2960021663530529, 'validation/num_examples': 3554, 'test/ssim': 0.7306603264189472, 'test/loss': 0.2976209549423171, 'test/num_examples': 3581, 'score': 707.5232479572296, 'total_duration': 953.1899363994598, 'accumulated_submission_time': 707.5232479572296, 'accumulated_eval_time': 245.47036266326904, 'accumulated_logging_time': 0.16553616523742676, 'global_step': 2422, 'preemption_count': 0}), (2771, {'train/ssim': 0.735692024230957, 'train/loss': 0.2747684717178345, 'validation/ssim': 0.7148846919843838, 'validation/loss': 0.29343669764701746, 'validation/num_examples': 3554, 'test/ssim': 0.7319949527453924, 'test/loss': 0.29509102129729825, 'test/num_examples': 3581, 'score': 787.5584256649017, 'total_duration': 1037.3668434619904, 'accumulated_submission_time': 787.5584256649017, 'accumulated_eval_time': 249.59062695503235, 'accumulated_logging_time': 0.18254852294921875, 'global_step': 2771, 'preemption_count': 0}), (3118, {'train/ssim': 0.7381557737077985, 'train/loss': 0.27350805486951557, 'validation/ssim': 0.717561858117614, 'validation/loss': 0.2919727469268782, 'validation/num_examples': 3554, 'test/ssim': 0.734773424410081, 'test/loss': 0.29350509579639067, 'test/num_examples': 3581, 'score': 867.7033286094666, 'total_duration': 1121.6508820056915, 'accumulated_submission_time': 867.7033286094666, 'accumulated_eval_time': 253.70736265182495, 'accumulated_logging_time': 0.20044374465942383, 'global_step': 3118, 'preemption_count': 0}), (3465, {'train/ssim': 0.7383127893720355, 'train/loss': 0.272965601512364, 'validation/ssim': 0.7170878653453855, 'validation/loss': 0.2921170399439892, 'validation/num_examples': 3554, 'test/ssim': 0.7341408813442474, 'test/loss': 0.2937979145577353, 'test/num_examples': 3581, 'score': 947.8799698352814, 'total_duration': 1205.9605913162231, 'accumulated_submission_time': 947.8799698352814, 'accumulated_eval_time': 257.8194839954376, 'accumulated_logging_time': 0.2169644832611084, 'global_step': 3465, 'preemption_count': 0}), (3811, {'train/ssim': 0.7382136753627232, 'train/loss': 0.27263624327523367, 'validation/ssim': 0.7175094441342501, 'validation/loss': 0.2913319293072067, 'validation/num_examples': 3554, 'test/ssim': 0.7347461537454621, 'test/loss': 0.2928568380100705, 'test/num_examples': 3581, 'score': 1028.0407388210297, 'total_duration': 1290.2571499347687, 'accumulated_submission_time': 1028.0407388210297, 'accumulated_eval_time': 261.934002161026, 'accumulated_logging_time': 0.2337958812713623, 'global_step': 3811, 'preemption_count': 0}), (4158, {'train/ssim': 0.7386917386736188, 'train/loss': 0.2720444883619036, 'validation/ssim': 0.717972514464336, 'validation/loss': 0.2907838150565384, 'validation/num_examples': 3554, 'test/ssim': 0.7351556227747138, 'test/loss': 0.2922634965246265, 'test/num_examples': 3581, 'score': 1108.1409313678741, 'total_duration': 1374.4935836791992, 'accumulated_submission_time': 1108.1409313678741, 'accumulated_eval_time': 266.0491807460785, 'accumulated_logging_time': 0.2504701614379883, 'global_step': 4158, 'preemption_count': 0}), (4505, {'train/ssim': 0.7411651611328125, 'train/loss': 0.2717025450297764, 'validation/ssim': 0.7198084464687676, 'validation/loss': 0.2907734078239308, 'validation/num_examples': 3554, 'test/ssim': 0.7369439647837546, 'test/loss': 0.2922905285709299, 'test/num_examples': 3581, 'score': 1188.394892692566, 'total_duration': 1458.8847167491913, 'accumulated_submission_time': 1188.394892692566, 'accumulated_eval_time': 270.164404630661, 'accumulated_logging_time': 0.267988920211792, 'global_step': 4505, 'preemption_count': 0}), (4853, {'train/ssim': 0.7385628564017159, 'train/loss': 0.2712897743497576, 'validation/ssim': 0.7181334659230796, 'validation/loss': 0.28997167309281796, 'validation/num_examples': 3554, 'test/ssim': 0.7352340941121545, 'test/loss': 0.29152020047210975, 'test/num_examples': 3581, 'score': 1268.5371408462524, 'total_duration': 1543.1685481071472, 'accumulated_submission_time': 1268.5371408462524, 'accumulated_eval_time': 274.2842457294464, 'accumulated_logging_time': 0.28524303436279297, 'global_step': 4853, 'preemption_count': 0}), (5202, {'train/ssim': 0.7359694072178432, 'train/loss': 0.2727207456316267, 'validation/ssim': 0.7162930000747397, 'validation/loss': 0.2909897271340391, 'validation/num_examples': 3554, 'test/ssim': 0.7335697654504677, 'test/loss': 0.2923361728458357, 'test/num_examples': 3581, 'score': 1348.571353673935, 'total_duration': 1627.3381361961365, 'accumulated_submission_time': 1348.571353673935, 'accumulated_eval_time': 278.3971393108368, 'accumulated_logging_time': 0.30319714546203613, 'global_step': 5202, 'preemption_count': 0}), (5428, {'train/ssim': 0.7419264657156808, 'train/loss': 0.2704759495598929, 'validation/ssim': 0.721031347821117, 'validation/loss': 0.2893194521687711, 'validation/num_examples': 3554, 'test/ssim': 0.7381033770900237, 'test/loss': 0.29087405616229756, 'test/num_examples': 3581, 'score': 1400.3847150802612, 'total_duration': 1683.2883462905884, 'accumulated_submission_time': 1400.3847150802612, 'accumulated_eval_time': 282.5134370326996, 'accumulated_logging_time': 0.3207216262817383, 'global_step': 5428, 'preemption_count': 0})], 'global_step': 5428}
I0502 02:23:41.123115 140096480905024 submission_runner.py:581] Timing: 1400.3847150802612
I0502 02:23:41.123160 140096480905024 submission_runner.py:582] ====================
I0502 02:23:41.123269 140096480905024 submission_runner.py:645] Final fastmri score: 1400.3847150802612
