torchrun --redirects 1:0,2:0,3:0,4:0,5:0,6:0,7:0 --standalone --nnodes=1 --nproc_per_node=8 submission_runner.py --framework=pytorch --workload=fastmri --submission_path=baselines/adamw/pytorch/submission.py --tuning_search_space=baselines/adamw/tuning_search_space.json --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=test_today/adamw --overwrite=True --save_checkpoints=False --max_global_steps=10 2>&1 | tee -a /logs/fastmri_pytorch_06-29-2023-17-21-35.log
master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-06-29 17:21:44.457898: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 17:21:44.457966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 17:21:44.457962: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 17:21:44.457965: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 17:21:44.457963: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 17:21:44.457967: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 17:21:44.457968: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-06-29 17:21:44.457968: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0629 17:21:59.178463 139705867302720 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
I0629 17:21:59.178500 140285658044224 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 6
I0629 17:21:59.178519 140645365126976 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
I0629 17:21:59.179754 140644574246720 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 5
I0629 17:21:59.179775 139816542635840 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 7
I0629 17:21:59.180244 140583111255872 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 4
I0629 17:22:00.161143 140588922275648 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
I0629 17:22:00.169437 139693899548480 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
I0629 17:22:00.169708 139693899548480 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 17:22:00.171774 140588922275648 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 17:22:00.178364 139705867302720 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 17:22:00.178474 140285658044224 distributed_c10d.py:476] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 17:22:00.178426 139816542635840 distributed_c10d.py:476] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 17:22:00.178500 140645365126976 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 17:22:00.178450 140644574246720 distributed_c10d.py:476] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 17:22:00.178541 140583111255872 distributed_c10d.py:476] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0629 17:22:00.489173 139693899548480 logger_utils.py:61] Removing existing experiment directory /experiment_runs/test_today/adamw/fastmri_pytorch because --overwrite was set.
I0629 17:22:00.491218 139693899548480 logger_utils.py:76] Creating experiment directory at /experiment_runs/test_today/adamw/fastmri_pytorch.
W0629 17:22:00.528711 139705867302720 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0629 17:22:00.528745 140644574246720 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0629 17:22:00.528830 140285658044224 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0629 17:22:00.529583 139816542635840 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0629 17:22:00.529822 140645365126976 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0629 17:22:00.529924 139693899548480 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0629 17:22:00.530373 140583111255872 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0629 17:22:00.531433 140588922275648 xla_bridge.py:463] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0629 17:22:00.534719 139693899548480 submission_runner.py:547] Using RNG seed 1492349683
I0629 17:22:00.536076 139693899548480 submission_runner.py:556] --- Tuning run 1/1 ---
I0629 17:22:00.536179 139693899548480 submission_runner.py:561] Creating tuning directory at /experiment_runs/test_today/adamw/fastmri_pytorch/trial_1.
I0629 17:22:00.536865 139693899548480 logger_utils.py:92] Saving hparams to /experiment_runs/test_today/adamw/fastmri_pytorch/trial_1/hparams.json.
I0629 17:22:00.537631 139693899548480 submission_runner.py:249] Initializing dataset.
I0629 17:22:00.537735 139693899548480 submission_runner.py:256] Initializing model.
I0629 17:22:04.782453 139693899548480 submission_runner.py:268] Initializing optimizer.
I0629 17:22:04.783469 139693899548480 submission_runner.py:275] Initializing metrics bundle.
I0629 17:22:04.783599 139693899548480 submission_runner.py:292] Initializing checkpoint and logger.
I0629 17:22:04.784579 139693899548480 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0629 17:22:04.784692 139693899548480 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0629 17:22:05.283142 139693899548480 submission_runner.py:313] Saving meta data to /experiment_runs/test_today/adamw/fastmri_pytorch/trial_1/meta_data_0.json.
I0629 17:22:05.284182 139693899548480 submission_runner.py:316] Saving flags to /experiment_runs/test_today/adamw/fastmri_pytorch/trial_1/flags_0.json.
I0629 17:22:05.371840 139693899548480 submission_runner.py:328] Starting training loop.
I0629 17:22:39.471479 139652623226624 logging_writer.py:48] [0] global_step=0, grad_norm=4.364724, loss=0.917612
I0629 17:22:39.483586 139693899548480 submission.py:119] 0) loss = 0.918, grad_norm = 4.365
I0629 17:22:39.499207 139693899548480 spec.py:298] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0629 17:23:58.905581 139693899548480 spec.py:310] Evaluating on the validation split.
I0629 17:24:40.222370 139693899548480 spec.py:326] Evaluating on the test split.
I0629 17:25:22.453355 139693899548480 submission_runner.py:424] Time since start: 197.08s, 	Step: 1, 	{'train/ssim': 0.20067313739231654, 'train/loss': 0.9397052356175014, 'validation/ssim': 0.1955551980383019, 'validation/loss': 0.9456622929269837, 'validation/num_examples': 3554, 'test/ssim': 0.21677013270450818, 'test/loss': 0.9434656624153519, 'test/num_examples': 3581, 'score': 34.12665152549744, 'total_duration': 197.08205032348633, 'accumulated_submission_time': 34.12665152549744, 'accumulated_eval_time': 162.95408034324646, 'accumulated_logging_time': 0}
I0629 17:25:22.468685 139630703789824 logging_writer.py:48] [1] accumulated_eval_time=162.954080, accumulated_logging_time=0, accumulated_submission_time=34.126652, global_step=1, preemption_count=0, score=34.126652, test/loss=0.943466, test/num_examples=3581, test/ssim=0.216770, total_duration=197.082050, train/loss=0.939705, train/ssim=0.200673, validation/loss=0.945662, validation/num_examples=3554, validation/ssim=0.195555
I0629 17:25:22.494733 140645365126976 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 17:25:22.494774 139693899548480 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 17:25:22.494756 139705867302720 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 17:25:22.494842 140285658044224 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 17:25:22.494867 140588922275648 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 17:25:22.494915 140644574246720 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 17:25:22.494934 139816542635840 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 17:25:22.494967 140583111255872 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I0629 17:25:22.579600 139630695397120 logging_writer.py:48] [1] global_step=1, grad_norm=4.478853, loss=0.919713
I0629 17:25:22.587122 139693899548480 submission.py:119] 1) loss = 0.920, grad_norm = 4.479
I0629 17:25:22.662361 139630703789824 logging_writer.py:48] [2] global_step=2, grad_norm=4.378720, loss=0.913199
I0629 17:25:22.667317 139693899548480 submission.py:119] 2) loss = 0.913, grad_norm = 4.379
I0629 17:25:22.750164 139630695397120 logging_writer.py:48] [3] global_step=3, grad_norm=3.961647, loss=0.867907
I0629 17:25:22.756632 139693899548480 submission.py:119] 3) loss = 0.868, grad_norm = 3.962
I0629 17:25:22.823832 139630703789824 logging_writer.py:48] [4] global_step=4, grad_norm=4.584695, loss=0.910597
I0629 17:25:22.827696 139693899548480 submission.py:119] 4) loss = 0.911, grad_norm = 4.585
I0629 17:25:22.896728 139630695397120 logging_writer.py:48] [5] global_step=5, grad_norm=4.215813, loss=0.896325
I0629 17:25:22.902294 139693899548480 submission.py:119] 5) loss = 0.896, grad_norm = 4.216
I0629 17:25:22.973624 139630703789824 logging_writer.py:48] [6] global_step=6, grad_norm=3.533180, loss=0.902650
I0629 17:25:22.979546 139693899548480 submission.py:119] 6) loss = 0.903, grad_norm = 3.533
I0629 17:25:23.050931 139630695397120 logging_writer.py:48] [7] global_step=7, grad_norm=4.053402, loss=0.924726
I0629 17:25:23.056900 139693899548480 submission.py:119] 7) loss = 0.925, grad_norm = 4.053
I0629 17:25:23.132302 139630703789824 logging_writer.py:48] [8] global_step=8, grad_norm=4.108622, loss=0.925178
I0629 17:25:23.140142 139693899548480 submission.py:119] 8) loss = 0.925, grad_norm = 4.109
I0629 17:25:23.213012 139630695397120 logging_writer.py:48] [9] global_step=9, grad_norm=4.164311, loss=0.897245
I0629 17:25:23.218989 139693899548480 submission.py:119] 9) loss = 0.897, grad_norm = 4.164
I0629 17:25:23.220481 139693899548480 spec.py:298] Evaluating on the training split.
/usr/local/lib/python3.8/dist-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html
  warn_deprecated('vmap', 'torch.vmap')
I0629 17:25:25.355403 139693899548480 spec.py:310] Evaluating on the validation split.
I0629 17:25:27.535011 139693899548480 spec.py:326] Evaluating on the test split.
I0629 17:25:29.657706 139693899548480 submission_runner.py:424] Time since start: 204.29s, 	Step: 10, 	{'train/ssim': 0.2141298225947789, 'train/loss': 0.8884669031415667, 'validation/ssim': 0.20805229225652433, 'validation/loss': 0.896522157032569, 'validation/num_examples': 3554, 'test/ssim': 0.2298438427202597, 'test/loss': 0.8940628763351718, 'test/num_examples': 3581, 'score': 34.86247658729553, 'total_duration': 204.28640365600586, 'accumulated_submission_time': 34.86247658729553, 'accumulated_eval_time': 169.39124131202698, 'accumulated_logging_time': 0.02541184425354004}
I0629 17:25:29.664672 139630703789824 logging_writer.py:48] [10] accumulated_eval_time=169.391241, accumulated_logging_time=0.025412, accumulated_submission_time=34.862477, global_step=10, preemption_count=0, score=34.862477, test/loss=0.894063, test/num_examples=3581, test/ssim=0.229844, total_duration=204.286404, train/loss=0.888467, train/ssim=0.214130, validation/loss=0.896522, validation/num_examples=3554, validation/ssim=0.208052
I0629 17:25:29.678889 139630695397120 logging_writer.py:48] [10] global_step=10, preemption_count=0, score=34.862477
I0629 17:25:29.815714 139693899548480 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/test_today/adamw/fastmri_pytorch/trial_1/checkpoint_10.
2023-06-29 17:25:29.816739: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
I0629 17:25:29.894019 139693899548480 submission_runner.py:587] Tuning trial 1/1
I0629 17:25:29.894272 139693899548480 submission_runner.py:588] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0629 17:25:29.894629 139693899548480 submission_runner.py:589] Metrics: {'eval_results': [(1, {'train/ssim': 0.20067313739231654, 'train/loss': 0.9397052356175014, 'validation/ssim': 0.1955551980383019, 'validation/loss': 0.9456622929269837, 'validation/num_examples': 3554, 'test/ssim': 0.21677013270450818, 'test/loss': 0.9434656624153519, 'test/num_examples': 3581, 'score': 34.12665152549744, 'total_duration': 197.08205032348633, 'accumulated_submission_time': 34.12665152549744, 'accumulated_eval_time': 162.95408034324646, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (10, {'train/ssim': 0.2141298225947789, 'train/loss': 0.8884669031415667, 'validation/ssim': 0.20805229225652433, 'validation/loss': 0.896522157032569, 'validation/num_examples': 3554, 'test/ssim': 0.2298438427202597, 'test/loss': 0.8940628763351718, 'test/num_examples': 3581, 'score': 34.86247658729553, 'total_duration': 204.28640365600586, 'accumulated_submission_time': 34.86247658729553, 'accumulated_eval_time': 169.39124131202698, 'accumulated_logging_time': 0.02541184425354004, 'global_step': 10, 'preemption_count': 0})], 'global_step': 10}
I0629 17:25:29.894719 139693899548480 submission_runner.py:590] Timing: 34.86247658729553
I0629 17:25:29.894778 139693899548480 submission_runner.py:591] ====================
I0629 17:25:29.894870 139693899548480 submission_runner.py:659] Final fastmri score: 34.86247658729553
