python3 submission_runner.py --framework=jax --workload=fastmri --submission_path=baselines/adamw/jax/submission.py --tuning_search_space=baselines/adamw/tuning_search_space.json --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=test_today/adamw --overwrite=True --save_checkpoints=False --max_global_steps=10 2>&1 | tee -a /logs/fastmri_jax_06-29-2023-17-12-01.log
2023-06-29 17:12:02.959269: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0629 17:12:15.124786 139963399804736 logger_utils.py:61] Removing existing experiment directory /experiment_runs/test_today/adamw/fastmri_jax because --overwrite was set.
I0629 17:12:15.129195 139963399804736 logger_utils.py:76] Creating experiment directory at /experiment_runs/test_today/adamw/fastmri_jax.
I0629 17:12:16.391939 139963399804736 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Host Interpreter CUDA
I0629 17:12:16.392612 139963399804736 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0629 17:12:16.392781 139963399804736 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0629 17:12:16.397226 139963399804736 submission_runner.py:547] Using RNG seed 717117961
I0629 17:12:18.547608 139963399804736 submission_runner.py:556] --- Tuning run 1/1 ---
I0629 17:12:18.547807 139963399804736 submission_runner.py:561] Creating tuning directory at /experiment_runs/test_today/adamw/fastmri_jax/trial_1.
I0629 17:12:18.548022 139963399804736 logger_utils.py:92] Saving hparams to /experiment_runs/test_today/adamw/fastmri_jax/trial_1/hparams.json.
I0629 17:12:18.729348 139963399804736 submission_runner.py:249] Initializing dataset.
I0629 17:12:25.172222 139963399804736 submission_runner.py:256] Initializing model.
I0629 17:12:31.669464 139963399804736 submission_runner.py:268] Initializing optimizer.
I0629 17:12:32.498593 139963399804736 submission_runner.py:275] Initializing metrics bundle.
I0629 17:12:32.498785 139963399804736 submission_runner.py:292] Initializing checkpoint and logger.
I0629 17:12:32.499698 139963399804736 checkpoints.py:915] Found no checkpoint files in /experiment_runs/test_today/adamw/fastmri_jax/trial_1 with prefix checkpoint_
I0629 17:12:32.499978 139963399804736 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0629 17:12:32.500065 139963399804736 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0629 17:12:33.437248 139963399804736 submission_runner.py:313] Saving meta data to /experiment_runs/test_today/adamw/fastmri_jax/trial_1/meta_data_0.json.
I0629 17:12:33.438230 139963399804736 submission_runner.py:316] Saving flags to /experiment_runs/test_today/adamw/fastmri_jax/trial_1/flags_0.json.
I0629 17:12:33.444411 139963399804736 submission_runner.py:328] Starting training loop.
2023-06-29 17:13:39.383317: E external/xla/xla/service/rendezvous.cc:31] This thread has been waiting for 10 seconds and may be stuck:
2023-06-29 17:13:41.449871: E external/xla/xla/service/rendezvous.cc:36] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.
I0629 17:13:42.913886 139798937335552 logging_writer.py:48] [0] global_step=0, grad_norm=3.3209242820739746, loss=0.750714898109436
I0629 17:13:42.925578 139963399804736 spec.py:298] Evaluating on the training split.
I0629 17:15:09.643859 139963399804736 spec.py:310] Evaluating on the validation split.
I0629 17:16:11.004901 139963399804736 spec.py:326] Evaluating on the test split.
I0629 17:17:07.110052 139963399804736 submission_runner.py:424] Time since start: 273.67s, 	Step: 1, 	{'train/ssim': 0.23103158814566477, 'train/loss': 0.8247026715959821, 'validation/ssim': 0.22176057539699986, 'validation/loss': 0.8362013559765406, 'validation/num_examples': 3554, 'test/ssim': 0.24382316037550614, 'test/loss': 0.8369790348584544, 'test/num_examples': 3581, 'score': 69.48100328445435, 'total_duration': 273.6655604839325, 'accumulated_submission_time': 69.48100328445435, 'accumulated_eval_time': 204.1844139099121, 'accumulated_logging_time': 0}
I0629 17:17:07.117190 139768495073024 logging_writer.py:48] [1] accumulated_eval_time=204.184414, accumulated_logging_time=0, accumulated_submission_time=69.481003, global_step=1, preemption_count=0, score=69.481003, test/loss=0.836979, test/num_examples=3581, test/ssim=0.243823, total_duration=273.665560, train/loss=0.824703, train/ssim=0.231032, validation/loss=0.836201, validation/num_examples=3554, validation/ssim=0.221761
I0629 17:17:07.724811 139963399804736 spec.py:298] Evaluating on the training split.
I0629 17:17:09.519273 139963399804736 spec.py:310] Evaluating on the validation split.
I0629 17:17:10.832966 139963399804736 spec.py:326] Evaluating on the test split.
I0629 17:17:12.146139 139963399804736 submission_runner.py:424] Time since start: 278.70s, 	Step: 10, 	{'train/ssim': 0.24442553520202637, 'train/loss': 0.7854603358677456, 'validation/ssim': 0.2339854500705631, 'validation/loss': 0.7985708637055079, 'validation/num_examples': 3554, 'test/ssim': 0.25662793050561994, 'test/loss': 0.7991057403658196, 'test/num_examples': 3581, 'score': 70.0796263217926, 'total_duration': 278.70166206359863, 'accumulated_submission_time': 70.0796263217926, 'accumulated_eval_time': 208.60569834709167, 'accumulated_logging_time': 0.015758752822875977}
I0629 17:17:12.153512 139768486680320 logging_writer.py:48] [10] accumulated_eval_time=208.605698, accumulated_logging_time=0.015759, accumulated_submission_time=70.079626, global_step=10, preemption_count=0, score=70.079626, test/loss=0.799106, test/num_examples=3581, test/ssim=0.256628, total_duration=278.701662, train/loss=0.785460, train/ssim=0.244426, validation/loss=0.798571, validation/num_examples=3554, validation/ssim=0.233985
I0629 17:17:12.166803 139768495073024 logging_writer.py:48] [10] global_step=10, preemption_count=0, score=70.079626
I0629 17:17:12.202300 139963399804736 checkpoints.py:490] Saving checkpoint at step: 10
I0629 17:17:12.404437 139963399804736 checkpoints.py:422] Saved checkpoint at /experiment_runs/test_today/adamw/fastmri_jax/trial_1/checkpoint_10
I0629 17:17:12.405781 139963399804736 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/test_today/adamw/fastmri_jax/trial_1/checkpoint_10.
2023-06-29 17:17:12.407155: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
I0629 17:17:12.468384 139963399804736 submission_runner.py:587] Tuning trial 1/1
I0629 17:17:12.468533 139963399804736 submission_runner.py:588] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0629 17:17:12.469047 139963399804736 submission_runner.py:589] Metrics: {'eval_results': [(1, {'train/ssim': 0.23103158814566477, 'train/loss': 0.8247026715959821, 'validation/ssim': 0.22176057539699986, 'validation/loss': 0.8362013559765406, 'validation/num_examples': 3554, 'test/ssim': 0.24382316037550614, 'test/loss': 0.8369790348584544, 'test/num_examples': 3581, 'score': 69.48100328445435, 'total_duration': 273.6655604839325, 'accumulated_submission_time': 69.48100328445435, 'accumulated_eval_time': 204.1844139099121, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (10, {'train/ssim': 0.24442553520202637, 'train/loss': 0.7854603358677456, 'validation/ssim': 0.2339854500705631, 'validation/loss': 0.7985708637055079, 'validation/num_examples': 3554, 'test/ssim': 0.25662793050561994, 'test/loss': 0.7991057403658196, 'test/num_examples': 3581, 'score': 70.0796263217926, 'total_duration': 278.70166206359863, 'accumulated_submission_time': 70.0796263217926, 'accumulated_eval_time': 208.60569834709167, 'accumulated_logging_time': 0.015758752822875977, 'global_step': 10, 'preemption_count': 0})], 'global_step': 10}
I0629 17:17:12.469153 139963399804736 submission_runner.py:590] Timing: 70.0796263217926
I0629 17:17:12.469222 139963399804736 submission_runner.py:591] ====================
I0629 17:17:12.469346 139963399804736 submission_runner.py:659] Final fastmri score: 70.0796263217926
