python3 submission_runner.py --framework=jax --workload=ogbg --submission_path=baselines/adamw/jax/submission.py --tuning_search_space=baselines/adamw/tuning_search_space.json --data_dir=/data/ogbg --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=test_today/adamw --overwrite=True --save_checkpoints=False --max_global_steps=10 2>&1 | tee -a /logs/ogbg_jax_06-29-2023-20-43-03.log
2023-06-29 20:43:05.575626: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0629 20:43:19.877501 140702288963392 logger_utils.py:61] Removing existing experiment directory /experiment_runs/test_today/adamw/ogbg_jax because --overwrite was set.
I0629 20:43:19.879925 140702288963392 logger_utils.py:76] Creating experiment directory at /experiment_runs/test_today/adamw/ogbg_jax.
I0629 20:43:20.856547 140702288963392 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Host Interpreter
I0629 20:43:20.857238 140702288963392 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0629 20:43:20.857380 140702288963392 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0629 20:43:20.861911 140702288963392 submission_runner.py:547] Using RNG seed 1113765105
I0629 20:43:23.057029 140702288963392 submission_runner.py:556] --- Tuning run 1/1 ---
I0629 20:43:23.057242 140702288963392 submission_runner.py:561] Creating tuning directory at /experiment_runs/test_today/adamw/ogbg_jax/trial_1.
I0629 20:43:23.057495 140702288963392 logger_utils.py:92] Saving hparams to /experiment_runs/test_today/adamw/ogbg_jax/trial_1/hparams.json.
I0629 20:43:23.243476 140702288963392 submission_runner.py:249] Initializing dataset.
I0629 20:43:23.357249 140702288963392 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0629 20:43:23.362872 140702288963392 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/reader.py:101: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
W0629 20:43:23.525392 140702288963392 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/reader.py:101: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
I0629 20:43:23.580238 140702288963392 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split train, from /data/ogbg/ogbg_molpcba/0.1.3
I0629 20:43:23.614255 140702288963392 submission_runner.py:256] Initializing model.
I0629 20:43:28.130992 140702288963392 submission_runner.py:268] Initializing optimizer.
I0629 20:43:28.773706 140702288963392 submission_runner.py:275] Initializing metrics bundle.
I0629 20:43:28.773905 140702288963392 submission_runner.py:292] Initializing checkpoint and logger.
I0629 20:43:28.774769 140702288963392 checkpoints.py:915] Found no checkpoint files in /experiment_runs/test_today/adamw/ogbg_jax/trial_1 with prefix checkpoint_
I0629 20:43:28.775017 140702288963392 logger_utils.py:239] Unable to record workload.train_mean information. Continuing without it.
I0629 20:43:28.775091 140702288963392 logger_utils.py:239] Unable to record workload.train_stddev information. Continuing without it.
I0629 20:43:29.812126 140702288963392 submission_runner.py:313] Saving meta data to /experiment_runs/test_today/adamw/ogbg_jax/trial_1/meta_data_0.json.
I0629 20:43:29.813161 140702288963392 submission_runner.py:316] Saving flags to /experiment_runs/test_today/adamw/ogbg_jax/trial_1/flags_0.json.
I0629 20:43:29.820159 140702288963392 submission_runner.py:328] Starting training loop.
I0629 20:43:53.552342 140538208581376 logging_writer.py:48] [0] global_step=0, grad_norm=3.1365458965301514, loss=0.7908625602722168
I0629 20:43:53.565486 140702288963392 spec.py:298] Evaluating on the training split.
I0629 20:43:53.571484 140702288963392 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0629 20:43:53.575280 140702288963392 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
I0629 20:43:53.640543 140702288963392 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split train, from /data/ogbg/ogbg_molpcba/0.1.3
I0629 20:45:42.786320 140702288963392 spec.py:310] Evaluating on the validation split.
I0629 20:45:42.789554 140702288963392 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0629 20:45:42.793628 140702288963392 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
I0629 20:45:42.855047 140702288963392 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split validation, from /data/ogbg/ogbg_molpcba/0.1.3
I0629 20:47:13.668885 140702288963392 spec.py:326] Evaluating on the test split.
I0629 20:47:13.672075 140702288963392 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0629 20:47:13.676143 140702288963392 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
I0629 20:47:13.738364 140702288963392 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split test, from /data/ogbg/ogbg_molpcba/0.1.3
I0629 20:48:47.885957 140702288963392 submission_runner.py:424] Time since start: 318.07s, 	Step: 1, 	{'train/accuracy': 0.4331156015396118, 'train/loss': 0.7881403565406799, 'train/mean_average_precision': 0.021851423039945375, 'validation/accuracy': 0.4265064597129822, 'validation/loss': 0.7946280241012573, 'validation/mean_average_precision': 0.02645749713390284, 'validation/num_examples': 43793, 'test/accuracy': 0.42541608214378357, 'test/loss': 0.79594886302948, 'test/mean_average_precision': 0.028751909408879808, 'test/num_examples': 43793, 'score': 23.74515128135681, 'total_duration': 318.065731048584, 'accumulated_submission_time': 23.74515128135681, 'accumulated_eval_time': 294.32041025161743, 'accumulated_logging_time': 0}
I0629 20:48:47.893047 140526925408000 logging_writer.py:48] [1] accumulated_eval_time=294.320410, accumulated_logging_time=0, accumulated_submission_time=23.745151, global_step=1, preemption_count=0, score=23.745151, test/accuracy=0.425416, test/loss=0.795949, test/mean_average_precision=0.028752, test/num_examples=43793, total_duration=318.065731, train/accuracy=0.433116, train/loss=0.788140, train/mean_average_precision=0.021851, validation/accuracy=0.426506, validation/loss=0.794628, validation/mean_average_precision=0.026457, validation/num_examples=43793
I0629 20:48:50.472329 140702288963392 spec.py:298] Evaluating on the training split.
I0629 20:50:36.867114 140702288963392 spec.py:310] Evaluating on the validation split.
I0629 20:50:39.724212 140702288963392 spec.py:326] Evaluating on the test split.
I0629 20:50:42.504961 140702288963392 submission_runner.py:424] Time since start: 432.68s, 	Step: 10, 	{'train/accuracy': 0.48730140924453735, 'train/loss': 0.7499004006385803, 'train/mean_average_precision': 0.024167001937187915, 'validation/accuracy': 0.48231780529022217, 'validation/loss': 0.7574464678764343, 'validation/mean_average_precision': 0.027504323695806722, 'validation/num_examples': 43793, 'test/accuracy': 0.4810291528701782, 'test/loss': 0.759008526802063, 'test/mean_average_precision': 0.029323286304498673, 'test/num_examples': 43793, 'score': 26.312742233276367, 'total_duration': 432.68472480773926, 'accumulated_submission_time': 26.312742233276367, 'accumulated_eval_time': 406.3529827594757, 'accumulated_logging_time': 0.018420934677124023}
I0629 20:50:42.512670 140528033195776 logging_writer.py:48] [10] accumulated_eval_time=406.352983, accumulated_logging_time=0.018421, accumulated_submission_time=26.312742, global_step=10, preemption_count=0, score=26.312742, test/accuracy=0.481029, test/loss=0.759009, test/mean_average_precision=0.029323, test/num_examples=43793, total_duration=432.684725, train/accuracy=0.487301, train/loss=0.749900, train/mean_average_precision=0.024167, validation/accuracy=0.482318, validation/loss=0.757446, validation/mean_average_precision=0.027504, validation/num_examples=43793
I0629 20:50:42.527442 140528142055168 logging_writer.py:48] [10] global_step=10, preemption_count=0, score=26.312742
I0629 20:50:42.571948 140702288963392 checkpoints.py:490] Saving checkpoint at step: 10
I0629 20:50:42.668833 140702288963392 checkpoints.py:422] Saved checkpoint at /experiment_runs/test_today/adamw/ogbg_jax/trial_1/checkpoint_10
I0629 20:50:42.669680 140702288963392 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/test_today/adamw/ogbg_jax/trial_1/checkpoint_10.
I0629 20:50:42.774117 140702288963392 submission_runner.py:587] Tuning trial 1/1
I0629 20:50:42.774360 140702288963392 submission_runner.py:588] Hyperparameters: Hyperparameters(learning_rate=0.0019814680146414726, one_minus_beta1=0.22838767981804783, beta2=0.999, warmup_factor=0.05, weight_decay=0.010340635370188849, label_smoothing=0.1, dropout_rate=0.0)
I0629 20:50:42.775409 140702288963392 submission_runner.py:589] Metrics: {'eval_results': [(1, {'train/accuracy': 0.4331156015396118, 'train/loss': 0.7881403565406799, 'train/mean_average_precision': 0.021851423039945375, 'validation/accuracy': 0.4265064597129822, 'validation/loss': 0.7946280241012573, 'validation/mean_average_precision': 0.02645749713390284, 'validation/num_examples': 43793, 'test/accuracy': 0.42541608214378357, 'test/loss': 0.79594886302948, 'test/mean_average_precision': 0.028751909408879808, 'test/num_examples': 43793, 'score': 23.74515128135681, 'total_duration': 318.065731048584, 'accumulated_submission_time': 23.74515128135681, 'accumulated_eval_time': 294.32041025161743, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (10, {'train/accuracy': 0.48730140924453735, 'train/loss': 0.7499004006385803, 'train/mean_average_precision': 0.024167001937187915, 'validation/accuracy': 0.48231780529022217, 'validation/loss': 0.7574464678764343, 'validation/mean_average_precision': 0.027504323695806722, 'validation/num_examples': 43793, 'test/accuracy': 0.4810291528701782, 'test/loss': 0.759008526802063, 'test/mean_average_precision': 0.029323286304498673, 'test/num_examples': 43793, 'score': 26.312742233276367, 'total_duration': 432.68472480773926, 'accumulated_submission_time': 26.312742233276367, 'accumulated_eval_time': 406.3529827594757, 'accumulated_logging_time': 0.018420934677124023, 'global_step': 10, 'preemption_count': 0})], 'global_step': 10}
I0629 20:50:42.775562 140702288963392 submission_runner.py:590] Timing: 26.312742233276367
I0629 20:50:42.775616 140702288963392 submission_runner.py:591] ====================
I0629 20:50:42.775723 140702288963392 submission_runner.py:659] Final ogbg score: 26.312742233276367
