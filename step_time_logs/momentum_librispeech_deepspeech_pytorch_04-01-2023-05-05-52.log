WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
I0401 05:06:07.808649 140032051865408 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 1
I0401 05:06:07.808685 139640970172224 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 5
I0401 05:06:07.809492 139843027441472 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 6
I0401 05:06:07.809581 139734686193472 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 4
I0401 05:06:07.809649 139767077095232 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 7
I0401 05:06:07.809752 140075582519104 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 2
I0401 05:06:07.809959 139962142926656 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 3
I0401 05:06:07.819831 140648769607488 distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 0
I0401 05:06:07.820030 139843027441472 distributed_c10d.py:353] Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0401 05:06:07.820090 139734686193472 distributed_c10d.py:353] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0401 05:06:07.820125 140648769607488 distributed_c10d.py:353] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0401 05:06:07.820232 139767077095232 distributed_c10d.py:353] Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0401 05:06:07.820254 140075582519104 distributed_c10d.py:353] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0401 05:06:07.820616 139962142926656 distributed_c10d.py:353] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0401 05:06:07.829678 139640970172224 distributed_c10d.py:353] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0401 05:06:07.829663 140032051865408 distributed_c10d.py:353] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
I0401 05:06:08.196519 140648769607488 logger_utils.py:67] Creating experiment directory at /experiment_runs/timing_momentum/librispeech_deepspeech_pytorch.
W0401 05:06:08.247171 139640970172224 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0401 05:06:08.248531 139767077095232 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0401 05:06:08.248786 139843027441472 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0401 05:06:08.251774 139734686193472 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0401 05:06:08.268043 140648769607488 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0401 05:06:08.271830 140648769607488 submission_runner.py:504] Using RNG seed 1143130136
I0401 05:06:08.272970 140648769607488 submission_runner.py:513] --- Tuning run 1/1 ---
I0401 05:06:08.273109 140648769607488 submission_runner.py:518] Creating tuning directory at /experiment_runs/timing_momentum/librispeech_deepspeech_pytorch/trial_1.
I0401 05:06:08.273329 140648769607488 logger_utils.py:84] Saving hparams to /experiment_runs/timing_momentum/librispeech_deepspeech_pytorch/trial_1/hparams.json.
W0401 05:06:08.273637 139962142926656 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0401 05:06:08.274321 140648769607488 submission_runner.py:230] Starting train once: RAM USED (GB) 5.746679808
I0401 05:06:08.274416 140648769607488 submission_runner.py:231] Initializing dataset.
I0401 05:06:08.274498 140648769607488 input_pipeline.py:20] Loading split = train-clean-100
W0401 05:06:08.279448 140075582519104 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
W0401 05:06:08.281640 140032051865408 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0401 05:06:08.303002 140648769607488 input_pipeline.py:20] Loading split = train-clean-360
I0401 05:06:08.630075 140648769607488 input_pipeline.py:20] Loading split = train-other-500
I0401 05:06:09.063259 140648769607488 submission_runner.py:239] After Initializing dataset: RAM USED (GB) 6.024380416
I0401 05:06:09.063425 140648769607488 submission_runner.py:240] Initializing model.
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
I0401 05:06:16.273684 140648769607488 submission_runner.py:251] After Initializing model: RAM USED (GB) 21.936521216
I0401 05:06:16.273872 140648769607488 submission_runner.py:252] Initializing optimizer.
I0401 05:06:16.431085 140648769607488 submission_runner.py:260] After Initializing metrics bundle: RAM USED (GB) 21.3701632
I0401 05:06:16.431260 140648769607488 submission_runner.py:261] Initializing metrics bundle.
I0401 05:06:16.431307 140648769607488 submission_runner.py:275] Initializing checkpoint and logger.
I0401 05:06:16.433036 140648769607488 logger_utils.py:231] Unable to record workload.train_mean information. Continuing without it.
I0401 05:06:16.433171 140648769607488 logger_utils.py:231] Unable to record workload.train_stddev information. Continuing without it.
I0401 05:06:17.261145 140648769607488 submission_runner.py:296] Saving meta data to /experiment_runs/timing_momentum/librispeech_deepspeech_pytorch/trial_1/meta_data_0.json.
I0401 05:06:17.262072 140648769607488 submission_runner.py:299] Saving flags to /experiment_runs/timing_momentum/librispeech_deepspeech_pytorch/trial_1/flags_0.json.
I0401 05:06:17.265140 140648769607488 submission_runner.py:304] After checkpoint and logger metrics bundle: RAM USED (GB) 21.377060864
I0401 05:06:17.266315 140648769607488 submission_runner.py:311] Before starting training loop and logger metrics bundle: RAM USED (GB) 21.377060864
I0401 05:06:17.266417 140648769607488 submission_runner.py:312] Starting training loop.
I0401 05:06:19.674202 140648769607488 submission_runner.py:333] After dataselection batch at step 0: RAM USED (GB) 25.839632384
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech_conformer/librispeech_pytorch/preprocessor.py:488: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1443.)
  spectrum = torch.abs(spectrum)
I0401 05:06:26.016592 140622572799744 logging_writer.py:48] [0] global_step=0, grad_norm=18.541002, loss=33.600731
I0401 05:06:26.027893 140648769607488 submission.py:139] 0) loss = 33.601, grad_norm = 18.541
I0401 05:06:26.028638 140648769607488 submission_runner.py:350] After update parameters step 0: RAM USED (GB) 31.655419904
I0401 05:06:26.029249 140648769607488 submission_runner.py:371] Before eval at step 1: RAM USED (GB) 31.655419904
I0401 05:06:26.029368 140648769607488 spec.py:298] Evaluating on the training split.
I0401 05:06:26.030128 140648769607488 input_pipeline.py:20] Loading split = train-clean-100
I0401 05:06:26.058547 140648769607488 input_pipeline.py:20] Loading split = train-clean-360
I0401 05:06:26.465381 140648769607488 input_pipeline.py:20] Loading split = train-other-500
I0401 05:06:42.839834 140648769607488 spec.py:310] Evaluating on the validation split.
I0401 05:06:42.841082 140648769607488 input_pipeline.py:20] Loading split = dev-clean
I0401 05:06:42.845220 140648769607488 input_pipeline.py:20] Loading split = dev-other
I0401 05:06:54.327454 140648769607488 spec.py:326] Evaluating on the test split.
I0401 05:06:54.328777 140648769607488 input_pipeline.py:20] Loading split = test-clean
I0401 05:07:01.057042 140648769607488 submission_runner.py:380] Time since start: 8.76s, 	Step: 1, 	{'train/ctc_loss': 30.90008681640526, 'train/wer': 4.166848859187619, 'validation/ctc_loss': 29.835468153506127, 'validation/wer': 3.8425143629604595, 'validation/num_examples': 5348, 'test/ctc_loss': 29.930876185560358, 'test/wer': 4.145613714378567, 'test/num_examples': 2472}
I0401 05:07:01.057877 140648769607488 submission_runner.py:390] After eval at step 1: RAM USED (GB) 45.945745408
I0401 05:07:01.070330 140620467263232 logging_writer.py:48] [1] global_step=1, preemption_count=0, score=8.761362, test/ctc_loss=29.930876, test/num_examples=2472, test/wer=4.145614, total_duration=8.763492, train/ctc_loss=30.900087, train/wer=4.166849, validation/ctc_loss=29.835468, validation/num_examples=5348, validation/wer=3.842514
I0401 05:07:01.282519 140648769607488 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/librispeech_deepspeech_pytorch/trial_1/checkpoint_1.
I0401 05:07:01.282986 140648769607488 submission_runner.py:409] After logging and checkpointing eval at step 1: RAM USED (GB) 45.99103488
I0401 05:07:01.285871 140648769607488 submission_runner.py:333] After dataselection batch at step 1: RAM USED (GB) 45.993906176
I0401 05:07:01.319831 140648769607488 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0401 05:07:01.319891 139734686193472 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0401 05:07:01.319926 140032051865408 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0401 05:07:01.319950 139640970172224 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0401 05:07:01.319952 139962142926656 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0401 05:07:01.320768 139843027441472 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0401 05:07:01.320806 139767077095232 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0401 05:07:01.320993 140075582519104 distributed.py:1027] Reducer buckets have been rebuilt in this iteration.
I0401 05:07:02.382973 140619745851136 logging_writer.py:48] [1] global_step=1, grad_norm=18.856630, loss=32.930157
I0401 05:07:02.386683 140648769607488 submission.py:139] 1) loss = 32.930, grad_norm = 18.857
I0401 05:07:02.387459 140648769607488 submission_runner.py:350] After update parameters step 1: RAM USED (GB) 46.180278272
I0401 05:07:03.352593 140620467263232 logging_writer.py:48] [2] global_step=2, grad_norm=21.021732, loss=33.501633
I0401 05:07:03.355869 140648769607488 submission.py:139] 2) loss = 33.502, grad_norm = 21.022
I0401 05:07:04.201185 140619745851136 logging_writer.py:48] [3] global_step=3, grad_norm=22.375340, loss=33.445461
I0401 05:07:04.204796 140648769607488 submission.py:139] 3) loss = 33.445, grad_norm = 22.375
I0401 05:07:05.028043 140620467263232 logging_writer.py:48] [4] global_step=4, grad_norm=27.910879, loss=32.764908
I0401 05:07:05.031513 140648769607488 submission.py:139] 4) loss = 32.765, grad_norm = 27.911
I0401 05:07:05.861825 140619745851136 logging_writer.py:48] [5] global_step=5, grad_norm=44.871925, loss=32.407730
I0401 05:07:05.865163 140648769607488 submission.py:139] 5) loss = 32.408, grad_norm = 44.872
I0401 05:07:06.692676 140620467263232 logging_writer.py:48] [6] global_step=6, grad_norm=64.196991, loss=31.139317
I0401 05:07:06.695880 140648769607488 submission.py:139] 6) loss = 31.139, grad_norm = 64.197
I0401 05:07:07.522451 140619745851136 logging_writer.py:48] [7] global_step=7, grad_norm=52.493439, loss=28.117300
I0401 05:07:07.525518 140648769607488 submission.py:139] 7) loss = 28.117, grad_norm = 52.493
I0401 05:07:08.342173 140620467263232 logging_writer.py:48] [8] global_step=8, grad_norm=40.407978, loss=26.514824
I0401 05:07:08.345395 140648769607488 submission.py:139] 8) loss = 26.515, grad_norm = 40.408
I0401 05:07:09.177830 140619745851136 logging_writer.py:48] [9] global_step=9, grad_norm=30.996653, loss=24.675518
I0401 05:07:09.181230 140648769607488 submission.py:139] 9) loss = 24.676, grad_norm = 30.997
I0401 05:07:10.006120 140620467263232 logging_writer.py:48] [10] global_step=10, grad_norm=28.111986, loss=23.305838
I0401 05:07:10.009792 140648769607488 submission.py:139] 10) loss = 23.306, grad_norm = 28.112
I0401 05:07:10.841221 140619745851136 logging_writer.py:48] [11] global_step=11, grad_norm=27.531734, loss=21.465654
I0401 05:07:10.844501 140648769607488 submission.py:139] 11) loss = 21.466, grad_norm = 27.532
I0401 05:07:11.662568 140620467263232 logging_writer.py:48] [12] global_step=12, grad_norm=25.396364, loss=20.317663
I0401 05:07:11.665771 140648769607488 submission.py:139] 12) loss = 20.318, grad_norm = 25.396
I0401 05:07:12.478258 140619745851136 logging_writer.py:48] [13] global_step=13, grad_norm=21.627157, loss=18.555141
I0401 05:07:12.481631 140648769607488 submission.py:139] 13) loss = 18.555, grad_norm = 21.627
I0401 05:07:13.302663 140620467263232 logging_writer.py:48] [14] global_step=14, grad_norm=20.174597, loss=16.887606
I0401 05:07:13.306089 140648769607488 submission.py:139] 14) loss = 16.888, grad_norm = 20.175
I0401 05:07:14.111781 140619745851136 logging_writer.py:48] [15] global_step=15, grad_norm=18.076290, loss=15.115673
I0401 05:07:14.115056 140648769607488 submission.py:139] 15) loss = 15.116, grad_norm = 18.076
I0401 05:07:14.923085 140620467263232 logging_writer.py:48] [16] global_step=16, grad_norm=15.780697, loss=14.239438
I0401 05:07:14.926453 140648769607488 submission.py:139] 16) loss = 14.239, grad_norm = 15.781
I0401 05:07:15.734917 140619745851136 logging_writer.py:48] [17] global_step=17, grad_norm=17.644932, loss=13.422619
I0401 05:07:15.738365 140648769607488 submission.py:139] 17) loss = 13.423, grad_norm = 17.645
I0401 05:07:16.550083 140620467263232 logging_writer.py:48] [18] global_step=18, grad_norm=12.825191, loss=12.002890
I0401 05:07:16.553433 140648769607488 submission.py:139] 18) loss = 12.003, grad_norm = 12.825
I0401 05:07:17.361765 140619745851136 logging_writer.py:48] [19] global_step=19, grad_norm=11.483274, loss=11.706590
I0401 05:07:17.364841 140648769607488 submission.py:139] 19) loss = 11.707, grad_norm = 11.483
I0401 05:07:18.180491 140620467263232 logging_writer.py:48] [20] global_step=20, grad_norm=10.030292, loss=11.006361
I0401 05:07:18.183488 140648769607488 submission.py:139] 20) loss = 11.006, grad_norm = 10.030
I0401 05:07:18.996708 140619745851136 logging_writer.py:48] [21] global_step=21, grad_norm=10.667162, loss=10.720779
I0401 05:07:18.999768 140648769607488 submission.py:139] 21) loss = 10.721, grad_norm = 10.667
I0401 05:07:19.810248 140620467263232 logging_writer.py:48] [22] global_step=22, grad_norm=11.593193, loss=10.683128
I0401 05:07:19.813760 140648769607488 submission.py:139] 22) loss = 10.683, grad_norm = 11.593
I0401 05:07:20.640049 140619745851136 logging_writer.py:48] [23] global_step=23, grad_norm=10.223305, loss=10.101333
I0401 05:07:20.643314 140648769607488 submission.py:139] 23) loss = 10.101, grad_norm = 10.223
I0401 05:07:21.457654 140620467263232 logging_writer.py:48] [24] global_step=24, grad_norm=10.422524, loss=9.935912
I0401 05:07:21.460765 140648769607488 submission.py:139] 24) loss = 9.936, grad_norm = 10.423
I0401 05:07:22.270234 140619745851136 logging_writer.py:48] [25] global_step=25, grad_norm=9.883797, loss=9.767447
I0401 05:07:22.273393 140648769607488 submission.py:139] 25) loss = 9.767, grad_norm = 9.884
I0401 05:07:23.089127 140620467263232 logging_writer.py:48] [26] global_step=26, grad_norm=6.251085, loss=9.067440
I0401 05:07:23.092388 140648769607488 submission.py:139] 26) loss = 9.067, grad_norm = 6.251
I0401 05:07:23.909041 140619745851136 logging_writer.py:48] [27] global_step=27, grad_norm=5.601612, loss=9.156185
I0401 05:07:23.912290 140648769607488 submission.py:139] 27) loss = 9.156, grad_norm = 5.602
I0401 05:07:24.727619 140620467263232 logging_writer.py:48] [28] global_step=28, grad_norm=5.907048, loss=8.731558
I0401 05:07:24.730859 140648769607488 submission.py:139] 28) loss = 8.732, grad_norm = 5.907
I0401 05:07:25.542387 140619745851136 logging_writer.py:48] [29] global_step=29, grad_norm=6.687174, loss=8.724344
I0401 05:07:25.545469 140648769607488 submission.py:139] 29) loss = 8.724, grad_norm = 6.687
I0401 05:07:26.359158 140620467263232 logging_writer.py:48] [30] global_step=30, grad_norm=12.083551, loss=8.449979
I0401 05:07:26.362550 140648769607488 submission.py:139] 30) loss = 8.450, grad_norm = 12.084
I0401 05:07:27.174175 140619745851136 logging_writer.py:48] [31] global_step=31, grad_norm=4.849006, loss=8.169219
I0401 05:07:27.177444 140648769607488 submission.py:139] 31) loss = 8.169, grad_norm = 4.849
I0401 05:07:27.991696 140620467263232 logging_writer.py:48] [32] global_step=32, grad_norm=8.148775, loss=8.072102
I0401 05:07:27.994987 140648769607488 submission.py:139] 32) loss = 8.072, grad_norm = 8.149
I0401 05:07:28.805376 140619745851136 logging_writer.py:48] [33] global_step=33, grad_norm=4.968626, loss=7.900500
I0401 05:07:28.808544 140648769607488 submission.py:139] 33) loss = 7.900, grad_norm = 4.969
I0401 05:07:29.616904 140620467263232 logging_writer.py:48] [34] global_step=34, grad_norm=5.290638, loss=7.752397
I0401 05:07:29.620141 140648769607488 submission.py:139] 34) loss = 7.752, grad_norm = 5.291
I0401 05:07:30.433465 140619745851136 logging_writer.py:48] [35] global_step=35, grad_norm=5.703874, loss=7.847862
I0401 05:07:30.436856 140648769607488 submission.py:139] 35) loss = 7.848, grad_norm = 5.704
I0401 05:07:31.247553 140620467263232 logging_writer.py:48] [36] global_step=36, grad_norm=7.419057, loss=7.766340
I0401 05:07:31.251205 140648769607488 submission.py:139] 36) loss = 7.766, grad_norm = 7.419
I0401 05:07:32.061622 140619745851136 logging_writer.py:48] [37] global_step=37, grad_norm=5.788554, loss=7.532988
I0401 05:07:32.064920 140648769607488 submission.py:139] 37) loss = 7.533, grad_norm = 5.789
I0401 05:07:32.876015 140620467263232 logging_writer.py:48] [38] global_step=38, grad_norm=6.661814, loss=7.462270
I0401 05:07:32.879500 140648769607488 submission.py:139] 38) loss = 7.462, grad_norm = 6.662
I0401 05:07:33.688056 140619745851136 logging_writer.py:48] [39] global_step=39, grad_norm=2.581222, loss=7.446083
I0401 05:07:33.691513 140648769607488 submission.py:139] 39) loss = 7.446, grad_norm = 2.581
I0401 05:07:34.501971 140620467263232 logging_writer.py:48] [40] global_step=40, grad_norm=13.744563, loss=7.460646
I0401 05:07:34.505107 140648769607488 submission.py:139] 40) loss = 7.461, grad_norm = 13.745
I0401 05:07:35.312845 140619745851136 logging_writer.py:48] [41] global_step=41, grad_norm=17.790131, loss=7.547685
I0401 05:07:35.315893 140648769607488 submission.py:139] 41) loss = 7.548, grad_norm = 17.790
I0401 05:07:36.127753 140620467263232 logging_writer.py:48] [42] global_step=42, grad_norm=5.496414, loss=7.271661
I0401 05:07:36.130950 140648769607488 submission.py:139] 42) loss = 7.272, grad_norm = 5.496
I0401 05:07:36.941297 140619745851136 logging_writer.py:48] [43] global_step=43, grad_norm=36.124935, loss=7.992463
I0401 05:07:36.944288 140648769607488 submission.py:139] 43) loss = 7.992, grad_norm = 36.125
I0401 05:07:37.784660 140620467263232 logging_writer.py:48] [44] global_step=44, grad_norm=9.388907, loss=7.440661
I0401 05:07:37.787939 140648769607488 submission.py:139] 44) loss = 7.441, grad_norm = 9.389
I0401 05:07:38.598326 140619745851136 logging_writer.py:48] [45] global_step=45, grad_norm=10.031996, loss=7.616152
I0401 05:07:38.601568 140648769607488 submission.py:139] 45) loss = 7.616, grad_norm = 10.032
I0401 05:07:39.413017 140620467263232 logging_writer.py:48] [46] global_step=46, grad_norm=7.261611, loss=7.511449
I0401 05:07:39.416104 140648769607488 submission.py:139] 46) loss = 7.511, grad_norm = 7.262
I0401 05:07:40.228922 140619745851136 logging_writer.py:48] [47] global_step=47, grad_norm=4.420567, loss=7.290745
I0401 05:07:40.232278 140648769607488 submission.py:139] 47) loss = 7.291, grad_norm = 4.421
I0401 05:07:41.043784 140620467263232 logging_writer.py:48] [48] global_step=48, grad_norm=4.995952, loss=7.375461
I0401 05:07:41.047253 140648769607488 submission.py:139] 48) loss = 7.375, grad_norm = 4.996
I0401 05:07:41.856724 140619745851136 logging_writer.py:48] [49] global_step=49, grad_norm=4.141256, loss=7.048342
I0401 05:07:41.860435 140648769607488 submission.py:139] 49) loss = 7.048, grad_norm = 4.141
I0401 05:07:42.673615 140620467263232 logging_writer.py:48] [50] global_step=50, grad_norm=4.505995, loss=7.005344
I0401 05:07:42.676810 140648769607488 submission.py:139] 50) loss = 7.005, grad_norm = 4.506
I0401 05:07:43.487622 140619745851136 logging_writer.py:48] [51] global_step=51, grad_norm=4.072418, loss=7.019448
I0401 05:07:43.490944 140648769607488 submission.py:139] 51) loss = 7.019, grad_norm = 4.072
I0401 05:07:44.302142 140620467263232 logging_writer.py:48] [52] global_step=52, grad_norm=9.513121, loss=6.916612
I0401 05:07:44.306368 140648769607488 submission.py:139] 52) loss = 6.917, grad_norm = 9.513
I0401 05:07:45.117670 140619745851136 logging_writer.py:48] [53] global_step=53, grad_norm=6.317818, loss=6.839365
I0401 05:07:45.120954 140648769607488 submission.py:139] 53) loss = 6.839, grad_norm = 6.318
I0401 05:07:45.930498 140620467263232 logging_writer.py:48] [54] global_step=54, grad_norm=8.974846, loss=6.821102
I0401 05:07:45.933880 140648769607488 submission.py:139] 54) loss = 6.821, grad_norm = 8.975
I0401 05:07:46.742453 140619745851136 logging_writer.py:48] [55] global_step=55, grad_norm=6.156025, loss=6.790944
I0401 05:07:46.745753 140648769607488 submission.py:139] 55) loss = 6.791, grad_norm = 6.156
I0401 05:07:47.559859 140620467263232 logging_writer.py:48] [56] global_step=56, grad_norm=6.242610, loss=6.654875
I0401 05:07:47.563140 140648769607488 submission.py:139] 56) loss = 6.655, grad_norm = 6.243
I0401 05:07:48.375175 140619745851136 logging_writer.py:48] [57] global_step=57, grad_norm=9.957745, loss=6.699446
I0401 05:07:48.378497 140648769607488 submission.py:139] 57) loss = 6.699, grad_norm = 9.958
I0401 05:07:49.187517 140620467263232 logging_writer.py:48] [58] global_step=58, grad_norm=5.569144, loss=6.666879
I0401 05:07:49.190722 140648769607488 submission.py:139] 58) loss = 6.667, grad_norm = 5.569
I0401 05:07:50.010560 140619745851136 logging_writer.py:48] [59] global_step=59, grad_norm=8.083926, loss=6.879070
I0401 05:07:50.013761 140648769607488 submission.py:139] 59) loss = 6.879, grad_norm = 8.084
I0401 05:07:50.820895 140620467263232 logging_writer.py:48] [60] global_step=60, grad_norm=6.137905, loss=6.723863
I0401 05:07:50.824459 140648769607488 submission.py:139] 60) loss = 6.724, grad_norm = 6.138
I0401 05:07:51.637370 140619745851136 logging_writer.py:48] [61] global_step=61, grad_norm=4.297096, loss=6.602321
I0401 05:07:51.641177 140648769607488 submission.py:139] 61) loss = 6.602, grad_norm = 4.297
I0401 05:07:52.451707 140620467263232 logging_writer.py:48] [62] global_step=62, grad_norm=12.703693, loss=6.725662
I0401 05:07:52.454875 140648769607488 submission.py:139] 62) loss = 6.726, grad_norm = 12.704
I0401 05:07:53.265505 140619745851136 logging_writer.py:48] [63] global_step=63, grad_norm=4.909576, loss=6.543461
I0401 05:07:53.268817 140648769607488 submission.py:139] 63) loss = 6.543, grad_norm = 4.910
I0401 05:07:54.078909 140620467263232 logging_writer.py:48] [64] global_step=64, grad_norm=7.915469, loss=6.498439
I0401 05:07:54.082202 140648769607488 submission.py:139] 64) loss = 6.498, grad_norm = 7.915
I0401 05:07:54.895069 140619745851136 logging_writer.py:48] [65] global_step=65, grad_norm=11.507043, loss=6.564167
I0401 05:07:54.898146 140648769607488 submission.py:139] 65) loss = 6.564, grad_norm = 11.507
I0401 05:07:55.710495 140620467263232 logging_writer.py:48] [66] global_step=66, grad_norm=10.459329, loss=6.414796
I0401 05:07:55.713976 140648769607488 submission.py:139] 66) loss = 6.415, grad_norm = 10.459
I0401 05:07:56.524748 140619745851136 logging_writer.py:48] [67] global_step=67, grad_norm=3.531654, loss=6.316885
I0401 05:07:56.528163 140648769607488 submission.py:139] 67) loss = 6.317, grad_norm = 3.532
I0401 05:07:57.339689 140620467263232 logging_writer.py:48] [68] global_step=68, grad_norm=1.588967, loss=6.263437
I0401 05:07:57.342898 140648769607488 submission.py:139] 68) loss = 6.263, grad_norm = 1.589
I0401 05:07:58.154121 140619745851136 logging_writer.py:48] [69] global_step=69, grad_norm=6.125474, loss=6.326265
I0401 05:07:58.157452 140648769607488 submission.py:139] 69) loss = 6.326, grad_norm = 6.125
I0401 05:07:58.963668 140620467263232 logging_writer.py:48] [70] global_step=70, grad_norm=1.165968, loss=6.232200
I0401 05:07:58.966737 140648769607488 submission.py:139] 70) loss = 6.232, grad_norm = 1.166
I0401 05:07:59.775541 140619745851136 logging_writer.py:48] [71] global_step=71, grad_norm=8.056504, loss=6.314263
I0401 05:07:59.778695 140648769607488 submission.py:139] 71) loss = 6.314, grad_norm = 8.057
I0401 05:08:00.590944 140620467263232 logging_writer.py:48] [72] global_step=72, grad_norm=4.972622, loss=6.253100
I0401 05:08:00.594140 140648769607488 submission.py:139] 72) loss = 6.253, grad_norm = 4.973
I0401 05:08:01.406855 140619745851136 logging_writer.py:48] [73] global_step=73, grad_norm=6.532242, loss=6.252528
I0401 05:08:01.410217 140648769607488 submission.py:139] 73) loss = 6.253, grad_norm = 6.532
I0401 05:08:02.227015 140620467263232 logging_writer.py:48] [74] global_step=74, grad_norm=6.314978, loss=6.277710
I0401 05:08:02.230336 140648769607488 submission.py:139] 74) loss = 6.278, grad_norm = 6.315
I0401 05:08:03.050096 140619745851136 logging_writer.py:48] [75] global_step=75, grad_norm=6.648811, loss=6.252626
I0401 05:08:03.053201 140648769607488 submission.py:139] 75) loss = 6.253, grad_norm = 6.649
I0401 05:08:03.871212 140620467263232 logging_writer.py:48] [76] global_step=76, grad_norm=7.731327, loss=6.259656
I0401 05:08:03.874519 140648769607488 submission.py:139] 76) loss = 6.260, grad_norm = 7.731
I0401 05:08:04.686496 140619745851136 logging_writer.py:48] [77] global_step=77, grad_norm=7.819118, loss=6.239176
I0401 05:08:04.690253 140648769607488 submission.py:139] 77) loss = 6.239, grad_norm = 7.819
I0401 05:08:05.501912 140620467263232 logging_writer.py:48] [78] global_step=78, grad_norm=12.350140, loss=6.326041
I0401 05:08:05.505199 140648769607488 submission.py:139] 78) loss = 6.326, grad_norm = 12.350
I0401 05:08:06.316785 140619745851136 logging_writer.py:48] [79] global_step=79, grad_norm=1.798252, loss=6.148746
I0401 05:08:06.319917 140648769607488 submission.py:139] 79) loss = 6.149, grad_norm = 1.798
I0401 05:08:07.130975 140620467263232 logging_writer.py:48] [80] global_step=80, grad_norm=9.076283, loss=6.242823
I0401 05:08:07.134219 140648769607488 submission.py:139] 80) loss = 6.243, grad_norm = 9.076
I0401 05:08:07.951674 140619745851136 logging_writer.py:48] [81] global_step=81, grad_norm=2.880290, loss=6.143325
I0401 05:08:07.954957 140648769607488 submission.py:139] 81) loss = 6.143, grad_norm = 2.880
I0401 05:08:08.766489 140620467263232 logging_writer.py:48] [82] global_step=82, grad_norm=12.093383, loss=6.287915
I0401 05:08:08.770067 140648769607488 submission.py:139] 82) loss = 6.288, grad_norm = 12.093
I0401 05:08:09.581317 140619745851136 logging_writer.py:48] [83] global_step=83, grad_norm=4.131727, loss=6.145671
I0401 05:08:09.584494 140648769607488 submission.py:139] 83) loss = 6.146, grad_norm = 4.132
I0401 05:08:10.395030 140620467263232 logging_writer.py:48] [84] global_step=84, grad_norm=6.289676, loss=6.196527
I0401 05:08:10.398314 140648769607488 submission.py:139] 84) loss = 6.197, grad_norm = 6.290
I0401 05:08:11.209386 140619745851136 logging_writer.py:48] [85] global_step=85, grad_norm=2.382227, loss=6.095119
I0401 05:08:11.212482 140648769607488 submission.py:139] 85) loss = 6.095, grad_norm = 2.382
I0401 05:08:12.026363 140620467263232 logging_writer.py:48] [86] global_step=86, grad_norm=6.764415, loss=6.137684
I0401 05:08:12.029785 140648769607488 submission.py:139] 86) loss = 6.138, grad_norm = 6.764
I0401 05:08:12.837863 140619745851136 logging_writer.py:48] [87] global_step=87, grad_norm=3.646751, loss=6.088969
I0401 05:08:12.841156 140648769607488 submission.py:139] 87) loss = 6.089, grad_norm = 3.647
I0401 05:08:13.653419 140620467263232 logging_writer.py:48] [88] global_step=88, grad_norm=6.479497, loss=6.124664
I0401 05:08:13.656886 140648769607488 submission.py:139] 88) loss = 6.125, grad_norm = 6.479
I0401 05:08:14.470021 140619745851136 logging_writer.py:48] [89] global_step=89, grad_norm=5.650476, loss=6.113251
I0401 05:08:14.473288 140648769607488 submission.py:139] 89) loss = 6.113, grad_norm = 5.650
I0401 05:08:15.285549 140620467263232 logging_writer.py:48] [90] global_step=90, grad_norm=3.966794, loss=6.061748
I0401 05:08:15.288726 140648769607488 submission.py:139] 90) loss = 6.062, grad_norm = 3.967
I0401 05:08:16.098224 140619745851136 logging_writer.py:48] [91] global_step=91, grad_norm=6.257413, loss=6.124899
I0401 05:08:16.102021 140648769607488 submission.py:139] 91) loss = 6.125, grad_norm = 6.257
I0401 05:08:16.917131 140620467263232 logging_writer.py:48] [92] global_step=92, grad_norm=2.572993, loss=6.049222
I0401 05:08:16.920434 140648769607488 submission.py:139] 92) loss = 6.049, grad_norm = 2.573
I0401 05:08:17.733274 140619745851136 logging_writer.py:48] [93] global_step=93, grad_norm=7.130540, loss=6.103698
I0401 05:08:17.737071 140648769607488 submission.py:139] 93) loss = 6.104, grad_norm = 7.131
I0401 05:08:18.547609 140620467263232 logging_writer.py:48] [94] global_step=94, grad_norm=0.931571, loss=6.035577
I0401 05:08:18.551134 140648769607488 submission.py:139] 94) loss = 6.036, grad_norm = 0.932
I0401 05:08:19.362413 140619745851136 logging_writer.py:48] [95] global_step=95, grad_norm=7.334308, loss=6.113656
I0401 05:08:19.365817 140648769607488 submission.py:139] 95) loss = 6.114, grad_norm = 7.334
I0401 05:08:20.174726 140620467263232 logging_writer.py:48] [96] global_step=96, grad_norm=0.903470, loss=6.039681
I0401 05:08:20.178067 140648769607488 submission.py:139] 96) loss = 6.040, grad_norm = 0.903
I0401 05:08:20.988188 140619745851136 logging_writer.py:48] [97] global_step=97, grad_norm=7.381388, loss=6.085460
I0401 05:08:20.991587 140648769607488 submission.py:139] 97) loss = 6.085, grad_norm = 7.381
I0401 05:08:21.806294 140620467263232 logging_writer.py:48] [98] global_step=98, grad_norm=3.429252, loss=6.039461
I0401 05:08:21.809488 140648769607488 submission.py:139] 98) loss = 6.039, grad_norm = 3.429
I0401 05:08:22.618790 140619745851136 logging_writer.py:48] [99] global_step=99, grad_norm=7.496885, loss=6.097164
I0401 05:08:22.621927 140648769607488 submission.py:139] 99) loss = 6.097, grad_norm = 7.497
I0401 05:08:23.445152 140620467263232 logging_writer.py:48] [100] global_step=100, grad_norm=10.198919, loss=6.167133
I0401 05:08:23.448358 140648769607488 submission.py:139] 100) loss = 6.167, grad_norm = 10.199
I0401 05:13:47.641012 140619745851136 logging_writer.py:48] [500] global_step=500, grad_norm=0.333349, loss=5.762359
I0401 05:13:47.646170 140648769607488 submission.py:139] 500) loss = 5.762, grad_norm = 0.333
I0401 05:20:31.905274 140620467263232 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.849420, loss=4.422804
I0401 05:20:31.909269 140648769607488 submission.py:139] 1000) loss = 4.423, grad_norm = 1.849
I0401 05:27:16.676965 140620467263232 logging_writer.py:48] [1500] global_step=1500, grad_norm=1.904337, loss=3.523729
I0401 05:27:16.704564 140648769607488 submission.py:139] 1500) loss = 3.524, grad_norm = 1.904
I0401 05:34:00.025798 140619745851136 logging_writer.py:48] [2000] global_step=2000, grad_norm=1.069294, loss=3.036127
I0401 05:34:00.030413 140648769607488 submission.py:139] 2000) loss = 3.036, grad_norm = 1.069
I0401 05:40:46.845620 140619745851136 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.982216, loss=2.865979
I0401 05:40:46.852791 140648769607488 submission.py:139] 2500) loss = 2.866, grad_norm = 0.982
I0401 05:47:02.408939 140648769607488 submission_runner.py:371] Before eval at step 2966: RAM USED (GB) 44.137734144
I0401 05:47:02.409212 140648769607488 spec.py:298] Evaluating on the training split.
I0401 05:47:13.187129 140648769607488 spec.py:310] Evaluating on the validation split.
I0401 05:47:22.326917 140648769607488 spec.py:326] Evaluating on the test split.
I0401 05:47:27.481701 140648769607488 submission_runner.py:380] Time since start: 2444.82s, 	Step: 2966, 	{'train/ctc_loss': 2.1538582207028414, 'train/wer': 0.5755811761918352, 'validation/ctc_loss': 2.350085392806912, 'validation/wer': 0.587968908415005, 'validation/num_examples': 5348, 'test/ctc_loss': 1.90784163494419, 'test/wer': 0.5268823756423537, 'test/num_examples': 2472}
I0401 05:47:27.482461 140648769607488 submission_runner.py:390] After eval at step 2966: RAM USED (GB) 42.392653824
I0401 05:47:27.499448 140619745851136 logging_writer.py:48] [2966] global_step=2966, preemption_count=0, score=1467.705837, test/ctc_loss=1.907842, test/num_examples=2472, test/wer=0.526882, total_duration=2444.819482, train/ctc_loss=2.153858, train/wer=0.575581, validation/ctc_loss=2.350085, validation/num_examples=5348, validation/wer=0.587969
I0401 05:47:27.706619 140648769607488 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/librispeech_deepspeech_pytorch/trial_1/checkpoint_2966.
I0401 05:47:27.707195 140648769607488 submission_runner.py:409] After logging and checkpointing eval at step 2966: RAM USED (GB) 42.399424512
I0401 05:47:55.815092 140619737458432 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.949602, loss=2.766330
I0401 05:47:55.819184 140648769607488 submission.py:139] 3000) loss = 2.766, grad_norm = 0.950
I0401 05:54:41.026772 140619737458432 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.956452, loss=2.717460
I0401 05:54:41.073845 140648769607488 submission.py:139] 3500) loss = 2.717, grad_norm = 0.956
I0401 06:01:23.886600 140619729065728 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.926904, loss=2.661445
I0401 06:01:23.988410 140648769607488 submission.py:139] 4000) loss = 2.661, grad_norm = 0.927
I0401 06:08:09.186581 140619729065728 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.689479, loss=2.640996
I0401 06:08:09.193613 140648769607488 submission.py:139] 4500) loss = 2.641, grad_norm = 0.689
I0401 06:14:52.766417 140619578078976 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.919655, loss=2.646399
I0401 06:14:52.770771 140648769607488 submission.py:139] 5000) loss = 2.646, grad_norm = 0.920
I0401 06:21:36.720938 140619578078976 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.865156, loss=2.508080
I0401 06:21:36.737608 140648769607488 submission.py:139] 5500) loss = 2.508, grad_norm = 0.865
I0401 06:27:28.520036 140648769607488 submission_runner.py:371] Before eval at step 5938: RAM USED (GB) 42.328809472
I0401 06:27:28.520263 140648769607488 spec.py:298] Evaluating on the training split.
I0401 06:27:39.373780 140648769607488 spec.py:310] Evaluating on the validation split.
I0401 06:27:48.569935 140648769607488 spec.py:326] Evaluating on the test split.
I0401 06:27:53.593000 140648769607488 submission_runner.py:380] Time since start: 4870.92s, 	Step: 5938, 	{'train/ctc_loss': 1.2509779513355201, 'train/wer': 0.40002477100284867, 'validation/ctc_loss': 1.4866433445411393, 'validation/wer': 0.42696857046299425, 'validation/num_examples': 5348, 'test/ctc_loss': 1.085056798019227, 'test/wer': 0.3591087278857677, 'test/num_examples': 2472}
I0401 06:27:53.593727 140648769607488 submission_runner.py:390] After eval at step 5938: RAM USED (GB) 42.043797504
I0401 06:27:53.619961 140619578078976 logging_writer.py:48] [5938] global_step=5938, preemption_count=0, score=2894.396834, test/ctc_loss=1.085057, test/num_examples=2472, test/wer=0.359109, total_duration=4870.920637, train/ctc_loss=1.250978, train/wer=0.400025, validation/ctc_loss=1.486643, validation/num_examples=5348, validation/wer=0.426969
I0401 06:27:53.841615 140648769607488 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/librispeech_deepspeech_pytorch/trial_1/checkpoint_5938.
I0401 06:27:53.842154 140648769607488 submission_runner.py:409] After logging and checkpointing eval at step 5938: RAM USED (GB) 42.05129728
I0401 06:28:44.459959 140619569686272 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.724563, loss=2.373929
I0401 06:28:44.463990 140648769607488 submission.py:139] 6000) loss = 2.374, grad_norm = 0.725
I0401 06:35:21.967856 140619578078976 logging_writer.py:48] [6500] global_step=6500, grad_norm=nan, loss=nan
I0401 06:35:21.974765 140648769607488 submission.py:139] 6500) loss = nan, grad_norm = nan
I0401 06:41:53.376073 140619569686272 logging_writer.py:48] [7000] global_step=7000, grad_norm=nan, loss=nan
I0401 06:41:53.380272 140648769607488 submission.py:139] 7000) loss = nan, grad_norm = nan
I0401 06:48:25.462447 140619578078976 logging_writer.py:48] [7500] global_step=7500, grad_norm=nan, loss=nan
I0401 06:48:25.468471 140648769607488 submission.py:139] 7500) loss = nan, grad_norm = nan
I0401 06:54:56.974068 140648769607488 submission_runner.py:371] Before eval at step 8000: RAM USED (GB) 42.135707648
I0401 06:54:56.974320 140648769607488 spec.py:298] Evaluating on the training split.
I0401 06:55:06.578510 140648769607488 spec.py:310] Evaluating on the validation split.
I0401 06:55:15.523792 140648769607488 spec.py:326] Evaluating on the test split.
I0401 06:55:20.925554 140648769607488 submission_runner.py:380] Time since start: 6519.40s, 	Step: 8000, 	{'train/ctc_loss': nan, 'train/wer': 0.9421004733415544, 'validation/ctc_loss': nan, 'validation/wer': 0.8967218654950997, 'validation/num_examples': 5348, 'test/ctc_loss': nan, 'test/wer': 0.899579550301627, 'test/num_examples': 2472}
I0401 06:55:20.926413 140648769607488 submission_runner.py:390] After eval at step 8000: RAM USED (GB) 42.230321152
I0401 06:55:20.943334 140619578078976 logging_writer.py:48] [8000] global_step=8000, preemption_count=0, score=3873.741771, test/ctc_loss=nan, test/num_examples=2472, test/wer=0.899580, total_duration=6519.396390, train/ctc_loss=nan, train/wer=0.942100, validation/ctc_loss=nan, validation/num_examples=5348, validation/wer=0.896722
I0401 06:55:21.161267 140648769607488 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/librispeech_deepspeech_pytorch/trial_1/checkpoint_8000.
I0401 06:55:21.161783 140648769607488 submission_runner.py:409] After logging and checkpointing eval at step 8000: RAM USED (GB) 42.218737664
I0401 06:55:21.170394 140619569686272 logging_writer.py:48] [8000] global_step=8000, preemption_count=0, score=3873.741771
I0401 06:55:21.484990 140648769607488 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/timing_momentum/librispeech_deepspeech_pytorch/trial_1/checkpoint_8000.
I0401 06:55:21.625327 140648769607488 submission_runner.py:543] Tuning trial 1/1
I0401 06:55:21.625566 140648769607488 submission_runner.py:544] Hyperparameters: Hyperparameters(learning_rate=0.4394877561366806, one_minus_beta1=0.07113602458522507, warmup_factor=0.05, weight_decay=9.611851572925426e-07, label_smoothing=0.2, dropout_rate=0.0, decay_steps_factor=0.9, end_factor=0.001)
I0401 06:55:21.625932 140648769607488 submission_runner.py:545] Metrics: {'eval_results': [(1, {'train/ctc_loss': 30.90008681640526, 'train/wer': 4.166848859187619, 'validation/ctc_loss': 29.835468153506127, 'validation/wer': 3.8425143629604595, 'validation/num_examples': 5348, 'test/ctc_loss': 29.930876185560358, 'test/wer': 4.145613714378567, 'test/num_examples': 2472, 'score': 8.761362075805664, 'total_duration': 8.7634916305542, 'global_step': 1, 'preemption_count': 0}), (2966, {'train/ctc_loss': 2.1538582207028414, 'train/wer': 0.5755811761918352, 'validation/ctc_loss': 2.350085392806912, 'validation/wer': 0.587968908415005, 'validation/num_examples': 5348, 'test/ctc_loss': 1.90784163494419, 'test/wer': 0.5268823756423537, 'test/num_examples': 2472, 'score': 1467.7058370113373, 'total_duration': 2444.8194818496704, 'global_step': 2966, 'preemption_count': 0}), (5938, {'train/ctc_loss': 1.2509779513355201, 'train/wer': 0.40002477100284867, 'validation/ctc_loss': 1.4866433445411393, 'validation/wer': 0.42696857046299425, 'validation/num_examples': 5348, 'test/ctc_loss': 1.085056798019227, 'test/wer': 0.3591087278857677, 'test/num_examples': 2472, 'score': 2894.396834373474, 'total_duration': 4870.9206366539, 'global_step': 5938, 'preemption_count': 0}), (8000, {'train/ctc_loss': nan, 'train/wer': 0.9421004733415544, 'validation/ctc_loss': nan, 'validation/wer': 0.8967218654950997, 'validation/num_examples': 5348, 'test/ctc_loss': nan, 'test/wer': 0.899579550301627, 'test/num_examples': 2472, 'score': 3873.741771221161, 'total_duration': 6519.396389961243, 'global_step': 8000, 'preemption_count': 0})], 'global_step': 8000}
I0401 06:55:21.626026 140648769607488 submission_runner.py:546] Timing: 3873.741771221161
I0401 06:55:21.626104 140648769607488 submission_runner.py:547] ====================
I0401 06:55:21.626268 140648769607488 submission_runner.py:606] Final librispeech_deepspeech score: 3873.741771221161
